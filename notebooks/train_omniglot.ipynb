{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/work/AnacondaProjects/categorical_bpl\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f48ad788430>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = collections.namedtuple('Args', 'config resume device')\n",
    "config = ConfigParser.from_args(Args(config='omniglot_config.json', resume=None, device=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = config.get_logger('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)\n",
    "model.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = config.init_obj('optimizer', pyro.optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, [], optimizer, config=config,\n",
    "                  data_loader=data_loader,\n",
    "                  valid_data_loader=valid_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/17352 (0%)] Loss: 13781.714844\n",
      "Train Epoch: 1 [80/17352 (0%)] Loss: 12762.446289\n",
      "Train Epoch: 1 [160/17352 (1%)] Loss: 27909.349609\n",
      "Train Epoch: 1 [240/17352 (1%)] Loss: -23961.429688\n",
      "Train Epoch: 1 [320/17352 (2%)] Loss: -39275.539062\n",
      "Train Epoch: 1 [400/17352 (2%)] Loss: -26783.416016\n",
      "Train Epoch: 1 [480/17352 (3%)] Loss: -64708.046875\n",
      "Train Epoch: 1 [560/17352 (3%)] Loss: -81343.093750\n",
      "Train Epoch: 1 [640/17352 (4%)] Loss: -78394.484375\n",
      "Train Epoch: 1 [720/17352 (4%)] Loss: -99848.968750\n",
      "Train Epoch: 1 [800/17352 (5%)] Loss: -117845.851562\n",
      "Train Epoch: 1 [880/17352 (5%)] Loss: -135559.562500\n",
      "Train Epoch: 1 [960/17352 (6%)] Loss: -158445.062500\n",
      "Train Epoch: 1 [1040/17352 (6%)] Loss: -185472.937500\n",
      "Train Epoch: 1 [1120/17352 (6%)] Loss: -210357.453125\n",
      "Train Epoch: 1 [1200/17352 (7%)] Loss: -188108.625000\n",
      "Train Epoch: 1 [1280/17352 (7%)] Loss: -212471.453125\n",
      "Train Epoch: 1 [1360/17352 (8%)] Loss: -200050.031250\n",
      "Train Epoch: 1 [1440/17352 (8%)] Loss: -195483.750000\n",
      "Train Epoch: 1 [1520/17352 (9%)] Loss: -183073.250000\n",
      "Train Epoch: 1 [1600/17352 (9%)] Loss: -182954.171875\n",
      "Train Epoch: 1 [1680/17352 (10%)] Loss: -218387.609375\n",
      "Train Epoch: 1 [1760/17352 (10%)] Loss: -212266.000000\n",
      "Train Epoch: 1 [1840/17352 (11%)] Loss: -212317.328125\n",
      "Train Epoch: 1 [1920/17352 (11%)] Loss: -200162.671875\n",
      "Train Epoch: 1 [2000/17352 (12%)] Loss: -198081.359375\n",
      "Train Epoch: 1 [2080/17352 (12%)] Loss: -210386.203125\n",
      "Train Epoch: 1 [2160/17352 (12%)] Loss: -210944.296875\n",
      "Train Epoch: 1 [2240/17352 (13%)] Loss: -206668.171875\n",
      "Train Epoch: 1 [2320/17352 (13%)] Loss: -179780.671875\n",
      "Train Epoch: 1 [2400/17352 (14%)] Loss: -174048.921875\n",
      "Train Epoch: 1 [2480/17352 (14%)] Loss: -211980.828125\n",
      "Train Epoch: 1 [2560/17352 (15%)] Loss: -167289.187500\n",
      "Train Epoch: 1 [2640/17352 (15%)] Loss: -180368.203125\n",
      "Train Epoch: 1 [2720/17352 (16%)] Loss: -196053.390625\n",
      "Train Epoch: 1 [2800/17352 (16%)] Loss: -200444.656250\n",
      "Train Epoch: 1 [2880/17352 (17%)] Loss: -150752.656250\n",
      "Train Epoch: 1 [2960/17352 (17%)] Loss: -175370.562500\n",
      "Train Epoch: 1 [3040/17352 (18%)] Loss: -193341.968750\n",
      "Train Epoch: 1 [3120/17352 (18%)] Loss: -202751.406250\n",
      "Train Epoch: 1 [3200/17352 (18%)] Loss: -207348.687500\n",
      "Train Epoch: 1 [3280/17352 (19%)] Loss: -202195.000000\n",
      "Train Epoch: 1 [3360/17352 (19%)] Loss: -167498.187500\n",
      "Train Epoch: 1 [3440/17352 (20%)] Loss: -176420.546875\n",
      "Train Epoch: 1 [3520/17352 (20%)] Loss: -195158.968750\n",
      "Train Epoch: 1 [3600/17352 (21%)] Loss: -189662.468750\n",
      "Train Epoch: 1 [3680/17352 (21%)] Loss: -196890.921875\n",
      "Train Epoch: 1 [3760/17352 (22%)] Loss: -202749.578125\n",
      "Train Epoch: 1 [3840/17352 (22%)] Loss: -203588.468750\n",
      "Train Epoch: 1 [3920/17352 (23%)] Loss: -187667.906250\n",
      "Train Epoch: 1 [4000/17352 (23%)] Loss: -165321.937500\n",
      "Train Epoch: 1 [4080/17352 (24%)] Loss: -195043.468750\n",
      "Train Epoch: 1 [4160/17352 (24%)] Loss: -187681.093750\n",
      "Train Epoch: 1 [4240/17352 (24%)] Loss: -174286.640625\n",
      "Train Epoch: 1 [4320/17352 (25%)] Loss: -187136.281250\n",
      "Train Epoch: 1 [4400/17352 (25%)] Loss: -178123.656250\n",
      "Train Epoch: 1 [4480/17352 (26%)] Loss: -178380.375000\n",
      "Train Epoch: 1 [4560/17352 (26%)] Loss: -194289.250000\n",
      "Train Epoch: 1 [4640/17352 (27%)] Loss: -196117.578125\n",
      "Train Epoch: 1 [4720/17352 (27%)] Loss: -201766.812500\n",
      "Train Epoch: 1 [4800/17352 (28%)] Loss: -209381.796875\n",
      "Train Epoch: 1 [4880/17352 (28%)] Loss: -150562.781250\n",
      "Train Epoch: 1 [4960/17352 (29%)] Loss: -180731.203125\n",
      "Train Epoch: 1 [5040/17352 (29%)] Loss: -176723.312500\n",
      "Train Epoch: 1 [5120/17352 (30%)] Loss: -212541.562500\n",
      "Train Epoch: 1 [5200/17352 (30%)] Loss: -196800.109375\n",
      "Train Epoch: 1 [5280/17352 (30%)] Loss: -179708.078125\n",
      "Train Epoch: 1 [5360/17352 (31%)] Loss: -171717.718750\n",
      "Train Epoch: 1 [5440/17352 (31%)] Loss: -178384.375000\n",
      "Train Epoch: 1 [5520/17352 (32%)] Loss: -209033.843750\n",
      "Train Epoch: 1 [5600/17352 (32%)] Loss: -201539.187500\n",
      "Train Epoch: 1 [5680/17352 (33%)] Loss: -184665.906250\n",
      "Train Epoch: 1 [5760/17352 (33%)] Loss: -172452.890625\n",
      "Train Epoch: 1 [5840/17352 (34%)] Loss: -202700.218750\n",
      "Train Epoch: 1 [5920/17352 (34%)] Loss: -194318.593750\n",
      "Train Epoch: 1 [6000/17352 (35%)] Loss: -191584.796875\n",
      "Train Epoch: 1 [6080/17352 (35%)] Loss: -192771.609375\n",
      "Train Epoch: 1 [6160/17352 (36%)] Loss: -175015.312500\n",
      "Train Epoch: 1 [6240/17352 (36%)] Loss: -191580.906250\n",
      "Train Epoch: 1 [6320/17352 (36%)] Loss: -180977.156250\n",
      "Train Epoch: 1 [6400/17352 (37%)] Loss: -167522.328125\n",
      "Train Epoch: 1 [6480/17352 (37%)] Loss: -182004.171875\n",
      "Train Epoch: 1 [6560/17352 (38%)] Loss: -203377.812500\n",
      "Train Epoch: 1 [6640/17352 (38%)] Loss: -182524.187500\n",
      "Train Epoch: 1 [6720/17352 (39%)] Loss: -192739.578125\n",
      "Train Epoch: 1 [6800/17352 (39%)] Loss: -186175.093750\n",
      "Train Epoch: 1 [6880/17352 (40%)] Loss: -176303.812500\n",
      "Train Epoch: 1 [6960/17352 (40%)] Loss: -176224.031250\n",
      "Train Epoch: 1 [7040/17352 (41%)] Loss: -169264.765625\n",
      "Train Epoch: 1 [7120/17352 (41%)] Loss: -175686.781250\n",
      "Train Epoch: 1 [7200/17352 (41%)] Loss: -214843.828125\n",
      "Train Epoch: 1 [7280/17352 (42%)] Loss: -179068.671875\n",
      "Train Epoch: 1 [7360/17352 (42%)] Loss: -189910.921875\n",
      "Train Epoch: 1 [7440/17352 (43%)] Loss: -188850.937500\n",
      "Train Epoch: 1 [7520/17352 (43%)] Loss: -187560.328125\n",
      "Train Epoch: 1 [7600/17352 (44%)] Loss: -190185.468750\n",
      "Train Epoch: 1 [7680/17352 (44%)] Loss: -192394.468750\n",
      "Train Epoch: 1 [7760/17352 (45%)] Loss: -193234.500000\n",
      "Train Epoch: 1 [7840/17352 (45%)] Loss: -223383.500000\n",
      "Train Epoch: 1 [7920/17352 (46%)] Loss: -169652.203125\n",
      "Train Epoch: 1 [8000/17352 (46%)] Loss: -170444.187500\n",
      "Train Epoch: 1 [8080/17352 (47%)] Loss: -202683.468750\n",
      "Train Epoch: 1 [8160/17352 (47%)] Loss: -172264.843750\n",
      "Train Epoch: 1 [8240/17352 (47%)] Loss: -199987.484375\n",
      "Train Epoch: 1 [8320/17352 (48%)] Loss: -199807.921875\n",
      "Train Epoch: 1 [8400/17352 (48%)] Loss: -184239.843750\n",
      "Train Epoch: 1 [8480/17352 (49%)] Loss: -230689.609375\n",
      "Train Epoch: 1 [8560/17352 (49%)] Loss: -215154.546875\n",
      "Train Epoch: 1 [8640/17352 (50%)] Loss: -184747.968750\n",
      "Train Epoch: 1 [8720/17352 (50%)] Loss: -213100.828125\n",
      "Train Epoch: 1 [8800/17352 (51%)] Loss: -174757.578125\n",
      "Train Epoch: 1 [8880/17352 (51%)] Loss: -186199.406250\n",
      "Train Epoch: 1 [8960/17352 (52%)] Loss: -173635.921875\n",
      "Train Epoch: 1 [9040/17352 (52%)] Loss: -171615.312500\n",
      "Train Epoch: 1 [9120/17352 (53%)] Loss: -164778.328125\n",
      "Train Epoch: 1 [9200/17352 (53%)] Loss: -218166.078125\n",
      "Train Epoch: 1 [9280/17352 (53%)] Loss: -192526.796875\n",
      "Train Epoch: 1 [9360/17352 (54%)] Loss: -192671.468750\n",
      "Train Epoch: 1 [9440/17352 (54%)] Loss: -185012.062500\n",
      "Train Epoch: 1 [9520/17352 (55%)] Loss: -173384.000000\n",
      "Train Epoch: 1 [9600/17352 (55%)] Loss: -210248.578125\n",
      "Train Epoch: 1 [9680/17352 (56%)] Loss: -188787.828125\n",
      "Train Epoch: 1 [9760/17352 (56%)] Loss: -205302.812500\n",
      "Train Epoch: 1 [9840/17352 (57%)] Loss: -182967.875000\n",
      "Train Epoch: 1 [9920/17352 (57%)] Loss: -170054.734375\n",
      "Train Epoch: 1 [10000/17352 (58%)] Loss: -200841.265625\n",
      "Train Epoch: 1 [10080/17352 (58%)] Loss: -199927.250000\n",
      "Train Epoch: 1 [10160/17352 (59%)] Loss: -163283.937500\n",
      "Train Epoch: 1 [10240/17352 (59%)] Loss: -178541.062500\n",
      "Train Epoch: 1 [10320/17352 (59%)] Loss: -188618.156250\n",
      "Train Epoch: 1 [10400/17352 (60%)] Loss: -184523.406250\n",
      "Train Epoch: 1 [10480/17352 (60%)] Loss: -179873.656250\n",
      "Train Epoch: 1 [10560/17352 (61%)] Loss: -188489.015625\n",
      "Train Epoch: 1 [10640/17352 (61%)] Loss: -188706.437500\n",
      "Train Epoch: 1 [10720/17352 (62%)] Loss: -175318.937500\n",
      "Train Epoch: 1 [10800/17352 (62%)] Loss: -158425.781250\n",
      "Train Epoch: 1 [10880/17352 (63%)] Loss: -183028.718750\n",
      "Train Epoch: 1 [10960/17352 (63%)] Loss: -202540.328125\n",
      "Train Epoch: 1 [11040/17352 (64%)] Loss: -194920.421875\n",
      "Train Epoch: 1 [11120/17352 (64%)] Loss: -180539.250000\n",
      "Train Epoch: 1 [11200/17352 (65%)] Loss: -218299.390625\n",
      "Train Epoch: 1 [11280/17352 (65%)] Loss: -214410.875000\n",
      "Train Epoch: 1 [11360/17352 (65%)] Loss: -219700.812500\n",
      "Train Epoch: 1 [11440/17352 (66%)] Loss: -196580.312500\n",
      "Train Epoch: 1 [11520/17352 (66%)] Loss: -227957.906250\n",
      "Train Epoch: 1 [11600/17352 (67%)] Loss: -159894.968750\n",
      "Train Epoch: 1 [11680/17352 (67%)] Loss: -212753.000000\n",
      "Train Epoch: 1 [11760/17352 (68%)] Loss: -174274.968750\n",
      "Train Epoch: 1 [11840/17352 (68%)] Loss: -192711.265625\n",
      "Train Epoch: 1 [11920/17352 (69%)] Loss: -189638.906250\n",
      "Train Epoch: 1 [12000/17352 (69%)] Loss: -170593.109375\n",
      "Train Epoch: 1 [12080/17352 (70%)] Loss: -178618.984375\n",
      "Train Epoch: 1 [12160/17352 (70%)] Loss: -201808.453125\n",
      "Train Epoch: 1 [12240/17352 (71%)] Loss: -190208.234375\n",
      "Train Epoch: 1 [12320/17352 (71%)] Loss: -198040.562500\n",
      "Train Epoch: 1 [12400/17352 (71%)] Loss: -197388.781250\n",
      "Train Epoch: 1 [12480/17352 (72%)] Loss: -187613.218750\n",
      "Train Epoch: 1 [12560/17352 (72%)] Loss: -187961.625000\n",
      "Train Epoch: 1 [12640/17352 (73%)] Loss: -174811.968750\n",
      "Train Epoch: 1 [12720/17352 (73%)] Loss: -184758.078125\n",
      "Train Epoch: 1 [12800/17352 (74%)] Loss: -187488.796875\n",
      "Train Epoch: 1 [12880/17352 (74%)] Loss: -170135.703125\n",
      "Train Epoch: 1 [12960/17352 (75%)] Loss: -200763.484375\n",
      "Train Epoch: 1 [13040/17352 (75%)] Loss: -192716.765625\n",
      "Train Epoch: 1 [13120/17352 (76%)] Loss: -159543.687500\n",
      "Train Epoch: 1 [13200/17352 (76%)] Loss: -184731.406250\n",
      "Train Epoch: 1 [13280/17352 (77%)] Loss: -183813.921875\n",
      "Train Epoch: 1 [13360/17352 (77%)] Loss: -187575.093750\n",
      "Train Epoch: 1 [13440/17352 (77%)] Loss: -191177.890625\n",
      "Train Epoch: 1 [13520/17352 (78%)] Loss: -187420.625000\n",
      "Train Epoch: 1 [13600/17352 (78%)] Loss: -152590.125000\n",
      "Train Epoch: 1 [13680/17352 (79%)] Loss: -186582.921875\n",
      "Train Epoch: 1 [13760/17352 (79%)] Loss: -183261.078125\n",
      "Train Epoch: 1 [13840/17352 (80%)] Loss: -185804.187500\n",
      "Train Epoch: 1 [13920/17352 (80%)] Loss: -176014.671875\n",
      "Train Epoch: 1 [14000/17352 (81%)] Loss: -195639.343750\n",
      "Train Epoch: 1 [14080/17352 (81%)] Loss: -164667.921875\n",
      "Train Epoch: 1 [14160/17352 (82%)] Loss: -202335.546875\n",
      "Train Epoch: 1 [14240/17352 (82%)] Loss: -163962.015625\n",
      "Train Epoch: 1 [14320/17352 (83%)] Loss: -208250.750000\n",
      "Train Epoch: 1 [14400/17352 (83%)] Loss: -196384.125000\n",
      "Train Epoch: 1 [14480/17352 (83%)] Loss: -183412.562500\n",
      "Train Epoch: 1 [14560/17352 (84%)] Loss: -181634.062500\n",
      "Train Epoch: 1 [14640/17352 (84%)] Loss: -195142.937500\n",
      "Train Epoch: 1 [14720/17352 (85%)] Loss: -184841.921875\n",
      "Train Epoch: 1 [14800/17352 (85%)] Loss: -200276.171875\n",
      "Train Epoch: 1 [14880/17352 (86%)] Loss: -176952.656250\n",
      "Train Epoch: 1 [14960/17352 (86%)] Loss: -170286.421875\n",
      "Train Epoch: 1 [15040/17352 (87%)] Loss: -204281.406250\n",
      "Train Epoch: 1 [15120/17352 (87%)] Loss: -164373.234375\n",
      "Train Epoch: 1 [15200/17352 (88%)] Loss: -144528.312500\n",
      "Train Epoch: 1 [15280/17352 (88%)] Loss: -169436.000000\n",
      "Train Epoch: 1 [15360/17352 (89%)] Loss: -186254.468750\n",
      "Train Epoch: 1 [15440/17352 (89%)] Loss: -194952.296875\n",
      "Train Epoch: 1 [15520/17352 (89%)] Loss: -175260.312500\n",
      "Train Epoch: 1 [15600/17352 (90%)] Loss: -180432.500000\n",
      "Train Epoch: 1 [15680/17352 (90%)] Loss: -204455.359375\n",
      "Train Epoch: 1 [15760/17352 (91%)] Loss: -192605.500000\n",
      "Train Epoch: 1 [15840/17352 (91%)] Loss: -190368.296875\n",
      "Train Epoch: 1 [15920/17352 (92%)] Loss: -185364.250000\n",
      "Train Epoch: 1 [16000/17352 (92%)] Loss: -207574.125000\n",
      "Train Epoch: 1 [16080/17352 (93%)] Loss: -181422.640625\n",
      "Train Epoch: 1 [16160/17352 (93%)] Loss: -180662.609375\n",
      "Train Epoch: 1 [16240/17352 (94%)] Loss: -206114.515625\n",
      "Train Epoch: 1 [16320/17352 (94%)] Loss: -187295.312500\n",
      "Train Epoch: 1 [16400/17352 (95%)] Loss: -178702.734375\n",
      "Train Epoch: 1 [16480/17352 (95%)] Loss: -148232.562500\n",
      "Train Epoch: 1 [16560/17352 (95%)] Loss: -209958.156250\n",
      "Train Epoch: 1 [16640/17352 (96%)] Loss: -176650.171875\n",
      "Train Epoch: 1 [16720/17352 (96%)] Loss: -163122.031250\n",
      "Train Epoch: 1 [16800/17352 (97%)] Loss: -206010.546875\n",
      "Train Epoch: 1 [16880/17352 (97%)] Loss: -185136.843750\n",
      "Train Epoch: 1 [16960/17352 (98%)] Loss: -208844.765625\n",
      "Train Epoch: 1 [17040/17352 (98%)] Loss: -171440.234375\n",
      "Train Epoch: 1 [17120/17352 (99%)] Loss: -189069.187500\n",
      "Train Epoch: 1 [17200/17352 (99%)] Loss: -180681.593750\n",
      "Train Epoch: 1 [17280/17352 (100%)] Loss: -215580.687500\n",
      "Train Epoch: 1 [17360/17352 (100%)] Loss: -189131.140625\n",
      "    epoch          : 1\n",
      "    loss           : -179230.1130511566\n",
      "    val_loss       : -23474.273012044843\n",
      "Train Epoch: 2 [0/17352 (0%)] Loss: -210984.625000\n",
      "Train Epoch: 2 [80/17352 (0%)] Loss: -204458.125000\n",
      "Train Epoch: 2 [160/17352 (1%)] Loss: -227974.468750\n",
      "Train Epoch: 2 [240/17352 (1%)] Loss: -214931.687500\n",
      "Train Epoch: 2 [320/17352 (2%)] Loss: -210722.859375\n",
      "Train Epoch: 2 [400/17352 (2%)] Loss: -208461.015625\n",
      "Train Epoch: 2 [480/17352 (3%)] Loss: -202979.250000\n",
      "Train Epoch: 2 [560/17352 (3%)] Loss: -203398.984375\n",
      "Train Epoch: 2 [640/17352 (4%)] Loss: -203075.984375\n",
      "Train Epoch: 2 [720/17352 (4%)] Loss: -207553.968750\n",
      "Train Epoch: 2 [800/17352 (5%)] Loss: -225500.171875\n",
      "Train Epoch: 2 [880/17352 (5%)] Loss: -230947.671875\n",
      "Train Epoch: 2 [960/17352 (6%)] Loss: -207933.062500\n",
      "Train Epoch: 2 [1040/17352 (6%)] Loss: -229122.953125\n",
      "Train Epoch: 2 [1120/17352 (6%)] Loss: -190188.812500\n",
      "Train Epoch: 2 [1200/17352 (7%)] Loss: -216524.406250\n",
      "Train Epoch: 2 [1280/17352 (7%)] Loss: -189631.296875\n",
      "Train Epoch: 2 [1360/17352 (8%)] Loss: -191045.718750\n",
      "Train Epoch: 2 [1440/17352 (8%)] Loss: -187103.890625\n",
      "Train Epoch: 2 [1520/17352 (9%)] Loss: -219805.000000\n",
      "Train Epoch: 2 [1600/17352 (9%)] Loss: -211379.140625\n",
      "Train Epoch: 2 [1680/17352 (10%)] Loss: -200927.843750\n",
      "Train Epoch: 2 [1760/17352 (10%)] Loss: -211460.296875\n",
      "Train Epoch: 2 [1840/17352 (11%)] Loss: -199850.437500\n",
      "Train Epoch: 2 [1920/17352 (11%)] Loss: -202038.875000\n",
      "Train Epoch: 2 [2000/17352 (12%)] Loss: -214480.500000\n",
      "Train Epoch: 2 [2080/17352 (12%)] Loss: -213536.796875\n",
      "Train Epoch: 2 [2160/17352 (12%)] Loss: -202165.484375\n",
      "Train Epoch: 2 [2240/17352 (13%)] Loss: -176764.765625\n",
      "Train Epoch: 2 [2320/17352 (13%)] Loss: -175104.437500\n",
      "Train Epoch: 2 [2400/17352 (14%)] Loss: -142616.703125\n",
      "Train Epoch: 2 [2480/17352 (14%)] Loss: -158566.343750\n",
      "Train Epoch: 2 [2560/17352 (15%)] Loss: -183171.484375\n",
      "Train Epoch: 2 [2640/17352 (15%)] Loss: -194854.218750\n",
      "Train Epoch: 2 [2720/17352 (16%)] Loss: -183272.781250\n",
      "Train Epoch: 2 [2800/17352 (16%)] Loss: -171041.093750\n",
      "Train Epoch: 2 [2880/17352 (17%)] Loss: -207105.093750\n",
      "Train Epoch: 2 [2960/17352 (17%)] Loss: -211704.031250\n",
      "Train Epoch: 2 [3040/17352 (18%)] Loss: -192194.359375\n",
      "Train Epoch: 2 [3120/17352 (18%)] Loss: -198369.484375\n",
      "Train Epoch: 2 [3200/17352 (18%)] Loss: -214152.359375\n",
      "Train Epoch: 2 [3280/17352 (19%)] Loss: -162915.156250\n",
      "Train Epoch: 2 [3360/17352 (19%)] Loss: -180185.562500\n",
      "Train Epoch: 2 [3440/17352 (20%)] Loss: -195555.437500\n",
      "Train Epoch: 2 [3520/17352 (20%)] Loss: -166179.078125\n",
      "Train Epoch: 2 [3600/17352 (21%)] Loss: -173438.718750\n",
      "Train Epoch: 2 [3680/17352 (21%)] Loss: -164719.015625\n",
      "Train Epoch: 2 [3760/17352 (22%)] Loss: -187255.687500\n",
      "Train Epoch: 2 [3840/17352 (22%)] Loss: -194668.109375\n",
      "Train Epoch: 2 [3920/17352 (23%)] Loss: -189317.171875\n",
      "Train Epoch: 2 [4000/17352 (23%)] Loss: -179994.453125\n",
      "Train Epoch: 2 [4080/17352 (24%)] Loss: -204630.953125\n",
      "Train Epoch: 2 [4160/17352 (24%)] Loss: -180346.906250\n",
      "Train Epoch: 2 [4240/17352 (24%)] Loss: -174267.171875\n",
      "Train Epoch: 2 [4320/17352 (25%)] Loss: -184678.671875\n",
      "Train Epoch: 2 [4400/17352 (25%)] Loss: -185751.484375\n",
      "Train Epoch: 2 [4480/17352 (26%)] Loss: -206870.312500\n",
      "Train Epoch: 2 [4560/17352 (26%)] Loss: -173910.453125\n",
      "Train Epoch: 2 [4640/17352 (27%)] Loss: -177472.906250\n",
      "Train Epoch: 2 [4720/17352 (27%)] Loss: -219681.250000\n",
      "Train Epoch: 2 [4800/17352 (28%)] Loss: -166762.734375\n",
      "Train Epoch: 2 [4880/17352 (28%)] Loss: -180260.984375\n",
      "Train Epoch: 2 [4960/17352 (29%)] Loss: -176446.828125\n",
      "Train Epoch: 2 [5040/17352 (29%)] Loss: -181420.812500\n",
      "Train Epoch: 2 [5120/17352 (30%)] Loss: -197292.281250\n",
      "Train Epoch: 2 [5200/17352 (30%)] Loss: -197715.437500\n",
      "Train Epoch: 2 [5280/17352 (30%)] Loss: -172895.718750\n",
      "Train Epoch: 2 [5360/17352 (31%)] Loss: -191018.531250\n",
      "Train Epoch: 2 [5440/17352 (31%)] Loss: -189966.359375\n",
      "Train Epoch: 2 [5520/17352 (32%)] Loss: -199984.781250\n",
      "Train Epoch: 2 [5600/17352 (32%)] Loss: -178432.812500\n",
      "Train Epoch: 2 [5680/17352 (33%)] Loss: -185178.468750\n",
      "Train Epoch: 2 [5760/17352 (33%)] Loss: -198001.781250\n",
      "Train Epoch: 2 [5840/17352 (34%)] Loss: -192408.437500\n",
      "Train Epoch: 2 [5920/17352 (34%)] Loss: -176869.046875\n",
      "Train Epoch: 2 [6000/17352 (35%)] Loss: -180037.296875\n",
      "Train Epoch: 2 [6080/17352 (35%)] Loss: -174443.484375\n",
      "Train Epoch: 2 [6160/17352 (36%)] Loss: -204958.453125\n",
      "Train Epoch: 2 [6240/17352 (36%)] Loss: -195674.078125\n",
      "Train Epoch: 2 [6320/17352 (36%)] Loss: -200391.453125\n",
      "Train Epoch: 2 [6400/17352 (37%)] Loss: -159507.953125\n",
      "Train Epoch: 2 [6480/17352 (37%)] Loss: -174764.328125\n",
      "Train Epoch: 2 [6560/17352 (38%)] Loss: -201123.515625\n",
      "Train Epoch: 2 [6640/17352 (38%)] Loss: -169538.437500\n",
      "Train Epoch: 2 [6720/17352 (39%)] Loss: -210320.125000\n",
      "Train Epoch: 2 [6800/17352 (39%)] Loss: -184726.750000\n",
      "Train Epoch: 2 [6880/17352 (40%)] Loss: -193281.390625\n",
      "Train Epoch: 2 [6960/17352 (40%)] Loss: -163761.375000\n",
      "Train Epoch: 2 [7040/17352 (41%)] Loss: -188293.328125\n",
      "Train Epoch: 2 [7120/17352 (41%)] Loss: -198339.703125\n",
      "Train Epoch: 2 [7200/17352 (41%)] Loss: -178367.109375\n",
      "Train Epoch: 2 [7280/17352 (42%)] Loss: -182908.031250\n",
      "Train Epoch: 2 [7360/17352 (42%)] Loss: -180074.578125\n",
      "Train Epoch: 2 [7440/17352 (43%)] Loss: -177112.265625\n",
      "Train Epoch: 2 [7520/17352 (43%)] Loss: -165490.359375\n",
      "Train Epoch: 2 [7600/17352 (44%)] Loss: -195921.750000\n",
      "Train Epoch: 2 [7680/17352 (44%)] Loss: -177181.765625\n",
      "Train Epoch: 2 [7760/17352 (45%)] Loss: -202992.500000\n",
      "Train Epoch: 2 [7840/17352 (45%)] Loss: -184880.218750\n",
      "Train Epoch: 2 [7920/17352 (46%)] Loss: -204153.312500\n",
      "Train Epoch: 2 [8000/17352 (46%)] Loss: -210002.968750\n",
      "Train Epoch: 2 [8080/17352 (47%)] Loss: -167579.718750\n",
      "Train Epoch: 2 [8160/17352 (47%)] Loss: -187021.578125\n",
      "Train Epoch: 2 [8240/17352 (47%)] Loss: -178482.656250\n",
      "Train Epoch: 2 [8320/17352 (48%)] Loss: -189385.265625\n",
      "Train Epoch: 2 [8400/17352 (48%)] Loss: -177176.453125\n",
      "Train Epoch: 2 [8480/17352 (49%)] Loss: -166914.437500\n",
      "Train Epoch: 2 [8560/17352 (49%)] Loss: -202849.062500\n",
      "Train Epoch: 2 [8640/17352 (50%)] Loss: -173345.484375\n",
      "Train Epoch: 2 [8720/17352 (50%)] Loss: -205915.687500\n",
      "Train Epoch: 2 [8800/17352 (51%)] Loss: -172351.781250\n",
      "Train Epoch: 2 [8880/17352 (51%)] Loss: -179945.187500\n",
      "Train Epoch: 2 [8960/17352 (52%)] Loss: -169248.140625\n",
      "Train Epoch: 2 [9040/17352 (52%)] Loss: -177448.625000\n",
      "Train Epoch: 2 [9120/17352 (53%)] Loss: -180367.921875\n",
      "Train Epoch: 2 [9200/17352 (53%)] Loss: -164661.250000\n",
      "Train Epoch: 2 [9280/17352 (53%)] Loss: -176745.218750\n",
      "Train Epoch: 2 [9360/17352 (54%)] Loss: -211958.546875\n",
      "Train Epoch: 2 [9440/17352 (54%)] Loss: -181759.500000\n",
      "Train Epoch: 2 [9520/17352 (55%)] Loss: -175164.546875\n",
      "Train Epoch: 2 [9600/17352 (55%)] Loss: -179150.468750\n",
      "Train Epoch: 2 [9680/17352 (56%)] Loss: -174331.593750\n",
      "Train Epoch: 2 [9760/17352 (56%)] Loss: -174808.453125\n",
      "Train Epoch: 2 [9840/17352 (57%)] Loss: -152597.453125\n",
      "Train Epoch: 2 [9920/17352 (57%)] Loss: -190771.859375\n",
      "Train Epoch: 2 [10000/17352 (58%)] Loss: -159484.828125\n",
      "Train Epoch: 2 [10080/17352 (58%)] Loss: -190080.125000\n",
      "Train Epoch: 2 [10160/17352 (59%)] Loss: -174835.609375\n",
      "Train Epoch: 2 [10240/17352 (59%)] Loss: -202417.796875\n",
      "Train Epoch: 2 [10320/17352 (59%)] Loss: -193922.000000\n",
      "Train Epoch: 2 [10400/17352 (60%)] Loss: -184114.390625\n",
      "Train Epoch: 2 [10480/17352 (60%)] Loss: -182381.984375\n",
      "Train Epoch: 2 [10560/17352 (61%)] Loss: -196456.437500\n",
      "Train Epoch: 2 [10640/17352 (61%)] Loss: -169772.500000\n",
      "Train Epoch: 2 [10720/17352 (62%)] Loss: -184570.437500\n",
      "Train Epoch: 2 [10800/17352 (62%)] Loss: -204324.000000\n",
      "Train Epoch: 2 [10880/17352 (63%)] Loss: -161371.984375\n",
      "Train Epoch: 2 [10960/17352 (63%)] Loss: -180888.906250\n",
      "Train Epoch: 2 [11040/17352 (64%)] Loss: -174547.078125\n",
      "Train Epoch: 2 [11120/17352 (64%)] Loss: -187321.515625\n",
      "Train Epoch: 2 [11200/17352 (65%)] Loss: -169953.875000\n",
      "Train Epoch: 2 [11280/17352 (65%)] Loss: -172061.500000\n",
      "Train Epoch: 2 [11360/17352 (65%)] Loss: -183022.750000\n",
      "Train Epoch: 2 [11440/17352 (66%)] Loss: -134389.937500\n",
      "Train Epoch: 2 [11520/17352 (66%)] Loss: -176440.343750\n",
      "Train Epoch: 2 [11600/17352 (67%)] Loss: -200009.062500\n",
      "Train Epoch: 2 [11680/17352 (67%)] Loss: -198578.234375\n",
      "Train Epoch: 2 [11760/17352 (68%)] Loss: -189635.312500\n",
      "Train Epoch: 2 [11840/17352 (68%)] Loss: -185129.406250\n",
      "Train Epoch: 2 [11920/17352 (69%)] Loss: -199642.328125\n",
      "Train Epoch: 2 [12000/17352 (69%)] Loss: -165653.296875\n",
      "Train Epoch: 2 [12080/17352 (70%)] Loss: -211025.984375\n",
      "Train Epoch: 2 [12160/17352 (70%)] Loss: -183530.234375\n",
      "Train Epoch: 2 [12240/17352 (71%)] Loss: -203579.859375\n",
      "Train Epoch: 2 [12320/17352 (71%)] Loss: -210300.828125\n",
      "Train Epoch: 2 [12400/17352 (71%)] Loss: -173794.906250\n",
      "Train Epoch: 2 [12480/17352 (72%)] Loss: -167767.671875\n",
      "Train Epoch: 2 [12560/17352 (72%)] Loss: -169398.390625\n",
      "Train Epoch: 2 [12640/17352 (73%)] Loss: -187174.125000\n",
      "Train Epoch: 2 [12720/17352 (73%)] Loss: -208596.296875\n",
      "Train Epoch: 2 [12800/17352 (74%)] Loss: -184730.281250\n",
      "Train Epoch: 2 [12880/17352 (74%)] Loss: -191958.593750\n",
      "Train Epoch: 2 [12960/17352 (75%)] Loss: -195681.625000\n",
      "Train Epoch: 2 [13040/17352 (75%)] Loss: -204848.562500\n",
      "Train Epoch: 2 [13120/17352 (76%)] Loss: -191578.531250\n",
      "Train Epoch: 2 [13200/17352 (76%)] Loss: -192220.890625\n",
      "Train Epoch: 2 [13280/17352 (77%)] Loss: -166293.250000\n",
      "Train Epoch: 2 [13360/17352 (77%)] Loss: -173558.656250\n",
      "Train Epoch: 2 [13440/17352 (77%)] Loss: -175554.968750\n",
      "Train Epoch: 2 [13520/17352 (78%)] Loss: -179906.796875\n",
      "Train Epoch: 2 [13600/17352 (78%)] Loss: -187919.656250\n",
      "Train Epoch: 2 [13680/17352 (79%)] Loss: -188032.656250\n",
      "Train Epoch: 2 [13760/17352 (79%)] Loss: -148406.468750\n",
      "Train Epoch: 2 [13840/17352 (80%)] Loss: -170659.000000\n",
      "Train Epoch: 2 [13920/17352 (80%)] Loss: -197002.468750\n",
      "Train Epoch: 2 [14000/17352 (81%)] Loss: -204466.625000\n",
      "Train Epoch: 2 [14080/17352 (81%)] Loss: -142511.671875\n",
      "Train Epoch: 2 [14160/17352 (82%)] Loss: -176049.796875\n",
      "Train Epoch: 2 [14240/17352 (82%)] Loss: -193210.406250\n",
      "Train Epoch: 2 [14320/17352 (83%)] Loss: -182935.703125\n",
      "Train Epoch: 2 [14400/17352 (83%)] Loss: -163001.234375\n",
      "Train Epoch: 2 [14480/17352 (83%)] Loss: -178206.812500\n",
      "Train Epoch: 2 [14560/17352 (84%)] Loss: -175523.093750\n",
      "Train Epoch: 2 [14640/17352 (84%)] Loss: -176036.750000\n",
      "Train Epoch: 2 [14720/17352 (85%)] Loss: -164269.531250\n",
      "Train Epoch: 2 [14800/17352 (85%)] Loss: -189862.640625\n",
      "Train Epoch: 2 [14880/17352 (86%)] Loss: -183416.343750\n",
      "Train Epoch: 2 [14960/17352 (86%)] Loss: -200074.859375\n",
      "Train Epoch: 2 [15040/17352 (87%)] Loss: -215883.343750\n",
      "Train Epoch: 2 [15120/17352 (87%)] Loss: -192189.031250\n",
      "Train Epoch: 2 [15200/17352 (88%)] Loss: -166373.531250\n",
      "Train Epoch: 2 [15280/17352 (88%)] Loss: -192188.515625\n",
      "Train Epoch: 2 [15360/17352 (89%)] Loss: -95184.351562\n",
      "Train Epoch: 2 [15440/17352 (89%)] Loss: -170589.906250\n",
      "Train Epoch: 2 [15520/17352 (89%)] Loss: -199939.625000\n",
      "Train Epoch: 2 [15600/17352 (90%)] Loss: -189287.937500\n",
      "Train Epoch: 2 [15680/17352 (90%)] Loss: -148285.828125\n",
      "Train Epoch: 2 [15760/17352 (91%)] Loss: -187485.093750\n",
      "Train Epoch: 2 [15840/17352 (91%)] Loss: -209720.937500\n",
      "Train Epoch: 2 [15920/17352 (92%)] Loss: -178622.343750\n",
      "Train Epoch: 2 [16000/17352 (92%)] Loss: -194484.531250\n",
      "Train Epoch: 2 [16080/17352 (93%)] Loss: -183268.156250\n",
      "Train Epoch: 2 [16160/17352 (93%)] Loss: -200931.093750\n",
      "Train Epoch: 2 [16240/17352 (94%)] Loss: -166547.250000\n",
      "Train Epoch: 2 [16320/17352 (94%)] Loss: -189137.562500\n",
      "Train Epoch: 2 [16400/17352 (95%)] Loss: -162631.703125\n",
      "Train Epoch: 2 [16480/17352 (95%)] Loss: -176775.109375\n",
      "Train Epoch: 2 [16560/17352 (95%)] Loss: -223857.421875\n",
      "Train Epoch: 2 [16640/17352 (96%)] Loss: -185327.796875\n",
      "Train Epoch: 2 [16720/17352 (96%)] Loss: -199293.562500\n",
      "Train Epoch: 2 [16800/17352 (97%)] Loss: -201207.687500\n",
      "Train Epoch: 2 [16880/17352 (97%)] Loss: -188593.156250\n",
      "Train Epoch: 2 [16960/17352 (98%)] Loss: -182639.343750\n",
      "Train Epoch: 2 [17040/17352 (98%)] Loss: -203008.578125\n",
      "Train Epoch: 2 [17120/17352 (99%)] Loss: -156492.250000\n",
      "Train Epoch: 2 [17200/17352 (99%)] Loss: -201697.328125\n",
      "Train Epoch: 2 [17280/17352 (100%)] Loss: -195996.875000\n",
      "Train Epoch: 2 [17360/17352 (100%)] Loss: -209102.765625\n",
      "    epoch          : 2\n",
      "    loss           : -188061.94818037975\n",
      "    val_loss       : -23685.375038612616\n",
      "Train Epoch: 3 [0/17352 (0%)] Loss: -233587.828125\n",
      "Train Epoch: 3 [80/17352 (0%)] Loss: -224113.093750\n",
      "Train Epoch: 3 [160/17352 (1%)] Loss: -225991.546875\n",
      "Train Epoch: 3 [240/17352 (1%)] Loss: -204242.906250\n",
      "Train Epoch: 3 [320/17352 (2%)] Loss: -200485.250000\n",
      "Train Epoch: 3 [400/17352 (2%)] Loss: -211718.593750\n",
      "Train Epoch: 3 [480/17352 (3%)] Loss: -229096.796875\n",
      "Train Epoch: 3 [560/17352 (3%)] Loss: -202097.906250\n",
      "Train Epoch: 3 [640/17352 (4%)] Loss: -210476.328125\n",
      "Train Epoch: 3 [720/17352 (4%)] Loss: -196316.953125\n",
      "Train Epoch: 3 [800/17352 (5%)] Loss: -228801.375000\n",
      "Train Epoch: 3 [880/17352 (5%)] Loss: -212559.906250\n",
      "Train Epoch: 3 [960/17352 (6%)] Loss: -205080.406250\n",
      "Train Epoch: 3 [1040/17352 (6%)] Loss: -194359.546875\n",
      "Train Epoch: 3 [1120/17352 (6%)] Loss: -230102.421875\n",
      "Train Epoch: 3 [1200/17352 (7%)] Loss: -236721.046875\n",
      "Train Epoch: 3 [1280/17352 (7%)] Loss: -207060.968750\n",
      "Train Epoch: 3 [1360/17352 (8%)] Loss: -204269.718750\n",
      "Train Epoch: 3 [1440/17352 (8%)] Loss: -236377.421875\n",
      "Train Epoch: 3 [1520/17352 (9%)] Loss: -218386.062500\n",
      "Train Epoch: 3 [1600/17352 (9%)] Loss: -212256.531250\n",
      "Train Epoch: 3 [1680/17352 (10%)] Loss: -196817.328125\n",
      "Train Epoch: 3 [1760/17352 (10%)] Loss: -235482.843750\n",
      "Train Epoch: 3 [1840/17352 (11%)] Loss: -208372.625000\n",
      "Train Epoch: 3 [1920/17352 (11%)] Loss: -205720.656250\n",
      "Train Epoch: 3 [2000/17352 (12%)] Loss: -204566.937500\n",
      "Train Epoch: 3 [2080/17352 (12%)] Loss: -231240.265625\n",
      "Train Epoch: 3 [2160/17352 (12%)] Loss: -203103.343750\n",
      "Train Epoch: 3 [2240/17352 (13%)] Loss: -166902.062500\n",
      "Train Epoch: 3 [2320/17352 (13%)] Loss: -203341.484375\n",
      "Train Epoch: 3 [2400/17352 (14%)] Loss: -177516.656250\n",
      "Train Epoch: 3 [2480/17352 (14%)] Loss: -201849.406250\n",
      "Train Epoch: 3 [2560/17352 (15%)] Loss: -192294.265625\n",
      "Train Epoch: 3 [2640/17352 (15%)] Loss: -176406.812500\n",
      "Train Epoch: 3 [2720/17352 (16%)] Loss: -194883.625000\n",
      "Train Epoch: 3 [2800/17352 (16%)] Loss: -177165.812500\n",
      "Train Epoch: 3 [2880/17352 (17%)] Loss: -180797.593750\n",
      "Train Epoch: 3 [2960/17352 (17%)] Loss: -188468.328125\n",
      "Train Epoch: 3 [3040/17352 (18%)] Loss: -181255.156250\n",
      "Train Epoch: 3 [3120/17352 (18%)] Loss: -230905.468750\n",
      "Train Epoch: 3 [3200/17352 (18%)] Loss: -180969.062500\n",
      "Train Epoch: 3 [3280/17352 (19%)] Loss: -201716.406250\n",
      "Train Epoch: 3 [3360/17352 (19%)] Loss: -193396.359375\n",
      "Train Epoch: 3 [3440/17352 (20%)] Loss: -180449.609375\n",
      "Train Epoch: 3 [3520/17352 (20%)] Loss: -148332.984375\n",
      "Train Epoch: 3 [3600/17352 (21%)] Loss: -177680.250000\n",
      "Train Epoch: 3 [3680/17352 (21%)] Loss: -192881.125000\n",
      "Train Epoch: 3 [3760/17352 (22%)] Loss: -167968.343750\n",
      "Train Epoch: 3 [3840/17352 (22%)] Loss: -196045.000000\n",
      "Train Epoch: 3 [3920/17352 (23%)] Loss: -162908.437500\n",
      "Train Epoch: 3 [4000/17352 (23%)] Loss: -193062.453125\n",
      "Train Epoch: 3 [4080/17352 (24%)] Loss: -199670.906250\n",
      "Train Epoch: 3 [4160/17352 (24%)] Loss: -212857.359375\n",
      "Train Epoch: 3 [4240/17352 (24%)] Loss: -183163.875000\n",
      "Train Epoch: 3 [4320/17352 (25%)] Loss: -169519.500000\n",
      "Train Epoch: 3 [4400/17352 (25%)] Loss: -173854.781250\n",
      "Train Epoch: 3 [4480/17352 (26%)] Loss: -216282.562500\n",
      "Train Epoch: 3 [4560/17352 (26%)] Loss: -212039.390625\n",
      "Train Epoch: 3 [4640/17352 (27%)] Loss: -180870.468750\n",
      "Train Epoch: 3 [4720/17352 (27%)] Loss: -191207.796875\n",
      "Train Epoch: 3 [4800/17352 (28%)] Loss: -174910.984375\n",
      "Train Epoch: 3 [4880/17352 (28%)] Loss: -196370.078125\n",
      "Train Epoch: 3 [4960/17352 (29%)] Loss: -187261.156250\n",
      "Train Epoch: 3 [5040/17352 (29%)] Loss: -175949.421875\n",
      "Train Epoch: 3 [5120/17352 (30%)] Loss: -185706.984375\n",
      "Train Epoch: 3 [5200/17352 (30%)] Loss: -172473.125000\n",
      "Train Epoch: 3 [5280/17352 (30%)] Loss: -197424.328125\n",
      "Train Epoch: 3 [5360/17352 (31%)] Loss: -177638.984375\n",
      "Train Epoch: 3 [5440/17352 (31%)] Loss: -173269.015625\n",
      "Train Epoch: 3 [5520/17352 (32%)] Loss: -183273.468750\n",
      "Train Epoch: 3 [5600/17352 (32%)] Loss: -192209.390625\n",
      "Train Epoch: 3 [5680/17352 (33%)] Loss: -167726.562500\n",
      "Train Epoch: 3 [5760/17352 (33%)] Loss: -218376.437500\n",
      "Train Epoch: 3 [5840/17352 (34%)] Loss: -159646.718750\n",
      "Train Epoch: 3 [5920/17352 (34%)] Loss: -179402.812500\n",
      "Train Epoch: 3 [6000/17352 (35%)] Loss: -179968.609375\n",
      "Train Epoch: 3 [6080/17352 (35%)] Loss: -179337.562500\n",
      "Train Epoch: 3 [6160/17352 (36%)] Loss: -201288.281250\n",
      "Train Epoch: 3 [6240/17352 (36%)] Loss: -200222.687500\n",
      "Train Epoch: 3 [6320/17352 (36%)] Loss: -189085.625000\n",
      "Train Epoch: 3 [6400/17352 (37%)] Loss: -200776.453125\n",
      "Train Epoch: 3 [6480/17352 (37%)] Loss: -200713.500000\n",
      "Train Epoch: 3 [6560/17352 (38%)] Loss: -192963.000000\n",
      "Train Epoch: 3 [6640/17352 (38%)] Loss: -181245.953125\n",
      "Train Epoch: 3 [6720/17352 (39%)] Loss: -175165.625000\n",
      "Train Epoch: 3 [6800/17352 (39%)] Loss: -165903.468750\n",
      "Train Epoch: 3 [6880/17352 (40%)] Loss: -207743.265625\n",
      "Train Epoch: 3 [6960/17352 (40%)] Loss: -211624.093750\n",
      "Train Epoch: 3 [7040/17352 (41%)] Loss: -173027.359375\n",
      "Train Epoch: 3 [7120/17352 (41%)] Loss: -151445.968750\n",
      "Train Epoch: 3 [7200/17352 (41%)] Loss: -195242.484375\n",
      "Train Epoch: 3 [7280/17352 (42%)] Loss: -204949.062500\n",
      "Train Epoch: 3 [7360/17352 (42%)] Loss: -168098.843750\n",
      "Train Epoch: 3 [7440/17352 (43%)] Loss: -216215.187500\n",
      "Train Epoch: 3 [7520/17352 (43%)] Loss: -200257.593750\n",
      "Train Epoch: 3 [7600/17352 (44%)] Loss: -195024.984375\n",
      "Train Epoch: 3 [7680/17352 (44%)] Loss: -180693.437500\n",
      "Train Epoch: 3 [7760/17352 (45%)] Loss: -171320.359375\n",
      "Train Epoch: 3 [7840/17352 (45%)] Loss: -174372.859375\n",
      "Train Epoch: 3 [7920/17352 (46%)] Loss: -202741.546875\n",
      "Train Epoch: 3 [8000/17352 (46%)] Loss: -204560.437500\n",
      "Train Epoch: 3 [8080/17352 (47%)] Loss: -187406.484375\n",
      "Train Epoch: 3 [8160/17352 (47%)] Loss: -182822.421875\n",
      "Train Epoch: 3 [8240/17352 (47%)] Loss: -172088.703125\n",
      "Train Epoch: 3 [8320/17352 (48%)] Loss: -183380.125000\n",
      "Train Epoch: 3 [8400/17352 (48%)] Loss: -211003.406250\n",
      "Train Epoch: 3 [8480/17352 (49%)] Loss: -169353.140625\n",
      "Train Epoch: 3 [8560/17352 (49%)] Loss: -178497.921875\n",
      "Train Epoch: 3 [8640/17352 (50%)] Loss: -191693.750000\n",
      "Train Epoch: 3 [8720/17352 (50%)] Loss: -189218.093750\n",
      "Train Epoch: 3 [8800/17352 (51%)] Loss: -192790.562500\n",
      "Train Epoch: 3 [8880/17352 (51%)] Loss: -177084.953125\n",
      "Train Epoch: 3 [8960/17352 (52%)] Loss: -156398.312500\n",
      "Train Epoch: 3 [9040/17352 (52%)] Loss: -159588.171875\n",
      "Train Epoch: 3 [9120/17352 (53%)] Loss: -184435.500000\n",
      "Train Epoch: 3 [9200/17352 (53%)] Loss: -195444.593750\n",
      "Train Epoch: 3 [9280/17352 (53%)] Loss: -185733.453125\n",
      "Train Epoch: 3 [9360/17352 (54%)] Loss: -203591.640625\n",
      "Train Epoch: 3 [9440/17352 (54%)] Loss: -174570.406250\n",
      "Train Epoch: 3 [9520/17352 (55%)] Loss: -156917.953125\n",
      "Train Epoch: 3 [9600/17352 (55%)] Loss: -148383.453125\n",
      "Train Epoch: 3 [9680/17352 (56%)] Loss: -166175.437500\n",
      "Train Epoch: 3 [9760/17352 (56%)] Loss: -190921.000000\n",
      "Train Epoch: 3 [9840/17352 (57%)] Loss: -202124.687500\n",
      "Train Epoch: 3 [9920/17352 (57%)] Loss: -205646.296875\n",
      "Train Epoch: 3 [10000/17352 (58%)] Loss: -164899.890625\n",
      "Train Epoch: 3 [10080/17352 (58%)] Loss: -175475.406250\n",
      "Train Epoch: 3 [10160/17352 (59%)] Loss: -167169.828125\n",
      "Train Epoch: 3 [10240/17352 (59%)] Loss: -159613.500000\n",
      "Train Epoch: 3 [10320/17352 (59%)] Loss: -184753.937500\n",
      "Train Epoch: 3 [10400/17352 (60%)] Loss: -202888.312500\n",
      "Train Epoch: 3 [10480/17352 (60%)] Loss: -193264.093750\n",
      "Train Epoch: 3 [10560/17352 (61%)] Loss: -210144.000000\n",
      "Train Epoch: 3 [10640/17352 (61%)] Loss: -200091.656250\n",
      "Train Epoch: 3 [10720/17352 (62%)] Loss: -196415.906250\n",
      "Train Epoch: 3 [10800/17352 (62%)] Loss: -167107.125000\n",
      "Train Epoch: 3 [10880/17352 (63%)] Loss: -205325.375000\n",
      "Train Epoch: 3 [10960/17352 (63%)] Loss: -186064.093750\n",
      "Train Epoch: 3 [11040/17352 (64%)] Loss: -180563.250000\n",
      "Train Epoch: 3 [11120/17352 (64%)] Loss: -179364.250000\n",
      "Train Epoch: 3 [11200/17352 (65%)] Loss: -179431.343750\n",
      "Train Epoch: 3 [11280/17352 (65%)] Loss: -148964.156250\n",
      "Train Epoch: 3 [11360/17352 (65%)] Loss: -205421.312500\n",
      "Train Epoch: 3 [11440/17352 (66%)] Loss: -199085.812500\n",
      "Train Epoch: 3 [11520/17352 (66%)] Loss: -215532.234375\n",
      "Train Epoch: 3 [11600/17352 (67%)] Loss: -195977.890625\n",
      "Train Epoch: 3 [11680/17352 (67%)] Loss: -183535.187500\n",
      "Train Epoch: 3 [11760/17352 (68%)] Loss: -190987.640625\n",
      "Train Epoch: 3 [11840/17352 (68%)] Loss: -210825.359375\n",
      "Train Epoch: 3 [11920/17352 (69%)] Loss: -184362.812500\n",
      "Train Epoch: 3 [12000/17352 (69%)] Loss: -152838.015625\n",
      "Train Epoch: 3 [12080/17352 (70%)] Loss: -191226.312500\n",
      "Train Epoch: 3 [12160/17352 (70%)] Loss: -183947.593750\n",
      "Train Epoch: 3 [12240/17352 (71%)] Loss: -196071.062500\n",
      "Train Epoch: 3 [12320/17352 (71%)] Loss: -207926.343750\n",
      "Train Epoch: 3 [12400/17352 (71%)] Loss: -177900.656250\n",
      "Train Epoch: 3 [12480/17352 (72%)] Loss: -208235.421875\n",
      "Train Epoch: 3 [12560/17352 (72%)] Loss: -171110.015625\n",
      "Train Epoch: 3 [12640/17352 (73%)] Loss: -193460.203125\n",
      "Train Epoch: 3 [12720/17352 (73%)] Loss: -199642.156250\n",
      "Train Epoch: 3 [12800/17352 (74%)] Loss: -198225.328125\n",
      "Train Epoch: 3 [12880/17352 (74%)] Loss: -183682.734375\n",
      "Train Epoch: 3 [12960/17352 (75%)] Loss: -197232.796875\n",
      "Train Epoch: 3 [13040/17352 (75%)] Loss: -204528.375000\n",
      "Train Epoch: 3 [13120/17352 (76%)] Loss: -187117.984375\n",
      "Train Epoch: 3 [13200/17352 (76%)] Loss: -172100.046875\n",
      "Train Epoch: 3 [13280/17352 (77%)] Loss: -148083.203125\n",
      "Train Epoch: 3 [13360/17352 (77%)] Loss: -180212.906250\n",
      "Train Epoch: 3 [13440/17352 (77%)] Loss: -225377.078125\n",
      "Train Epoch: 3 [13520/17352 (78%)] Loss: -177026.640625\n",
      "Train Epoch: 3 [13600/17352 (78%)] Loss: -182680.140625\n",
      "Train Epoch: 3 [13680/17352 (79%)] Loss: -206495.031250\n",
      "Train Epoch: 3 [13760/17352 (79%)] Loss: -193977.875000\n",
      "Train Epoch: 3 [13840/17352 (80%)] Loss: -176221.328125\n",
      "Train Epoch: 3 [13920/17352 (80%)] Loss: -178000.593750\n",
      "Train Epoch: 3 [14000/17352 (81%)] Loss: -192099.625000\n",
      "Train Epoch: 3 [14080/17352 (81%)] Loss: -191073.218750\n",
      "Train Epoch: 3 [14160/17352 (82%)] Loss: -165637.250000\n",
      "Train Epoch: 3 [14240/17352 (82%)] Loss: -191445.031250\n",
      "Train Epoch: 3 [14320/17352 (83%)] Loss: -194494.765625\n",
      "Train Epoch: 3 [14400/17352 (83%)] Loss: -179324.046875\n",
      "Train Epoch: 3 [14480/17352 (83%)] Loss: -178668.718750\n",
      "Train Epoch: 3 [14560/17352 (84%)] Loss: -189495.921875\n",
      "Train Epoch: 3 [14640/17352 (84%)] Loss: -172539.656250\n",
      "Train Epoch: 3 [14720/17352 (85%)] Loss: -181672.578125\n",
      "Train Epoch: 3 [14800/17352 (85%)] Loss: -203645.484375\n",
      "Train Epoch: 3 [14880/17352 (86%)] Loss: -177081.890625\n",
      "Train Epoch: 3 [14960/17352 (86%)] Loss: -208361.781250\n",
      "Train Epoch: 3 [15040/17352 (87%)] Loss: -223884.859375\n",
      "Train Epoch: 3 [15120/17352 (87%)] Loss: -180096.078125\n",
      "Train Epoch: 3 [15200/17352 (88%)] Loss: -205714.156250\n",
      "Train Epoch: 3 [15280/17352 (88%)] Loss: -190706.843750\n",
      "Train Epoch: 3 [15360/17352 (89%)] Loss: -164303.359375\n",
      "Train Epoch: 3 [15440/17352 (89%)] Loss: -178107.328125\n",
      "Train Epoch: 3 [15520/17352 (89%)] Loss: -181655.968750\n",
      "Train Epoch: 3 [15600/17352 (90%)] Loss: -203792.609375\n",
      "Train Epoch: 3 [15680/17352 (90%)] Loss: -206605.359375\n",
      "Train Epoch: 3 [15760/17352 (91%)] Loss: -190897.687500\n",
      "Train Epoch: 3 [15840/17352 (91%)] Loss: -202935.000000\n",
      "Train Epoch: 3 [15920/17352 (92%)] Loss: -201211.781250\n",
      "Train Epoch: 3 [16000/17352 (92%)] Loss: -199817.250000\n",
      "Train Epoch: 3 [16080/17352 (93%)] Loss: -193279.531250\n",
      "Train Epoch: 3 [16160/17352 (93%)] Loss: -188012.953125\n",
      "Train Epoch: 3 [16240/17352 (94%)] Loss: -176617.546875\n",
      "Train Epoch: 3 [16320/17352 (94%)] Loss: -171499.765625\n",
      "Train Epoch: 3 [16400/17352 (95%)] Loss: -175337.546875\n",
      "Train Epoch: 3 [16480/17352 (95%)] Loss: -182009.671875\n",
      "Train Epoch: 3 [16560/17352 (95%)] Loss: -168930.218750\n",
      "Train Epoch: 3 [16640/17352 (96%)] Loss: -163893.859375\n",
      "Train Epoch: 3 [16720/17352 (96%)] Loss: -189425.312500\n",
      "Train Epoch: 3 [16800/17352 (97%)] Loss: -157414.765625\n",
      "Train Epoch: 3 [16880/17352 (97%)] Loss: -183182.234375\n",
      "Train Epoch: 3 [16960/17352 (98%)] Loss: -185263.812500\n",
      "Train Epoch: 3 [17040/17352 (98%)] Loss: -198461.625000\n",
      "Train Epoch: 3 [17120/17352 (99%)] Loss: -163678.203125\n",
      "Train Epoch: 3 [17200/17352 (99%)] Loss: -174658.156250\n",
      "Train Epoch: 3 [17280/17352 (100%)] Loss: -161894.187500\n",
      "Train Epoch: 3 [17360/17352 (100%)] Loss: -171754.937500\n",
      "    epoch          : 3\n",
      "    loss           : -188874.58576668584\n",
      "    val_loss       : -23697.264971809207\n",
      "Train Epoch: 4 [0/17352 (0%)] Loss: -198692.437500\n",
      "Train Epoch: 4 [80/17352 (0%)] Loss: -203939.562500\n",
      "Train Epoch: 4 [160/17352 (1%)] Loss: -213247.421875\n",
      "Train Epoch: 4 [240/17352 (1%)] Loss: -214404.031250\n",
      "Train Epoch: 4 [320/17352 (2%)] Loss: -218455.875000\n",
      "Train Epoch: 4 [400/17352 (2%)] Loss: -210470.250000\n",
      "Train Epoch: 4 [480/17352 (3%)] Loss: -215763.843750\n",
      "Train Epoch: 4 [560/17352 (3%)] Loss: -236431.796875\n",
      "Train Epoch: 4 [640/17352 (4%)] Loss: -210137.937500\n",
      "Train Epoch: 4 [720/17352 (4%)] Loss: -196372.875000\n",
      "Train Epoch: 4 [800/17352 (5%)] Loss: -213751.406250\n",
      "Train Epoch: 4 [880/17352 (5%)] Loss: -229114.156250\n",
      "Train Epoch: 4 [960/17352 (6%)] Loss: -199457.734375\n",
      "Train Epoch: 4 [1040/17352 (6%)] Loss: -231256.343750\n",
      "Train Epoch: 4 [1120/17352 (6%)] Loss: -214281.984375\n",
      "Train Epoch: 4 [1200/17352 (7%)] Loss: -210550.046875\n",
      "Train Epoch: 4 [1280/17352 (7%)] Loss: -221397.890625\n",
      "Train Epoch: 4 [1360/17352 (8%)] Loss: -219126.437500\n",
      "Train Epoch: 4 [1440/17352 (8%)] Loss: -235530.296875\n",
      "Train Epoch: 4 [1520/17352 (9%)] Loss: -204631.781250\n",
      "Train Epoch: 4 [1600/17352 (9%)] Loss: -193337.156250\n",
      "Train Epoch: 4 [1680/17352 (10%)] Loss: -206074.031250\n",
      "Train Epoch: 4 [1760/17352 (10%)] Loss: -212196.343750\n",
      "Train Epoch: 4 [1840/17352 (11%)] Loss: -233658.937500\n",
      "Train Epoch: 4 [1920/17352 (11%)] Loss: -203177.906250\n",
      "Train Epoch: 4 [2000/17352 (12%)] Loss: -211796.437500\n",
      "Train Epoch: 4 [2080/17352 (12%)] Loss: -202134.328125\n",
      "Train Epoch: 4 [2160/17352 (12%)] Loss: -204983.906250\n",
      "Train Epoch: 4 [2240/17352 (13%)] Loss: -224801.390625\n",
      "Train Epoch: 4 [2320/17352 (13%)] Loss: -187143.093750\n",
      "Train Epoch: 4 [2400/17352 (14%)] Loss: -213667.609375\n",
      "Train Epoch: 4 [2480/17352 (14%)] Loss: -193373.953125\n",
      "Train Epoch: 4 [2560/17352 (15%)] Loss: -210405.031250\n",
      "Train Epoch: 4 [2640/17352 (15%)] Loss: -205742.984375\n",
      "Train Epoch: 4 [2720/17352 (16%)] Loss: -193139.843750\n",
      "Train Epoch: 4 [2800/17352 (16%)] Loss: -163437.906250\n",
      "Train Epoch: 4 [2880/17352 (17%)] Loss: -220921.953125\n",
      "Train Epoch: 4 [2960/17352 (17%)] Loss: -213330.781250\n",
      "Train Epoch: 4 [3040/17352 (18%)] Loss: -205565.250000\n",
      "Train Epoch: 4 [3120/17352 (18%)] Loss: -204936.406250\n",
      "Train Epoch: 4 [3200/17352 (18%)] Loss: -170247.171875\n",
      "Train Epoch: 4 [3280/17352 (19%)] Loss: -219843.640625\n",
      "Train Epoch: 4 [3360/17352 (19%)] Loss: -184865.906250\n",
      "Train Epoch: 4 [3440/17352 (20%)] Loss: -172171.015625\n",
      "Train Epoch: 4 [3520/17352 (20%)] Loss: -209533.796875\n",
      "Train Epoch: 4 [3600/17352 (21%)] Loss: -164721.796875\n",
      "Train Epoch: 4 [3680/17352 (21%)] Loss: -181268.031250\n",
      "Train Epoch: 4 [3760/17352 (22%)] Loss: -193415.125000\n",
      "Train Epoch: 4 [3840/17352 (22%)] Loss: -186873.906250\n",
      "Train Epoch: 4 [3920/17352 (23%)] Loss: -179899.546875\n",
      "Train Epoch: 4 [4000/17352 (23%)] Loss: -187181.593750\n",
      "Train Epoch: 4 [4080/17352 (24%)] Loss: -227819.859375\n",
      "Train Epoch: 4 [4160/17352 (24%)] Loss: -200344.046875\n",
      "Train Epoch: 4 [4240/17352 (24%)] Loss: -208098.718750\n",
      "Train Epoch: 4 [4320/17352 (25%)] Loss: -129653.015625\n",
      "Train Epoch: 4 [4400/17352 (25%)] Loss: -175991.328125\n",
      "Train Epoch: 4 [4480/17352 (26%)] Loss: -187449.578125\n",
      "Train Epoch: 4 [4560/17352 (26%)] Loss: -218787.531250\n",
      "Train Epoch: 4 [4640/17352 (27%)] Loss: -187283.531250\n",
      "Train Epoch: 4 [4720/17352 (27%)] Loss: -206310.687500\n",
      "Train Epoch: 4 [4800/17352 (28%)] Loss: -184972.171875\n",
      "Train Epoch: 4 [4880/17352 (28%)] Loss: -228093.125000\n",
      "Train Epoch: 4 [4960/17352 (29%)] Loss: -191239.218750\n",
      "Train Epoch: 4 [5040/17352 (29%)] Loss: -192991.531250\n",
      "Train Epoch: 4 [5120/17352 (30%)] Loss: -190995.390625\n",
      "Train Epoch: 4 [5200/17352 (30%)] Loss: -169367.687500\n",
      "Train Epoch: 4 [5280/17352 (30%)] Loss: -176884.625000\n",
      "Train Epoch: 4 [5360/17352 (31%)] Loss: -184174.296875\n",
      "Train Epoch: 4 [5440/17352 (31%)] Loss: -216269.000000\n",
      "Train Epoch: 4 [5520/17352 (32%)] Loss: -163043.671875\n",
      "Train Epoch: 4 [5600/17352 (32%)] Loss: -187245.062500\n",
      "Train Epoch: 4 [5680/17352 (33%)] Loss: -162503.656250\n",
      "Train Epoch: 4 [5760/17352 (33%)] Loss: -175152.093750\n",
      "Train Epoch: 4 [5840/17352 (34%)] Loss: -202168.312500\n",
      "Train Epoch: 4 [5920/17352 (34%)] Loss: -159681.093750\n",
      "Train Epoch: 4 [6000/17352 (35%)] Loss: -148968.265625\n",
      "Train Epoch: 4 [6080/17352 (35%)] Loss: -174455.812500\n",
      "Train Epoch: 4 [6160/17352 (36%)] Loss: -193979.953125\n",
      "Train Epoch: 4 [6240/17352 (36%)] Loss: -183822.140625\n",
      "Train Epoch: 4 [6320/17352 (36%)] Loss: -157709.625000\n",
      "Train Epoch: 4 [6400/17352 (37%)] Loss: -164329.000000\n",
      "Train Epoch: 4 [6480/17352 (37%)] Loss: -182470.593750\n",
      "Train Epoch: 4 [6560/17352 (38%)] Loss: -196506.843750\n",
      "Train Epoch: 4 [6640/17352 (38%)] Loss: -176015.187500\n",
      "Train Epoch: 4 [6720/17352 (39%)] Loss: -179116.453125\n",
      "Train Epoch: 4 [6800/17352 (39%)] Loss: -165706.312500\n",
      "Train Epoch: 4 [6880/17352 (40%)] Loss: -209346.593750\n",
      "Train Epoch: 4 [6960/17352 (40%)] Loss: -157440.328125\n",
      "Train Epoch: 4 [7040/17352 (41%)] Loss: -193209.468750\n",
      "Train Epoch: 4 [7120/17352 (41%)] Loss: -203811.968750\n",
      "Train Epoch: 4 [7200/17352 (41%)] Loss: -209201.562500\n",
      "Train Epoch: 4 [7280/17352 (42%)] Loss: -205153.171875\n",
      "Train Epoch: 4 [7360/17352 (42%)] Loss: -204139.796875\n",
      "Train Epoch: 4 [7440/17352 (43%)] Loss: -203406.093750\n",
      "Train Epoch: 4 [7520/17352 (43%)] Loss: -200553.000000\n",
      "Train Epoch: 4 [7600/17352 (44%)] Loss: -188410.000000\n",
      "Train Epoch: 4 [7680/17352 (44%)] Loss: -177683.953125\n",
      "Train Epoch: 4 [7760/17352 (45%)] Loss: -174411.906250\n",
      "Train Epoch: 4 [7840/17352 (45%)] Loss: -207780.843750\n",
      "Train Epoch: 4 [7920/17352 (46%)] Loss: -171485.031250\n",
      "Train Epoch: 4 [8000/17352 (46%)] Loss: -167732.218750\n",
      "Train Epoch: 4 [8080/17352 (47%)] Loss: -188132.359375\n",
      "Train Epoch: 4 [8160/17352 (47%)] Loss: -188125.484375\n",
      "Train Epoch: 4 [8240/17352 (47%)] Loss: -191105.312500\n",
      "Train Epoch: 4 [8320/17352 (48%)] Loss: -188821.562500\n",
      "Train Epoch: 4 [8400/17352 (48%)] Loss: -198945.000000\n",
      "Train Epoch: 4 [8480/17352 (49%)] Loss: -188436.031250\n",
      "Train Epoch: 4 [8560/17352 (49%)] Loss: -158195.125000\n",
      "Train Epoch: 4 [8640/17352 (50%)] Loss: -187154.468750\n",
      "Train Epoch: 4 [8720/17352 (50%)] Loss: -192576.890625\n",
      "Train Epoch: 4 [8800/17352 (51%)] Loss: -164034.218750\n",
      "Train Epoch: 4 [8880/17352 (51%)] Loss: -185729.156250\n",
      "Train Epoch: 4 [8960/17352 (52%)] Loss: -198213.921875\n",
      "Train Epoch: 4 [9040/17352 (52%)] Loss: -200816.687500\n",
      "Train Epoch: 4 [9120/17352 (53%)] Loss: -185945.031250\n",
      "Train Epoch: 4 [9200/17352 (53%)] Loss: -175041.468750\n",
      "Train Epoch: 4 [9280/17352 (53%)] Loss: -183930.281250\n",
      "Train Epoch: 4 [9360/17352 (54%)] Loss: -200010.328125\n",
      "Train Epoch: 4 [9440/17352 (54%)] Loss: -188202.265625\n",
      "Train Epoch: 4 [9520/17352 (55%)] Loss: -179842.859375\n",
      "Train Epoch: 4 [9600/17352 (55%)] Loss: -190421.515625\n",
      "Train Epoch: 4 [9680/17352 (56%)] Loss: -203807.500000\n",
      "Train Epoch: 4 [9760/17352 (56%)] Loss: -177701.578125\n",
      "Train Epoch: 4 [9840/17352 (57%)] Loss: -181547.156250\n",
      "Train Epoch: 4 [9920/17352 (57%)] Loss: -177091.375000\n",
      "Train Epoch: 4 [10000/17352 (58%)] Loss: -178771.062500\n",
      "Train Epoch: 4 [10080/17352 (58%)] Loss: -210213.671875\n",
      "Train Epoch: 4 [10160/17352 (59%)] Loss: -182504.562500\n",
      "Train Epoch: 4 [10240/17352 (59%)] Loss: -165987.265625\n",
      "Train Epoch: 4 [10320/17352 (59%)] Loss: -176850.578125\n",
      "Train Epoch: 4 [10400/17352 (60%)] Loss: -178768.593750\n",
      "Train Epoch: 4 [10480/17352 (60%)] Loss: -191621.312500\n",
      "Train Epoch: 4 [10560/17352 (61%)] Loss: -228028.937500\n",
      "Train Epoch: 4 [10640/17352 (61%)] Loss: -159549.500000\n",
      "Train Epoch: 4 [10720/17352 (62%)] Loss: -187527.421875\n",
      "Train Epoch: 4 [10800/17352 (62%)] Loss: -186655.406250\n",
      "Train Epoch: 4 [10880/17352 (63%)] Loss: -178282.937500\n",
      "Train Epoch: 4 [10960/17352 (63%)] Loss: -160031.562500\n",
      "Train Epoch: 4 [11040/17352 (64%)] Loss: -193464.984375\n",
      "Train Epoch: 4 [11120/17352 (64%)] Loss: -180826.890625\n",
      "Train Epoch: 4 [11200/17352 (65%)] Loss: -193736.281250\n",
      "Train Epoch: 4 [11280/17352 (65%)] Loss: -192061.937500\n",
      "Train Epoch: 4 [11360/17352 (65%)] Loss: -164928.390625\n",
      "Train Epoch: 4 [11440/17352 (66%)] Loss: -184431.687500\n",
      "Train Epoch: 4 [11520/17352 (66%)] Loss: -189748.046875\n",
      "Train Epoch: 4 [11600/17352 (67%)] Loss: -200058.078125\n",
      "Train Epoch: 4 [11680/17352 (67%)] Loss: -186450.656250\n",
      "Train Epoch: 4 [11760/17352 (68%)] Loss: -183030.484375\n",
      "Train Epoch: 4 [11840/17352 (68%)] Loss: -201798.265625\n",
      "Train Epoch: 4 [11920/17352 (69%)] Loss: -204291.125000\n",
      "Train Epoch: 4 [12000/17352 (69%)] Loss: -207957.625000\n",
      "Train Epoch: 4 [12080/17352 (70%)] Loss: -187234.203125\n",
      "Train Epoch: 4 [12160/17352 (70%)] Loss: -182269.937500\n",
      "Train Epoch: 4 [12240/17352 (71%)] Loss: -165753.765625\n",
      "Train Epoch: 4 [12320/17352 (71%)] Loss: -179653.796875\n",
      "Train Epoch: 4 [12400/17352 (71%)] Loss: -207995.656250\n",
      "Train Epoch: 4 [12480/17352 (72%)] Loss: -185317.265625\n",
      "Train Epoch: 4 [12560/17352 (72%)] Loss: -175256.281250\n",
      "Train Epoch: 4 [12640/17352 (73%)] Loss: -196046.265625\n",
      "Train Epoch: 4 [12720/17352 (73%)] Loss: -154557.937500\n",
      "Train Epoch: 4 [12800/17352 (74%)] Loss: -198650.531250\n",
      "Train Epoch: 4 [12880/17352 (74%)] Loss: -172483.468750\n",
      "Train Epoch: 4 [12960/17352 (75%)] Loss: -205459.328125\n",
      "Train Epoch: 4 [13040/17352 (75%)] Loss: -181670.281250\n",
      "Train Epoch: 4 [13120/17352 (76%)] Loss: -204370.531250\n",
      "Train Epoch: 4 [13200/17352 (76%)] Loss: -178137.734375\n",
      "Train Epoch: 4 [13280/17352 (77%)] Loss: -95218.937500\n",
      "Train Epoch: 4 [13360/17352 (77%)] Loss: -165826.828125\n",
      "Train Epoch: 4 [13440/17352 (77%)] Loss: -151679.500000\n",
      "Train Epoch: 4 [13520/17352 (78%)] Loss: -179867.734375\n",
      "Train Epoch: 4 [13600/17352 (78%)] Loss: -163691.328125\n",
      "Train Epoch: 4 [13680/17352 (79%)] Loss: -205478.828125\n",
      "Train Epoch: 4 [13760/17352 (79%)] Loss: -178382.781250\n",
      "Train Epoch: 4 [13840/17352 (80%)] Loss: -192318.375000\n",
      "Train Epoch: 4 [13920/17352 (80%)] Loss: -190871.921875\n",
      "Train Epoch: 4 [14000/17352 (81%)] Loss: -168021.343750\n",
      "Train Epoch: 4 [14080/17352 (81%)] Loss: -201327.640625\n",
      "Train Epoch: 4 [14160/17352 (82%)] Loss: -192041.515625\n",
      "Train Epoch: 4 [14240/17352 (82%)] Loss: -210182.078125\n",
      "Train Epoch: 4 [14320/17352 (83%)] Loss: -196339.515625\n",
      "Train Epoch: 4 [14400/17352 (83%)] Loss: -174496.390625\n",
      "Train Epoch: 4 [14480/17352 (83%)] Loss: -148773.125000\n",
      "Train Epoch: 4 [14560/17352 (84%)] Loss: -190959.671875\n",
      "Train Epoch: 4 [14640/17352 (84%)] Loss: -164019.593750\n",
      "Train Epoch: 4 [14720/17352 (85%)] Loss: -164840.593750\n",
      "Train Epoch: 4 [14800/17352 (85%)] Loss: -187486.828125\n",
      "Train Epoch: 4 [14880/17352 (86%)] Loss: -210851.062500\n",
      "Train Epoch: 4 [14960/17352 (86%)] Loss: -178270.609375\n",
      "Train Epoch: 4 [15040/17352 (87%)] Loss: -200972.140625\n",
      "Train Epoch: 4 [15120/17352 (87%)] Loss: -165752.671875\n",
      "Train Epoch: 4 [15200/17352 (88%)] Loss: -167195.937500\n",
      "Train Epoch: 4 [15280/17352 (88%)] Loss: -207979.828125\n",
      "Train Epoch: 4 [15360/17352 (89%)] Loss: -213842.578125\n",
      "Train Epoch: 4 [15440/17352 (89%)] Loss: -203390.718750\n",
      "Train Epoch: 4 [15520/17352 (89%)] Loss: -191816.593750\n",
      "Train Epoch: 4 [15600/17352 (90%)] Loss: -194549.750000\n",
      "Train Epoch: 4 [15680/17352 (90%)] Loss: -215577.750000\n",
      "Train Epoch: 4 [15760/17352 (91%)] Loss: -170706.656250\n",
      "Train Epoch: 4 [15840/17352 (91%)] Loss: -192931.265625\n",
      "Train Epoch: 4 [15920/17352 (92%)] Loss: -167814.671875\n",
      "Train Epoch: 4 [16000/17352 (92%)] Loss: -208845.828125\n",
      "Train Epoch: 4 [16080/17352 (93%)] Loss: -182693.078125\n",
      "Train Epoch: 4 [16160/17352 (93%)] Loss: -182695.218750\n",
      "Train Epoch: 4 [16240/17352 (94%)] Loss: -174866.671875\n",
      "Train Epoch: 4 [16320/17352 (94%)] Loss: -181363.296875\n",
      "Train Epoch: 4 [16400/17352 (95%)] Loss: -179629.546875\n",
      "Train Epoch: 4 [16480/17352 (95%)] Loss: -204976.359375\n",
      "Train Epoch: 4 [16560/17352 (95%)] Loss: -208378.546875\n",
      "Train Epoch: 4 [16640/17352 (96%)] Loss: -186380.359375\n",
      "Train Epoch: 4 [16720/17352 (96%)] Loss: -201473.859375\n",
      "Train Epoch: 4 [16800/17352 (97%)] Loss: -180463.046875\n",
      "Train Epoch: 4 [16880/17352 (97%)] Loss: -202026.953125\n",
      "Train Epoch: 4 [16960/17352 (98%)] Loss: -175541.218750\n",
      "Train Epoch: 4 [17040/17352 (98%)] Loss: -172843.406250\n",
      "Train Epoch: 4 [17120/17352 (99%)] Loss: -211093.265625\n",
      "Train Epoch: 4 [17200/17352 (99%)] Loss: -167831.687500\n",
      "Train Epoch: 4 [17280/17352 (100%)] Loss: -183667.500000\n",
      "Train Epoch: 4 [17360/17352 (100%)] Loss: -189423.203125\n",
      "    epoch          : 4\n",
      "    loss           : -189480.0371835443\n",
      "    val_loss       : -23704.875656772667\n",
      "Train Epoch: 5 [0/17352 (0%)] Loss: -199028.578125\n",
      "Train Epoch: 5 [80/17352 (0%)] Loss: -199819.687500\n",
      "Train Epoch: 5 [160/17352 (1%)] Loss: -202176.625000\n",
      "Train Epoch: 5 [240/17352 (1%)] Loss: -207097.140625\n",
      "Train Epoch: 5 [320/17352 (2%)] Loss: -205166.859375\n",
      "Train Epoch: 5 [400/17352 (2%)] Loss: -216037.703125\n",
      "Train Epoch: 5 [480/17352 (3%)] Loss: -230132.984375\n",
      "Train Epoch: 5 [560/17352 (3%)] Loss: -224261.578125\n",
      "Train Epoch: 5 [640/17352 (4%)] Loss: -210294.171875\n",
      "Train Epoch: 5 [720/17352 (4%)] Loss: -204646.281250\n",
      "Train Epoch: 5 [800/17352 (5%)] Loss: -217596.375000\n",
      "Train Epoch: 5 [880/17352 (5%)] Loss: -206697.484375\n",
      "Train Epoch: 5 [960/17352 (6%)] Loss: -209501.390625\n",
      "Train Epoch: 5 [1040/17352 (6%)] Loss: -229883.218750\n",
      "Train Epoch: 5 [1120/17352 (6%)] Loss: -226045.546875\n",
      "Train Epoch: 5 [1200/17352 (7%)] Loss: -217861.718750\n",
      "Train Epoch: 5 [1280/17352 (7%)] Loss: -194216.156250\n",
      "Train Epoch: 5 [1360/17352 (8%)] Loss: -215428.109375\n",
      "Train Epoch: 5 [1440/17352 (8%)] Loss: -213290.593750\n",
      "Train Epoch: 5 [1520/17352 (9%)] Loss: -214456.234375\n",
      "Train Epoch: 5 [1600/17352 (9%)] Loss: -182702.484375\n",
      "Train Epoch: 5 [1680/17352 (10%)] Loss: -229154.625000\n",
      "Train Epoch: 5 [1760/17352 (10%)] Loss: -204330.140625\n",
      "Train Epoch: 5 [1840/17352 (11%)] Loss: -203675.109375\n",
      "Train Epoch: 5 [1920/17352 (11%)] Loss: -204677.328125\n",
      "Train Epoch: 5 [2000/17352 (12%)] Loss: -196895.968750\n",
      "Train Epoch: 5 [2080/17352 (12%)] Loss: -216065.640625\n",
      "Train Epoch: 5 [2160/17352 (12%)] Loss: -209613.265625\n",
      "Train Epoch: 5 [2240/17352 (13%)] Loss: -205124.421875\n",
      "Train Epoch: 5 [2320/17352 (13%)] Loss: -183016.265625\n",
      "Train Epoch: 5 [2400/17352 (14%)] Loss: -185989.968750\n",
      "Train Epoch: 5 [2480/17352 (14%)] Loss: -188844.203125\n",
      "Train Epoch: 5 [2560/17352 (15%)] Loss: -190172.625000\n",
      "Train Epoch: 5 [2640/17352 (15%)] Loss: -199543.578125\n",
      "Train Epoch: 5 [2720/17352 (16%)] Loss: -185754.718750\n",
      "Train Epoch: 5 [2800/17352 (16%)] Loss: -183544.250000\n",
      "Train Epoch: 5 [2880/17352 (17%)] Loss: -193084.078125\n",
      "Train Epoch: 5 [2960/17352 (17%)] Loss: -179355.593750\n",
      "Train Epoch: 5 [3040/17352 (18%)] Loss: -178758.812500\n",
      "Train Epoch: 5 [3120/17352 (18%)] Loss: -187361.484375\n",
      "Train Epoch: 5 [3200/17352 (18%)] Loss: -157453.609375\n",
      "Train Epoch: 5 [3280/17352 (19%)] Loss: -195326.031250\n",
      "Train Epoch: 5 [3360/17352 (19%)] Loss: -168151.437500\n",
      "Train Epoch: 5 [3440/17352 (20%)] Loss: -178165.593750\n",
      "Train Epoch: 5 [3520/17352 (20%)] Loss: -204967.625000\n",
      "Train Epoch: 5 [3600/17352 (21%)] Loss: -179466.250000\n",
      "Train Epoch: 5 [3680/17352 (21%)] Loss: -177161.140625\n",
      "Train Epoch: 5 [3760/17352 (22%)] Loss: -186732.640625\n",
      "Train Epoch: 5 [3840/17352 (22%)] Loss: -191328.203125\n",
      "Train Epoch: 5 [3920/17352 (23%)] Loss: -169149.546875\n",
      "Train Epoch: 5 [4000/17352 (23%)] Loss: -145948.453125\n",
      "Train Epoch: 5 [4080/17352 (24%)] Loss: -188156.281250\n",
      "Train Epoch: 5 [4160/17352 (24%)] Loss: -181694.656250\n",
      "Train Epoch: 5 [4240/17352 (24%)] Loss: -172494.312500\n",
      "Train Epoch: 5 [4320/17352 (25%)] Loss: -206889.359375\n",
      "Train Epoch: 5 [4400/17352 (25%)] Loss: -228203.187500\n",
      "Train Epoch: 5 [4480/17352 (26%)] Loss: -210748.109375\n",
      "Train Epoch: 5 [4560/17352 (26%)] Loss: -180881.906250\n",
      "Train Epoch: 5 [4640/17352 (27%)] Loss: -173498.796875\n",
      "Train Epoch: 5 [4720/17352 (27%)] Loss: -185997.546875\n",
      "Train Epoch: 5 [4800/17352 (28%)] Loss: -168461.390625\n",
      "Train Epoch: 5 [4880/17352 (28%)] Loss: -180252.718750\n",
      "Train Epoch: 5 [4960/17352 (29%)] Loss: -95220.156250\n",
      "Train Epoch: 5 [5040/17352 (29%)] Loss: -149302.375000\n",
      "Train Epoch: 5 [5120/17352 (30%)] Loss: -195025.281250\n",
      "Train Epoch: 5 [5200/17352 (30%)] Loss: -171175.531250\n",
      "Train Epoch: 5 [5280/17352 (30%)] Loss: -207804.578125\n",
      "Train Epoch: 5 [5360/17352 (31%)] Loss: -187322.453125\n",
      "Train Epoch: 5 [5440/17352 (31%)] Loss: -167679.859375\n",
      "Train Epoch: 5 [5520/17352 (32%)] Loss: -196882.140625\n",
      "Train Epoch: 5 [5600/17352 (32%)] Loss: -184002.453125\n",
      "Train Epoch: 5 [5680/17352 (33%)] Loss: -202131.312500\n",
      "Train Epoch: 5 [5760/17352 (33%)] Loss: -192607.921875\n",
      "Train Epoch: 5 [5840/17352 (34%)] Loss: -213702.937500\n",
      "Train Epoch: 5 [5920/17352 (34%)] Loss: -203804.703125\n",
      "Train Epoch: 5 [6000/17352 (35%)] Loss: -191953.390625\n",
      "Train Epoch: 5 [6080/17352 (35%)] Loss: -202934.781250\n",
      "Train Epoch: 5 [6160/17352 (36%)] Loss: -187679.968750\n",
      "Train Epoch: 5 [6240/17352 (36%)] Loss: -199410.671875\n",
      "Train Epoch: 5 [6320/17352 (36%)] Loss: -192957.031250\n",
      "Train Epoch: 5 [6400/17352 (37%)] Loss: -189523.406250\n",
      "Train Epoch: 5 [6480/17352 (37%)] Loss: -192612.875000\n",
      "Train Epoch: 5 [6560/17352 (38%)] Loss: -197498.046875\n",
      "Train Epoch: 5 [6640/17352 (38%)] Loss: -174902.281250\n",
      "Train Epoch: 5 [6720/17352 (39%)] Loss: -189561.875000\n",
      "Train Epoch: 5 [6800/17352 (39%)] Loss: -148877.484375\n",
      "Train Epoch: 5 [6880/17352 (40%)] Loss: -180956.500000\n",
      "Train Epoch: 5 [6960/17352 (40%)] Loss: -185894.593750\n",
      "Train Epoch: 5 [7040/17352 (41%)] Loss: -194547.562500\n",
      "Train Epoch: 5 [7120/17352 (41%)] Loss: -187478.203125\n",
      "Train Epoch: 5 [7200/17352 (41%)] Loss: -140553.234375\n",
      "Train Epoch: 5 [7280/17352 (42%)] Loss: -208292.156250\n",
      "Train Epoch: 5 [7360/17352 (42%)] Loss: -179688.203125\n",
      "Train Epoch: 5 [7440/17352 (43%)] Loss: -208665.328125\n",
      "Train Epoch: 5 [7520/17352 (43%)] Loss: -170302.234375\n",
      "Train Epoch: 5 [7600/17352 (44%)] Loss: -166424.187500\n",
      "Train Epoch: 5 [7680/17352 (44%)] Loss: -161635.078125\n",
      "Train Epoch: 5 [7760/17352 (45%)] Loss: -182721.312500\n",
      "Train Epoch: 5 [7840/17352 (45%)] Loss: -211027.062500\n",
      "Train Epoch: 5 [7920/17352 (46%)] Loss: -161461.359375\n",
      "Train Epoch: 5 [8000/17352 (46%)] Loss: -180206.281250\n",
      "Train Epoch: 5 [8080/17352 (47%)] Loss: -179137.234375\n",
      "Train Epoch: 5 [8160/17352 (47%)] Loss: -177271.796875\n",
      "Train Epoch: 5 [8240/17352 (47%)] Loss: -191272.640625\n",
      "Train Epoch: 5 [8320/17352 (48%)] Loss: -181275.515625\n",
      "Train Epoch: 5 [8400/17352 (48%)] Loss: -180752.062500\n",
      "Train Epoch: 5 [8480/17352 (49%)] Loss: -193761.109375\n",
      "Train Epoch: 5 [8560/17352 (49%)] Loss: -199666.156250\n",
      "Train Epoch: 5 [8640/17352 (50%)] Loss: -181219.859375\n",
      "Train Epoch: 5 [8720/17352 (50%)] Loss: -174877.859375\n",
      "Train Epoch: 5 [8800/17352 (51%)] Loss: -177079.640625\n",
      "Train Epoch: 5 [8880/17352 (51%)] Loss: -180592.671875\n",
      "Train Epoch: 5 [8960/17352 (52%)] Loss: -168011.265625\n",
      "Train Epoch: 5 [9040/17352 (52%)] Loss: -191628.125000\n",
      "Train Epoch: 5 [9120/17352 (53%)] Loss: -210198.328125\n",
      "Train Epoch: 5 [9200/17352 (53%)] Loss: -179997.640625\n",
      "Train Epoch: 5 [9280/17352 (53%)] Loss: -195749.718750\n",
      "Train Epoch: 5 [9360/17352 (54%)] Loss: -162508.093750\n",
      "Train Epoch: 5 [9440/17352 (54%)] Loss: -176239.375000\n",
      "Train Epoch: 5 [9520/17352 (55%)] Loss: -203404.781250\n",
      "Train Epoch: 5 [9600/17352 (55%)] Loss: -159698.250000\n",
      "Train Epoch: 5 [9680/17352 (56%)] Loss: -196243.921875\n",
      "Train Epoch: 5 [9760/17352 (56%)] Loss: -205658.312500\n",
      "Train Epoch: 5 [9840/17352 (57%)] Loss: -202921.156250\n",
      "Train Epoch: 5 [9920/17352 (57%)] Loss: -204159.375000\n",
      "Train Epoch: 5 [10000/17352 (58%)] Loss: -196090.203125\n",
      "Train Epoch: 5 [10080/17352 (58%)] Loss: -174510.281250\n",
      "Train Epoch: 5 [10160/17352 (59%)] Loss: -184794.125000\n",
      "Train Epoch: 5 [10240/17352 (59%)] Loss: -166616.234375\n",
      "Train Epoch: 5 [10320/17352 (59%)] Loss: -172517.671875\n",
      "Train Epoch: 5 [10400/17352 (60%)] Loss: -171782.015625\n",
      "Train Epoch: 5 [10480/17352 (60%)] Loss: -165846.906250\n",
      "Train Epoch: 5 [10560/17352 (61%)] Loss: -175491.203125\n",
      "Train Epoch: 5 [10640/17352 (61%)] Loss: -180109.250000\n",
      "Train Epoch: 5 [10720/17352 (62%)] Loss: -159581.421875\n",
      "Train Epoch: 5 [10800/17352 (62%)] Loss: -167836.953125\n",
      "Train Epoch: 5 [10880/17352 (63%)] Loss: -177260.562500\n",
      "Train Epoch: 5 [10960/17352 (63%)] Loss: -203678.218750\n",
      "Train Epoch: 5 [11040/17352 (64%)] Loss: -223634.265625\n",
      "Train Epoch: 5 [11120/17352 (64%)] Loss: -191521.687500\n",
      "Train Epoch: 5 [11200/17352 (65%)] Loss: -183317.046875\n",
      "Train Epoch: 5 [11280/17352 (65%)] Loss: -190451.640625\n",
      "Train Epoch: 5 [11360/17352 (65%)] Loss: -185011.437500\n",
      "Train Epoch: 5 [11440/17352 (66%)] Loss: -173797.265625\n",
      "Train Epoch: 5 [11520/17352 (66%)] Loss: -196346.234375\n",
      "Train Epoch: 5 [11600/17352 (67%)] Loss: -180250.390625\n",
      "Train Epoch: 5 [11680/17352 (67%)] Loss: -203800.343750\n",
      "Train Epoch: 5 [11760/17352 (68%)] Loss: -183338.703125\n",
      "Train Epoch: 5 [11840/17352 (68%)] Loss: -218798.140625\n",
      "Train Epoch: 5 [11920/17352 (69%)] Loss: -179406.062500\n",
      "Train Epoch: 5 [12000/17352 (69%)] Loss: -173632.656250\n",
      "Train Epoch: 5 [12080/17352 (70%)] Loss: -202022.203125\n",
      "Train Epoch: 5 [12160/17352 (70%)] Loss: -174441.062500\n",
      "Train Epoch: 5 [12240/17352 (71%)] Loss: -183687.875000\n",
      "Train Epoch: 5 [12320/17352 (71%)] Loss: -193043.578125\n",
      "Train Epoch: 5 [12400/17352 (71%)] Loss: -177940.187500\n",
      "Train Epoch: 5 [12480/17352 (72%)] Loss: -186473.140625\n",
      "Train Epoch: 5 [12560/17352 (72%)] Loss: -185371.500000\n",
      "Train Epoch: 5 [12640/17352 (73%)] Loss: -177421.593750\n",
      "Train Epoch: 5 [12720/17352 (73%)] Loss: -168059.953125\n",
      "Train Epoch: 5 [12800/17352 (74%)] Loss: -174423.781250\n",
      "Train Epoch: 5 [12880/17352 (74%)] Loss: -181037.031250\n",
      "Train Epoch: 5 [12960/17352 (75%)] Loss: -204285.640625\n",
      "Train Epoch: 5 [13040/17352 (75%)] Loss: -191777.937500\n",
      "Train Epoch: 5 [13120/17352 (76%)] Loss: -167103.578125\n",
      "Train Epoch: 5 [13200/17352 (76%)] Loss: -194534.796875\n",
      "Train Epoch: 5 [13280/17352 (77%)] Loss: -167834.656250\n",
      "Train Epoch: 5 [13360/17352 (77%)] Loss: -197565.953125\n",
      "Train Epoch: 5 [13440/17352 (77%)] Loss: -206430.453125\n",
      "Train Epoch: 5 [13520/17352 (78%)] Loss: -208711.875000\n",
      "Train Epoch: 5 [13600/17352 (78%)] Loss: -209142.156250\n",
      "Train Epoch: 5 [13680/17352 (79%)] Loss: -160113.203125\n",
      "Train Epoch: 5 [13760/17352 (79%)] Loss: -213857.265625\n",
      "Train Epoch: 5 [13840/17352 (80%)] Loss: -183827.734375\n",
      "Train Epoch: 5 [13920/17352 (80%)] Loss: -196075.890625\n",
      "Train Epoch: 5 [14000/17352 (81%)] Loss: -201905.921875\n",
      "Train Epoch: 5 [14080/17352 (81%)] Loss: -184710.671875\n",
      "Train Epoch: 5 [14160/17352 (82%)] Loss: -188616.218750\n",
      "Train Epoch: 5 [14240/17352 (82%)] Loss: -198971.593750\n",
      "Train Epoch: 5 [14320/17352 (83%)] Loss: -180836.671875\n",
      "Train Epoch: 5 [14400/17352 (83%)] Loss: -198512.125000\n",
      "Train Epoch: 5 [14480/17352 (83%)] Loss: -178335.656250\n",
      "Train Epoch: 5 [14560/17352 (84%)] Loss: -164836.406250\n",
      "Train Epoch: 5 [14640/17352 (84%)] Loss: -200927.265625\n",
      "Train Epoch: 5 [14720/17352 (85%)] Loss: -204554.875000\n",
      "Train Epoch: 5 [14800/17352 (85%)] Loss: -181299.281250\n",
      "Train Epoch: 5 [14880/17352 (86%)] Loss: -195803.031250\n",
      "Train Epoch: 5 [14960/17352 (86%)] Loss: -201991.140625\n",
      "Train Epoch: 5 [15040/17352 (87%)] Loss: -187273.437500\n",
      "Train Epoch: 5 [15120/17352 (87%)] Loss: -198784.859375\n",
      "Train Epoch: 5 [15200/17352 (88%)] Loss: -215388.562500\n",
      "Train Epoch: 5 [15280/17352 (88%)] Loss: -196535.109375\n",
      "Train Epoch: 5 [15360/17352 (89%)] Loss: -187611.734375\n",
      "Train Epoch: 5 [15440/17352 (89%)] Loss: -183133.468750\n",
      "Train Epoch: 5 [15520/17352 (89%)] Loss: -231002.593750\n",
      "Train Epoch: 5 [15600/17352 (90%)] Loss: -201282.843750\n",
      "Train Epoch: 5 [15680/17352 (90%)] Loss: -164767.468750\n",
      "Train Epoch: 5 [15760/17352 (91%)] Loss: -187452.218750\n",
      "Train Epoch: 5 [15840/17352 (91%)] Loss: -157569.671875\n",
      "Train Epoch: 5 [15920/17352 (92%)] Loss: -166611.546875\n",
      "Train Epoch: 5 [16000/17352 (92%)] Loss: -186587.171875\n",
      "Train Epoch: 5 [16080/17352 (93%)] Loss: -163454.921875\n",
      "Train Epoch: 5 [16160/17352 (93%)] Loss: -183891.250000\n",
      "Train Epoch: 5 [16240/17352 (94%)] Loss: -200832.562500\n",
      "Train Epoch: 5 [16320/17352 (94%)] Loss: -187285.296875\n",
      "Train Epoch: 5 [16400/17352 (95%)] Loss: -197299.031250\n",
      "Train Epoch: 5 [16480/17352 (95%)] Loss: -202897.328125\n",
      "Train Epoch: 5 [16560/17352 (95%)] Loss: -165332.500000\n",
      "Train Epoch: 5 [16640/17352 (96%)] Loss: -174588.187500\n",
      "Train Epoch: 5 [16720/17352 (96%)] Loss: -159613.781250\n",
      "Train Epoch: 5 [16800/17352 (97%)] Loss: -189171.531250\n",
      "Train Epoch: 5 [16880/17352 (97%)] Loss: -170491.921875\n",
      "Train Epoch: 5 [16960/17352 (98%)] Loss: -193864.484375\n",
      "Train Epoch: 5 [17040/17352 (98%)] Loss: -200258.031250\n",
      "Train Epoch: 5 [17120/17352 (99%)] Loss: -174120.265625\n",
      "Train Epoch: 5 [17200/17352 (99%)] Loss: -129644.367188\n",
      "Train Epoch: 5 [17280/17352 (100%)] Loss: -179995.671875\n",
      "Train Epoch: 5 [17360/17352 (100%)] Loss: -166523.437500\n",
      "    epoch          : 5\n",
      "    loss           : -189302.29834040563\n",
      "    val_loss       : -23707.88081223752\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch5.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 6 [0/17352 (0%)] Loss: -224296.359375\n",
      "Train Epoch: 6 [80/17352 (0%)] Loss: -193655.765625\n",
      "Train Epoch: 6 [160/17352 (1%)] Loss: -206517.468750\n",
      "Train Epoch: 6 [240/17352 (1%)] Loss: -233701.109375\n",
      "Train Epoch: 6 [320/17352 (2%)] Loss: -216069.718750\n",
      "Train Epoch: 6 [400/17352 (2%)] Loss: -182729.296875\n",
      "Train Epoch: 6 [480/17352 (3%)] Loss: -186041.906250\n",
      "Train Epoch: 6 [560/17352 (3%)] Loss: -218478.750000\n",
      "Train Epoch: 6 [640/17352 (4%)] Loss: -185226.359375\n",
      "Train Epoch: 6 [720/17352 (4%)] Loss: -212621.640625\n",
      "Train Epoch: 6 [800/17352 (5%)] Loss: -227959.156250\n",
      "Train Epoch: 6 [880/17352 (5%)] Loss: -219172.640625\n",
      "Train Epoch: 6 [960/17352 (6%)] Loss: -196370.484375\n",
      "Train Epoch: 6 [1040/17352 (6%)] Loss: -206616.765625\n",
      "Train Epoch: 6 [1120/17352 (6%)] Loss: -202183.625000\n",
      "Train Epoch: 6 [1200/17352 (7%)] Loss: -193367.937500\n",
      "Train Epoch: 6 [1280/17352 (7%)] Loss: -221708.046875\n",
      "Train Epoch: 6 [1360/17352 (8%)] Loss: -203696.562500\n",
      "Train Epoch: 6 [1440/17352 (8%)] Loss: -214657.687500\n",
      "Train Epoch: 6 [1520/17352 (9%)] Loss: -188711.906250\n",
      "Train Epoch: 6 [1600/17352 (9%)] Loss: -229193.875000\n",
      "Train Epoch: 6 [1680/17352 (10%)] Loss: -205157.156250\n",
      "Train Epoch: 6 [1760/17352 (10%)] Loss: -231291.375000\n",
      "Train Epoch: 6 [1840/17352 (11%)] Loss: -236583.375000\n",
      "Train Epoch: 6 [1920/17352 (11%)] Loss: -205522.593750\n",
      "Train Epoch: 6 [2000/17352 (12%)] Loss: -212201.062500\n",
      "Train Epoch: 6 [2080/17352 (12%)] Loss: -200565.031250\n",
      "Train Epoch: 6 [2160/17352 (12%)] Loss: -208488.078125\n",
      "Train Epoch: 6 [2240/17352 (13%)] Loss: -174680.984375\n",
      "Train Epoch: 6 [2320/17352 (13%)] Loss: -166513.734375\n",
      "Train Epoch: 6 [2400/17352 (14%)] Loss: -201214.734375\n",
      "Train Epoch: 6 [2480/17352 (14%)] Loss: -167109.984375\n",
      "Train Epoch: 6 [2560/17352 (15%)] Loss: -160107.031250\n",
      "Train Epoch: 6 [2640/17352 (15%)] Loss: -178136.671875\n",
      "Train Epoch: 6 [2720/17352 (16%)] Loss: -165762.359375\n",
      "Train Epoch: 6 [2800/17352 (16%)] Loss: -134498.812500\n",
      "Train Epoch: 6 [2880/17352 (17%)] Loss: -196658.765625\n",
      "Train Epoch: 6 [2960/17352 (17%)] Loss: -185298.953125\n",
      "Train Epoch: 6 [3040/17352 (18%)] Loss: -197048.937500\n",
      "Train Epoch: 6 [3120/17352 (18%)] Loss: -181690.062500\n",
      "Train Epoch: 6 [3200/17352 (18%)] Loss: -178840.062500\n",
      "Train Epoch: 6 [3280/17352 (19%)] Loss: -200257.843750\n",
      "Train Epoch: 6 [3360/17352 (19%)] Loss: -204888.609375\n",
      "Train Epoch: 6 [3440/17352 (20%)] Loss: -217555.093750\n",
      "Train Epoch: 6 [3520/17352 (20%)] Loss: -186461.656250\n",
      "Train Epoch: 6 [3600/17352 (21%)] Loss: -187271.406250\n",
      "Train Epoch: 6 [3680/17352 (21%)] Loss: -208281.312500\n",
      "Train Epoch: 6 [3760/17352 (22%)] Loss: -173889.703125\n",
      "Train Epoch: 6 [3840/17352 (22%)] Loss: -202735.593750\n",
      "Train Epoch: 6 [3920/17352 (23%)] Loss: -169159.109375\n",
      "Train Epoch: 6 [4000/17352 (23%)] Loss: -189699.109375\n",
      "Train Epoch: 6 [4080/17352 (24%)] Loss: -167056.062500\n",
      "Train Epoch: 6 [4160/17352 (24%)] Loss: -170758.359375\n",
      "Train Epoch: 6 [4240/17352 (24%)] Loss: -180105.843750\n",
      "Train Epoch: 6 [4320/17352 (25%)] Loss: -183221.421875\n",
      "Train Epoch: 6 [4400/17352 (25%)] Loss: -201050.406250\n",
      "Train Epoch: 6 [4480/17352 (26%)] Loss: -205367.906250\n",
      "Train Epoch: 6 [4560/17352 (26%)] Loss: -180963.140625\n",
      "Train Epoch: 6 [4640/17352 (27%)] Loss: -195697.078125\n",
      "Train Epoch: 6 [4720/17352 (27%)] Loss: -188409.968750\n",
      "Train Epoch: 6 [4800/17352 (28%)] Loss: -196424.312500\n",
      "Train Epoch: 6 [4880/17352 (28%)] Loss: -191312.421875\n",
      "Train Epoch: 6 [4960/17352 (29%)] Loss: -172862.593750\n",
      "Train Epoch: 6 [5040/17352 (29%)] Loss: -196704.328125\n",
      "Train Epoch: 6 [5120/17352 (30%)] Loss: -208113.250000\n",
      "Train Epoch: 6 [5200/17352 (30%)] Loss: -187183.515625\n",
      "Train Epoch: 6 [5280/17352 (30%)] Loss: -200583.500000\n",
      "Train Epoch: 6 [5360/17352 (31%)] Loss: -200444.593750\n",
      "Train Epoch: 6 [5440/17352 (31%)] Loss: -189963.500000\n",
      "Train Epoch: 6 [5520/17352 (32%)] Loss: -187289.656250\n",
      "Train Epoch: 6 [5600/17352 (32%)] Loss: -194950.250000\n",
      "Train Epoch: 6 [5680/17352 (33%)] Loss: -220948.000000\n",
      "Train Epoch: 6 [5760/17352 (33%)] Loss: -163522.734375\n",
      "Train Epoch: 6 [5840/17352 (34%)] Loss: -183361.390625\n",
      "Train Epoch: 6 [5920/17352 (34%)] Loss: -197350.265625\n",
      "Train Epoch: 6 [6000/17352 (35%)] Loss: -177442.781250\n",
      "Train Epoch: 6 [6080/17352 (35%)] Loss: -213179.984375\n",
      "Train Epoch: 6 [6160/17352 (36%)] Loss: -192065.015625\n",
      "Train Epoch: 6 [6240/17352 (36%)] Loss: -184474.656250\n",
      "Train Epoch: 6 [6320/17352 (36%)] Loss: -209552.500000\n",
      "Train Epoch: 6 [6400/17352 (37%)] Loss: -188395.000000\n",
      "Train Epoch: 6 [6480/17352 (37%)] Loss: -184804.890625\n",
      "Train Epoch: 6 [6560/17352 (38%)] Loss: -173806.906250\n",
      "Train Epoch: 6 [6640/17352 (38%)] Loss: -187678.484375\n",
      "Train Epoch: 6 [6720/17352 (39%)] Loss: -183026.781250\n",
      "Train Epoch: 6 [6800/17352 (39%)] Loss: -218824.843750\n",
      "Train Epoch: 6 [6880/17352 (40%)] Loss: -181126.000000\n",
      "Train Epoch: 6 [6960/17352 (40%)] Loss: -175643.593750\n",
      "Train Epoch: 6 [7040/17352 (41%)] Loss: -190429.500000\n",
      "Train Epoch: 6 [7120/17352 (41%)] Loss: -172576.406250\n",
      "Train Epoch: 6 [7200/17352 (41%)] Loss: -183249.312500\n",
      "Train Epoch: 6 [7280/17352 (42%)] Loss: -198961.171875\n",
      "Train Epoch: 6 [7360/17352 (42%)] Loss: -183940.937500\n",
      "Train Epoch: 6 [7440/17352 (43%)] Loss: -129657.882812\n",
      "Train Epoch: 6 [7520/17352 (43%)] Loss: -203478.265625\n",
      "Train Epoch: 6 [7600/17352 (44%)] Loss: -169717.515625\n",
      "Train Epoch: 6 [7680/17352 (44%)] Loss: -186525.562500\n",
      "Train Epoch: 6 [7760/17352 (45%)] Loss: -188448.953125\n",
      "Train Epoch: 6 [7840/17352 (45%)] Loss: -168163.625000\n",
      "Train Epoch: 6 [7920/17352 (46%)] Loss: -198287.031250\n",
      "Train Epoch: 6 [8000/17352 (46%)] Loss: -167705.812500\n",
      "Train Epoch: 6 [8080/17352 (47%)] Loss: -192969.515625\n",
      "Train Epoch: 6 [8160/17352 (47%)] Loss: -177570.500000\n",
      "Train Epoch: 6 [8240/17352 (47%)] Loss: -190213.390625\n",
      "Train Epoch: 6 [8320/17352 (48%)] Loss: -187272.921875\n",
      "Train Epoch: 6 [8400/17352 (48%)] Loss: -183570.609375\n",
      "Train Epoch: 6 [8480/17352 (49%)] Loss: -165357.640625\n",
      "Train Epoch: 6 [8560/17352 (49%)] Loss: -194921.265625\n",
      "Train Epoch: 6 [8640/17352 (50%)] Loss: -189449.921875\n",
      "Train Epoch: 6 [8720/17352 (50%)] Loss: -180078.562500\n",
      "Train Epoch: 6 [8800/17352 (51%)] Loss: -194021.515625\n",
      "Train Epoch: 6 [8880/17352 (51%)] Loss: -191012.343750\n",
      "Train Epoch: 6 [8960/17352 (52%)] Loss: -223658.687500\n",
      "Train Epoch: 6 [9040/17352 (52%)] Loss: -194569.984375\n",
      "Train Epoch: 6 [9120/17352 (53%)] Loss: -173999.984375\n",
      "Train Epoch: 6 [9200/17352 (53%)] Loss: -199409.546875\n",
      "Train Epoch: 6 [9280/17352 (53%)] Loss: -170202.421875\n",
      "Train Epoch: 6 [9360/17352 (54%)] Loss: -165701.828125\n",
      "Train Epoch: 6 [9440/17352 (54%)] Loss: -175631.890625\n",
      "Train Epoch: 6 [9520/17352 (55%)] Loss: -204333.390625\n",
      "Train Epoch: 6 [9600/17352 (55%)] Loss: -186387.906250\n",
      "Train Epoch: 6 [9680/17352 (56%)] Loss: -221206.203125\n",
      "Train Epoch: 6 [9760/17352 (56%)] Loss: -149391.812500\n",
      "Train Epoch: 6 [9840/17352 (57%)] Loss: -199748.093750\n",
      "Train Epoch: 6 [9920/17352 (57%)] Loss: -203117.328125\n",
      "Train Epoch: 6 [10000/17352 (58%)] Loss: -205771.265625\n",
      "Train Epoch: 6 [10080/17352 (58%)] Loss: -183371.609375\n",
      "Train Epoch: 6 [10160/17352 (59%)] Loss: -184422.781250\n",
      "Train Epoch: 6 [10240/17352 (59%)] Loss: -210214.218750\n",
      "Train Epoch: 6 [10320/17352 (59%)] Loss: -193405.109375\n",
      "Train Epoch: 6 [10400/17352 (60%)] Loss: -190912.640625\n",
      "Train Epoch: 6 [10480/17352 (60%)] Loss: -200850.609375\n",
      "Train Epoch: 6 [10560/17352 (61%)] Loss: -195475.578125\n",
      "Train Epoch: 6 [10640/17352 (61%)] Loss: -170496.531250\n",
      "Train Epoch: 6 [10720/17352 (62%)] Loss: -179949.875000\n",
      "Train Epoch: 6 [10800/17352 (62%)] Loss: -178681.875000\n",
      "Train Epoch: 6 [10880/17352 (63%)] Loss: -205135.156250\n",
      "Train Epoch: 6 [10960/17352 (63%)] Loss: -204577.046875\n",
      "Train Epoch: 6 [11040/17352 (64%)] Loss: -192287.234375\n",
      "Train Epoch: 6 [11120/17352 (64%)] Loss: -184805.062500\n",
      "Train Epoch: 6 [11200/17352 (65%)] Loss: -178164.656250\n",
      "Train Epoch: 6 [11280/17352 (65%)] Loss: -181329.296875\n",
      "Train Epoch: 6 [11360/17352 (65%)] Loss: -211678.531250\n",
      "Train Epoch: 6 [11440/17352 (66%)] Loss: -184992.890625\n",
      "Train Epoch: 6 [11520/17352 (66%)] Loss: -183428.750000\n",
      "Train Epoch: 6 [11600/17352 (67%)] Loss: -202560.453125\n",
      "Train Epoch: 6 [11680/17352 (67%)] Loss: -200384.281250\n",
      "Train Epoch: 6 [11760/17352 (68%)] Loss: -163943.812500\n",
      "Train Epoch: 6 [11840/17352 (68%)] Loss: -131020.242188\n",
      "Train Epoch: 6 [11920/17352 (69%)] Loss: -166390.359375\n",
      "Train Epoch: 6 [12000/17352 (69%)] Loss: -228232.578125\n",
      "Train Epoch: 6 [12080/17352 (70%)] Loss: -194206.875000\n",
      "Train Epoch: 6 [12160/17352 (70%)] Loss: -175371.484375\n",
      "Train Epoch: 6 [12240/17352 (71%)] Loss: -163319.703125\n",
      "Train Epoch: 6 [12320/17352 (71%)] Loss: -165967.359375\n",
      "Train Epoch: 6 [12400/17352 (71%)] Loss: -163748.421875\n",
      "Train Epoch: 6 [12480/17352 (72%)] Loss: -187749.468750\n",
      "Train Epoch: 6 [12560/17352 (72%)] Loss: -171267.750000\n",
      "Train Epoch: 6 [12640/17352 (73%)] Loss: -178326.703125\n",
      "Train Epoch: 6 [12720/17352 (73%)] Loss: -203426.468750\n",
      "Train Epoch: 6 [12800/17352 (74%)] Loss: -164054.281250\n",
      "Train Epoch: 6 [12880/17352 (74%)] Loss: -199490.218750\n",
      "Train Epoch: 6 [12960/17352 (75%)] Loss: -200022.531250\n",
      "Train Epoch: 6 [13040/17352 (75%)] Loss: -177591.000000\n",
      "Train Epoch: 6 [13120/17352 (76%)] Loss: -145975.234375\n",
      "Train Epoch: 6 [13200/17352 (76%)] Loss: -193140.281250\n",
      "Train Epoch: 6 [13280/17352 (77%)] Loss: -159627.421875\n",
      "Train Epoch: 6 [13360/17352 (77%)] Loss: -154573.875000\n",
      "Train Epoch: 6 [13440/17352 (77%)] Loss: -168971.343750\n",
      "Train Epoch: 6 [13520/17352 (78%)] Loss: -185197.265625\n",
      "Train Epoch: 6 [13600/17352 (78%)] Loss: -184949.093750\n",
      "Train Epoch: 6 [13680/17352 (79%)] Loss: -170647.203125\n",
      "Train Epoch: 6 [13760/17352 (79%)] Loss: -171276.265625\n",
      "Train Epoch: 6 [13840/17352 (80%)] Loss: -159726.109375\n",
      "Train Epoch: 6 [13920/17352 (80%)] Loss: -184213.109375\n",
      "Train Epoch: 6 [14000/17352 (81%)] Loss: -174126.375000\n",
      "Train Epoch: 6 [14080/17352 (81%)] Loss: -177580.812500\n",
      "Train Epoch: 6 [14160/17352 (82%)] Loss: -198761.328125\n",
      "Train Epoch: 6 [14240/17352 (82%)] Loss: -187839.562500\n",
      "Train Epoch: 6 [14320/17352 (83%)] Loss: -206160.671875\n",
      "Train Epoch: 6 [14400/17352 (83%)] Loss: -210888.093750\n",
      "Train Epoch: 6 [14480/17352 (83%)] Loss: -183840.625000\n",
      "Train Epoch: 6 [14560/17352 (84%)] Loss: -191785.500000\n",
      "Train Epoch: 6 [14640/17352 (84%)] Loss: -179418.140625\n",
      "Train Epoch: 6 [14720/17352 (85%)] Loss: -188925.125000\n",
      "Train Epoch: 6 [14800/17352 (85%)] Loss: -189258.843750\n",
      "Train Epoch: 6 [14880/17352 (86%)] Loss: -201311.593750\n",
      "Train Epoch: 6 [14960/17352 (86%)] Loss: -209245.187500\n",
      "Train Epoch: 6 [15040/17352 (87%)] Loss: -181877.468750\n",
      "Train Epoch: 6 [15120/17352 (87%)] Loss: -208083.671875\n",
      "Train Epoch: 6 [15200/17352 (88%)] Loss: -140561.062500\n",
      "Train Epoch: 6 [15280/17352 (88%)] Loss: -176943.328125\n",
      "Train Epoch: 6 [15360/17352 (89%)] Loss: -177546.812500\n",
      "Train Epoch: 6 [15440/17352 (89%)] Loss: -192257.921875\n",
      "Train Epoch: 6 [15520/17352 (89%)] Loss: -203844.359375\n",
      "Train Epoch: 6 [15600/17352 (90%)] Loss: -207762.750000\n",
      "Train Epoch: 6 [15680/17352 (90%)] Loss: -200800.031250\n",
      "Train Epoch: 6 [15760/17352 (91%)] Loss: -167009.234375\n",
      "Train Epoch: 6 [15840/17352 (91%)] Loss: -171168.828125\n",
      "Train Epoch: 6 [15920/17352 (92%)] Loss: -176122.671875\n",
      "Train Epoch: 6 [16000/17352 (92%)] Loss: -187936.593750\n",
      "Train Epoch: 6 [16080/17352 (93%)] Loss: -166949.906250\n",
      "Train Epoch: 6 [16160/17352 (93%)] Loss: -183765.843750\n",
      "Train Epoch: 6 [16240/17352 (94%)] Loss: -164633.406250\n",
      "Train Epoch: 6 [16320/17352 (94%)] Loss: -179009.906250\n",
      "Train Epoch: 6 [16400/17352 (95%)] Loss: -224835.156250\n",
      "Train Epoch: 6 [16480/17352 (95%)] Loss: -205480.656250\n",
      "Train Epoch: 6 [16560/17352 (95%)] Loss: -183696.515625\n",
      "Train Epoch: 6 [16640/17352 (96%)] Loss: -191965.156250\n",
      "Train Epoch: 6 [16720/17352 (96%)] Loss: -172145.578125\n",
      "Train Epoch: 6 [16800/17352 (97%)] Loss: -181930.296875\n",
      "Train Epoch: 6 [16880/17352 (97%)] Loss: -201485.453125\n",
      "Train Epoch: 6 [16960/17352 (98%)] Loss: -173463.171875\n",
      "Train Epoch: 6 [17040/17352 (98%)] Loss: -179128.093750\n",
      "Train Epoch: 6 [17120/17352 (99%)] Loss: -172201.171875\n",
      "Train Epoch: 6 [17200/17352 (99%)] Loss: -179688.421875\n",
      "Train Epoch: 6 [17280/17352 (100%)] Loss: -178991.078125\n",
      "Train Epoch: 6 [17360/17352 (100%)] Loss: -197617.390625\n",
      "    epoch          : 6\n",
      "    loss           : -189205.55952423764\n",
      "    val_loss       : -23710.827319221316\n",
      "Train Epoch: 7 [0/17352 (0%)] Loss: -215451.156250\n",
      "Train Epoch: 7 [80/17352 (0%)] Loss: -194252.093750\n",
      "Train Epoch: 7 [160/17352 (1%)] Loss: -193544.937500\n",
      "Train Epoch: 7 [240/17352 (1%)] Loss: -196395.687500\n",
      "Train Epoch: 7 [320/17352 (2%)] Loss: -205151.187500\n",
      "Train Epoch: 7 [400/17352 (2%)] Loss: -216177.703125\n",
      "Train Epoch: 7 [480/17352 (3%)] Loss: -210318.328125\n",
      "Train Epoch: 7 [560/17352 (3%)] Loss: -214403.343750\n",
      "Train Epoch: 7 [640/17352 (4%)] Loss: -187688.468750\n",
      "Train Epoch: 7 [720/17352 (4%)] Loss: -212373.359375\n",
      "Train Epoch: 7 [800/17352 (5%)] Loss: -205520.765625\n",
      "Train Epoch: 7 [880/17352 (5%)] Loss: -206612.171875\n",
      "Train Epoch: 7 [960/17352 (6%)] Loss: -224185.484375\n",
      "Train Epoch: 7 [1040/17352 (6%)] Loss: -230377.296875\n",
      "Train Epoch: 7 [1120/17352 (6%)] Loss: -212214.625000\n",
      "Train Epoch: 7 [1200/17352 (7%)] Loss: -206120.984375\n",
      "Train Epoch: 7 [1280/17352 (7%)] Loss: -209738.093750\n",
      "Train Epoch: 7 [1360/17352 (8%)] Loss: -214373.312500\n",
      "Train Epoch: 7 [1440/17352 (8%)] Loss: -193672.796875\n",
      "Train Epoch: 7 [1520/17352 (9%)] Loss: -211858.312500\n",
      "Train Epoch: 7 [1600/17352 (9%)] Loss: -202183.718750\n",
      "Train Epoch: 7 [1680/17352 (10%)] Loss: -212663.046875\n",
      "Train Epoch: 7 [1760/17352 (10%)] Loss: -224224.093750\n",
      "Train Epoch: 7 [1840/17352 (11%)] Loss: -206527.671875\n",
      "Train Epoch: 7 [1920/17352 (11%)] Loss: -201974.609375\n",
      "Train Epoch: 7 [2000/17352 (12%)] Loss: -213300.078125\n",
      "Train Epoch: 7 [2080/17352 (12%)] Loss: -214473.968750\n",
      "Train Epoch: 7 [2160/17352 (12%)] Loss: -216044.640625\n",
      "Train Epoch: 7 [2240/17352 (13%)] Loss: -193463.859375\n",
      "Train Epoch: 7 [2320/17352 (13%)] Loss: -177538.390625\n",
      "Train Epoch: 7 [2400/17352 (14%)] Loss: -197547.484375\n",
      "Train Epoch: 7 [2480/17352 (14%)] Loss: -179466.984375\n",
      "Train Epoch: 7 [2560/17352 (15%)] Loss: -180267.437500\n",
      "Train Epoch: 7 [2640/17352 (15%)] Loss: -187854.515625\n",
      "Train Epoch: 7 [2720/17352 (16%)] Loss: -192278.093750\n",
      "Train Epoch: 7 [2800/17352 (16%)] Loss: -149305.437500\n",
      "Train Epoch: 7 [2880/17352 (17%)] Loss: -183751.468750\n",
      "Train Epoch: 7 [2960/17352 (17%)] Loss: -186013.953125\n",
      "Train Epoch: 7 [3040/17352 (18%)] Loss: -177947.843750\n",
      "Train Epoch: 7 [3120/17352 (18%)] Loss: -213208.968750\n",
      "Train Epoch: 7 [3200/17352 (18%)] Loss: -200826.250000\n",
      "Train Epoch: 7 [3280/17352 (19%)] Loss: -171195.515625\n",
      "Train Epoch: 7 [3360/17352 (19%)] Loss: -193150.796875\n",
      "Train Epoch: 7 [3440/17352 (20%)] Loss: -164966.343750\n",
      "Train Epoch: 7 [3520/17352 (20%)] Loss: -175641.250000\n",
      "Train Epoch: 7 [3600/17352 (21%)] Loss: -187579.234375\n",
      "Train Epoch: 7 [3680/17352 (21%)] Loss: -175287.718750\n",
      "Train Epoch: 7 [3760/17352 (22%)] Loss: -190946.640625\n",
      "Train Epoch: 7 [3840/17352 (22%)] Loss: -210521.375000\n",
      "Train Epoch: 7 [3920/17352 (23%)] Loss: -188225.031250\n",
      "Train Epoch: 7 [4000/17352 (23%)] Loss: -166759.984375\n",
      "Train Epoch: 7 [4080/17352 (24%)] Loss: -225440.656250\n",
      "Train Epoch: 7 [4160/17352 (24%)] Loss: -185751.390625\n",
      "Train Epoch: 7 [4240/17352 (24%)] Loss: -192912.156250\n",
      "Train Epoch: 7 [4320/17352 (25%)] Loss: -177442.656250\n",
      "Train Epoch: 7 [4400/17352 (25%)] Loss: -189370.375000\n",
      "Train Epoch: 7 [4480/17352 (26%)] Loss: -212925.984375\n",
      "Train Epoch: 7 [4560/17352 (26%)] Loss: -196904.156250\n",
      "Train Epoch: 7 [4640/17352 (27%)] Loss: -145957.031250\n",
      "Train Epoch: 7 [4720/17352 (27%)] Loss: -176109.875000\n",
      "Train Epoch: 7 [4800/17352 (28%)] Loss: -190894.406250\n",
      "Train Epoch: 7 [4880/17352 (28%)] Loss: -181947.968750\n",
      "Train Epoch: 7 [4960/17352 (29%)] Loss: -178188.578125\n",
      "Train Epoch: 7 [5040/17352 (29%)] Loss: -177738.187500\n",
      "Train Epoch: 7 [5120/17352 (30%)] Loss: -134508.515625\n",
      "Train Epoch: 7 [5200/17352 (30%)] Loss: -180978.890625\n",
      "Train Epoch: 7 [5280/17352 (30%)] Loss: -181333.406250\n",
      "Train Epoch: 7 [5360/17352 (31%)] Loss: -177059.218750\n",
      "Train Epoch: 7 [5440/17352 (31%)] Loss: -176559.906250\n",
      "Train Epoch: 7 [5520/17352 (32%)] Loss: -197071.968750\n",
      "Train Epoch: 7 [5600/17352 (32%)] Loss: -224832.281250\n",
      "Train Epoch: 7 [5680/17352 (33%)] Loss: -181518.046875\n",
      "Train Epoch: 7 [5760/17352 (33%)] Loss: -186748.468750\n",
      "Train Epoch: 7 [5840/17352 (34%)] Loss: -185192.406250\n",
      "Train Epoch: 7 [5920/17352 (34%)] Loss: -185977.875000\n",
      "Train Epoch: 7 [6000/17352 (35%)] Loss: -207996.218750\n",
      "Train Epoch: 7 [6080/17352 (35%)] Loss: -187969.453125\n",
      "Train Epoch: 7 [6160/17352 (36%)] Loss: -187231.078125\n",
      "Train Epoch: 7 [6240/17352 (36%)] Loss: -203657.421875\n",
      "Train Epoch: 7 [6320/17352 (36%)] Loss: -202182.828125\n",
      "Train Epoch: 7 [6400/17352 (37%)] Loss: -203820.671875\n",
      "Train Epoch: 7 [6480/17352 (37%)] Loss: -157722.312500\n",
      "Train Epoch: 7 [6560/17352 (38%)] Loss: -163057.078125\n",
      "Train Epoch: 7 [6640/17352 (38%)] Loss: -196379.578125\n",
      "Train Epoch: 7 [6720/17352 (39%)] Loss: -178987.906250\n",
      "Train Epoch: 7 [6800/17352 (39%)] Loss: -177271.765625\n",
      "Train Epoch: 7 [6880/17352 (40%)] Loss: -206184.187500\n",
      "Train Epoch: 7 [6960/17352 (40%)] Loss: -177561.625000\n",
      "Train Epoch: 7 [7040/17352 (41%)] Loss: -191803.031250\n",
      "Train Epoch: 7 [7120/17352 (41%)] Loss: -177716.859375\n",
      "Train Epoch: 7 [7200/17352 (41%)] Loss: -200595.218750\n",
      "Train Epoch: 7 [7280/17352 (42%)] Loss: -186101.312500\n",
      "Train Epoch: 7 [7360/17352 (42%)] Loss: -195851.312500\n",
      "Train Epoch: 7 [7440/17352 (43%)] Loss: -200248.500000\n",
      "Train Epoch: 7 [7520/17352 (43%)] Loss: -191600.625000\n",
      "Train Epoch: 7 [7600/17352 (44%)] Loss: -199745.031250\n",
      "Train Epoch: 7 [7680/17352 (44%)] Loss: -148810.156250\n",
      "Train Epoch: 7 [7760/17352 (45%)] Loss: -176851.765625\n",
      "Train Epoch: 7 [7840/17352 (45%)] Loss: -183897.703125\n",
      "Train Epoch: 7 [7920/17352 (46%)] Loss: -172995.078125\n",
      "Train Epoch: 7 [8000/17352 (46%)] Loss: -198277.406250\n",
      "Train Epoch: 7 [8080/17352 (47%)] Loss: -195031.515625\n",
      "Train Epoch: 7 [8160/17352 (47%)] Loss: -180214.218750\n",
      "Train Epoch: 7 [8240/17352 (47%)] Loss: -185795.828125\n",
      "Train Epoch: 7 [8320/17352 (48%)] Loss: -159711.906250\n",
      "Train Epoch: 7 [8400/17352 (48%)] Loss: -208393.812500\n",
      "Train Epoch: 7 [8480/17352 (49%)] Loss: -194920.109375\n",
      "Train Epoch: 7 [8560/17352 (49%)] Loss: -204632.359375\n",
      "Train Epoch: 7 [8640/17352 (50%)] Loss: -205118.765625\n",
      "Train Epoch: 7 [8720/17352 (50%)] Loss: -201007.718750\n",
      "Train Epoch: 7 [8800/17352 (51%)] Loss: -158578.281250\n",
      "Train Epoch: 7 [8880/17352 (51%)] Loss: -197536.875000\n",
      "Train Epoch: 7 [8960/17352 (52%)] Loss: -166389.687500\n",
      "Train Epoch: 7 [9040/17352 (52%)] Loss: -203239.984375\n",
      "Train Epoch: 7 [9120/17352 (53%)] Loss: -148124.328125\n",
      "Train Epoch: 7 [9200/17352 (53%)] Loss: -199045.968750\n",
      "Train Epoch: 7 [9280/17352 (53%)] Loss: -204297.343750\n",
      "Train Epoch: 7 [9360/17352 (54%)] Loss: -209472.937500\n",
      "Train Epoch: 7 [9440/17352 (54%)] Loss: -164066.218750\n",
      "Train Epoch: 7 [9520/17352 (55%)] Loss: -200042.031250\n",
      "Train Epoch: 7 [9600/17352 (55%)] Loss: -190210.187500\n",
      "Train Epoch: 7 [9680/17352 (56%)] Loss: -187487.906250\n",
      "Train Epoch: 7 [9760/17352 (56%)] Loss: -170755.015625\n",
      "Train Epoch: 7 [9840/17352 (57%)] Loss: -204908.718750\n",
      "Train Epoch: 7 [9920/17352 (57%)] Loss: -160114.453125\n",
      "Train Epoch: 7 [10000/17352 (58%)] Loss: -205605.453125\n",
      "Train Epoch: 7 [10080/17352 (58%)] Loss: -191329.031250\n",
      "Train Epoch: 7 [10160/17352 (59%)] Loss: -188024.078125\n",
      "Train Epoch: 7 [10240/17352 (59%)] Loss: -209233.828125\n",
      "Train Epoch: 7 [10320/17352 (59%)] Loss: -176677.046875\n",
      "Train Epoch: 7 [10400/17352 (60%)] Loss: -218798.203125\n",
      "Train Epoch: 7 [10480/17352 (60%)] Loss: -171704.296875\n",
      "Train Epoch: 7 [10560/17352 (61%)] Loss: -185251.781250\n",
      "Train Epoch: 7 [10640/17352 (61%)] Loss: -195996.718750\n",
      "Train Epoch: 7 [10720/17352 (62%)] Loss: -168964.125000\n",
      "Train Epoch: 7 [10800/17352 (62%)] Loss: -175479.578125\n",
      "Train Epoch: 7 [10880/17352 (63%)] Loss: -169156.953125\n",
      "Train Epoch: 7 [10960/17352 (63%)] Loss: -205656.703125\n",
      "Train Epoch: 7 [11040/17352 (64%)] Loss: -196844.109375\n",
      "Train Epoch: 7 [11120/17352 (64%)] Loss: -203792.390625\n",
      "Train Epoch: 7 [11200/17352 (65%)] Loss: -210434.109375\n",
      "Train Epoch: 7 [11280/17352 (65%)] Loss: -143589.265625\n",
      "Train Epoch: 7 [11360/17352 (65%)] Loss: -228214.093750\n",
      "Train Epoch: 7 [11440/17352 (66%)] Loss: -187682.062500\n",
      "Train Epoch: 7 [11520/17352 (66%)] Loss: -189235.562500\n",
      "Train Epoch: 7 [11600/17352 (67%)] Loss: -217575.296875\n",
      "Train Epoch: 7 [11680/17352 (67%)] Loss: -162527.171875\n",
      "Train Epoch: 7 [11760/17352 (68%)] Loss: -170516.812500\n",
      "Train Epoch: 7 [11840/17352 (68%)] Loss: -185290.531250\n",
      "Train Epoch: 7 [11920/17352 (69%)] Loss: -193457.093750\n",
      "Train Epoch: 7 [12000/17352 (69%)] Loss: -179444.796875\n",
      "Train Epoch: 7 [12080/17352 (70%)] Loss: -167831.031250\n",
      "Train Epoch: 7 [12160/17352 (70%)] Loss: -164048.578125\n",
      "Train Epoch: 7 [12240/17352 (71%)] Loss: -178797.015625\n",
      "Train Epoch: 7 [12320/17352 (71%)] Loss: -219985.531250\n",
      "Train Epoch: 7 [12400/17352 (71%)] Loss: -181043.093750\n",
      "Train Epoch: 7 [12480/17352 (72%)] Loss: -149030.734375\n",
      "Train Epoch: 7 [12560/17352 (72%)] Loss: -208109.765625\n",
      "Train Epoch: 7 [12640/17352 (73%)] Loss: -208010.578125\n",
      "Train Epoch: 7 [12720/17352 (73%)] Loss: -168054.421875\n",
      "Train Epoch: 7 [12800/17352 (74%)] Loss: -178354.562500\n",
      "Train Epoch: 7 [12880/17352 (74%)] Loss: -183998.343750\n",
      "Train Epoch: 7 [12960/17352 (75%)] Loss: -193164.484375\n",
      "Train Epoch: 7 [13040/17352 (75%)] Loss: -196092.359375\n",
      "Train Epoch: 7 [13120/17352 (76%)] Loss: -174705.156250\n",
      "Train Epoch: 7 [13200/17352 (76%)] Loss: -210228.453125\n",
      "Train Epoch: 7 [13280/17352 (77%)] Loss: -183255.890625\n",
      "Train Epoch: 7 [13360/17352 (77%)] Loss: -178694.765625\n",
      "Train Epoch: 7 [13440/17352 (77%)] Loss: -196231.828125\n",
      "Train Epoch: 7 [13520/17352 (78%)] Loss: -187741.718750\n",
      "Train Epoch: 7 [13600/17352 (78%)] Loss: -178296.046875\n",
      "Train Epoch: 7 [13680/17352 (79%)] Loss: -195626.781250\n",
      "Train Epoch: 7 [13760/17352 (79%)] Loss: -187190.578125\n",
      "Train Epoch: 7 [13840/17352 (80%)] Loss: -217596.343750\n",
      "Train Epoch: 7 [13920/17352 (80%)] Loss: -203439.562500\n",
      "Train Epoch: 7 [14000/17352 (81%)] Loss: -184715.921875\n",
      "Train Epoch: 7 [14080/17352 (81%)] Loss: -176261.359375\n",
      "Train Epoch: 7 [14160/17352 (82%)] Loss: -187762.421875\n",
      "Train Epoch: 7 [14240/17352 (82%)] Loss: -172167.093750\n",
      "Train Epoch: 7 [14320/17352 (83%)] Loss: -174917.796875\n",
      "Train Epoch: 7 [14400/17352 (83%)] Loss: -175997.546875\n",
      "Train Epoch: 7 [14480/17352 (83%)] Loss: -200286.203125\n",
      "Train Epoch: 7 [14560/17352 (84%)] Loss: -189468.015625\n",
      "Train Epoch: 7 [14640/17352 (84%)] Loss: -196267.125000\n",
      "Train Epoch: 7 [14720/17352 (85%)] Loss: -210138.890625\n",
      "Train Epoch: 7 [14800/17352 (85%)] Loss: -186813.140625\n",
      "Train Epoch: 7 [14880/17352 (86%)] Loss: -189532.687500\n",
      "Train Epoch: 7 [14960/17352 (86%)] Loss: -170747.468750\n",
      "Train Epoch: 7 [15040/17352 (87%)] Loss: -208882.765625\n",
      "Train Epoch: 7 [15120/17352 (87%)] Loss: -166001.718750\n",
      "Train Epoch: 7 [15200/17352 (88%)] Loss: -206661.937500\n",
      "Train Epoch: 7 [15280/17352 (88%)] Loss: -166472.687500\n",
      "Train Epoch: 7 [15360/17352 (89%)] Loss: -204958.687500\n",
      "Train Epoch: 7 [15440/17352 (89%)] Loss: -188413.015625\n",
      "Train Epoch: 7 [15520/17352 (89%)] Loss: -199686.031250\n",
      "Train Epoch: 7 [15600/17352 (90%)] Loss: -180018.875000\n",
      "Train Epoch: 7 [15680/17352 (90%)] Loss: -185152.171875\n",
      "Train Epoch: 7 [15760/17352 (91%)] Loss: -174436.343750\n",
      "Train Epoch: 7 [15840/17352 (91%)] Loss: -215610.390625\n",
      "Train Epoch: 7 [15920/17352 (92%)] Loss: -166389.781250\n",
      "Train Epoch: 7 [16000/17352 (92%)] Loss: -184049.484375\n",
      "Train Epoch: 7 [16080/17352 (93%)] Loss: -183666.593750\n",
      "Train Epoch: 7 [16160/17352 (93%)] Loss: -167916.328125\n",
      "Train Epoch: 7 [16240/17352 (94%)] Loss: -165748.421875\n",
      "Train Epoch: 7 [16320/17352 (94%)] Loss: -184468.328125\n",
      "Train Epoch: 7 [16400/17352 (95%)] Loss: -164726.609375\n",
      "Train Epoch: 7 [16480/17352 (95%)] Loss: -173346.218750\n",
      "Train Epoch: 7 [16560/17352 (95%)] Loss: -159281.125000\n",
      "Train Epoch: 7 [16640/17352 (96%)] Loss: -208322.078125\n",
      "Train Epoch: 7 [16720/17352 (96%)] Loss: -208731.015625\n",
      "Train Epoch: 7 [16800/17352 (97%)] Loss: -214745.828125\n",
      "Train Epoch: 7 [16880/17352 (97%)] Loss: -163749.812500\n",
      "Train Epoch: 7 [16960/17352 (98%)] Loss: -168025.281250\n",
      "Train Epoch: 7 [17040/17352 (98%)] Loss: -183859.500000\n",
      "Train Epoch: 7 [17120/17352 (99%)] Loss: -178581.265625\n",
      "Train Epoch: 7 [17200/17352 (99%)] Loss: -192951.359375\n",
      "Train Epoch: 7 [17280/17352 (100%)] Loss: -193025.890625\n",
      "Train Epoch: 7 [17360/17352 (100%)] Loss: -177179.500000\n",
      "    epoch          : 7\n",
      "    loss           : -189325.0460029488\n",
      "    val_loss       : -23711.444378275268\n",
      "Train Epoch: 8 [0/17352 (0%)] Loss: -216076.468750\n",
      "Train Epoch: 8 [80/17352 (0%)] Loss: -217912.218750\n",
      "Train Epoch: 8 [160/17352 (1%)] Loss: -212236.156250\n",
      "Train Epoch: 8 [240/17352 (1%)] Loss: -206618.890625\n",
      "Train Epoch: 8 [320/17352 (2%)] Loss: -215810.937500\n",
      "Train Epoch: 8 [400/17352 (2%)] Loss: -186044.500000\n",
      "Train Epoch: 8 [480/17352 (3%)] Loss: -206723.515625\n",
      "Train Epoch: 8 [560/17352 (3%)] Loss: -212346.546875\n",
      "Train Epoch: 8 [640/17352 (4%)] Loss: -196422.203125\n",
      "Train Epoch: 8 [720/17352 (4%)] Loss: -206108.328125\n",
      "Train Epoch: 8 [800/17352 (5%)] Loss: -221727.109375\n",
      "Train Epoch: 8 [880/17352 (5%)] Loss: -205177.500000\n",
      "Train Epoch: 8 [960/17352 (6%)] Loss: -213775.171875\n",
      "Train Epoch: 8 [1040/17352 (6%)] Loss: -209734.578125\n",
      "Train Epoch: 8 [1120/17352 (6%)] Loss: -194474.265625\n",
      "Train Epoch: 8 [1200/17352 (7%)] Loss: -211059.484375\n",
      "Train Epoch: 8 [1280/17352 (7%)] Loss: -209534.843750\n",
      "Train Epoch: 8 [1360/17352 (8%)] Loss: -233689.250000\n",
      "Train Epoch: 8 [1440/17352 (8%)] Loss: -210315.203125\n",
      "Train Epoch: 8 [1520/17352 (9%)] Loss: -230166.375000\n",
      "Train Epoch: 8 [1600/17352 (9%)] Loss: -210162.062500\n",
      "Train Epoch: 8 [1680/17352 (10%)] Loss: -182745.828125\n",
      "Train Epoch: 8 [1760/17352 (10%)] Loss: -210491.546875\n",
      "Train Epoch: 8 [1840/17352 (11%)] Loss: -205171.375000\n",
      "Train Epoch: 8 [1920/17352 (11%)] Loss: -224215.343750\n",
      "Train Epoch: 8 [2000/17352 (12%)] Loss: -214387.171875\n",
      "Train Epoch: 8 [2080/17352 (12%)] Loss: -218532.406250\n",
      "Train Epoch: 8 [2160/17352 (12%)] Loss: -217548.281250\n",
      "Train Epoch: 8 [2240/17352 (13%)] Loss: -183931.281250\n",
      "Train Epoch: 8 [2320/17352 (13%)] Loss: -197069.140625\n",
      "Train Epoch: 8 [2400/17352 (14%)] Loss: -207823.125000\n",
      "Train Epoch: 8 [2480/17352 (14%)] Loss: -203489.187500\n",
      "Train Epoch: 8 [2560/17352 (15%)] Loss: -166407.765625\n",
      "Train Epoch: 8 [2640/17352 (15%)] Loss: -178794.187500\n",
      "Train Epoch: 8 [2720/17352 (16%)] Loss: -183346.562500\n",
      "Train Epoch: 8 [2800/17352 (16%)] Loss: -175479.609375\n",
      "Train Epoch: 8 [2880/17352 (17%)] Loss: -178304.484375\n",
      "Train Epoch: 8 [2960/17352 (17%)] Loss: -181670.171875\n",
      "Train Epoch: 8 [3040/17352 (18%)] Loss: -181653.312500\n",
      "Train Epoch: 8 [3120/17352 (18%)] Loss: -205457.437500\n",
      "Train Epoch: 8 [3200/17352 (18%)] Loss: -197279.562500\n",
      "Train Epoch: 8 [3280/17352 (19%)] Loss: -159291.875000\n",
      "Train Epoch: 8 [3360/17352 (19%)] Loss: -158582.078125\n",
      "Train Epoch: 8 [3440/17352 (20%)] Loss: -140566.984375\n",
      "Train Epoch: 8 [3520/17352 (20%)] Loss: -184154.656250\n",
      "Train Epoch: 8 [3600/17352 (21%)] Loss: -209231.187500\n",
      "Train Epoch: 8 [3680/17352 (21%)] Loss: -213157.046875\n",
      "Train Epoch: 8 [3760/17352 (22%)] Loss: -199490.781250\n",
      "Train Epoch: 8 [3840/17352 (22%)] Loss: -179460.515625\n",
      "Train Epoch: 8 [3920/17352 (23%)] Loss: -186659.843750\n",
      "Train Epoch: 8 [4000/17352 (23%)] Loss: -183685.578125\n",
      "Train Epoch: 8 [4080/17352 (24%)] Loss: -206448.406250\n",
      "Train Epoch: 8 [4160/17352 (24%)] Loss: -187249.937500\n",
      "Train Epoch: 8 [4240/17352 (24%)] Loss: -181142.000000\n",
      "Train Epoch: 8 [4320/17352 (25%)] Loss: -142310.312500\n",
      "Train Epoch: 8 [4400/17352 (25%)] Loss: -196670.093750\n",
      "Train Epoch: 8 [4480/17352 (26%)] Loss: -193024.015625\n",
      "Train Epoch: 8 [4560/17352 (26%)] Loss: -180849.828125\n",
      "Train Epoch: 8 [4640/17352 (27%)] Loss: -203434.609375\n",
      "Train Epoch: 8 [4720/17352 (27%)] Loss: -187248.984375\n",
      "Train Epoch: 8 [4800/17352 (28%)] Loss: -198801.281250\n",
      "Train Epoch: 8 [4880/17352 (28%)] Loss: -170748.187500\n",
      "Train Epoch: 8 [4960/17352 (29%)] Loss: -216291.000000\n",
      "Train Epoch: 8 [5040/17352 (29%)] Loss: -209154.937500\n",
      "Train Epoch: 8 [5120/17352 (30%)] Loss: -168925.421875\n",
      "Train Epoch: 8 [5200/17352 (30%)] Loss: -170072.250000\n",
      "Train Epoch: 8 [5280/17352 (30%)] Loss: -166546.281250\n",
      "Train Epoch: 8 [5360/17352 (31%)] Loss: -198243.984375\n",
      "Train Epoch: 8 [5440/17352 (31%)] Loss: -180047.718750\n",
      "Train Epoch: 8 [5520/17352 (32%)] Loss: -166990.250000\n",
      "Train Epoch: 8 [5600/17352 (32%)] Loss: -202962.218750\n",
      "Train Epoch: 8 [5680/17352 (33%)] Loss: -200955.750000\n",
      "Train Epoch: 8 [5760/17352 (33%)] Loss: -185509.031250\n",
      "Train Epoch: 8 [5840/17352 (34%)] Loss: -200195.406250\n",
      "Train Epoch: 8 [5920/17352 (34%)] Loss: -190186.281250\n",
      "Train Epoch: 8 [6000/17352 (35%)] Loss: -187276.468750\n",
      "Train Epoch: 8 [6080/17352 (35%)] Loss: -206574.750000\n",
      "Train Epoch: 8 [6160/17352 (36%)] Loss: -199423.812500\n",
      "Train Epoch: 8 [6240/17352 (36%)] Loss: -197415.062500\n",
      "Train Epoch: 8 [6320/17352 (36%)] Loss: -180508.968750\n",
      "Train Epoch: 8 [6400/17352 (37%)] Loss: -183361.125000\n",
      "Train Epoch: 8 [6480/17352 (37%)] Loss: -197984.296875\n",
      "Train Epoch: 8 [6560/17352 (38%)] Loss: -203862.984375\n",
      "Train Epoch: 8 [6640/17352 (38%)] Loss: -202759.828125\n",
      "Train Epoch: 8 [6720/17352 (39%)] Loss: -161067.218750\n",
      "Train Epoch: 8 [6800/17352 (39%)] Loss: -183858.218750\n",
      "Train Epoch: 8 [6880/17352 (40%)] Loss: -192229.687500\n",
      "Train Epoch: 8 [6960/17352 (40%)] Loss: -184000.156250\n",
      "Train Epoch: 8 [7040/17352 (41%)] Loss: -193476.812500\n",
      "Train Epoch: 8 [7120/17352 (41%)] Loss: -138320.734375\n",
      "Train Epoch: 8 [7200/17352 (41%)] Loss: -176471.375000\n",
      "Train Epoch: 8 [7280/17352 (42%)] Loss: -162535.468750\n",
      "Train Epoch: 8 [7360/17352 (42%)] Loss: -195767.812500\n",
      "Train Epoch: 8 [7440/17352 (43%)] Loss: -199746.593750\n",
      "Train Epoch: 8 [7520/17352 (43%)] Loss: -164110.000000\n",
      "Train Epoch: 8 [7600/17352 (44%)] Loss: -189693.000000\n",
      "Train Epoch: 8 [7680/17352 (44%)] Loss: -175632.531250\n",
      "Train Epoch: 8 [7760/17352 (45%)] Loss: -204465.359375\n",
      "Train Epoch: 8 [7840/17352 (45%)] Loss: -178772.156250\n",
      "Train Epoch: 8 [7920/17352 (46%)] Loss: -215148.937500\n",
      "Train Epoch: 8 [8000/17352 (46%)] Loss: -179436.000000\n",
      "Train Epoch: 8 [8080/17352 (47%)] Loss: -204972.468750\n",
      "Train Epoch: 8 [8160/17352 (47%)] Loss: -191981.437500\n",
      "Train Epoch: 8 [8240/17352 (47%)] Loss: -196424.421875\n",
      "Train Epoch: 8 [8320/17352 (48%)] Loss: -188127.281250\n",
      "Train Epoch: 8 [8400/17352 (48%)] Loss: -200594.546875\n",
      "Train Epoch: 8 [8480/17352 (49%)] Loss: -174991.718750\n",
      "Train Epoch: 8 [8560/17352 (49%)] Loss: -152725.625000\n",
      "Train Epoch: 8 [8640/17352 (50%)] Loss: -174117.843750\n",
      "Train Epoch: 8 [8720/17352 (50%)] Loss: -210237.359375\n",
      "Train Epoch: 8 [8800/17352 (51%)] Loss: -157744.437500\n",
      "Train Epoch: 8 [8880/17352 (51%)] Loss: -192091.875000\n",
      "Train Epoch: 8 [8960/17352 (52%)] Loss: -185145.875000\n",
      "Train Epoch: 8 [9040/17352 (52%)] Loss: -197314.562500\n",
      "Train Epoch: 8 [9120/17352 (53%)] Loss: -208013.484375\n",
      "Train Epoch: 8 [9200/17352 (53%)] Loss: -175643.968750\n",
      "Train Epoch: 8 [9280/17352 (53%)] Loss: -186405.093750\n",
      "Train Epoch: 8 [9360/17352 (54%)] Loss: -209581.781250\n",
      "Train Epoch: 8 [9440/17352 (54%)] Loss: -192614.078125\n",
      "Train Epoch: 8 [9520/17352 (55%)] Loss: -178299.578125\n",
      "Train Epoch: 8 [9600/17352 (55%)] Loss: -173860.281250\n",
      "Train Epoch: 8 [9680/17352 (56%)] Loss: -208314.015625\n",
      "Train Epoch: 8 [9760/17352 (56%)] Loss: -180811.421875\n",
      "Train Epoch: 8 [9840/17352 (57%)] Loss: -175293.343750\n",
      "Train Epoch: 8 [9920/17352 (57%)] Loss: -200371.406250\n",
      "Train Epoch: 8 [10000/17352 (58%)] Loss: -177572.046875\n",
      "Train Epoch: 8 [10080/17352 (58%)] Loss: -190914.531250\n",
      "Train Epoch: 8 [10160/17352 (59%)] Loss: -186917.156250\n",
      "Train Epoch: 8 [10240/17352 (59%)] Loss: -164058.453125\n",
      "Train Epoch: 8 [10320/17352 (59%)] Loss: -174854.750000\n",
      "Train Epoch: 8 [10400/17352 (60%)] Loss: -178798.265625\n",
      "Train Epoch: 8 [10480/17352 (60%)] Loss: -165369.484375\n",
      "Train Epoch: 8 [10560/17352 (61%)] Loss: -193893.906250\n",
      "Train Epoch: 8 [10640/17352 (61%)] Loss: -196708.250000\n",
      "Train Epoch: 8 [10720/17352 (62%)] Loss: -192718.781250\n",
      "Train Epoch: 8 [10800/17352 (62%)] Loss: -194207.859375\n",
      "Train Epoch: 8 [10880/17352 (63%)] Loss: -136410.484375\n",
      "Train Epoch: 8 [10960/17352 (63%)] Loss: -200273.812500\n",
      "Train Epoch: 8 [11040/17352 (64%)] Loss: -159597.109375\n",
      "Train Epoch: 8 [11120/17352 (64%)] Loss: -169152.421875\n",
      "Train Epoch: 8 [11200/17352 (65%)] Loss: -167169.968750\n",
      "Train Epoch: 8 [11280/17352 (65%)] Loss: -209173.734375\n",
      "Train Epoch: 8 [11360/17352 (65%)] Loss: -159723.500000\n",
      "Train Epoch: 8 [11440/17352 (66%)] Loss: -194932.796875\n",
      "Train Epoch: 8 [11520/17352 (66%)] Loss: -211058.875000\n",
      "Train Epoch: 8 [11600/17352 (67%)] Loss: -182896.671875\n",
      "Train Epoch: 8 [11680/17352 (67%)] Loss: -152877.812500\n",
      "Train Epoch: 8 [11760/17352 (68%)] Loss: -148427.203125\n",
      "Train Epoch: 8 [11840/17352 (68%)] Loss: -206899.343750\n",
      "Train Epoch: 8 [11920/17352 (69%)] Loss: -165334.140625\n",
      "Train Epoch: 8 [12000/17352 (69%)] Loss: -180200.828125\n",
      "Train Epoch: 8 [12080/17352 (70%)] Loss: -204913.531250\n",
      "Train Epoch: 8 [12160/17352 (70%)] Loss: -205678.796875\n",
      "Train Epoch: 8 [12240/17352 (71%)] Loss: -184431.046875\n",
      "Train Epoch: 8 [12320/17352 (71%)] Loss: -207094.750000\n",
      "Train Epoch: 8 [12400/17352 (71%)] Loss: -189370.093750\n",
      "Train Epoch: 8 [12480/17352 (72%)] Loss: -203122.062500\n",
      "Train Epoch: 8 [12560/17352 (72%)] Loss: -201074.937500\n",
      "Train Epoch: 8 [12640/17352 (73%)] Loss: -213206.312500\n",
      "Train Epoch: 8 [12720/17352 (73%)] Loss: -162686.968750\n",
      "Train Epoch: 8 [12800/17352 (74%)] Loss: -207759.531250\n",
      "Train Epoch: 8 [12880/17352 (74%)] Loss: -197091.843750\n",
      "Train Epoch: 8 [12960/17352 (75%)] Loss: -176870.187500\n",
      "Train Epoch: 8 [13040/17352 (75%)] Loss: -177223.359375\n",
      "Train Epoch: 8 [13120/17352 (76%)] Loss: -167463.453125\n",
      "Train Epoch: 8 [13200/17352 (76%)] Loss: -203856.687500\n",
      "Train Epoch: 8 [13280/17352 (77%)] Loss: -171880.156250\n",
      "Train Epoch: 8 [13360/17352 (77%)] Loss: -183734.406250\n",
      "Train Epoch: 8 [13440/17352 (77%)] Loss: -190200.375000\n",
      "Train Epoch: 8 [13520/17352 (78%)] Loss: -221222.234375\n",
      "Train Epoch: 8 [13600/17352 (78%)] Loss: -206523.125000\n",
      "Train Epoch: 8 [13680/17352 (79%)] Loss: -166241.109375\n",
      "Train Epoch: 8 [13760/17352 (79%)] Loss: -168974.937500\n",
      "Train Epoch: 8 [13840/17352 (80%)] Loss: -174638.234375\n",
      "Train Epoch: 8 [13920/17352 (80%)] Loss: -203869.203125\n",
      "Train Epoch: 8 [14000/17352 (81%)] Loss: -187857.062500\n",
      "Train Epoch: 8 [14080/17352 (81%)] Loss: -169415.500000\n",
      "Train Epoch: 8 [14160/17352 (82%)] Loss: -187699.328125\n",
      "Train Epoch: 8 [14240/17352 (82%)] Loss: -201307.062500\n",
      "Train Epoch: 8 [14320/17352 (83%)] Loss: -181248.406250\n",
      "Train Epoch: 8 [14400/17352 (83%)] Loss: -203106.750000\n",
      "Train Epoch: 8 [14480/17352 (83%)] Loss: -171565.218750\n",
      "Train Epoch: 8 [14560/17352 (84%)] Loss: -201346.500000\n",
      "Train Epoch: 8 [14640/17352 (84%)] Loss: -193255.281250\n",
      "Train Epoch: 8 [14720/17352 (85%)] Loss: -176664.750000\n",
      "Train Epoch: 8 [14800/17352 (85%)] Loss: -156455.156250\n",
      "Train Epoch: 8 [14880/17352 (86%)] Loss: -217598.687500\n",
      "Train Epoch: 8 [14960/17352 (86%)] Loss: -171404.375000\n",
      "Train Epoch: 8 [15040/17352 (87%)] Loss: -183144.046875\n",
      "Train Epoch: 8 [15120/17352 (87%)] Loss: -191609.281250\n",
      "Train Epoch: 8 [15200/17352 (88%)] Loss: -202844.484375\n",
      "Train Epoch: 8 [15280/17352 (88%)] Loss: -168022.046875\n",
      "Train Epoch: 8 [15360/17352 (89%)] Loss: -187752.718750\n",
      "Train Epoch: 8 [15440/17352 (89%)] Loss: -181576.687500\n",
      "Train Epoch: 8 [15520/17352 (89%)] Loss: -202281.765625\n",
      "Train Epoch: 8 [15600/17352 (90%)] Loss: -193159.421875\n",
      "Train Epoch: 8 [15680/17352 (90%)] Loss: -199150.109375\n",
      "Train Epoch: 8 [15760/17352 (91%)] Loss: -190465.875000\n",
      "Train Epoch: 8 [15840/17352 (91%)] Loss: -178101.750000\n",
      "Train Epoch: 8 [15920/17352 (92%)] Loss: -166009.578125\n",
      "Train Epoch: 8 [16000/17352 (92%)] Loss: -187928.156250\n",
      "Train Epoch: 8 [16080/17352 (93%)] Loss: -172936.734375\n",
      "Train Epoch: 8 [16160/17352 (93%)] Loss: -195015.765625\n",
      "Train Epoch: 8 [16240/17352 (94%)] Loss: -175191.937500\n",
      "Train Epoch: 8 [16320/17352 (94%)] Loss: -218723.078125\n",
      "Train Epoch: 8 [16400/17352 (95%)] Loss: -204663.281250\n",
      "Train Epoch: 8 [16480/17352 (95%)] Loss: -177272.125000\n",
      "Train Epoch: 8 [16560/17352 (95%)] Loss: -167854.687500\n",
      "Train Epoch: 8 [16640/17352 (96%)] Loss: -162960.562500\n",
      "Train Epoch: 8 [16720/17352 (96%)] Loss: -177179.843750\n",
      "Train Epoch: 8 [16800/17352 (97%)] Loss: -174174.843750\n",
      "Train Epoch: 8 [16880/17352 (97%)] Loss: -164771.812500\n",
      "Train Epoch: 8 [16960/17352 (98%)] Loss: -191299.234375\n",
      "Train Epoch: 8 [17040/17352 (98%)] Loss: -157578.312500\n",
      "Train Epoch: 8 [17120/17352 (99%)] Loss: -191494.140625\n",
      "Train Epoch: 8 [17200/17352 (99%)] Loss: -163183.984375\n",
      "Train Epoch: 8 [17280/17352 (100%)] Loss: -176244.281250\n",
      "Train Epoch: 8 [17360/17352 (100%)] Loss: -205376.875000\n",
      "    epoch          : 8\n",
      "    loss           : -189069.69404487917\n",
      "    val_loss       : -23711.611928089125\n",
      "Train Epoch: 9 [0/17352 (0%)] Loss: -212338.312500\n",
      "Train Epoch: 9 [80/17352 (0%)] Loss: -221455.062500\n",
      "Train Epoch: 9 [160/17352 (1%)] Loss: -187698.359375\n",
      "Train Epoch: 9 [240/17352 (1%)] Loss: -199871.062500\n",
      "Train Epoch: 9 [320/17352 (2%)] Loss: -202232.218750\n",
      "Train Epoch: 9 [400/17352 (2%)] Loss: -216184.406250\n",
      "Train Epoch: 9 [480/17352 (3%)] Loss: -215452.109375\n",
      "Train Epoch: 9 [560/17352 (3%)] Loss: -193560.140625\n",
      "Train Epoch: 9 [640/17352 (4%)] Loss: -194274.968750\n",
      "Train Epoch: 9 [720/17352 (4%)] Loss: -215797.156250\n",
      "Train Epoch: 9 [800/17352 (5%)] Loss: -214697.000000\n",
      "Train Epoch: 9 [880/17352 (5%)] Loss: -224208.406250\n",
      "Train Epoch: 9 [960/17352 (6%)] Loss: -214303.156250\n",
      "Train Epoch: 9 [1040/17352 (6%)] Loss: -212233.187500\n",
      "Train Epoch: 9 [1120/17352 (6%)] Loss: -191838.437500\n",
      "Train Epoch: 9 [1200/17352 (7%)] Loss: -214502.046875\n",
      "Train Epoch: 9 [1280/17352 (7%)] Loss: -219630.015625\n",
      "Train Epoch: 9 [1360/17352 (8%)] Loss: -203714.296875\n",
      "Train Epoch: 9 [1440/17352 (8%)] Loss: -205174.375000\n",
      "Train Epoch: 9 [1520/17352 (9%)] Loss: -236477.906250\n",
      "Train Epoch: 9 [1600/17352 (9%)] Loss: -185126.484375\n",
      "Train Epoch: 9 [1680/17352 (10%)] Loss: -236813.109375\n",
      "Train Epoch: 9 [1760/17352 (10%)] Loss: -231317.078125\n",
      "Train Epoch: 9 [1840/17352 (11%)] Loss: -204337.093750\n",
      "Train Epoch: 9 [1920/17352 (11%)] Loss: -212665.296875\n",
      "Train Epoch: 9 [2000/17352 (12%)] Loss: -210176.703125\n",
      "Train Epoch: 9 [2080/17352 (12%)] Loss: -230377.234375\n",
      "Train Epoch: 9 [2160/17352 (12%)] Loss: -208352.390625\n",
      "Train Epoch: 9 [2240/17352 (13%)] Loss: -189766.109375\n",
      "Train Epoch: 9 [2320/17352 (13%)] Loss: -178819.953125\n",
      "Train Epoch: 9 [2400/17352 (14%)] Loss: -174963.875000\n",
      "Train Epoch: 9 [2480/17352 (14%)] Loss: -142604.500000\n",
      "Train Epoch: 9 [2560/17352 (15%)] Loss: -163939.250000\n",
      "Train Epoch: 9 [2640/17352 (15%)] Loss: -228138.968750\n",
      "Train Epoch: 9 [2720/17352 (16%)] Loss: -208136.546875\n",
      "Train Epoch: 9 [2800/17352 (16%)] Loss: -140575.171875\n",
      "Train Epoch: 9 [2880/17352 (17%)] Loss: -175386.281250\n",
      "Train Epoch: 9 [2960/17352 (17%)] Loss: -194962.375000\n",
      "Train Epoch: 9 [3040/17352 (18%)] Loss: -194042.343750\n",
      "Train Epoch: 9 [3120/17352 (18%)] Loss: -179368.781250\n",
      "Train Epoch: 9 [3200/17352 (18%)] Loss: -200313.734375\n",
      "Train Epoch: 9 [3280/17352 (19%)] Loss: -183892.437500\n",
      "Train Epoch: 9 [3360/17352 (19%)] Loss: -164357.671875\n",
      "Train Epoch: 9 [3440/17352 (20%)] Loss: -195798.640625\n",
      "Train Epoch: 9 [3520/17352 (20%)] Loss: -169161.984375\n",
      "Train Epoch: 9 [3600/17352 (21%)] Loss: -208768.843750\n",
      "Train Epoch: 9 [3680/17352 (21%)] Loss: -165662.421875\n",
      "Train Epoch: 9 [3760/17352 (22%)] Loss: -177561.937500\n",
      "Train Epoch: 9 [3840/17352 (22%)] Loss: -216353.062500\n",
      "Train Epoch: 9 [3920/17352 (23%)] Loss: -192230.250000\n",
      "Train Epoch: 9 [4000/17352 (23%)] Loss: -206164.671875\n",
      "Train Epoch: 9 [4080/17352 (24%)] Loss: -175527.125000\n",
      "Train Epoch: 9 [4160/17352 (24%)] Loss: -209861.609375\n",
      "Train Epoch: 9 [4240/17352 (24%)] Loss: -185485.312500\n",
      "Train Epoch: 9 [4320/17352 (25%)] Loss: -169483.765625\n",
      "Train Epoch: 9 [4400/17352 (25%)] Loss: -205147.812500\n",
      "Train Epoch: 9 [4480/17352 (26%)] Loss: -199432.859375\n",
      "Train Epoch: 9 [4560/17352 (26%)] Loss: -193157.203125\n",
      "Train Epoch: 9 [4640/17352 (27%)] Loss: -151707.953125\n",
      "Train Epoch: 9 [4720/17352 (27%)] Loss: -181593.531250\n",
      "Train Epoch: 9 [4800/17352 (28%)] Loss: -217576.421875\n",
      "Train Epoch: 9 [4880/17352 (28%)] Loss: -174971.187500\n",
      "Train Epoch: 9 [4960/17352 (29%)] Loss: -185277.609375\n",
      "Train Epoch: 9 [5040/17352 (29%)] Loss: -212105.218750\n",
      "Train Epoch: 9 [5120/17352 (30%)] Loss: -168046.921875\n",
      "Train Epoch: 9 [5200/17352 (30%)] Loss: -198510.046875\n",
      "Train Epoch: 9 [5280/17352 (30%)] Loss: -180217.000000\n",
      "Train Epoch: 9 [5360/17352 (31%)] Loss: -193516.015625\n",
      "Train Epoch: 9 [5440/17352 (31%)] Loss: -183241.453125\n",
      "Train Epoch: 9 [5520/17352 (32%)] Loss: -202581.718750\n",
      "Train Epoch: 9 [5600/17352 (32%)] Loss: -181347.687500\n",
      "Train Epoch: 9 [5680/17352 (33%)] Loss: -194548.015625\n",
      "Train Epoch: 9 [5760/17352 (33%)] Loss: -200084.625000\n",
      "Train Epoch: 9 [5840/17352 (34%)] Loss: -193896.859375\n",
      "Train Epoch: 9 [5920/17352 (34%)] Loss: -187485.781250\n",
      "Train Epoch: 9 [6000/17352 (35%)] Loss: -201099.171875\n",
      "Train Epoch: 9 [6080/17352 (35%)] Loss: -208733.078125\n",
      "Train Epoch: 9 [6160/17352 (36%)] Loss: -152890.968750\n",
      "Train Epoch: 9 [6240/17352 (36%)] Loss: -197053.343750\n",
      "Train Epoch: 9 [6320/17352 (36%)] Loss: -191980.093750\n",
      "Train Epoch: 9 [6400/17352 (37%)] Loss: -210770.203125\n",
      "Train Epoch: 9 [6480/17352 (37%)] Loss: -175668.328125\n",
      "Train Epoch: 9 [6560/17352 (38%)] Loss: -149412.765625\n",
      "Train Epoch: 9 [6640/17352 (38%)] Loss: -188657.390625\n",
      "Train Epoch: 9 [6720/17352 (39%)] Loss: -156587.234375\n",
      "Train Epoch: 9 [6800/17352 (39%)] Loss: -178995.796875\n",
      "Train Epoch: 9 [6880/17352 (40%)] Loss: -183039.375000\n",
      "Train Epoch: 9 [6960/17352 (40%)] Loss: -196099.000000\n",
      "Train Epoch: 9 [7040/17352 (41%)] Loss: -200446.718750\n",
      "Train Epoch: 9 [7120/17352 (41%)] Loss: -197412.343750\n",
      "Train Epoch: 9 [7200/17352 (41%)] Loss: -189713.109375\n",
      "Train Epoch: 9 [7280/17352 (42%)] Loss: -196912.625000\n",
      "Train Epoch: 9 [7360/17352 (42%)] Loss: -155839.906250\n",
      "Train Epoch: 9 [7440/17352 (43%)] Loss: -159654.906250\n",
      "Train Epoch: 9 [7520/17352 (43%)] Loss: -177710.953125\n",
      "Train Epoch: 9 [7600/17352 (44%)] Loss: -196228.437500\n",
      "Train Epoch: 9 [7680/17352 (44%)] Loss: -178579.421875\n",
      "Train Epoch: 9 [7760/17352 (45%)] Loss: -209569.000000\n",
      "Train Epoch: 9 [7840/17352 (45%)] Loss: -166626.109375\n",
      "Train Epoch: 9 [7920/17352 (46%)] Loss: -159066.421875\n",
      "Train Epoch: 9 [8000/17352 (46%)] Loss: -185314.640625\n",
      "Train Epoch: 9 [8080/17352 (47%)] Loss: -198533.843750\n",
      "Train Epoch: 9 [8160/17352 (47%)] Loss: -195084.750000\n",
      "Train Epoch: 9 [8240/17352 (47%)] Loss: -194026.500000\n",
      "Train Epoch: 9 [8320/17352 (48%)] Loss: -196082.687500\n",
      "Train Epoch: 9 [8400/17352 (48%)] Loss: -164651.609375\n",
      "Train Epoch: 9 [8480/17352 (49%)] Loss: -200157.234375\n",
      "Train Epoch: 9 [8560/17352 (49%)] Loss: -196012.234375\n",
      "Train Epoch: 9 [8640/17352 (50%)] Loss: -192989.125000\n",
      "Train Epoch: 9 [8720/17352 (50%)] Loss: -180979.265625\n",
      "Train Epoch: 9 [8800/17352 (51%)] Loss: -191206.046875\n",
      "Train Epoch: 9 [8880/17352 (51%)] Loss: -170770.890625\n",
      "Train Epoch: 9 [8960/17352 (52%)] Loss: -157743.703125\n",
      "Train Epoch: 9 [9040/17352 (52%)] Loss: -156976.578125\n",
      "Train Epoch: 9 [9120/17352 (53%)] Loss: -176058.609375\n",
      "Train Epoch: 9 [9200/17352 (53%)] Loss: -183440.796875\n",
      "Train Epoch: 9 [9280/17352 (53%)] Loss: -176939.531250\n",
      "Train Epoch: 9 [9360/17352 (54%)] Loss: -204312.968750\n",
      "Train Epoch: 9 [9440/17352 (54%)] Loss: -202547.437500\n",
      "Train Epoch: 9 [9520/17352 (55%)] Loss: -198240.453125\n",
      "Train Epoch: 9 [9600/17352 (55%)] Loss: -172601.218750\n",
      "Train Epoch: 9 [9680/17352 (56%)] Loss: -184055.875000\n",
      "Train Epoch: 9 [9760/17352 (56%)] Loss: -202922.546875\n",
      "Train Epoch: 9 [9840/17352 (57%)] Loss: -213198.640625\n",
      "Train Epoch: 9 [9920/17352 (57%)] Loss: -153299.296875\n",
      "Train Epoch: 9 [10000/17352 (58%)] Loss: -186012.265625\n",
      "Train Epoch: 9 [10080/17352 (58%)] Loss: -175648.453125\n",
      "Train Epoch: 9 [10160/17352 (59%)] Loss: -144973.093750\n",
      "Train Epoch: 9 [10240/17352 (59%)] Loss: -165766.250000\n",
      "Train Epoch: 9 [10320/17352 (59%)] Loss: -173823.937500\n",
      "Train Epoch: 9 [10400/17352 (60%)] Loss: -164816.312500\n",
      "Train Epoch: 9 [10480/17352 (60%)] Loss: -201065.437500\n",
      "Train Epoch: 9 [10560/17352 (61%)] Loss: -206336.000000\n",
      "Train Epoch: 9 [10640/17352 (61%)] Loss: -167939.015625\n",
      "Train Epoch: 9 [10720/17352 (62%)] Loss: -179877.625000\n",
      "Train Epoch: 9 [10800/17352 (62%)] Loss: -206073.125000\n",
      "Train Epoch: 9 [10880/17352 (63%)] Loss: -167847.093750\n",
      "Train Epoch: 9 [10960/17352 (63%)] Loss: -181942.046875\n",
      "Train Epoch: 9 [11040/17352 (64%)] Loss: -164961.375000\n",
      "Train Epoch: 9 [11120/17352 (64%)] Loss: -191325.000000\n",
      "Train Epoch: 9 [11200/17352 (65%)] Loss: -164063.078125\n",
      "Train Epoch: 9 [11280/17352 (65%)] Loss: -163169.296875\n",
      "Train Epoch: 9 [11360/17352 (65%)] Loss: -172539.390625\n",
      "Train Epoch: 9 [11440/17352 (66%)] Loss: -191668.062500\n",
      "Train Epoch: 9 [11520/17352 (66%)] Loss: -172208.796875\n",
      "Train Epoch: 9 [11600/17352 (67%)] Loss: -178303.796875\n",
      "Train Epoch: 9 [11680/17352 (67%)] Loss: -176263.359375\n",
      "Train Epoch: 9 [11760/17352 (68%)] Loss: -202286.703125\n",
      "Train Epoch: 9 [11840/17352 (68%)] Loss: -203126.718750\n",
      "Train Epoch: 9 [11920/17352 (69%)] Loss: -159647.562500\n",
      "Train Epoch: 9 [12000/17352 (69%)] Loss: -177179.281250\n",
      "Train Epoch: 9 [12080/17352 (70%)] Loss: -178335.390625\n",
      "Train Epoch: 9 [12160/17352 (70%)] Loss: -198296.687500\n",
      "Train Epoch: 9 [12240/17352 (71%)] Loss: -208893.968750\n",
      "Train Epoch: 9 [12320/17352 (71%)] Loss: -197518.781250\n",
      "Train Epoch: 9 [12400/17352 (71%)] Loss: -174499.359375\n",
      "Train Epoch: 9 [12480/17352 (72%)] Loss: -186154.156250\n",
      "Train Epoch: 9 [12560/17352 (72%)] Loss: -204660.687500\n",
      "Train Epoch: 9 [12640/17352 (73%)] Loss: -208395.328125\n",
      "Train Epoch: 9 [12720/17352 (73%)] Loss: -184977.968750\n",
      "Train Epoch: 9 [12800/17352 (74%)] Loss: -183379.625000\n",
      "Train Epoch: 9 [12880/17352 (74%)] Loss: -192926.015625\n",
      "Train Epoch: 9 [12960/17352 (75%)] Loss: -187971.937500\n",
      "Train Epoch: 9 [13040/17352 (75%)] Loss: -185303.468750\n",
      "Train Epoch: 9 [13120/17352 (76%)] Loss: -178612.171875\n",
      "Train Epoch: 9 [13200/17352 (76%)] Loss: -188424.156250\n",
      "Train Epoch: 9 [13280/17352 (77%)] Loss: -190459.656250\n",
      "Train Epoch: 9 [13360/17352 (77%)] Loss: -183336.687500\n",
      "Train Epoch: 9 [13440/17352 (77%)] Loss: -207102.109375\n",
      "Train Epoch: 9 [13520/17352 (78%)] Loss: -169407.812500\n",
      "Train Epoch: 9 [13600/17352 (78%)] Loss: -220958.812500\n",
      "Train Epoch: 9 [13680/17352 (79%)] Loss: -208277.703125\n",
      "Train Epoch: 9 [13760/17352 (79%)] Loss: -176127.656250\n",
      "Train Epoch: 9 [13840/17352 (80%)] Loss: -177052.968750\n",
      "Train Epoch: 9 [13920/17352 (80%)] Loss: -160118.937500\n",
      "Train Epoch: 9 [14000/17352 (81%)] Loss: -177756.718750\n",
      "Train Epoch: 9 [14080/17352 (81%)] Loss: -176024.453125\n",
      "Train Epoch: 9 [14160/17352 (82%)] Loss: -162540.640625\n",
      "Train Epoch: 9 [14240/17352 (82%)] Loss: -188790.515625\n",
      "Train Epoch: 9 [14320/17352 (83%)] Loss: -174008.734375\n",
      "Train Epoch: 9 [14400/17352 (83%)] Loss: -217610.500000\n",
      "Train Epoch: 9 [14480/17352 (83%)] Loss: -184470.500000\n",
      "Train Epoch: 9 [14560/17352 (84%)] Loss: -178823.234375\n",
      "Train Epoch: 9 [14640/17352 (84%)] Loss: -184439.921875\n",
      "Train Epoch: 9 [14720/17352 (85%)] Loss: -190778.875000\n",
      "Train Epoch: 9 [14800/17352 (85%)] Loss: -187244.406250\n",
      "Train Epoch: 9 [14880/17352 (86%)] Loss: -200173.625000\n",
      "Train Epoch: 9 [14960/17352 (86%)] Loss: -176459.578125\n",
      "Train Epoch: 9 [15040/17352 (87%)] Loss: -200381.390625\n",
      "Train Epoch: 9 [15120/17352 (87%)] Loss: -205178.140625\n",
      "Train Epoch: 9 [15200/17352 (88%)] Loss: -192257.218750\n",
      "Train Epoch: 9 [15280/17352 (88%)] Loss: -190188.656250\n",
      "Train Epoch: 9 [15360/17352 (89%)] Loss: -175296.437500\n",
      "Train Epoch: 9 [15440/17352 (89%)] Loss: -173638.765625\n",
      "Train Epoch: 9 [15520/17352 (89%)] Loss: -161940.546875\n",
      "Train Epoch: 9 [15600/17352 (90%)] Loss: -183593.312500\n",
      "Train Epoch: 9 [15680/17352 (90%)] Loss: -206900.875000\n",
      "Train Epoch: 9 [15760/17352 (91%)] Loss: -161662.000000\n",
      "Train Epoch: 9 [15840/17352 (91%)] Loss: -199386.531250\n",
      "Train Epoch: 9 [15920/17352 (92%)] Loss: -180125.093750\n",
      "Train Epoch: 9 [16000/17352 (92%)] Loss: -167003.984375\n",
      "Train Epoch: 9 [16080/17352 (93%)] Loss: -198804.812500\n",
      "Train Epoch: 9 [16160/17352 (93%)] Loss: -188186.234375\n",
      "Train Epoch: 9 [16240/17352 (94%)] Loss: -170755.578125\n",
      "Train Epoch: 9 [16320/17352 (94%)] Loss: -181734.500000\n",
      "Train Epoch: 9 [16400/17352 (95%)] Loss: -142329.296875\n",
      "Train Epoch: 9 [16480/17352 (95%)] Loss: -188665.265625\n",
      "Train Epoch: 9 [16560/17352 (95%)] Loss: -205385.453125\n",
      "Train Epoch: 9 [16640/17352 (96%)] Loss: -179143.875000\n",
      "Train Epoch: 9 [16720/17352 (96%)] Loss: -186737.359375\n",
      "Train Epoch: 9 [16800/17352 (97%)] Loss: -187594.125000\n",
      "Train Epoch: 9 [16880/17352 (97%)] Loss: -218728.906250\n",
      "Train Epoch: 9 [16960/17352 (98%)] Loss: -178841.593750\n",
      "Train Epoch: 9 [17040/17352 (98%)] Loss: -181894.625000\n",
      "Train Epoch: 9 [17120/17352 (99%)] Loss: -158243.812500\n",
      "Train Epoch: 9 [17200/17352 (99%)] Loss: -186836.359375\n",
      "Train Epoch: 9 [17280/17352 (100%)] Loss: -180220.296875\n",
      "Train Epoch: 9 [17360/17352 (100%)] Loss: -177748.062500\n",
      "    epoch          : 9\n",
      "    loss           : -189074.37339974107\n",
      "    val_loss       : -23711.635387868388\n",
      "Train Epoch: 10 [0/17352 (0%)] Loss: -212361.312500\n",
      "Train Epoch: 10 [80/17352 (0%)] Loss: -235566.890625\n",
      "Train Epoch: 10 [160/17352 (1%)] Loss: -210336.953125\n",
      "Train Epoch: 10 [240/17352 (1%)] Loss: -194461.312500\n",
      "Train Epoch: 10 [320/17352 (2%)] Loss: -199077.765625\n",
      "Train Epoch: 10 [400/17352 (2%)] Loss: -193004.953125\n",
      "Train Epoch: 10 [480/17352 (3%)] Loss: -224229.000000\n",
      "Train Epoch: 10 [560/17352 (3%)] Loss: -211882.312500\n",
      "Train Epoch: 10 [640/17352 (4%)] Loss: -204377.656250\n",
      "Train Epoch: 10 [720/17352 (4%)] Loss: -208349.531250\n",
      "Train Epoch: 10 [800/17352 (5%)] Loss: -202296.062500\n",
      "Train Epoch: 10 [880/17352 (5%)] Loss: -214495.015625\n",
      "Train Epoch: 10 [960/17352 (6%)] Loss: -224236.000000\n",
      "Train Epoch: 10 [1040/17352 (6%)] Loss: -186043.000000\n",
      "Train Epoch: 10 [1120/17352 (6%)] Loss: -213809.718750\n",
      "Train Epoch: 10 [1200/17352 (7%)] Loss: -230177.343750\n",
      "Train Epoch: 10 [1280/17352 (7%)] Loss: -233708.531250\n",
      "Train Epoch: 10 [1360/17352 (8%)] Loss: -193676.265625\n",
      "Train Epoch: 10 [1440/17352 (8%)] Loss: -217610.156250\n",
      "Train Epoch: 10 [1520/17352 (9%)] Loss: -222979.500000\n",
      "Train Epoch: 10 [1600/17352 (9%)] Loss: -198750.093750\n",
      "Train Epoch: 10 [1680/17352 (10%)] Loss: -211065.453125\n",
      "Train Epoch: 10 [1760/17352 (10%)] Loss: -191838.015625\n",
      "Train Epoch: 10 [1840/17352 (11%)] Loss: -209751.656250\n",
      "Train Epoch: 10 [1920/17352 (11%)] Loss: -227983.968750\n",
      "Train Epoch: 10 [2000/17352 (12%)] Loss: -231319.328125\n",
      "Train Epoch: 10 [2080/17352 (12%)] Loss: -213304.171875\n",
      "Train Epoch: 10 [2160/17352 (12%)] Loss: -204721.437500\n",
      "Train Epoch: 10 [2240/17352 (13%)] Loss: -186763.140625\n",
      "Train Epoch: 10 [2320/17352 (13%)] Loss: -198518.718750\n",
      "Train Epoch: 10 [2400/17352 (14%)] Loss: -167464.281250\n",
      "Train Epoch: 10 [2480/17352 (14%)] Loss: -192867.671875\n",
      "Train Epoch: 10 [2560/17352 (15%)] Loss: -217592.546875\n",
      "Train Epoch: 10 [2640/17352 (15%)] Loss: -208102.203125\n",
      "Train Epoch: 10 [2720/17352 (16%)] Loss: -213393.328125\n",
      "Train Epoch: 10 [2800/17352 (16%)] Loss: -162530.609375\n",
      "Train Epoch: 10 [2880/17352 (17%)] Loss: -175634.109375\n",
      "Train Epoch: 10 [2960/17352 (17%)] Loss: -167069.640625\n",
      "Train Epoch: 10 [3040/17352 (18%)] Loss: -196282.000000\n",
      "Train Epoch: 10 [3120/17352 (18%)] Loss: -191029.953125\n",
      "Train Epoch: 10 [3200/17352 (18%)] Loss: -138323.968750\n",
      "Train Epoch: 10 [3280/17352 (19%)] Loss: -207763.437500\n",
      "Train Epoch: 10 [3360/17352 (19%)] Loss: -201813.390625\n",
      "Train Epoch: 10 [3440/17352 (20%)] Loss: -193480.203125\n",
      "Train Epoch: 10 [3520/17352 (20%)] Loss: -194042.468750\n",
      "Train Epoch: 10 [3600/17352 (21%)] Loss: -178357.734375\n",
      "Train Epoch: 10 [3680/17352 (21%)] Loss: -192245.468750\n",
      "Train Epoch: 10 [3760/17352 (22%)] Loss: -205492.265625\n",
      "Train Epoch: 10 [3840/17352 (22%)] Loss: -179011.390625\n",
      "Train Epoch: 10 [3920/17352 (23%)] Loss: -180221.312500\n",
      "Train Epoch: 10 [4000/17352 (23%)] Loss: -180944.796875\n",
      "Train Epoch: 10 [4080/17352 (24%)] Loss: -186528.109375\n",
      "Train Epoch: 10 [4160/17352 (24%)] Loss: -190340.578125\n",
      "Train Epoch: 10 [4240/17352 (24%)] Loss: -188657.312500\n",
      "Train Epoch: 10 [4320/17352 (25%)] Loss: -192273.750000\n",
      "Train Epoch: 10 [4400/17352 (25%)] Loss: -179423.546875\n",
      "Train Epoch: 10 [4480/17352 (26%)] Loss: -151484.906250\n",
      "Train Epoch: 10 [4560/17352 (26%)] Loss: -197053.828125\n",
      "Train Epoch: 10 [4640/17352 (27%)] Loss: -208386.187500\n",
      "Train Epoch: 10 [4720/17352 (27%)] Loss: -205191.843750\n",
      "Train Epoch: 10 [4800/17352 (28%)] Loss: -215930.062500\n",
      "Train Epoch: 10 [4880/17352 (28%)] Loss: -200056.093750\n",
      "Train Epoch: 10 [4960/17352 (29%)] Loss: -206532.609375\n",
      "Train Epoch: 10 [5040/17352 (29%)] Loss: -182717.750000\n",
      "Train Epoch: 10 [5120/17352 (30%)] Loss: -185328.406250\n",
      "Train Epoch: 10 [5200/17352 (30%)] Loss: -171570.828125\n",
      "Train Epoch: 10 [5280/17352 (30%)] Loss: -224846.562500\n",
      "Train Epoch: 10 [5360/17352 (31%)] Loss: -169736.187500\n",
      "Train Epoch: 10 [5440/17352 (31%)] Loss: -163340.156250\n",
      "Train Epoch: 10 [5520/17352 (32%)] Loss: -167194.875000\n",
      "Train Epoch: 10 [5600/17352 (32%)] Loss: -202496.890625\n",
      "Train Epoch: 10 [5680/17352 (33%)] Loss: -165774.281250\n",
      "Train Epoch: 10 [5760/17352 (33%)] Loss: -169922.734375\n",
      "Train Epoch: 10 [5840/17352 (34%)] Loss: -168063.156250\n",
      "Train Epoch: 10 [5920/17352 (34%)] Loss: -166506.718750\n",
      "Train Epoch: 10 [6000/17352 (35%)] Loss: -189515.468750\n",
      "Train Epoch: 10 [6080/17352 (35%)] Loss: -203780.875000\n",
      "Train Epoch: 10 [6160/17352 (36%)] Loss: -198787.734375\n",
      "Train Epoch: 10 [6240/17352 (36%)] Loss: -196536.343750\n",
      "Train Epoch: 10 [6320/17352 (36%)] Loss: -173643.343750\n",
      "Train Epoch: 10 [6400/17352 (37%)] Loss: -182384.421875\n",
      "Train Epoch: 10 [6480/17352 (37%)] Loss: -182085.812500\n",
      "Train Epoch: 10 [6560/17352 (38%)] Loss: -181242.593750\n",
      "Train Epoch: 10 [6640/17352 (38%)] Loss: -186491.921875\n",
      "Train Epoch: 10 [6720/17352 (39%)] Loss: -199864.046875\n",
      "Train Epoch: 10 [6800/17352 (39%)] Loss: -206222.171875\n",
      "Train Epoch: 10 [6880/17352 (40%)] Loss: -220001.687500\n",
      "Train Epoch: 10 [6960/17352 (40%)] Loss: -181907.984375\n",
      "Train Epoch: 10 [7040/17352 (41%)] Loss: -172879.328125\n",
      "Train Epoch: 10 [7120/17352 (41%)] Loss: -190931.187500\n",
      "Train Epoch: 10 [7200/17352 (41%)] Loss: -177575.875000\n",
      "Train Epoch: 10 [7280/17352 (42%)] Loss: -167855.468750\n",
      "Train Epoch: 10 [7360/17352 (42%)] Loss: -193489.234375\n",
      "Train Epoch: 10 [7440/17352 (43%)] Loss: -183586.515625\n",
      "Train Epoch: 10 [7520/17352 (43%)] Loss: -175388.812500\n",
      "Train Epoch: 10 [7600/17352 (44%)] Loss: -179713.406250\n",
      "Train Epoch: 10 [7680/17352 (44%)] Loss: -164972.984375\n",
      "Train Epoch: 10 [7760/17352 (45%)] Loss: -170282.640625\n",
      "Train Epoch: 10 [7840/17352 (45%)] Loss: -183145.031250\n",
      "Train Epoch: 10 [7920/17352 (46%)] Loss: -178624.781250\n",
      "Train Epoch: 10 [8000/17352 (46%)] Loss: -208327.218750\n",
      "Train Epoch: 10 [8080/17352 (47%)] Loss: -178306.203125\n",
      "Train Epoch: 10 [8160/17352 (47%)] Loss: -183748.687500\n",
      "Train Epoch: 10 [8240/17352 (47%)] Loss: -173937.859375\n",
      "Train Epoch: 10 [8320/17352 (48%)] Loss: -188782.109375\n",
      "Train Epoch: 10 [8400/17352 (48%)] Loss: -203398.468750\n",
      "Train Epoch: 10 [8480/17352 (49%)] Loss: -183258.312500\n",
      "Train Epoch: 10 [8560/17352 (49%)] Loss: -199044.171875\n",
      "Train Epoch: 10 [8640/17352 (50%)] Loss: -171837.125000\n",
      "Train Epoch: 10 [8720/17352 (50%)] Loss: -197359.562500\n",
      "Train Epoch: 10 [8800/17352 (51%)] Loss: -190487.609375\n",
      "Train Epoch: 10 [8880/17352 (51%)] Loss: -191811.453125\n",
      "Train Epoch: 10 [8960/17352 (52%)] Loss: -165668.359375\n",
      "Train Epoch: 10 [9040/17352 (52%)] Loss: -197284.531250\n",
      "Train Epoch: 10 [9120/17352 (53%)] Loss: -200623.484375\n",
      "Train Epoch: 10 [9200/17352 (53%)] Loss: -183691.062500\n",
      "Train Epoch: 10 [9280/17352 (53%)] Loss: -202049.875000\n",
      "Train Epoch: 10 [9360/17352 (54%)] Loss: -225445.843750\n",
      "Train Epoch: 10 [9440/17352 (54%)] Loss: -222827.625000\n",
      "Train Epoch: 10 [9520/17352 (55%)] Loss: -202178.984375\n",
      "Train Epoch: 10 [9600/17352 (55%)] Loss: -163186.500000\n",
      "Train Epoch: 10 [9680/17352 (56%)] Loss: -211679.562500\n",
      "Train Epoch: 10 [9760/17352 (56%)] Loss: -164780.296875\n",
      "Train Epoch: 10 [9840/17352 (57%)] Loss: -211128.984375\n",
      "Train Epoch: 10 [9920/17352 (57%)] Loss: -207983.890625\n",
      "Train Epoch: 10 [10000/17352 (58%)] Loss: -185913.296875\n",
      "Train Epoch: 10 [10080/17352 (58%)] Loss: -200198.031250\n",
      "Train Epoch: 10 [10160/17352 (59%)] Loss: -195033.468750\n",
      "Train Epoch: 10 [10240/17352 (59%)] Loss: -184817.093750\n",
      "Train Epoch: 10 [10320/17352 (59%)] Loss: -180486.203125\n",
      "Train Epoch: 10 [10400/17352 (60%)] Loss: -190895.046875\n",
      "Train Epoch: 10 [10480/17352 (60%)] Loss: -177170.281250\n",
      "Train Epoch: 10 [10560/17352 (61%)] Loss: -131022.953125\n",
      "Train Epoch: 10 [10640/17352 (61%)] Loss: -168179.046875\n",
      "Train Epoch: 10 [10720/17352 (62%)] Loss: -194576.781250\n",
      "Train Epoch: 10 [10800/17352 (62%)] Loss: -178297.609375\n",
      "Train Epoch: 10 [10880/17352 (63%)] Loss: -190556.156250\n",
      "Train Epoch: 10 [10960/17352 (63%)] Loss: -148419.515625\n",
      "Train Epoch: 10 [11040/17352 (64%)] Loss: -184214.218750\n",
      "Train Epoch: 10 [11120/17352 (64%)] Loss: -189718.921875\n",
      "Train Epoch: 10 [11200/17352 (65%)] Loss: -190446.484375\n",
      "Train Epoch: 10 [11280/17352 (65%)] Loss: -203458.046875\n",
      "Train Epoch: 10 [11360/17352 (65%)] Loss: -168971.609375\n",
      "Train Epoch: 10 [11440/17352 (66%)] Loss: -182668.218750\n",
      "Train Epoch: 10 [11520/17352 (66%)] Loss: -192227.593750\n",
      "Train Epoch: 10 [11600/17352 (67%)] Loss: -177577.031250\n",
      "Train Epoch: 10 [11680/17352 (67%)] Loss: -201504.312500\n",
      "Train Epoch: 10 [11760/17352 (68%)] Loss: -188469.843750\n",
      "Train Epoch: 10 [11840/17352 (68%)] Loss: -183899.375000\n",
      "Train Epoch: 10 [11920/17352 (69%)] Loss: -212880.281250\n",
      "Train Epoch: 10 [12000/17352 (69%)] Loss: -192934.171875\n",
      "Train Epoch: 10 [12080/17352 (70%)] Loss: -190213.718750\n",
      "Train Epoch: 10 [12160/17352 (70%)] Loss: -169592.734375\n",
      "Train Epoch: 10 [12240/17352 (71%)] Loss: -187928.531250\n",
      "Train Epoch: 10 [12320/17352 (71%)] Loss: -179403.484375\n",
      "Train Epoch: 10 [12400/17352 (71%)] Loss: -181911.062500\n",
      "Train Epoch: 10 [12480/17352 (72%)] Loss: -183239.421875\n",
      "Train Epoch: 10 [12560/17352 (72%)] Loss: -202144.375000\n",
      "Train Epoch: 10 [12640/17352 (73%)] Loss: -174177.812500\n",
      "Train Epoch: 10 [12720/17352 (73%)] Loss: -196808.015625\n",
      "Train Epoch: 10 [12800/17352 (74%)] Loss: -176674.531250\n",
      "Train Epoch: 10 [12880/17352 (74%)] Loss: -181963.343750\n",
      "Train Epoch: 10 [12960/17352 (75%)] Loss: -174858.125000\n",
      "Train Epoch: 10 [13040/17352 (75%)] Loss: -171415.343750\n",
      "Train Epoch: 10 [13120/17352 (76%)] Loss: -176264.281250\n",
      "Train Epoch: 10 [13200/17352 (76%)] Loss: -202219.593750\n",
      "Train Epoch: 10 [13280/17352 (77%)] Loss: -206078.687500\n",
      "Train Epoch: 10 [13360/17352 (77%)] Loss: -189790.828125\n",
      "Train Epoch: 10 [13440/17352 (77%)] Loss: -195267.093750\n",
      "Train Epoch: 10 [13520/17352 (78%)] Loss: -174004.968750\n",
      "Train Epoch: 10 [13600/17352 (78%)] Loss: -164730.562500\n",
      "Train Epoch: 10 [13680/17352 (79%)] Loss: -184720.484375\n",
      "Train Epoch: 10 [13760/17352 (79%)] Loss: -193193.093750\n",
      "Train Epoch: 10 [13840/17352 (80%)] Loss: -187476.750000\n",
      "Train Epoch: 10 [13920/17352 (80%)] Loss: -176962.390625\n",
      "Train Epoch: 10 [14000/17352 (81%)] Loss: -184448.625000\n",
      "Train Epoch: 10 [14080/17352 (81%)] Loss: -183705.953125\n",
      "Train Epoch: 10 [14160/17352 (82%)] Loss: -196119.187500\n",
      "Train Epoch: 10 [14240/17352 (82%)] Loss: -184043.500000\n",
      "Train Epoch: 10 [14320/17352 (83%)] Loss: -164815.375000\n",
      "Train Epoch: 10 [14400/17352 (83%)] Loss: -165744.640625\n",
      "Train Epoch: 10 [14480/17352 (83%)] Loss: -174136.156250\n",
      "Train Epoch: 10 [14560/17352 (84%)] Loss: -204468.609375\n",
      "Train Epoch: 10 [14640/17352 (84%)] Loss: -188994.453125\n",
      "Train Epoch: 10 [14720/17352 (85%)] Loss: -208733.875000\n",
      "Train Epoch: 10 [14800/17352 (85%)] Loss: -206208.000000\n",
      "Train Epoch: 10 [14880/17352 (86%)] Loss: -179282.234375\n",
      "Train Epoch: 10 [14960/17352 (86%)] Loss: -184738.593750\n",
      "Train Epoch: 10 [15040/17352 (87%)] Loss: -189283.578125\n",
      "Train Epoch: 10 [15120/17352 (87%)] Loss: -207812.593750\n",
      "Train Epoch: 10 [15200/17352 (88%)] Loss: -164352.875000\n",
      "Train Epoch: 10 [15280/17352 (88%)] Loss: -198532.437500\n",
      "Train Epoch: 10 [15360/17352 (89%)] Loss: -189153.843750\n",
      "Train Epoch: 10 [15440/17352 (89%)] Loss: -191538.218750\n",
      "Train Epoch: 10 [15520/17352 (89%)] Loss: -205691.656250\n",
      "Train Epoch: 10 [15600/17352 (90%)] Loss: -176905.375000\n",
      "Train Epoch: 10 [15680/17352 (90%)] Loss: -196914.000000\n",
      "Train Epoch: 10 [15760/17352 (91%)] Loss: -173003.859375\n",
      "Train Epoch: 10 [15840/17352 (91%)] Loss: -177291.453125\n",
      "Train Epoch: 10 [15920/17352 (92%)] Loss: -174600.125000\n",
      "Train Epoch: 10 [16000/17352 (92%)] Loss: -180242.140625\n",
      "Train Epoch: 10 [16080/17352 (93%)] Loss: -204636.968750\n",
      "Train Epoch: 10 [16160/17352 (93%)] Loss: -208001.687500\n",
      "Train Epoch: 10 [16240/17352 (94%)] Loss: -201362.781250\n",
      "Train Epoch: 10 [16320/17352 (94%)] Loss: -174477.937500\n",
      "Train Epoch: 10 [16400/17352 (95%)] Loss: -172162.515625\n",
      "Train Epoch: 10 [16480/17352 (95%)] Loss: -218833.890625\n",
      "Train Epoch: 10 [16560/17352 (95%)] Loss: -200978.515625\n",
      "Train Epoch: 10 [16640/17352 (96%)] Loss: -168481.750000\n",
      "Train Epoch: 10 [16720/17352 (96%)] Loss: -189558.609375\n",
      "Train Epoch: 10 [16800/17352 (97%)] Loss: -176153.531250\n",
      "Train Epoch: 10 [16880/17352 (97%)] Loss: -191604.406250\n",
      "Train Epoch: 10 [16960/17352 (98%)] Loss: -196840.187500\n",
      "Train Epoch: 10 [17040/17352 (98%)] Loss: -184983.718750\n",
      "Train Epoch: 10 [17120/17352 (99%)] Loss: -171167.109375\n",
      "Train Epoch: 10 [17200/17352 (99%)] Loss: -203120.468750\n",
      "Train Epoch: 10 [17280/17352 (100%)] Loss: -207076.015625\n",
      "Train Epoch: 10 [17360/17352 (100%)] Loss: -175392.218750\n",
      "    epoch          : 10\n",
      "    loss           : -189116.250575374\n",
      "    val_loss       : -23712.818871010077\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch10.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 11 [0/17352 (0%)] Loss: -210603.968750\n",
      "Train Epoch: 11 [80/17352 (0%)] Loss: -236604.484375\n",
      "Train Epoch: 11 [160/17352 (1%)] Loss: -216067.390625\n",
      "Train Epoch: 11 [240/17352 (1%)] Loss: -228897.531250\n",
      "Train Epoch: 11 [320/17352 (2%)] Loss: -193691.609375\n",
      "Train Epoch: 11 [400/17352 (2%)] Loss: -210343.390625\n",
      "Train Epoch: 11 [480/17352 (3%)] Loss: -214395.234375\n",
      "Train Epoch: 11 [560/17352 (3%)] Loss: -221464.656250\n",
      "Train Epoch: 11 [640/17352 (4%)] Loss: -222981.000000\n",
      "Train Epoch: 11 [720/17352 (4%)] Loss: -204501.421875\n",
      "Train Epoch: 11 [800/17352 (5%)] Loss: -210503.968750\n",
      "Train Epoch: 11 [880/17352 (5%)] Loss: -204688.921875\n",
      "Train Epoch: 11 [960/17352 (6%)] Loss: -214312.250000\n",
      "Train Epoch: 11 [1040/17352 (6%)] Loss: -215444.875000\n",
      "Train Epoch: 11 [1120/17352 (6%)] Loss: -194268.328125\n",
      "Train Epoch: 11 [1200/17352 (7%)] Loss: -217900.609375\n",
      "Train Epoch: 11 [1280/17352 (7%)] Loss: -209745.187500\n",
      "Train Epoch: 11 [1360/17352 (8%)] Loss: -224216.046875\n",
      "Train Epoch: 11 [1440/17352 (8%)] Loss: -204371.984375\n",
      "Train Epoch: 11 [1520/17352 (9%)] Loss: -205077.500000\n",
      "Train Epoch: 11 [1600/17352 (9%)] Loss: -185282.562500\n",
      "Train Epoch: 11 [1680/17352 (10%)] Loss: -230386.125000\n",
      "Train Epoch: 11 [1760/17352 (10%)] Loss: -216077.750000\n",
      "Train Epoch: 11 [1840/17352 (11%)] Loss: -222502.031250\n",
      "Train Epoch: 11 [1920/17352 (11%)] Loss: -205054.515625\n",
      "Train Epoch: 11 [2000/17352 (12%)] Loss: -206109.796875\n",
      "Train Epoch: 11 [2080/17352 (12%)] Loss: -235571.593750\n",
      "Train Epoch: 11 [2160/17352 (12%)] Loss: -212696.968750\n",
      "Train Epoch: 11 [2240/17352 (13%)] Loss: -177233.156250\n",
      "Train Epoch: 11 [2320/17352 (13%)] Loss: -194017.921875\n",
      "Train Epoch: 11 [2400/17352 (14%)] Loss: -183492.515625\n",
      "Train Epoch: 11 [2480/17352 (14%)] Loss: -181309.515625\n",
      "Train Epoch: 11 [2560/17352 (15%)] Loss: -192088.640625\n",
      "Train Epoch: 11 [2640/17352 (15%)] Loss: -183570.859375\n",
      "Train Epoch: 11 [2720/17352 (16%)] Loss: -176950.671875\n",
      "Train Epoch: 11 [2800/17352 (16%)] Loss: -177264.921875\n",
      "Train Epoch: 11 [2880/17352 (17%)] Loss: -195823.828125\n",
      "Train Epoch: 11 [2960/17352 (17%)] Loss: -204985.781250\n",
      "Train Epoch: 11 [3040/17352 (18%)] Loss: -190910.531250\n",
      "Train Epoch: 11 [3120/17352 (18%)] Loss: -193072.906250\n",
      "Train Epoch: 11 [3200/17352 (18%)] Loss: -177468.187500\n",
      "Train Epoch: 11 [3280/17352 (19%)] Loss: -191865.406250\n",
      "Train Epoch: 11 [3360/17352 (19%)] Loss: -196104.875000\n",
      "Train Epoch: 11 [3440/17352 (20%)] Loss: -202057.718750\n",
      "Train Epoch: 11 [3520/17352 (20%)] Loss: -187105.453125\n",
      "Train Epoch: 11 [3600/17352 (21%)] Loss: -167219.375000\n",
      "Train Epoch: 11 [3680/17352 (21%)] Loss: -187983.890625\n",
      "Train Epoch: 11 [3760/17352 (22%)] Loss: -181522.531250\n",
      "Train Epoch: 11 [3840/17352 (22%)] Loss: -157765.046875\n",
      "Train Epoch: 11 [3920/17352 (23%)] Loss: -173923.250000\n",
      "Train Epoch: 11 [4000/17352 (23%)] Loss: -181964.093750\n",
      "Train Epoch: 11 [4080/17352 (24%)] Loss: -188192.250000\n",
      "Train Epoch: 11 [4160/17352 (24%)] Loss: -176271.031250\n",
      "Train Epoch: 11 [4240/17352 (24%)] Loss: -177753.109375\n",
      "Train Epoch: 11 [4320/17352 (25%)] Loss: -180898.171875\n",
      "Train Epoch: 11 [4400/17352 (25%)] Loss: -192622.750000\n",
      "Train Epoch: 11 [4480/17352 (26%)] Loss: -190781.187500\n",
      "Train Epoch: 11 [4560/17352 (26%)] Loss: -148922.031250\n",
      "Train Epoch: 11 [4640/17352 (27%)] Loss: -179295.750000\n",
      "Train Epoch: 11 [4720/17352 (27%)] Loss: -174911.734375\n",
      "Train Epoch: 11 [4800/17352 (28%)] Loss: -170336.390625\n",
      "Train Epoch: 11 [4880/17352 (28%)] Loss: -198687.328125\n",
      "Train Epoch: 11 [4960/17352 (29%)] Loss: -176524.968750\n",
      "Train Epoch: 11 [5040/17352 (29%)] Loss: -206072.843750\n",
      "Train Epoch: 11 [5120/17352 (30%)] Loss: -201993.265625\n",
      "Train Epoch: 11 [5200/17352 (30%)] Loss: -186928.890625\n",
      "Train Epoch: 11 [5280/17352 (30%)] Loss: -186679.625000\n",
      "Train Epoch: 11 [5360/17352 (31%)] Loss: -181894.953125\n",
      "Train Epoch: 11 [5440/17352 (31%)] Loss: -159589.906250\n",
      "Train Epoch: 11 [5520/17352 (32%)] Loss: -148390.937500\n",
      "Train Epoch: 11 [5600/17352 (32%)] Loss: -179964.453125\n",
      "Train Epoch: 11 [5680/17352 (33%)] Loss: -231019.484375\n",
      "Train Epoch: 11 [5760/17352 (33%)] Loss: -187175.437500\n",
      "Train Epoch: 11 [5840/17352 (34%)] Loss: -188462.859375\n",
      "Train Epoch: 11 [5920/17352 (34%)] Loss: -187345.125000\n",
      "Train Epoch: 11 [6000/17352 (35%)] Loss: -159673.046875\n",
      "Train Epoch: 11 [6080/17352 (35%)] Loss: -173651.484375\n",
      "Train Epoch: 11 [6160/17352 (36%)] Loss: -156594.953125\n",
      "Train Epoch: 11 [6240/17352 (36%)] Loss: -153320.343750\n",
      "Train Epoch: 11 [6320/17352 (36%)] Loss: -165574.625000\n",
      "Train Epoch: 11 [6400/17352 (37%)] Loss: -197576.015625\n",
      "Train Epoch: 11 [6480/17352 (37%)] Loss: -216367.109375\n",
      "Train Epoch: 11 [6560/17352 (38%)] Loss: -168034.875000\n",
      "Train Epoch: 11 [6640/17352 (38%)] Loss: -190209.718750\n",
      "Train Epoch: 11 [6720/17352 (39%)] Loss: -178106.000000\n",
      "Train Epoch: 11 [6800/17352 (39%)] Loss: -185019.546875\n",
      "Train Epoch: 11 [6880/17352 (40%)] Loss: -228137.500000\n",
      "Train Epoch: 11 [6960/17352 (40%)] Loss: -172524.500000\n",
      "Train Epoch: 11 [7040/17352 (41%)] Loss: -148495.484375\n",
      "Train Epoch: 11 [7120/17352 (41%)] Loss: -178582.859375\n",
      "Train Epoch: 11 [7200/17352 (41%)] Loss: -179385.109375\n",
      "Train Epoch: 11 [7280/17352 (42%)] Loss: -200067.578125\n",
      "Train Epoch: 11 [7360/17352 (42%)] Loss: -214930.000000\n",
      "Train Epoch: 11 [7440/17352 (43%)] Loss: -164867.046875\n",
      "Train Epoch: 11 [7520/17352 (43%)] Loss: -174169.156250\n",
      "Train Epoch: 11 [7600/17352 (44%)] Loss: -164735.421875\n",
      "Train Epoch: 11 [7680/17352 (44%)] Loss: -191996.015625\n",
      "Train Epoch: 11 [7760/17352 (45%)] Loss: -202977.437500\n",
      "Train Epoch: 11 [7840/17352 (45%)] Loss: -182724.281250\n",
      "Train Epoch: 11 [7920/17352 (46%)] Loss: -167858.015625\n",
      "Train Epoch: 11 [8000/17352 (46%)] Loss: -195803.937500\n",
      "Train Epoch: 11 [8080/17352 (47%)] Loss: -182662.609375\n",
      "Train Epoch: 11 [8160/17352 (47%)] Loss: -185346.203125\n",
      "Train Epoch: 11 [8240/17352 (47%)] Loss: -184743.468750\n",
      "Train Epoch: 11 [8320/17352 (48%)] Loss: -203856.468750\n",
      "Train Epoch: 11 [8400/17352 (48%)] Loss: -176667.812500\n",
      "Train Epoch: 11 [8480/17352 (49%)] Loss: -172943.406250\n",
      "Train Epoch: 11 [8560/17352 (49%)] Loss: -201296.234375\n",
      "Train Epoch: 11 [8640/17352 (50%)] Loss: -171293.937500\n",
      "Train Epoch: 11 [8720/17352 (50%)] Loss: -204313.796875\n",
      "Train Epoch: 11 [8800/17352 (51%)] Loss: -192710.234375\n",
      "Train Epoch: 11 [8880/17352 (51%)] Loss: -182747.859375\n",
      "Train Epoch: 11 [8960/17352 (52%)] Loss: -206903.640625\n",
      "Train Epoch: 11 [9040/17352 (52%)] Loss: -204921.421875\n",
      "Train Epoch: 11 [9120/17352 (53%)] Loss: -161661.296875\n",
      "Train Epoch: 11 [9200/17352 (53%)] Loss: -203787.625000\n",
      "Train Epoch: 11 [9280/17352 (53%)] Loss: -185252.671875\n",
      "Train Epoch: 11 [9360/17352 (54%)] Loss: -215442.187500\n",
      "Train Epoch: 11 [9440/17352 (54%)] Loss: -177071.453125\n",
      "Train Epoch: 11 [9520/17352 (55%)] Loss: -185525.046875\n",
      "Train Epoch: 11 [9600/17352 (55%)] Loss: -199775.250000\n",
      "Train Epoch: 11 [9680/17352 (56%)] Loss: -166775.531250\n",
      "Train Epoch: 11 [9760/17352 (56%)] Loss: -200856.343750\n",
      "Train Epoch: 11 [9840/17352 (57%)] Loss: -194917.750000\n",
      "Train Epoch: 11 [9920/17352 (57%)] Loss: -189192.968750\n",
      "Train Epoch: 11 [10000/17352 (58%)] Loss: -200203.187500\n",
      "Train Epoch: 11 [10080/17352 (58%)] Loss: -214653.000000\n",
      "Train Epoch: 11 [10160/17352 (59%)] Loss: -164813.093750\n",
      "Train Epoch: 11 [10240/17352 (59%)] Loss: -167858.796875\n",
      "Train Epoch: 11 [10320/17352 (59%)] Loss: -176259.046875\n",
      "Train Epoch: 11 [10400/17352 (60%)] Loss: -156983.421875\n",
      "Train Epoch: 11 [10480/17352 (60%)] Loss: -160031.453125\n",
      "Train Epoch: 11 [10560/17352 (61%)] Loss: -197088.609375\n",
      "Train Epoch: 11 [10640/17352 (61%)] Loss: -165843.125000\n",
      "Train Epoch: 11 [10720/17352 (62%)] Loss: -214732.484375\n",
      "Train Epoch: 11 [10800/17352 (62%)] Loss: -178557.218750\n",
      "Train Epoch: 11 [10880/17352 (63%)] Loss: -163093.390625\n",
      "Train Epoch: 11 [10960/17352 (63%)] Loss: -172984.203125\n",
      "Train Epoch: 11 [11040/17352 (64%)] Loss: -200267.671875\n",
      "Train Epoch: 11 [11120/17352 (64%)] Loss: -167170.187500\n",
      "Train Epoch: 11 [11200/17352 (65%)] Loss: -131031.843750\n",
      "Train Epoch: 11 [11280/17352 (65%)] Loss: -189278.281250\n",
      "Train Epoch: 11 [11360/17352 (65%)] Loss: -169172.500000\n",
      "Train Epoch: 11 [11440/17352 (66%)] Loss: -172531.968750\n",
      "Train Epoch: 11 [11520/17352 (66%)] Loss: -196267.359375\n",
      "Train Epoch: 11 [11600/17352 (67%)] Loss: -212126.515625\n",
      "Train Epoch: 11 [11680/17352 (67%)] Loss: -167018.453125\n",
      "Train Epoch: 11 [11760/17352 (68%)] Loss: -177123.796875\n",
      "Train Epoch: 11 [11840/17352 (68%)] Loss: -176559.234375\n",
      "Train Epoch: 11 [11920/17352 (69%)] Loss: -176131.046875\n",
      "Train Epoch: 11 [12000/17352 (69%)] Loss: -206208.250000\n",
      "Train Epoch: 11 [12080/17352 (70%)] Loss: -173495.890625\n",
      "Train Epoch: 11 [12160/17352 (70%)] Loss: -200453.312500\n",
      "Train Epoch: 11 [12240/17352 (71%)] Loss: -179436.406250\n",
      "Train Epoch: 11 [12320/17352 (71%)] Loss: -166985.765625\n",
      "Train Epoch: 11 [12400/17352 (71%)] Loss: -201362.281250\n",
      "Train Epoch: 11 [12480/17352 (72%)] Loss: -183907.000000\n",
      "Train Epoch: 11 [12560/17352 (72%)] Loss: -199884.921875\n",
      "Train Epoch: 11 [12640/17352 (73%)] Loss: -166016.937500\n",
      "Train Epoch: 11 [12720/17352 (73%)] Loss: -200813.515625\n",
      "Train Epoch: 11 [12800/17352 (74%)] Loss: -187299.421875\n",
      "Train Epoch: 11 [12880/17352 (74%)] Loss: -203496.171875\n",
      "Train Epoch: 11 [12960/17352 (75%)] Loss: -190773.281250\n",
      "Train Epoch: 11 [13040/17352 (75%)] Loss: -180516.890625\n",
      "Train Epoch: 11 [13120/17352 (76%)] Loss: -176154.734375\n",
      "Train Epoch: 11 [13200/17352 (76%)] Loss: -197934.875000\n",
      "Train Epoch: 11 [13280/17352 (77%)] Loss: -170669.328125\n",
      "Train Epoch: 11 [13360/17352 (77%)] Loss: -184975.984375\n",
      "Train Epoch: 11 [13440/17352 (77%)] Loss: -186027.218750\n",
      "Train Epoch: 11 [13520/17352 (78%)] Loss: -192243.718750\n",
      "Train Epoch: 11 [13600/17352 (78%)] Loss: -188233.765625\n",
      "Train Epoch: 11 [13680/17352 (79%)] Loss: -185377.406250\n",
      "Train Epoch: 11 [13760/17352 (79%)] Loss: -142594.328125\n",
      "Train Epoch: 11 [13840/17352 (80%)] Loss: -185213.828125\n",
      "Train Epoch: 11 [13920/17352 (80%)] Loss: -186029.734375\n",
      "Train Epoch: 11 [14000/17352 (81%)] Loss: -178714.250000\n",
      "Train Epoch: 11 [14080/17352 (81%)] Loss: -192929.468750\n",
      "Train Epoch: 11 [14160/17352 (82%)] Loss: -165364.015625\n",
      "Train Epoch: 11 [14240/17352 (82%)] Loss: -209267.750000\n",
      "Train Epoch: 11 [14320/17352 (83%)] Loss: -209244.343750\n",
      "Train Epoch: 11 [14400/17352 (83%)] Loss: -185500.343750\n",
      "Train Epoch: 11 [14480/17352 (83%)] Loss: -193145.000000\n",
      "Train Epoch: 11 [14560/17352 (84%)] Loss: -187430.140625\n",
      "Train Epoch: 11 [14640/17352 (84%)] Loss: -202777.281250\n",
      "Train Epoch: 11 [14720/17352 (85%)] Loss: -219908.281250\n",
      "Train Epoch: 11 [14800/17352 (85%)] Loss: -178360.718750\n",
      "Train Epoch: 11 [14880/17352 (86%)] Loss: -177142.265625\n",
      "Train Epoch: 11 [14960/17352 (86%)] Loss: -210535.468750\n",
      "Train Epoch: 11 [15040/17352 (87%)] Loss: -194209.046875\n",
      "Train Epoch: 11 [15120/17352 (87%)] Loss: -185809.453125\n",
      "Train Epoch: 11 [15200/17352 (88%)] Loss: -187238.203125\n",
      "Train Epoch: 11 [15280/17352 (88%)] Loss: -189521.796875\n",
      "Train Epoch: 11 [15360/17352 (89%)] Loss: -181648.562500\n",
      "Train Epoch: 11 [15440/17352 (89%)] Loss: -152899.890625\n",
      "Train Epoch: 11 [15520/17352 (89%)] Loss: -172212.890625\n",
      "Train Epoch: 11 [15600/17352 (90%)] Loss: -181680.968750\n",
      "Train Epoch: 11 [15680/17352 (90%)] Loss: -207995.156250\n",
      "Train Epoch: 11 [15760/17352 (91%)] Loss: -181884.406250\n",
      "Train Epoch: 11 [15840/17352 (91%)] Loss: -149023.046875\n",
      "Train Epoch: 11 [15920/17352 (92%)] Loss: -172876.281250\n",
      "Train Epoch: 11 [16000/17352 (92%)] Loss: -182315.515625\n",
      "Train Epoch: 11 [16080/17352 (93%)] Loss: -180996.250000\n",
      "Train Epoch: 11 [16160/17352 (93%)] Loss: -146836.687500\n",
      "Train Epoch: 11 [16240/17352 (94%)] Loss: -182539.500000\n",
      "Train Epoch: 11 [16320/17352 (94%)] Loss: -177968.281250\n",
      "Train Epoch: 11 [16400/17352 (95%)] Loss: -205790.484375\n",
      "Train Epoch: 11 [16480/17352 (95%)] Loss: -205382.781250\n",
      "Train Epoch: 11 [16560/17352 (95%)] Loss: -207077.093750\n",
      "Train Epoch: 11 [16640/17352 (96%)] Loss: -215638.546875\n",
      "Train Epoch: 11 [16720/17352 (96%)] Loss: -151197.484375\n",
      "Train Epoch: 11 [16800/17352 (97%)] Loss: -183858.125000\n",
      "Train Epoch: 11 [16880/17352 (97%)] Loss: -192938.453125\n",
      "Train Epoch: 11 [16960/17352 (98%)] Loss: -219991.406250\n",
      "Train Epoch: 11 [17040/17352 (98%)] Loss: -174704.406250\n",
      "Train Epoch: 11 [17120/17352 (99%)] Loss: -180808.437500\n",
      "Train Epoch: 11 [17200/17352 (99%)] Loss: -177295.781250\n",
      "Train Epoch: 11 [17280/17352 (100%)] Loss: -178770.093750\n",
      "Train Epoch: 11 [17360/17352 (100%)] Loss: -196183.828125\n",
      "    epoch          : 11\n",
      "    loss           : -189150.918791355\n",
      "    val_loss       : -23712.914202837877\n",
      "Train Epoch: 12 [0/17352 (0%)] Loss: -204370.968750\n",
      "Train Epoch: 12 [80/17352 (0%)] Loss: -222495.890625\n",
      "Train Epoch: 12 [160/17352 (1%)] Loss: -204714.000000\n",
      "Train Epoch: 12 [240/17352 (1%)] Loss: -201990.046875\n",
      "Train Epoch: 12 [320/17352 (2%)] Loss: -219204.515625\n",
      "Train Epoch: 12 [400/17352 (2%)] Loss: -214505.781250\n",
      "Train Epoch: 12 [480/17352 (3%)] Loss: -182762.671875\n",
      "Train Epoch: 12 [560/17352 (3%)] Loss: -227996.437500\n",
      "Train Epoch: 12 [640/17352 (4%)] Loss: -199776.812500\n",
      "Train Epoch: 12 [720/17352 (4%)] Loss: -199867.921875\n",
      "Train Epoch: 12 [800/17352 (5%)] Loss: -212681.687500\n",
      "Train Epoch: 12 [880/17352 (5%)] Loss: -214402.359375\n",
      "Train Epoch: 12 [960/17352 (6%)] Loss: -206639.109375\n",
      "Train Epoch: 12 [1040/17352 (6%)] Loss: -211875.625000\n",
      "Train Epoch: 12 [1120/17352 (6%)] Loss: -210736.406250\n",
      "Train Epoch: 12 [1200/17352 (7%)] Loss: -194246.875000\n",
      "Train Epoch: 12 [1280/17352 (7%)] Loss: -196902.343750\n",
      "Train Epoch: 12 [1360/17352 (8%)] Loss: -198090.859375\n",
      "Train Epoch: 12 [1440/17352 (8%)] Loss: -211076.515625\n",
      "Train Epoch: 12 [1520/17352 (9%)] Loss: -209624.562500\n",
      "Train Epoch: 12 [1600/17352 (9%)] Loss: -199903.250000\n",
      "Train Epoch: 12 [1680/17352 (10%)] Loss: -212232.421875\n",
      "Train Epoch: 12 [1760/17352 (10%)] Loss: -224228.343750\n",
      "Train Epoch: 12 [1840/17352 (11%)] Loss: -224230.453125\n",
      "Train Epoch: 12 [1920/17352 (11%)] Loss: -205188.546875\n",
      "Train Epoch: 12 [2000/17352 (12%)] Loss: -210504.062500\n",
      "Train Epoch: 12 [2080/17352 (12%)] Loss: -199092.062500\n",
      "Train Epoch: 12 [2160/17352 (12%)] Loss: -201630.562500\n",
      "Train Epoch: 12 [2240/17352 (13%)] Loss: -152714.640625\n",
      "Train Epoch: 12 [2320/17352 (13%)] Loss: -189493.062500\n",
      "Train Epoch: 12 [2400/17352 (14%)] Loss: -212108.625000\n",
      "Train Epoch: 12 [2480/17352 (14%)] Loss: -197627.046875\n",
      "Train Epoch: 12 [2560/17352 (15%)] Loss: -178851.000000\n",
      "Train Epoch: 12 [2640/17352 (15%)] Loss: -163534.687500\n",
      "Train Epoch: 12 [2720/17352 (16%)] Loss: -168493.656250\n",
      "Train Epoch: 12 [2800/17352 (16%)] Loss: -218499.656250\n",
      "Train Epoch: 12 [2880/17352 (17%)] Loss: -194973.750000\n",
      "Train Epoch: 12 [2960/17352 (17%)] Loss: -175661.109375\n",
      "Train Epoch: 12 [3040/17352 (18%)] Loss: -183937.828125\n",
      "Train Epoch: 12 [3120/17352 (18%)] Loss: -167241.187500\n",
      "Train Epoch: 12 [3200/17352 (18%)] Loss: -164669.343750\n",
      "Train Epoch: 12 [3280/17352 (19%)] Loss: -210370.703125\n",
      "Train Epoch: 12 [3360/17352 (19%)] Loss: -163941.093750\n",
      "Train Epoch: 12 [3440/17352 (20%)] Loss: -183260.328125\n",
      "Train Epoch: 12 [3520/17352 (20%)] Loss: -197504.265625\n",
      "Train Epoch: 12 [3600/17352 (21%)] Loss: -166636.640625\n",
      "Train Epoch: 12 [3680/17352 (21%)] Loss: -199696.359375\n",
      "Train Epoch: 12 [3760/17352 (22%)] Loss: -178807.984375\n",
      "Train Epoch: 12 [3840/17352 (22%)] Loss: -187292.875000\n",
      "Train Epoch: 12 [3920/17352 (23%)] Loss: -187508.046875\n",
      "Train Epoch: 12 [4000/17352 (23%)] Loss: -187309.250000\n",
      "Train Epoch: 12 [4080/17352 (24%)] Loss: -190226.812500\n",
      "Train Epoch: 12 [4160/17352 (24%)] Loss: -202511.218750\n",
      "Train Epoch: 12 [4240/17352 (24%)] Loss: -208771.484375\n",
      "Train Epoch: 12 [4320/17352 (25%)] Loss: -181727.890625\n",
      "Train Epoch: 12 [4400/17352 (25%)] Loss: -179305.000000\n",
      "Train Epoch: 12 [4480/17352 (26%)] Loss: -173292.531250\n",
      "Train Epoch: 12 [4560/17352 (26%)] Loss: -202572.500000\n",
      "Train Epoch: 12 [4640/17352 (27%)] Loss: -196276.140625\n",
      "Train Epoch: 12 [4720/17352 (27%)] Loss: -165345.984375\n",
      "Train Epoch: 12 [4800/17352 (28%)] Loss: -208331.640625\n",
      "Train Epoch: 12 [4880/17352 (28%)] Loss: -193176.250000\n",
      "Train Epoch: 12 [4960/17352 (29%)] Loss: -187264.312500\n",
      "Train Epoch: 12 [5040/17352 (29%)] Loss: -157761.265625\n",
      "Train Epoch: 12 [5120/17352 (30%)] Loss: -164929.781250\n",
      "Train Epoch: 12 [5200/17352 (30%)] Loss: -160073.875000\n",
      "Train Epoch: 12 [5280/17352 (30%)] Loss: -188024.046875\n",
      "Train Epoch: 12 [5360/17352 (31%)] Loss: -191485.000000\n",
      "Train Epoch: 12 [5440/17352 (31%)] Loss: -223665.531250\n",
      "Train Epoch: 12 [5520/17352 (32%)] Loss: -177252.406250\n",
      "Train Epoch: 12 [5600/17352 (32%)] Loss: -188737.890625\n",
      "Train Epoch: 12 [5680/17352 (33%)] Loss: -208703.015625\n",
      "Train Epoch: 12 [5760/17352 (33%)] Loss: -191946.078125\n",
      "Train Epoch: 12 [5840/17352 (34%)] Loss: -225304.406250\n",
      "Train Epoch: 12 [5920/17352 (34%)] Loss: -184808.390625\n",
      "Train Epoch: 12 [6000/17352 (35%)] Loss: -189006.031250\n",
      "Train Epoch: 12 [6080/17352 (35%)] Loss: -185214.203125\n",
      "Train Epoch: 12 [6160/17352 (36%)] Loss: -192938.843750\n",
      "Train Epoch: 12 [6240/17352 (36%)] Loss: -177183.000000\n",
      "Train Epoch: 12 [6320/17352 (36%)] Loss: -191937.375000\n",
      "Train Epoch: 12 [6400/17352 (37%)] Loss: -203803.531250\n",
      "Train Epoch: 12 [6480/17352 (37%)] Loss: -179909.171875\n",
      "Train Epoch: 12 [6560/17352 (38%)] Loss: -190466.515625\n",
      "Train Epoch: 12 [6640/17352 (38%)] Loss: -209565.218750\n",
      "Train Epoch: 12 [6720/17352 (39%)] Loss: -178581.093750\n",
      "Train Epoch: 12 [6800/17352 (39%)] Loss: -192961.421875\n",
      "Train Epoch: 12 [6880/17352 (40%)] Loss: -181732.546875\n",
      "Train Epoch: 12 [6960/17352 (40%)] Loss: -174919.546875\n",
      "Train Epoch: 12 [7040/17352 (41%)] Loss: -179877.031250\n",
      "Train Epoch: 12 [7120/17352 (41%)] Loss: -201301.062500\n",
      "Train Epoch: 12 [7200/17352 (41%)] Loss: -175480.062500\n",
      "Train Epoch: 12 [7280/17352 (42%)] Loss: -166428.843750\n",
      "Train Epoch: 12 [7360/17352 (42%)] Loss: -202841.750000\n",
      "Train Epoch: 12 [7440/17352 (43%)] Loss: -178787.609375\n",
      "Train Epoch: 12 [7520/17352 (43%)] Loss: -205201.968750\n",
      "Train Epoch: 12 [7600/17352 (44%)] Loss: -164480.859375\n",
      "Train Epoch: 12 [7680/17352 (44%)] Loss: -192091.078125\n",
      "Train Epoch: 12 [7760/17352 (45%)] Loss: -180232.703125\n",
      "Train Epoch: 12 [7840/17352 (45%)] Loss: -196917.359375\n",
      "Train Epoch: 12 [7920/17352 (46%)] Loss: -168047.640625\n",
      "Train Epoch: 12 [8000/17352 (46%)] Loss: -188547.859375\n",
      "Train Epoch: 12 [8080/17352 (47%)] Loss: -196426.937500\n",
      "Train Epoch: 12 [8160/17352 (47%)] Loss: -176678.156250\n",
      "Train Epoch: 12 [8240/17352 (47%)] Loss: -181945.968750\n",
      "Train Epoch: 12 [8320/17352 (48%)] Loss: -185255.937500\n",
      "Train Epoch: 12 [8400/17352 (48%)] Loss: -165863.625000\n",
      "Train Epoch: 12 [8480/17352 (49%)] Loss: -177295.390625\n",
      "Train Epoch: 12 [8560/17352 (49%)] Loss: -147404.187500\n",
      "Train Epoch: 12 [8640/17352 (50%)] Loss: -177086.609375\n",
      "Train Epoch: 12 [8720/17352 (50%)] Loss: -169930.937500\n",
      "Train Epoch: 12 [8800/17352 (51%)] Loss: -196270.031250\n",
      "Train Epoch: 12 [8880/17352 (51%)] Loss: -159669.281250\n",
      "Train Epoch: 12 [8960/17352 (52%)] Loss: -179666.046875\n",
      "Train Epoch: 12 [9040/17352 (52%)] Loss: -184437.703125\n",
      "Train Epoch: 12 [9120/17352 (53%)] Loss: -136423.296875\n",
      "Train Epoch: 12 [9200/17352 (53%)] Loss: -179387.125000\n",
      "Train Epoch: 12 [9280/17352 (53%)] Loss: -205487.156250\n",
      "Train Epoch: 12 [9360/17352 (54%)] Loss: -158725.453125\n",
      "Train Epoch: 12 [9440/17352 (54%)] Loss: -167770.015625\n",
      "Train Epoch: 12 [9520/17352 (55%)] Loss: -197071.687500\n",
      "Train Epoch: 12 [9600/17352 (55%)] Loss: -172593.687500\n",
      "Train Epoch: 12 [9680/17352 (56%)] Loss: -185485.859375\n",
      "Train Epoch: 12 [9760/17352 (56%)] Loss: -199114.937500\n",
      "Train Epoch: 12 [9840/17352 (57%)] Loss: -186702.609375\n",
      "Train Epoch: 12 [9920/17352 (57%)] Loss: -190368.718750\n",
      "Train Epoch: 12 [10000/17352 (58%)] Loss: -194563.890625\n",
      "Train Epoch: 12 [10080/17352 (58%)] Loss: -170773.531250\n",
      "Train Epoch: 12 [10160/17352 (59%)] Loss: -179443.859375\n",
      "Train Epoch: 12 [10240/17352 (59%)] Loss: -187611.593750\n",
      "Train Epoch: 12 [10320/17352 (59%)] Loss: -223931.937500\n",
      "Train Epoch: 12 [10400/17352 (60%)] Loss: -169151.328125\n",
      "Train Epoch: 12 [10480/17352 (60%)] Loss: -228133.625000\n",
      "Train Epoch: 12 [10560/17352 (61%)] Loss: -219995.781250\n",
      "Train Epoch: 12 [10640/17352 (61%)] Loss: -166005.328125\n",
      "Train Epoch: 12 [10720/17352 (62%)] Loss: -161667.234375\n",
      "Train Epoch: 12 [10800/17352 (62%)] Loss: -188421.390625\n",
      "Train Epoch: 12 [10880/17352 (63%)] Loss: -187868.046875\n",
      "Train Epoch: 12 [10960/17352 (63%)] Loss: -197938.859375\n",
      "Train Epoch: 12 [11040/17352 (64%)] Loss: -194052.359375\n",
      "Train Epoch: 12 [11120/17352 (64%)] Loss: -172533.093750\n",
      "Train Epoch: 12 [11200/17352 (65%)] Loss: -203824.609375\n",
      "Train Epoch: 12 [11280/17352 (65%)] Loss: -209877.468750\n",
      "Train Epoch: 12 [11360/17352 (65%)] Loss: -183025.343750\n",
      "Train Epoch: 12 [11440/17352 (66%)] Loss: -197996.968750\n",
      "Train Epoch: 12 [11520/17352 (66%)] Loss: -185913.203125\n",
      "Train Epoch: 12 [11600/17352 (67%)] Loss: -202769.281250\n",
      "Train Epoch: 12 [11680/17352 (67%)] Loss: -200974.671875\n",
      "Train Epoch: 12 [11760/17352 (68%)] Loss: -176874.781250\n",
      "Train Epoch: 12 [11840/17352 (68%)] Loss: -171296.703125\n",
      "Train Epoch: 12 [11920/17352 (69%)] Loss: -190199.437500\n",
      "Train Epoch: 12 [12000/17352 (69%)] Loss: -177605.921875\n",
      "Train Epoch: 12 [12080/17352 (70%)] Loss: -129668.046875\n",
      "Train Epoch: 12 [12160/17352 (70%)] Loss: -163096.750000\n",
      "Train Epoch: 12 [12240/17352 (71%)] Loss: -192103.250000\n",
      "Train Epoch: 12 [12320/17352 (71%)] Loss: -182733.609375\n",
      "Train Epoch: 12 [12400/17352 (71%)] Loss: -218734.203125\n",
      "Train Epoch: 12 [12480/17352 (72%)] Loss: -185827.921875\n",
      "Train Epoch: 12 [12560/17352 (72%)] Loss: -181359.921875\n",
      "Train Epoch: 12 [12640/17352 (73%)] Loss: -196799.968750\n",
      "Train Epoch: 12 [12720/17352 (73%)] Loss: -177978.218750\n",
      "Train Epoch: 12 [12800/17352 (74%)] Loss: -172175.578125\n",
      "Train Epoch: 12 [12880/17352 (74%)] Loss: -178655.171875\n",
      "Train Epoch: 12 [12960/17352 (75%)] Loss: -190791.937500\n",
      "Train Epoch: 12 [13040/17352 (75%)] Loss: -178862.484375\n",
      "Train Epoch: 12 [13120/17352 (76%)] Loss: -193498.500000\n",
      "Train Epoch: 12 [13200/17352 (76%)] Loss: -176124.921875\n",
      "Train Epoch: 12 [13280/17352 (77%)] Loss: -196170.406250\n",
      "Train Epoch: 12 [13360/17352 (77%)] Loss: -168945.953125\n",
      "Train Epoch: 12 [13440/17352 (77%)] Loss: -187430.234375\n",
      "Train Epoch: 12 [13520/17352 (78%)] Loss: -204312.375000\n",
      "Train Epoch: 12 [13600/17352 (78%)] Loss: -195813.203125\n",
      "Train Epoch: 12 [13680/17352 (79%)] Loss: -163200.093750\n",
      "Train Epoch: 12 [13760/17352 (79%)] Loss: -192937.109375\n",
      "Train Epoch: 12 [13840/17352 (80%)] Loss: -214671.062500\n",
      "Train Epoch: 12 [13920/17352 (80%)] Loss: -201914.062500\n",
      "Train Epoch: 12 [14000/17352 (81%)] Loss: -192152.312500\n",
      "Train Epoch: 12 [14080/17352 (81%)] Loss: -199431.812500\n",
      "Train Epoch: 12 [14160/17352 (82%)] Loss: -159082.359375\n",
      "Train Epoch: 12 [14240/17352 (82%)] Loss: -191294.671875\n",
      "Train Epoch: 12 [14320/17352 (83%)] Loss: -193892.609375\n",
      "Train Epoch: 12 [14400/17352 (83%)] Loss: -171179.437500\n",
      "Train Epoch: 12 [14480/17352 (83%)] Loss: -203653.859375\n",
      "Train Epoch: 12 [14560/17352 (84%)] Loss: -200205.671875\n",
      "Train Epoch: 12 [14640/17352 (84%)] Loss: -204978.765625\n",
      "Train Epoch: 12 [14720/17352 (85%)] Loss: -171832.359375\n",
      "Train Epoch: 12 [14800/17352 (85%)] Loss: -196135.875000\n",
      "Train Epoch: 12 [14880/17352 (86%)] Loss: -192663.015625\n",
      "Train Epoch: 12 [14960/17352 (86%)] Loss: -197539.687500\n",
      "Train Epoch: 12 [15040/17352 (87%)] Loss: -221232.906250\n",
      "Train Epoch: 12 [15120/17352 (87%)] Loss: -166650.781250\n",
      "Train Epoch: 12 [15200/17352 (88%)] Loss: -181315.671875\n",
      "Train Epoch: 12 [15280/17352 (88%)] Loss: -189296.156250\n",
      "Train Epoch: 12 [15360/17352 (89%)] Loss: -180132.062500\n",
      "Train Epoch: 12 [15440/17352 (89%)] Loss: -200176.875000\n",
      "Train Epoch: 12 [15520/17352 (89%)] Loss: -189574.578125\n",
      "Train Epoch: 12 [15600/17352 (90%)] Loss: -186008.515625\n",
      "Train Epoch: 12 [15680/17352 (90%)] Loss: -199576.765625\n",
      "Train Epoch: 12 [15760/17352 (91%)] Loss: -200854.843750\n",
      "Train Epoch: 12 [15840/17352 (91%)] Loss: -185282.468750\n",
      "Train Epoch: 12 [15920/17352 (92%)] Loss: -206575.750000\n",
      "Train Epoch: 12 [16000/17352 (92%)] Loss: -176266.406250\n",
      "Train Epoch: 12 [16080/17352 (93%)] Loss: -178357.781250\n",
      "Train Epoch: 12 [16160/17352 (93%)] Loss: -177216.156250\n",
      "Train Epoch: 12 [16240/17352 (94%)] Loss: -188173.468750\n",
      "Train Epoch: 12 [16320/17352 (94%)] Loss: -164811.312500\n",
      "Train Epoch: 12 [16400/17352 (95%)] Loss: -215398.468750\n",
      "Train Epoch: 12 [16480/17352 (95%)] Loss: -169484.968750\n",
      "Train Epoch: 12 [16560/17352 (95%)] Loss: -184826.078125\n",
      "Train Epoch: 12 [16640/17352 (96%)] Loss: -197084.093750\n",
      "Train Epoch: 12 [16720/17352 (96%)] Loss: -197584.921875\n",
      "Train Epoch: 12 [16800/17352 (97%)] Loss: -200824.343750\n",
      "Train Epoch: 12 [16880/17352 (97%)] Loss: -162945.046875\n",
      "Train Epoch: 12 [16960/17352 (98%)] Loss: -183895.234375\n",
      "Train Epoch: 12 [17040/17352 (98%)] Loss: -207820.531250\n",
      "Train Epoch: 12 [17120/17352 (99%)] Loss: -180505.562500\n",
      "Train Epoch: 12 [17200/17352 (99%)] Loss: -208893.406250\n",
      "Train Epoch: 12 [17280/17352 (100%)] Loss: -186484.328125\n",
      "Train Epoch: 12 [17360/17352 (100%)] Loss: -179361.953125\n",
      "    epoch          : 12\n",
      "    loss           : -188939.43411068758\n",
      "    val_loss       : -23713.71355334358\n",
      "Train Epoch: 13 [0/17352 (0%)] Loss: -193393.937500\n",
      "Train Epoch: 13 [80/17352 (0%)] Loss: -236493.828125\n",
      "Train Epoch: 13 [160/17352 (1%)] Loss: -193559.531250\n",
      "Train Epoch: 13 [240/17352 (1%)] Loss: -229225.921875\n",
      "Train Epoch: 13 [320/17352 (2%)] Loss: -222496.687500\n",
      "Train Epoch: 13 [400/17352 (2%)] Loss: -205897.921875\n",
      "Train Epoch: 13 [480/17352 (3%)] Loss: -198097.578125\n",
      "Train Epoch: 13 [560/17352 (3%)] Loss: -217908.468750\n",
      "Train Epoch: 13 [640/17352 (4%)] Loss: -205536.703125\n",
      "Train Epoch: 13 [720/17352 (4%)] Loss: -206541.203125\n",
      "Train Epoch: 13 [800/17352 (5%)] Loss: -236811.953125\n",
      "Train Epoch: 13 [880/17352 (5%)] Loss: -196418.046875\n",
      "Train Epoch: 13 [960/17352 (6%)] Loss: -233723.140625\n",
      "Train Epoch: 13 [1040/17352 (6%)] Loss: -215813.484375\n",
      "Train Epoch: 13 [1120/17352 (6%)] Loss: -204379.531250\n",
      "Train Epoch: 13 [1200/17352 (7%)] Loss: -219636.109375\n",
      "Train Epoch: 13 [1280/17352 (7%)] Loss: -230155.500000\n",
      "Train Epoch: 13 [1360/17352 (8%)] Loss: -210189.515625\n",
      "Train Epoch: 13 [1440/17352 (8%)] Loss: -185275.906250\n",
      "Train Epoch: 13 [1520/17352 (9%)] Loss: -199883.281250\n",
      "Train Epoch: 13 [1600/17352 (9%)] Loss: -230380.453125\n",
      "Train Epoch: 13 [1680/17352 (10%)] Loss: -222977.234375\n",
      "Train Epoch: 13 [1760/17352 (10%)] Loss: -211080.406250\n",
      "Train Epoch: 13 [1840/17352 (11%)] Loss: -215077.937500\n",
      "Train Epoch: 13 [1920/17352 (11%)] Loss: -221460.671875\n",
      "Train Epoch: 13 [2000/17352 (12%)] Loss: -202261.015625\n",
      "Train Epoch: 13 [2080/17352 (12%)] Loss: -236608.671875\n",
      "Train Epoch: 13 [2160/17352 (12%)] Loss: -199523.312500\n",
      "Train Epoch: 13 [2240/17352 (13%)] Loss: -182389.015625\n",
      "Train Epoch: 13 [2320/17352 (13%)] Loss: -168063.921875\n",
      "Train Epoch: 13 [2400/17352 (14%)] Loss: -159737.671875\n",
      "Train Epoch: 13 [2480/17352 (14%)] Loss: -204579.046875\n",
      "Train Epoch: 13 [2560/17352 (15%)] Loss: -189514.937500\n",
      "Train Epoch: 13 [2640/17352 (15%)] Loss: -174529.875000\n",
      "Train Epoch: 13 [2720/17352 (16%)] Loss: -177466.500000\n",
      "Train Epoch: 13 [2800/17352 (16%)] Loss: -178860.484375\n",
      "Train Epoch: 13 [2880/17352 (17%)] Loss: -187304.796875\n",
      "Train Epoch: 13 [2960/17352 (17%)] Loss: -184154.562500\n",
      "Train Epoch: 13 [3040/17352 (18%)] Loss: -177136.437500\n",
      "Train Epoch: 13 [3120/17352 (18%)] Loss: -180309.000000\n",
      "Train Epoch: 13 [3200/17352 (18%)] Loss: -190906.312500\n",
      "Train Epoch: 13 [3280/17352 (19%)] Loss: -197077.343750\n",
      "Train Epoch: 13 [3360/17352 (19%)] Loss: -200828.468750\n",
      "Train Epoch: 13 [3440/17352 (20%)] Loss: -178306.250000\n",
      "Train Epoch: 13 [3520/17352 (20%)] Loss: -152721.796875\n",
      "Train Epoch: 13 [3600/17352 (21%)] Loss: -163333.843750\n",
      "Train Epoch: 13 [3680/17352 (21%)] Loss: -201362.625000\n",
      "Train Epoch: 13 [3760/17352 (22%)] Loss: -205468.500000\n",
      "Train Epoch: 13 [3840/17352 (22%)] Loss: -169417.468750\n",
      "Train Epoch: 13 [3920/17352 (23%)] Loss: -176525.875000\n",
      "Train Epoch: 13 [4000/17352 (23%)] Loss: -162960.843750\n",
      "Train Epoch: 13 [4080/17352 (24%)] Loss: -193246.515625\n",
      "Train Epoch: 13 [4160/17352 (24%)] Loss: -179665.062500\n",
      "Train Epoch: 13 [4240/17352 (24%)] Loss: -207105.359375\n",
      "Train Epoch: 13 [4320/17352 (25%)] Loss: -172159.625000\n",
      "Train Epoch: 13 [4400/17352 (25%)] Loss: -202074.015625\n",
      "Train Epoch: 13 [4480/17352 (26%)] Loss: -217587.718750\n",
      "Train Epoch: 13 [4560/17352 (26%)] Loss: -185223.703125\n",
      "Train Epoch: 13 [4640/17352 (27%)] Loss: -174492.171875\n",
      "Train Epoch: 13 [4720/17352 (27%)] Loss: -177160.218750\n",
      "Train Epoch: 13 [4800/17352 (28%)] Loss: -208006.343750\n",
      "Train Epoch: 13 [4880/17352 (28%)] Loss: -176573.656250\n",
      "Train Epoch: 13 [4960/17352 (29%)] Loss: -201006.968750\n",
      "Train Epoch: 13 [5040/17352 (29%)] Loss: -129671.195312\n",
      "Train Epoch: 13 [5120/17352 (30%)] Loss: -198240.062500\n",
      "Train Epoch: 13 [5200/17352 (30%)] Loss: -172599.531250\n",
      "Train Epoch: 13 [5280/17352 (30%)] Loss: -178110.937500\n",
      "Train Epoch: 13 [5360/17352 (31%)] Loss: -144979.203125\n",
      "Train Epoch: 13 [5440/17352 (31%)] Loss: -172204.375000\n",
      "Train Epoch: 13 [5520/17352 (32%)] Loss: -168952.906250\n",
      "Train Epoch: 13 [5600/17352 (32%)] Loss: -161667.593750\n",
      "Train Epoch: 13 [5680/17352 (33%)] Loss: -177601.671875\n",
      "Train Epoch: 13 [5760/17352 (33%)] Loss: -183237.375000\n",
      "Train Epoch: 13 [5840/17352 (34%)] Loss: -195034.593750\n",
      "Train Epoch: 13 [5920/17352 (34%)] Loss: -188672.343750\n",
      "Train Epoch: 13 [6000/17352 (35%)] Loss: -192100.843750\n",
      "Train Epoch: 13 [6080/17352 (35%)] Loss: -174469.781250\n",
      "Train Epoch: 13 [6160/17352 (36%)] Loss: -164731.609375\n",
      "Train Epoch: 13 [6240/17352 (36%)] Loss: -185580.046875\n",
      "Train Epoch: 13 [6320/17352 (36%)] Loss: -180243.312500\n",
      "Train Epoch: 13 [6400/17352 (37%)] Loss: -180485.171875\n",
      "Train Epoch: 13 [6480/17352 (37%)] Loss: -228154.453125\n",
      "Train Epoch: 13 [6560/17352 (38%)] Loss: -163242.390625\n",
      "Train Epoch: 13 [6640/17352 (38%)] Loss: -191292.968750\n",
      "Train Epoch: 13 [6720/17352 (39%)] Loss: -163765.031250\n",
      "Train Epoch: 13 [6800/17352 (39%)] Loss: -192295.984375\n",
      "Train Epoch: 13 [6880/17352 (40%)] Loss: -196844.406250\n",
      "Train Epoch: 13 [6960/17352 (40%)] Loss: -170010.390625\n",
      "Train Epoch: 13 [7040/17352 (41%)] Loss: -186932.750000\n",
      "Train Epoch: 13 [7120/17352 (41%)] Loss: -140578.312500\n",
      "Train Epoch: 13 [7200/17352 (41%)] Loss: -196793.078125\n",
      "Train Epoch: 13 [7280/17352 (42%)] Loss: -172983.921875\n",
      "Train Epoch: 13 [7360/17352 (42%)] Loss: -206214.171875\n",
      "Train Epoch: 13 [7440/17352 (43%)] Loss: -180889.062500\n",
      "Train Epoch: 13 [7520/17352 (43%)] Loss: -199778.296875\n",
      "Train Epoch: 13 [7600/17352 (44%)] Loss: -163533.250000\n",
      "Train Epoch: 13 [7680/17352 (44%)] Loss: -192772.968750\n",
      "Train Epoch: 13 [7760/17352 (45%)] Loss: -174445.093750\n",
      "Train Epoch: 13 [7840/17352 (45%)] Loss: -182545.140625\n",
      "Train Epoch: 13 [7920/17352 (46%)] Loss: -197327.796875\n",
      "Train Epoch: 13 [8000/17352 (46%)] Loss: -183718.593750\n",
      "Train Epoch: 13 [8080/17352 (47%)] Loss: -167476.734375\n",
      "Train Epoch: 13 [8160/17352 (47%)] Loss: -203658.312500\n",
      "Train Epoch: 13 [8240/17352 (47%)] Loss: -177286.718750\n",
      "Train Epoch: 13 [8320/17352 (48%)] Loss: -186703.046875\n",
      "Train Epoch: 13 [8400/17352 (48%)] Loss: -190791.812500\n",
      "Train Epoch: 13 [8480/17352 (49%)] Loss: -192263.718750\n",
      "Train Epoch: 13 [8560/17352 (49%)] Loss: -188795.890625\n",
      "Train Epoch: 13 [8640/17352 (50%)] Loss: -190912.625000\n",
      "Train Epoch: 13 [8720/17352 (50%)] Loss: -210249.343750\n",
      "Train Epoch: 13 [8800/17352 (51%)] Loss: -142312.984375\n",
      "Train Epoch: 13 [8880/17352 (51%)] Loss: -179951.046875\n",
      "Train Epoch: 13 [8960/17352 (52%)] Loss: -184822.968750\n",
      "Train Epoch: 13 [9040/17352 (52%)] Loss: -210627.312500\n",
      "Train Epoch: 13 [9120/17352 (53%)] Loss: -183401.000000\n",
      "Train Epoch: 13 [9200/17352 (53%)] Loss: -148382.609375\n",
      "Train Epoch: 13 [9280/17352 (53%)] Loss: -180154.734375\n",
      "Train Epoch: 13 [9360/17352 (54%)] Loss: -179476.609375\n",
      "Train Epoch: 13 [9440/17352 (54%)] Loss: -202971.890625\n",
      "Train Epoch: 13 [9520/17352 (55%)] Loss: -186778.656250\n",
      "Train Epoch: 13 [9600/17352 (55%)] Loss: -183850.828125\n",
      "Train Epoch: 13 [9680/17352 (56%)] Loss: -192216.875000\n",
      "Train Epoch: 13 [9760/17352 (56%)] Loss: -214667.781250\n",
      "Train Epoch: 13 [9840/17352 (57%)] Loss: -199757.078125\n",
      "Train Epoch: 13 [9920/17352 (57%)] Loss: -170753.156250\n",
      "Train Epoch: 13 [10000/17352 (58%)] Loss: -208702.453125\n",
      "Train Epoch: 13 [10080/17352 (58%)] Loss: -178205.531250\n",
      "Train Epoch: 13 [10160/17352 (59%)] Loss: -209235.312500\n",
      "Train Epoch: 13 [10240/17352 (59%)] Loss: -223938.437500\n",
      "Train Epoch: 13 [10320/17352 (59%)] Loss: -202826.343750\n",
      "Train Epoch: 13 [10400/17352 (60%)] Loss: -180902.312500\n",
      "Train Epoch: 13 [10480/17352 (60%)] Loss: -166648.296875\n",
      "Train Epoch: 13 [10560/17352 (61%)] Loss: -183911.312500\n",
      "Train Epoch: 13 [10640/17352 (61%)] Loss: -180783.562500\n",
      "Train Epoch: 13 [10720/17352 (62%)] Loss: -190373.828125\n",
      "Train Epoch: 13 [10800/17352 (62%)] Loss: -197499.203125\n",
      "Train Epoch: 13 [10880/17352 (63%)] Loss: -218500.171875\n",
      "Train Epoch: 13 [10960/17352 (63%)] Loss: -188418.968750\n",
      "Train Epoch: 13 [11040/17352 (64%)] Loss: -197981.296875\n",
      "Train Epoch: 13 [11120/17352 (64%)] Loss: -167951.890625\n",
      "Train Epoch: 13 [11200/17352 (65%)] Loss: -187296.968750\n",
      "Train Epoch: 13 [11280/17352 (65%)] Loss: -161080.078125\n",
      "Train Epoch: 13 [11360/17352 (65%)] Loss: -187267.140625\n",
      "Train Epoch: 13 [11440/17352 (66%)] Loss: -186835.890625\n",
      "Train Epoch: 13 [11520/17352 (66%)] Loss: -149433.187500\n",
      "Train Epoch: 13 [11600/17352 (67%)] Loss: -206459.187500\n",
      "Train Epoch: 13 [11680/17352 (67%)] Loss: -174856.562500\n",
      "Train Epoch: 13 [11760/17352 (68%)] Loss: -195825.234375\n",
      "Train Epoch: 13 [11840/17352 (68%)] Loss: -164815.843750\n",
      "Train Epoch: 13 [11920/17352 (69%)] Loss: -180139.953125\n",
      "Train Epoch: 13 [12000/17352 (69%)] Loss: -180532.031250\n",
      "Train Epoch: 13 [12080/17352 (70%)] Loss: -192971.609375\n",
      "Train Epoch: 13 [12160/17352 (70%)] Loss: -196391.312500\n",
      "Train Epoch: 13 [12240/17352 (71%)] Loss: -167126.484375\n",
      "Train Epoch: 13 [12320/17352 (71%)] Loss: -179286.140625\n",
      "Train Epoch: 13 [12400/17352 (71%)] Loss: -225442.500000\n",
      "Train Epoch: 13 [12480/17352 (72%)] Loss: -181955.484375\n",
      "Train Epoch: 13 [12560/17352 (72%)] Loss: -173119.875000\n",
      "Train Epoch: 13 [12640/17352 (73%)] Loss: -213170.843750\n",
      "Train Epoch: 13 [12720/17352 (73%)] Loss: -190203.703125\n",
      "Train Epoch: 13 [12800/17352 (74%)] Loss: -180010.281250\n",
      "Train Epoch: 13 [12880/17352 (74%)] Loss: -219899.625000\n",
      "Train Epoch: 13 [12960/17352 (75%)] Loss: -167022.656250\n",
      "Train Epoch: 13 [13040/17352 (75%)] Loss: -157766.984375\n",
      "Train Epoch: 13 [13120/17352 (76%)] Loss: -184806.656250\n",
      "Train Epoch: 13 [13200/17352 (76%)] Loss: -181720.234375\n",
      "Train Epoch: 13 [13280/17352 (77%)] Loss: -177181.218750\n",
      "Train Epoch: 13 [13360/17352 (77%)] Loss: -213895.093750\n",
      "Train Epoch: 13 [13440/17352 (77%)] Loss: -199880.421875\n",
      "Train Epoch: 13 [13520/17352 (78%)] Loss: -176271.828125\n",
      "Train Epoch: 13 [13600/17352 (78%)] Loss: -203497.203125\n",
      "Train Epoch: 13 [13680/17352 (79%)] Loss: -185365.312500\n",
      "Train Epoch: 13 [13760/17352 (79%)] Loss: -157580.859375\n",
      "Train Epoch: 13 [13840/17352 (80%)] Loss: -184015.046875\n",
      "Train Epoch: 13 [13920/17352 (80%)] Loss: -177581.109375\n",
      "Train Epoch: 13 [14000/17352 (81%)] Loss: -196181.859375\n",
      "Train Epoch: 13 [14080/17352 (81%)] Loss: -178189.984375\n",
      "Train Epoch: 13 [14160/17352 (82%)] Loss: -192619.468750\n",
      "Train Epoch: 13 [14240/17352 (82%)] Loss: -201912.343750\n",
      "Train Epoch: 13 [14320/17352 (83%)] Loss: -167785.156250\n",
      "Train Epoch: 13 [14400/17352 (83%)] Loss: -197560.734375\n",
      "Train Epoch: 13 [14480/17352 (83%)] Loss: -192361.328125\n",
      "Train Epoch: 13 [14560/17352 (84%)] Loss: -212956.468750\n",
      "Train Epoch: 13 [14640/17352 (84%)] Loss: -193183.281250\n",
      "Train Epoch: 13 [14720/17352 (85%)] Loss: -148810.453125\n",
      "Train Epoch: 13 [14800/17352 (85%)] Loss: -195083.234375\n",
      "Train Epoch: 13 [14880/17352 (86%)] Loss: -188887.578125\n",
      "Train Epoch: 13 [14960/17352 (86%)] Loss: -194031.562500\n",
      "Train Epoch: 13 [15040/17352 (87%)] Loss: -203724.937500\n",
      "Train Epoch: 13 [15120/17352 (87%)] Loss: -166237.968750\n",
      "Train Epoch: 13 [15200/17352 (88%)] Loss: -180239.921875\n",
      "Train Epoch: 13 [15280/17352 (88%)] Loss: -190499.765625\n",
      "Train Epoch: 13 [15360/17352 (89%)] Loss: -183590.968750\n",
      "Train Epoch: 13 [15440/17352 (89%)] Loss: -188251.953125\n",
      "Train Epoch: 13 [15520/17352 (89%)] Loss: -194045.640625\n",
      "Train Epoch: 13 [15600/17352 (90%)] Loss: -185380.859375\n",
      "Train Epoch: 13 [15680/17352 (90%)] Loss: -189256.500000\n",
      "Train Epoch: 13 [15760/17352 (91%)] Loss: -163745.468750\n",
      "Train Epoch: 13 [15840/17352 (91%)] Loss: -148501.015625\n",
      "Train Epoch: 13 [15920/17352 (92%)] Loss: -192978.718750\n",
      "Train Epoch: 13 [16000/17352 (92%)] Loss: -187311.453125\n",
      "Train Epoch: 13 [16080/17352 (93%)] Loss: -165989.562500\n",
      "Train Epoch: 13 [16160/17352 (93%)] Loss: -180676.734375\n",
      "Train Epoch: 13 [16240/17352 (94%)] Loss: -173901.937500\n",
      "Train Epoch: 13 [16320/17352 (94%)] Loss: -190217.531250\n",
      "Train Epoch: 13 [16400/17352 (95%)] Loss: -177189.859375\n",
      "Train Epoch: 13 [16480/17352 (95%)] Loss: -193890.250000\n",
      "Train Epoch: 13 [16560/17352 (95%)] Loss: -195276.687500\n",
      "Train Epoch: 13 [16640/17352 (96%)] Loss: -215157.593750\n",
      "Train Epoch: 13 [16720/17352 (96%)] Loss: -193147.156250\n",
      "Train Epoch: 13 [16800/17352 (97%)] Loss: -206077.984375\n",
      "Train Epoch: 13 [16880/17352 (97%)] Loss: -185251.093750\n",
      "Train Epoch: 13 [16960/17352 (98%)] Loss: -170082.562500\n",
      "Train Epoch: 13 [17040/17352 (98%)] Loss: -159650.609375\n",
      "Train Epoch: 13 [17120/17352 (99%)] Loss: -183768.218750\n",
      "Train Epoch: 13 [17200/17352 (99%)] Loss: -166421.812500\n",
      "Train Epoch: 13 [17280/17352 (100%)] Loss: -192276.890625\n",
      "Train Epoch: 13 [17360/17352 (100%)] Loss: -184898.734375\n",
      "    epoch          : 13\n",
      "    loss           : -189104.56494533946\n",
      "    val_loss       : -23713.410569025316\n",
      "Train Epoch: 14 [0/17352 (0%)] Loss: -213817.000000\n",
      "Train Epoch: 14 [80/17352 (0%)] Loss: -231319.453125\n",
      "Train Epoch: 14 [160/17352 (1%)] Loss: -194272.921875\n",
      "Train Epoch: 14 [240/17352 (1%)] Loss: -241873.390625\n",
      "Train Epoch: 14 [320/17352 (2%)] Loss: -188736.656250\n",
      "Train Epoch: 14 [400/17352 (2%)] Loss: -209624.125000\n",
      "Train Epoch: 14 [480/17352 (3%)] Loss: -205533.875000\n",
      "Train Epoch: 14 [560/17352 (3%)] Loss: -214492.890625\n",
      "Train Epoch: 14 [640/17352 (4%)] Loss: -219180.140625\n",
      "Train Epoch: 14 [720/17352 (4%)] Loss: -217919.593750\n",
      "Train Epoch: 14 [800/17352 (5%)] Loss: -213322.421875\n",
      "Train Epoch: 14 [880/17352 (5%)] Loss: -212672.984375\n",
      "Train Epoch: 14 [960/17352 (6%)] Loss: -205081.375000\n",
      "Train Epoch: 14 [1040/17352 (6%)] Loss: -199916.687500\n",
      "Train Epoch: 14 [1120/17352 (6%)] Loss: -214305.531250\n",
      "Train Epoch: 14 [1200/17352 (7%)] Loss: -229948.734375\n",
      "Train Epoch: 14 [1280/17352 (7%)] Loss: -227994.015625\n",
      "Train Epoch: 14 [1360/17352 (8%)] Loss: -214506.640625\n",
      "Train Epoch: 14 [1440/17352 (8%)] Loss: -191856.703125\n",
      "Train Epoch: 14 [1520/17352 (9%)] Loss: -204345.437500\n",
      "Train Epoch: 14 [1600/17352 (9%)] Loss: -209539.390625\n",
      "Train Epoch: 14 [1680/17352 (10%)] Loss: -217563.234375\n",
      "Train Epoch: 14 [1760/17352 (10%)] Loss: -193403.593750\n",
      "Train Epoch: 14 [1840/17352 (11%)] Loss: -196405.781250\n",
      "Train Epoch: 14 [1920/17352 (11%)] Loss: -196914.984375\n",
      "Train Epoch: 14 [2000/17352 (12%)] Loss: -203733.500000\n",
      "Train Epoch: 14 [2080/17352 (12%)] Loss: -204388.796875\n",
      "Train Epoch: 14 [2160/17352 (12%)] Loss: -224228.406250\n",
      "Train Epoch: 14 [2240/17352 (13%)] Loss: -200282.265625\n",
      "Train Epoch: 14 [2320/17352 (13%)] Loss: -195490.437500\n",
      "Train Epoch: 14 [2400/17352 (14%)] Loss: -175391.015625\n",
      "Train Epoch: 14 [2480/17352 (14%)] Loss: -188062.015625\n",
      "Train Epoch: 14 [2560/17352 (15%)] Loss: -157582.062500\n",
      "Train Epoch: 14 [2640/17352 (15%)] Loss: -177293.203125\n",
      "Train Epoch: 14 [2720/17352 (16%)] Loss: -183043.015625\n",
      "Train Epoch: 14 [2800/17352 (16%)] Loss: -205514.828125\n",
      "Train Epoch: 14 [2880/17352 (17%)] Loss: -192848.046875\n",
      "Train Epoch: 14 [2960/17352 (17%)] Loss: -184757.906250\n",
      "Train Epoch: 14 [3040/17352 (18%)] Loss: -215395.703125\n",
      "Train Epoch: 14 [3120/17352 (18%)] Loss: -166643.171875\n",
      "Train Epoch: 14 [3200/17352 (18%)] Loss: -185500.453125\n",
      "Train Epoch: 14 [3280/17352 (19%)] Loss: -182670.484375\n",
      "Train Epoch: 14 [3360/17352 (19%)] Loss: -196433.500000\n",
      "Train Epoch: 14 [3440/17352 (20%)] Loss: -208141.671875\n",
      "Train Epoch: 14 [3520/17352 (20%)] Loss: -188235.156250\n",
      "Train Epoch: 14 [3600/17352 (21%)] Loss: -164356.687500\n",
      "Train Epoch: 14 [3680/17352 (21%)] Loss: -227869.343750\n",
      "Train Epoch: 14 [3760/17352 (22%)] Loss: -178183.500000\n",
      "Train Epoch: 14 [3840/17352 (22%)] Loss: -201233.734375\n",
      "Train Epoch: 14 [3920/17352 (23%)] Loss: -189233.500000\n",
      "Train Epoch: 14 [4000/17352 (23%)] Loss: -214666.875000\n",
      "Train Epoch: 14 [4080/17352 (24%)] Loss: -179712.625000\n",
      "Train Epoch: 14 [4160/17352 (24%)] Loss: -181944.156250\n",
      "Train Epoch: 14 [4240/17352 (24%)] Loss: -200612.859375\n",
      "Train Epoch: 14 [4320/17352 (25%)] Loss: -191671.109375\n",
      "Train Epoch: 14 [4400/17352 (25%)] Loss: -194572.781250\n",
      "Train Epoch: 14 [4480/17352 (26%)] Loss: -167069.890625\n",
      "Train Epoch: 14 [4560/17352 (26%)] Loss: -197301.359375\n",
      "Train Epoch: 14 [4640/17352 (27%)] Loss: -171297.859375\n",
      "Train Epoch: 14 [4720/17352 (27%)] Loss: -213887.937500\n",
      "Train Epoch: 14 [4800/17352 (28%)] Loss: -210540.218750\n",
      "Train Epoch: 14 [4880/17352 (28%)] Loss: -183902.000000\n",
      "Train Epoch: 14 [4960/17352 (29%)] Loss: -183906.593750\n",
      "Train Epoch: 14 [5040/17352 (29%)] Loss: -187240.812500\n",
      "Train Epoch: 14 [5120/17352 (30%)] Loss: -187309.281250\n",
      "Train Epoch: 14 [5200/17352 (30%)] Loss: -162702.765625\n",
      "Train Epoch: 14 [5280/17352 (30%)] Loss: -189594.281250\n",
      "Train Epoch: 14 [5360/17352 (31%)] Loss: -173658.703125\n",
      "Train Epoch: 14 [5440/17352 (31%)] Loss: -196924.890625\n",
      "Train Epoch: 14 [5520/17352 (32%)] Loss: -167708.875000\n",
      "Train Epoch: 14 [5600/17352 (32%)] Loss: -199587.187500\n",
      "Train Epoch: 14 [5680/17352 (33%)] Loss: -164947.734375\n",
      "Train Epoch: 14 [5760/17352 (33%)] Loss: -206233.578125\n",
      "Train Epoch: 14 [5840/17352 (34%)] Loss: -190581.140625\n",
      "Train Epoch: 14 [5920/17352 (34%)] Loss: -181691.296875\n",
      "Train Epoch: 14 [6000/17352 (35%)] Loss: -167181.984375\n",
      "Train Epoch: 14 [6080/17352 (35%)] Loss: -168489.359375\n",
      "Train Epoch: 14 [6160/17352 (36%)] Loss: -176278.343750\n",
      "Train Epoch: 14 [6240/17352 (36%)] Loss: -174462.968750\n",
      "Train Epoch: 14 [6320/17352 (36%)] Loss: -205787.703125\n",
      "Train Epoch: 14 [6400/17352 (37%)] Loss: -187695.984375\n",
      "Train Epoch: 14 [6480/17352 (37%)] Loss: -200614.437500\n",
      "Train Epoch: 14 [6560/17352 (38%)] Loss: -196433.843750\n",
      "Train Epoch: 14 [6640/17352 (38%)] Loss: -157477.343750\n",
      "Train Epoch: 14 [6720/17352 (39%)] Loss: -187110.375000\n",
      "Train Epoch: 14 [6800/17352 (39%)] Loss: -194204.031250\n",
      "Train Epoch: 14 [6880/17352 (40%)] Loss: -190972.656250\n",
      "Train Epoch: 14 [6960/17352 (40%)] Loss: -168651.984375\n",
      "Train Epoch: 14 [7040/17352 (41%)] Loss: -208013.296875\n",
      "Train Epoch: 14 [7120/17352 (41%)] Loss: -178811.437500\n",
      "Train Epoch: 14 [7200/17352 (41%)] Loss: -192101.843750\n",
      "Train Epoch: 14 [7280/17352 (42%)] Loss: -183770.859375\n",
      "Train Epoch: 14 [7360/17352 (42%)] Loss: -217592.968750\n",
      "Train Epoch: 14 [7440/17352 (43%)] Loss: -199781.343750\n",
      "Train Epoch: 14 [7520/17352 (43%)] Loss: -208717.000000\n",
      "Train Epoch: 14 [7600/17352 (44%)] Loss: -183609.171875\n",
      "Train Epoch: 14 [7680/17352 (44%)] Loss: -186491.062500\n",
      "Train Epoch: 14 [7760/17352 (45%)] Loss: -192736.828125\n",
      "Train Epoch: 14 [7840/17352 (45%)] Loss: -192291.187500\n",
      "Train Epoch: 14 [7920/17352 (46%)] Loss: -192373.312500\n",
      "Train Epoch: 14 [8000/17352 (46%)] Loss: -191039.218750\n",
      "Train Epoch: 14 [8080/17352 (47%)] Loss: -167954.125000\n",
      "Train Epoch: 14 [8160/17352 (47%)] Loss: -170227.781250\n",
      "Train Epoch: 14 [8240/17352 (47%)] Loss: -193350.156250\n",
      "Train Epoch: 14 [8320/17352 (48%)] Loss: -193333.796875\n",
      "Train Epoch: 14 [8400/17352 (48%)] Loss: -177223.500000\n",
      "Train Epoch: 14 [8480/17352 (49%)] Loss: -221256.687500\n",
      "Train Epoch: 14 [8560/17352 (49%)] Loss: -206153.031250\n",
      "Train Epoch: 14 [8640/17352 (50%)] Loss: -208784.093750\n",
      "Train Epoch: 14 [8720/17352 (50%)] Loss: -210252.343750\n",
      "Train Epoch: 14 [8800/17352 (51%)] Loss: -183148.375000\n",
      "Train Epoch: 14 [8880/17352 (51%)] Loss: -158244.640625\n",
      "Train Epoch: 14 [8960/17352 (52%)] Loss: -200610.468750\n",
      "Train Epoch: 14 [9040/17352 (52%)] Loss: -200323.515625\n",
      "Train Epoch: 14 [9120/17352 (53%)] Loss: -163206.656250\n",
      "Train Epoch: 14 [9200/17352 (53%)] Loss: -174497.937500\n",
      "Train Epoch: 14 [9280/17352 (53%)] Loss: -180243.515625\n",
      "Train Epoch: 14 [9360/17352 (54%)] Loss: -188654.937500\n",
      "Train Epoch: 14 [9440/17352 (54%)] Loss: -192874.656250\n",
      "Train Epoch: 14 [9520/17352 (55%)] Loss: -174969.390625\n",
      "Train Epoch: 14 [9600/17352 (55%)] Loss: -164131.921875\n",
      "Train Epoch: 14 [9680/17352 (56%)] Loss: -195051.937500\n",
      "Train Epoch: 14 [9760/17352 (56%)] Loss: -178821.734375\n",
      "Train Epoch: 14 [9840/17352 (57%)] Loss: -200153.406250\n",
      "Train Epoch: 14 [9920/17352 (57%)] Loss: -181729.062500\n",
      "Train Epoch: 14 [10000/17352 (58%)] Loss: -204599.031250\n",
      "Train Epoch: 14 [10080/17352 (58%)] Loss: -184008.250000\n",
      "Train Epoch: 14 [10160/17352 (59%)] Loss: -200977.453125\n",
      "Train Epoch: 14 [10240/17352 (59%)] Loss: -189804.031250\n",
      "Train Epoch: 14 [10320/17352 (59%)] Loss: -177758.890625\n",
      "Train Epoch: 14 [10400/17352 (60%)] Loss: -208294.375000\n",
      "Train Epoch: 14 [10480/17352 (60%)] Loss: -192775.625000\n",
      "Train Epoch: 14 [10560/17352 (61%)] Loss: -168986.609375\n",
      "Train Epoch: 14 [10640/17352 (61%)] Loss: -179420.531250\n",
      "Train Epoch: 14 [10720/17352 (62%)] Loss: -179371.593750\n",
      "Train Epoch: 14 [10800/17352 (62%)] Loss: -174441.000000\n",
      "Train Epoch: 14 [10880/17352 (63%)] Loss: -178128.718750\n",
      "Train Epoch: 14 [10960/17352 (63%)] Loss: -165351.828125\n",
      "Train Epoch: 14 [11040/17352 (64%)] Loss: -187635.906250\n",
      "Train Epoch: 14 [11120/17352 (64%)] Loss: -215952.453125\n",
      "Train Epoch: 14 [11200/17352 (65%)] Loss: -197576.515625\n",
      "Train Epoch: 14 [11280/17352 (65%)] Loss: -184446.531250\n",
      "Train Epoch: 14 [11360/17352 (65%)] Loss: -177758.015625\n",
      "Train Epoch: 14 [11440/17352 (66%)] Loss: -222846.937500\n",
      "Train Epoch: 14 [11520/17352 (66%)] Loss: -181001.859375\n",
      "Train Epoch: 14 [11600/17352 (67%)] Loss: -183035.921875\n",
      "Train Epoch: 14 [11680/17352 (67%)] Loss: -166245.906250\n",
      "Train Epoch: 14 [11760/17352 (68%)] Loss: -170027.156250\n",
      "Train Epoch: 14 [11840/17352 (68%)] Loss: -198980.890625\n",
      "Train Epoch: 14 [11920/17352 (69%)] Loss: -195858.906250\n",
      "Train Epoch: 14 [12000/17352 (69%)] Loss: -197336.406250\n",
      "Train Epoch: 14 [12080/17352 (70%)] Loss: -193090.187500\n",
      "Train Epoch: 14 [12160/17352 (70%)] Loss: -172229.140625\n",
      "Train Epoch: 14 [12240/17352 (71%)] Loss: -213386.078125\n",
      "Train Epoch: 14 [12320/17352 (71%)] Loss: -166383.000000\n",
      "Train Epoch: 14 [12400/17352 (71%)] Loss: -201936.718750\n",
      "Train Epoch: 14 [12480/17352 (72%)] Loss: -180956.421875\n",
      "Train Epoch: 14 [12560/17352 (72%)] Loss: -193121.265625\n",
      "Train Epoch: 14 [12640/17352 (73%)] Loss: -196271.656250\n",
      "Train Epoch: 14 [12720/17352 (73%)] Loss: -188186.750000\n",
      "Train Epoch: 14 [12800/17352 (74%)] Loss: -190464.843750\n",
      "Train Epoch: 14 [12880/17352 (74%)] Loss: -191047.875000\n",
      "Train Epoch: 14 [12960/17352 (75%)] Loss: -203417.156250\n",
      "Train Epoch: 14 [13040/17352 (75%)] Loss: -180100.546875\n",
      "Train Epoch: 14 [13120/17352 (76%)] Loss: -201081.359375\n",
      "Train Epoch: 14 [13200/17352 (76%)] Loss: -215445.281250\n",
      "Train Epoch: 14 [13280/17352 (77%)] Loss: -180676.484375\n",
      "Train Epoch: 14 [13360/17352 (77%)] Loss: -184812.671875\n",
      "Train Epoch: 14 [13440/17352 (77%)] Loss: -164499.203125\n",
      "Train Epoch: 14 [13520/17352 (78%)] Loss: -171529.812500\n",
      "Train Epoch: 14 [13600/17352 (78%)] Loss: -177965.468750\n",
      "Train Epoch: 14 [13680/17352 (79%)] Loss: -148423.156250\n",
      "Train Epoch: 14 [13760/17352 (79%)] Loss: -187448.593750\n",
      "Train Epoch: 14 [13840/17352 (80%)] Loss: -210615.812500\n",
      "Train Epoch: 14 [13920/17352 (80%)] Loss: -185227.125000\n",
      "Train Epoch: 14 [14000/17352 (81%)] Loss: -178594.484375\n",
      "Train Epoch: 14 [14080/17352 (81%)] Loss: -183775.312500\n",
      "Train Epoch: 14 [14160/17352 (82%)] Loss: -185579.281250\n",
      "Train Epoch: 14 [14240/17352 (82%)] Loss: -196017.734375\n",
      "Train Epoch: 14 [14320/17352 (83%)] Loss: -152736.671875\n",
      "Train Epoch: 14 [14400/17352 (83%)] Loss: -197532.640625\n",
      "Train Epoch: 14 [14480/17352 (83%)] Loss: -181668.703125\n",
      "Train Epoch: 14 [14560/17352 (84%)] Loss: -196544.046875\n",
      "Train Epoch: 14 [14640/17352 (84%)] Loss: -185769.640625\n",
      "Train Epoch: 14 [14720/17352 (85%)] Loss: -209810.421875\n",
      "Train Epoch: 14 [14800/17352 (85%)] Loss: -151728.546875\n",
      "Train Epoch: 14 [14880/17352 (86%)] Loss: -217600.656250\n",
      "Train Epoch: 14 [14960/17352 (86%)] Loss: -183769.250000\n",
      "Train Epoch: 14 [15040/17352 (87%)] Loss: -187263.796875\n",
      "Train Epoch: 14 [15120/17352 (87%)] Loss: -195046.250000\n",
      "Train Epoch: 14 [15200/17352 (88%)] Loss: -209487.703125\n",
      "Train Epoch: 14 [15280/17352 (88%)] Loss: -166780.265625\n",
      "Train Epoch: 14 [15360/17352 (89%)] Loss: -198243.500000\n",
      "Train Epoch: 14 [15440/17352 (89%)] Loss: -193034.453125\n",
      "Train Epoch: 14 [15520/17352 (89%)] Loss: -186492.531250\n",
      "Train Epoch: 14 [15600/17352 (90%)] Loss: -185044.718750\n",
      "Train Epoch: 14 [15680/17352 (90%)] Loss: -175661.937500\n",
      "Train Epoch: 14 [15760/17352 (91%)] Loss: -199699.031250\n",
      "Train Epoch: 14 [15840/17352 (91%)] Loss: -167235.093750\n",
      "Train Epoch: 14 [15920/17352 (92%)] Loss: -204586.015625\n",
      "Train Epoch: 14 [16000/17352 (92%)] Loss: -190489.046875\n",
      "Train Epoch: 14 [16080/17352 (93%)] Loss: -202782.015625\n",
      "Train Epoch: 14 [16160/17352 (93%)] Loss: -187757.093750\n",
      "Train Epoch: 14 [16240/17352 (94%)] Loss: -192880.718750\n",
      "Train Epoch: 14 [16320/17352 (94%)] Loss: -169432.375000\n",
      "Train Epoch: 14 [16400/17352 (95%)] Loss: -208411.687500\n",
      "Train Epoch: 14 [16480/17352 (95%)] Loss: -179913.312500\n",
      "Train Epoch: 14 [16560/17352 (95%)] Loss: -178859.406250\n",
      "Train Epoch: 14 [16640/17352 (96%)] Loss: -178995.343750\n",
      "Train Epoch: 14 [16720/17352 (96%)] Loss: -166536.921875\n",
      "Train Epoch: 14 [16800/17352 (97%)] Loss: -152890.828125\n",
      "Train Epoch: 14 [16880/17352 (97%)] Loss: -187572.500000\n",
      "Train Epoch: 14 [16960/17352 (98%)] Loss: -155853.359375\n",
      "Train Epoch: 14 [17040/17352 (98%)] Loss: -183238.593750\n",
      "Train Epoch: 14 [17120/17352 (99%)] Loss: -174135.921875\n",
      "Train Epoch: 14 [17200/17352 (99%)] Loss: -171696.984375\n",
      "Train Epoch: 14 [17280/17352 (100%)] Loss: -185989.453125\n",
      "Train Epoch: 14 [17360/17352 (100%)] Loss: -187942.031250\n",
      "    epoch          : 14\n",
      "    loss           : -189335.84617735902\n",
      "    val_loss       : -23713.583250305463\n",
      "Train Epoch: 15 [0/17352 (0%)] Loss: -185271.531250\n",
      "Train Epoch: 15 [80/17352 (0%)] Loss: -224342.218750\n",
      "Train Epoch: 15 [160/17352 (1%)] Loss: -213321.843750\n",
      "Train Epoch: 15 [240/17352 (1%)] Loss: -205198.343750\n",
      "Train Epoch: 15 [320/17352 (2%)] Loss: -205189.281250\n",
      "Train Epoch: 15 [400/17352 (2%)] Loss: -206128.937500\n",
      "Train Epoch: 15 [480/17352 (3%)] Loss: -229232.656250\n",
      "Train Epoch: 15 [560/17352 (3%)] Loss: -214520.796875\n",
      "Train Epoch: 15 [640/17352 (4%)] Loss: -210611.062500\n",
      "Train Epoch: 15 [720/17352 (4%)] Loss: -201654.968750\n",
      "Train Epoch: 15 [800/17352 (5%)] Loss: -206543.718750\n",
      "Train Epoch: 15 [880/17352 (5%)] Loss: -214497.843750\n",
      "Train Epoch: 15 [960/17352 (6%)] Loss: -236807.625000\n",
      "Train Epoch: 15 [1040/17352 (6%)] Loss: -215813.984375\n",
      "Train Epoch: 15 [1120/17352 (6%)] Loss: -221754.109375\n",
      "Train Epoch: 15 [1200/17352 (7%)] Loss: -199800.359375\n",
      "Train Epoch: 15 [1280/17352 (7%)] Loss: -202213.593750\n",
      "Train Epoch: 15 [1360/17352 (8%)] Loss: -217622.093750\n",
      "Train Epoch: 15 [1440/17352 (8%)] Loss: -186068.203125\n",
      "Train Epoch: 15 [1520/17352 (9%)] Loss: -204728.437500\n",
      "Train Epoch: 15 [1600/17352 (9%)] Loss: -212641.656250\n",
      "Train Epoch: 15 [1680/17352 (10%)] Loss: -191854.890625\n",
      "Train Epoch: 15 [1760/17352 (10%)] Loss: -193007.640625\n",
      "Train Epoch: 15 [1840/17352 (11%)] Loss: -212357.125000\n",
      "Train Epoch: 15 [1920/17352 (11%)] Loss: -219196.312500\n",
      "Train Epoch: 15 [2000/17352 (12%)] Loss: -212247.765625\n",
      "Train Epoch: 15 [2080/17352 (12%)] Loss: -206731.265625\n",
      "Train Epoch: 15 [2160/17352 (12%)] Loss: -198110.375000\n",
      "Train Epoch: 15 [2240/17352 (13%)] Loss: -174853.312500\n",
      "Train Epoch: 15 [2320/17352 (13%)] Loss: -188423.125000\n",
      "Train Epoch: 15 [2400/17352 (14%)] Loss: -176116.781250\n",
      "Train Epoch: 15 [2480/17352 (14%)] Loss: -190787.187500\n",
      "Train Epoch: 15 [2560/17352 (15%)] Loss: -210904.046875\n",
      "Train Epoch: 15 [2640/17352 (15%)] Loss: -175539.390625\n",
      "Train Epoch: 15 [2720/17352 (16%)] Loss: -193482.171875\n",
      "Train Epoch: 15 [2800/17352 (16%)] Loss: -181005.218750\n",
      "Train Epoch: 15 [2880/17352 (17%)] Loss: -203262.343750\n",
      "Train Epoch: 15 [2960/17352 (17%)] Loss: -180889.296875\n",
      "Train Epoch: 15 [3040/17352 (18%)] Loss: -187294.859375\n",
      "Train Epoch: 15 [3120/17352 (18%)] Loss: -171209.937500\n",
      "Train Epoch: 15 [3200/17352 (18%)] Loss: -152726.906250\n",
      "Train Epoch: 15 [3280/17352 (19%)] Loss: -168244.296875\n",
      "Train Epoch: 15 [3360/17352 (19%)] Loss: -201309.156250\n",
      "Train Epoch: 15 [3440/17352 (20%)] Loss: -205477.093750\n",
      "Train Epoch: 15 [3520/17352 (20%)] Loss: -176034.000000\n",
      "Train Epoch: 15 [3600/17352 (21%)] Loss: -187309.468750\n",
      "Train Epoch: 15 [3680/17352 (21%)] Loss: -181535.765625\n",
      "Train Epoch: 15 [3760/17352 (22%)] Loss: -181321.984375\n",
      "Train Epoch: 15 [3840/17352 (22%)] Loss: -204334.937500\n",
      "Train Epoch: 15 [3920/17352 (23%)] Loss: -153305.671875\n",
      "Train Epoch: 15 [4000/17352 (23%)] Loss: -192938.703125\n",
      "Train Epoch: 15 [4080/17352 (24%)] Loss: -174972.750000\n",
      "Train Epoch: 15 [4160/17352 (24%)] Loss: -192983.140625\n",
      "Train Epoch: 15 [4240/17352 (24%)] Loss: -163086.640625\n",
      "Train Epoch: 15 [4320/17352 (25%)] Loss: -175351.421875\n",
      "Train Epoch: 15 [4400/17352 (25%)] Loss: -187764.687500\n",
      "Train Epoch: 15 [4480/17352 (26%)] Loss: -184746.484375\n",
      "Train Epoch: 15 [4560/17352 (26%)] Loss: -194919.640625\n",
      "Train Epoch: 15 [4640/17352 (27%)] Loss: -203875.109375\n",
      "Train Epoch: 15 [4720/17352 (27%)] Loss: -201944.359375\n",
      "Train Epoch: 15 [4800/17352 (28%)] Loss: -192109.187500\n",
      "Train Epoch: 15 [4880/17352 (28%)] Loss: -175315.250000\n",
      "Train Epoch: 15 [4960/17352 (29%)] Loss: -186024.156250\n",
      "Train Epoch: 15 [5040/17352 (29%)] Loss: -177130.234375\n",
      "Train Epoch: 15 [5120/17352 (30%)] Loss: -186148.375000\n",
      "Train Epoch: 15 [5200/17352 (30%)] Loss: -182722.765625\n",
      "Train Epoch: 15 [5280/17352 (30%)] Loss: -197429.281250\n",
      "Train Epoch: 15 [5360/17352 (31%)] Loss: -218395.562500\n",
      "Train Epoch: 15 [5440/17352 (31%)] Loss: -159726.421875\n",
      "Train Epoch: 15 [5520/17352 (32%)] Loss: -187113.000000\n",
      "Train Epoch: 15 [5600/17352 (32%)] Loss: -172610.250000\n",
      "Train Epoch: 15 [5680/17352 (33%)] Loss: -219906.687500\n",
      "Train Epoch: 15 [5760/17352 (33%)] Loss: -197059.921875\n",
      "Train Epoch: 15 [5840/17352 (34%)] Loss: -179004.093750\n",
      "Train Epoch: 15 [5920/17352 (34%)] Loss: -177754.750000\n",
      "Train Epoch: 15 [6000/17352 (35%)] Loss: -196422.500000\n",
      "Train Epoch: 15 [6080/17352 (35%)] Loss: -192670.781250\n",
      "Train Epoch: 15 [6160/17352 (36%)] Loss: -218507.421875\n",
      "Train Epoch: 15 [6240/17352 (36%)] Loss: -191298.640625\n",
      "Train Epoch: 15 [6320/17352 (36%)] Loss: -177458.343750\n",
      "Train Epoch: 15 [6400/17352 (37%)] Loss: -201249.609375\n",
      "Train Epoch: 15 [6480/17352 (37%)] Loss: -171294.750000\n",
      "Train Epoch: 15 [6560/17352 (38%)] Loss: -160086.406250\n",
      "Train Epoch: 15 [6640/17352 (38%)] Loss: -192235.531250\n",
      "Train Epoch: 15 [6720/17352 (39%)] Loss: -198529.062500\n",
      "Train Epoch: 15 [6800/17352 (39%)] Loss: -200281.984375\n",
      "Train Epoch: 15 [6880/17352 (40%)] Loss: -167180.828125\n",
      "Train Epoch: 15 [6960/17352 (40%)] Loss: -171415.437500\n",
      "Train Epoch: 15 [7040/17352 (41%)] Loss: -169426.484375\n",
      "Train Epoch: 15 [7120/17352 (41%)] Loss: -168988.390625\n",
      "Train Epoch: 15 [7200/17352 (41%)] Loss: -188152.890625\n",
      "Train Epoch: 15 [7280/17352 (42%)] Loss: -193077.796875\n",
      "Train Epoch: 15 [7360/17352 (42%)] Loss: -186028.125000\n",
      "Train Epoch: 15 [7440/17352 (43%)] Loss: -202839.812500\n",
      "Train Epoch: 15 [7520/17352 (43%)] Loss: -196181.562500\n",
      "Train Epoch: 15 [7600/17352 (44%)] Loss: -179445.828125\n",
      "Train Epoch: 15 [7680/17352 (44%)] Loss: -214615.890625\n",
      "Train Epoch: 15 [7760/17352 (45%)] Loss: -197292.234375\n",
      "Train Epoch: 15 [7840/17352 (45%)] Loss: -177165.578125\n",
      "Train Epoch: 15 [7920/17352 (46%)] Loss: -184011.453125\n",
      "Train Epoch: 15 [8000/17352 (46%)] Loss: -140579.296875\n",
      "Train Epoch: 15 [8080/17352 (47%)] Loss: -167857.453125\n",
      "Train Epoch: 15 [8160/17352 (47%)] Loss: -177590.421875\n",
      "Train Epoch: 15 [8240/17352 (47%)] Loss: -181967.031250\n",
      "Train Epoch: 15 [8320/17352 (48%)] Loss: -181908.484375\n",
      "Train Epoch: 15 [8400/17352 (48%)] Loss: -197367.984375\n",
      "Train Epoch: 15 [8480/17352 (49%)] Loss: -178724.500000\n",
      "Train Epoch: 15 [8560/17352 (49%)] Loss: -202856.046875\n",
      "Train Epoch: 15 [8640/17352 (50%)] Loss: -220959.046875\n",
      "Train Epoch: 15 [8720/17352 (50%)] Loss: -225465.703125\n",
      "Train Epoch: 15 [8800/17352 (51%)] Loss: -185160.203125\n",
      "Train Epoch: 15 [8880/17352 (51%)] Loss: -182326.218750\n",
      "Train Epoch: 15 [8960/17352 (52%)] Loss: -201805.359375\n",
      "Train Epoch: 15 [9040/17352 (52%)] Loss: -187502.312500\n",
      "Train Epoch: 15 [9120/17352 (53%)] Loss: -180984.468750\n",
      "Train Epoch: 15 [9200/17352 (53%)] Loss: -197929.187500\n",
      "Train Epoch: 15 [9280/17352 (53%)] Loss: -166643.156250\n",
      "Train Epoch: 15 [9360/17352 (54%)] Loss: -193335.609375\n",
      "Train Epoch: 15 [9440/17352 (54%)] Loss: -182389.546875\n",
      "Train Epoch: 15 [9520/17352 (55%)] Loss: -186495.093750\n",
      "Train Epoch: 15 [9600/17352 (55%)] Loss: -166006.781250\n",
      "Train Epoch: 15 [9680/17352 (56%)] Loss: -177568.562500\n",
      "Train Epoch: 15 [9760/17352 (56%)] Loss: -181247.593750\n",
      "Train Epoch: 15 [9840/17352 (57%)] Loss: -168946.453125\n",
      "Train Epoch: 15 [9920/17352 (57%)] Loss: -215956.109375\n",
      "Train Epoch: 15 [10000/17352 (58%)] Loss: -199505.765625\n",
      "Train Epoch: 15 [10080/17352 (58%)] Loss: -201362.875000\n",
      "Train Epoch: 15 [10160/17352 (59%)] Loss: -193504.937500\n",
      "Train Epoch: 15 [10240/17352 (59%)] Loss: -172221.562500\n",
      "Train Epoch: 15 [10320/17352 (59%)] Loss: -197083.875000\n",
      "Train Epoch: 15 [10400/17352 (60%)] Loss: -183961.390625\n",
      "Train Epoch: 15 [10480/17352 (60%)] Loss: -200314.531250\n",
      "Train Epoch: 15 [10560/17352 (61%)] Loss: -198543.437500\n",
      "Train Epoch: 15 [10640/17352 (61%)] Loss: -180244.562500\n",
      "Train Epoch: 15 [10720/17352 (62%)] Loss: -205151.140625\n",
      "Train Epoch: 15 [10800/17352 (62%)] Loss: -171695.671875\n",
      "Train Epoch: 15 [10880/17352 (63%)] Loss: -159295.171875\n",
      "Train Epoch: 15 [10960/17352 (63%)] Loss: -200627.859375\n",
      "Train Epoch: 15 [11040/17352 (64%)] Loss: -209885.796875\n",
      "Train Epoch: 15 [11120/17352 (64%)] Loss: -185230.546875\n",
      "Train Epoch: 15 [11200/17352 (65%)] Loss: -131048.343750\n",
      "Train Epoch: 15 [11280/17352 (65%)] Loss: -191863.281250\n",
      "Train Epoch: 15 [11360/17352 (65%)] Loss: -189392.625000\n",
      "Train Epoch: 15 [11440/17352 (66%)] Loss: -157477.609375\n",
      "Train Epoch: 15 [11520/17352 (66%)] Loss: -167029.234375\n",
      "Train Epoch: 15 [11600/17352 (67%)] Loss: -197524.656250\n",
      "Train Epoch: 15 [11680/17352 (67%)] Loss: -163538.562500\n",
      "Train Epoch: 15 [11760/17352 (68%)] Loss: -185042.484375\n",
      "Train Epoch: 15 [11840/17352 (68%)] Loss: -185381.359375\n",
      "Train Epoch: 15 [11920/17352 (69%)] Loss: -192359.953125\n",
      "Train Epoch: 15 [12000/17352 (69%)] Loss: -181887.000000\n",
      "Train Epoch: 15 [12080/17352 (70%)] Loss: -200820.953125\n",
      "Train Epoch: 15 [12160/17352 (70%)] Loss: -181949.796875\n",
      "Train Epoch: 15 [12240/17352 (71%)] Loss: -172160.718750\n",
      "Train Epoch: 15 [12320/17352 (71%)] Loss: -196148.906250\n",
      "Train Epoch: 15 [12400/17352 (71%)] Loss: -208710.546875\n",
      "Train Epoch: 15 [12480/17352 (72%)] Loss: -213390.578125\n",
      "Train Epoch: 15 [12560/17352 (72%)] Loss: -210142.375000\n",
      "Train Epoch: 15 [12640/17352 (73%)] Loss: -178817.140625\n",
      "Train Epoch: 15 [12720/17352 (73%)] Loss: -210777.375000\n",
      "Train Epoch: 15 [12800/17352 (74%)] Loss: -164355.687500\n",
      "Train Epoch: 15 [12880/17352 (74%)] Loss: -210387.703125\n",
      "Train Epoch: 15 [12960/17352 (75%)] Loss: -182673.218750\n",
      "Train Epoch: 15 [13040/17352 (75%)] Loss: -143621.734375\n",
      "Train Epoch: 15 [13120/17352 (76%)] Loss: -177729.593750\n",
      "Train Epoch: 15 [13200/17352 (76%)] Loss: -168046.828125\n",
      "Train Epoch: 15 [13280/17352 (77%)] Loss: -183754.593750\n",
      "Train Epoch: 15 [13360/17352 (77%)] Loss: -215165.328125\n",
      "Train Epoch: 15 [13440/17352 (77%)] Loss: -205498.578125\n",
      "Train Epoch: 15 [13520/17352 (78%)] Loss: -173873.531250\n",
      "Train Epoch: 15 [13600/17352 (78%)] Loss: -178790.062500\n",
      "Train Epoch: 15 [13680/17352 (79%)] Loss: -193163.687500\n",
      "Train Epoch: 15 [13760/17352 (79%)] Loss: -175493.734375\n",
      "Train Epoch: 15 [13840/17352 (80%)] Loss: -205786.093750\n",
      "Train Epoch: 15 [13920/17352 (80%)] Loss: -206675.187500\n",
      "Train Epoch: 15 [14000/17352 (81%)] Loss: -204479.828125\n",
      "Train Epoch: 15 [14080/17352 (81%)] Loss: -215411.015625\n",
      "Train Epoch: 15 [14160/17352 (82%)] Loss: -173425.203125\n",
      "Train Epoch: 15 [14240/17352 (82%)] Loss: -204390.515625\n",
      "Train Epoch: 15 [14320/17352 (83%)] Loss: -192373.781250\n",
      "Train Epoch: 15 [14400/17352 (83%)] Loss: -167944.765625\n",
      "Train Epoch: 15 [14480/17352 (83%)] Loss: -199398.140625\n",
      "Train Epoch: 15 [14560/17352 (84%)] Loss: -199769.718750\n",
      "Train Epoch: 15 [14640/17352 (84%)] Loss: -174443.062500\n",
      "Train Epoch: 15 [14720/17352 (85%)] Loss: -199759.843750\n",
      "Train Epoch: 15 [14800/17352 (85%)] Loss: -167794.531250\n",
      "Train Epoch: 15 [14880/17352 (86%)] Loss: -191951.546875\n",
      "Train Epoch: 15 [14960/17352 (86%)] Loss: -171817.187500\n",
      "Train Epoch: 15 [15040/17352 (87%)] Loss: -187312.593750\n",
      "Train Epoch: 15 [15120/17352 (87%)] Loss: -179436.625000\n",
      "Train Epoch: 15 [15200/17352 (88%)] Loss: -213737.921875\n",
      "Train Epoch: 15 [15280/17352 (88%)] Loss: -187230.203125\n",
      "Train Epoch: 15 [15360/17352 (89%)] Loss: -205520.937500\n",
      "Train Epoch: 15 [15440/17352 (89%)] Loss: -192206.531250\n",
      "Train Epoch: 15 [15520/17352 (89%)] Loss: -180516.421875\n",
      "Train Epoch: 15 [15600/17352 (90%)] Loss: -187778.140625\n",
      "Train Epoch: 15 [15680/17352 (90%)] Loss: -173001.593750\n",
      "Train Epoch: 15 [15760/17352 (91%)] Loss: -199157.796875\n",
      "Train Epoch: 15 [15840/17352 (91%)] Loss: -170763.640625\n",
      "Train Epoch: 15 [15920/17352 (92%)] Loss: -166647.046875\n",
      "Train Epoch: 15 [16000/17352 (92%)] Loss: -176560.562500\n",
      "Train Epoch: 15 [16080/17352 (93%)] Loss: -211696.421875\n",
      "Train Epoch: 15 [16160/17352 (93%)] Loss: -203439.734375\n",
      "Train Epoch: 15 [16240/17352 (94%)] Loss: -182899.296875\n",
      "Train Epoch: 15 [16320/17352 (94%)] Loss: -190924.171875\n",
      "Train Epoch: 15 [16400/17352 (95%)] Loss: -191949.156250\n",
      "Train Epoch: 15 [16480/17352 (95%)] Loss: -202513.765625\n",
      "Train Epoch: 15 [16560/17352 (95%)] Loss: -187520.078125\n",
      "Train Epoch: 15 [16640/17352 (96%)] Loss: -174500.500000\n",
      "Train Epoch: 15 [16720/17352 (96%)] Loss: -169491.750000\n",
      "Train Epoch: 15 [16800/17352 (97%)] Loss: -189199.640625\n",
      "Train Epoch: 15 [16880/17352 (97%)] Loss: -172954.281250\n",
      "Train Epoch: 15 [16960/17352 (98%)] Loss: -209180.562500\n",
      "Train Epoch: 15 [17040/17352 (98%)] Loss: -199790.671875\n",
      "Train Epoch: 15 [17120/17352 (99%)] Loss: -180043.375000\n",
      "Train Epoch: 15 [17200/17352 (99%)] Loss: -178310.125000\n",
      "Train Epoch: 15 [17280/17352 (100%)] Loss: -182556.125000\n",
      "Train Epoch: 15 [17360/17352 (100%)] Loss: -200618.437500\n",
      "    epoch          : 15\n",
      "    loss           : -189173.59926999424\n",
      "    val_loss       : -23713.99758366688\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch15.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 16 [0/17352 (0%)] Loss: -210511.546875\n",
      "Train Epoch: 16 [80/17352 (0%)] Loss: -230398.796875\n",
      "Train Epoch: 16 [160/17352 (1%)] Loss: -227988.218750\n",
      "Train Epoch: 16 [240/17352 (1%)] Loss: -222990.703125\n",
      "Train Epoch: 16 [320/17352 (2%)] Loss: -208363.578125\n",
      "Train Epoch: 16 [400/17352 (2%)] Loss: -235569.375000\n",
      "Train Epoch: 16 [480/17352 (3%)] Loss: -204691.531250\n",
      "Train Epoch: 16 [560/17352 (3%)] Loss: -218539.125000\n",
      "Train Epoch: 16 [640/17352 (4%)] Loss: -201655.218750\n",
      "Train Epoch: 16 [720/17352 (4%)] Loss: -219197.093750\n",
      "Train Epoch: 16 [800/17352 (5%)] Loss: -233734.109375\n",
      "Train Epoch: 16 [880/17352 (5%)] Loss: -212164.765625\n",
      "Train Epoch: 16 [960/17352 (6%)] Loss: -204025.218750\n",
      "Train Epoch: 16 [1040/17352 (6%)] Loss: -209628.140625\n",
      "Train Epoch: 16 [1120/17352 (6%)] Loss: -212233.640625\n",
      "Train Epoch: 16 [1200/17352 (7%)] Loss: -199093.859375\n",
      "Train Epoch: 16 [1280/17352 (7%)] Loss: -216091.812500\n",
      "Train Epoch: 16 [1360/17352 (8%)] Loss: -215820.968750\n",
      "Train Epoch: 16 [1440/17352 (8%)] Loss: -210619.890625\n",
      "Train Epoch: 16 [1520/17352 (9%)] Loss: -224334.015625\n",
      "Train Epoch: 16 [1600/17352 (9%)] Loss: -206136.203125\n",
      "Train Epoch: 16 [1680/17352 (10%)] Loss: -206790.109375\n",
      "Train Epoch: 16 [1760/17352 (10%)] Loss: -221465.703125\n",
      "Train Epoch: 16 [1840/17352 (11%)] Loss: -236489.468750\n",
      "Train Epoch: 16 [1920/17352 (11%)] Loss: -206544.937500\n",
      "Train Epoch: 16 [2000/17352 (12%)] Loss: -213814.921875\n",
      "Train Epoch: 16 [2080/17352 (12%)] Loss: -199514.312500\n",
      "Train Epoch: 16 [2160/17352 (12%)] Loss: -205908.515625\n",
      "Train Epoch: 16 [2240/17352 (13%)] Loss: -204684.218750\n",
      "Train Epoch: 16 [2320/17352 (13%)] Loss: -177085.734375\n",
      "Train Epoch: 16 [2400/17352 (14%)] Loss: -178877.875000\n",
      "Train Epoch: 16 [2480/17352 (14%)] Loss: -210377.578125\n",
      "Train Epoch: 16 [2560/17352 (15%)] Loss: -196267.828125\n",
      "Train Epoch: 16 [2640/17352 (15%)] Loss: -211625.500000\n",
      "Train Epoch: 16 [2720/17352 (16%)] Loss: -200412.453125\n",
      "Train Epoch: 16 [2800/17352 (16%)] Loss: -173571.578125\n",
      "Train Epoch: 16 [2880/17352 (17%)] Loss: -180635.687500\n",
      "Train Epoch: 16 [2960/17352 (17%)] Loss: -176689.500000\n",
      "Train Epoch: 16 [3040/17352 (18%)] Loss: -200180.000000\n",
      "Train Epoch: 16 [3120/17352 (18%)] Loss: -186557.468750\n",
      "Train Epoch: 16 [3200/17352 (18%)] Loss: -202986.750000\n",
      "Train Epoch: 16 [3280/17352 (19%)] Loss: -138332.578125\n",
      "Train Epoch: 16 [3360/17352 (19%)] Loss: -215624.671875\n",
      "Train Epoch: 16 [3440/17352 (20%)] Loss: -177229.062500\n",
      "Train Epoch: 16 [3520/17352 (20%)] Loss: -173030.171875\n",
      "Train Epoch: 16 [3600/17352 (21%)] Loss: -159079.625000\n",
      "Train Epoch: 16 [3680/17352 (21%)] Loss: -178204.640625\n",
      "Train Epoch: 16 [3760/17352 (22%)] Loss: -177184.578125\n",
      "Train Epoch: 16 [3840/17352 (22%)] Loss: -160034.218750\n",
      "Train Epoch: 16 [3920/17352 (23%)] Loss: -189292.031250\n",
      "Train Epoch: 16 [4000/17352 (23%)] Loss: -179966.390625\n",
      "Train Epoch: 16 [4080/17352 (24%)] Loss: -171568.828125\n",
      "Train Epoch: 16 [4160/17352 (24%)] Loss: -148140.906250\n",
      "Train Epoch: 16 [4240/17352 (24%)] Loss: -155857.593750\n",
      "Train Epoch: 16 [4320/17352 (25%)] Loss: -181905.187500\n",
      "Train Epoch: 16 [4400/17352 (25%)] Loss: -196188.015625\n",
      "Train Epoch: 16 [4480/17352 (26%)] Loss: -178304.281250\n",
      "Train Epoch: 16 [4560/17352 (26%)] Loss: -153875.187500\n",
      "Train Epoch: 16 [4640/17352 (27%)] Loss: -202174.687500\n",
      "Train Epoch: 16 [4720/17352 (27%)] Loss: -202573.703125\n",
      "Train Epoch: 16 [4800/17352 (28%)] Loss: -175580.609375\n",
      "Train Epoch: 16 [4880/17352 (28%)] Loss: -216370.734375\n",
      "Train Epoch: 16 [4960/17352 (29%)] Loss: -165369.515625\n",
      "Train Epoch: 16 [5040/17352 (29%)] Loss: -175502.796875\n",
      "Train Epoch: 16 [5120/17352 (30%)] Loss: -184979.109375\n",
      "Train Epoch: 16 [5200/17352 (30%)] Loss: -188658.765625\n",
      "Train Epoch: 16 [5280/17352 (30%)] Loss: -190925.046875\n",
      "Train Epoch: 16 [5360/17352 (31%)] Loss: -188071.531250\n",
      "Train Epoch: 16 [5440/17352 (31%)] Loss: -185416.062500\n",
      "Train Epoch: 16 [5520/17352 (32%)] Loss: -190973.937500\n",
      "Train Epoch: 16 [5600/17352 (32%)] Loss: -182670.968750\n",
      "Train Epoch: 16 [5680/17352 (33%)] Loss: -183486.343750\n",
      "Train Epoch: 16 [5760/17352 (33%)] Loss: -180290.421875\n",
      "Train Epoch: 16 [5840/17352 (34%)] Loss: -189995.937500\n",
      "Train Epoch: 16 [5920/17352 (34%)] Loss: -204640.953125\n",
      "Train Epoch: 16 [6000/17352 (35%)] Loss: -187502.640625\n",
      "Train Epoch: 16 [6080/17352 (35%)] Loss: -187520.406250\n",
      "Train Epoch: 16 [6160/17352 (36%)] Loss: -200110.937500\n",
      "Train Epoch: 16 [6240/17352 (36%)] Loss: -185257.203125\n",
      "Train Epoch: 16 [6320/17352 (36%)] Loss: -171175.796875\n",
      "Train Epoch: 16 [6400/17352 (37%)] Loss: -193158.328125\n",
      "Train Epoch: 16 [6480/17352 (37%)] Loss: -188484.468750\n",
      "Train Epoch: 16 [6560/17352 (38%)] Loss: -174980.218750\n",
      "Train Epoch: 16 [6640/17352 (38%)] Loss: -208023.218750\n",
      "Train Epoch: 16 [6720/17352 (39%)] Loss: -174909.046875\n",
      "Train Epoch: 16 [6800/17352 (39%)] Loss: -187195.218750\n",
      "Train Epoch: 16 [6880/17352 (40%)] Loss: -202843.781250\n",
      "Train Epoch: 16 [6960/17352 (40%)] Loss: -175360.703125\n",
      "Train Epoch: 16 [7040/17352 (41%)] Loss: -176276.109375\n",
      "Train Epoch: 16 [7120/17352 (41%)] Loss: -177178.406250\n",
      "Train Epoch: 16 [7200/17352 (41%)] Loss: -177178.625000\n",
      "Train Epoch: 16 [7280/17352 (42%)] Loss: -185343.843750\n",
      "Train Epoch: 16 [7360/17352 (42%)] Loss: -152900.640625\n",
      "Train Epoch: 16 [7440/17352 (43%)] Loss: -200321.421875\n",
      "Train Epoch: 16 [7520/17352 (43%)] Loss: -189392.343750\n",
      "Train Epoch: 16 [7600/17352 (44%)] Loss: -207820.937500\n",
      "Train Epoch: 16 [7680/17352 (44%)] Loss: -225459.312500\n",
      "Train Epoch: 16 [7760/17352 (45%)] Loss: -178649.359375\n",
      "Train Epoch: 16 [7840/17352 (45%)] Loss: -193151.078125\n",
      "Train Epoch: 16 [7920/17352 (46%)] Loss: -185049.781250\n",
      "Train Epoch: 16 [8000/17352 (46%)] Loss: -168063.484375\n",
      "Train Epoch: 16 [8080/17352 (47%)] Loss: -193503.781250\n",
      "Train Epoch: 16 [8160/17352 (47%)] Loss: -185581.546875\n",
      "Train Epoch: 16 [8240/17352 (47%)] Loss: -178309.125000\n",
      "Train Epoch: 16 [8320/17352 (48%)] Loss: -176064.828125\n",
      "Train Epoch: 16 [8400/17352 (48%)] Loss: -178187.437500\n",
      "Train Epoch: 16 [8480/17352 (49%)] Loss: -178415.640625\n",
      "Train Epoch: 16 [8560/17352 (49%)] Loss: -174472.078125\n",
      "Train Epoch: 16 [8640/17352 (50%)] Loss: -195634.828125\n",
      "Train Epoch: 16 [8720/17352 (50%)] Loss: -186026.609375\n",
      "Train Epoch: 16 [8800/17352 (51%)] Loss: -178118.531250\n",
      "Train Epoch: 16 [8880/17352 (51%)] Loss: -167235.734375\n",
      "Train Epoch: 16 [8960/17352 (52%)] Loss: -192869.671875\n",
      "Train Epoch: 16 [9040/17352 (52%)] Loss: -209799.250000\n",
      "Train Epoch: 16 [9120/17352 (53%)] Loss: -184154.000000\n",
      "Train Epoch: 16 [9200/17352 (53%)] Loss: -202462.921875\n",
      "Train Epoch: 16 [9280/17352 (53%)] Loss: -208792.250000\n",
      "Train Epoch: 16 [9360/17352 (54%)] Loss: -196288.843750\n",
      "Train Epoch: 16 [9440/17352 (54%)] Loss: -164816.828125\n",
      "Train Epoch: 16 [9520/17352 (55%)] Loss: -164969.656250\n",
      "Train Epoch: 16 [9600/17352 (55%)] Loss: -144975.078125\n",
      "Train Epoch: 16 [9680/17352 (56%)] Loss: -184990.500000\n",
      "Train Epoch: 16 [9760/17352 (56%)] Loss: -191611.515625\n",
      "Train Epoch: 16 [9840/17352 (57%)] Loss: -165738.359375\n",
      "Train Epoch: 16 [9920/17352 (57%)] Loss: -166986.265625\n",
      "Train Epoch: 16 [10000/17352 (58%)] Loss: -174936.578125\n",
      "Train Epoch: 16 [10080/17352 (58%)] Loss: -192879.937500\n",
      "Train Epoch: 16 [10160/17352 (59%)] Loss: -157485.625000\n",
      "Train Epoch: 16 [10240/17352 (59%)] Loss: -163487.968750\n",
      "Train Epoch: 16 [10320/17352 (59%)] Loss: -181602.250000\n",
      "Train Epoch: 16 [10400/17352 (60%)] Loss: -190905.375000\n",
      "Train Epoch: 16 [10480/17352 (60%)] Loss: -181533.750000\n",
      "Train Epoch: 16 [10560/17352 (61%)] Loss: -208736.656250\n",
      "Train Epoch: 16 [10640/17352 (61%)] Loss: -197087.281250\n",
      "Train Epoch: 16 [10720/17352 (62%)] Loss: -177601.000000\n",
      "Train Epoch: 16 [10800/17352 (62%)] Loss: -183247.296875\n",
      "Train Epoch: 16 [10880/17352 (63%)] Loss: -198795.500000\n",
      "Train Epoch: 16 [10960/17352 (63%)] Loss: -179452.125000\n",
      "Train Epoch: 16 [11040/17352 (64%)] Loss: -210615.296875\n",
      "Train Epoch: 16 [11120/17352 (64%)] Loss: -203412.718750\n",
      "Train Epoch: 16 [11200/17352 (65%)] Loss: -185816.187500\n",
      "Train Epoch: 16 [11280/17352 (65%)] Loss: -220960.703125\n",
      "Train Epoch: 16 [11360/17352 (65%)] Loss: -202227.671875\n",
      "Train Epoch: 16 [11440/17352 (66%)] Loss: -199771.640625\n",
      "Train Epoch: 16 [11520/17352 (66%)] Loss: -187495.750000\n",
      "Train Epoch: 16 [11600/17352 (67%)] Loss: -201826.687500\n",
      "Train Epoch: 16 [11680/17352 (67%)] Loss: -181005.390625\n",
      "Train Epoch: 16 [11760/17352 (68%)] Loss: -192939.062500\n",
      "Train Epoch: 16 [11840/17352 (68%)] Loss: -188137.000000\n",
      "Train Epoch: 16 [11920/17352 (69%)] Loss: -187312.187500\n",
      "Train Epoch: 16 [12000/17352 (69%)] Loss: -186177.562500\n",
      "Train Epoch: 16 [12080/17352 (70%)] Loss: -176148.687500\n",
      "Train Epoch: 16 [12160/17352 (70%)] Loss: -208891.765625\n",
      "Train Epoch: 16 [12240/17352 (71%)] Loss: -192218.250000\n",
      "Train Epoch: 16 [12320/17352 (71%)] Loss: -184734.390625\n",
      "Train Epoch: 16 [12400/17352 (71%)] Loss: -167020.281250\n",
      "Train Epoch: 16 [12480/17352 (72%)] Loss: -199053.640625\n",
      "Train Epoch: 16 [12560/17352 (72%)] Loss: -180244.375000\n",
      "Train Epoch: 16 [12640/17352 (73%)] Loss: -188437.312500\n",
      "Train Epoch: 16 [12720/17352 (73%)] Loss: -188423.921875\n",
      "Train Epoch: 16 [12800/17352 (74%)] Loss: -182730.609375\n",
      "Train Epoch: 16 [12880/17352 (74%)] Loss: -192098.000000\n",
      "Train Epoch: 16 [12960/17352 (75%)] Loss: -164498.062500\n",
      "Train Epoch: 16 [13040/17352 (75%)] Loss: -159744.265625\n",
      "Train Epoch: 16 [13120/17352 (76%)] Loss: -188661.078125\n",
      "Train Epoch: 16 [13200/17352 (76%)] Loss: -186480.203125\n",
      "Train Epoch: 16 [13280/17352 (77%)] Loss: -174497.468750\n",
      "Train Epoch: 16 [13360/17352 (77%)] Loss: -193482.968750\n",
      "Train Epoch: 16 [13440/17352 (77%)] Loss: -189007.750000\n",
      "Train Epoch: 16 [13520/17352 (78%)] Loss: -180882.781250\n",
      "Train Epoch: 16 [13600/17352 (78%)] Loss: -204577.968750\n",
      "Train Epoch: 16 [13680/17352 (79%)] Loss: -204474.109375\n",
      "Train Epoch: 16 [13760/17352 (79%)] Loss: -186710.187500\n",
      "Train Epoch: 16 [13840/17352 (80%)] Loss: -170757.203125\n",
      "Train Epoch: 16 [13920/17352 (80%)] Loss: -186489.593750\n",
      "Train Epoch: 16 [14000/17352 (81%)] Loss: -95255.351562\n",
      "Train Epoch: 16 [14080/17352 (81%)] Loss: -198534.921875\n",
      "Train Epoch: 16 [14160/17352 (82%)] Loss: -168649.546875\n",
      "Train Epoch: 16 [14240/17352 (82%)] Loss: -197491.671875\n",
      "Train Epoch: 16 [14320/17352 (83%)] Loss: -187289.500000\n",
      "Train Epoch: 16 [14400/17352 (83%)] Loss: -173438.078125\n",
      "Train Epoch: 16 [14480/17352 (83%)] Loss: -160143.625000\n",
      "Train Epoch: 16 [14560/17352 (84%)] Loss: -173641.046875\n",
      "Train Epoch: 16 [14640/17352 (84%)] Loss: -174438.468750\n",
      "Train Epoch: 16 [14720/17352 (85%)] Loss: -185173.406250\n",
      "Train Epoch: 16 [14800/17352 (85%)] Loss: -191542.343750\n",
      "Train Epoch: 16 [14880/17352 (86%)] Loss: -203657.093750\n",
      "Train Epoch: 16 [14960/17352 (86%)] Loss: -180501.140625\n",
      "Train Epoch: 16 [15040/17352 (87%)] Loss: -216298.062500\n",
      "Train Epoch: 16 [15120/17352 (87%)] Loss: -187209.546875\n",
      "Train Epoch: 16 [15200/17352 (88%)] Loss: -183783.046875\n",
      "Train Epoch: 16 [15280/17352 (88%)] Loss: -161078.421875\n",
      "Train Epoch: 16 [15360/17352 (89%)] Loss: -201507.062500\n",
      "Train Epoch: 16 [15440/17352 (89%)] Loss: -186784.765625\n",
      "Train Epoch: 16 [15520/17352 (89%)] Loss: -161671.812500\n",
      "Train Epoch: 16 [15600/17352 (90%)] Loss: -228240.687500\n",
      "Train Epoch: 16 [15680/17352 (90%)] Loss: -184826.140625\n",
      "Train Epoch: 16 [15760/17352 (91%)] Loss: -192350.937500\n",
      "Train Epoch: 16 [15840/17352 (91%)] Loss: -177965.671875\n",
      "Train Epoch: 16 [15920/17352 (92%)] Loss: -191996.171875\n",
      "Train Epoch: 16 [16000/17352 (92%)] Loss: -207070.968750\n",
      "Train Epoch: 16 [16080/17352 (93%)] Loss: -183449.500000\n",
      "Train Epoch: 16 [16160/17352 (93%)] Loss: -164864.203125\n",
      "Train Epoch: 16 [16240/17352 (94%)] Loss: -179002.781250\n",
      "Train Epoch: 16 [16320/17352 (94%)] Loss: -203475.484375\n",
      "Train Epoch: 16 [16400/17352 (95%)] Loss: -164350.375000\n",
      "Train Epoch: 16 [16480/17352 (95%)] Loss: -188562.609375\n",
      "Train Epoch: 16 [16560/17352 (95%)] Loss: -165717.921875\n",
      "Train Epoch: 16 [16640/17352 (96%)] Loss: -179467.562500\n",
      "Train Epoch: 16 [16720/17352 (96%)] Loss: -180223.187500\n",
      "Train Epoch: 16 [16800/17352 (97%)] Loss: -179497.937500\n",
      "Train Epoch: 16 [16880/17352 (97%)] Loss: -198689.640625\n",
      "Train Epoch: 16 [16960/17352 (98%)] Loss: -201959.781250\n",
      "Train Epoch: 16 [17040/17352 (98%)] Loss: -184057.796875\n",
      "Train Epoch: 16 [17120/17352 (99%)] Loss: -191143.640625\n",
      "Train Epoch: 16 [17200/17352 (99%)] Loss: -185234.375000\n",
      "Train Epoch: 16 [17280/17352 (100%)] Loss: -159594.500000\n",
      "Train Epoch: 16 [17360/17352 (100%)] Loss: -192095.437500\n",
      "    epoch          : 16\n",
      "    loss           : -189326.0553168153\n",
      "    val_loss       : -23713.921550840278\n",
      "Train Epoch: 17 [0/17352 (0%)] Loss: -231323.625000\n",
      "Train Epoch: 17 [80/17352 (0%)] Loss: -186055.031250\n",
      "Train Epoch: 17 [160/17352 (1%)] Loss: -199102.437500\n",
      "Train Epoch: 17 [240/17352 (1%)] Loss: -222492.328125\n",
      "Train Epoch: 17 [320/17352 (2%)] Loss: -203732.937500\n",
      "Train Epoch: 17 [400/17352 (2%)] Loss: -212233.734375\n",
      "Train Epoch: 17 [480/17352 (3%)] Loss: -204010.687500\n",
      "Train Epoch: 17 [560/17352 (3%)] Loss: -199535.968750\n",
      "Train Epoch: 17 [640/17352 (4%)] Loss: -201647.062500\n",
      "Train Epoch: 17 [720/17352 (4%)] Loss: -193694.921875\n",
      "Train Epoch: 17 [800/17352 (5%)] Loss: -211867.437500\n",
      "Train Epoch: 17 [880/17352 (5%)] Loss: -206140.640625\n",
      "Train Epoch: 17 [960/17352 (6%)] Loss: -205912.968750\n",
      "Train Epoch: 17 [1040/17352 (6%)] Loss: -205066.593750\n",
      "Train Epoch: 17 [1120/17352 (6%)] Loss: -202317.453125\n",
      "Train Epoch: 17 [1200/17352 (7%)] Loss: -230176.906250\n",
      "Train Epoch: 17 [1280/17352 (7%)] Loss: -208363.828125\n",
      "Train Epoch: 17 [1360/17352 (8%)] Loss: -212373.828125\n",
      "Train Epoch: 17 [1440/17352 (8%)] Loss: -204723.781250\n",
      "Train Epoch: 17 [1520/17352 (9%)] Loss: -214491.921875\n",
      "Train Epoch: 17 [1600/17352 (9%)] Loss: -218542.703125\n",
      "Train Epoch: 17 [1680/17352 (10%)] Loss: -226095.234375\n",
      "Train Epoch: 17 [1760/17352 (10%)] Loss: -212688.218750\n",
      "Train Epoch: 17 [1840/17352 (11%)] Loss: -188735.171875\n",
      "Train Epoch: 17 [1920/17352 (11%)] Loss: -213319.937500\n",
      "Train Epoch: 17 [2000/17352 (12%)] Loss: -236821.968750\n",
      "Train Epoch: 17 [2080/17352 (12%)] Loss: -204510.859375\n",
      "Train Epoch: 17 [2160/17352 (12%)] Loss: -219247.578125\n",
      "Train Epoch: 17 [2240/17352 (13%)] Loss: -192004.000000\n",
      "Train Epoch: 17 [2320/17352 (13%)] Loss: -178121.500000\n",
      "Train Epoch: 17 [2400/17352 (14%)] Loss: -192991.140625\n",
      "Train Epoch: 17 [2480/17352 (14%)] Loss: -180999.062500\n",
      "Train Epoch: 17 [2560/17352 (15%)] Loss: -186147.281250\n",
      "Train Epoch: 17 [2640/17352 (15%)] Loss: -188486.921875\n",
      "Train Epoch: 17 [2720/17352 (16%)] Loss: -194941.890625\n",
      "Train Epoch: 17 [2800/17352 (16%)] Loss: -189203.390625\n",
      "Train Epoch: 17 [2880/17352 (17%)] Loss: -187437.984375\n",
      "Train Epoch: 17 [2960/17352 (17%)] Loss: -176902.671875\n",
      "Train Epoch: 17 [3040/17352 (18%)] Loss: -169928.875000\n",
      "Train Epoch: 17 [3120/17352 (18%)] Loss: -208329.859375\n",
      "Train Epoch: 17 [3200/17352 (18%)] Loss: -220953.000000\n",
      "Train Epoch: 17 [3280/17352 (19%)] Loss: -185302.765625\n",
      "Train Epoch: 17 [3360/17352 (19%)] Loss: -182910.421875\n",
      "Train Epoch: 17 [3440/17352 (20%)] Loss: -182733.109375\n",
      "Train Epoch: 17 [3520/17352 (20%)] Loss: -177226.843750\n",
      "Train Epoch: 17 [3600/17352 (21%)] Loss: -191499.781250\n",
      "Train Epoch: 17 [3680/17352 (21%)] Loss: -186662.343750\n",
      "Train Epoch: 17 [3760/17352 (22%)] Loss: -218515.609375\n",
      "Train Epoch: 17 [3840/17352 (22%)] Loss: -173911.375000\n",
      "Train Epoch: 17 [3920/17352 (23%)] Loss: -169607.203125\n",
      "Train Epoch: 17 [4000/17352 (23%)] Loss: -208405.375000\n",
      "Train Epoch: 17 [4080/17352 (24%)] Loss: -203264.734375\n",
      "Train Epoch: 17 [4160/17352 (24%)] Loss: -175348.031250\n",
      "Train Epoch: 17 [4240/17352 (24%)] Loss: -197286.656250\n",
      "Train Epoch: 17 [4320/17352 (25%)] Loss: -177949.625000\n",
      "Train Epoch: 17 [4400/17352 (25%)] Loss: -203728.625000\n",
      "Train Epoch: 17 [4480/17352 (26%)] Loss: -192253.796875\n",
      "Train Epoch: 17 [4560/17352 (26%)] Loss: -193248.453125\n",
      "Train Epoch: 17 [4640/17352 (27%)] Loss: -151493.281250\n",
      "Train Epoch: 17 [4720/17352 (27%)] Loss: -163336.328125\n",
      "Train Epoch: 17 [4800/17352 (28%)] Loss: -200463.218750\n",
      "Train Epoch: 17 [4880/17352 (28%)] Loss: -217613.859375\n",
      "Train Epoch: 17 [4960/17352 (29%)] Loss: -177585.500000\n",
      "Train Epoch: 17 [5040/17352 (29%)] Loss: -167132.218750\n",
      "Train Epoch: 17 [5120/17352 (30%)] Loss: -208721.109375\n",
      "Train Epoch: 17 [5200/17352 (30%)] Loss: -186834.640625\n",
      "Train Epoch: 17 [5280/17352 (30%)] Loss: -176474.656250\n",
      "Train Epoch: 17 [5360/17352 (31%)] Loss: -176074.671875\n",
      "Train Epoch: 17 [5440/17352 (31%)] Loss: -183251.375000\n",
      "Train Epoch: 17 [5520/17352 (32%)] Loss: -199786.390625\n",
      "Train Epoch: 17 [5600/17352 (32%)] Loss: -199708.015625\n",
      "Train Epoch: 17 [5680/17352 (33%)] Loss: -156595.968750\n",
      "Train Epoch: 17 [5760/17352 (33%)] Loss: -185274.046875\n",
      "Train Epoch: 17 [5840/17352 (34%)] Loss: -193183.015625\n",
      "Train Epoch: 17 [5920/17352 (34%)] Loss: -177758.734375\n",
      "Train Epoch: 17 [6000/17352 (35%)] Loss: -201294.796875\n",
      "Train Epoch: 17 [6080/17352 (35%)] Loss: -189602.984375\n",
      "Train Epoch: 17 [6160/17352 (36%)] Loss: -191300.109375\n",
      "Train Epoch: 17 [6240/17352 (36%)] Loss: -209256.000000\n",
      "Train Epoch: 17 [6320/17352 (36%)] Loss: -188184.390625\n",
      "Train Epoch: 17 [6400/17352 (37%)] Loss: -176680.500000\n",
      "Train Epoch: 17 [6480/17352 (37%)] Loss: -180046.500000\n",
      "Train Epoch: 17 [6560/17352 (38%)] Loss: -188431.500000\n",
      "Train Epoch: 17 [6640/17352 (38%)] Loss: -203851.265625\n",
      "Train Epoch: 17 [6720/17352 (39%)] Loss: -178865.359375\n",
      "Train Epoch: 17 [6800/17352 (39%)] Loss: -159604.156250\n",
      "Train Epoch: 17 [6880/17352 (40%)] Loss: -181659.140625\n",
      "Train Epoch: 17 [6960/17352 (40%)] Loss: -199888.578125\n",
      "Train Epoch: 17 [7040/17352 (41%)] Loss: -210250.953125\n",
      "Train Epoch: 17 [7120/17352 (41%)] Loss: -168035.312500\n",
      "Train Epoch: 17 [7200/17352 (41%)] Loss: -148916.250000\n",
      "Train Epoch: 17 [7280/17352 (42%)] Loss: -169493.187500\n",
      "Train Epoch: 17 [7360/17352 (42%)] Loss: -183044.109375\n",
      "Train Epoch: 17 [7440/17352 (43%)] Loss: -208702.125000\n",
      "Train Epoch: 17 [7520/17352 (43%)] Loss: -193126.468750\n",
      "Train Epoch: 17 [7600/17352 (44%)] Loss: -180291.078125\n",
      "Train Epoch: 17 [7680/17352 (44%)] Loss: -178806.578125\n",
      "Train Epoch: 17 [7760/17352 (45%)] Loss: -176022.156250\n",
      "Train Epoch: 17 [7840/17352 (45%)] Loss: -178200.140625\n",
      "Train Epoch: 17 [7920/17352 (46%)] Loss: -157481.218750\n",
      "Train Epoch: 17 [8000/17352 (46%)] Loss: -167035.437500\n",
      "Train Epoch: 17 [8080/17352 (47%)] Loss: -181350.578125\n",
      "Train Epoch: 17 [8160/17352 (47%)] Loss: -148390.093750\n",
      "Train Epoch: 17 [8240/17352 (47%)] Loss: -182517.312500\n",
      "Train Epoch: 17 [8320/17352 (48%)] Loss: -179655.234375\n",
      "Train Epoch: 17 [8400/17352 (48%)] Loss: -206215.718750\n",
      "Train Epoch: 17 [8480/17352 (49%)] Loss: -206903.515625\n",
      "Train Epoch: 17 [8560/17352 (49%)] Loss: -183613.109375\n",
      "Train Epoch: 17 [8640/17352 (50%)] Loss: -196010.312500\n",
      "Train Epoch: 17 [8720/17352 (50%)] Loss: -194053.921875\n",
      "Train Epoch: 17 [8800/17352 (51%)] Loss: -210248.046875\n",
      "Train Epoch: 17 [8880/17352 (51%)] Loss: -195866.750000\n",
      "Train Epoch: 17 [8960/17352 (52%)] Loss: -171896.546875\n",
      "Train Epoch: 17 [9040/17352 (52%)] Loss: -184474.640625\n",
      "Train Epoch: 17 [9120/17352 (53%)] Loss: -193527.312500\n",
      "Train Epoch: 17 [9200/17352 (53%)] Loss: -205724.187500\n",
      "Train Epoch: 17 [9280/17352 (53%)] Loss: -208301.250000\n",
      "Train Epoch: 17 [9360/17352 (54%)] Loss: -201364.625000\n",
      "Train Epoch: 17 [9440/17352 (54%)] Loss: -163541.781250\n",
      "Train Epoch: 17 [9520/17352 (55%)] Loss: -213734.890625\n",
      "Train Epoch: 17 [9600/17352 (55%)] Loss: -164945.250000\n",
      "Train Epoch: 17 [9680/17352 (56%)] Loss: -187302.453125\n",
      "Train Epoch: 17 [9760/17352 (56%)] Loss: -166399.328125\n",
      "Train Epoch: 17 [9840/17352 (57%)] Loss: -172534.609375\n",
      "Train Epoch: 17 [9920/17352 (57%)] Loss: -202223.234375\n",
      "Train Epoch: 17 [10000/17352 (58%)] Loss: -202505.406250\n",
      "Train Epoch: 17 [10080/17352 (58%)] Loss: -206455.421875\n",
      "Train Epoch: 17 [10160/17352 (59%)] Loss: -204924.765625\n",
      "Train Epoch: 17 [10240/17352 (59%)] Loss: -203801.656250\n",
      "Train Epoch: 17 [10320/17352 (59%)] Loss: -183596.890625\n",
      "Train Epoch: 17 [10400/17352 (60%)] Loss: -197936.031250\n",
      "Train Epoch: 17 [10480/17352 (60%)] Loss: -199162.750000\n",
      "Train Epoch: 17 [10560/17352 (61%)] Loss: -183276.437500\n",
      "Train Epoch: 17 [10640/17352 (61%)] Loss: -188259.609375\n",
      "Train Epoch: 17 [10720/17352 (62%)] Loss: -163111.500000\n",
      "Train Epoch: 17 [10800/17352 (62%)] Loss: -179912.156250\n",
      "Train Epoch: 17 [10880/17352 (63%)] Loss: -149014.765625\n",
      "Train Epoch: 17 [10960/17352 (63%)] Loss: -200413.625000\n",
      "Train Epoch: 17 [11040/17352 (64%)] Loss: -228078.093750\n",
      "Train Epoch: 17 [11120/17352 (64%)] Loss: -185562.437500\n",
      "Train Epoch: 17 [11200/17352 (65%)] Loss: -185044.093750\n",
      "Train Epoch: 17 [11280/17352 (65%)] Loss: -178715.109375\n",
      "Train Epoch: 17 [11360/17352 (65%)] Loss: -216377.859375\n",
      "Train Epoch: 17 [11440/17352 (66%)] Loss: -215627.750000\n",
      "Train Epoch: 17 [11520/17352 (66%)] Loss: -186924.312500\n",
      "Train Epoch: 17 [11600/17352 (67%)] Loss: -181943.953125\n",
      "Train Epoch: 17 [11680/17352 (67%)] Loss: -165792.515625\n",
      "Train Epoch: 17 [11760/17352 (68%)] Loss: -190899.812500\n",
      "Train Epoch: 17 [11840/17352 (68%)] Loss: -185227.031250\n",
      "Train Epoch: 17 [11920/17352 (69%)] Loss: -208803.187500\n",
      "Train Epoch: 17 [12000/17352 (69%)] Loss: -199796.468750\n",
      "Train Epoch: 17 [12080/17352 (70%)] Loss: -205005.656250\n",
      "Train Epoch: 17 [12160/17352 (70%)] Loss: -196812.937500\n",
      "Train Epoch: 17 [12240/17352 (71%)] Loss: -177265.234375\n",
      "Train Epoch: 17 [12320/17352 (71%)] Loss: -184728.750000\n",
      "Train Epoch: 17 [12400/17352 (71%)] Loss: -183854.968750\n",
      "Train Epoch: 17 [12480/17352 (72%)] Loss: -183069.640625\n",
      "Train Epoch: 17 [12560/17352 (72%)] Loss: -197371.640625\n",
      "Train Epoch: 17 [12640/17352 (73%)] Loss: -197428.968750\n",
      "Train Epoch: 17 [12720/17352 (73%)] Loss: -159672.718750\n",
      "Train Epoch: 17 [12800/17352 (74%)] Loss: -180821.156250\n",
      "Train Epoch: 17 [12880/17352 (74%)] Loss: -200287.015625\n",
      "Train Epoch: 17 [12960/17352 (75%)] Loss: -174510.468750\n",
      "Train Epoch: 17 [13040/17352 (75%)] Loss: -166546.703125\n",
      "Train Epoch: 17 [13120/17352 (76%)] Loss: -203474.031250\n",
      "Train Epoch: 17 [13200/17352 (76%)] Loss: -191701.218750\n",
      "Train Epoch: 17 [13280/17352 (77%)] Loss: -190004.859375\n",
      "Train Epoch: 17 [13360/17352 (77%)] Loss: -183714.734375\n",
      "Train Epoch: 17 [13440/17352 (77%)] Loss: -178632.093750\n",
      "Train Epoch: 17 [13520/17352 (78%)] Loss: -180779.921875\n",
      "Train Epoch: 17 [13600/17352 (78%)] Loss: -163203.500000\n",
      "Train Epoch: 17 [13680/17352 (79%)] Loss: -189711.453125\n",
      "Train Epoch: 17 [13760/17352 (79%)] Loss: -186190.109375\n",
      "Train Epoch: 17 [13840/17352 (80%)] Loss: -153877.484375\n",
      "Train Epoch: 17 [13920/17352 (80%)] Loss: -180260.640625\n",
      "Train Epoch: 17 [14000/17352 (81%)] Loss: -207853.640625\n",
      "Train Epoch: 17 [14080/17352 (81%)] Loss: -156464.578125\n",
      "Train Epoch: 17 [14160/17352 (82%)] Loss: -198241.062500\n",
      "Train Epoch: 17 [14240/17352 (82%)] Loss: -178419.875000\n",
      "Train Epoch: 17 [14320/17352 (83%)] Loss: -200163.500000\n",
      "Train Epoch: 17 [14400/17352 (83%)] Loss: -196113.046875\n",
      "Train Epoch: 17 [14480/17352 (83%)] Loss: -201108.125000\n",
      "Train Epoch: 17 [14560/17352 (84%)] Loss: -184950.343750\n",
      "Train Epoch: 17 [14640/17352 (84%)] Loss: -192972.031250\n",
      "Train Epoch: 17 [14720/17352 (85%)] Loss: -184821.687500\n",
      "Train Epoch: 17 [14800/17352 (85%)] Loss: -204357.125000\n",
      "Train Epoch: 17 [14880/17352 (86%)] Loss: -183203.468750\n",
      "Train Epoch: 17 [14960/17352 (86%)] Loss: -206584.687500\n",
      "Train Epoch: 17 [15040/17352 (87%)] Loss: -165752.578125\n",
      "Train Epoch: 17 [15120/17352 (87%)] Loss: -203667.125000\n",
      "Train Epoch: 17 [15200/17352 (88%)] Loss: -174028.296875\n",
      "Train Epoch: 17 [15280/17352 (88%)] Loss: -188666.859375\n",
      "Train Epoch: 17 [15360/17352 (89%)] Loss: -190493.281250\n",
      "Train Epoch: 17 [15440/17352 (89%)] Loss: -188557.359375\n",
      "Train Epoch: 17 [15520/17352 (89%)] Loss: -223948.312500\n",
      "Train Epoch: 17 [15600/17352 (90%)] Loss: -214632.109375\n",
      "Train Epoch: 17 [15680/17352 (90%)] Loss: -178661.078125\n",
      "Train Epoch: 17 [15760/17352 (91%)] Loss: -205483.515625\n",
      "Train Epoch: 17 [15840/17352 (91%)] Loss: -219998.218750\n",
      "Train Epoch: 17 [15920/17352 (92%)] Loss: -210622.640625\n",
      "Train Epoch: 17 [16000/17352 (92%)] Loss: -192773.890625\n",
      "Train Epoch: 17 [16080/17352 (93%)] Loss: -195499.921875\n",
      "Train Epoch: 17 [16160/17352 (93%)] Loss: -189273.328125\n",
      "Train Epoch: 17 [16240/17352 (94%)] Loss: -185328.125000\n",
      "Train Epoch: 17 [16320/17352 (94%)] Loss: -159720.500000\n",
      "Train Epoch: 17 [16400/17352 (95%)] Loss: -168246.703125\n",
      "Train Epoch: 17 [16480/17352 (95%)] Loss: -219918.421875\n",
      "Train Epoch: 17 [16560/17352 (95%)] Loss: -198533.656250\n",
      "Train Epoch: 17 [16640/17352 (96%)] Loss: -154581.656250\n",
      "Train Epoch: 17 [16720/17352 (96%)] Loss: -180895.031250\n",
      "Train Epoch: 17 [16800/17352 (97%)] Loss: -205205.281250\n",
      "Train Epoch: 17 [16880/17352 (97%)] Loss: -173578.343750\n",
      "Train Epoch: 17 [16960/17352 (98%)] Loss: -196693.203125\n",
      "Train Epoch: 17 [17040/17352 (98%)] Loss: -191788.015625\n",
      "Train Epoch: 17 [17120/17352 (99%)] Loss: -204335.531250\n",
      "Train Epoch: 17 [17200/17352 (99%)] Loss: -194580.125000\n",
      "Train Epoch: 17 [17280/17352 (100%)] Loss: -210774.937500\n",
      "Train Epoch: 17 [17360/17352 (100%)] Loss: -187354.500000\n",
      "    epoch          : 17\n",
      "    loss           : -189091.6177718642\n",
      "    val_loss       : -23713.904326891115\n",
      "Train Epoch: 18 [0/17352 (0%)] Loss: -193021.281250\n",
      "Train Epoch: 18 [80/17352 (0%)] Loss: -205184.625000\n",
      "Train Epoch: 18 [160/17352 (1%)] Loss: -187691.406250\n",
      "Train Epoch: 18 [240/17352 (1%)] Loss: -217620.296875\n",
      "Train Epoch: 18 [320/17352 (2%)] Loss: -210344.031250\n",
      "Train Epoch: 18 [400/17352 (2%)] Loss: -203248.703125\n",
      "Train Epoch: 18 [480/17352 (3%)] Loss: -213337.109375\n",
      "Train Epoch: 18 [560/17352 (3%)] Loss: -199910.156250\n",
      "Train Epoch: 18 [640/17352 (4%)] Loss: -200585.062500\n",
      "Train Epoch: 18 [720/17352 (4%)] Loss: -226076.656250\n",
      "Train Epoch: 18 [800/17352 (5%)] Loss: -205205.156250\n",
      "Train Epoch: 18 [880/17352 (5%)] Loss: -185141.687500\n",
      "Train Epoch: 18 [960/17352 (6%)] Loss: -213309.500000\n",
      "Train Epoch: 18 [1040/17352 (6%)] Loss: -191868.171875\n",
      "Train Epoch: 18 [1120/17352 (6%)] Loss: -222520.031250\n",
      "Train Epoch: 18 [1200/17352 (7%)] Loss: -196915.375000\n",
      "Train Epoch: 18 [1280/17352 (7%)] Loss: -236503.390625\n",
      "Train Epoch: 18 [1360/17352 (8%)] Loss: -228010.968750\n",
      "Train Epoch: 18 [1440/17352 (8%)] Loss: -214518.546875\n",
      "Train Epoch: 18 [1520/17352 (9%)] Loss: -211896.656250\n",
      "Train Epoch: 18 [1600/17352 (9%)] Loss: -221460.218750\n",
      "Train Epoch: 18 [1680/17352 (10%)] Loss: -224343.140625\n",
      "Train Epoch: 18 [1760/17352 (10%)] Loss: -206779.609375\n",
      "Train Epoch: 18 [1840/17352 (11%)] Loss: -212396.718750\n",
      "Train Epoch: 18 [1920/17352 (11%)] Loss: -219239.343750\n",
      "Train Epoch: 18 [2000/17352 (12%)] Loss: -193569.406250\n",
      "Train Epoch: 18 [2080/17352 (12%)] Loss: -213312.640625\n",
      "Train Epoch: 18 [2160/17352 (12%)] Loss: -209551.515625\n",
      "Train Epoch: 18 [2240/17352 (13%)] Loss: -175388.171875\n",
      "Train Epoch: 18 [2320/17352 (13%)] Loss: -148155.234375\n",
      "Train Epoch: 18 [2400/17352 (14%)] Loss: -193157.218750\n",
      "Train Epoch: 18 [2480/17352 (14%)] Loss: -189713.843750\n",
      "Train Epoch: 18 [2560/17352 (15%)] Loss: -199886.000000\n",
      "Train Epoch: 18 [2640/17352 (15%)] Loss: -184962.500000\n",
      "Train Epoch: 18 [2720/17352 (16%)] Loss: -189002.375000\n",
      "Train Epoch: 18 [2800/17352 (16%)] Loss: -203256.687500\n",
      "Train Epoch: 18 [2880/17352 (17%)] Loss: -217595.531250\n",
      "Train Epoch: 18 [2960/17352 (17%)] Loss: -181324.656250\n",
      "Train Epoch: 18 [3040/17352 (18%)] Loss: -171883.375000\n",
      "Train Epoch: 18 [3120/17352 (18%)] Loss: -174969.500000\n",
      "Train Epoch: 18 [3200/17352 (18%)] Loss: -176579.906250\n",
      "Train Epoch: 18 [3280/17352 (19%)] Loss: -213394.359375\n",
      "Train Epoch: 18 [3360/17352 (19%)] Loss: -183773.312500\n",
      "Train Epoch: 18 [3440/17352 (20%)] Loss: -178309.531250\n",
      "Train Epoch: 18 [3520/17352 (20%)] Loss: -176866.000000\n",
      "Train Epoch: 18 [3600/17352 (21%)] Loss: -172543.406250\n",
      "Train Epoch: 18 [3680/17352 (21%)] Loss: -205803.421875\n",
      "Train Epoch: 18 [3760/17352 (22%)] Loss: -174999.093750\n",
      "Train Epoch: 18 [3840/17352 (22%)] Loss: -152903.546875\n",
      "Train Epoch: 18 [3920/17352 (23%)] Loss: -192776.031250\n",
      "Train Epoch: 18 [4000/17352 (23%)] Loss: -210783.609375\n",
      "Train Epoch: 18 [4080/17352 (24%)] Loss: -169928.953125\n",
      "Train Epoch: 18 [4160/17352 (24%)] Loss: -179497.734375\n",
      "Train Epoch: 18 [4240/17352 (24%)] Loss: -193489.890625\n",
      "Train Epoch: 18 [4320/17352 (25%)] Loss: -191149.343750\n",
      "Train Epoch: 18 [4400/17352 (25%)] Loss: -166536.437500\n",
      "Train Epoch: 18 [4480/17352 (26%)] Loss: -169479.015625\n",
      "Train Epoch: 18 [4560/17352 (26%)] Loss: -192299.156250\n",
      "Train Epoch: 18 [4640/17352 (27%)] Loss: -192988.343750\n",
      "Train Epoch: 18 [4720/17352 (27%)] Loss: -185800.171875\n",
      "Train Epoch: 18 [4800/17352 (28%)] Loss: -187588.734375\n",
      "Train Epoch: 18 [4880/17352 (28%)] Loss: -180900.906250\n",
      "Train Epoch: 18 [4960/17352 (29%)] Loss: -146835.671875\n",
      "Train Epoch: 18 [5040/17352 (29%)] Loss: -188075.453125\n",
      "Train Epoch: 18 [5120/17352 (30%)] Loss: -209267.203125\n",
      "Train Epoch: 18 [5200/17352 (30%)] Loss: -156458.375000\n",
      "Train Epoch: 18 [5280/17352 (30%)] Loss: -196018.781250\n",
      "Train Epoch: 18 [5360/17352 (31%)] Loss: -199006.875000\n",
      "Train Epoch: 18 [5440/17352 (31%)] Loss: -171306.890625\n",
      "Train Epoch: 18 [5520/17352 (32%)] Loss: -177126.781250\n",
      "Train Epoch: 18 [5600/17352 (32%)] Loss: -187987.406250\n",
      "Train Epoch: 18 [5680/17352 (33%)] Loss: -210248.187500\n",
      "Train Epoch: 18 [5760/17352 (33%)] Loss: -180035.234375\n",
      "Train Epoch: 18 [5840/17352 (34%)] Loss: -191348.281250\n",
      "Train Epoch: 18 [5920/17352 (34%)] Loss: -186174.875000\n",
      "Train Epoch: 18 [6000/17352 (35%)] Loss: -188047.125000\n",
      "Train Epoch: 18 [6080/17352 (35%)] Loss: -167473.203125\n",
      "Train Epoch: 18 [6160/17352 (36%)] Loss: -208745.468750\n",
      "Train Epoch: 18 [6240/17352 (36%)] Loss: -169736.984375\n",
      "Train Epoch: 18 [6320/17352 (36%)] Loss: -208786.562500\n",
      "Train Epoch: 18 [6400/17352 (37%)] Loss: -178802.171875\n",
      "Train Epoch: 18 [6480/17352 (37%)] Loss: -192888.593750\n",
      "Train Epoch: 18 [6560/17352 (38%)] Loss: -202770.453125\n",
      "Train Epoch: 18 [6640/17352 (38%)] Loss: -177468.156250\n",
      "Train Epoch: 18 [6720/17352 (39%)] Loss: -173563.687500\n",
      "Train Epoch: 18 [6800/17352 (39%)] Loss: -164864.437500\n",
      "Train Epoch: 18 [6880/17352 (40%)] Loss: -189285.109375\n",
      "Train Epoch: 18 [6960/17352 (40%)] Loss: -170766.265625\n",
      "Train Epoch: 18 [7040/17352 (41%)] Loss: -188942.625000\n",
      "Train Epoch: 18 [7120/17352 (41%)] Loss: -178188.687500\n",
      "Train Epoch: 18 [7200/17352 (41%)] Loss: -188559.828125\n",
      "Train Epoch: 18 [7280/17352 (42%)] Loss: -185994.078125\n",
      "Train Epoch: 18 [7360/17352 (42%)] Loss: -167246.250000\n",
      "Train Epoch: 18 [7440/17352 (43%)] Loss: -200208.890625\n",
      "Train Epoch: 18 [7520/17352 (43%)] Loss: -175661.093750\n",
      "Train Epoch: 18 [7600/17352 (44%)] Loss: -161507.843750\n",
      "Train Epoch: 18 [7680/17352 (44%)] Loss: -204591.187500\n",
      "Train Epoch: 18 [7760/17352 (45%)] Loss: -173652.671875\n",
      "Train Epoch: 18 [7840/17352 (45%)] Loss: -188443.343750\n",
      "Train Epoch: 18 [7920/17352 (46%)] Loss: -200114.109375\n",
      "Train Epoch: 18 [8000/17352 (46%)] Loss: -195829.093750\n",
      "Train Epoch: 18 [8080/17352 (47%)] Loss: -222845.156250\n",
      "Train Epoch: 18 [8160/17352 (47%)] Loss: -206461.796875\n",
      "Train Epoch: 18 [8240/17352 (47%)] Loss: -189550.859375\n",
      "Train Epoch: 18 [8320/17352 (48%)] Loss: -201816.312500\n",
      "Train Epoch: 18 [8400/17352 (48%)] Loss: -159742.843750\n",
      "Train Epoch: 18 [8480/17352 (49%)] Loss: -218826.281250\n",
      "Train Epoch: 18 [8560/17352 (49%)] Loss: -195057.796875\n",
      "Train Epoch: 18 [8640/17352 (50%)] Loss: -180033.546875\n",
      "Train Epoch: 18 [8720/17352 (50%)] Loss: -176012.828125\n",
      "Train Epoch: 18 [8800/17352 (51%)] Loss: -180870.640625\n",
      "Train Epoch: 18 [8880/17352 (51%)] Loss: -186488.171875\n",
      "Train Epoch: 18 [8960/17352 (52%)] Loss: -180635.875000\n",
      "Train Epoch: 18 [9040/17352 (52%)] Loss: -181539.937500\n",
      "Train Epoch: 18 [9120/17352 (53%)] Loss: -190502.296875\n",
      "Train Epoch: 18 [9200/17352 (53%)] Loss: -200823.703125\n",
      "Train Epoch: 18 [9280/17352 (53%)] Loss: -201380.859375\n",
      "Train Epoch: 18 [9360/17352 (54%)] Loss: -184993.656250\n",
      "Train Epoch: 18 [9440/17352 (54%)] Loss: -202989.203125\n",
      "Train Epoch: 18 [9520/17352 (55%)] Loss: -167230.500000\n",
      "Train Epoch: 18 [9600/17352 (55%)] Loss: -206192.937500\n",
      "Train Epoch: 18 [9680/17352 (56%)] Loss: -175655.906250\n",
      "Train Epoch: 18 [9760/17352 (56%)] Loss: -189256.500000\n",
      "Train Epoch: 18 [9840/17352 (57%)] Loss: -179027.593750\n",
      "Train Epoch: 18 [9920/17352 (57%)] Loss: -206915.218750\n",
      "Train Epoch: 18 [10000/17352 (58%)] Loss: -165348.468750\n",
      "Train Epoch: 18 [10080/17352 (58%)] Loss: -217613.406250\n",
      "Train Epoch: 18 [10160/17352 (59%)] Loss: -177445.593750\n",
      "Train Epoch: 18 [10240/17352 (59%)] Loss: -173120.921875\n",
      "Train Epoch: 18 [10320/17352 (59%)] Loss: -202230.031250\n",
      "Train Epoch: 18 [10400/17352 (60%)] Loss: -163099.250000\n",
      "Train Epoch: 18 [10480/17352 (60%)] Loss: -180505.890625\n",
      "Train Epoch: 18 [10560/17352 (61%)] Loss: -174035.093750\n",
      "Train Epoch: 18 [10640/17352 (61%)] Loss: -200415.687500\n",
      "Train Epoch: 18 [10720/17352 (62%)] Loss: -180832.859375\n",
      "Train Epoch: 18 [10800/17352 (62%)] Loss: -186684.109375\n",
      "Train Epoch: 18 [10880/17352 (63%)] Loss: -170657.703125\n",
      "Train Epoch: 18 [10960/17352 (63%)] Loss: -183044.031250\n",
      "Train Epoch: 18 [11040/17352 (64%)] Loss: -170765.265625\n",
      "Train Epoch: 18 [11120/17352 (64%)] Loss: -189477.625000\n",
      "Train Epoch: 18 [11200/17352 (65%)] Loss: -183260.500000\n",
      "Train Epoch: 18 [11280/17352 (65%)] Loss: -160092.296875\n",
      "Train Epoch: 18 [11360/17352 (65%)] Loss: -171426.125000\n",
      "Train Epoch: 18 [11440/17352 (66%)] Loss: -174922.187500\n",
      "Train Epoch: 18 [11520/17352 (66%)] Loss: -170240.562500\n",
      "Train Epoch: 18 [11600/17352 (67%)] Loss: -192994.718750\n",
      "Train Epoch: 18 [11680/17352 (67%)] Loss: -159599.687500\n",
      "Train Epoch: 18 [11760/17352 (68%)] Loss: -178571.843750\n",
      "Train Epoch: 18 [11840/17352 (68%)] Loss: -174494.171875\n",
      "Train Epoch: 18 [11920/17352 (69%)] Loss: -197427.718750\n",
      "Train Epoch: 18 [12000/17352 (69%)] Loss: -178202.343750\n",
      "Train Epoch: 18 [12080/17352 (70%)] Loss: -192672.906250\n",
      "Train Epoch: 18 [12160/17352 (70%)] Loss: -167200.906250\n",
      "Train Epoch: 18 [12240/17352 (71%)] Loss: -197087.515625\n",
      "Train Epoch: 18 [12320/17352 (71%)] Loss: -181414.265625\n",
      "Train Epoch: 18 [12400/17352 (71%)] Loss: -204873.046875\n",
      "Train Epoch: 18 [12480/17352 (72%)] Loss: -188701.000000\n",
      "Train Epoch: 18 [12560/17352 (72%)] Loss: -197580.156250\n",
      "Train Epoch: 18 [12640/17352 (73%)] Loss: -188660.093750\n",
      "Train Epoch: 18 [12720/17352 (73%)] Loss: -187052.125000\n",
      "Train Epoch: 18 [12800/17352 (74%)] Loss: -184455.375000\n",
      "Train Epoch: 18 [12880/17352 (74%)] Loss: -185978.765625\n",
      "Train Epoch: 18 [12960/17352 (75%)] Loss: -163055.781250\n",
      "Train Epoch: 18 [13040/17352 (75%)] Loss: -193853.859375\n",
      "Train Epoch: 18 [13120/17352 (76%)] Loss: -136405.109375\n",
      "Train Epoch: 18 [13200/17352 (76%)] Loss: -201972.890625\n",
      "Train Epoch: 18 [13280/17352 (77%)] Loss: -171810.109375\n",
      "Train Epoch: 18 [13360/17352 (77%)] Loss: -174408.546875\n",
      "Train Epoch: 18 [13440/17352 (77%)] Loss: -188407.812500\n",
      "Train Epoch: 18 [13520/17352 (78%)] Loss: -186835.250000\n",
      "Train Epoch: 18 [13600/17352 (78%)] Loss: -212948.609375\n",
      "Train Epoch: 18 [13680/17352 (79%)] Loss: -180667.187500\n",
      "Train Epoch: 18 [13760/17352 (79%)] Loss: -182487.984375\n",
      "Train Epoch: 18 [13840/17352 (80%)] Loss: -196266.171875\n",
      "Train Epoch: 18 [13920/17352 (80%)] Loss: -201926.593750\n",
      "Train Epoch: 18 [14000/17352 (81%)] Loss: -191621.984375\n",
      "Train Epoch: 18 [14080/17352 (81%)] Loss: -191976.515625\n",
      "Train Epoch: 18 [14160/17352 (82%)] Loss: -208319.343750\n",
      "Train Epoch: 18 [14240/17352 (82%)] Loss: -193490.218750\n",
      "Train Epoch: 18 [14320/17352 (83%)] Loss: -189138.453125\n",
      "Train Epoch: 18 [14400/17352 (83%)] Loss: -171202.421875\n",
      "Train Epoch: 18 [14480/17352 (83%)] Loss: -179901.156250\n",
      "Train Epoch: 18 [14560/17352 (84%)] Loss: -163469.406250\n",
      "Train Epoch: 18 [14640/17352 (84%)] Loss: -172186.140625\n",
      "Train Epoch: 18 [14720/17352 (85%)] Loss: -164361.187500\n",
      "Train Epoch: 18 [14800/17352 (85%)] Loss: -179657.921875\n",
      "Train Epoch: 18 [14880/17352 (86%)] Loss: -169431.921875\n",
      "Train Epoch: 18 [14960/17352 (86%)] Loss: -192630.187500\n",
      "Train Epoch: 18 [15040/17352 (87%)] Loss: -177588.265625\n",
      "Train Epoch: 18 [15120/17352 (87%)] Loss: -208405.328125\n",
      "Train Epoch: 18 [15200/17352 (88%)] Loss: -191326.359375\n",
      "Train Epoch: 18 [15280/17352 (88%)] Loss: -196720.718750\n",
      "Train Epoch: 18 [15360/17352 (89%)] Loss: -163229.359375\n",
      "Train Epoch: 18 [15440/17352 (89%)] Loss: -202451.312500\n",
      "Train Epoch: 18 [15520/17352 (89%)] Loss: -184726.718750\n",
      "Train Epoch: 18 [15600/17352 (90%)] Loss: -178583.093750\n",
      "Train Epoch: 18 [15680/17352 (90%)] Loss: -193350.343750\n",
      "Train Epoch: 18 [15760/17352 (91%)] Loss: -168172.734375\n",
      "Train Epoch: 18 [15840/17352 (91%)] Loss: -193480.765625\n",
      "Train Epoch: 18 [15920/17352 (92%)] Loss: -179426.656250\n",
      "Train Epoch: 18 [16000/17352 (92%)] Loss: -186404.812500\n",
      "Train Epoch: 18 [16080/17352 (93%)] Loss: -208704.609375\n",
      "Train Epoch: 18 [16160/17352 (93%)] Loss: -218443.718750\n",
      "Train Epoch: 18 [16240/17352 (94%)] Loss: -185915.109375\n",
      "Train Epoch: 18 [16320/17352 (94%)] Loss: -173873.312500\n",
      "Train Epoch: 18 [16400/17352 (95%)] Loss: -190567.343750\n",
      "Train Epoch: 18 [16480/17352 (95%)] Loss: -160042.062500\n",
      "Train Epoch: 18 [16560/17352 (95%)] Loss: -154596.359375\n",
      "Train Epoch: 18 [16640/17352 (96%)] Loss: -177288.312500\n",
      "Train Epoch: 18 [16720/17352 (96%)] Loss: -185350.062500\n",
      "Train Epoch: 18 [16800/17352 (97%)] Loss: -179391.390625\n",
      "Train Epoch: 18 [16880/17352 (97%)] Loss: -206198.968750\n",
      "Train Epoch: 18 [16960/17352 (98%)] Loss: -185787.703125\n",
      "Train Epoch: 18 [17040/17352 (98%)] Loss: -198000.718750\n",
      "Train Epoch: 18 [17120/17352 (99%)] Loss: -183284.796875\n",
      "Train Epoch: 18 [17200/17352 (99%)] Loss: -183209.125000\n",
      "Train Epoch: 18 [17280/17352 (100%)] Loss: -149025.265625\n",
      "Train Epoch: 18 [17360/17352 (100%)] Loss: -215948.609375\n",
      "    epoch          : 18\n",
      "    loss           : -189059.82568865074\n",
      "    val_loss       : -23713.95144230659\n",
      "Train Epoch: 19 [0/17352 (0%)] Loss: -205182.000000\n",
      "Train Epoch: 19 [80/17352 (0%)] Loss: -233719.968750\n",
      "Train Epoch: 19 [160/17352 (1%)] Loss: -186051.406250\n",
      "Train Epoch: 19 [240/17352 (1%)] Loss: -217603.812500\n",
      "Train Epoch: 19 [320/17352 (2%)] Loss: -212377.671875\n",
      "Train Epoch: 19 [400/17352 (2%)] Loss: -209528.281250\n",
      "Train Epoch: 19 [480/17352 (3%)] Loss: -224234.062500\n",
      "Train Epoch: 19 [560/17352 (3%)] Loss: -236828.640625\n",
      "Train Epoch: 19 [640/17352 (4%)] Loss: -211084.218750\n",
      "Train Epoch: 19 [720/17352 (4%)] Loss: -204512.562500\n",
      "Train Epoch: 19 [800/17352 (5%)] Loss: -205907.625000\n",
      "Train Epoch: 19 [880/17352 (5%)] Loss: -204337.390625\n",
      "Train Epoch: 19 [960/17352 (6%)] Loss: -193697.546875\n",
      "Train Epoch: 19 [1040/17352 (6%)] Loss: -214328.843750\n",
      "Train Epoch: 19 [1120/17352 (6%)] Loss: -218547.671875\n",
      "Train Epoch: 19 [1200/17352 (7%)] Loss: -235568.140625\n",
      "Train Epoch: 19 [1280/17352 (7%)] Loss: -217925.250000\n",
      "Train Epoch: 19 [1360/17352 (8%)] Loss: -194278.609375\n",
      "Train Epoch: 19 [1440/17352 (8%)] Loss: -214390.328125\n",
      "Train Epoch: 19 [1520/17352 (9%)] Loss: -210178.171875\n",
      "Train Epoch: 19 [1600/17352 (9%)] Loss: -222999.078125\n",
      "Train Epoch: 19 [1680/17352 (10%)] Loss: -219193.671875\n",
      "Train Epoch: 19 [1760/17352 (10%)] Loss: -221474.171875\n",
      "Train Epoch: 19 [1840/17352 (11%)] Loss: -182764.531250\n",
      "Train Epoch: 19 [1920/17352 (11%)] Loss: -210503.265625\n",
      "Train Epoch: 19 [2000/17352 (12%)] Loss: -196399.234375\n",
      "Train Epoch: 19 [2080/17352 (12%)] Loss: -203244.562500\n",
      "Train Epoch: 19 [2160/17352 (12%)] Loss: -229949.171875\n",
      "Train Epoch: 19 [2240/17352 (13%)] Loss: -228232.359375\n",
      "Train Epoch: 19 [2320/17352 (13%)] Loss: -193481.750000\n",
      "Train Epoch: 19 [2400/17352 (14%)] Loss: -206142.562500\n",
      "Train Epoch: 19 [2480/17352 (14%)] Loss: -210473.843750\n",
      "Train Epoch: 19 [2560/17352 (15%)] Loss: -180983.906250\n",
      "Train Epoch: 19 [2640/17352 (15%)] Loss: -199156.031250\n",
      "Train Epoch: 19 [2720/17352 (16%)] Loss: -157463.906250\n",
      "Train Epoch: 19 [2800/17352 (16%)] Loss: -192100.703125\n",
      "Train Epoch: 19 [2880/17352 (17%)] Loss: -178311.875000\n",
      "Train Epoch: 19 [2960/17352 (17%)] Loss: -178196.531250\n",
      "Train Epoch: 19 [3040/17352 (18%)] Loss: -148426.187500\n",
      "Train Epoch: 19 [3120/17352 (18%)] Loss: -176272.343750\n",
      "Train Epoch: 19 [3200/17352 (18%)] Loss: -193123.531250\n",
      "Train Epoch: 19 [3280/17352 (19%)] Loss: -184444.046875\n",
      "Train Epoch: 19 [3360/17352 (19%)] Loss: -177299.453125\n",
      "Train Epoch: 19 [3440/17352 (20%)] Loss: -185032.109375\n",
      "Train Epoch: 19 [3520/17352 (20%)] Loss: -169589.656250\n",
      "Train Epoch: 19 [3600/17352 (21%)] Loss: -219902.515625\n",
      "Train Epoch: 19 [3680/17352 (21%)] Loss: -200602.390625\n",
      "Train Epoch: 19 [3760/17352 (22%)] Loss: -178298.578125\n",
      "Train Epoch: 19 [3840/17352 (22%)] Loss: -183374.171875\n",
      "Train Epoch: 19 [3920/17352 (23%)] Loss: -172225.015625\n",
      "Train Epoch: 19 [4000/17352 (23%)] Loss: -193910.578125\n",
      "Train Epoch: 19 [4080/17352 (24%)] Loss: -134529.093750\n",
      "Train Epoch: 19 [4160/17352 (24%)] Loss: -182395.859375\n",
      "Train Epoch: 19 [4240/17352 (24%)] Loss: -203469.859375\n",
      "Train Epoch: 19 [4320/17352 (25%)] Loss: -169959.000000\n",
      "Train Epoch: 19 [4400/17352 (25%)] Loss: -167228.531250\n",
      "Train Epoch: 19 [4480/17352 (26%)] Loss: -180736.859375\n",
      "Train Epoch: 19 [4560/17352 (26%)] Loss: -148147.421875\n",
      "Train Epoch: 19 [4640/17352 (27%)] Loss: -178201.984375\n",
      "Train Epoch: 19 [4720/17352 (27%)] Loss: -201826.109375\n",
      "Train Epoch: 19 [4800/17352 (28%)] Loss: -191800.171875\n",
      "Train Epoch: 19 [4880/17352 (28%)] Loss: -200970.421875\n",
      "Train Epoch: 19 [4960/17352 (29%)] Loss: -180908.312500\n",
      "Train Epoch: 19 [5040/17352 (29%)] Loss: -191665.187500\n",
      "Train Epoch: 19 [5120/17352 (30%)] Loss: -186504.156250\n",
      "Train Epoch: 19 [5200/17352 (30%)] Loss: -177610.250000\n",
      "Train Epoch: 19 [5280/17352 (30%)] Loss: -190612.531250\n",
      "Train Epoch: 19 [5360/17352 (31%)] Loss: -168043.218750\n",
      "Train Epoch: 19 [5440/17352 (31%)] Loss: -175663.281250\n",
      "Train Epoch: 19 [5520/17352 (32%)] Loss: -205477.953125\n",
      "Train Epoch: 19 [5600/17352 (32%)] Loss: -176265.578125\n",
      "Train Epoch: 19 [5680/17352 (33%)] Loss: -194992.734375\n",
      "Train Epoch: 19 [5760/17352 (33%)] Loss: -187938.468750\n",
      "Train Epoch: 19 [5840/17352 (34%)] Loss: -159598.968750\n",
      "Train Epoch: 19 [5920/17352 (34%)] Loss: -188492.734375\n",
      "Train Epoch: 19 [6000/17352 (35%)] Loss: -167878.250000\n",
      "Train Epoch: 19 [6080/17352 (35%)] Loss: -188794.078125\n",
      "Train Epoch: 19 [6160/17352 (36%)] Loss: -173880.703125\n",
      "Train Epoch: 19 [6240/17352 (36%)] Loss: -200152.062500\n",
      "Train Epoch: 19 [6320/17352 (36%)] Loss: -204635.093750\n",
      "Train Epoch: 19 [6400/17352 (37%)] Loss: -191295.156250\n",
      "Train Epoch: 19 [6480/17352 (37%)] Loss: -171878.312500\n",
      "Train Epoch: 19 [6560/17352 (38%)] Loss: -185348.546875\n",
      "Train Epoch: 19 [6640/17352 (38%)] Loss: -170758.468750\n",
      "Train Epoch: 19 [6720/17352 (39%)] Loss: -187312.078125\n",
      "Train Epoch: 19 [6800/17352 (39%)] Loss: -170222.156250\n",
      "Train Epoch: 19 [6880/17352 (40%)] Loss: -197592.765625\n",
      "Train Epoch: 19 [6960/17352 (40%)] Loss: -156460.531250\n",
      "Train Epoch: 19 [7040/17352 (41%)] Loss: -185499.984375\n",
      "Train Epoch: 19 [7120/17352 (41%)] Loss: -179896.296875\n",
      "Train Epoch: 19 [7200/17352 (41%)] Loss: -201951.406250\n",
      "Train Epoch: 19 [7280/17352 (42%)] Loss: -199709.765625\n",
      "Train Epoch: 19 [7360/17352 (42%)] Loss: -199430.562500\n",
      "Train Epoch: 19 [7440/17352 (43%)] Loss: -186184.468750\n",
      "Train Epoch: 19 [7520/17352 (43%)] Loss: -181593.937500\n",
      "Train Epoch: 19 [7600/17352 (44%)] Loss: -166017.812500\n",
      "Train Epoch: 19 [7680/17352 (44%)] Loss: -195774.437500\n",
      "Train Epoch: 19 [7760/17352 (45%)] Loss: -198533.312500\n",
      "Train Epoch: 19 [7840/17352 (45%)] Loss: -163086.125000\n",
      "Train Epoch: 19 [7920/17352 (46%)] Loss: -171428.921875\n",
      "Train Epoch: 19 [8000/17352 (46%)] Loss: -204986.156250\n",
      "Train Epoch: 19 [8080/17352 (47%)] Loss: -174625.671875\n",
      "Train Epoch: 19 [8160/17352 (47%)] Loss: -207838.656250\n",
      "Train Epoch: 19 [8240/17352 (47%)] Loss: -204361.953125\n",
      "Train Epoch: 19 [8320/17352 (48%)] Loss: -208888.406250\n",
      "Train Epoch: 19 [8400/17352 (48%)] Loss: -158731.156250\n",
      "Train Epoch: 19 [8480/17352 (49%)] Loss: -179016.421875\n",
      "Train Epoch: 19 [8560/17352 (49%)] Loss: -195364.656250\n",
      "Train Epoch: 19 [8640/17352 (50%)] Loss: -138332.250000\n",
      "Train Epoch: 19 [8720/17352 (50%)] Loss: -190214.156250\n",
      "Train Epoch: 19 [8800/17352 (51%)] Loss: -163534.078125\n",
      "Train Epoch: 19 [8880/17352 (51%)] Loss: -188250.984375\n",
      "Train Epoch: 19 [8960/17352 (52%)] Loss: -153309.625000\n",
      "Train Epoch: 19 [9040/17352 (52%)] Loss: -199878.578125\n",
      "Train Epoch: 19 [9120/17352 (53%)] Loss: -200391.468750\n",
      "Train Epoch: 19 [9200/17352 (53%)] Loss: -174968.562500\n",
      "Train Epoch: 19 [9280/17352 (53%)] Loss: -202162.375000\n",
      "Train Epoch: 19 [9360/17352 (54%)] Loss: -197299.984375\n",
      "Train Epoch: 19 [9440/17352 (54%)] Loss: -173425.984375\n",
      "Train Epoch: 19 [9520/17352 (55%)] Loss: -171709.125000\n",
      "Train Epoch: 19 [9600/17352 (55%)] Loss: -178641.062500\n",
      "Train Epoch: 19 [9680/17352 (56%)] Loss: -185782.796875\n",
      "Train Epoch: 19 [9760/17352 (56%)] Loss: -175387.093750\n",
      "Train Epoch: 19 [9840/17352 (57%)] Loss: -184807.015625\n",
      "Train Epoch: 19 [9920/17352 (57%)] Loss: -172958.312500\n",
      "Train Epoch: 19 [10000/17352 (58%)] Loss: -173831.984375\n",
      "Train Epoch: 19 [10080/17352 (58%)] Loss: -165755.500000\n",
      "Train Epoch: 19 [10160/17352 (59%)] Loss: -187706.312500\n",
      "Train Epoch: 19 [10240/17352 (59%)] Loss: -193492.000000\n",
      "Train Epoch: 19 [10320/17352 (59%)] Loss: -181739.000000\n",
      "Train Epoch: 19 [10400/17352 (60%)] Loss: -197530.156250\n",
      "Train Epoch: 19 [10480/17352 (60%)] Loss: -181325.468750\n",
      "Train Epoch: 19 [10560/17352 (61%)] Loss: -168763.062500\n",
      "Train Epoch: 19 [10640/17352 (61%)] Loss: -217594.421875\n",
      "Train Epoch: 19 [10720/17352 (62%)] Loss: -185793.953125\n",
      "Train Epoch: 19 [10800/17352 (62%)] Loss: -178858.046875\n",
      "Train Epoch: 19 [10880/17352 (63%)] Loss: -200606.593750\n",
      "Train Epoch: 19 [10960/17352 (63%)] Loss: -188074.468750\n",
      "Train Epoch: 19 [11040/17352 (64%)] Loss: -189583.890625\n",
      "Train Epoch: 19 [11120/17352 (64%)] Loss: -227889.515625\n",
      "Train Epoch: 19 [11200/17352 (65%)] Loss: -191587.906250\n",
      "Train Epoch: 19 [11280/17352 (65%)] Loss: -183146.031250\n",
      "Train Epoch: 19 [11360/17352 (65%)] Loss: -187244.281250\n",
      "Train Epoch: 19 [11440/17352 (66%)] Loss: -172543.562500\n",
      "Train Epoch: 19 [11520/17352 (66%)] Loss: -183901.421875\n",
      "Train Epoch: 19 [11600/17352 (67%)] Loss: -149322.906250\n",
      "Train Epoch: 19 [11680/17352 (67%)] Loss: -185591.859375\n",
      "Train Epoch: 19 [11760/17352 (68%)] Loss: -162713.609375\n",
      "Train Epoch: 19 [11840/17352 (68%)] Loss: -181244.734375\n",
      "Train Epoch: 19 [11920/17352 (69%)] Loss: -209178.546875\n",
      "Train Epoch: 19 [12000/17352 (69%)] Loss: -208144.187500\n",
      "Train Epoch: 19 [12080/17352 (70%)] Loss: -164796.343750\n",
      "Train Epoch: 19 [12160/17352 (70%)] Loss: -183620.343750\n",
      "Train Epoch: 19 [12240/17352 (71%)] Loss: -180799.109375\n",
      "Train Epoch: 19 [12320/17352 (71%)] Loss: -179297.218750\n",
      "Train Epoch: 19 [12400/17352 (71%)] Loss: -189796.250000\n",
      "Train Epoch: 19 [12480/17352 (72%)] Loss: -175312.218750\n",
      "Train Epoch: 19 [12560/17352 (72%)] Loss: -180990.000000\n",
      "Train Epoch: 19 [12640/17352 (73%)] Loss: -183700.562500\n",
      "Train Epoch: 19 [12720/17352 (73%)] Loss: -174544.593750\n",
      "Train Epoch: 19 [12800/17352 (74%)] Loss: -192255.062500\n",
      "Train Epoch: 19 [12880/17352 (74%)] Loss: -151207.593750\n",
      "Train Epoch: 19 [12960/17352 (75%)] Loss: -187113.500000\n",
      "Train Epoch: 19 [13040/17352 (75%)] Loss: -164971.625000\n",
      "Train Epoch: 19 [13120/17352 (76%)] Loss: -209193.203125\n",
      "Train Epoch: 19 [13200/17352 (76%)] Loss: -206682.312500\n",
      "Train Epoch: 19 [13280/17352 (77%)] Loss: -195497.031250\n",
      "Train Epoch: 19 [13360/17352 (77%)] Loss: -180152.515625\n",
      "Train Epoch: 19 [13440/17352 (77%)] Loss: -189561.515625\n",
      "Train Epoch: 19 [13520/17352 (78%)] Loss: -177196.953125\n",
      "Train Epoch: 19 [13600/17352 (78%)] Loss: -177290.781250\n",
      "Train Epoch: 19 [13680/17352 (79%)] Loss: -163484.906250\n",
      "Train Epoch: 19 [13760/17352 (79%)] Loss: -183745.171875\n",
      "Train Epoch: 19 [13840/17352 (80%)] Loss: -149026.343750\n",
      "Train Epoch: 19 [13920/17352 (80%)] Loss: -193938.421875\n",
      "Train Epoch: 19 [14000/17352 (81%)] Loss: -180886.203125\n",
      "Train Epoch: 19 [14080/17352 (81%)] Loss: -164493.796875\n",
      "Train Epoch: 19 [14160/17352 (82%)] Loss: -194036.843750\n",
      "Train Epoch: 19 [14240/17352 (82%)] Loss: -174614.546875\n",
      "Train Epoch: 19 [14320/17352 (83%)] Loss: -201920.484375\n",
      "Train Epoch: 19 [14400/17352 (83%)] Loss: -210623.609375\n",
      "Train Epoch: 19 [14480/17352 (83%)] Loss: -200849.140625\n",
      "Train Epoch: 19 [14560/17352 (84%)] Loss: -182518.781250\n",
      "Train Epoch: 19 [14640/17352 (84%)] Loss: -176887.187500\n",
      "Train Epoch: 19 [14720/17352 (85%)] Loss: -165351.328125\n",
      "Train Epoch: 19 [14800/17352 (85%)] Loss: -165665.968750\n",
      "Train Epoch: 19 [14880/17352 (86%)] Loss: -166996.906250\n",
      "Train Epoch: 19 [14960/17352 (86%)] Loss: -167865.328125\n",
      "Train Epoch: 19 [15040/17352 (87%)] Loss: -152725.406250\n",
      "Train Epoch: 19 [15120/17352 (87%)] Loss: -177089.125000\n",
      "Train Epoch: 19 [15200/17352 (88%)] Loss: -177460.546875\n",
      "Train Epoch: 19 [15280/17352 (88%)] Loss: -166252.984375\n",
      "Train Epoch: 19 [15360/17352 (89%)] Loss: -192638.656250\n",
      "Train Epoch: 19 [15440/17352 (89%)] Loss: -208024.093750\n",
      "Train Epoch: 19 [15520/17352 (89%)] Loss: -182732.968750\n",
      "Train Epoch: 19 [15600/17352 (90%)] Loss: -162954.484375\n",
      "Train Epoch: 19 [15680/17352 (90%)] Loss: -213723.218750\n",
      "Train Epoch: 19 [15760/17352 (91%)] Loss: -163338.078125\n",
      "Train Epoch: 19 [15840/17352 (91%)] Loss: -180009.343750\n",
      "Train Epoch: 19 [15920/17352 (92%)] Loss: -204673.703125\n",
      "Train Epoch: 19 [16000/17352 (92%)] Loss: -177230.375000\n",
      "Train Epoch: 19 [16080/17352 (93%)] Loss: -178818.468750\n",
      "Train Epoch: 19 [16160/17352 (93%)] Loss: -175739.140625\n",
      "Train Epoch: 19 [16240/17352 (94%)] Loss: -193345.031250\n",
      "Train Epoch: 19 [16320/17352 (94%)] Loss: -149427.328125\n",
      "Train Epoch: 19 [16400/17352 (95%)] Loss: -180224.515625\n",
      "Train Epoch: 19 [16480/17352 (95%)] Loss: -192999.656250\n",
      "Train Epoch: 19 [16560/17352 (95%)] Loss: -166450.156250\n",
      "Train Epoch: 19 [16640/17352 (96%)] Loss: -179487.578125\n",
      "Train Epoch: 19 [16720/17352 (96%)] Loss: -200460.734375\n",
      "Train Epoch: 19 [16800/17352 (97%)] Loss: -191820.578125\n",
      "Train Epoch: 19 [16880/17352 (97%)] Loss: -177281.046875\n",
      "Train Epoch: 19 [16960/17352 (98%)] Loss: -178592.000000\n",
      "Train Epoch: 19 [17040/17352 (98%)] Loss: -209249.562500\n",
      "Train Epoch: 19 [17120/17352 (99%)] Loss: -167210.343750\n",
      "Train Epoch: 19 [17200/17352 (99%)] Loss: -189397.718750\n",
      "Train Epoch: 19 [17280/17352 (100%)] Loss: -212969.953125\n",
      "Train Epoch: 19 [17360/17352 (100%)] Loss: -186429.750000\n",
      "    epoch          : 19\n",
      "    loss           : -189270.9598766542\n",
      "    val_loss       : -23714.002122332793\n",
      "Train Epoch: 20 [0/17352 (0%)] Loss: -208371.359375\n",
      "Train Epoch: 20 [80/17352 (0%)] Loss: -209755.656250\n",
      "Train Epoch: 20 [160/17352 (1%)] Loss: -215087.484375\n",
      "Train Epoch: 20 [240/17352 (1%)] Loss: -233721.281250\n",
      "Train Epoch: 20 [320/17352 (2%)] Loss: -203734.859375\n",
      "Train Epoch: 20 [400/17352 (2%)] Loss: -211101.625000\n",
      "Train Epoch: 20 [480/17352 (3%)] Loss: -194271.218750\n",
      "Train Epoch: 20 [560/17352 (3%)] Loss: -204014.687500\n",
      "Train Epoch: 20 [640/17352 (4%)] Loss: -206629.484375\n",
      "Train Epoch: 20 [720/17352 (4%)] Loss: -206552.359375\n",
      "Train Epoch: 20 [800/17352 (5%)] Loss: -212698.000000\n",
      "Train Epoch: 20 [880/17352 (5%)] Loss: -216096.062500\n",
      "Train Epoch: 20 [960/17352 (6%)] Loss: -205902.453125\n",
      "Train Epoch: 20 [1040/17352 (6%)] Loss: -218535.890625\n",
      "Train Epoch: 20 [1120/17352 (6%)] Loss: -241902.531250\n",
      "Train Epoch: 20 [1200/17352 (7%)] Loss: -193702.796875\n",
      "Train Epoch: 20 [1280/17352 (7%)] Loss: -217943.921875\n",
      "Train Epoch: 20 [1360/17352 (8%)] Loss: -224325.234375\n",
      "Train Epoch: 20 [1440/17352 (8%)] Loss: -209542.312500\n",
      "Train Epoch: 20 [1520/17352 (9%)] Loss: -206735.265625\n",
      "Train Epoch: 20 [1600/17352 (9%)] Loss: -196418.656250\n",
      "Train Epoch: 20 [1680/17352 (10%)] Loss: -199804.515625\n",
      "Train Epoch: 20 [1760/17352 (10%)] Loss: -204353.625000\n",
      "Train Epoch: 20 [1840/17352 (11%)] Loss: -193011.515625\n",
      "Train Epoch: 20 [1920/17352 (11%)] Loss: -216084.093750\n",
      "Train Epoch: 20 [2000/17352 (12%)] Loss: -200583.968750\n",
      "Train Epoch: 20 [2080/17352 (12%)] Loss: -236816.328125\n",
      "Train Epoch: 20 [2160/17352 (12%)] Loss: -210199.953125\n",
      "Train Epoch: 20 [2240/17352 (13%)] Loss: -197563.875000\n",
      "Train Epoch: 20 [2320/17352 (13%)] Loss: -188263.812500\n",
      "Train Epoch: 20 [2400/17352 (14%)] Loss: -180513.250000\n",
      "Train Epoch: 20 [2480/17352 (14%)] Loss: -194584.671875\n",
      "Train Epoch: 20 [2560/17352 (15%)] Loss: -168665.937500\n",
      "Train Epoch: 20 [2640/17352 (15%)] Loss: -179290.296875\n",
      "Train Epoch: 20 [2720/17352 (16%)] Loss: -173565.875000\n",
      "Train Epoch: 20 [2800/17352 (16%)] Loss: -202071.109375\n",
      "Train Epoch: 20 [2880/17352 (17%)] Loss: -189003.921875\n",
      "Train Epoch: 20 [2960/17352 (17%)] Loss: -169601.625000\n",
      "Train Epoch: 20 [3040/17352 (18%)] Loss: -178596.281250\n",
      "Train Epoch: 20 [3120/17352 (18%)] Loss: -185055.890625\n",
      "Train Epoch: 20 [3200/17352 (18%)] Loss: -196795.265625\n",
      "Train Epoch: 20 [3280/17352 (19%)] Loss: -200957.406250\n",
      "Train Epoch: 20 [3360/17352 (19%)] Loss: -205486.265625\n",
      "Train Epoch: 20 [3440/17352 (20%)] Loss: -206085.328125\n",
      "Train Epoch: 20 [3520/17352 (20%)] Loss: -177185.468750\n",
      "Train Epoch: 20 [3600/17352 (21%)] Loss: -197327.703125\n",
      "Train Epoch: 20 [3680/17352 (21%)] Loss: -197512.703125\n",
      "Train Epoch: 20 [3760/17352 (22%)] Loss: -171812.000000\n",
      "Train Epoch: 20 [3840/17352 (22%)] Loss: -168754.734375\n",
      "Train Epoch: 20 [3920/17352 (23%)] Loss: -187252.593750\n",
      "Train Epoch: 20 [4000/17352 (23%)] Loss: -208900.609375\n",
      "Train Epoch: 20 [4080/17352 (24%)] Loss: -175394.359375\n",
      "Train Epoch: 20 [4160/17352 (24%)] Loss: -190501.125000\n",
      "Train Epoch: 20 [4240/17352 (24%)] Loss: -221246.000000\n",
      "Train Epoch: 20 [4320/17352 (25%)] Loss: -192301.656250\n",
      "Train Epoch: 20 [4400/17352 (25%)] Loss: -180152.796875\n",
      "Train Epoch: 20 [4480/17352 (26%)] Loss: -184260.000000\n",
      "Train Epoch: 20 [4560/17352 (26%)] Loss: -177310.140625\n",
      "Train Epoch: 20 [4640/17352 (27%)] Loss: -188944.000000\n",
      "Train Epoch: 20 [4720/17352 (27%)] Loss: -202576.687500\n",
      "Train Epoch: 20 [4800/17352 (28%)] Loss: -196686.093750\n",
      "Train Epoch: 20 [4880/17352 (28%)] Loss: -204351.656250\n",
      "Train Epoch: 20 [4960/17352 (29%)] Loss: -194924.125000\n",
      "Train Epoch: 20 [5040/17352 (29%)] Loss: -193498.687500\n",
      "Train Epoch: 20 [5120/17352 (30%)] Loss: -175299.343750\n",
      "Train Epoch: 20 [5200/17352 (30%)] Loss: -195054.218750\n",
      "Train Epoch: 20 [5280/17352 (30%)] Loss: -187356.031250\n",
      "Train Epoch: 20 [5360/17352 (31%)] Loss: -225309.984375\n",
      "Train Epoch: 20 [5440/17352 (31%)] Loss: -177239.578125\n",
      "Train Epoch: 20 [5520/17352 (32%)] Loss: -188424.468750\n",
      "Train Epoch: 20 [5600/17352 (32%)] Loss: -207109.031250\n",
      "Train Epoch: 20 [5680/17352 (33%)] Loss: -191706.078125\n",
      "Train Epoch: 20 [5760/17352 (33%)] Loss: -184934.406250\n",
      "Train Epoch: 20 [5840/17352 (34%)] Loss: -207825.921875\n",
      "Train Epoch: 20 [5920/17352 (34%)] Loss: -185782.062500\n",
      "Train Epoch: 20 [6000/17352 (35%)] Loss: -179002.234375\n",
      "Train Epoch: 20 [6080/17352 (35%)] Loss: -193526.140625\n",
      "Train Epoch: 20 [6160/17352 (36%)] Loss: -184977.093750\n",
      "Train Epoch: 20 [6240/17352 (36%)] Loss: -164067.218750\n",
      "Train Epoch: 20 [6320/17352 (36%)] Loss: -177754.859375\n",
      "Train Epoch: 20 [6400/17352 (37%)] Loss: -199455.250000\n",
      "Train Epoch: 20 [6480/17352 (37%)] Loss: -208008.187500\n",
      "Train Epoch: 20 [6560/17352 (38%)] Loss: -203739.437500\n",
      "Train Epoch: 20 [6640/17352 (38%)] Loss: -204193.250000\n",
      "Train Epoch: 20 [6720/17352 (39%)] Loss: -191218.046875\n",
      "Train Epoch: 20 [6800/17352 (39%)] Loss: -159740.781250\n",
      "Train Epoch: 20 [6880/17352 (40%)] Loss: -180957.468750\n",
      "Train Epoch: 20 [6960/17352 (40%)] Loss: -167946.218750\n",
      "Train Epoch: 20 [7040/17352 (41%)] Loss: -190934.343750\n",
      "Train Epoch: 20 [7120/17352 (41%)] Loss: -203871.687500\n",
      "Train Epoch: 20 [7200/17352 (41%)] Loss: -171294.390625\n",
      "Train Epoch: 20 [7280/17352 (42%)] Loss: -173430.125000\n",
      "Train Epoch: 20 [7360/17352 (42%)] Loss: -181951.531250\n",
      "Train Epoch: 20 [7440/17352 (43%)] Loss: -192261.671875\n",
      "Train Epoch: 20 [7520/17352 (43%)] Loss: -180638.546875\n",
      "Train Epoch: 20 [7600/17352 (44%)] Loss: -180044.078125\n",
      "Train Epoch: 20 [7680/17352 (44%)] Loss: -204650.515625\n",
      "Train Epoch: 20 [7760/17352 (45%)] Loss: -178814.781250\n",
      "Train Epoch: 20 [7840/17352 (45%)] Loss: -165855.390625\n",
      "Train Epoch: 20 [7920/17352 (46%)] Loss: -177770.890625\n",
      "Train Epoch: 20 [8000/17352 (46%)] Loss: -199710.218750\n",
      "Train Epoch: 20 [8080/17352 (47%)] Loss: -223676.156250\n",
      "Train Epoch: 20 [8160/17352 (47%)] Loss: -210383.296875\n",
      "Train Epoch: 20 [8240/17352 (47%)] Loss: -161681.765625\n",
      "Train Epoch: 20 [8320/17352 (48%)] Loss: -177471.281250\n",
      "Train Epoch: 20 [8400/17352 (48%)] Loss: -179911.015625\n",
      "Train Epoch: 20 [8480/17352 (49%)] Loss: -170300.250000\n",
      "Train Epoch: 20 [8560/17352 (49%)] Loss: -174542.031250\n",
      "Train Epoch: 20 [8640/17352 (50%)] Loss: -210777.750000\n",
      "Train Epoch: 20 [8720/17352 (50%)] Loss: -186176.875000\n",
      "Train Epoch: 20 [8800/17352 (51%)] Loss: -178658.031250\n",
      "Train Epoch: 20 [8880/17352 (51%)] Loss: -176045.609375\n",
      "Train Epoch: 20 [8960/17352 (52%)] Loss: -187881.687500\n",
      "Train Epoch: 20 [9040/17352 (52%)] Loss: -184808.781250\n",
      "Train Epoch: 20 [9120/17352 (53%)] Loss: -178868.421875\n",
      "Train Epoch: 20 [9200/17352 (53%)] Loss: -184743.906250\n",
      "Train Epoch: 20 [9280/17352 (53%)] Loss: -149443.250000\n",
      "Train Epoch: 20 [9360/17352 (54%)] Loss: -191784.843750\n",
      "Train Epoch: 20 [9440/17352 (54%)] Loss: -189276.968750\n",
      "Train Epoch: 20 [9520/17352 (55%)] Loss: -190222.593750\n",
      "Train Epoch: 20 [9600/17352 (55%)] Loss: -173031.875000\n",
      "Train Epoch: 20 [9680/17352 (56%)] Loss: -178729.453125\n",
      "Train Epoch: 20 [9760/17352 (56%)] Loss: -202457.187500\n",
      "Train Epoch: 20 [9840/17352 (57%)] Loss: -165345.765625\n",
      "Train Epoch: 20 [9920/17352 (57%)] Loss: -176090.484375\n",
      "Train Epoch: 20 [10000/17352 (58%)] Loss: -195057.765625\n",
      "Train Epoch: 20 [10080/17352 (58%)] Loss: -187203.625000\n",
      "Train Epoch: 20 [10160/17352 (59%)] Loss: -172998.625000\n",
      "Train Epoch: 20 [10240/17352 (59%)] Loss: -166019.328125\n",
      "Train Epoch: 20 [10320/17352 (59%)] Loss: -206339.046875\n",
      "Train Epoch: 20 [10400/17352 (60%)] Loss: -183952.734375\n",
      "Train Epoch: 20 [10480/17352 (60%)] Loss: -179158.125000\n",
      "Train Epoch: 20 [10560/17352 (61%)] Loss: -183905.296875\n",
      "Train Epoch: 20 [10640/17352 (61%)] Loss: -167138.859375\n",
      "Train Epoch: 20 [10720/17352 (62%)] Loss: -176157.375000\n",
      "Train Epoch: 20 [10800/17352 (62%)] Loss: -176584.359375\n",
      "Train Epoch: 20 [10880/17352 (63%)] Loss: -183861.640625\n",
      "Train Epoch: 20 [10960/17352 (63%)] Loss: -193353.593750\n",
      "Train Epoch: 20 [11040/17352 (64%)] Loss: -179885.406250\n",
      "Train Epoch: 20 [11120/17352 (64%)] Loss: -192376.859375\n",
      "Train Epoch: 20 [11200/17352 (65%)] Loss: -180240.828125\n",
      "Train Epoch: 20 [11280/17352 (65%)] Loss: -212605.593750\n",
      "Train Epoch: 20 [11360/17352 (65%)] Loss: -205205.140625\n",
      "Train Epoch: 20 [11440/17352 (66%)] Loss: -177304.890625\n",
      "Train Epoch: 20 [11520/17352 (66%)] Loss: -181719.843750\n",
      "Train Epoch: 20 [11600/17352 (67%)] Loss: -189562.671875\n",
      "Train Epoch: 20 [11680/17352 (67%)] Loss: -193430.953125\n",
      "Train Epoch: 20 [11760/17352 (68%)] Loss: -208791.968750\n",
      "Train Epoch: 20 [11840/17352 (68%)] Loss: -171226.343750\n",
      "Train Epoch: 20 [11920/17352 (69%)] Loss: -171569.359375\n",
      "Train Epoch: 20 [12000/17352 (69%)] Loss: -213734.390625\n",
      "Train Epoch: 20 [12080/17352 (70%)] Loss: -173348.468750\n",
      "Train Epoch: 20 [12160/17352 (70%)] Loss: -178991.359375\n",
      "Train Epoch: 20 [12240/17352 (71%)] Loss: -198534.875000\n",
      "Train Epoch: 20 [12320/17352 (71%)] Loss: -187609.281250\n",
      "Train Epoch: 20 [12400/17352 (71%)] Loss: -199797.593750\n",
      "Train Epoch: 20 [12480/17352 (72%)] Loss: -183702.781250\n",
      "Train Epoch: 20 [12560/17352 (72%)] Loss: -188490.687500\n",
      "Train Epoch: 20 [12640/17352 (73%)] Loss: -177233.468750\n",
      "Train Epoch: 20 [12720/17352 (73%)] Loss: -187711.187500\n",
      "Train Epoch: 20 [12800/17352 (74%)] Loss: -182666.140625\n",
      "Train Epoch: 20 [12880/17352 (74%)] Loss: -163240.656250\n",
      "Train Epoch: 20 [12960/17352 (75%)] Loss: -167857.359375\n",
      "Train Epoch: 20 [13040/17352 (75%)] Loss: -175585.812500\n",
      "Train Epoch: 20 [13120/17352 (76%)] Loss: -186773.250000\n",
      "Train Epoch: 20 [13200/17352 (76%)] Loss: -186844.140625\n",
      "Train Epoch: 20 [13280/17352 (77%)] Loss: -181735.484375\n",
      "Train Epoch: 20 [13360/17352 (77%)] Loss: -210620.687500\n",
      "Train Epoch: 20 [13440/17352 (77%)] Loss: -182770.937500\n",
      "Train Epoch: 20 [13520/17352 (78%)] Loss: -215455.156250\n",
      "Train Epoch: 20 [13600/17352 (78%)] Loss: -204329.343750\n",
      "Train Epoch: 20 [13680/17352 (79%)] Loss: -172222.750000\n",
      "Train Epoch: 20 [13760/17352 (79%)] Loss: -179007.375000\n",
      "Train Epoch: 20 [13840/17352 (80%)] Loss: -171547.796875\n",
      "Train Epoch: 20 [13920/17352 (80%)] Loss: -183375.187500\n",
      "Train Epoch: 20 [14000/17352 (81%)] Loss: -198543.609375\n",
      "Train Epoch: 20 [14080/17352 (81%)] Loss: -189476.734375\n",
      "Train Epoch: 20 [14160/17352 (82%)] Loss: -184997.890625\n",
      "Train Epoch: 20 [14240/17352 (82%)] Loss: -203874.640625\n",
      "Train Epoch: 20 [14320/17352 (83%)] Loss: -200816.421875\n",
      "Train Epoch: 20 [14400/17352 (83%)] Loss: -197098.015625\n",
      "Train Epoch: 20 [14480/17352 (83%)] Loss: -161090.562500\n",
      "Train Epoch: 20 [14560/17352 (84%)] Loss: -181000.421875\n",
      "Train Epoch: 20 [14640/17352 (84%)] Loss: -178590.984375\n",
      "Train Epoch: 20 [14720/17352 (85%)] Loss: -190373.015625\n",
      "Train Epoch: 20 [14800/17352 (85%)] Loss: -205685.781250\n",
      "Train Epoch: 20 [14880/17352 (86%)] Loss: -199596.203125\n",
      "Train Epoch: 20 [14960/17352 (86%)] Loss: -196028.390625\n",
      "Train Epoch: 20 [15040/17352 (87%)] Loss: -200266.234375\n",
      "Train Epoch: 20 [15120/17352 (87%)] Loss: -187201.000000\n",
      "Train Epoch: 20 [15200/17352 (88%)] Loss: -200152.718750\n",
      "Train Epoch: 20 [15280/17352 (88%)] Loss: -169187.187500\n",
      "Train Epoch: 20 [15360/17352 (89%)] Loss: -192269.140625\n",
      "Train Epoch: 20 [15440/17352 (89%)] Loss: -196494.750000\n",
      "Train Epoch: 20 [15520/17352 (89%)] Loss: -174873.609375\n",
      "Train Epoch: 20 [15600/17352 (90%)] Loss: -185360.250000\n",
      "Train Epoch: 20 [15680/17352 (90%)] Loss: -202191.546875\n",
      "Train Epoch: 20 [15760/17352 (91%)] Loss: -192674.593750\n",
      "Train Epoch: 20 [15840/17352 (91%)] Loss: -188013.421875\n",
      "Train Epoch: 20 [15920/17352 (92%)] Loss: -185494.812500\n",
      "Train Epoch: 20 [16000/17352 (92%)] Loss: -174971.265625\n",
      "Train Epoch: 20 [16080/17352 (93%)] Loss: -203650.312500\n",
      "Train Epoch: 20 [16160/17352 (93%)] Loss: -164736.875000\n",
      "Train Epoch: 20 [16240/17352 (94%)] Loss: -187758.937500\n",
      "Train Epoch: 20 [16320/17352 (94%)] Loss: -176668.125000\n",
      "Train Epoch: 20 [16400/17352 (95%)] Loss: -180231.828125\n",
      "Train Epoch: 20 [16480/17352 (95%)] Loss: -179429.031250\n",
      "Train Epoch: 20 [16560/17352 (95%)] Loss: -188556.390625\n",
      "Train Epoch: 20 [16640/17352 (96%)] Loss: -180239.750000\n",
      "Train Epoch: 20 [16720/17352 (96%)] Loss: -162554.218750\n",
      "Train Epoch: 20 [16800/17352 (97%)] Loss: -187294.531250\n",
      "Train Epoch: 20 [16880/17352 (97%)] Loss: -187499.968750\n",
      "Train Epoch: 20 [16960/17352 (98%)] Loss: -192989.828125\n",
      "Train Epoch: 20 [17040/17352 (98%)] Loss: -186795.734375\n",
      "Train Epoch: 20 [17120/17352 (99%)] Loss: -197077.140625\n",
      "Train Epoch: 20 [17200/17352 (99%)] Loss: -194050.921875\n",
      "Train Epoch: 20 [17280/17352 (100%)] Loss: -200619.250000\n",
      "Train Epoch: 20 [17360/17352 (100%)] Loss: -195708.718750\n",
      "    epoch          : 20\n",
      "    loss           : -189215.55201740508\n",
      "    val_loss       : -23714.584005794615\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch20.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 21 [0/17352 (0%)] Loss: -187705.515625\n",
      "Train Epoch: 21 [80/17352 (0%)] Loss: -185148.718750\n",
      "Train Epoch: 21 [160/17352 (1%)] Loss: -217936.765625\n",
      "Train Epoch: 21 [240/17352 (1%)] Loss: -221468.328125\n",
      "Train Epoch: 21 [320/17352 (2%)] Loss: -202212.328125\n",
      "Train Epoch: 21 [400/17352 (2%)] Loss: -202252.328125\n",
      "Train Epoch: 21 [480/17352 (3%)] Loss: -204525.562500\n",
      "Train Epoch: 21 [560/17352 (3%)] Loss: -213326.843750\n",
      "Train Epoch: 21 [640/17352 (4%)] Loss: -235577.093750\n",
      "Train Epoch: 21 [720/17352 (4%)] Loss: -229939.453125\n",
      "Train Epoch: 21 [800/17352 (5%)] Loss: -202019.875000\n",
      "Train Epoch: 21 [880/17352 (5%)] Loss: -219180.515625\n",
      "Train Epoch: 21 [960/17352 (6%)] Loss: -236619.609375\n",
      "Train Epoch: 21 [1040/17352 (6%)] Loss: -214445.671875\n",
      "Train Epoch: 21 [1120/17352 (6%)] Loss: -204695.109375\n",
      "Train Epoch: 21 [1200/17352 (7%)] Loss: -230176.843750\n",
      "Train Epoch: 21 [1280/17352 (7%)] Loss: -213317.687500\n",
      "Train Epoch: 21 [1360/17352 (8%)] Loss: -218536.500000\n",
      "Train Epoch: 21 [1440/17352 (8%)] Loss: -186061.218750\n",
      "Train Epoch: 21 [1520/17352 (9%)] Loss: -204354.250000\n",
      "Train Epoch: 21 [1600/17352 (9%)] Loss: -214325.453125\n",
      "Train Epoch: 21 [1680/17352 (10%)] Loss: -202311.609375\n",
      "Train Epoch: 21 [1760/17352 (10%)] Loss: -193573.609375\n",
      "Train Epoch: 21 [1840/17352 (11%)] Loss: -204389.859375\n",
      "Train Epoch: 21 [1920/17352 (11%)] Loss: -212179.843750\n",
      "Train Epoch: 21 [2000/17352 (12%)] Loss: -205193.609375\n",
      "Train Epoch: 21 [2080/17352 (12%)] Loss: -210332.734375\n",
      "Train Epoch: 21 [2160/17352 (12%)] Loss: -222999.468750\n",
      "Train Epoch: 21 [2240/17352 (13%)] Loss: -179302.218750\n",
      "Train Epoch: 21 [2320/17352 (13%)] Loss: -170221.781250\n",
      "Train Epoch: 21 [2400/17352 (14%)] Loss: -175298.937500\n",
      "Train Epoch: 21 [2480/17352 (14%)] Loss: -163742.156250\n",
      "Train Epoch: 21 [2560/17352 (15%)] Loss: -214953.796875\n",
      "Train Epoch: 21 [2640/17352 (15%)] Loss: -189485.390625\n",
      "Train Epoch: 21 [2720/17352 (16%)] Loss: -199174.640625\n",
      "Train Epoch: 21 [2800/17352 (16%)] Loss: -193492.250000\n",
      "Train Epoch: 21 [2880/17352 (17%)] Loss: -190071.593750\n",
      "Train Epoch: 21 [2960/17352 (17%)] Loss: -200383.218750\n",
      "Train Epoch: 21 [3040/17352 (18%)] Loss: -184959.093750\n",
      "Train Epoch: 21 [3120/17352 (18%)] Loss: -161509.015625\n",
      "Train Epoch: 21 [3200/17352 (18%)] Loss: -143616.062500\n",
      "Train Epoch: 21 [3280/17352 (19%)] Loss: -192104.390625\n",
      "Train Epoch: 21 [3360/17352 (19%)] Loss: -189995.296875\n",
      "Train Epoch: 21 [3440/17352 (20%)] Loss: -180149.578125\n",
      "Train Epoch: 21 [3520/17352 (20%)] Loss: -175656.359375\n",
      "Train Epoch: 21 [3600/17352 (21%)] Loss: -196121.500000\n",
      "Train Epoch: 21 [3680/17352 (21%)] Loss: -179882.562500\n",
      "Train Epoch: 21 [3760/17352 (22%)] Loss: -170762.046875\n",
      "Train Epoch: 21 [3840/17352 (22%)] Loss: -200856.734375\n",
      "Train Epoch: 21 [3920/17352 (23%)] Loss: -165789.156250\n",
      "Train Epoch: 21 [4000/17352 (23%)] Loss: -196104.437500\n",
      "Train Epoch: 21 [4080/17352 (24%)] Loss: -197589.265625\n",
      "Train Epoch: 21 [4160/17352 (24%)] Loss: -157587.312500\n",
      "Train Epoch: 21 [4240/17352 (24%)] Loss: -171577.968750\n",
      "Train Epoch: 21 [4320/17352 (25%)] Loss: -162710.906250\n",
      "Train Epoch: 21 [4400/17352 (25%)] Loss: -176693.437500\n",
      "Train Epoch: 21 [4480/17352 (26%)] Loss: -148916.718750\n",
      "Train Epoch: 21 [4560/17352 (26%)] Loss: -203797.484375\n",
      "Train Epoch: 21 [4640/17352 (27%)] Loss: -170769.531250\n",
      "Train Epoch: 21 [4720/17352 (27%)] Loss: -166549.500000\n",
      "Train Epoch: 21 [4800/17352 (28%)] Loss: -157481.562500\n",
      "Train Epoch: 21 [4880/17352 (28%)] Loss: -183599.531250\n",
      "Train Epoch: 21 [4960/17352 (29%)] Loss: -169941.906250\n",
      "Train Epoch: 21 [5040/17352 (29%)] Loss: -180908.250000\n",
      "Train Epoch: 21 [5120/17352 (30%)] Loss: -173571.937500\n",
      "Train Epoch: 21 [5200/17352 (30%)] Loss: -181954.546875\n",
      "Train Epoch: 21 [5280/17352 (30%)] Loss: -201920.703125\n",
      "Train Epoch: 21 [5360/17352 (31%)] Loss: -202226.984375\n",
      "Train Epoch: 21 [5440/17352 (31%)] Loss: -184244.593750\n",
      "Train Epoch: 21 [5520/17352 (32%)] Loss: -178313.468750\n",
      "Train Epoch: 21 [5600/17352 (32%)] Loss: -200108.796875\n",
      "Train Epoch: 21 [5680/17352 (33%)] Loss: -177771.562500\n",
      "Train Epoch: 21 [5760/17352 (33%)] Loss: -180019.546875\n",
      "Train Epoch: 21 [5840/17352 (34%)] Loss: -166507.078125\n",
      "Train Epoch: 21 [5920/17352 (34%)] Loss: -176578.593750\n",
      "Train Epoch: 21 [6000/17352 (35%)] Loss: -189290.750000\n",
      "Train Epoch: 21 [6080/17352 (35%)] Loss: -197644.281250\n",
      "Train Epoch: 21 [6160/17352 (36%)] Loss: -177474.906250\n",
      "Train Epoch: 21 [6240/17352 (36%)] Loss: -136418.578125\n",
      "Train Epoch: 21 [6320/17352 (36%)] Loss: -196243.468750\n",
      "Train Epoch: 21 [6400/17352 (37%)] Loss: -190380.015625\n",
      "Train Epoch: 21 [6480/17352 (37%)] Loss: -211714.875000\n",
      "Train Epoch: 21 [6560/17352 (38%)] Loss: -192949.968750\n",
      "Train Epoch: 21 [6640/17352 (38%)] Loss: -194049.156250\n",
      "Train Epoch: 21 [6720/17352 (39%)] Loss: -187872.468750\n",
      "Train Epoch: 21 [6800/17352 (39%)] Loss: -179445.328125\n",
      "Train Epoch: 21 [6880/17352 (40%)] Loss: -178824.265625\n",
      "Train Epoch: 21 [6960/17352 (40%)] Loss: -187705.531250\n",
      "Train Epoch: 21 [7040/17352 (41%)] Loss: -186764.546875\n",
      "Train Epoch: 21 [7120/17352 (41%)] Loss: -174501.875000\n",
      "Train Epoch: 21 [7200/17352 (41%)] Loss: -186027.484375\n",
      "Train Epoch: 21 [7280/17352 (42%)] Loss: -214633.734375\n",
      "Train Epoch: 21 [7360/17352 (42%)] Loss: -193503.187500\n",
      "Train Epoch: 21 [7440/17352 (43%)] Loss: -187600.531250\n",
      "Train Epoch: 21 [7520/17352 (43%)] Loss: -175353.015625\n",
      "Train Epoch: 21 [7600/17352 (44%)] Loss: -183361.437500\n",
      "Train Epoch: 21 [7680/17352 (44%)] Loss: -180047.640625\n",
      "Train Epoch: 21 [7760/17352 (45%)] Loss: -196704.796875\n",
      "Train Epoch: 21 [7840/17352 (45%)] Loss: -187781.062500\n",
      "Train Epoch: 21 [7920/17352 (46%)] Loss: -158741.218750\n",
      "Train Epoch: 21 [8000/17352 (46%)] Loss: -192297.687500\n",
      "Train Epoch: 21 [8080/17352 (47%)] Loss: -198537.687500\n",
      "Train Epoch: 21 [8160/17352 (47%)] Loss: -175199.375000\n",
      "Train Epoch: 21 [8240/17352 (47%)] Loss: -198998.187500\n",
      "Train Epoch: 21 [8320/17352 (48%)] Loss: -192872.718750\n",
      "Train Epoch: 21 [8400/17352 (48%)] Loss: -184745.890625\n",
      "Train Epoch: 21 [8480/17352 (49%)] Loss: -196549.984375\n",
      "Train Epoch: 21 [8560/17352 (49%)] Loss: -181884.250000\n",
      "Train Epoch: 21 [8640/17352 (50%)] Loss: -197336.890625\n",
      "Train Epoch: 21 [8720/17352 (50%)] Loss: -184945.875000\n",
      "Train Epoch: 21 [8800/17352 (51%)] Loss: -178425.984375\n",
      "Train Epoch: 21 [8880/17352 (51%)] Loss: -206193.500000\n",
      "Train Epoch: 21 [8960/17352 (52%)] Loss: -174718.640625\n",
      "Train Epoch: 21 [9040/17352 (52%)] Loss: -192115.375000\n",
      "Train Epoch: 21 [9120/17352 (53%)] Loss: -188960.546875\n",
      "Train Epoch: 21 [9200/17352 (53%)] Loss: -176075.687500\n",
      "Train Epoch: 21 [9280/17352 (53%)] Loss: -185985.921875\n",
      "Train Epoch: 21 [9360/17352 (54%)] Loss: -183209.906250\n",
      "Train Epoch: 21 [9440/17352 (54%)] Loss: -184925.562500\n",
      "Train Epoch: 21 [9520/17352 (55%)] Loss: -189564.765625\n",
      "Train Epoch: 21 [9600/17352 (55%)] Loss: -194985.578125\n",
      "Train Epoch: 21 [9680/17352 (56%)] Loss: -220964.796875\n",
      "Train Epoch: 21 [9760/17352 (56%)] Loss: -168076.031250\n",
      "Train Epoch: 21 [9840/17352 (57%)] Loss: -193903.968750\n",
      "Train Epoch: 21 [9920/17352 (57%)] Loss: -194561.093750\n",
      "Train Epoch: 21 [10000/17352 (58%)] Loss: -209251.265625\n",
      "Train Epoch: 21 [10080/17352 (58%)] Loss: -196812.609375\n",
      "Train Epoch: 21 [10160/17352 (59%)] Loss: -185776.500000\n",
      "Train Epoch: 21 [10240/17352 (59%)] Loss: -192105.093750\n",
      "Train Epoch: 21 [10320/17352 (59%)] Loss: -218834.656250\n",
      "Train Epoch: 21 [10400/17352 (60%)] Loss: -196016.625000\n",
      "Train Epoch: 21 [10480/17352 (60%)] Loss: -187251.578125\n",
      "Train Epoch: 21 [10560/17352 (61%)] Loss: -196727.843750\n",
      "Train Epoch: 21 [10640/17352 (61%)] Loss: -203835.203125\n",
      "Train Epoch: 21 [10720/17352 (62%)] Loss: -190493.812500\n",
      "Train Epoch: 21 [10800/17352 (62%)] Loss: -164132.187500\n",
      "Train Epoch: 21 [10880/17352 (63%)] Loss: -195098.546875\n",
      "Train Epoch: 21 [10960/17352 (63%)] Loss: -198251.203125\n",
      "Train Epoch: 21 [11040/17352 (64%)] Loss: -190568.984375\n",
      "Train Epoch: 21 [11120/17352 (64%)] Loss: -178988.734375\n",
      "Train Epoch: 21 [11200/17352 (65%)] Loss: -185033.656250\n",
      "Train Epoch: 21 [11280/17352 (65%)] Loss: -200416.015625\n",
      "Train Epoch: 21 [11360/17352 (65%)] Loss: -206590.500000\n",
      "Train Epoch: 21 [11440/17352 (66%)] Loss: -164069.359375\n",
      "Train Epoch: 21 [11520/17352 (66%)] Loss: -184837.484375\n",
      "Train Epoch: 21 [11600/17352 (67%)] Loss: -179459.781250\n",
      "Train Epoch: 21 [11680/17352 (67%)] Loss: -165994.937500\n",
      "Train Epoch: 21 [11760/17352 (68%)] Loss: -179965.656250\n",
      "Train Epoch: 21 [11840/17352 (68%)] Loss: -210779.937500\n",
      "Train Epoch: 21 [11920/17352 (69%)] Loss: -174934.218750\n",
      "Train Epoch: 21 [12000/17352 (69%)] Loss: -202584.781250\n",
      "Train Epoch: 21 [12080/17352 (70%)] Loss: -196290.453125\n",
      "Train Epoch: 21 [12160/17352 (70%)] Loss: -195825.109375\n",
      "Train Epoch: 21 [12240/17352 (71%)] Loss: -208888.453125\n",
      "Train Epoch: 21 [12320/17352 (71%)] Loss: -210486.500000\n",
      "Train Epoch: 21 [12400/17352 (71%)] Loss: -209805.796875\n",
      "Train Epoch: 21 [12480/17352 (72%)] Loss: -198282.828125\n",
      "Train Epoch: 21 [12560/17352 (72%)] Loss: -159673.031250\n",
      "Train Epoch: 21 [12640/17352 (73%)] Loss: -164994.359375\n",
      "Train Epoch: 21 [12720/17352 (73%)] Loss: -180788.437500\n",
      "Train Epoch: 21 [12800/17352 (74%)] Loss: -181714.375000\n",
      "Train Epoch: 21 [12880/17352 (74%)] Loss: -180641.906250\n",
      "Train Epoch: 21 [12960/17352 (75%)] Loss: -186842.453125\n",
      "Train Epoch: 21 [13040/17352 (75%)] Loss: -177233.796875\n",
      "Train Epoch: 21 [13120/17352 (76%)] Loss: -210622.812500\n",
      "Train Epoch: 21 [13200/17352 (76%)] Loss: -180742.828125\n",
      "Train Epoch: 21 [13280/17352 (77%)] Loss: -166984.859375\n",
      "Train Epoch: 21 [13360/17352 (77%)] Loss: -174179.968750\n",
      "Train Epoch: 21 [13440/17352 (77%)] Loss: -189469.734375\n",
      "Train Epoch: 21 [13520/17352 (78%)] Loss: -210153.250000\n",
      "Train Epoch: 21 [13600/17352 (78%)] Loss: -177192.000000\n",
      "Train Epoch: 21 [13680/17352 (79%)] Loss: -180978.906250\n",
      "Train Epoch: 21 [13760/17352 (79%)] Loss: -173353.296875\n",
      "Train Epoch: 21 [13840/17352 (80%)] Loss: -176866.531250\n",
      "Train Epoch: 21 [13920/17352 (80%)] Loss: -188003.250000\n",
      "Train Epoch: 21 [14000/17352 (81%)] Loss: -180227.484375\n",
      "Train Epoch: 21 [14080/17352 (81%)] Loss: -217612.781250\n",
      "Train Epoch: 21 [14160/17352 (82%)] Loss: -193168.406250\n",
      "Train Epoch: 21 [14240/17352 (82%)] Loss: -163547.296875\n",
      "Train Epoch: 21 [14320/17352 (83%)] Loss: -192228.500000\n",
      "Train Epoch: 21 [14400/17352 (83%)] Loss: -163083.093750\n",
      "Train Epoch: 21 [14480/17352 (83%)] Loss: -192161.421875\n",
      "Train Epoch: 21 [14560/17352 (84%)] Loss: -190795.187500\n",
      "Train Epoch: 21 [14640/17352 (84%)] Loss: -194215.890625\n",
      "Train Epoch: 21 [14720/17352 (85%)] Loss: -185348.296875\n",
      "Train Epoch: 21 [14800/17352 (85%)] Loss: -181006.828125\n",
      "Train Epoch: 21 [14880/17352 (86%)] Loss: -197430.843750\n",
      "Train Epoch: 21 [14960/17352 (86%)] Loss: -181062.296875\n",
      "Train Epoch: 21 [15040/17352 (87%)] Loss: -192274.812500\n",
      "Train Epoch: 21 [15120/17352 (87%)] Loss: -187584.546875\n",
      "Train Epoch: 21 [15200/17352 (88%)] Loss: -192243.609375\n",
      "Train Epoch: 21 [15280/17352 (88%)] Loss: -169965.468750\n",
      "Train Epoch: 21 [15360/17352 (89%)] Loss: -148446.328125\n",
      "Train Epoch: 21 [15440/17352 (89%)] Loss: -179476.265625\n",
      "Train Epoch: 21 [15520/17352 (89%)] Loss: -169616.437500\n",
      "Train Epoch: 21 [15600/17352 (90%)] Loss: -211156.234375\n",
      "Train Epoch: 21 [15680/17352 (90%)] Loss: -200155.343750\n",
      "Train Epoch: 21 [15760/17352 (91%)] Loss: -193539.437500\n",
      "Train Epoch: 21 [15840/17352 (91%)] Loss: -198001.859375\n",
      "Train Epoch: 21 [15920/17352 (92%)] Loss: -208719.484375\n",
      "Train Epoch: 21 [16000/17352 (92%)] Loss: -199055.093750\n",
      "Train Epoch: 21 [16080/17352 (93%)] Loss: -202311.687500\n",
      "Train Epoch: 21 [16160/17352 (93%)] Loss: -210548.671875\n",
      "Train Epoch: 21 [16240/17352 (94%)] Loss: -181910.812500\n",
      "Train Epoch: 21 [16320/17352 (94%)] Loss: -168184.171875\n",
      "Train Epoch: 21 [16400/17352 (95%)] Loss: -197372.531250\n",
      "Train Epoch: 21 [16480/17352 (95%)] Loss: -156992.843750\n",
      "Train Epoch: 21 [16560/17352 (95%)] Loss: -203727.640625\n",
      "Train Epoch: 21 [16640/17352 (96%)] Loss: -177571.609375\n",
      "Train Epoch: 21 [16720/17352 (96%)] Loss: -202214.953125\n",
      "Train Epoch: 21 [16800/17352 (97%)] Loss: -166433.062500\n",
      "Train Epoch: 21 [16880/17352 (97%)] Loss: -183916.937500\n",
      "Train Epoch: 21 [16960/17352 (98%)] Loss: -219998.625000\n",
      "Train Epoch: 21 [17040/17352 (98%)] Loss: -191516.312500\n",
      "Train Epoch: 21 [17120/17352 (99%)] Loss: -205381.109375\n",
      "Train Epoch: 21 [17200/17352 (99%)] Loss: -183394.671875\n",
      "Train Epoch: 21 [17280/17352 (100%)] Loss: -183385.078125\n",
      "Train Epoch: 21 [17360/17352 (100%)] Loss: -199141.218750\n",
      "    epoch          : 21\n",
      "    loss           : -189311.94326273014\n",
      "    val_loss       : -23714.388299574875\n",
      "Train Epoch: 22 [0/17352 (0%)] Loss: -199534.656250\n",
      "Train Epoch: 22 [80/17352 (0%)] Loss: -241893.812500\n",
      "Train Epoch: 22 [160/17352 (1%)] Loss: -206548.109375\n",
      "Train Epoch: 22 [240/17352 (1%)] Loss: -214447.015625\n",
      "Train Epoch: 22 [320/17352 (2%)] Loss: -193558.765625\n",
      "Train Epoch: 22 [400/17352 (2%)] Loss: -205538.937500\n",
      "Train Epoch: 22 [480/17352 (3%)] Loss: -204385.953125\n",
      "Train Epoch: 22 [560/17352 (3%)] Loss: -214318.875000\n",
      "Train Epoch: 22 [640/17352 (4%)] Loss: -214511.875000\n",
      "Train Epoch: 22 [720/17352 (4%)] Loss: -236831.390625\n",
      "Train Epoch: 22 [800/17352 (5%)] Loss: -230387.984375\n",
      "Train Epoch: 22 [880/17352 (5%)] Loss: -235586.250000\n",
      "Train Epoch: 22 [960/17352 (6%)] Loss: -211087.093750\n",
      "Train Epoch: 22 [1040/17352 (6%)] Loss: -224235.250000\n",
      "Train Epoch: 22 [1120/17352 (6%)] Loss: -222513.609375\n",
      "Train Epoch: 22 [1200/17352 (7%)] Loss: -204732.656250\n",
      "Train Epoch: 22 [1280/17352 (7%)] Loss: -182763.375000\n",
      "Train Epoch: 22 [1360/17352 (8%)] Loss: -219654.531250\n",
      "Train Epoch: 22 [1440/17352 (8%)] Loss: -185139.218750\n",
      "Train Epoch: 22 [1520/17352 (9%)] Loss: -194284.968750\n",
      "Train Epoch: 22 [1600/17352 (9%)] Loss: -222998.890625\n",
      "Train Epoch: 22 [1680/17352 (10%)] Loss: -214421.984375\n",
      "Train Epoch: 22 [1760/17352 (10%)] Loss: -193404.218750\n",
      "Train Epoch: 22 [1840/17352 (11%)] Loss: -218518.578125\n",
      "Train Epoch: 22 [1920/17352 (11%)] Loss: -215480.390625\n",
      "Train Epoch: 22 [2000/17352 (12%)] Loss: -208377.812500\n",
      "Train Epoch: 22 [2080/17352 (12%)] Loss: -212170.281250\n",
      "Train Epoch: 22 [2160/17352 (12%)] Loss: -204020.984375\n",
      "Train Epoch: 22 [2240/17352 (13%)] Loss: -231021.125000\n",
      "Train Epoch: 22 [2320/17352 (13%)] Loss: -190003.609375\n",
      "Train Epoch: 22 [2400/17352 (14%)] Loss: -228245.390625\n",
      "Train Epoch: 22 [2480/17352 (14%)] Loss: -200106.687500\n",
      "Train Epoch: 22 [2560/17352 (15%)] Loss: -183392.875000\n",
      "Train Epoch: 22 [2640/17352 (15%)] Loss: -199783.468750\n",
      "Train Epoch: 22 [2720/17352 (16%)] Loss: -216316.875000\n",
      "Train Epoch: 22 [2800/17352 (16%)] Loss: -180096.843750\n",
      "Train Epoch: 22 [2880/17352 (17%)] Loss: -200980.843750\n",
      "Train Epoch: 22 [2960/17352 (17%)] Loss: -177750.734375\n",
      "Train Epoch: 22 [3040/17352 (18%)] Loss: -199166.593750\n",
      "Train Epoch: 22 [3120/17352 (18%)] Loss: -183462.890625\n",
      "Train Epoch: 22 [3200/17352 (18%)] Loss: -209256.937500\n",
      "Train Epoch: 22 [3280/17352 (19%)] Loss: -169498.859375\n",
      "Train Epoch: 22 [3360/17352 (19%)] Loss: -221242.718750\n",
      "Train Epoch: 22 [3440/17352 (20%)] Loss: -185358.546875\n",
      "Train Epoch: 22 [3520/17352 (20%)] Loss: -192950.937500\n",
      "Train Epoch: 22 [3600/17352 (21%)] Loss: -183923.953125\n",
      "Train Epoch: 22 [3680/17352 (21%)] Loss: -181972.718750\n",
      "Train Epoch: 22 [3760/17352 (22%)] Loss: -198820.140625\n",
      "Train Epoch: 22 [3840/17352 (22%)] Loss: -209177.453125\n",
      "Train Epoch: 22 [3920/17352 (23%)] Loss: -184747.546875\n",
      "Train Epoch: 22 [4000/17352 (23%)] Loss: -178082.484375\n",
      "Train Epoch: 22 [4080/17352 (24%)] Loss: -166451.484375\n",
      "Train Epoch: 22 [4160/17352 (24%)] Loss: -185981.281250\n",
      "Train Epoch: 22 [4240/17352 (24%)] Loss: -210554.781250\n",
      "Train Epoch: 22 [4320/17352 (25%)] Loss: -171181.843750\n",
      "Train Epoch: 22 [4400/17352 (25%)] Loss: -158255.484375\n",
      "Train Epoch: 22 [4480/17352 (26%)] Loss: -213393.968750\n",
      "Train Epoch: 22 [4560/17352 (26%)] Loss: -182728.640625\n",
      "Train Epoch: 22 [4640/17352 (27%)] Loss: -198543.375000\n",
      "Train Epoch: 22 [4720/17352 (27%)] Loss: -163111.187500\n",
      "Train Epoch: 22 [4800/17352 (28%)] Loss: -179008.671875\n",
      "Train Epoch: 22 [4880/17352 (28%)] Loss: -202978.312500\n",
      "Train Epoch: 22 [4960/17352 (29%)] Loss: -182759.578125\n",
      "Train Epoch: 22 [5040/17352 (29%)] Loss: -164984.828125\n",
      "Train Epoch: 22 [5120/17352 (30%)] Loss: -179952.921875\n",
      "Train Epoch: 22 [5200/17352 (30%)] Loss: -176885.437500\n",
      "Train Epoch: 22 [5280/17352 (30%)] Loss: -194938.765625\n",
      "Train Epoch: 22 [5360/17352 (31%)] Loss: -172602.468750\n",
      "Train Epoch: 22 [5440/17352 (31%)] Loss: -185232.765625\n",
      "Train Epoch: 22 [5520/17352 (32%)] Loss: -187339.968750\n",
      "Train Epoch: 22 [5600/17352 (32%)] Loss: -207844.390625\n",
      "Train Epoch: 22 [5680/17352 (33%)] Loss: -174026.875000\n",
      "Train Epoch: 22 [5760/17352 (33%)] Loss: -163953.125000\n",
      "Train Epoch: 22 [5840/17352 (34%)] Loss: -200472.515625\n",
      "Train Epoch: 22 [5920/17352 (34%)] Loss: -177240.187500\n",
      "Train Epoch: 22 [6000/17352 (35%)] Loss: -180537.140625\n",
      "Train Epoch: 22 [6080/17352 (35%)] Loss: -191799.984375\n",
      "Train Epoch: 22 [6160/17352 (36%)] Loss: -200159.906250\n",
      "Train Epoch: 22 [6240/17352 (36%)] Loss: -186765.187500\n",
      "Train Epoch: 22 [6320/17352 (36%)] Loss: -205478.625000\n",
      "Train Epoch: 22 [6400/17352 (37%)] Loss: -187319.187500\n",
      "Train Epoch: 22 [6480/17352 (37%)] Loss: -200328.562500\n",
      "Train Epoch: 22 [6560/17352 (38%)] Loss: -210376.234375\n",
      "Train Epoch: 22 [6640/17352 (38%)] Loss: -180689.406250\n",
      "Train Epoch: 22 [6720/17352 (39%)] Loss: -191629.390625\n",
      "Train Epoch: 22 [6800/17352 (39%)] Loss: -195823.484375\n",
      "Train Epoch: 22 [6880/17352 (40%)] Loss: -200160.234375\n",
      "Train Epoch: 22 [6960/17352 (40%)] Loss: -208898.796875\n",
      "Train Epoch: 22 [7040/17352 (41%)] Loss: -219995.781250\n",
      "Train Epoch: 22 [7120/17352 (41%)] Loss: -193335.140625\n",
      "Train Epoch: 22 [7200/17352 (41%)] Loss: -196723.968750\n",
      "Train Epoch: 22 [7280/17352 (42%)] Loss: -195876.937500\n",
      "Train Epoch: 22 [7360/17352 (42%)] Loss: -213222.515625\n",
      "Train Epoch: 22 [7440/17352 (43%)] Loss: -213904.406250\n",
      "Train Epoch: 22 [7520/17352 (43%)] Loss: -204338.984375\n",
      "Train Epoch: 22 [7600/17352 (44%)] Loss: -192851.375000\n",
      "Train Epoch: 22 [7680/17352 (44%)] Loss: -192255.234375\n",
      "Train Epoch: 22 [7760/17352 (45%)] Loss: -198013.156250\n",
      "Train Epoch: 22 [7840/17352 (45%)] Loss: -195498.984375\n",
      "Train Epoch: 22 [7920/17352 (46%)] Loss: -191712.156250\n",
      "Train Epoch: 22 [8000/17352 (46%)] Loss: -205146.796875\n",
      "Train Epoch: 22 [8080/17352 (47%)] Loss: -188260.078125\n",
      "Train Epoch: 22 [8160/17352 (47%)] Loss: -192154.562500\n",
      "Train Epoch: 22 [8240/17352 (47%)] Loss: -189558.265625\n",
      "Train Epoch: 22 [8320/17352 (48%)] Loss: -196915.093750\n",
      "Train Epoch: 22 [8400/17352 (48%)] Loss: -181685.250000\n",
      "Train Epoch: 22 [8480/17352 (49%)] Loss: -182547.906250\n",
      "Train Epoch: 22 [8560/17352 (49%)] Loss: -174507.140625\n",
      "Train Epoch: 22 [8640/17352 (50%)] Loss: -188198.937500\n",
      "Train Epoch: 22 [8720/17352 (50%)] Loss: -198792.062500\n",
      "Train Epoch: 22 [8800/17352 (51%)] Loss: -178304.890625\n",
      "Train Epoch: 22 [8880/17352 (51%)] Loss: -186178.046875\n",
      "Train Epoch: 22 [8960/17352 (52%)] Loss: -187997.375000\n",
      "Train Epoch: 22 [9040/17352 (52%)] Loss: -193501.171875\n",
      "Train Epoch: 22 [9120/17352 (53%)] Loss: -170527.140625\n",
      "Train Epoch: 22 [9200/17352 (53%)] Loss: -202515.812500\n",
      "Train Epoch: 22 [9280/17352 (53%)] Loss: -199408.703125\n",
      "Train Epoch: 22 [9360/17352 (54%)] Loss: -181325.953125\n",
      "Train Epoch: 22 [9440/17352 (54%)] Loss: -209586.125000\n",
      "Train Epoch: 22 [9520/17352 (55%)] Loss: -187125.656250\n",
      "Train Epoch: 22 [9600/17352 (55%)] Loss: -188417.484375\n",
      "Train Epoch: 22 [9680/17352 (56%)] Loss: -177966.828125\n",
      "Train Epoch: 22 [9760/17352 (56%)] Loss: -149326.421875\n",
      "Train Epoch: 22 [9840/17352 (57%)] Loss: -181737.015625\n",
      "Train Epoch: 22 [9920/17352 (57%)] Loss: -167233.968750\n",
      "Train Epoch: 22 [10000/17352 (58%)] Loss: -180994.906250\n",
      "Train Epoch: 22 [10080/17352 (58%)] Loss: -181753.875000\n",
      "Train Epoch: 22 [10160/17352 (59%)] Loss: -197428.093750\n",
      "Train Epoch: 22 [10240/17352 (59%)] Loss: -187218.609375\n",
      "Train Epoch: 22 [10320/17352 (59%)] Loss: -184274.453125\n",
      "Train Epoch: 22 [10400/17352 (60%)] Loss: -180782.375000\n",
      "Train Epoch: 22 [10480/17352 (60%)] Loss: -208145.921875\n",
      "Train Epoch: 22 [10560/17352 (61%)] Loss: -199716.421875\n",
      "Train Epoch: 22 [10640/17352 (61%)] Loss: -199767.078125\n",
      "Train Epoch: 22 [10720/17352 (62%)] Loss: -173433.359375\n",
      "Train Epoch: 22 [10800/17352 (62%)] Loss: -159664.656250\n",
      "Train Epoch: 22 [10880/17352 (63%)] Loss: -180229.109375\n",
      "Train Epoch: 22 [10960/17352 (63%)] Loss: -183150.703125\n",
      "Train Epoch: 22 [11040/17352 (64%)] Loss: -207084.890625\n",
      "Train Epoch: 22 [11120/17352 (64%)] Loss: -195771.265625\n",
      "Train Epoch: 22 [11200/17352 (65%)] Loss: -180239.906250\n",
      "Train Epoch: 22 [11280/17352 (65%)] Loss: -196304.796875\n",
      "Train Epoch: 22 [11360/17352 (65%)] Loss: -190496.656250\n",
      "Train Epoch: 22 [11440/17352 (66%)] Loss: -176919.859375\n",
      "Train Epoch: 22 [11520/17352 (66%)] Loss: -195108.718750\n",
      "Train Epoch: 22 [11600/17352 (67%)] Loss: -192364.046875\n",
      "Train Epoch: 22 [11680/17352 (67%)] Loss: -193040.046875\n",
      "Train Epoch: 22 [11760/17352 (68%)] Loss: -158741.703125\n",
      "Train Epoch: 22 [11840/17352 (68%)] Loss: -199881.187500\n",
      "Train Epoch: 22 [11920/17352 (69%)] Loss: -175540.765625\n",
      "Train Epoch: 22 [12000/17352 (69%)] Loss: -174636.281250\n",
      "Train Epoch: 22 [12080/17352 (70%)] Loss: -188244.875000\n",
      "Train Epoch: 22 [12160/17352 (70%)] Loss: -174998.000000\n",
      "Train Epoch: 22 [12240/17352 (71%)] Loss: -174929.843750\n",
      "Train Epoch: 22 [12320/17352 (71%)] Loss: -194593.187500\n",
      "Train Epoch: 22 [12400/17352 (71%)] Loss: -169438.640625\n",
      "Train Epoch: 22 [12480/17352 (72%)] Loss: -198286.921875\n",
      "Train Epoch: 22 [12560/17352 (72%)] Loss: -155850.140625\n",
      "Train Epoch: 22 [12640/17352 (73%)] Loss: -183587.078125\n",
      "Train Epoch: 22 [12720/17352 (73%)] Loss: -184057.890625\n",
      "Train Epoch: 22 [12800/17352 (74%)] Loss: -179156.875000\n",
      "Train Epoch: 22 [12880/17352 (74%)] Loss: -146000.421875\n",
      "Train Epoch: 22 [12960/17352 (75%)] Loss: -211621.156250\n",
      "Train Epoch: 22 [13040/17352 (75%)] Loss: -207842.250000\n",
      "Train Epoch: 22 [13120/17352 (76%)] Loss: -165986.296875\n",
      "Train Epoch: 22 [13200/17352 (76%)] Loss: -184162.656250\n",
      "Train Epoch: 22 [13280/17352 (77%)] Loss: -187755.093750\n",
      "Train Epoch: 22 [13360/17352 (77%)] Loss: -203506.453125\n",
      "Train Epoch: 22 [13440/17352 (77%)] Loss: -187950.250000\n",
      "Train Epoch: 22 [13520/17352 (78%)] Loss: -165797.625000\n",
      "Train Epoch: 22 [13600/17352 (78%)] Loss: -187259.781250\n",
      "Train Epoch: 22 [13680/17352 (79%)] Loss: -159656.984375\n",
      "Train Epoch: 22 [13760/17352 (79%)] Loss: -189300.265625\n",
      "Train Epoch: 22 [13840/17352 (80%)] Loss: -196189.890625\n",
      "Train Epoch: 22 [13920/17352 (80%)] Loss: -163332.343750\n",
      "Train Epoch: 22 [14000/17352 (81%)] Loss: -191997.046875\n",
      "Train Epoch: 22 [14080/17352 (81%)] Loss: -190081.656250\n",
      "Train Epoch: 22 [14160/17352 (82%)] Loss: -203810.500000\n",
      "Train Epoch: 22 [14240/17352 (82%)] Loss: -201024.343750\n",
      "Train Epoch: 22 [14320/17352 (83%)] Loss: -172221.984375\n",
      "Train Epoch: 22 [14400/17352 (83%)] Loss: -205531.781250\n",
      "Train Epoch: 22 [14480/17352 (83%)] Loss: -207821.781250\n",
      "Train Epoch: 22 [14560/17352 (84%)] Loss: -166402.000000\n",
      "Train Epoch: 22 [14640/17352 (84%)] Loss: -192940.734375\n",
      "Train Epoch: 22 [14720/17352 (85%)] Loss: -177473.437500\n",
      "Train Epoch: 22 [14800/17352 (85%)] Loss: -163244.906250\n",
      "Train Epoch: 22 [14880/17352 (86%)] Loss: -200607.468750\n",
      "Train Epoch: 22 [14960/17352 (86%)] Loss: -181673.343750\n",
      "Train Epoch: 22 [15040/17352 (87%)] Loss: -192676.421875\n",
      "Train Epoch: 22 [15120/17352 (87%)] Loss: -186496.156250\n",
      "Train Epoch: 22 [15200/17352 (88%)] Loss: -196016.796875\n",
      "Train Epoch: 22 [15280/17352 (88%)] Loss: -218456.625000\n",
      "Train Epoch: 22 [15360/17352 (89%)] Loss: -169965.890625\n",
      "Train Epoch: 22 [15440/17352 (89%)] Loss: -183364.640625\n",
      "Train Epoch: 22 [15520/17352 (89%)] Loss: -210488.875000\n",
      "Train Epoch: 22 [15600/17352 (90%)] Loss: -176582.078125\n",
      "Train Epoch: 22 [15680/17352 (90%)] Loss: -170678.062500\n",
      "Train Epoch: 22 [15760/17352 (91%)] Loss: -199588.125000\n",
      "Train Epoch: 22 [15840/17352 (91%)] Loss: -174911.531250\n",
      "Train Epoch: 22 [15920/17352 (92%)] Loss: -197638.968750\n",
      "Train Epoch: 22 [16000/17352 (92%)] Loss: -191802.046875\n",
      "Train Epoch: 22 [16080/17352 (93%)] Loss: -178317.890625\n",
      "Train Epoch: 22 [16160/17352 (93%)] Loss: -171887.546875\n",
      "Train Epoch: 22 [16240/17352 (94%)] Loss: -164497.812500\n",
      "Train Epoch: 22 [16320/17352 (94%)] Loss: -218402.437500\n",
      "Train Epoch: 22 [16400/17352 (95%)] Loss: -224870.187500\n",
      "Train Epoch: 22 [16480/17352 (95%)] Loss: -148438.718750\n",
      "Train Epoch: 22 [16560/17352 (95%)] Loss: -190996.937500\n",
      "Train Epoch: 22 [16640/17352 (96%)] Loss: -196450.453125\n",
      "Train Epoch: 22 [16720/17352 (96%)] Loss: -180510.687500\n",
      "Train Epoch: 22 [16800/17352 (97%)] Loss: -196144.890625\n",
      "Train Epoch: 22 [16880/17352 (97%)] Loss: -171304.578125\n",
      "Train Epoch: 22 [16960/17352 (98%)] Loss: -177586.312500\n",
      "Train Epoch: 22 [17040/17352 (98%)] Loss: -173501.968750\n",
      "Train Epoch: 22 [17120/17352 (99%)] Loss: -197069.046875\n",
      "Train Epoch: 22 [17200/17352 (99%)] Loss: -171724.187500\n",
      "Train Epoch: 22 [17280/17352 (100%)] Loss: -186720.546875\n",
      "Train Epoch: 22 [17360/17352 (100%)] Loss: -185492.281250\n",
      "    epoch          : 22\n",
      "    loss           : -189281.92691851265\n",
      "    val_loss       : -23714.57100251247\n",
      "Train Epoch: 23 [0/17352 (0%)] Loss: -203737.734375\n",
      "Train Epoch: 23 [80/17352 (0%)] Loss: -205172.078125\n",
      "Train Epoch: 23 [160/17352 (1%)] Loss: -230180.609375\n",
      "Train Epoch: 23 [240/17352 (1%)] Loss: -215813.812500\n",
      "Train Epoch: 23 [320/17352 (2%)] Loss: -210520.421875\n",
      "Train Epoch: 23 [400/17352 (2%)] Loss: -191869.046875\n",
      "Train Epoch: 23 [480/17352 (3%)] Loss: -215487.546875\n",
      "Train Epoch: 23 [560/17352 (3%)] Loss: -208524.484375\n",
      "Train Epoch: 23 [640/17352 (4%)] Loss: -212383.078125\n",
      "Train Epoch: 23 [720/17352 (4%)] Loss: -227996.500000\n",
      "Train Epoch: 23 [800/17352 (5%)] Loss: -199808.812500\n",
      "Train Epoch: 23 [880/17352 (5%)] Loss: -206131.015625\n",
      "Train Epoch: 23 [960/17352 (6%)] Loss: -215088.859375\n",
      "Train Epoch: 23 [1040/17352 (6%)] Loss: -210202.453125\n",
      "Train Epoch: 23 [1120/17352 (6%)] Loss: -216204.234375\n",
      "Train Epoch: 23 [1200/17352 (7%)] Loss: -206563.484375\n",
      "Train Epoch: 23 [1280/17352 (7%)] Loss: -206739.515625\n",
      "Train Epoch: 23 [1360/17352 (8%)] Loss: -226087.531250\n",
      "Train Epoch: 23 [1440/17352 (8%)] Loss: -222512.687500\n",
      "Train Epoch: 23 [1520/17352 (9%)] Loss: -202322.265625\n",
      "Train Epoch: 23 [1600/17352 (9%)] Loss: -205100.937500\n",
      "Train Epoch: 23 [1680/17352 (10%)] Loss: -212184.250000\n",
      "Train Epoch: 23 [1760/17352 (10%)] Loss: -204727.812500\n",
      "Train Epoch: 23 [1840/17352 (11%)] Loss: -221743.703125\n",
      "Train Epoch: 23 [1920/17352 (11%)] Loss: -218541.593750\n",
      "Train Epoch: 23 [2000/17352 (12%)] Loss: -209635.437500\n",
      "Train Epoch: 23 [2080/17352 (12%)] Loss: -210334.140625\n",
      "Train Epoch: 23 [2160/17352 (12%)] Loss: -198750.437500\n",
      "Train Epoch: 23 [2240/17352 (13%)] Loss: -166787.390625\n",
      "Train Epoch: 23 [2320/17352 (13%)] Loss: -204322.781250\n",
      "Train Epoch: 23 [2400/17352 (14%)] Loss: -172232.640625\n",
      "Train Epoch: 23 [2480/17352 (14%)] Loss: -174035.859375\n",
      "Train Epoch: 23 [2560/17352 (15%)] Loss: -202076.609375\n",
      "Train Epoch: 23 [2640/17352 (15%)] Loss: -177958.562500\n",
      "Train Epoch: 23 [2720/17352 (16%)] Loss: -176283.625000\n",
      "Train Epoch: 23 [2800/17352 (16%)] Loss: -205395.703125\n",
      "Train Epoch: 23 [2880/17352 (17%)] Loss: -185225.109375\n",
      "Train Epoch: 23 [2960/17352 (17%)] Loss: -179963.765625\n",
      "Train Epoch: 23 [3040/17352 (18%)] Loss: -228148.375000\n",
      "Train Epoch: 23 [3120/17352 (18%)] Loss: -213894.703125\n",
      "Train Epoch: 23 [3200/17352 (18%)] Loss: -162558.906250\n",
      "Train Epoch: 23 [3280/17352 (19%)] Loss: -191799.687500\n",
      "Train Epoch: 23 [3360/17352 (19%)] Loss: -178419.015625\n",
      "Train Epoch: 23 [3440/17352 (20%)] Loss: -187267.796875\n",
      "Train Epoch: 23 [3520/17352 (20%)] Loss: -205625.375000\n",
      "Train Epoch: 23 [3600/17352 (21%)] Loss: -131034.132812\n",
      "Train Epoch: 23 [3680/17352 (21%)] Loss: -189397.156250\n",
      "Train Epoch: 23 [3760/17352 (22%)] Loss: -167870.328125\n",
      "Train Epoch: 23 [3840/17352 (22%)] Loss: -170684.031250\n",
      "Train Epoch: 23 [3920/17352 (23%)] Loss: -173647.046875\n",
      "Train Epoch: 23 [4000/17352 (23%)] Loss: -216316.750000\n",
      "Train Epoch: 23 [4080/17352 (24%)] Loss: -191879.156250\n",
      "Train Epoch: 23 [4160/17352 (24%)] Loss: -202975.765625\n",
      "Train Epoch: 23 [4240/17352 (24%)] Loss: -184456.953125\n",
      "Train Epoch: 23 [4320/17352 (25%)] Loss: -180546.468750\n",
      "Train Epoch: 23 [4400/17352 (25%)] Loss: -202843.843750\n",
      "Train Epoch: 23 [4480/17352 (26%)] Loss: -215625.281250\n",
      "Train Epoch: 23 [4560/17352 (26%)] Loss: -225468.093750\n",
      "Train Epoch: 23 [4640/17352 (27%)] Loss: -209259.234375\n",
      "Train Epoch: 23 [4720/17352 (27%)] Loss: -208011.406250\n",
      "Train Epoch: 23 [4800/17352 (28%)] Loss: -148388.406250\n",
      "Train Epoch: 23 [4880/17352 (28%)] Loss: -198545.781250\n",
      "Train Epoch: 23 [4960/17352 (29%)] Loss: -180740.921875\n",
      "Train Epoch: 23 [5040/17352 (29%)] Loss: -200217.593750\n",
      "Train Epoch: 23 [5120/17352 (30%)] Loss: -178811.703125\n",
      "Train Epoch: 23 [5200/17352 (30%)] Loss: -177440.281250\n",
      "Train Epoch: 23 [5280/17352 (30%)] Loss: -187457.187500\n",
      "Train Epoch: 23 [5360/17352 (31%)] Loss: -184168.156250\n",
      "Train Epoch: 23 [5440/17352 (31%)] Loss: -191037.546875\n",
      "Train Epoch: 23 [5520/17352 (32%)] Loss: -161958.093750\n",
      "Train Epoch: 23 [5600/17352 (32%)] Loss: -159656.000000\n",
      "Train Epoch: 23 [5680/17352 (33%)] Loss: -184606.296875\n",
      "Train Epoch: 23 [5760/17352 (33%)] Loss: -148908.812500\n",
      "Train Epoch: 23 [5840/17352 (34%)] Loss: -146852.046875\n",
      "Train Epoch: 23 [5920/17352 (34%)] Loss: -183746.546875\n",
      "Train Epoch: 23 [6000/17352 (35%)] Loss: -206151.468750\n",
      "Train Epoch: 23 [6080/17352 (35%)] Loss: -176139.171875\n",
      "Train Epoch: 23 [6160/17352 (36%)] Loss: -171316.031250\n",
      "Train Epoch: 23 [6240/17352 (36%)] Loss: -156985.046875\n",
      "Train Epoch: 23 [6320/17352 (36%)] Loss: -195059.312500\n",
      "Train Epoch: 23 [6400/17352 (37%)] Loss: -176050.750000\n",
      "Train Epoch: 23 [6480/17352 (37%)] Loss: -180043.875000\n",
      "Train Epoch: 23 [6560/17352 (38%)] Loss: -180695.531250\n",
      "Train Epoch: 23 [6640/17352 (38%)] Loss: -213220.015625\n",
      "Train Epoch: 23 [6720/17352 (39%)] Loss: -174479.359375\n",
      "Train Epoch: 23 [6800/17352 (39%)] Loss: -186678.781250\n",
      "Train Epoch: 23 [6880/17352 (40%)] Loss: -190225.765625\n",
      "Train Epoch: 23 [6960/17352 (40%)] Loss: -181318.937500\n",
      "Train Epoch: 23 [7040/17352 (41%)] Loss: -156594.625000\n",
      "Train Epoch: 23 [7120/17352 (41%)] Loss: -175000.031250\n",
      "Train Epoch: 23 [7200/17352 (41%)] Loss: -187699.562500\n",
      "Train Epoch: 23 [7280/17352 (42%)] Loss: -183284.843750\n",
      "Train Epoch: 23 [7360/17352 (42%)] Loss: -187205.828125\n",
      "Train Epoch: 23 [7440/17352 (43%)] Loss: -188243.312500\n",
      "Train Epoch: 23 [7520/17352 (43%)] Loss: -196030.843750\n",
      "Train Epoch: 23 [7600/17352 (44%)] Loss: -169963.171875\n",
      "Train Epoch: 23 [7680/17352 (44%)] Loss: -193336.671875\n",
      "Train Epoch: 23 [7760/17352 (45%)] Loss: -181955.406250\n",
      "Train Epoch: 23 [7840/17352 (45%)] Loss: -192246.546875\n",
      "Train Epoch: 23 [7920/17352 (46%)] Loss: -175682.546875\n",
      "Train Epoch: 23 [8000/17352 (46%)] Loss: -174968.750000\n",
      "Train Epoch: 23 [8080/17352 (47%)] Loss: -201025.578125\n",
      "Train Epoch: 23 [8160/17352 (47%)] Loss: -203870.296875\n",
      "Train Epoch: 23 [8240/17352 (47%)] Loss: -187502.515625\n",
      "Train Epoch: 23 [8320/17352 (48%)] Loss: -164504.343750\n",
      "Train Epoch: 23 [8400/17352 (48%)] Loss: -184262.281250\n",
      "Train Epoch: 23 [8480/17352 (49%)] Loss: -199791.812500\n",
      "Train Epoch: 23 [8560/17352 (49%)] Loss: -190570.921875\n",
      "Train Epoch: 23 [8640/17352 (50%)] Loss: -193164.093750\n",
      "Train Epoch: 23 [8720/17352 (50%)] Loss: -195374.218750\n",
      "Train Epoch: 23 [8800/17352 (51%)] Loss: -185383.296875\n",
      "Train Epoch: 23 [8880/17352 (51%)] Loss: -179471.062500\n",
      "Train Epoch: 23 [8960/17352 (52%)] Loss: -159663.703125\n",
      "Train Epoch: 23 [9040/17352 (52%)] Loss: -187343.562500\n",
      "Train Epoch: 23 [9120/17352 (53%)] Loss: -196680.968750\n",
      "Train Epoch: 23 [9200/17352 (53%)] Loss: -178828.109375\n",
      "Train Epoch: 23 [9280/17352 (53%)] Loss: -213747.640625\n",
      "Train Epoch: 23 [9360/17352 (54%)] Loss: -164070.625000\n",
      "Train Epoch: 23 [9440/17352 (54%)] Loss: -158729.812500\n",
      "Train Epoch: 23 [9520/17352 (55%)] Loss: -143604.234375\n",
      "Train Epoch: 23 [9600/17352 (55%)] Loss: -196433.656250\n",
      "Train Epoch: 23 [9680/17352 (56%)] Loss: -179490.625000\n",
      "Train Epoch: 23 [9760/17352 (56%)] Loss: -177169.828125\n",
      "Train Epoch: 23 [9840/17352 (57%)] Loss: -163113.671875\n",
      "Train Epoch: 23 [9920/17352 (57%)] Loss: -203734.437500\n",
      "Train Epoch: 23 [10000/17352 (58%)] Loss: -178869.593750\n",
      "Train Epoch: 23 [10080/17352 (58%)] Loss: -197073.765625\n",
      "Train Epoch: 23 [10160/17352 (59%)] Loss: -210483.062500\n",
      "Train Epoch: 23 [10240/17352 (59%)] Loss: -195771.546875\n",
      "Train Epoch: 23 [10320/17352 (59%)] Loss: -203809.593750\n",
      "Train Epoch: 23 [10400/17352 (60%)] Loss: -192271.375000\n",
      "Train Epoch: 23 [10480/17352 (60%)] Loss: -176911.062500\n",
      "Train Epoch: 23 [10560/17352 (61%)] Loss: -146000.656250\n",
      "Train Epoch: 23 [10640/17352 (61%)] Loss: -208117.171875\n",
      "Train Epoch: 23 [10720/17352 (62%)] Loss: -204609.500000\n",
      "Train Epoch: 23 [10800/17352 (62%)] Loss: -162712.781250\n",
      "Train Epoch: 23 [10880/17352 (63%)] Loss: -207846.015625\n",
      "Train Epoch: 23 [10960/17352 (63%)] Loss: -188671.000000\n",
      "Train Epoch: 23 [11040/17352 (64%)] Loss: -198813.578125\n",
      "Train Epoch: 23 [11120/17352 (64%)] Loss: -201928.671875\n",
      "Train Epoch: 23 [11200/17352 (65%)] Loss: -231032.734375\n",
      "Train Epoch: 23 [11280/17352 (65%)] Loss: -153313.281250\n",
      "Train Epoch: 23 [11360/17352 (65%)] Loss: -201359.546875\n",
      "Train Epoch: 23 [11440/17352 (66%)] Loss: -204335.031250\n",
      "Train Epoch: 23 [11520/17352 (66%)] Loss: -168498.375000\n",
      "Train Epoch: 23 [11600/17352 (67%)] Loss: -194069.312500\n",
      "Train Epoch: 23 [11680/17352 (67%)] Loss: -208302.390625\n",
      "Train Epoch: 23 [11760/17352 (68%)] Loss: -204362.968750\n",
      "Train Epoch: 23 [11840/17352 (68%)] Loss: -183053.312500\n",
      "Train Epoch: 23 [11920/17352 (69%)] Loss: -168968.187500\n",
      "Train Epoch: 23 [12000/17352 (69%)] Loss: -187938.828125\n",
      "Train Epoch: 23 [12080/17352 (70%)] Loss: -192999.734375\n",
      "Train Epoch: 23 [12160/17352 (70%)] Loss: -158250.250000\n",
      "Train Epoch: 23 [12240/17352 (71%)] Loss: -189014.359375\n",
      "Train Epoch: 23 [12320/17352 (71%)] Loss: -185353.390625\n",
      "Train Epoch: 23 [12400/17352 (71%)] Loss: -178376.546875\n",
      "Train Epoch: 23 [12480/17352 (72%)] Loss: -210546.625000\n",
      "Train Epoch: 23 [12560/17352 (72%)] Loss: -197298.828125\n",
      "Train Epoch: 23 [12640/17352 (73%)] Loss: -189477.171875\n",
      "Train Epoch: 23 [12720/17352 (73%)] Loss: -178190.890625\n",
      "Train Epoch: 23 [12800/17352 (74%)] Loss: -197102.671875\n",
      "Train Epoch: 23 [12880/17352 (74%)] Loss: -186425.968750\n",
      "Train Epoch: 23 [12960/17352 (75%)] Loss: -200629.546875\n",
      "Train Epoch: 23 [13040/17352 (75%)] Loss: -180499.453125\n",
      "Train Epoch: 23 [13120/17352 (76%)] Loss: -182742.531250\n",
      "Train Epoch: 23 [13200/17352 (76%)] Loss: -174931.390625\n",
      "Train Epoch: 23 [13280/17352 (77%)] Loss: -219927.953125\n",
      "Train Epoch: 23 [13360/17352 (77%)] Loss: -196272.406250\n",
      "Train Epoch: 23 [13440/17352 (77%)] Loss: -186940.781250\n",
      "Train Epoch: 23 [13520/17352 (78%)] Loss: -174715.812500\n",
      "Train Epoch: 23 [13600/17352 (78%)] Loss: -191322.718750\n",
      "Train Epoch: 23 [13680/17352 (79%)] Loss: -169437.437500\n",
      "Train Epoch: 23 [13760/17352 (79%)] Loss: -193185.062500\n",
      "Train Epoch: 23 [13840/17352 (80%)] Loss: -192947.531250\n",
      "Train Epoch: 23 [13920/17352 (80%)] Loss: -202783.218750\n",
      "Train Epoch: 23 [14000/17352 (81%)] Loss: -177767.750000\n",
      "Train Epoch: 23 [14080/17352 (81%)] Loss: -175409.843750\n",
      "Train Epoch: 23 [14160/17352 (82%)] Loss: -199440.921875\n",
      "Train Epoch: 23 [14240/17352 (82%)] Loss: -188176.437500\n",
      "Train Epoch: 23 [14320/17352 (83%)] Loss: -205723.218750\n",
      "Train Epoch: 23 [14400/17352 (83%)] Loss: -223689.375000\n",
      "Train Epoch: 23 [14480/17352 (83%)] Loss: -174499.609375\n",
      "Train Epoch: 23 [14560/17352 (84%)] Loss: -183382.640625\n",
      "Train Epoch: 23 [14640/17352 (84%)] Loss: -185252.953125\n",
      "Train Epoch: 23 [14720/17352 (85%)] Loss: -196439.421875\n",
      "Train Epoch: 23 [14800/17352 (85%)] Loss: -179664.203125\n",
      "Train Epoch: 23 [14880/17352 (86%)] Loss: -181729.859375\n",
      "Train Epoch: 23 [14960/17352 (86%)] Loss: -193503.953125\n",
      "Train Epoch: 23 [15040/17352 (87%)] Loss: -187611.750000\n",
      "Train Epoch: 23 [15120/17352 (87%)] Loss: -163202.609375\n",
      "Train Epoch: 23 [15200/17352 (88%)] Loss: -166434.843750\n",
      "Train Epoch: 23 [15280/17352 (88%)] Loss: -186037.062500\n",
      "Train Epoch: 23 [15360/17352 (89%)] Loss: -221235.656250\n",
      "Train Epoch: 23 [15440/17352 (89%)] Loss: -162966.656250\n",
      "Train Epoch: 23 [15520/17352 (89%)] Loss: -169499.500000\n",
      "Train Epoch: 23 [15600/17352 (90%)] Loss: -194929.671875\n",
      "Train Epoch: 23 [15680/17352 (90%)] Loss: -180515.078125\n",
      "Train Epoch: 23 [15760/17352 (91%)] Loss: -181751.421875\n",
      "Train Epoch: 23 [15840/17352 (91%)] Loss: -180039.765625\n",
      "Train Epoch: 23 [15920/17352 (92%)] Loss: -175531.125000\n",
      "Train Epoch: 23 [16000/17352 (92%)] Loss: -171579.031250\n",
      "Train Epoch: 23 [16080/17352 (93%)] Loss: -204586.000000\n",
      "Train Epoch: 23 [16160/17352 (93%)] Loss: -170228.218750\n",
      "Train Epoch: 23 [16240/17352 (94%)] Loss: -183607.546875\n",
      "Train Epoch: 23 [16320/17352 (94%)] Loss: -197538.906250\n",
      "Train Epoch: 23 [16400/17352 (95%)] Loss: -176071.000000\n",
      "Train Epoch: 23 [16480/17352 (95%)] Loss: -184474.703125\n",
      "Train Epoch: 23 [16560/17352 (95%)] Loss: -163484.468750\n",
      "Train Epoch: 23 [16640/17352 (96%)] Loss: -195044.187500\n",
      "Train Epoch: 23 [16720/17352 (96%)] Loss: -209822.421875\n",
      "Train Epoch: 23 [16800/17352 (97%)] Loss: -190198.718750\n",
      "Train Epoch: 23 [16880/17352 (97%)] Loss: -148433.359375\n",
      "Train Epoch: 23 [16960/17352 (98%)] Loss: -183070.812500\n",
      "Train Epoch: 23 [17040/17352 (98%)] Loss: -208416.781250\n",
      "Train Epoch: 23 [17120/17352 (99%)] Loss: -184991.906250\n",
      "Train Epoch: 23 [17200/17352 (99%)] Loss: -188076.484375\n",
      "Train Epoch: 23 [17280/17352 (100%)] Loss: -183714.078125\n",
      "Train Epoch: 23 [17360/17352 (100%)] Loss: -178999.609375\n",
      "    epoch          : 23\n",
      "    loss           : -189487.10226373706\n",
      "    val_loss       : -23714.545420257138\n",
      "Train Epoch: 24 [0/17352 (0%)] Loss: -206782.453125\n",
      "Train Epoch: 24 [80/17352 (0%)] Loss: -236494.281250\n",
      "Train Epoch: 24 [160/17352 (1%)] Loss: -214503.781250\n",
      "Train Epoch: 24 [240/17352 (1%)] Loss: -185150.109375\n",
      "Train Epoch: 24 [320/17352 (2%)] Loss: -202023.328125\n",
      "Train Epoch: 24 [400/17352 (2%)] Loss: -212646.796875\n",
      "Train Epoch: 24 [480/17352 (3%)] Loss: -216202.031250\n",
      "Train Epoch: 24 [560/17352 (3%)] Loss: -204030.093750\n",
      "Train Epoch: 24 [640/17352 (4%)] Loss: -223000.156250\n",
      "Train Epoch: 24 [720/17352 (4%)] Loss: -187711.500000\n",
      "Train Epoch: 24 [800/17352 (5%)] Loss: -199929.109375\n",
      "Train Epoch: 24 [880/17352 (5%)] Loss: -186059.093750\n",
      "Train Epoch: 24 [960/17352 (6%)] Loss: -206746.921875\n",
      "Train Epoch: 24 [1040/17352 (6%)] Loss: -228012.671875\n",
      "Train Epoch: 24 [1120/17352 (6%)] Loss: -212374.031250\n",
      "Train Epoch: 24 [1200/17352 (7%)] Loss: -205914.312500\n",
      "Train Epoch: 24 [1280/17352 (7%)] Loss: -199803.578125\n",
      "Train Epoch: 24 [1360/17352 (8%)] Loss: -230405.375000\n",
      "Train Epoch: 24 [1440/17352 (8%)] Loss: -201651.250000\n",
      "Train Epoch: 24 [1520/17352 (9%)] Loss: -214399.125000\n",
      "Train Epoch: 24 [1600/17352 (9%)] Loss: -206541.531250\n",
      "Train Epoch: 24 [1680/17352 (10%)] Loss: -221468.531250\n",
      "Train Epoch: 24 [1760/17352 (10%)] Loss: -203263.453125\n",
      "Train Epoch: 24 [1840/17352 (11%)] Loss: -193558.265625\n",
      "Train Epoch: 24 [1920/17352 (11%)] Loss: -200595.546875\n",
      "Train Epoch: 24 [2000/17352 (12%)] Loss: -213327.890625\n",
      "Train Epoch: 24 [2080/17352 (12%)] Loss: -194483.906250\n",
      "Train Epoch: 24 [2160/17352 (12%)] Loss: -204725.546875\n",
      "Train Epoch: 24 [2240/17352 (13%)] Loss: -199783.875000\n",
      "Train Epoch: 24 [2320/17352 (13%)] Loss: -182090.531250\n",
      "Train Epoch: 24 [2400/17352 (14%)] Loss: -204202.281250\n",
      "Train Epoch: 24 [2480/17352 (14%)] Loss: -179461.531250\n",
      "Train Epoch: 24 [2560/17352 (15%)] Loss: -180697.828125\n",
      "Train Epoch: 24 [2640/17352 (15%)] Loss: -196942.500000\n",
      "Train Epoch: 24 [2720/17352 (16%)] Loss: -192789.296875\n",
      "Train Epoch: 24 [2800/17352 (16%)] Loss: -203808.093750\n",
      "Train Epoch: 24 [2880/17352 (17%)] Loss: -173022.765625\n",
      "Train Epoch: 24 [2960/17352 (17%)] Loss: -171220.453125\n",
      "Train Epoch: 24 [3040/17352 (18%)] Loss: -192942.750000\n",
      "Train Epoch: 24 [3120/17352 (18%)] Loss: -190986.953125\n",
      "Train Epoch: 24 [3200/17352 (18%)] Loss: -173914.140625\n",
      "Train Epoch: 24 [3280/17352 (19%)] Loss: -185498.343750\n",
      "Train Epoch: 24 [3360/17352 (19%)] Loss: -218399.156250\n",
      "Train Epoch: 24 [3440/17352 (20%)] Loss: -208117.140625\n",
      "Train Epoch: 24 [3520/17352 (20%)] Loss: -217610.687500\n",
      "Train Epoch: 24 [3600/17352 (21%)] Loss: -186426.468750\n",
      "Train Epoch: 24 [3680/17352 (21%)] Loss: -166665.296875\n",
      "Train Epoch: 24 [3760/17352 (22%)] Loss: -196930.312500\n",
      "Train Epoch: 24 [3840/17352 (22%)] Loss: -158741.656250\n",
      "Train Epoch: 24 [3920/17352 (23%)] Loss: -202565.812500\n",
      "Train Epoch: 24 [4000/17352 (23%)] Loss: -221237.750000\n",
      "Train Epoch: 24 [4080/17352 (24%)] Loss: -201507.578125\n",
      "Train Epoch: 24 [4160/17352 (24%)] Loss: -164732.531250\n",
      "Train Epoch: 24 [4240/17352 (24%)] Loss: -180282.171875\n",
      "Train Epoch: 24 [4320/17352 (25%)] Loss: -185922.500000\n",
      "Train Epoch: 24 [4400/17352 (25%)] Loss: -200272.375000\n",
      "Train Epoch: 24 [4480/17352 (26%)] Loss: -162558.062500\n",
      "Train Epoch: 24 [4560/17352 (26%)] Loss: -189163.328125\n",
      "Train Epoch: 24 [4640/17352 (27%)] Loss: -165351.015625\n",
      "Train Epoch: 24 [4720/17352 (27%)] Loss: -200473.000000\n",
      "Train Epoch: 24 [4800/17352 (28%)] Loss: -180964.734375\n",
      "Train Epoch: 24 [4880/17352 (28%)] Loss: -168954.968750\n",
      "Train Epoch: 24 [4960/17352 (29%)] Loss: -164940.328125\n",
      "Train Epoch: 24 [5040/17352 (29%)] Loss: -163095.843750\n",
      "Train Epoch: 24 [5120/17352 (30%)] Loss: -164059.984375\n",
      "Train Epoch: 24 [5200/17352 (30%)] Loss: -185162.921875\n",
      "Train Epoch: 24 [5280/17352 (30%)] Loss: -208712.328125\n",
      "Train Epoch: 24 [5360/17352 (31%)] Loss: -193484.015625\n",
      "Train Epoch: 24 [5440/17352 (31%)] Loss: -192383.656250\n",
      "Train Epoch: 24 [5520/17352 (32%)] Loss: -193794.093750\n",
      "Train Epoch: 24 [5600/17352 (32%)] Loss: -203456.421875\n",
      "Train Epoch: 24 [5680/17352 (33%)] Loss: -179886.546875\n",
      "Train Epoch: 24 [5760/17352 (33%)] Loss: -193504.031250\n",
      "Train Epoch: 24 [5840/17352 (34%)] Loss: -190930.281250\n",
      "Train Epoch: 24 [5920/17352 (34%)] Loss: -195057.718750\n",
      "Train Epoch: 24 [6000/17352 (35%)] Loss: -179492.343750\n",
      "Train Epoch: 24 [6080/17352 (35%)] Loss: -184017.781250\n",
      "Train Epoch: 24 [6160/17352 (36%)] Loss: -183210.546875\n",
      "Train Epoch: 24 [6240/17352 (36%)] Loss: -181362.562500\n",
      "Train Epoch: 24 [6320/17352 (36%)] Loss: -193482.046875\n",
      "Train Epoch: 24 [6400/17352 (37%)] Loss: -178591.156250\n",
      "Train Epoch: 24 [6480/17352 (37%)] Loss: -187880.484375\n",
      "Train Epoch: 24 [6560/17352 (38%)] Loss: -196851.687500\n",
      "Train Epoch: 24 [6640/17352 (38%)] Loss: -147408.750000\n",
      "Train Epoch: 24 [6720/17352 (39%)] Loss: -215634.796875\n",
      "Train Epoch: 24 [6800/17352 (39%)] Loss: -166985.296875\n",
      "Train Epoch: 24 [6880/17352 (40%)] Loss: -211154.156250\n",
      "Train Epoch: 24 [6960/17352 (40%)] Loss: -170772.750000\n",
      "Train Epoch: 24 [7040/17352 (41%)] Loss: -174616.062500\n",
      "Train Epoch: 24 [7120/17352 (41%)] Loss: -170300.343750\n",
      "Train Epoch: 24 [7200/17352 (41%)] Loss: -196442.578125\n",
      "Train Epoch: 24 [7280/17352 (42%)] Loss: -176891.734375\n",
      "Train Epoch: 24 [7360/17352 (42%)] Loss: -174535.546875\n",
      "Train Epoch: 24 [7440/17352 (43%)] Loss: -204927.078125\n",
      "Train Epoch: 24 [7520/17352 (43%)] Loss: -187706.109375\n",
      "Train Epoch: 24 [7600/17352 (44%)] Loss: -192740.640625\n",
      "Train Epoch: 24 [7680/17352 (44%)] Loss: -175314.234375\n",
      "Train Epoch: 24 [7760/17352 (45%)] Loss: -176693.562500\n",
      "Train Epoch: 24 [7840/17352 (45%)] Loss: -187390.906250\n",
      "Train Epoch: 24 [7920/17352 (46%)] Loss: -202931.640625\n",
      "Train Epoch: 24 [8000/17352 (46%)] Loss: -209498.968750\n",
      "Train Epoch: 24 [8080/17352 (47%)] Loss: -175504.375000\n",
      "Train Epoch: 24 [8160/17352 (47%)] Loss: -176136.234375\n",
      "Train Epoch: 24 [8240/17352 (47%)] Loss: -223959.125000\n",
      "Train Epoch: 24 [8320/17352 (48%)] Loss: -205505.484375\n",
      "Train Epoch: 24 [8400/17352 (48%)] Loss: -202516.718750\n",
      "Train Epoch: 24 [8480/17352 (49%)] Loss: -183794.703125\n",
      "Train Epoch: 24 [8560/17352 (49%)] Loss: -185384.984375\n",
      "Train Epoch: 24 [8640/17352 (50%)] Loss: -202859.750000\n",
      "Train Epoch: 24 [8720/17352 (50%)] Loss: -173119.250000\n",
      "Train Epoch: 24 [8800/17352 (51%)] Loss: -188906.531250\n",
      "Train Epoch: 24 [8880/17352 (51%)] Loss: -187499.250000\n",
      "Train Epoch: 24 [8960/17352 (52%)] Loss: -165580.093750\n",
      "Train Epoch: 24 [9040/17352 (52%)] Loss: -159601.281250\n",
      "Train Epoch: 24 [9120/17352 (53%)] Loss: -178307.203125\n",
      "Train Epoch: 24 [9200/17352 (53%)] Loss: -191720.843750\n",
      "Train Epoch: 24 [9280/17352 (53%)] Loss: -186832.937500\n",
      "Train Epoch: 24 [9360/17352 (54%)] Loss: -159729.984375\n",
      "Train Epoch: 24 [9440/17352 (54%)] Loss: -165780.609375\n",
      "Train Epoch: 24 [9520/17352 (55%)] Loss: -188509.250000\n",
      "Train Epoch: 24 [9600/17352 (55%)] Loss: -167085.671875\n",
      "Train Epoch: 24 [9680/17352 (56%)] Loss: -207088.437500\n",
      "Train Epoch: 24 [9760/17352 (56%)] Loss: -192003.468750\n",
      "Train Epoch: 24 [9840/17352 (57%)] Loss: -196021.546875\n",
      "Train Epoch: 24 [9920/17352 (57%)] Loss: -156468.984375\n",
      "Train Epoch: 24 [10000/17352 (58%)] Loss: -185586.234375\n",
      "Train Epoch: 24 [10080/17352 (58%)] Loss: -173565.062500\n",
      "Train Epoch: 24 [10160/17352 (59%)] Loss: -197082.750000\n",
      "Train Epoch: 24 [10240/17352 (59%)] Loss: -187451.890625\n",
      "Train Epoch: 24 [10320/17352 (59%)] Loss: -183710.187500\n",
      "Train Epoch: 24 [10400/17352 (60%)] Loss: -181617.531250\n",
      "Train Epoch: 24 [10480/17352 (60%)] Loss: -188444.187500\n",
      "Train Epoch: 24 [10560/17352 (61%)] Loss: -164140.187500\n",
      "Train Epoch: 24 [10640/17352 (61%)] Loss: -190486.859375\n",
      "Train Epoch: 24 [10720/17352 (62%)] Loss: -196385.500000\n",
      "Train Epoch: 24 [10800/17352 (62%)] Loss: -209184.500000\n",
      "Train Epoch: 24 [10880/17352 (63%)] Loss: -207846.515625\n",
      "Train Epoch: 24 [10960/17352 (63%)] Loss: -197558.281250\n",
      "Train Epoch: 24 [11040/17352 (64%)] Loss: -182389.203125\n",
      "Train Epoch: 24 [11120/17352 (64%)] Loss: -188744.171875\n",
      "Train Epoch: 24 [11200/17352 (65%)] Loss: -204690.140625\n",
      "Train Epoch: 24 [11280/17352 (65%)] Loss: -183403.656250\n",
      "Train Epoch: 24 [11360/17352 (65%)] Loss: -184761.468750\n",
      "Train Epoch: 24 [11440/17352 (66%)] Loss: -171886.234375\n",
      "Train Epoch: 24 [11520/17352 (66%)] Loss: -193045.031250\n",
      "Train Epoch: 24 [11600/17352 (67%)] Loss: -183599.015625\n",
      "Train Epoch: 24 [11680/17352 (67%)] Loss: -177140.000000\n",
      "Train Epoch: 24 [11760/17352 (68%)] Loss: -195042.109375\n",
      "Train Epoch: 24 [11840/17352 (68%)] Loss: -168043.250000\n",
      "Train Epoch: 24 [11920/17352 (69%)] Loss: -151214.812500\n",
      "Train Epoch: 24 [12000/17352 (69%)] Loss: -165377.593750\n",
      "Train Epoch: 24 [12080/17352 (70%)] Loss: -172236.250000\n",
      "Train Epoch: 24 [12160/17352 (70%)] Loss: -175347.265625\n",
      "Train Epoch: 24 [12240/17352 (71%)] Loss: -167234.968750\n",
      "Train Epoch: 24 [12320/17352 (71%)] Loss: -174980.765625\n",
      "Train Epoch: 24 [12400/17352 (71%)] Loss: -167177.750000\n",
      "Train Epoch: 24 [12480/17352 (72%)] Loss: -201818.671875\n",
      "Train Epoch: 24 [12560/17352 (72%)] Loss: -187316.859375\n",
      "Train Epoch: 24 [12640/17352 (73%)] Loss: -170762.250000\n",
      "Train Epoch: 24 [12720/17352 (73%)] Loss: -180792.578125\n",
      "Train Epoch: 24 [12800/17352 (74%)] Loss: -191146.343750\n",
      "Train Epoch: 24 [12880/17352 (74%)] Loss: -175600.125000\n",
      "Train Epoch: 24 [12960/17352 (75%)] Loss: -200119.718750\n",
      "Train Epoch: 24 [13040/17352 (75%)] Loss: -192282.046875\n",
      "Train Epoch: 24 [13120/17352 (76%)] Loss: -166538.750000\n",
      "Train Epoch: 24 [13200/17352 (76%)] Loss: -228248.390625\n",
      "Train Epoch: 24 [13280/17352 (77%)] Loss: -209886.546875\n",
      "Train Epoch: 24 [13360/17352 (77%)] Loss: -170241.171875\n",
      "Train Epoch: 24 [13440/17352 (77%)] Loss: -181958.281250\n",
      "Train Epoch: 24 [13520/17352 (78%)] Loss: -153878.546875\n",
      "Train Epoch: 24 [13600/17352 (78%)] Loss: -228083.562500\n",
      "Train Epoch: 24 [13680/17352 (79%)] Loss: -179168.062500\n",
      "Train Epoch: 24 [13760/17352 (79%)] Loss: -176478.312500\n",
      "Train Epoch: 24 [13840/17352 (80%)] Loss: -192877.125000\n",
      "Train Epoch: 24 [13920/17352 (80%)] Loss: -205165.328125\n",
      "Train Epoch: 24 [14000/17352 (81%)] Loss: -218742.171875\n",
      "Train Epoch: 24 [14080/17352 (81%)] Loss: -192682.234375\n",
      "Train Epoch: 24 [14160/17352 (82%)] Loss: -190072.812500\n",
      "Train Epoch: 24 [14240/17352 (82%)] Loss: -174467.390625\n",
      "Train Epoch: 24 [14320/17352 (83%)] Loss: -182538.093750\n",
      "Train Epoch: 24 [14400/17352 (83%)] Loss: -192359.437500\n",
      "Train Epoch: 24 [14480/17352 (83%)] Loss: -187315.500000\n",
      "Train Epoch: 24 [14560/17352 (84%)] Loss: -179429.625000\n",
      "Train Epoch: 24 [14640/17352 (84%)] Loss: -176282.390625\n",
      "Train Epoch: 24 [14720/17352 (85%)] Loss: -148150.328125\n",
      "Train Epoch: 24 [14800/17352 (85%)] Loss: -178666.562500\n",
      "Train Epoch: 24 [14880/17352 (86%)] Loss: -200627.546875\n",
      "Train Epoch: 24 [14960/17352 (86%)] Loss: -193124.718750\n",
      "Train Epoch: 24 [15040/17352 (87%)] Loss: -187637.984375\n",
      "Train Epoch: 24 [15120/17352 (87%)] Loss: -165857.234375\n",
      "Train Epoch: 24 [15200/17352 (88%)] Loss: -159682.375000\n",
      "Train Epoch: 24 [15280/17352 (88%)] Loss: -205388.000000\n",
      "Train Epoch: 24 [15360/17352 (89%)] Loss: -191823.859375\n",
      "Train Epoch: 24 [15440/17352 (89%)] Loss: -208325.718750\n",
      "Train Epoch: 24 [15520/17352 (89%)] Loss: -173364.265625\n",
      "Train Epoch: 24 [15600/17352 (90%)] Loss: -187323.546875\n",
      "Train Epoch: 24 [15680/17352 (90%)] Loss: -181248.531250\n",
      "Train Epoch: 24 [15760/17352 (91%)] Loss: -163951.968750\n",
      "Train Epoch: 24 [15840/17352 (91%)] Loss: -173002.796875\n",
      "Train Epoch: 24 [15920/17352 (92%)] Loss: -183451.718750\n",
      "Train Epoch: 24 [16000/17352 (92%)] Loss: -191586.328125\n",
      "Train Epoch: 24 [16080/17352 (93%)] Loss: -201363.531250\n",
      "Train Epoch: 24 [16160/17352 (93%)] Loss: -185328.265625\n",
      "Train Epoch: 24 [16240/17352 (94%)] Loss: -194037.562500\n",
      "Train Epoch: 24 [16320/17352 (94%)] Loss: -172173.312500\n",
      "Train Epoch: 24 [16400/17352 (95%)] Loss: -174910.921875\n",
      "Train Epoch: 24 [16480/17352 (95%)] Loss: -174984.921875\n",
      "Train Epoch: 24 [16560/17352 (95%)] Loss: -170347.703125\n",
      "Train Epoch: 24 [16640/17352 (96%)] Loss: -164873.125000\n",
      "Train Epoch: 24 [16720/17352 (96%)] Loss: -193341.000000\n",
      "Train Epoch: 24 [16800/17352 (97%)] Loss: -197637.187500\n",
      "Train Epoch: 24 [16880/17352 (97%)] Loss: -194953.703125\n",
      "Train Epoch: 24 [16960/17352 (98%)] Loss: -171420.953125\n",
      "Train Epoch: 24 [17040/17352 (98%)] Loss: -206466.281250\n",
      "Train Epoch: 24 [17120/17352 (99%)] Loss: -164975.218750\n",
      "Train Epoch: 24 [17200/17352 (99%)] Loss: -200161.562500\n",
      "Train Epoch: 24 [17280/17352 (100%)] Loss: -213182.828125\n",
      "Train Epoch: 24 [17360/17352 (100%)] Loss: -175010.375000\n",
      "    epoch          : 24\n",
      "    loss           : -189435.90111658516\n",
      "    val_loss       : -23714.45150319847\n",
      "Train Epoch: 25 [0/17352 (0%)] Loss: -241900.328125\n",
      "Train Epoch: 25 [80/17352 (0%)] Loss: -210513.031250\n",
      "Train Epoch: 25 [160/17352 (1%)] Loss: -204525.593750\n",
      "Train Epoch: 25 [240/17352 (1%)] Loss: -214693.515625\n",
      "Train Epoch: 25 [320/17352 (2%)] Loss: -212685.218750\n",
      "Train Epoch: 25 [400/17352 (2%)] Loss: -213807.687500\n",
      "Train Epoch: 25 [480/17352 (3%)] Loss: -216087.937500\n",
      "Train Epoch: 25 [560/17352 (3%)] Loss: -230393.234375\n",
      "Train Epoch: 25 [640/17352 (4%)] Loss: -222991.078125\n",
      "Train Epoch: 25 [720/17352 (4%)] Loss: -213336.812500\n",
      "Train Epoch: 25 [800/17352 (5%)] Loss: -186065.546875\n",
      "Train Epoch: 25 [880/17352 (5%)] Loss: -209544.609375\n",
      "Train Epoch: 25 [960/17352 (6%)] Loss: -199525.796875\n",
      "Train Epoch: 25 [1040/17352 (6%)] Loss: -215481.234375\n",
      "Train Epoch: 25 [1120/17352 (6%)] Loss: -217928.140625\n",
      "Train Epoch: 25 [1200/17352 (7%)] Loss: -209763.640625\n",
      "Train Epoch: 25 [1280/17352 (7%)] Loss: -214451.500000\n",
      "Train Epoch: 25 [1360/17352 (8%)] Loss: -202256.781250\n",
      "Train Epoch: 25 [1440/17352 (8%)] Loss: -202321.953125\n",
      "Train Epoch: 25 [1520/17352 (9%)] Loss: -212384.296875\n",
      "Train Epoch: 25 [1600/17352 (9%)] Loss: -229948.218750\n",
      "Train Epoch: 25 [1680/17352 (10%)] Loss: -226089.125000\n",
      "Train Epoch: 25 [1760/17352 (10%)] Loss: -210337.968750\n",
      "Train Epoch: 25 [1840/17352 (11%)] Loss: -193010.453125\n",
      "Train Epoch: 25 [1920/17352 (11%)] Loss: -199917.203125\n",
      "Train Epoch: 25 [2000/17352 (12%)] Loss: -216197.843750\n",
      "Train Epoch: 25 [2080/17352 (12%)] Loss: -199893.656250\n",
      "Train Epoch: 25 [2160/17352 (12%)] Loss: -213321.812500\n",
      "Train Epoch: 25 [2240/17352 (13%)] Loss: -200400.109375\n",
      "Train Epoch: 25 [2320/17352 (13%)] Loss: -207103.765625\n",
      "Train Epoch: 25 [2400/17352 (14%)] Loss: -185541.046875\n",
      "Train Epoch: 25 [2480/17352 (14%)] Loss: -183395.250000\n",
      "Train Epoch: 25 [2560/17352 (15%)] Loss: -177303.375000\n",
      "Train Epoch: 25 [2640/17352 (15%)] Loss: -197438.156250\n",
      "Train Epoch: 25 [2720/17352 (16%)] Loss: -216311.734375\n",
      "Train Epoch: 25 [2800/17352 (16%)] Loss: -199136.453125\n",
      "Train Epoch: 25 [2880/17352 (17%)] Loss: -184026.765625\n",
      "Train Epoch: 25 [2960/17352 (17%)] Loss: -194921.468750\n",
      "Train Epoch: 25 [3040/17352 (18%)] Loss: -201355.734375\n",
      "Train Epoch: 25 [3120/17352 (18%)] Loss: -200993.000000\n",
      "Train Epoch: 25 [3200/17352 (18%)] Loss: -187309.859375\n",
      "Train Epoch: 25 [3280/17352 (19%)] Loss: -171829.312500\n",
      "Train Epoch: 25 [3360/17352 (19%)] Loss: -180986.562500\n",
      "Train Epoch: 25 [3440/17352 (20%)] Loss: -202472.984375\n",
      "Train Epoch: 25 [3520/17352 (20%)] Loss: -185173.750000\n",
      "Train Epoch: 25 [3600/17352 (21%)] Loss: -184448.265625\n",
      "Train Epoch: 25 [3680/17352 (21%)] Loss: -188173.078125\n",
      "Train Epoch: 25 [3760/17352 (22%)] Loss: -185929.437500\n",
      "Train Epoch: 25 [3840/17352 (22%)] Loss: -213171.234375\n",
      "Train Epoch: 25 [3920/17352 (23%)] Loss: -189589.109375\n",
      "Train Epoch: 25 [4000/17352 (23%)] Loss: -211710.500000\n",
      "Train Epoch: 25 [4080/17352 (24%)] Loss: -184730.468750\n",
      "Train Epoch: 25 [4160/17352 (24%)] Loss: -189597.671875\n",
      "Train Epoch: 25 [4240/17352 (24%)] Loss: -183920.203125\n",
      "Train Epoch: 25 [4320/17352 (25%)] Loss: -184974.734375\n",
      "Train Epoch: 25 [4400/17352 (25%)] Loss: -197649.546875\n",
      "Train Epoch: 25 [4480/17352 (26%)] Loss: -163345.765625\n",
      "Train Epoch: 25 [4560/17352 (26%)] Loss: -204652.828125\n",
      "Train Epoch: 25 [4640/17352 (27%)] Loss: -170233.609375\n",
      "Train Epoch: 25 [4720/17352 (27%)] Loss: -187340.531250\n",
      "Train Epoch: 25 [4800/17352 (28%)] Loss: -162543.906250\n",
      "Train Epoch: 25 [4880/17352 (28%)] Loss: -166397.093750\n",
      "Train Epoch: 25 [4960/17352 (29%)] Loss: -209268.468750\n",
      "Train Epoch: 25 [5040/17352 (29%)] Loss: -175067.500000\n",
      "Train Epoch: 25 [5120/17352 (30%)] Loss: -195505.812500\n",
      "Train Epoch: 25 [5200/17352 (30%)] Loss: -178196.046875\n",
      "Train Epoch: 25 [5280/17352 (30%)] Loss: -191222.421875\n",
      "Train Epoch: 25 [5360/17352 (31%)] Loss: -179004.296875\n",
      "Train Epoch: 25 [5440/17352 (31%)] Loss: -187323.062500\n",
      "Train Epoch: 25 [5520/17352 (32%)] Loss: -191670.531250\n",
      "Train Epoch: 25 [5600/17352 (32%)] Loss: -212604.218750\n",
      "Train Epoch: 25 [5680/17352 (33%)] Loss: -185580.625000\n",
      "Train Epoch: 25 [5760/17352 (33%)] Loss: -200454.718750\n",
      "Train Epoch: 25 [5840/17352 (34%)] Loss: -219915.281250\n",
      "Train Epoch: 25 [5920/17352 (34%)] Loss: -184745.484375\n",
      "Train Epoch: 25 [6000/17352 (35%)] Loss: -195771.406250\n",
      "Train Epoch: 25 [6080/17352 (35%)] Loss: -200266.421875\n",
      "Train Epoch: 25 [6160/17352 (36%)] Loss: -187503.171875\n",
      "Train Epoch: 25 [6240/17352 (36%)] Loss: -183607.421875\n",
      "Train Epoch: 25 [6320/17352 (36%)] Loss: -174507.140625\n",
      "Train Epoch: 25 [6400/17352 (37%)] Loss: -206467.484375\n",
      "Train Epoch: 25 [6480/17352 (37%)] Loss: -191553.937500\n",
      "Train Epoch: 25 [6560/17352 (38%)] Loss: -202016.750000\n",
      "Train Epoch: 25 [6640/17352 (38%)] Loss: -206214.875000\n",
      "Train Epoch: 25 [6720/17352 (39%)] Loss: -173838.343750\n",
      "Train Epoch: 25 [6800/17352 (39%)] Loss: -178086.828125\n",
      "Train Epoch: 25 [6880/17352 (40%)] Loss: -151508.046875\n",
      "Train Epoch: 25 [6960/17352 (40%)] Loss: -183505.375000\n",
      "Train Epoch: 25 [7040/17352 (41%)] Loss: -165722.031250\n",
      "Train Epoch: 25 [7120/17352 (41%)] Loss: -183617.687500\n",
      "Train Epoch: 25 [7200/17352 (41%)] Loss: -197512.734375\n",
      "Train Epoch: 25 [7280/17352 (42%)] Loss: -189534.593750\n",
      "Train Epoch: 25 [7360/17352 (42%)] Loss: -178801.265625\n",
      "Train Epoch: 25 [7440/17352 (43%)] Loss: -192988.125000\n",
      "Train Epoch: 25 [7520/17352 (43%)] Loss: -200323.359375\n",
      "Train Epoch: 25 [7600/17352 (44%)] Loss: -206229.750000\n",
      "Train Epoch: 25 [7680/17352 (44%)] Loss: -203840.859375\n",
      "Train Epoch: 25 [7760/17352 (45%)] Loss: -202979.109375\n",
      "Train Epoch: 25 [7840/17352 (45%)] Loss: -200293.015625\n",
      "Train Epoch: 25 [7920/17352 (46%)] Loss: -196801.296875\n",
      "Train Epoch: 25 [8000/17352 (46%)] Loss: -167291.515625\n",
      "Train Epoch: 25 [8080/17352 (47%)] Loss: -183784.453125\n",
      "Train Epoch: 25 [8160/17352 (47%)] Loss: -196436.984375\n",
      "Train Epoch: 25 [8240/17352 (47%)] Loss: -187307.765625\n",
      "Train Epoch: 25 [8320/17352 (48%)] Loss: -204485.343750\n",
      "Train Epoch: 25 [8400/17352 (48%)] Loss: -159669.546875\n",
      "Train Epoch: 25 [8480/17352 (49%)] Loss: -195882.312500\n",
      "Train Epoch: 25 [8560/17352 (49%)] Loss: -210251.515625\n",
      "Train Epoch: 25 [8640/17352 (50%)] Loss: -217621.234375\n",
      "Train Epoch: 25 [8720/17352 (50%)] Loss: -192116.312500\n",
      "Train Epoch: 25 [8800/17352 (51%)] Loss: -213897.281250\n",
      "Train Epoch: 25 [8880/17352 (51%)] Loss: -179297.343750\n",
      "Train Epoch: 25 [8960/17352 (52%)] Loss: -178296.359375\n",
      "Train Epoch: 25 [9040/17352 (52%)] Loss: -192289.687500\n",
      "Train Epoch: 25 [9120/17352 (53%)] Loss: -184489.453125\n",
      "Train Epoch: 25 [9200/17352 (53%)] Loss: -171180.843750\n",
      "Train Epoch: 25 [9280/17352 (53%)] Loss: -193348.421875\n",
      "Train Epoch: 25 [9360/17352 (54%)] Loss: -193051.109375\n",
      "Train Epoch: 25 [9440/17352 (54%)] Loss: -201315.718750\n",
      "Train Epoch: 25 [9520/17352 (55%)] Loss: -199714.468750\n",
      "Train Epoch: 25 [9600/17352 (55%)] Loss: -181418.312500\n",
      "Train Epoch: 25 [9680/17352 (56%)] Loss: -198004.500000\n",
      "Train Epoch: 25 [9760/17352 (56%)] Loss: -191585.765625\n",
      "Train Epoch: 25 [9840/17352 (57%)] Loss: -158741.390625\n",
      "Train Epoch: 25 [9920/17352 (57%)] Loss: -192847.078125\n",
      "Train Epoch: 25 [10000/17352 (58%)] Loss: -183203.750000\n",
      "Train Epoch: 25 [10080/17352 (58%)] Loss: -192952.171875\n",
      "Train Epoch: 25 [10160/17352 (59%)] Loss: -181332.015625\n",
      "Train Epoch: 25 [10240/17352 (59%)] Loss: -192267.421875\n",
      "Train Epoch: 25 [10320/17352 (59%)] Loss: -208327.468750\n",
      "Train Epoch: 25 [10400/17352 (60%)] Loss: -195637.562500\n",
      "Train Epoch: 25 [10480/17352 (60%)] Loss: -183390.171875\n",
      "Train Epoch: 25 [10560/17352 (61%)] Loss: -180694.437500\n",
      "Train Epoch: 25 [10640/17352 (61%)] Loss: -197556.875000\n",
      "Train Epoch: 25 [10720/17352 (62%)] Loss: -199171.046875\n",
      "Train Epoch: 25 [10800/17352 (62%)] Loss: -197312.359375\n",
      "Train Epoch: 25 [10880/17352 (63%)] Loss: -167237.562500\n",
      "Train Epoch: 25 [10960/17352 (63%)] Loss: -175666.156250\n",
      "Train Epoch: 25 [11040/17352 (64%)] Loss: -153320.359375\n",
      "Train Epoch: 25 [11120/17352 (64%)] Loss: -186151.593750\n",
      "Train Epoch: 25 [11200/17352 (65%)] Loss: -206590.890625\n",
      "Train Epoch: 25 [11280/17352 (65%)] Loss: -177304.812500\n",
      "Train Epoch: 25 [11360/17352 (65%)] Loss: -167241.781250\n",
      "Train Epoch: 25 [11440/17352 (66%)] Loss: -190496.421875\n",
      "Train Epoch: 25 [11520/17352 (66%)] Loss: -173887.187500\n",
      "Train Epoch: 25 [11600/17352 (67%)] Loss: -170029.187500\n",
      "Train Epoch: 25 [11680/17352 (67%)] Loss: -208123.953125\n",
      "Train Epoch: 25 [11760/17352 (68%)] Loss: -165670.281250\n",
      "Train Epoch: 25 [11840/17352 (68%)] Loss: -205013.125000\n",
      "Train Epoch: 25 [11920/17352 (69%)] Loss: -192638.421875\n",
      "Train Epoch: 25 [12000/17352 (69%)] Loss: -175506.218750\n",
      "Train Epoch: 25 [12080/17352 (70%)] Loss: -176954.203125\n",
      "Train Epoch: 25 [12160/17352 (70%)] Loss: -152893.343750\n",
      "Train Epoch: 25 [12240/17352 (71%)] Loss: -209402.031250\n",
      "Train Epoch: 25 [12320/17352 (71%)] Loss: -184839.843750\n",
      "Train Epoch: 25 [12400/17352 (71%)] Loss: -191993.875000\n",
      "Train Epoch: 25 [12480/17352 (72%)] Loss: -197090.625000\n",
      "Train Epoch: 25 [12560/17352 (72%)] Loss: -180910.015625\n",
      "Train Epoch: 25 [12640/17352 (73%)] Loss: -187950.218750\n",
      "Train Epoch: 25 [12720/17352 (73%)] Loss: -148400.281250\n",
      "Train Epoch: 25 [12800/17352 (74%)] Loss: -190928.875000\n",
      "Train Epoch: 25 [12880/17352 (74%)] Loss: -183793.781250\n",
      "Train Epoch: 25 [12960/17352 (75%)] Loss: -210912.687500\n",
      "Train Epoch: 25 [13040/17352 (75%)] Loss: -188753.109375\n",
      "Train Epoch: 25 [13120/17352 (76%)] Loss: -193524.531250\n",
      "Train Epoch: 25 [13200/17352 (76%)] Loss: -193049.234375\n",
      "Train Epoch: 25 [13280/17352 (77%)] Loss: -167208.140625\n",
      "Train Epoch: 25 [13360/17352 (77%)] Loss: -208304.875000\n",
      "Train Epoch: 25 [13440/17352 (77%)] Loss: -192941.328125\n",
      "Train Epoch: 25 [13520/17352 (78%)] Loss: -195048.640625\n",
      "Train Epoch: 25 [13600/17352 (78%)] Loss: -193191.406250\n",
      "Train Epoch: 25 [13680/17352 (79%)] Loss: -188146.750000\n",
      "Train Epoch: 25 [13760/17352 (79%)] Loss: -225469.359375\n",
      "Train Epoch: 25 [13840/17352 (80%)] Loss: -134538.437500\n",
      "Train Epoch: 25 [13920/17352 (80%)] Loss: -179491.718750\n",
      "Train Epoch: 25 [14000/17352 (81%)] Loss: -164670.015625\n",
      "Train Epoch: 25 [14080/17352 (81%)] Loss: -178631.156250\n",
      "Train Epoch: 25 [14160/17352 (82%)] Loss: -201029.421875\n",
      "Train Epoch: 25 [14240/17352 (82%)] Loss: -178421.921875\n",
      "Train Epoch: 25 [14320/17352 (83%)] Loss: -207856.453125\n",
      "Train Epoch: 25 [14400/17352 (83%)] Loss: -208719.515625\n",
      "Train Epoch: 25 [14480/17352 (83%)] Loss: -179966.906250\n",
      "Train Epoch: 25 [14560/17352 (84%)] Loss: -203657.796875\n",
      "Train Epoch: 25 [14640/17352 (84%)] Loss: -185362.296875\n",
      "Train Epoch: 25 [14720/17352 (85%)] Loss: -168752.625000\n",
      "Train Epoch: 25 [14800/17352 (85%)] Loss: -198302.906250\n",
      "Train Epoch: 25 [14880/17352 (86%)] Loss: -185436.375000\n",
      "Train Epoch: 25 [14960/17352 (86%)] Loss: -208894.562500\n",
      "Train Epoch: 25 [15040/17352 (87%)] Loss: -180751.203125\n",
      "Train Epoch: 25 [15120/17352 (87%)] Loss: -193361.671875\n",
      "Train Epoch: 25 [15200/17352 (88%)] Loss: -181712.796875\n",
      "Train Epoch: 25 [15280/17352 (88%)] Loss: -177734.250000\n",
      "Train Epoch: 25 [15360/17352 (89%)] Loss: -161084.859375\n",
      "Train Epoch: 25 [15440/17352 (89%)] Loss: -188503.046875\n",
      "Train Epoch: 25 [15520/17352 (89%)] Loss: -191298.250000\n",
      "Train Epoch: 25 [15600/17352 (90%)] Loss: -208416.312500\n",
      "Train Epoch: 25 [15680/17352 (90%)] Loss: -218398.890625\n",
      "Train Epoch: 25 [15760/17352 (91%)] Loss: -187881.218750\n",
      "Train Epoch: 25 [15840/17352 (91%)] Loss: -163765.406250\n",
      "Train Epoch: 25 [15920/17352 (92%)] Loss: -164731.375000\n",
      "Train Epoch: 25 [16000/17352 (92%)] Loss: -173926.125000\n",
      "Train Epoch: 25 [16080/17352 (93%)] Loss: -189484.015625\n",
      "Train Epoch: 25 [16160/17352 (93%)] Loss: -181950.359375\n",
      "Train Epoch: 25 [16240/17352 (94%)] Loss: -173567.484375\n",
      "Train Epoch: 25 [16320/17352 (94%)] Loss: -204333.046875\n",
      "Train Epoch: 25 [16400/17352 (95%)] Loss: -174978.984375\n",
      "Train Epoch: 25 [16480/17352 (95%)] Loss: -196021.218750\n",
      "Train Epoch: 25 [16560/17352 (95%)] Loss: -181909.578125\n",
      "Train Epoch: 25 [16640/17352 (96%)] Loss: -183957.250000\n",
      "Train Epoch: 25 [16720/17352 (96%)] Loss: -190206.218750\n",
      "Train Epoch: 25 [16800/17352 (97%)] Loss: -185237.859375\n",
      "Train Epoch: 25 [16880/17352 (97%)] Loss: -167864.890625\n",
      "Train Epoch: 25 [16960/17352 (98%)] Loss: -206080.156250\n",
      "Train Epoch: 25 [17040/17352 (98%)] Loss: -188860.484375\n",
      "Train Epoch: 25 [17120/17352 (99%)] Loss: -195712.562500\n",
      "Train Epoch: 25 [17200/17352 (99%)] Loss: -215640.250000\n",
      "Train Epoch: 25 [17280/17352 (100%)] Loss: -185283.406250\n",
      "Train Epoch: 25 [17360/17352 (100%)] Loss: -210143.562500\n",
      "    epoch          : 25\n",
      "    loss           : -189430.43019095223\n",
      "    val_loss       : -23714.926966635834\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch25.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 26 [0/17352 (0%)] Loss: -219653.578125\n",
      "Train Epoch: 26 [80/17352 (0%)] Loss: -212690.328125\n",
      "Train Epoch: 26 [160/17352 (1%)] Loss: -214411.593750\n",
      "Train Epoch: 26 [240/17352 (1%)] Loss: -224238.062500\n",
      "Train Epoch: 26 [320/17352 (2%)] Loss: -213346.531250\n",
      "Train Epoch: 26 [400/17352 (2%)] Loss: -218534.359375\n",
      "Train Epoch: 26 [480/17352 (3%)] Loss: -224235.421875\n",
      "Train Epoch: 26 [560/17352 (3%)] Loss: -215095.015625\n",
      "Train Epoch: 26 [640/17352 (4%)] Loss: -199899.015625\n",
      "Train Epoch: 26 [720/17352 (4%)] Loss: -222512.203125\n",
      "Train Epoch: 26 [800/17352 (5%)] Loss: -206130.218750\n",
      "Train Epoch: 26 [880/17352 (5%)] Loss: -193019.921875\n",
      "Train Epoch: 26 [960/17352 (6%)] Loss: -213326.265625\n",
      "Train Epoch: 26 [1040/17352 (6%)] Loss: -216203.015625\n",
      "Train Epoch: 26 [1120/17352 (6%)] Loss: -191881.484375\n",
      "Train Epoch: 26 [1200/17352 (7%)] Loss: -196409.250000\n",
      "Train Epoch: 26 [1280/17352 (7%)] Loss: -199804.109375\n",
      "Train Epoch: 26 [1360/17352 (8%)] Loss: -202312.250000\n",
      "Train Epoch: 26 [1440/17352 (8%)] Loss: -212651.281250\n",
      "Train Epoch: 26 [1520/17352 (9%)] Loss: -211896.656250\n",
      "Train Epoch: 26 [1600/17352 (9%)] Loss: -205186.265625\n",
      "Train Epoch: 26 [1680/17352 (10%)] Loss: -202269.406250\n",
      "Train Epoch: 26 [1760/17352 (10%)] Loss: -205081.671875\n",
      "Train Epoch: 26 [1840/17352 (11%)] Loss: -206634.046875\n",
      "Train Epoch: 26 [1920/17352 (11%)] Loss: -199093.875000\n",
      "Train Epoch: 26 [2000/17352 (12%)] Loss: -214718.656250\n",
      "Train Epoch: 26 [2080/17352 (12%)] Loss: -229225.515625\n",
      "Train Epoch: 26 [2160/17352 (12%)] Loss: -193695.656250\n",
      "Train Epoch: 26 [2240/17352 (13%)] Loss: -188263.609375\n",
      "Train Epoch: 26 [2320/17352 (13%)] Loss: -197557.625000\n",
      "Train Epoch: 26 [2400/17352 (14%)] Loss: -160045.968750\n",
      "Train Epoch: 26 [2480/17352 (14%)] Loss: -178814.015625\n",
      "Train Epoch: 26 [2560/17352 (15%)] Loss: -190926.421875\n",
      "Train Epoch: 26 [2640/17352 (15%)] Loss: -199798.765625\n",
      "Train Epoch: 26 [2720/17352 (16%)] Loss: -166454.203125\n",
      "Train Epoch: 26 [2800/17352 (16%)] Loss: -195650.515625\n",
      "Train Epoch: 26 [2880/17352 (17%)] Loss: -166402.578125\n",
      "Train Epoch: 26 [2960/17352 (17%)] Loss: -162552.671875\n",
      "Train Epoch: 26 [3040/17352 (18%)] Loss: -188446.328125\n",
      "Train Epoch: 26 [3120/17352 (18%)] Loss: -159730.359375\n",
      "Train Epoch: 26 [3200/17352 (18%)] Loss: -206158.687500\n",
      "Train Epoch: 26 [3280/17352 (19%)] Loss: -176907.734375\n",
      "Train Epoch: 26 [3360/17352 (19%)] Loss: -202914.046875\n",
      "Train Epoch: 26 [3440/17352 (20%)] Loss: -134534.890625\n",
      "Train Epoch: 26 [3520/17352 (20%)] Loss: -184059.625000\n",
      "Train Epoch: 26 [3600/17352 (21%)] Loss: -179669.015625\n",
      "Train Epoch: 26 [3680/17352 (21%)] Loss: -151213.312500\n",
      "Train Epoch: 26 [3760/17352 (22%)] Loss: -206917.984375\n",
      "Train Epoch: 26 [3840/17352 (22%)] Loss: -176163.078125\n",
      "Train Epoch: 26 [3920/17352 (23%)] Loss: -187394.937500\n",
      "Train Epoch: 26 [4000/17352 (23%)] Loss: -198295.687500\n",
      "Train Epoch: 26 [4080/17352 (24%)] Loss: -184741.687500\n",
      "Train Epoch: 26 [4160/17352 (24%)] Loss: -181606.921875\n",
      "Train Epoch: 26 [4240/17352 (24%)] Loss: -192001.437500\n",
      "Train Epoch: 26 [4320/17352 (25%)] Loss: -170683.062500\n",
      "Train Epoch: 26 [4400/17352 (25%)] Loss: -202782.593750\n",
      "Train Epoch: 26 [4480/17352 (26%)] Loss: -138322.828125\n",
      "Train Epoch: 26 [4560/17352 (26%)] Loss: -158247.062500\n",
      "Train Epoch: 26 [4640/17352 (27%)] Loss: -187996.265625\n",
      "Train Epoch: 26 [4720/17352 (27%)] Loss: -200991.812500\n",
      "Train Epoch: 26 [4800/17352 (28%)] Loss: -166653.937500\n",
      "Train Epoch: 26 [4880/17352 (28%)] Loss: -193900.265625\n",
      "Train Epoch: 26 [4960/17352 (29%)] Loss: -197101.687500\n",
      "Train Epoch: 26 [5040/17352 (29%)] Loss: -167865.718750\n",
      "Train Epoch: 26 [5120/17352 (30%)] Loss: -204328.062500\n",
      "Train Epoch: 26 [5200/17352 (30%)] Loss: -166429.187500\n",
      "Train Epoch: 26 [5280/17352 (30%)] Loss: -206468.953125\n",
      "Train Epoch: 26 [5360/17352 (31%)] Loss: -176699.843750\n",
      "Train Epoch: 26 [5440/17352 (31%)] Loss: -180014.062500\n",
      "Train Epoch: 26 [5520/17352 (32%)] Loss: -173908.671875\n",
      "Train Epoch: 26 [5600/17352 (32%)] Loss: -192390.953125\n",
      "Train Epoch: 26 [5680/17352 (33%)] Loss: -184947.015625\n",
      "Train Epoch: 26 [5760/17352 (33%)] Loss: -202570.562500\n",
      "Train Epoch: 26 [5840/17352 (34%)] Loss: -181885.921875\n",
      "Train Epoch: 26 [5920/17352 (34%)] Loss: -95252.820312\n",
      "Train Epoch: 26 [6000/17352 (35%)] Loss: -187591.593750\n",
      "Train Epoch: 26 [6080/17352 (35%)] Loss: -189795.562500\n",
      "Train Epoch: 26 [6160/17352 (36%)] Loss: -202474.109375\n",
      "Train Epoch: 26 [6240/17352 (36%)] Loss: -180509.406250\n",
      "Train Epoch: 26 [6320/17352 (36%)] Loss: -191821.468750\n",
      "Train Epoch: 26 [6400/17352 (37%)] Loss: -192277.515625\n",
      "Train Epoch: 26 [6480/17352 (37%)] Loss: -200403.281250\n",
      "Train Epoch: 26 [6560/17352 (38%)] Loss: -195295.312500\n",
      "Train Epoch: 26 [6640/17352 (38%)] Loss: -186796.156250\n",
      "Train Epoch: 26 [6720/17352 (39%)] Loss: -175499.656250\n",
      "Train Epoch: 26 [6800/17352 (39%)] Loss: -206220.843750\n",
      "Train Epoch: 26 [6880/17352 (40%)] Loss: -205495.484375\n",
      "Train Epoch: 26 [6960/17352 (40%)] Loss: -180906.265625\n",
      "Train Epoch: 26 [7040/17352 (41%)] Loss: -194587.687500\n",
      "Train Epoch: 26 [7120/17352 (41%)] Loss: -201085.656250\n",
      "Train Epoch: 26 [7200/17352 (41%)] Loss: -176885.765625\n",
      "Train Epoch: 26 [7280/17352 (42%)] Loss: -166541.421875\n",
      "Train Epoch: 26 [7360/17352 (42%)] Loss: -174448.656250\n",
      "Train Epoch: 26 [7440/17352 (43%)] Loss: -175010.156250\n",
      "Train Epoch: 26 [7520/17352 (43%)] Loss: -192935.687500\n",
      "Train Epoch: 26 [7600/17352 (44%)] Loss: -136423.796875\n",
      "Train Epoch: 26 [7680/17352 (44%)] Loss: -183377.203125\n",
      "Train Epoch: 26 [7760/17352 (45%)] Loss: -185359.375000\n",
      "Train Epoch: 26 [7840/17352 (45%)] Loss: -182674.000000\n",
      "Train Epoch: 26 [7920/17352 (46%)] Loss: -171538.328125\n",
      "Train Epoch: 26 [8000/17352 (46%)] Loss: -203803.828125\n",
      "Train Epoch: 26 [8080/17352 (47%)] Loss: -186842.406250\n",
      "Train Epoch: 26 [8160/17352 (47%)] Loss: -174982.531250\n",
      "Train Epoch: 26 [8240/17352 (47%)] Loss: -199782.375000\n",
      "Train Epoch: 26 [8320/17352 (48%)] Loss: -148815.703125\n",
      "Train Epoch: 26 [8400/17352 (48%)] Loss: -187949.937500\n",
      "Train Epoch: 26 [8480/17352 (49%)] Loss: -202187.687500\n",
      "Train Epoch: 26 [8560/17352 (49%)] Loss: -167134.578125\n",
      "Train Epoch: 26 [8640/17352 (50%)] Loss: -200126.578125\n",
      "Train Epoch: 26 [8720/17352 (50%)] Loss: -191047.687500\n",
      "Train Epoch: 26 [8800/17352 (51%)] Loss: -192308.343750\n",
      "Train Epoch: 26 [8880/17352 (51%)] Loss: -173841.281250\n",
      "Train Epoch: 26 [8960/17352 (52%)] Loss: -225470.015625\n",
      "Train Epoch: 26 [9040/17352 (52%)] Loss: -218402.812500\n",
      "Train Epoch: 26 [9120/17352 (53%)] Loss: -131034.218750\n",
      "Train Epoch: 26 [9200/17352 (53%)] Loss: -189996.875000\n",
      "Train Epoch: 26 [9280/17352 (53%)] Loss: -191940.828125\n",
      "Train Epoch: 26 [9360/17352 (54%)] Loss: -179435.515625\n",
      "Train Epoch: 26 [9440/17352 (54%)] Loss: -153317.750000\n",
      "Train Epoch: 26 [9520/17352 (55%)] Loss: -177187.859375\n",
      "Train Epoch: 26 [9600/17352 (55%)] Loss: -161088.328125\n",
      "Train Epoch: 26 [9680/17352 (56%)] Loss: -203871.328125\n",
      "Train Epoch: 26 [9760/17352 (56%)] Loss: -192225.546875\n",
      "Train Epoch: 26 [9840/17352 (57%)] Loss: -186939.578125\n",
      "Train Epoch: 26 [9920/17352 (57%)] Loss: -180245.781250\n",
      "Train Epoch: 26 [10000/17352 (58%)] Loss: -208721.140625\n",
      "Train Epoch: 26 [10080/17352 (58%)] Loss: -160145.015625\n",
      "Train Epoch: 26 [10160/17352 (59%)] Loss: -178817.875000\n",
      "Train Epoch: 26 [10240/17352 (59%)] Loss: -193049.203125\n",
      "Train Epoch: 26 [10320/17352 (59%)] Loss: -202234.281250\n",
      "Train Epoch: 26 [10400/17352 (60%)] Loss: -173117.250000\n",
      "Train Epoch: 26 [10480/17352 (60%)] Loss: -159309.203125\n",
      "Train Epoch: 26 [10560/17352 (61%)] Loss: -176080.062500\n",
      "Train Epoch: 26 [10640/17352 (61%)] Loss: -202838.812500\n",
      "Train Epoch: 26 [10720/17352 (62%)] Loss: -202008.984375\n",
      "Train Epoch: 26 [10800/17352 (62%)] Loss: -173937.687500\n",
      "Train Epoch: 26 [10880/17352 (63%)] Loss: -187128.218750\n",
      "Train Epoch: 26 [10960/17352 (63%)] Loss: -210787.000000\n",
      "Train Epoch: 26 [11040/17352 (64%)] Loss: -192634.843750\n",
      "Train Epoch: 26 [11120/17352 (64%)] Loss: -202084.359375\n",
      "Train Epoch: 26 [11200/17352 (65%)] Loss: -145999.937500\n",
      "Train Epoch: 26 [11280/17352 (65%)] Loss: -186545.250000\n",
      "Train Epoch: 26 [11360/17352 (65%)] Loss: -176584.125000\n",
      "Train Epoch: 26 [11440/17352 (66%)] Loss: -200634.187500\n",
      "Train Epoch: 26 [11520/17352 (66%)] Loss: -183913.656250\n",
      "Train Epoch: 26 [11600/17352 (67%)] Loss: -180103.281250\n",
      "Train Epoch: 26 [11680/17352 (67%)] Loss: -164868.703125\n",
      "Train Epoch: 26 [11760/17352 (68%)] Loss: -167295.718750\n",
      "Train Epoch: 26 [11840/17352 (68%)] Loss: -190982.875000\n",
      "Train Epoch: 26 [11920/17352 (69%)] Loss: -164823.281250\n",
      "Train Epoch: 26 [12000/17352 (69%)] Loss: -197997.937500\n",
      "Train Epoch: 26 [12080/17352 (70%)] Loss: -205160.250000\n",
      "Train Epoch: 26 [12160/17352 (70%)] Loss: -205018.031250\n",
      "Train Epoch: 26 [12240/17352 (71%)] Loss: -165349.031250\n",
      "Train Epoch: 26 [12320/17352 (71%)] Loss: -184728.031250\n",
      "Train Epoch: 26 [12400/17352 (71%)] Loss: -190234.187500\n",
      "Train Epoch: 26 [12480/17352 (72%)] Loss: -184838.734375\n",
      "Train Epoch: 26 [12560/17352 (72%)] Loss: -168243.484375\n",
      "Train Epoch: 26 [12640/17352 (73%)] Loss: -148438.500000\n",
      "Train Epoch: 26 [12720/17352 (73%)] Loss: -208027.171875\n",
      "Train Epoch: 26 [12800/17352 (74%)] Loss: -156991.687500\n",
      "Train Epoch: 26 [12880/17352 (74%)] Loss: -201119.015625\n",
      "Train Epoch: 26 [12960/17352 (75%)] Loss: -185356.062500\n",
      "Train Epoch: 26 [13040/17352 (75%)] Loss: -192674.500000\n",
      "Train Epoch: 26 [13120/17352 (76%)] Loss: -189500.750000\n",
      "Train Epoch: 26 [13200/17352 (76%)] Loss: -180227.843750\n",
      "Train Epoch: 26 [13280/17352 (77%)] Loss: -176587.000000\n",
      "Train Epoch: 26 [13360/17352 (77%)] Loss: -193502.187500\n",
      "Train Epoch: 26 [13440/17352 (77%)] Loss: -191628.203125\n",
      "Train Epoch: 26 [13520/17352 (78%)] Loss: -176477.468750\n",
      "Train Epoch: 26 [13600/17352 (78%)] Loss: -196018.437500\n",
      "Train Epoch: 26 [13680/17352 (79%)] Loss: -181964.875000\n",
      "Train Epoch: 26 [13760/17352 (79%)] Loss: -162716.859375\n",
      "Train Epoch: 26 [13840/17352 (80%)] Loss: -186038.734375\n",
      "Train Epoch: 26 [13920/17352 (80%)] Loss: -151731.125000\n",
      "Train Epoch: 26 [14000/17352 (81%)] Loss: -192735.812500\n",
      "Train Epoch: 26 [14080/17352 (81%)] Loss: -196913.421875\n",
      "Train Epoch: 26 [14160/17352 (82%)] Loss: -171290.984375\n",
      "Train Epoch: 26 [14240/17352 (82%)] Loss: -203471.765625\n",
      "Train Epoch: 26 [14320/17352 (83%)] Loss: -206602.781250\n",
      "Train Epoch: 26 [14400/17352 (83%)] Loss: -185039.750000\n",
      "Train Epoch: 26 [14480/17352 (83%)] Loss: -193178.656250\n",
      "Train Epoch: 26 [14560/17352 (84%)] Loss: -185232.546875\n",
      "Train Epoch: 26 [14640/17352 (84%)] Loss: -190805.656250\n",
      "Train Epoch: 26 [14720/17352 (85%)] Loss: -196933.375000\n",
      "Train Epoch: 26 [14800/17352 (85%)] Loss: -186779.921875\n",
      "Train Epoch: 26 [14880/17352 (86%)] Loss: -182913.484375\n",
      "Train Epoch: 26 [14960/17352 (86%)] Loss: -158738.187500\n",
      "Train Epoch: 26 [15040/17352 (87%)] Loss: -191592.562500\n",
      "Train Epoch: 26 [15120/17352 (87%)] Loss: -196037.421875\n",
      "Train Epoch: 26 [15200/17352 (88%)] Loss: -209496.984375\n",
      "Train Epoch: 26 [15280/17352 (88%)] Loss: -194942.593750\n",
      "Train Epoch: 26 [15360/17352 (89%)] Loss: -176958.140625\n",
      "Train Epoch: 26 [15440/17352 (89%)] Loss: -181654.625000\n",
      "Train Epoch: 26 [15520/17352 (89%)] Loss: -187639.375000\n",
      "Train Epoch: 26 [15600/17352 (90%)] Loss: -153888.906250\n",
      "Train Epoch: 26 [15680/17352 (90%)] Loss: -200615.906250\n",
      "Train Epoch: 26 [15760/17352 (91%)] Loss: -210268.000000\n",
      "Train Epoch: 26 [15840/17352 (91%)] Loss: -182533.687500\n",
      "Train Epoch: 26 [15920/17352 (92%)] Loss: -198011.250000\n",
      "Train Epoch: 26 [16000/17352 (92%)] Loss: -200975.968750\n",
      "Train Epoch: 26 [16080/17352 (93%)] Loss: -177163.281250\n",
      "Train Epoch: 26 [16160/17352 (93%)] Loss: -169186.406250\n",
      "Train Epoch: 26 [16240/17352 (94%)] Loss: -187251.437500\n",
      "Train Epoch: 26 [16320/17352 (94%)] Loss: -195035.234375\n",
      "Train Epoch: 26 [16400/17352 (95%)] Loss: -190618.656250\n",
      "Train Epoch: 26 [16480/17352 (95%)] Loss: -187613.406250\n",
      "Train Epoch: 26 [16560/17352 (95%)] Loss: -208748.765625\n",
      "Train Epoch: 26 [16640/17352 (96%)] Loss: -203124.125000\n",
      "Train Epoch: 26 [16720/17352 (96%)] Loss: -159682.953125\n",
      "Train Epoch: 26 [16800/17352 (97%)] Loss: -198543.656250\n",
      "Train Epoch: 26 [16880/17352 (97%)] Loss: -204990.250000\n",
      "Train Epoch: 26 [16960/17352 (98%)] Loss: -196699.562500\n",
      "Train Epoch: 26 [17040/17352 (98%)] Loss: -203451.468750\n",
      "Train Epoch: 26 [17120/17352 (99%)] Loss: -184016.687500\n",
      "Train Epoch: 26 [17200/17352 (99%)] Loss: -181252.609375\n",
      "Train Epoch: 26 [17280/17352 (100%)] Loss: -180828.640625\n",
      "Train Epoch: 26 [17360/17352 (100%)] Loss: -181434.359375\n",
      "    epoch          : 26\n",
      "    loss           : -188986.0627966772\n",
      "    val_loss       : -23714.78744908006\n",
      "Train Epoch: 27 [0/17352 (0%)] Loss: -231320.890625\n",
      "Train Epoch: 27 [80/17352 (0%)] Loss: -199790.015625\n",
      "Train Epoch: 27 [160/17352 (1%)] Loss: -202013.109375\n",
      "Train Epoch: 27 [240/17352 (1%)] Loss: -185289.562500\n",
      "Train Epoch: 27 [320/17352 (2%)] Loss: -194295.546875\n",
      "Train Epoch: 27 [400/17352 (2%)] Loss: -196436.734375\n",
      "Train Epoch: 27 [480/17352 (3%)] Loss: -205074.218750\n",
      "Train Epoch: 27 [560/17352 (3%)] Loss: -193022.218750\n",
      "Train Epoch: 27 [640/17352 (4%)] Loss: -209629.218750\n",
      "Train Epoch: 27 [720/17352 (4%)] Loss: -205552.125000\n",
      "Train Epoch: 27 [800/17352 (5%)] Loss: -228901.609375\n",
      "Train Epoch: 27 [880/17352 (5%)] Loss: -214413.375000\n",
      "Train Epoch: 27 [960/17352 (6%)] Loss: -218537.640625\n",
      "Train Epoch: 27 [1040/17352 (6%)] Loss: -199098.828125\n",
      "Train Epoch: 27 [1120/17352 (6%)] Loss: -212687.343750\n",
      "Train Epoch: 27 [1200/17352 (7%)] Loss: -213319.234375\n",
      "Train Epoch: 27 [1280/17352 (7%)] Loss: -217579.515625\n",
      "Train Epoch: 27 [1360/17352 (8%)] Loss: -202227.312500\n",
      "Train Epoch: 27 [1440/17352 (8%)] Loss: -224237.890625\n",
      "Train Epoch: 27 [1520/17352 (9%)] Loss: -182758.578125\n",
      "Train Epoch: 27 [1600/17352 (9%)] Loss: -185145.593750\n",
      "Train Epoch: 27 [1680/17352 (10%)] Loss: -198090.250000\n",
      "Train Epoch: 27 [1760/17352 (10%)] Loss: -193419.437500\n",
      "Train Epoch: 27 [1840/17352 (11%)] Loss: -188748.812500\n",
      "Train Epoch: 27 [1920/17352 (11%)] Loss: -229961.546875\n",
      "Train Epoch: 27 [2000/17352 (12%)] Loss: -216213.687500\n",
      "Train Epoch: 27 [2080/17352 (12%)] Loss: -206641.312500\n",
      "Train Epoch: 27 [2160/17352 (12%)] Loss: -196408.375000\n",
      "Train Epoch: 27 [2240/17352 (13%)] Loss: -203802.234375\n",
      "Train Epoch: 27 [2320/17352 (13%)] Loss: -168250.359375\n",
      "Train Epoch: 27 [2400/17352 (14%)] Loss: -208430.140625\n",
      "Train Epoch: 27 [2480/17352 (14%)] Loss: -149028.390625\n",
      "Train Epoch: 27 [2560/17352 (15%)] Loss: -173933.515625\n",
      "Train Epoch: 27 [2640/17352 (15%)] Loss: -181005.093750\n",
      "Train Epoch: 27 [2720/17352 (16%)] Loss: -192167.156250\n",
      "Train Epoch: 27 [2800/17352 (16%)] Loss: -178208.687500\n",
      "Train Epoch: 27 [2880/17352 (17%)] Loss: -183874.609375\n",
      "Train Epoch: 27 [2960/17352 (17%)] Loss: -202165.000000\n",
      "Train Epoch: 27 [3040/17352 (18%)] Loss: -171830.109375\n",
      "Train Epoch: 27 [3120/17352 (18%)] Loss: -146862.000000\n",
      "Train Epoch: 27 [3200/17352 (18%)] Loss: -178324.281250\n",
      "Train Epoch: 27 [3280/17352 (19%)] Loss: -188749.765625\n",
      "Train Epoch: 27 [3360/17352 (19%)] Loss: -206553.859375\n",
      "Train Epoch: 27 [3440/17352 (20%)] Loss: -184939.531250\n",
      "Train Epoch: 27 [3520/17352 (20%)] Loss: -176482.750000\n",
      "Train Epoch: 27 [3600/17352 (21%)] Loss: -178875.437500\n",
      "Train Epoch: 27 [3680/17352 (21%)] Loss: -208117.187500\n",
      "Train Epoch: 27 [3760/17352 (22%)] Loss: -184825.687500\n",
      "Train Epoch: 27 [3840/17352 (22%)] Loss: -184026.703125\n",
      "Train Epoch: 27 [3920/17352 (23%)] Loss: -180280.828125\n",
      "Train Epoch: 27 [4000/17352 (23%)] Loss: -187762.687500\n",
      "Train Epoch: 27 [4080/17352 (24%)] Loss: -197563.890625\n",
      "Train Epoch: 27 [4160/17352 (24%)] Loss: -202566.531250\n",
      "Train Epoch: 27 [4240/17352 (24%)] Loss: -161679.203125\n",
      "Train Epoch: 27 [4320/17352 (25%)] Loss: -173114.906250\n",
      "Train Epoch: 27 [4400/17352 (25%)] Loss: -143608.156250\n",
      "Train Epoch: 27 [4480/17352 (26%)] Loss: -175346.359375\n",
      "Train Epoch: 27 [4560/17352 (26%)] Loss: -194593.968750\n",
      "Train Epoch: 27 [4640/17352 (27%)] Loss: -185583.609375\n",
      "Train Epoch: 27 [4720/17352 (27%)] Loss: -191880.671875\n",
      "Train Epoch: 27 [4800/17352 (28%)] Loss: -172185.906250\n",
      "Train Epoch: 27 [4880/17352 (28%)] Loss: -183582.171875\n",
      "Train Epoch: 27 [4960/17352 (29%)] Loss: -202776.562500\n",
      "Train Epoch: 27 [5040/17352 (29%)] Loss: -185494.234375\n",
      "Train Epoch: 27 [5120/17352 (30%)] Loss: -198024.625000\n",
      "Train Epoch: 27 [5200/17352 (30%)] Loss: -212648.171875\n",
      "Train Epoch: 27 [5280/17352 (30%)] Loss: -181723.343750\n",
      "Train Epoch: 27 [5360/17352 (31%)] Loss: -189205.703125\n",
      "Train Epoch: 27 [5440/17352 (31%)] Loss: -202007.593750\n",
      "Train Epoch: 27 [5520/17352 (32%)] Loss: -188258.734375\n",
      "Train Epoch: 27 [5600/17352 (32%)] Loss: -190985.609375\n",
      "Train Epoch: 27 [5680/17352 (33%)] Loss: -175403.296875\n",
      "Train Epoch: 27 [5760/17352 (33%)] Loss: -206684.375000\n",
      "Train Epoch: 27 [5840/17352 (34%)] Loss: -195092.609375\n",
      "Train Epoch: 27 [5920/17352 (34%)] Loss: -166016.828125\n",
      "Train Epoch: 27 [6000/17352 (35%)] Loss: -188075.531250\n",
      "Train Epoch: 27 [6080/17352 (35%)] Loss: -186772.031250\n",
      "Train Epoch: 27 [6160/17352 (36%)] Loss: -166548.421875\n",
      "Train Epoch: 27 [6240/17352 (36%)] Loss: -209886.781250\n",
      "Train Epoch: 27 [6320/17352 (36%)] Loss: -192000.000000\n",
      "Train Epoch: 27 [6400/17352 (37%)] Loss: -183797.906250\n",
      "Train Epoch: 27 [6480/17352 (37%)] Loss: -164504.265625\n",
      "Train Epoch: 27 [6560/17352 (38%)] Loss: -196188.218750\n",
      "Train Epoch: 27 [6640/17352 (38%)] Loss: -180505.781250\n",
      "Train Epoch: 27 [6720/17352 (39%)] Loss: -180050.750000\n",
      "Train Epoch: 27 [6800/17352 (39%)] Loss: -151499.640625\n",
      "Train Epoch: 27 [6880/17352 (40%)] Loss: -207857.062500\n",
      "Train Epoch: 27 [6960/17352 (40%)] Loss: -185776.859375\n",
      "Train Epoch: 27 [7040/17352 (41%)] Loss: -208039.796875\n",
      "Train Epoch: 27 [7120/17352 (41%)] Loss: -208147.218750\n",
      "Train Epoch: 27 [7200/17352 (41%)] Loss: -167173.250000\n",
      "Train Epoch: 27 [7280/17352 (42%)] Loss: -174912.515625\n",
      "Train Epoch: 27 [7360/17352 (42%)] Loss: -197641.812500\n",
      "Train Epoch: 27 [7440/17352 (43%)] Loss: -175657.484375\n",
      "Train Epoch: 27 [7520/17352 (43%)] Loss: -184166.562500\n",
      "Train Epoch: 27 [7600/17352 (44%)] Loss: -205164.953125\n",
      "Train Epoch: 27 [7680/17352 (44%)] Loss: -191351.031250\n",
      "Train Epoch: 27 [7760/17352 (45%)] Loss: -187316.062500\n",
      "Train Epoch: 27 [7840/17352 (45%)] Loss: -179968.281250\n",
      "Train Epoch: 27 [7920/17352 (46%)] Loss: -196940.062500\n",
      "Train Epoch: 27 [8000/17352 (46%)] Loss: -169501.703125\n",
      "Train Epoch: 27 [8080/17352 (47%)] Loss: -159743.156250\n",
      "Train Epoch: 27 [8160/17352 (47%)] Loss: -185567.296875\n",
      "Train Epoch: 27 [8240/17352 (47%)] Loss: -199596.828125\n",
      "Train Epoch: 27 [8320/17352 (48%)] Loss: -149326.890625\n",
      "Train Epoch: 27 [8400/17352 (48%)] Loss: -213231.906250\n",
      "Train Epoch: 27 [8480/17352 (49%)] Loss: -211626.906250\n",
      "Train Epoch: 27 [8560/17352 (49%)] Loss: -158737.828125\n",
      "Train Epoch: 27 [8640/17352 (50%)] Loss: -151500.828125\n",
      "Train Epoch: 27 [8720/17352 (50%)] Loss: -180111.015625\n",
      "Train Epoch: 27 [8800/17352 (51%)] Loss: -194064.843750\n",
      "Train Epoch: 27 [8880/17352 (51%)] Loss: -200633.312500\n",
      "Train Epoch: 27 [8960/17352 (52%)] Loss: -166258.296875\n",
      "Train Epoch: 27 [9040/17352 (52%)] Loss: -172176.593750\n",
      "Train Epoch: 27 [9120/17352 (53%)] Loss: -198816.640625\n",
      "Train Epoch: 27 [9200/17352 (53%)] Loss: -188477.343750\n",
      "Train Epoch: 27 [9280/17352 (53%)] Loss: -167802.843750\n",
      "Train Epoch: 27 [9360/17352 (54%)] Loss: -185363.906250\n",
      "Train Epoch: 27 [9440/17352 (54%)] Loss: -182094.421875\n",
      "Train Epoch: 27 [9520/17352 (55%)] Loss: -191031.968750\n",
      "Train Epoch: 27 [9600/17352 (55%)] Loss: -177244.500000\n",
      "Train Epoch: 27 [9680/17352 (56%)] Loss: -223958.734375\n",
      "Train Epoch: 27 [9760/17352 (56%)] Loss: -201372.265625\n",
      "Train Epoch: 27 [9840/17352 (57%)] Loss: -227892.593750\n",
      "Train Epoch: 27 [9920/17352 (57%)] Loss: -172540.296875\n",
      "Train Epoch: 27 [10000/17352 (58%)] Loss: -187714.375000\n",
      "Train Epoch: 27 [10080/17352 (58%)] Loss: -170762.203125\n",
      "Train Epoch: 27 [10160/17352 (59%)] Loss: -175499.156250\n",
      "Train Epoch: 27 [10240/17352 (59%)] Loss: -211157.250000\n",
      "Train Epoch: 27 [10320/17352 (59%)] Loss: -215638.421875\n",
      "Train Epoch: 27 [10400/17352 (60%)] Loss: -190221.156250\n",
      "Train Epoch: 27 [10480/17352 (60%)] Loss: -175307.703125\n",
      "Train Epoch: 27 [10560/17352 (61%)] Loss: -188001.046875\n",
      "Train Epoch: 27 [10640/17352 (61%)] Loss: -195054.328125\n",
      "Train Epoch: 27 [10720/17352 (62%)] Loss: -186505.421875\n",
      "Train Epoch: 27 [10800/17352 (62%)] Loss: -174972.875000\n",
      "Train Epoch: 27 [10880/17352 (63%)] Loss: -192370.718750\n",
      "Train Epoch: 27 [10960/17352 (63%)] Loss: -144979.718750\n",
      "Train Epoch: 27 [11040/17352 (64%)] Loss: -187314.578125\n",
      "Train Epoch: 27 [11120/17352 (64%)] Loss: -174183.578125\n",
      "Train Epoch: 27 [11200/17352 (65%)] Loss: -157586.328125\n",
      "Train Epoch: 27 [11280/17352 (65%)] Loss: -151729.750000\n",
      "Train Epoch: 27 [11360/17352 (65%)] Loss: -209582.937500\n",
      "Train Epoch: 27 [11440/17352 (66%)] Loss: -213740.812500\n",
      "Train Epoch: 27 [11520/17352 (66%)] Loss: -164736.093750\n",
      "Train Epoch: 27 [11600/17352 (67%)] Loss: -180991.328125\n",
      "Train Epoch: 27 [11680/17352 (67%)] Loss: -180299.187500\n",
      "Train Epoch: 27 [11760/17352 (68%)] Loss: -195884.406250\n",
      "Train Epoch: 27 [11840/17352 (68%)] Loss: -183384.718750\n",
      "Train Epoch: 27 [11920/17352 (69%)] Loss: -187264.406250\n",
      "Train Epoch: 27 [12000/17352 (69%)] Loss: -193047.734375\n",
      "Train Epoch: 27 [12080/17352 (70%)] Loss: -186495.828125\n",
      "Train Epoch: 27 [12160/17352 (70%)] Loss: -174618.562500\n",
      "Train Epoch: 27 [12240/17352 (71%)] Loss: -203453.281250\n",
      "Train Epoch: 27 [12320/17352 (71%)] Loss: -179407.250000\n",
      "Train Epoch: 27 [12400/17352 (71%)] Loss: -180747.562500\n",
      "Train Epoch: 27 [12480/17352 (72%)] Loss: -181888.453125\n",
      "Train Epoch: 27 [12560/17352 (72%)] Loss: -213184.406250\n",
      "Train Epoch: 27 [12640/17352 (73%)] Loss: -184981.312500\n",
      "Train Epoch: 27 [12720/17352 (73%)] Loss: -201360.843750\n",
      "Train Epoch: 27 [12800/17352 (74%)] Loss: -199781.046875\n",
      "Train Epoch: 27 [12880/17352 (74%)] Loss: -192004.640625\n",
      "Train Epoch: 27 [12960/17352 (75%)] Loss: -199775.328125\n",
      "Train Epoch: 27 [13040/17352 (75%)] Loss: -210246.312500\n",
      "Train Epoch: 27 [13120/17352 (76%)] Loss: -166510.531250\n",
      "Train Epoch: 27 [13200/17352 (76%)] Loss: -176135.718750\n",
      "Train Epoch: 27 [13280/17352 (77%)] Loss: -178320.484375\n",
      "Train Epoch: 27 [13360/17352 (77%)] Loss: -181912.078125\n",
      "Train Epoch: 27 [13440/17352 (77%)] Loss: -159300.328125\n",
      "Train Epoch: 27 [13520/17352 (78%)] Loss: -167076.687500\n",
      "Train Epoch: 27 [13600/17352 (78%)] Loss: -166654.375000\n",
      "Train Epoch: 27 [13680/17352 (79%)] Loss: -165732.000000\n",
      "Train Epoch: 27 [13760/17352 (79%)] Loss: -196241.578125\n",
      "Train Epoch: 27 [13840/17352 (80%)] Loss: -200457.750000\n",
      "Train Epoch: 27 [13920/17352 (80%)] Loss: -179012.156250\n",
      "Train Epoch: 27 [14000/17352 (81%)] Loss: -218504.937500\n",
      "Train Epoch: 27 [14080/17352 (81%)] Loss: -193914.312500\n",
      "Train Epoch: 27 [14160/17352 (82%)] Loss: -195372.578125\n",
      "Train Epoch: 27 [14240/17352 (82%)] Loss: -207787.296875\n",
      "Train Epoch: 27 [14320/17352 (83%)] Loss: -214634.859375\n",
      "Train Epoch: 27 [14400/17352 (83%)] Loss: -202981.531250\n",
      "Train Epoch: 27 [14480/17352 (83%)] Loss: -216393.453125\n",
      "Train Epoch: 27 [14560/17352 (84%)] Loss: -189016.359375\n",
      "Train Epoch: 27 [14640/17352 (84%)] Loss: -200630.453125\n",
      "Train Epoch: 27 [14720/17352 (85%)] Loss: -204340.765625\n",
      "Train Epoch: 27 [14800/17352 (85%)] Loss: -170681.390625\n",
      "Train Epoch: 27 [14880/17352 (86%)] Loss: -193039.812500\n",
      "Train Epoch: 27 [14960/17352 (86%)] Loss: -189164.015625\n",
      "Train Epoch: 27 [15040/17352 (87%)] Loss: -220008.968750\n",
      "Train Epoch: 27 [15120/17352 (87%)] Loss: -209500.500000\n",
      "Train Epoch: 27 [15200/17352 (88%)] Loss: -204336.484375\n",
      "Train Epoch: 27 [15280/17352 (88%)] Loss: -171302.468750\n",
      "Train Epoch: 27 [15360/17352 (89%)] Loss: -204356.734375\n",
      "Train Epoch: 27 [15440/17352 (89%)] Loss: -174507.125000\n",
      "Train Epoch: 27 [15520/17352 (89%)] Loss: -184815.281250\n",
      "Train Epoch: 27 [15600/17352 (90%)] Loss: -180024.484375\n",
      "Train Epoch: 27 [15680/17352 (90%)] Loss: -187304.765625\n",
      "Train Epoch: 27 [15760/17352 (91%)] Loss: -196551.843750\n",
      "Train Epoch: 27 [15840/17352 (91%)] Loss: -169948.781250\n",
      "Train Epoch: 27 [15920/17352 (92%)] Loss: -163957.171875\n",
      "Train Epoch: 27 [16000/17352 (92%)] Loss: -185540.250000\n",
      "Train Epoch: 27 [16080/17352 (93%)] Loss: -159733.484375\n",
      "Train Epoch: 27 [16160/17352 (93%)] Loss: -174713.437500\n",
      "Train Epoch: 27 [16240/17352 (94%)] Loss: -176677.281250\n",
      "Train Epoch: 27 [16320/17352 (94%)] Loss: -180508.843750\n",
      "Train Epoch: 27 [16400/17352 (95%)] Loss: -180638.171875\n",
      "Train Epoch: 27 [16480/17352 (95%)] Loss: -221237.203125\n",
      "Train Epoch: 27 [16560/17352 (95%)] Loss: -180789.343750\n",
      "Train Epoch: 27 [16640/17352 (96%)] Loss: -192267.921875\n",
      "Train Epoch: 27 [16720/17352 (96%)] Loss: -218404.609375\n",
      "Train Epoch: 27 [16800/17352 (97%)] Loss: -183725.140625\n",
      "Train Epoch: 27 [16880/17352 (97%)] Loss: -191302.578125\n",
      "Train Epoch: 27 [16960/17352 (98%)] Loss: -196726.875000\n",
      "Train Epoch: 27 [17040/17352 (98%)] Loss: -195713.218750\n",
      "Train Epoch: 27 [17120/17352 (99%)] Loss: -196117.000000\n",
      "Train Epoch: 27 [17200/17352 (99%)] Loss: -170101.781250\n",
      "Train Epoch: 27 [17280/17352 (100%)] Loss: -165996.859375\n",
      "Train Epoch: 27 [17360/17352 (100%)] Loss: -208331.296875\n",
      "    epoch          : 27\n",
      "    loss           : -189174.1537507192\n",
      "    val_loss       : -23714.90984906837\n",
      "Train Epoch: 28 [0/17352 (0%)] Loss: -194299.515625\n",
      "Train Epoch: 28 [80/17352 (0%)] Loss: -198757.546875\n",
      "Train Epoch: 28 [160/17352 (1%)] Loss: -216204.062500\n",
      "Train Epoch: 28 [240/17352 (1%)] Loss: -226099.296875\n",
      "Train Epoch: 28 [320/17352 (2%)] Loss: -216069.593750\n",
      "Train Epoch: 28 [400/17352 (2%)] Loss: -202228.437500\n",
      "Train Epoch: 28 [480/17352 (3%)] Loss: -218547.078125\n",
      "Train Epoch: 28 [560/17352 (3%)] Loss: -206784.312500\n",
      "Train Epoch: 28 [640/17352 (4%)] Loss: -199899.187500\n",
      "Train Epoch: 28 [720/17352 (4%)] Loss: -214341.265625\n",
      "Train Epoch: 28 [800/17352 (5%)] Loss: -213825.812500\n",
      "Train Epoch: 28 [880/17352 (5%)] Loss: -215482.609375\n",
      "Train Epoch: 28 [960/17352 (6%)] Loss: -228007.312500\n",
      "Train Epoch: 28 [1040/17352 (6%)] Loss: -210742.656250\n",
      "Train Epoch: 28 [1120/17352 (6%)] Loss: -204721.843750\n",
      "Train Epoch: 28 [1200/17352 (7%)] Loss: -209639.640625\n",
      "Train Epoch: 28 [1280/17352 (7%)] Loss: -214509.125000\n",
      "Train Epoch: 28 [1360/17352 (8%)] Loss: -230393.875000\n",
      "Train Epoch: 28 [1440/17352 (8%)] Loss: -229941.937500\n",
      "Train Epoch: 28 [1520/17352 (9%)] Loss: -236833.484375\n",
      "Train Epoch: 28 [1600/17352 (9%)] Loss: -217582.671875\n",
      "Train Epoch: 28 [1680/17352 (10%)] Loss: -199925.062500\n",
      "Train Epoch: 28 [1760/17352 (10%)] Loss: -204353.953125\n",
      "Train Epoch: 28 [1840/17352 (11%)] Loss: -221463.906250\n",
      "Train Epoch: 28 [1920/17352 (11%)] Loss: -213316.406250\n",
      "Train Epoch: 28 [2000/17352 (12%)] Loss: -188744.625000\n",
      "Train Epoch: 28 [2080/17352 (12%)] Loss: -219256.171875\n",
      "Train Epoch: 28 [2160/17352 (12%)] Loss: -193576.125000\n",
      "Train Epoch: 28 [2240/17352 (13%)] Loss: -176262.656250\n",
      "Train Epoch: 28 [2320/17352 (13%)] Loss: -199725.031250\n",
      "Train Epoch: 28 [2400/17352 (14%)] Loss: -187451.843750\n",
      "Train Epoch: 28 [2480/17352 (14%)] Loss: -192946.968750\n",
      "Train Epoch: 28 [2560/17352 (15%)] Loss: -178308.562500\n",
      "Train Epoch: 28 [2640/17352 (15%)] Loss: -172172.796875\n",
      "Train Epoch: 28 [2720/17352 (16%)] Loss: -165380.390625\n",
      "Train Epoch: 28 [2800/17352 (16%)] Loss: -181159.875000\n",
      "Train Epoch: 28 [2880/17352 (17%)] Loss: -210487.843750\n",
      "Train Epoch: 28 [2960/17352 (17%)] Loss: -188752.281250\n",
      "Train Epoch: 28 [3040/17352 (18%)] Loss: -183384.218750\n",
      "Train Epoch: 28 [3120/17352 (18%)] Loss: -166646.671875\n",
      "Train Epoch: 28 [3200/17352 (18%)] Loss: -180286.265625\n",
      "Train Epoch: 28 [3280/17352 (19%)] Loss: -180897.343750\n",
      "Train Epoch: 28 [3360/17352 (19%)] Loss: -185423.953125\n",
      "Train Epoch: 28 [3440/17352 (20%)] Loss: -159694.578125\n",
      "Train Epoch: 28 [3520/17352 (20%)] Loss: -164061.500000\n",
      "Train Epoch: 28 [3600/17352 (21%)] Loss: -202783.609375\n",
      "Train Epoch: 28 [3680/17352 (21%)] Loss: -185987.718750\n",
      "Train Epoch: 28 [3760/17352 (22%)] Loss: -195881.281250\n",
      "Train Epoch: 28 [3840/17352 (22%)] Loss: -142608.187500\n",
      "Train Epoch: 28 [3920/17352 (23%)] Loss: -198553.031250\n",
      "Train Epoch: 28 [4000/17352 (23%)] Loss: -213175.125000\n",
      "Train Epoch: 28 [4080/17352 (24%)] Loss: -196124.656250\n",
      "Train Epoch: 28 [4160/17352 (24%)] Loss: -192246.218750\n",
      "Train Epoch: 28 [4240/17352 (24%)] Loss: -188480.500000\n",
      "Train Epoch: 28 [4320/17352 (25%)] Loss: -204991.984375\n",
      "Train Epoch: 28 [4400/17352 (25%)] Loss: -190787.484375\n",
      "Train Epoch: 28 [4480/17352 (26%)] Loss: -203844.031250\n",
      "Train Epoch: 28 [4560/17352 (26%)] Loss: -202232.890625\n",
      "Train Epoch: 28 [4640/17352 (27%)] Loss: -167246.859375\n",
      "Train Epoch: 28 [4720/17352 (27%)] Loss: -202013.062500\n",
      "Train Epoch: 28 [4800/17352 (28%)] Loss: -220012.250000\n",
      "Train Epoch: 28 [4880/17352 (28%)] Loss: -185785.515625\n",
      "Train Epoch: 28 [4960/17352 (29%)] Loss: -185820.875000\n",
      "Train Epoch: 28 [5040/17352 (29%)] Loss: -189165.625000\n",
      "Train Epoch: 28 [5120/17352 (30%)] Loss: -200060.906250\n",
      "Train Epoch: 28 [5200/17352 (30%)] Loss: -185227.218750\n",
      "Train Epoch: 28 [5280/17352 (30%)] Loss: -190469.156250\n",
      "Train Epoch: 28 [5360/17352 (31%)] Loss: -163774.937500\n",
      "Train Epoch: 28 [5440/17352 (31%)] Loss: -200989.984375\n",
      "Train Epoch: 28 [5520/17352 (32%)] Loss: -177226.781250\n",
      "Train Epoch: 28 [5600/17352 (32%)] Loss: -191163.421875\n",
      "Train Epoch: 28 [5680/17352 (33%)] Loss: -178320.390625\n",
      "Train Epoch: 28 [5760/17352 (33%)] Loss: -218503.843750\n",
      "Train Epoch: 28 [5840/17352 (34%)] Loss: -168985.671875\n",
      "Train Epoch: 28 [5920/17352 (34%)] Loss: -178632.796875\n",
      "Train Epoch: 28 [6000/17352 (35%)] Loss: -171893.625000\n",
      "Train Epoch: 28 [6080/17352 (35%)] Loss: -205526.421875\n",
      "Train Epoch: 28 [6160/17352 (36%)] Loss: -191957.984375\n",
      "Train Epoch: 28 [6240/17352 (36%)] Loss: -181366.937500\n",
      "Train Epoch: 28 [6320/17352 (36%)] Loss: -143623.421875\n",
      "Train Epoch: 28 [6400/17352 (37%)] Loss: -194046.843750\n",
      "Train Epoch: 28 [6480/17352 (37%)] Loss: -185532.859375\n",
      "Train Epoch: 28 [6560/17352 (38%)] Loss: -174638.203125\n",
      "Train Epoch: 28 [6640/17352 (38%)] Loss: -181671.765625\n",
      "Train Epoch: 28 [6720/17352 (39%)] Loss: -185281.578125\n",
      "Train Epoch: 28 [6800/17352 (39%)] Loss: -185168.390625\n",
      "Train Epoch: 28 [6880/17352 (40%)] Loss: -213896.968750\n",
      "Train Epoch: 28 [6960/17352 (40%)] Loss: -166659.250000\n",
      "Train Epoch: 28 [7040/17352 (41%)] Loss: -193904.484375\n",
      "Train Epoch: 28 [7120/17352 (41%)] Loss: -190076.718750\n",
      "Train Epoch: 28 [7200/17352 (41%)] Loss: -197074.796875\n",
      "Train Epoch: 28 [7280/17352 (42%)] Loss: -192002.750000\n",
      "Train Epoch: 28 [7360/17352 (42%)] Loss: -196114.687500\n",
      "Train Epoch: 28 [7440/17352 (43%)] Loss: -167792.062500\n",
      "Train Epoch: 28 [7520/17352 (43%)] Loss: -176956.968750\n",
      "Train Epoch: 28 [7600/17352 (44%)] Loss: -169739.562500\n",
      "Train Epoch: 28 [7680/17352 (44%)] Loss: -215459.437500\n",
      "Train Epoch: 28 [7760/17352 (45%)] Loss: -187511.609375\n",
      "Train Epoch: 28 [7840/17352 (45%)] Loss: -199411.703125\n",
      "Train Epoch: 28 [7920/17352 (46%)] Loss: -195829.406250\n",
      "Train Epoch: 28 [8000/17352 (46%)] Loss: -175209.250000\n",
      "Train Epoch: 28 [8080/17352 (47%)] Loss: -173830.406250\n",
      "Train Epoch: 28 [8160/17352 (47%)] Loss: -206220.906250\n",
      "Train Epoch: 28 [8240/17352 (47%)] Loss: -202925.500000\n",
      "Train Epoch: 28 [8320/17352 (48%)] Loss: -162555.734375\n",
      "Train Epoch: 28 [8400/17352 (48%)] Loss: -177584.828125\n",
      "Train Epoch: 28 [8480/17352 (49%)] Loss: -159741.656250\n",
      "Train Epoch: 28 [8560/17352 (49%)] Loss: -194055.796875\n",
      "Train Epoch: 28 [8640/17352 (50%)] Loss: -177303.562500\n",
      "Train Epoch: 28 [8720/17352 (50%)] Loss: -201311.046875\n",
      "Train Epoch: 28 [8800/17352 (51%)] Loss: -192688.859375\n",
      "Train Epoch: 28 [8880/17352 (51%)] Loss: -206687.437500\n",
      "Train Epoch: 28 [8960/17352 (52%)] Loss: -210251.906250\n",
      "Train Epoch: 28 [9040/17352 (52%)] Loss: -174966.828125\n",
      "Train Epoch: 28 [9120/17352 (53%)] Loss: -193443.281250\n",
      "Train Epoch: 28 [9200/17352 (53%)] Loss: -203439.937500\n",
      "Train Epoch: 28 [9280/17352 (53%)] Loss: -205007.062500\n",
      "Train Epoch: 28 [9360/17352 (54%)] Loss: -197647.031250\n",
      "Train Epoch: 28 [9440/17352 (54%)] Loss: -192165.296875\n",
      "Train Epoch: 28 [9520/17352 (55%)] Loss: -210383.187500\n",
      "Train Epoch: 28 [9600/17352 (55%)] Loss: -207832.500000\n",
      "Train Epoch: 28 [9680/17352 (56%)] Loss: -188435.500000\n",
      "Train Epoch: 28 [9760/17352 (56%)] Loss: -160050.796875\n",
      "Train Epoch: 28 [9840/17352 (57%)] Loss: -200291.109375\n",
      "Train Epoch: 28 [9920/17352 (57%)] Loss: -201321.015625\n",
      "Train Epoch: 28 [10000/17352 (58%)] Loss: -189217.187500\n",
      "Train Epoch: 28 [10080/17352 (58%)] Loss: -191945.093750\n",
      "Train Epoch: 28 [10160/17352 (59%)] Loss: -178724.125000\n",
      "Train Epoch: 28 [10240/17352 (59%)] Loss: -206082.781250\n",
      "Train Epoch: 28 [10320/17352 (59%)] Loss: -213230.078125\n",
      "Train Epoch: 28 [10400/17352 (60%)] Loss: -189295.718750\n",
      "Train Epoch: 28 [10480/17352 (60%)] Loss: -195830.203125\n",
      "Train Epoch: 28 [10560/17352 (61%)] Loss: -179887.031250\n",
      "Train Epoch: 28 [10640/17352 (61%)] Loss: -192282.234375\n",
      "Train Epoch: 28 [10720/17352 (62%)] Loss: -183714.562500\n",
      "Train Epoch: 28 [10800/17352 (62%)] Loss: -212643.906250\n",
      "Train Epoch: 28 [10880/17352 (63%)] Loss: -172612.484375\n",
      "Train Epoch: 28 [10960/17352 (63%)] Loss: -211724.968750\n",
      "Train Epoch: 28 [11040/17352 (64%)] Loss: -193785.750000\n",
      "Train Epoch: 28 [11120/17352 (64%)] Loss: -171316.843750\n",
      "Train Epoch: 28 [11200/17352 (65%)] Loss: -165732.234375\n",
      "Train Epoch: 28 [11280/17352 (65%)] Loss: -180532.828125\n",
      "Train Epoch: 28 [11360/17352 (65%)] Loss: -144986.875000\n",
      "Train Epoch: 28 [11440/17352 (66%)] Loss: -198537.875000\n",
      "Train Epoch: 28 [11520/17352 (66%)] Loss: -148922.812500\n",
      "Train Epoch: 28 [11600/17352 (67%)] Loss: -153875.046875\n",
      "Train Epoch: 28 [11680/17352 (67%)] Loss: -183860.531250\n",
      "Train Epoch: 28 [11760/17352 (68%)] Loss: -174991.953125\n",
      "Train Epoch: 28 [11840/17352 (68%)] Loss: -178820.734375\n",
      "Train Epoch: 28 [11920/17352 (69%)] Loss: -168075.500000\n",
      "Train Epoch: 28 [12000/17352 (69%)] Loss: -209584.953125\n",
      "Train Epoch: 28 [12080/17352 (70%)] Loss: -208145.000000\n",
      "Train Epoch: 28 [12160/17352 (70%)] Loss: -187640.750000\n",
      "Train Epoch: 28 [12240/17352 (71%)] Loss: -209171.484375\n",
      "Train Epoch: 28 [12320/17352 (71%)] Loss: -159309.156250\n",
      "Train Epoch: 28 [12400/17352 (71%)] Loss: -156610.562500\n",
      "Train Epoch: 28 [12480/17352 (72%)] Loss: -201971.609375\n",
      "Train Epoch: 28 [12560/17352 (72%)] Loss: -192373.906250\n",
      "Train Epoch: 28 [12640/17352 (73%)] Loss: -200855.906250\n",
      "Train Epoch: 28 [12720/17352 (73%)] Loss: -209260.750000\n",
      "Train Epoch: 28 [12800/17352 (74%)] Loss: -183283.484375\n",
      "Train Epoch: 28 [12880/17352 (74%)] Loss: -174518.343750\n",
      "Train Epoch: 28 [12960/17352 (75%)] Loss: -174865.500000\n",
      "Train Epoch: 28 [13040/17352 (75%)] Loss: -228249.734375\n",
      "Train Epoch: 28 [13120/17352 (76%)] Loss: -182771.468750\n",
      "Train Epoch: 28 [13200/17352 (76%)] Loss: -187604.796875\n",
      "Train Epoch: 28 [13280/17352 (77%)] Loss: -196400.437500\n",
      "Train Epoch: 28 [13360/17352 (77%)] Loss: -192222.109375\n",
      "Train Epoch: 28 [13440/17352 (77%)] Loss: -228152.000000\n",
      "Train Epoch: 28 [13520/17352 (78%)] Loss: -164144.687500\n",
      "Train Epoch: 28 [13600/17352 (78%)] Loss: -147411.375000\n",
      "Train Epoch: 28 [13680/17352 (79%)] Loss: -204683.562500\n",
      "Train Epoch: 28 [13760/17352 (79%)] Loss: -176876.859375\n",
      "Train Epoch: 28 [13840/17352 (80%)] Loss: -201379.375000\n",
      "Train Epoch: 28 [13920/17352 (80%)] Loss: -183462.937500\n",
      "Train Epoch: 28 [14000/17352 (81%)] Loss: -196026.343750\n",
      "Train Epoch: 28 [14080/17352 (81%)] Loss: -201360.296875\n",
      "Train Epoch: 28 [14160/17352 (82%)] Loss: -191621.015625\n",
      "Train Epoch: 28 [14240/17352 (82%)] Loss: -191884.750000\n",
      "Train Epoch: 28 [14320/17352 (83%)] Loss: -171292.031250\n",
      "Train Epoch: 28 [14400/17352 (83%)] Loss: -181911.781250\n",
      "Train Epoch: 28 [14480/17352 (83%)] Loss: -193361.109375\n",
      "Train Epoch: 28 [14560/17352 (84%)] Loss: -193039.859375\n",
      "Train Epoch: 28 [14640/17352 (84%)] Loss: -178874.421875\n",
      "Train Epoch: 28 [14720/17352 (85%)] Loss: -148812.796875\n",
      "Train Epoch: 28 [14800/17352 (85%)] Loss: -180503.656250\n",
      "Train Epoch: 28 [14880/17352 (86%)] Loss: -193486.171875\n",
      "Train Epoch: 28 [14960/17352 (86%)] Loss: -140586.531250\n",
      "Train Epoch: 28 [15040/17352 (87%)] Loss: -176476.671875\n",
      "Train Epoch: 28 [15120/17352 (87%)] Loss: -185590.546875\n",
      "Train Epoch: 28 [15200/17352 (88%)] Loss: -185928.265625\n",
      "Train Epoch: 28 [15280/17352 (88%)] Loss: -164985.125000\n",
      "Train Epoch: 28 [15360/17352 (89%)] Loss: -175012.203125\n",
      "Train Epoch: 28 [15440/17352 (89%)] Loss: -149438.109375\n",
      "Train Epoch: 28 [15520/17352 (89%)] Loss: -219921.500000\n",
      "Train Epoch: 28 [15600/17352 (90%)] Loss: -172547.671875\n",
      "Train Epoch: 28 [15680/17352 (90%)] Loss: -196441.687500\n",
      "Train Epoch: 28 [15760/17352 (91%)] Loss: -202080.062500\n",
      "Train Epoch: 28 [15840/17352 (91%)] Loss: -208342.765625\n",
      "Train Epoch: 28 [15920/17352 (92%)] Loss: -174938.328125\n",
      "Train Epoch: 28 [16000/17352 (92%)] Loss: -169437.328125\n",
      "Train Epoch: 28 [16080/17352 (93%)] Loss: -187761.859375\n",
      "Train Epoch: 28 [16160/17352 (93%)] Loss: -186513.937500\n",
      "Train Epoch: 28 [16240/17352 (94%)] Loss: -183969.296875\n",
      "Train Epoch: 28 [16320/17352 (94%)] Loss: -169176.171875\n",
      "Train Epoch: 28 [16400/17352 (95%)] Loss: -183396.156250\n",
      "Train Epoch: 28 [16480/17352 (95%)] Loss: -179478.375000\n",
      "Train Epoch: 28 [16560/17352 (95%)] Loss: -215403.453125\n",
      "Train Epoch: 28 [16640/17352 (96%)] Loss: -206149.812500\n",
      "Train Epoch: 28 [16720/17352 (96%)] Loss: -199136.140625\n",
      "Train Epoch: 28 [16800/17352 (97%)] Loss: -212606.546875\n",
      "Train Epoch: 28 [16880/17352 (97%)] Loss: -194062.968750\n",
      "Train Epoch: 28 [16960/17352 (98%)] Loss: -210774.687500\n",
      "Train Epoch: 28 [17040/17352 (98%)] Loss: -163340.343750\n",
      "Train Epoch: 28 [17120/17352 (99%)] Loss: -166510.843750\n",
      "Train Epoch: 28 [17200/17352 (99%)] Loss: -189567.703125\n",
      "Train Epoch: 28 [17280/17352 (100%)] Loss: -177463.468750\n",
      "Train Epoch: 28 [17360/17352 (100%)] Loss: -203885.031250\n",
      "    epoch          : 28\n",
      "    loss           : -189516.25836090333\n",
      "    val_loss       : -23715.068370192264\n",
      "Train Epoch: 29 [0/17352 (0%)] Loss: -230176.453125\n",
      "Train Epoch: 29 [80/17352 (0%)] Loss: -199096.250000\n",
      "Train Epoch: 29 [160/17352 (1%)] Loss: -228899.281250\n",
      "Train Epoch: 29 [240/17352 (1%)] Loss: -218529.968750\n",
      "Train Epoch: 29 [320/17352 (2%)] Loss: -214707.921875\n",
      "Train Epoch: 29 [400/17352 (2%)] Loss: -221759.375000\n",
      "Train Epoch: 29 [480/17352 (3%)] Loss: -214508.218750\n",
      "Train Epoch: 29 [560/17352 (3%)] Loss: -210626.046875\n",
      "Train Epoch: 29 [640/17352 (4%)] Loss: -204347.437500\n",
      "Train Epoch: 29 [720/17352 (4%)] Loss: -206647.203125\n",
      "Train Epoch: 29 [800/17352 (5%)] Loss: -217625.171875\n",
      "Train Epoch: 29 [880/17352 (5%)] Loss: -211100.078125\n",
      "Train Epoch: 29 [960/17352 (6%)] Loss: -230407.515625\n",
      "Train Epoch: 29 [1040/17352 (6%)] Loss: -219251.859375\n",
      "Train Epoch: 29 [1120/17352 (6%)] Loss: -212173.328125\n",
      "Train Epoch: 29 [1200/17352 (7%)] Loss: -208377.671875\n",
      "Train Epoch: 29 [1280/17352 (7%)] Loss: -182772.625000\n",
      "Train Epoch: 29 [1360/17352 (8%)] Loss: -194488.296875\n",
      "Train Epoch: 29 [1440/17352 (8%)] Loss: -236506.343750\n",
      "Train Epoch: 29 [1520/17352 (9%)] Loss: -193694.171875\n",
      "Train Epoch: 29 [1600/17352 (9%)] Loss: -196433.640625\n",
      "Train Epoch: 29 [1680/17352 (10%)] Loss: -236829.453125\n",
      "Train Epoch: 29 [1760/17352 (10%)] Loss: -212384.562500\n",
      "Train Epoch: 29 [1840/17352 (11%)] Loss: -199518.000000\n",
      "Train Epoch: 29 [1920/17352 (11%)] Loss: -198104.765625\n",
      "Train Epoch: 29 [2000/17352 (12%)] Loss: -205187.015625\n",
      "Train Epoch: 29 [2080/17352 (12%)] Loss: -204526.984375\n",
      "Train Epoch: 29 [2160/17352 (12%)] Loss: -223002.078125\n",
      "Train Epoch: 29 [2240/17352 (13%)] Loss: -189476.078125\n",
      "Train Epoch: 29 [2320/17352 (13%)] Loss: -201264.843750\n",
      "Train Epoch: 29 [2400/17352 (14%)] Loss: -187440.234375\n",
      "Train Epoch: 29 [2480/17352 (14%)] Loss: -196699.296875\n",
      "Train Epoch: 29 [2560/17352 (15%)] Loss: -203427.625000\n",
      "Train Epoch: 29 [2640/17352 (15%)] Loss: -200862.281250\n",
      "Train Epoch: 29 [2720/17352 (16%)] Loss: -205532.140625\n",
      "Train Epoch: 29 [2800/17352 (16%)] Loss: -156607.515625\n",
      "Train Epoch: 29 [2880/17352 (17%)] Loss: -200826.687500\n",
      "Train Epoch: 29 [2960/17352 (17%)] Loss: -213227.546875\n",
      "Train Epoch: 29 [3040/17352 (18%)] Loss: -179434.125000\n",
      "Train Epoch: 29 [3120/17352 (18%)] Loss: -197939.625000\n",
      "Train Epoch: 29 [3200/17352 (18%)] Loss: -199411.703125\n",
      "Train Epoch: 29 [3280/17352 (19%)] Loss: -231029.593750\n",
      "Train Epoch: 29 [3360/17352 (19%)] Loss: -201318.296875\n",
      "Train Epoch: 29 [3440/17352 (20%)] Loss: -165862.765625\n",
      "Train Epoch: 29 [3520/17352 (20%)] Loss: -200972.437500\n",
      "Train Epoch: 29 [3600/17352 (21%)] Loss: -185997.625000\n",
      "Train Epoch: 29 [3680/17352 (21%)] Loss: -179381.140625\n",
      "Train Epoch: 29 [3760/17352 (22%)] Loss: -140591.843750\n",
      "Train Epoch: 29 [3840/17352 (22%)] Loss: -205148.625000\n",
      "Train Epoch: 29 [3920/17352 (23%)] Loss: -168499.078125\n",
      "Train Epoch: 29 [4000/17352 (23%)] Loss: -228244.562500\n",
      "Train Epoch: 29 [4080/17352 (24%)] Loss: -174478.000000\n",
      "Train Epoch: 29 [4160/17352 (24%)] Loss: -196443.187500\n",
      "Train Epoch: 29 [4240/17352 (24%)] Loss: -177231.687500\n",
      "Train Epoch: 29 [4320/17352 (25%)] Loss: -218404.046875\n",
      "Train Epoch: 29 [4400/17352 (25%)] Loss: -195815.656250\n",
      "Train Epoch: 29 [4480/17352 (26%)] Loss: -142329.484375\n",
      "Train Epoch: 29 [4560/17352 (26%)] Loss: -180281.781250\n",
      "Train Epoch: 29 [4640/17352 (27%)] Loss: -210387.218750\n",
      "Train Epoch: 29 [4720/17352 (27%)] Loss: -191505.578125\n",
      "Train Epoch: 29 [4800/17352 (28%)] Loss: -179004.109375\n",
      "Train Epoch: 29 [4880/17352 (28%)] Loss: -167877.531250\n",
      "Train Epoch: 29 [4960/17352 (29%)] Loss: -172540.343750\n",
      "Train Epoch: 29 [5040/17352 (29%)] Loss: -187213.984375\n",
      "Train Epoch: 29 [5120/17352 (30%)] Loss: -176961.046875\n",
      "Train Epoch: 29 [5200/17352 (30%)] Loss: -174510.187500\n",
      "Train Epoch: 29 [5280/17352 (30%)] Loss: -182725.515625\n",
      "Train Epoch: 29 [5360/17352 (31%)] Loss: -192639.484375\n",
      "Train Epoch: 29 [5440/17352 (31%)] Loss: -178870.703125\n",
      "Train Epoch: 29 [5520/17352 (32%)] Loss: -179960.375000\n",
      "Train Epoch: 29 [5600/17352 (32%)] Loss: -179002.281250\n",
      "Train Epoch: 29 [5680/17352 (33%)] Loss: -165730.546875\n",
      "Train Epoch: 29 [5760/17352 (33%)] Loss: -194047.765625\n",
      "Train Epoch: 29 [5840/17352 (34%)] Loss: -191589.453125\n",
      "Train Epoch: 29 [5920/17352 (34%)] Loss: -163541.843750\n",
      "Train Epoch: 29 [6000/17352 (35%)] Loss: -185231.453125\n",
      "Train Epoch: 29 [6080/17352 (35%)] Loss: -220967.781250\n",
      "Train Epoch: 29 [6160/17352 (36%)] Loss: -184911.296875\n",
      "Train Epoch: 29 [6240/17352 (36%)] Loss: -173575.046875\n",
      "Train Epoch: 29 [6320/17352 (36%)] Loss: -192276.375000\n",
      "Train Epoch: 29 [6400/17352 (37%)] Loss: -169502.906250\n",
      "Train Epoch: 29 [6480/17352 (37%)] Loss: -168048.343750\n",
      "Train Epoch: 29 [6560/17352 (38%)] Loss: -175413.906250\n",
      "Train Epoch: 29 [6640/17352 (38%)] Loss: -203261.921875\n",
      "Train Epoch: 29 [6720/17352 (39%)] Loss: -159689.484375\n",
      "Train Epoch: 29 [6800/17352 (39%)] Loss: -198258.359375\n",
      "Train Epoch: 29 [6880/17352 (40%)] Loss: -191337.718750\n",
      "Train Epoch: 29 [6960/17352 (40%)] Loss: -171178.625000\n",
      "Train Epoch: 29 [7040/17352 (41%)] Loss: -203142.500000\n",
      "Train Epoch: 29 [7120/17352 (41%)] Loss: -196034.296875\n",
      "Train Epoch: 29 [7200/17352 (41%)] Loss: -218516.546875\n",
      "Train Epoch: 29 [7280/17352 (42%)] Loss: -187263.234375\n",
      "Train Epoch: 29 [7360/17352 (42%)] Loss: -207082.203125\n",
      "Train Epoch: 29 [7440/17352 (43%)] Loss: -177775.125000\n",
      "Train Epoch: 29 [7520/17352 (43%)] Loss: -182680.203125\n",
      "Train Epoch: 29 [7600/17352 (44%)] Loss: -193485.328125\n",
      "Train Epoch: 29 [7680/17352 (44%)] Loss: -178318.343750\n",
      "Train Epoch: 29 [7760/17352 (45%)] Loss: -187200.718750\n",
      "Train Epoch: 29 [7840/17352 (45%)] Loss: -208125.968750\n",
      "Train Epoch: 29 [7920/17352 (46%)] Loss: -202237.265625\n",
      "Train Epoch: 29 [8000/17352 (46%)] Loss: -206195.125000\n",
      "Train Epoch: 29 [8080/17352 (47%)] Loss: -209808.421875\n",
      "Train Epoch: 29 [8160/17352 (47%)] Loss: -177192.500000\n",
      "Train Epoch: 29 [8240/17352 (47%)] Loss: -180991.062500\n",
      "Train Epoch: 29 [8320/17352 (48%)] Loss: -194058.656250\n",
      "Train Epoch: 29 [8400/17352 (48%)] Loss: -152907.546875\n",
      "Train Epoch: 29 [8480/17352 (49%)] Loss: -186503.265625\n",
      "Train Epoch: 29 [8560/17352 (49%)] Loss: -181883.875000\n",
      "Train Epoch: 29 [8640/17352 (50%)] Loss: -167213.890625\n",
      "Train Epoch: 29 [8720/17352 (50%)] Loss: -166781.375000\n",
      "Train Epoch: 29 [8800/17352 (51%)] Loss: -188055.000000\n",
      "Train Epoch: 29 [8880/17352 (51%)] Loss: -182526.218750\n",
      "Train Epoch: 29 [8960/17352 (52%)] Loss: -203872.156250\n",
      "Train Epoch: 29 [9040/17352 (52%)] Loss: -175314.750000\n",
      "Train Epoch: 29 [9120/17352 (53%)] Loss: -178137.281250\n",
      "Train Epoch: 29 [9200/17352 (53%)] Loss: -176271.718750\n",
      "Train Epoch: 29 [9280/17352 (53%)] Loss: -191714.125000\n",
      "Train Epoch: 29 [9360/17352 (54%)] Loss: -188437.187500\n",
      "Train Epoch: 29 [9440/17352 (54%)] Loss: -173888.484375\n",
      "Train Epoch: 29 [9520/17352 (55%)] Loss: -163740.437500\n",
      "Train Epoch: 29 [9600/17352 (55%)] Loss: -208337.875000\n",
      "Train Epoch: 29 [9680/17352 (56%)] Loss: -183084.609375\n",
      "Train Epoch: 29 [9760/17352 (56%)] Loss: -201933.062500\n",
      "Train Epoch: 29 [9840/17352 (57%)] Loss: -166247.828125\n",
      "Train Epoch: 29 [9920/17352 (57%)] Loss: -193362.078125\n",
      "Train Epoch: 29 [10000/17352 (58%)] Loss: -207835.750000\n",
      "Train Epoch: 29 [10080/17352 (58%)] Loss: -195784.515625\n",
      "Train Epoch: 29 [10160/17352 (59%)] Loss: -192265.312500\n",
      "Train Epoch: 29 [10240/17352 (59%)] Loss: -177969.500000\n",
      "Train Epoch: 29 [10320/17352 (59%)] Loss: -170523.484375\n",
      "Train Epoch: 29 [10400/17352 (60%)] Loss: -207862.390625\n",
      "Train Epoch: 29 [10480/17352 (60%)] Loss: -211079.468750\n",
      "Train Epoch: 29 [10560/17352 (61%)] Loss: -192779.312500\n",
      "Train Epoch: 29 [10640/17352 (61%)] Loss: -204406.250000\n",
      "Train Epoch: 29 [10720/17352 (62%)] Loss: -191232.343750\n",
      "Train Epoch: 29 [10800/17352 (62%)] Loss: -208803.171875\n",
      "Train Epoch: 29 [10880/17352 (63%)] Loss: -205483.265625\n",
      "Train Epoch: 29 [10960/17352 (63%)] Loss: -184596.781250\n",
      "Train Epoch: 29 [11040/17352 (64%)] Loss: -193041.171875\n",
      "Train Epoch: 29 [11120/17352 (64%)] Loss: -189263.703125\n",
      "Train Epoch: 29 [11200/17352 (65%)] Loss: -184740.843750\n",
      "Train Epoch: 29 [11280/17352 (65%)] Loss: -164733.437500\n",
      "Train Epoch: 29 [11360/17352 (65%)] Loss: -197433.125000\n",
      "Train Epoch: 29 [11440/17352 (66%)] Loss: -181365.718750\n",
      "Train Epoch: 29 [11520/17352 (66%)] Loss: -173833.843750\n",
      "Train Epoch: 29 [11600/17352 (67%)] Loss: -167944.828125\n",
      "Train Epoch: 29 [11680/17352 (67%)] Loss: -180540.859375\n",
      "Train Epoch: 29 [11760/17352 (68%)] Loss: -197368.062500\n",
      "Train Epoch: 29 [11840/17352 (68%)] Loss: -195709.875000\n",
      "Train Epoch: 29 [11920/17352 (69%)] Loss: -157489.156250\n",
      "Train Epoch: 29 [12000/17352 (69%)] Loss: -162547.250000\n",
      "Train Epoch: 29 [12080/17352 (70%)] Loss: -161512.765625\n",
      "Train Epoch: 29 [12160/17352 (70%)] Loss: -180298.968750\n",
      "Train Epoch: 29 [12240/17352 (71%)] Loss: -163496.953125\n",
      "Train Epoch: 29 [12320/17352 (71%)] Loss: -215405.468750\n",
      "Train Epoch: 29 [12400/17352 (71%)] Loss: -148821.656250\n",
      "Train Epoch: 29 [12480/17352 (72%)] Loss: -187939.187500\n",
      "Train Epoch: 29 [12560/17352 (72%)] Loss: -179299.125000\n",
      "Train Epoch: 29 [12640/17352 (73%)] Loss: -206692.015625\n",
      "Train Epoch: 29 [12720/17352 (73%)] Loss: -178796.859375\n",
      "Train Epoch: 29 [12800/17352 (74%)] Loss: -184484.109375\n",
      "Train Epoch: 29 [12880/17352 (74%)] Loss: -193904.156250\n",
      "Train Epoch: 29 [12960/17352 (75%)] Loss: -176530.765625\n",
      "Train Epoch: 29 [13040/17352 (75%)] Loss: -183253.875000\n",
      "Train Epoch: 29 [13120/17352 (76%)] Loss: -164990.093750\n",
      "Train Epoch: 29 [13200/17352 (76%)] Loss: -186493.656250\n",
      "Train Epoch: 29 [13280/17352 (77%)] Loss: -175010.140625\n",
      "Train Epoch: 29 [13360/17352 (77%)] Loss: -188554.203125\n",
      "Train Epoch: 29 [13440/17352 (77%)] Loss: -217611.125000\n",
      "Train Epoch: 29 [13520/17352 (78%)] Loss: -163770.343750\n",
      "Train Epoch: 29 [13600/17352 (78%)] Loss: -204201.609375\n",
      "Train Epoch: 29 [13680/17352 (79%)] Loss: -197566.828125\n",
      "Train Epoch: 29 [13760/17352 (79%)] Loss: -191826.031250\n",
      "Train Epoch: 29 [13840/17352 (80%)] Loss: -160131.812500\n",
      "Train Epoch: 29 [13920/17352 (80%)] Loss: -171590.843750\n",
      "Train Epoch: 29 [14000/17352 (81%)] Loss: -189564.812500\n",
      "Train Epoch: 29 [14080/17352 (81%)] Loss: -215641.796875\n",
      "Train Epoch: 29 [14160/17352 (82%)] Loss: -167482.859375\n",
      "Train Epoch: 29 [14240/17352 (82%)] Loss: -203452.078125\n",
      "Train Epoch: 29 [14320/17352 (83%)] Loss: -173024.250000\n",
      "Train Epoch: 29 [14400/17352 (83%)] Loss: -196150.843750\n",
      "Train Epoch: 29 [14480/17352 (83%)] Loss: -169182.156250\n",
      "Train Epoch: 29 [14560/17352 (84%)] Loss: -209887.875000\n",
      "Train Epoch: 29 [14640/17352 (84%)] Loss: -209253.312500\n",
      "Train Epoch: 29 [14720/17352 (85%)] Loss: -190370.312500\n",
      "Train Epoch: 29 [14800/17352 (85%)] Loss: -192278.687500\n",
      "Train Epoch: 29 [14880/17352 (86%)] Loss: -206222.359375\n",
      "Train Epoch: 29 [14960/17352 (86%)] Loss: -188075.234375\n",
      "Train Epoch: 29 [15040/17352 (87%)] Loss: -168252.140625\n",
      "Train Epoch: 29 [15120/17352 (87%)] Loss: -193253.468750\n",
      "Train Epoch: 29 [15200/17352 (88%)] Loss: -203131.031250\n",
      "Train Epoch: 29 [15280/17352 (88%)] Loss: -167074.640625\n",
      "Train Epoch: 29 [15360/17352 (89%)] Loss: -191036.796875\n",
      "Train Epoch: 29 [15440/17352 (89%)] Loss: -181664.890625\n",
      "Train Epoch: 29 [15520/17352 (89%)] Loss: -172550.218750\n",
      "Train Epoch: 29 [15600/17352 (90%)] Loss: -193934.843750\n",
      "Train Epoch: 29 [15680/17352 (90%)] Loss: -183445.484375\n",
      "Train Epoch: 29 [15760/17352 (91%)] Loss: -166998.734375\n",
      "Train Epoch: 29 [15840/17352 (91%)] Loss: -175666.406250\n",
      "Train Epoch: 29 [15920/17352 (92%)] Loss: -175744.812500\n",
      "Train Epoch: 29 [16000/17352 (92%)] Loss: -187637.750000\n",
      "Train Epoch: 29 [16080/17352 (93%)] Loss: -164675.671875\n",
      "Train Epoch: 29 [16160/17352 (93%)] Loss: -190804.609375\n",
      "Train Epoch: 29 [16240/17352 (94%)] Loss: -186184.890625\n",
      "Train Epoch: 29 [16320/17352 (94%)] Loss: -200163.250000\n",
      "Train Epoch: 29 [16400/17352 (95%)] Loss: -199506.812500\n",
      "Train Epoch: 29 [16480/17352 (95%)] Loss: -156475.156250\n",
      "Train Epoch: 29 [16560/17352 (95%)] Loss: -167034.000000\n",
      "Train Epoch: 29 [16640/17352 (96%)] Loss: -202078.796875\n",
      "Train Epoch: 29 [16720/17352 (96%)] Loss: -195648.312500\n",
      "Train Epoch: 29 [16800/17352 (97%)] Loss: -211149.843750\n",
      "Train Epoch: 29 [16880/17352 (97%)] Loss: -183063.671875\n",
      "Train Epoch: 29 [16960/17352 (98%)] Loss: -178419.734375\n",
      "Train Epoch: 29 [17040/17352 (98%)] Loss: -174191.968750\n",
      "Train Epoch: 29 [17120/17352 (99%)] Loss: -204343.453125\n",
      "Train Epoch: 29 [17200/17352 (99%)] Loss: -218738.984375\n",
      "Train Epoch: 29 [17280/17352 (100%)] Loss: -176914.140625\n",
      "Train Epoch: 29 [17360/17352 (100%)] Loss: -191801.500000\n",
      "    epoch          : 29\n",
      "    loss           : -189253.17962456847\n",
      "    val_loss       : -23715.25852636776\n",
      "Train Epoch: 30 [0/17352 (0%)] Loss: -210206.812500\n",
      "Train Epoch: 30 [80/17352 (0%)] Loss: -206565.593750\n",
      "Train Epoch: 30 [160/17352 (1%)] Loss: -228006.812500\n",
      "Train Epoch: 30 [240/17352 (1%)] Loss: -230406.062500\n",
      "Train Epoch: 30 [320/17352 (2%)] Loss: -205183.671875\n",
      "Train Epoch: 30 [400/17352 (2%)] Loss: -219665.687500\n",
      "Train Epoch: 30 [480/17352 (3%)] Loss: -204526.062500\n",
      "Train Epoch: 30 [560/17352 (3%)] Loss: -205072.171875\n",
      "Train Epoch: 30 [640/17352 (4%)] Loss: -193405.703125\n",
      "Train Epoch: 30 [720/17352 (4%)] Loss: -207161.531250\n",
      "Train Epoch: 30 [800/17352 (5%)] Loss: -212377.656250\n",
      "Train Epoch: 30 [880/17352 (5%)] Loss: -226095.203125\n",
      "Train Epoch: 30 [960/17352 (6%)] Loss: -196411.390625\n",
      "Train Epoch: 30 [1040/17352 (6%)] Loss: -217623.234375\n",
      "Train Epoch: 30 [1120/17352 (6%)] Loss: -214715.140625\n",
      "Train Epoch: 30 [1200/17352 (7%)] Loss: -213312.062500\n",
      "Train Epoch: 30 [1280/17352 (7%)] Loss: -203738.515625\n",
      "Train Epoch: 30 [1360/17352 (8%)] Loss: -241889.296875\n",
      "Train Epoch: 30 [1440/17352 (8%)] Loss: -224247.781250\n",
      "Train Epoch: 30 [1520/17352 (9%)] Loss: -229230.765625\n",
      "Train Epoch: 30 [1600/17352 (9%)] Loss: -222509.062500\n",
      "Train Epoch: 30 [1680/17352 (10%)] Loss: -210520.468750\n",
      "Train Epoch: 30 [1760/17352 (10%)] Loss: -204395.765625\n",
      "Train Epoch: 30 [1840/17352 (11%)] Loss: -198765.421875\n",
      "Train Epoch: 30 [1920/17352 (11%)] Loss: -229950.062500\n",
      "Train Epoch: 30 [2000/17352 (12%)] Loss: -205555.281250\n",
      "Train Epoch: 30 [2080/17352 (12%)] Loss: -209635.890625\n",
      "Train Epoch: 30 [2160/17352 (12%)] Loss: -206642.765625\n",
      "Train Epoch: 30 [2240/17352 (13%)] Loss: -196288.750000\n",
      "Train Epoch: 30 [2320/17352 (13%)] Loss: -204490.218750\n",
      "Train Epoch: 30 [2400/17352 (14%)] Loss: -189163.078125\n",
      "Train Epoch: 30 [2480/17352 (14%)] Loss: -184939.125000\n",
      "Train Epoch: 30 [2560/17352 (15%)] Loss: -196027.375000\n",
      "Train Epoch: 30 [2640/17352 (15%)] Loss: -185922.765625\n",
      "Train Epoch: 30 [2720/17352 (16%)] Loss: -190913.468750\n",
      "Train Epoch: 30 [2800/17352 (16%)] Loss: -194933.500000\n",
      "Train Epoch: 30 [2880/17352 (17%)] Loss: -173656.562500\n",
      "Train Epoch: 30 [2960/17352 (17%)] Loss: -186151.171875\n",
      "Train Epoch: 30 [3040/17352 (18%)] Loss: -176164.062500\n",
      "Train Epoch: 30 [3120/17352 (18%)] Loss: -192885.578125\n",
      "Train Epoch: 30 [3200/17352 (18%)] Loss: -179380.875000\n",
      "Train Epoch: 30 [3280/17352 (19%)] Loss: -192103.156250\n",
      "Train Epoch: 30 [3360/17352 (19%)] Loss: -210631.750000\n",
      "Train Epoch: 30 [3440/17352 (20%)] Loss: -166992.640625\n",
      "Train Epoch: 30 [3520/17352 (20%)] Loss: -149028.734375\n",
      "Train Epoch: 30 [3600/17352 (21%)] Loss: -179963.250000\n",
      "Train Epoch: 30 [3680/17352 (21%)] Loss: -167180.453125\n",
      "Train Epoch: 30 [3760/17352 (22%)] Loss: -177092.171875\n",
      "Train Epoch: 30 [3840/17352 (22%)] Loss: -222852.734375\n",
      "Train Epoch: 30 [3920/17352 (23%)] Loss: -180236.203125\n",
      "Train Epoch: 30 [4000/17352 (23%)] Loss: -195499.453125\n",
      "Train Epoch: 30 [4080/17352 (24%)] Loss: -157595.734375\n",
      "Train Epoch: 30 [4160/17352 (24%)] Loss: -166547.218750\n",
      "Train Epoch: 30 [4240/17352 (24%)] Loss: -171436.296875\n",
      "Train Epoch: 30 [4320/17352 (25%)] Loss: -177464.625000\n",
      "Train Epoch: 30 [4400/17352 (25%)] Loss: -204338.125000\n",
      "Train Epoch: 30 [4480/17352 (26%)] Loss: -220012.781250\n",
      "Train Epoch: 30 [4560/17352 (26%)] Loss: -202784.093750\n",
      "Train Epoch: 30 [4640/17352 (27%)] Loss: -191225.921875\n",
      "Train Epoch: 30 [4720/17352 (27%)] Loss: -199063.375000\n",
      "Train Epoch: 30 [4800/17352 (28%)] Loss: -192783.078125\n",
      "Train Epoch: 30 [4880/17352 (28%)] Loss: -179432.265625\n",
      "Train Epoch: 30 [4960/17352 (29%)] Loss: -177476.312500\n",
      "Train Epoch: 30 [5040/17352 (29%)] Loss: -159752.781250\n",
      "Train Epoch: 30 [5120/17352 (30%)] Loss: -149332.515625\n",
      "Train Epoch: 30 [5200/17352 (30%)] Loss: -177461.703125\n",
      "Train Epoch: 30 [5280/17352 (30%)] Loss: -180988.437500\n",
      "Train Epoch: 30 [5360/17352 (31%)] Loss: -138331.843750\n",
      "Train Epoch: 30 [5440/17352 (31%)] Loss: -191956.203125\n",
      "Train Epoch: 30 [5520/17352 (32%)] Loss: -166403.953125\n",
      "Train Epoch: 30 [5600/17352 (32%)] Loss: -174935.031250\n",
      "Train Epoch: 30 [5680/17352 (33%)] Loss: -147410.656250\n",
      "Train Epoch: 30 [5760/17352 (33%)] Loss: -177615.906250\n",
      "Train Epoch: 30 [5840/17352 (34%)] Loss: -158602.375000\n",
      "Train Epoch: 30 [5920/17352 (34%)] Loss: -191362.968750\n",
      "Train Epoch: 30 [6000/17352 (35%)] Loss: -162727.562500\n",
      "Train Epoch: 30 [6080/17352 (35%)] Loss: -200629.562500\n",
      "Train Epoch: 30 [6160/17352 (36%)] Loss: -208893.921875\n",
      "Train Epoch: 30 [6240/17352 (36%)] Loss: -153881.578125\n",
      "Train Epoch: 30 [6320/17352 (36%)] Loss: -206356.890625\n",
      "Train Epoch: 30 [6400/17352 (37%)] Loss: -185772.359375\n",
      "Train Epoch: 30 [6480/17352 (37%)] Loss: -191999.203125\n",
      "Train Epoch: 30 [6560/17352 (38%)] Loss: -183274.187500\n",
      "Train Epoch: 30 [6640/17352 (38%)] Loss: -197594.046875\n",
      "Train Epoch: 30 [6720/17352 (39%)] Loss: -183573.281250\n",
      "Train Epoch: 30 [6800/17352 (39%)] Loss: -167864.546875\n",
      "Train Epoch: 30 [6880/17352 (40%)] Loss: -185310.468750\n",
      "Train Epoch: 30 [6960/17352 (40%)] Loss: -181364.250000\n",
      "Train Epoch: 30 [7040/17352 (41%)] Loss: -171715.468750\n",
      "Train Epoch: 30 [7120/17352 (41%)] Loss: -171415.859375\n",
      "Train Epoch: 30 [7200/17352 (41%)] Loss: -187722.218750\n",
      "Train Epoch: 30 [7280/17352 (42%)] Loss: -169613.031250\n",
      "Train Epoch: 30 [7360/17352 (42%)] Loss: -177232.546875\n",
      "Train Epoch: 30 [7440/17352 (43%)] Loss: -202844.078125\n",
      "Train Epoch: 30 [7520/17352 (43%)] Loss: -198790.843750\n",
      "Train Epoch: 30 [7600/17352 (44%)] Loss: -186723.640625\n",
      "Train Epoch: 30 [7680/17352 (44%)] Loss: -161091.406250\n",
      "Train Epoch: 30 [7760/17352 (45%)] Loss: -178190.593750\n",
      "Train Epoch: 30 [7840/17352 (45%)] Loss: -142612.437500\n",
      "Train Epoch: 30 [7920/17352 (46%)] Loss: -201815.703125\n",
      "Train Epoch: 30 [8000/17352 (46%)] Loss: -180960.796875\n",
      "Train Epoch: 30 [8080/17352 (47%)] Loss: -180163.296875\n",
      "Train Epoch: 30 [8160/17352 (47%)] Loss: -196570.562500\n",
      "Train Epoch: 30 [8240/17352 (47%)] Loss: -192632.234375\n",
      "Train Epoch: 30 [8320/17352 (48%)] Loss: -187238.140625\n",
      "Train Epoch: 30 [8400/17352 (48%)] Loss: -186600.640625\n",
      "Train Epoch: 30 [8480/17352 (49%)] Loss: -196727.984375\n",
      "Train Epoch: 30 [8560/17352 (49%)] Loss: -183381.546875\n",
      "Train Epoch: 30 [8640/17352 (50%)] Loss: -168998.875000\n",
      "Train Epoch: 30 [8720/17352 (50%)] Loss: -199592.078125\n",
      "Train Epoch: 30 [8800/17352 (51%)] Loss: -184496.781250\n",
      "Train Epoch: 30 [8880/17352 (51%)] Loss: -181613.968750\n",
      "Train Epoch: 30 [8960/17352 (52%)] Loss: -205510.781250\n",
      "Train Epoch: 30 [9040/17352 (52%)] Loss: -173913.343750\n",
      "Train Epoch: 30 [9120/17352 (53%)] Loss: -204664.546875\n",
      "Train Epoch: 30 [9200/17352 (53%)] Loss: -183791.875000\n",
      "Train Epoch: 30 [9280/17352 (53%)] Loss: -161958.953125\n",
      "Train Epoch: 30 [9360/17352 (54%)] Loss: -176916.500000\n",
      "Train Epoch: 30 [9440/17352 (54%)] Loss: -208418.140625\n",
      "Train Epoch: 30 [9520/17352 (55%)] Loss: -169184.593750\n",
      "Train Epoch: 30 [9600/17352 (55%)] Loss: -164814.531250\n",
      "Train Epoch: 30 [9680/17352 (56%)] Loss: -190986.765625\n",
      "Train Epoch: 30 [9760/17352 (56%)] Loss: -170785.640625\n",
      "Train Epoch: 30 [9840/17352 (57%)] Loss: -200267.171875\n",
      "Train Epoch: 30 [9920/17352 (57%)] Loss: -200396.343750\n",
      "Train Epoch: 30 [10000/17352 (58%)] Loss: -196933.203125\n",
      "Train Epoch: 30 [10080/17352 (58%)] Loss: -182531.750000\n",
      "Train Epoch: 30 [10160/17352 (59%)] Loss: -183779.187500\n",
      "Train Epoch: 30 [10240/17352 (59%)] Loss: -184910.968750\n",
      "Train Epoch: 30 [10320/17352 (59%)] Loss: -187771.093750\n",
      "Train Epoch: 30 [10400/17352 (60%)] Loss: -176079.562500\n",
      "Train Epoch: 30 [10480/17352 (60%)] Loss: -188886.953125\n",
      "Train Epoch: 30 [10560/17352 (61%)] Loss: -210549.250000\n",
      "Train Epoch: 30 [10640/17352 (61%)] Loss: -184842.671875\n",
      "Train Epoch: 30 [10720/17352 (62%)] Loss: -178131.750000\n",
      "Train Epoch: 30 [10800/17352 (62%)] Loss: -174480.375000\n",
      "Train Epoch: 30 [10880/17352 (63%)] Loss: -179914.640625\n",
      "Train Epoch: 30 [10960/17352 (63%)] Loss: -192357.109375\n",
      "Train Epoch: 30 [11040/17352 (64%)] Loss: -184454.312500\n",
      "Train Epoch: 30 [11120/17352 (64%)] Loss: -167946.171875\n",
      "Train Epoch: 30 [11200/17352 (65%)] Loss: -193803.437500\n",
      "Train Epoch: 30 [11280/17352 (65%)] Loss: -179490.359375\n",
      "Train Epoch: 30 [11360/17352 (65%)] Loss: -184059.453125\n",
      "Train Epoch: 30 [11440/17352 (66%)] Loss: -191589.562500\n",
      "Train Epoch: 30 [11520/17352 (66%)] Loss: -192263.718750\n",
      "Train Epoch: 30 [11600/17352 (67%)] Loss: -223686.328125\n",
      "Train Epoch: 30 [11680/17352 (67%)] Loss: -188427.828125\n",
      "Train Epoch: 30 [11760/17352 (68%)] Loss: -167801.968750\n",
      "Train Epoch: 30 [11840/17352 (68%)] Loss: -192102.937500\n",
      "Train Epoch: 30 [11920/17352 (69%)] Loss: -182562.984375\n",
      "Train Epoch: 30 [12000/17352 (69%)] Loss: -165800.796875\n",
      "Train Epoch: 30 [12080/17352 (70%)] Loss: -217596.265625\n",
      "Train Epoch: 30 [12160/17352 (70%)] Loss: -206221.546875\n",
      "Train Epoch: 30 [12240/17352 (71%)] Loss: -221253.046875\n",
      "Train Epoch: 30 [12320/17352 (71%)] Loss: -194051.937500\n",
      "Train Epoch: 30 [12400/17352 (71%)] Loss: -164078.031250\n",
      "Train Epoch: 30 [12480/17352 (72%)] Loss: -183460.281250\n",
      "Train Epoch: 30 [12560/17352 (72%)] Loss: -218838.234375\n",
      "Train Epoch: 30 [12640/17352 (73%)] Loss: -193529.062500\n",
      "Train Epoch: 30 [12720/17352 (73%)] Loss: -191554.500000\n",
      "Train Epoch: 30 [12800/17352 (74%)] Loss: -176264.281250\n",
      "Train Epoch: 30 [12880/17352 (74%)] Loss: -181334.109375\n",
      "Train Epoch: 30 [12960/17352 (75%)] Loss: -189214.046875\n",
      "Train Epoch: 30 [13040/17352 (75%)] Loss: -180746.578125\n",
      "Train Epoch: 30 [13120/17352 (76%)] Loss: -164803.281250\n",
      "Train Epoch: 30 [13200/17352 (76%)] Loss: -218750.828125\n",
      "Train Epoch: 30 [13280/17352 (77%)] Loss: -210384.937500\n",
      "Train Epoch: 30 [13360/17352 (77%)] Loss: -208035.812500\n",
      "Train Epoch: 30 [13440/17352 (77%)] Loss: -179304.953125\n",
      "Train Epoch: 30 [13520/17352 (78%)] Loss: -196810.250000\n",
      "Train Epoch: 30 [13600/17352 (78%)] Loss: -185502.906250\n",
      "Train Epoch: 30 [13680/17352 (79%)] Loss: -204331.062500\n",
      "Train Epoch: 30 [13760/17352 (79%)] Loss: -187266.406250\n",
      "Train Epoch: 30 [13840/17352 (80%)] Loss: -154603.812500\n",
      "Train Epoch: 30 [13920/17352 (80%)] Loss: -206155.937500\n",
      "Train Epoch: 30 [14000/17352 (81%)] Loss: -212128.703125\n",
      "Train Epoch: 30 [14080/17352 (81%)] Loss: -184476.968750\n",
      "Train Epoch: 30 [14160/17352 (82%)] Loss: -157489.562500\n",
      "Train Epoch: 30 [14240/17352 (82%)] Loss: -200992.187500\n",
      "Train Epoch: 30 [14320/17352 (83%)] Loss: -164872.781250\n",
      "Train Epoch: 30 [14400/17352 (83%)] Loss: -171724.359375\n",
      "Train Epoch: 30 [14480/17352 (83%)] Loss: -188497.390625\n",
      "Train Epoch: 30 [14560/17352 (84%)] Loss: -195050.687500\n",
      "Train Epoch: 30 [14640/17352 (84%)] Loss: -188498.640625\n",
      "Train Epoch: 30 [14720/17352 (85%)] Loss: -209190.171875\n",
      "Train Epoch: 30 [14800/17352 (85%)] Loss: -197532.484375\n",
      "Train Epoch: 30 [14880/17352 (86%)] Loss: -181670.750000\n",
      "Train Epoch: 30 [14960/17352 (86%)] Loss: -203865.718750\n",
      "Train Epoch: 30 [15040/17352 (87%)] Loss: -190501.546875\n",
      "Train Epoch: 30 [15120/17352 (87%)] Loss: -201926.515625\n",
      "Train Epoch: 30 [15200/17352 (88%)] Loss: -179430.125000\n",
      "Train Epoch: 30 [15280/17352 (88%)] Loss: -177187.109375\n",
      "Train Epoch: 30 [15360/17352 (89%)] Loss: -165760.921875\n",
      "Train Epoch: 30 [15440/17352 (89%)] Loss: -191831.390625\n",
      "Train Epoch: 30 [15520/17352 (89%)] Loss: -177577.859375\n",
      "Train Epoch: 30 [15600/17352 (90%)] Loss: -165345.765625\n",
      "Train Epoch: 30 [15680/17352 (90%)] Loss: -194222.125000\n",
      "Train Epoch: 30 [15760/17352 (91%)] Loss: -183082.484375\n",
      "Train Epoch: 30 [15840/17352 (91%)] Loss: -203130.375000\n",
      "Train Epoch: 30 [15920/17352 (92%)] Loss: -213743.718750\n",
      "Train Epoch: 30 [16000/17352 (92%)] Loss: -200870.937500\n",
      "Train Epoch: 30 [16080/17352 (93%)] Loss: -163205.859375\n",
      "Train Epoch: 30 [16160/17352 (93%)] Loss: -191153.312500\n",
      "Train Epoch: 30 [16240/17352 (94%)] Loss: -180868.312500\n",
      "Train Epoch: 30 [16320/17352 (94%)] Loss: -192266.453125\n",
      "Train Epoch: 30 [16400/17352 (95%)] Loss: -181537.343750\n",
      "Train Epoch: 30 [16480/17352 (95%)] Loss: -171533.718750\n",
      "Train Epoch: 30 [16560/17352 (95%)] Loss: -199505.890625\n",
      "Train Epoch: 30 [16640/17352 (96%)] Loss: -193504.046875\n",
      "Train Epoch: 30 [16720/17352 (96%)] Loss: -210252.593750\n",
      "Train Epoch: 30 [16800/17352 (97%)] Loss: -195827.796875\n",
      "Train Epoch: 30 [16880/17352 (97%)] Loss: -187353.437500\n",
      "Train Epoch: 30 [16960/17352 (98%)] Loss: -189500.843750\n",
      "Train Epoch: 30 [17040/17352 (98%)] Loss: -187447.718750\n",
      "Train Epoch: 30 [17120/17352 (99%)] Loss: -174038.125000\n",
      "Train Epoch: 30 [17200/17352 (99%)] Loss: -170677.703125\n",
      "Train Epoch: 30 [17280/17352 (100%)] Loss: -192177.500000\n",
      "Train Epoch: 30 [17360/17352 (100%)] Loss: -187591.953125\n",
      "    epoch          : 30\n",
      "    loss           : -189268.55750143842\n",
      "    val_loss       : -23715.174701099666\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch30.pth ...\n",
      "Train Epoch: 31 [0/17352 (0%)] Loss: -214701.062500\n",
      "Train Epoch: 31 [80/17352 (0%)] Loss: -229955.453125\n",
      "Train Epoch: 31 [160/17352 (1%)] Loss: -217585.062500\n",
      "Train Epoch: 31 [240/17352 (1%)] Loss: -193701.468750\n",
      "Train Epoch: 31 [320/17352 (2%)] Loss: -217929.265625\n",
      "Train Epoch: 31 [400/17352 (2%)] Loss: -212655.375000\n",
      "Train Epoch: 31 [480/17352 (3%)] Loss: -206552.546875\n",
      "Train Epoch: 31 [560/17352 (3%)] Loss: -204729.546875\n",
      "Train Epoch: 31 [640/17352 (4%)] Loss: -198757.375000\n",
      "Train Epoch: 31 [720/17352 (4%)] Loss: -200597.718750\n",
      "Train Epoch: 31 [800/17352 (5%)] Loss: -208380.750000\n",
      "Train Epoch: 31 [880/17352 (5%)] Loss: -202304.093750\n",
      "Train Epoch: 31 [960/17352 (6%)] Loss: -236625.968750\n",
      "Train Epoch: 31 [1040/17352 (6%)] Loss: -182772.062500\n",
      "Train Epoch: 31 [1120/17352 (6%)] Loss: -202254.625000\n",
      "Train Epoch: 31 [1200/17352 (7%)] Loss: -199892.343750\n",
      "Train Epoch: 31 [1280/17352 (7%)] Loss: -205072.203125\n",
      "Train Epoch: 31 [1360/17352 (8%)] Loss: -228008.296875\n",
      "Train Epoch: 31 [1440/17352 (8%)] Loss: -210340.031250\n",
      "Train Epoch: 31 [1520/17352 (9%)] Loss: -210202.796875\n",
      "Train Epoch: 31 [1600/17352 (9%)] Loss: -212246.500000\n",
      "Train Epoch: 31 [1680/17352 (10%)] Loss: -218555.875000\n",
      "Train Epoch: 31 [1760/17352 (10%)] Loss: -224238.281250\n",
      "Train Epoch: 31 [1840/17352 (11%)] Loss: -209766.296875\n",
      "Train Epoch: 31 [1920/17352 (11%)] Loss: -194292.937500\n",
      "Train Epoch: 31 [2000/17352 (12%)] Loss: -205215.015625\n",
      "Train Epoch: 31 [2080/17352 (12%)] Loss: -236830.484375\n",
      "Train Epoch: 31 [2160/17352 (12%)] Loss: -205910.093750\n",
      "Train Epoch: 31 [2240/17352 (13%)] Loss: -181544.265625\n",
      "Train Epoch: 31 [2320/17352 (13%)] Loss: -203666.203125\n",
      "Train Epoch: 31 [2400/17352 (14%)] Loss: -177271.750000\n",
      "Train Epoch: 31 [2480/17352 (14%)] Loss: -177569.343750\n",
      "Train Epoch: 31 [2560/17352 (15%)] Loss: -202014.234375\n",
      "Train Epoch: 31 [2640/17352 (15%)] Loss: -170681.281250\n",
      "Train Epoch: 31 [2720/17352 (16%)] Loss: -166431.625000\n",
      "Train Epoch: 31 [2800/17352 (16%)] Loss: -192242.640625\n",
      "Train Epoch: 31 [2880/17352 (17%)] Loss: -167864.531250\n",
      "Train Epoch: 31 [2960/17352 (17%)] Loss: -178869.843750\n",
      "Train Epoch: 31 [3040/17352 (18%)] Loss: -168065.515625\n",
      "Train Epoch: 31 [3120/17352 (18%)] Loss: -179472.718750\n",
      "Train Epoch: 31 [3200/17352 (18%)] Loss: -219908.156250\n",
      "Train Epoch: 31 [3280/17352 (19%)] Loss: -159690.625000\n",
      "Train Epoch: 31 [3360/17352 (19%)] Loss: -183706.031250\n",
      "Train Epoch: 31 [3440/17352 (20%)] Loss: -145998.937500\n",
      "Train Epoch: 31 [3520/17352 (20%)] Loss: -155861.031250\n",
      "Train Epoch: 31 [3600/17352 (21%)] Loss: -174539.796875\n",
      "Train Epoch: 31 [3680/17352 (21%)] Loss: -167286.968750\n",
      "Train Epoch: 31 [3760/17352 (22%)] Loss: -223959.296875\n",
      "Train Epoch: 31 [3840/17352 (22%)] Loss: -164987.312500\n",
      "Train Epoch: 31 [3920/17352 (23%)] Loss: -205513.562500\n",
      "Train Epoch: 31 [4000/17352 (23%)] Loss: -156609.656250\n",
      "Train Epoch: 31 [4080/17352 (24%)] Loss: -158244.578125\n",
      "Train Epoch: 31 [4160/17352 (24%)] Loss: -196728.437500\n",
      "Train Epoch: 31 [4240/17352 (24%)] Loss: -193118.703125\n",
      "Train Epoch: 31 [4320/17352 (25%)] Loss: -181161.656250\n",
      "Train Epoch: 31 [4400/17352 (25%)] Loss: -167182.468750\n",
      "Train Epoch: 31 [4480/17352 (26%)] Loss: -212975.875000\n",
      "Train Epoch: 31 [4560/17352 (26%)] Loss: -164947.953125\n",
      "Train Epoch: 31 [4640/17352 (27%)] Loss: -183049.156250\n",
      "Train Epoch: 31 [4720/17352 (27%)] Loss: -179451.187500\n",
      "Train Epoch: 31 [4800/17352 (28%)] Loss: -203744.062500\n",
      "Train Epoch: 31 [4880/17352 (28%)] Loss: -173027.812500\n",
      "Train Epoch: 31 [4960/17352 (29%)] Loss: -176484.031250\n",
      "Train Epoch: 31 [5040/17352 (29%)] Loss: -185789.609375\n",
      "Train Epoch: 31 [5120/17352 (30%)] Loss: -200268.390625\n",
      "Train Epoch: 31 [5200/17352 (30%)] Loss: -134535.968750\n",
      "Train Epoch: 31 [5280/17352 (30%)] Loss: -184945.796875\n",
      "Train Epoch: 31 [5360/17352 (31%)] Loss: -189719.593750\n",
      "Train Epoch: 31 [5440/17352 (31%)] Loss: -190371.671875\n",
      "Train Epoch: 31 [5520/17352 (32%)] Loss: -208755.000000\n",
      "Train Epoch: 31 [5600/17352 (32%)] Loss: -166406.937500\n",
      "Train Epoch: 31 [5680/17352 (33%)] Loss: -194940.421875\n",
      "Train Epoch: 31 [5760/17352 (33%)] Loss: -173566.421875\n",
      "Train Epoch: 31 [5840/17352 (34%)] Loss: -212612.875000\n",
      "Train Epoch: 31 [5920/17352 (34%)] Loss: -193055.062500\n",
      "Train Epoch: 31 [6000/17352 (35%)] Loss: -191881.093750\n",
      "Train Epoch: 31 [6080/17352 (35%)] Loss: -198013.593750\n",
      "Train Epoch: 31 [6160/17352 (36%)] Loss: -180234.593750\n",
      "Train Epoch: 31 [6240/17352 (36%)] Loss: -164873.218750\n",
      "Train Epoch: 31 [6320/17352 (36%)] Loss: -173301.968750\n",
      "Train Epoch: 31 [6400/17352 (37%)] Loss: -191790.750000\n",
      "Train Epoch: 31 [6480/17352 (37%)] Loss: -194998.578125\n",
      "Train Epoch: 31 [6560/17352 (38%)] Loss: -193527.750000\n",
      "Train Epoch: 31 [6640/17352 (38%)] Loss: -187319.093750\n",
      "Train Epoch: 31 [6720/17352 (39%)] Loss: -181946.437500\n",
      "Train Epoch: 31 [6800/17352 (39%)] Loss: -184268.625000\n",
      "Train Epoch: 31 [6880/17352 (40%)] Loss: -218508.125000\n",
      "Train Epoch: 31 [6960/17352 (40%)] Loss: -181969.562500\n",
      "Train Epoch: 31 [7040/17352 (41%)] Loss: -205641.437500\n",
      "Train Epoch: 31 [7120/17352 (41%)] Loss: -191033.187500\n",
      "Train Epoch: 31 [7200/17352 (41%)] Loss: -189212.343750\n",
      "Train Epoch: 31 [7280/17352 (42%)] Loss: -160148.921875\n",
      "Train Epoch: 31 [7360/17352 (42%)] Loss: -194603.750000\n",
      "Train Epoch: 31 [7440/17352 (43%)] Loss: -184251.500000\n",
      "Train Epoch: 31 [7520/17352 (43%)] Loss: -156467.000000\n",
      "Train Epoch: 31 [7600/17352 (44%)] Loss: -216378.781250\n",
      "Train Epoch: 31 [7680/17352 (44%)] Loss: -213238.484375\n",
      "Train Epoch: 31 [7760/17352 (45%)] Loss: -185361.453125\n",
      "Train Epoch: 31 [7840/17352 (45%)] Loss: -183222.125000\n",
      "Train Epoch: 31 [7920/17352 (46%)] Loss: -203869.968750\n",
      "Train Epoch: 31 [8000/17352 (46%)] Loss: -202234.921875\n",
      "Train Epoch: 31 [8080/17352 (47%)] Loss: -198537.406250\n",
      "Train Epoch: 31 [8160/17352 (47%)] Loss: -204944.390625\n",
      "Train Epoch: 31 [8240/17352 (47%)] Loss: -175075.593750\n",
      "Train Epoch: 31 [8320/17352 (48%)] Loss: -202851.109375\n",
      "Train Epoch: 31 [8400/17352 (48%)] Loss: -175529.234375\n",
      "Train Epoch: 31 [8480/17352 (49%)] Loss: -186037.125000\n",
      "Train Epoch: 31 [8560/17352 (49%)] Loss: -194945.015625\n",
      "Train Epoch: 31 [8640/17352 (50%)] Loss: -200400.531250\n",
      "Train Epoch: 31 [8720/17352 (50%)] Loss: -210480.687500\n",
      "Train Epoch: 31 [8800/17352 (51%)] Loss: -199445.968750\n",
      "Train Epoch: 31 [8880/17352 (51%)] Loss: -174929.578125\n",
      "Train Epoch: 31 [8960/17352 (52%)] Loss: -204586.421875\n",
      "Train Epoch: 31 [9040/17352 (52%)] Loss: -151499.171875\n",
      "Train Epoch: 31 [9120/17352 (53%)] Loss: -183776.046875\n",
      "Train Epoch: 31 [9200/17352 (53%)] Loss: -171711.109375\n",
      "Train Epoch: 31 [9280/17352 (53%)] Loss: -192003.125000\n",
      "Train Epoch: 31 [9360/17352 (54%)] Loss: -193493.890625\n",
      "Train Epoch: 31 [9440/17352 (54%)] Loss: -166252.156250\n",
      "Train Epoch: 31 [9520/17352 (55%)] Loss: -189247.718750\n",
      "Train Epoch: 31 [9600/17352 (55%)] Loss: -195878.781250\n",
      "Train Epoch: 31 [9680/17352 (56%)] Loss: -168076.890625\n",
      "Train Epoch: 31 [9760/17352 (56%)] Loss: -206086.906250\n",
      "Train Epoch: 31 [9840/17352 (57%)] Loss: -146845.078125\n",
      "Train Epoch: 31 [9920/17352 (57%)] Loss: -185358.703125\n",
      "Train Epoch: 31 [10000/17352 (58%)] Loss: -198802.015625\n",
      "Train Epoch: 31 [10080/17352 (58%)] Loss: -184735.875000\n",
      "Train Epoch: 31 [10160/17352 (59%)] Loss: -149439.531250\n",
      "Train Epoch: 31 [10240/17352 (59%)] Loss: -159084.390625\n",
      "Train Epoch: 31 [10320/17352 (59%)] Loss: -176669.515625\n",
      "Train Epoch: 31 [10400/17352 (60%)] Loss: -174178.718750\n",
      "Train Epoch: 31 [10480/17352 (60%)] Loss: -205487.375000\n",
      "Train Epoch: 31 [10560/17352 (61%)] Loss: -199783.156250\n",
      "Train Epoch: 31 [10640/17352 (61%)] Loss: -176695.453125\n",
      "Train Epoch: 31 [10720/17352 (62%)] Loss: -203816.687500\n",
      "Train Epoch: 31 [10800/17352 (62%)] Loss: -166548.250000\n",
      "Train Epoch: 31 [10880/17352 (63%)] Loss: -153315.125000\n",
      "Train Epoch: 31 [10960/17352 (63%)] Loss: -195051.828125\n",
      "Train Epoch: 31 [11040/17352 (64%)] Loss: -171731.171875\n",
      "Train Epoch: 31 [11120/17352 (64%)] Loss: -200126.828125\n",
      "Train Epoch: 31 [11200/17352 (65%)] Loss: -176138.250000\n",
      "Train Epoch: 31 [11280/17352 (65%)] Loss: -186683.687500\n",
      "Train Epoch: 31 [11360/17352 (65%)] Loss: -187239.843750\n",
      "Train Epoch: 31 [11440/17352 (66%)] Loss: -187324.640625\n",
      "Train Epoch: 31 [11520/17352 (66%)] Loss: -217596.828125\n",
      "Train Epoch: 31 [11600/17352 (67%)] Loss: -148816.687500\n",
      "Train Epoch: 31 [11680/17352 (67%)] Loss: -218459.187500\n",
      "Train Epoch: 31 [11760/17352 (68%)] Loss: -209812.390625\n",
      "Train Epoch: 31 [11840/17352 (68%)] Loss: -183621.343750\n",
      "Train Epoch: 31 [11920/17352 (69%)] Loss: -175684.875000\n",
      "Train Epoch: 31 [12000/17352 (69%)] Loss: -168053.187500\n",
      "Train Epoch: 31 [12080/17352 (70%)] Loss: -196021.062500\n",
      "Train Epoch: 31 [12160/17352 (70%)] Loss: -180050.500000\n",
      "Train Epoch: 31 [12240/17352 (71%)] Loss: -187398.343750\n",
      "Train Epoch: 31 [12320/17352 (71%)] Loss: -179164.125000\n",
      "Train Epoch: 31 [12400/17352 (71%)] Loss: -180634.656250\n",
      "Train Epoch: 31 [12480/17352 (72%)] Loss: -201118.390625\n",
      "Train Epoch: 31 [12560/17352 (72%)] Loss: -199895.078125\n",
      "Train Epoch: 31 [12640/17352 (73%)] Loss: -177298.250000\n",
      "Train Epoch: 31 [12720/17352 (73%)] Loss: -192380.343750\n",
      "Train Epoch: 31 [12800/17352 (74%)] Loss: -192945.187500\n",
      "Train Epoch: 31 [12880/17352 (74%)] Loss: -191719.140625\n",
      "Train Epoch: 31 [12960/17352 (75%)] Loss: -159668.218750\n",
      "Train Epoch: 31 [13040/17352 (75%)] Loss: -170239.218750\n",
      "Train Epoch: 31 [13120/17352 (76%)] Loss: -223679.937500\n",
      "Train Epoch: 31 [13200/17352 (76%)] Loss: -194574.312500\n",
      "Train Epoch: 31 [13280/17352 (77%)] Loss: -163487.484375\n",
      "Train Epoch: 31 [13360/17352 (77%)] Loss: -200630.312500\n",
      "Train Epoch: 31 [13440/17352 (77%)] Loss: -181914.375000\n",
      "Train Epoch: 31 [13520/17352 (78%)] Loss: -165999.312500\n",
      "Train Epoch: 31 [13600/17352 (78%)] Loss: -218402.875000\n",
      "Train Epoch: 31 [13680/17352 (79%)] Loss: -177300.281250\n",
      "Train Epoch: 31 [13760/17352 (79%)] Loss: -208015.453125\n",
      "Train Epoch: 31 [13840/17352 (80%)] Loss: -205166.593750\n",
      "Train Epoch: 31 [13920/17352 (80%)] Loss: -186602.234375\n",
      "Train Epoch: 31 [14000/17352 (81%)] Loss: -164368.375000\n",
      "Train Epoch: 31 [14080/17352 (81%)] Loss: -202176.343750\n",
      "Train Epoch: 31 [14160/17352 (82%)] Loss: -180027.328125\n",
      "Train Epoch: 31 [14240/17352 (82%)] Loss: -179960.375000\n",
      "Train Epoch: 31 [14320/17352 (83%)] Loss: -180791.468750\n",
      "Train Epoch: 31 [14400/17352 (83%)] Loss: -148501.968750\n",
      "Train Epoch: 31 [14480/17352 (83%)] Loss: -190991.046875\n",
      "Train Epoch: 31 [14560/17352 (84%)] Loss: -212648.734375\n",
      "Train Epoch: 31 [14640/17352 (84%)] Loss: -193357.234375\n",
      "Train Epoch: 31 [14720/17352 (85%)] Loss: -166786.375000\n",
      "Train Epoch: 31 [14800/17352 (85%)] Loss: -175355.062500\n",
      "Train Epoch: 31 [14880/17352 (86%)] Loss: -157476.359375\n",
      "Train Epoch: 31 [14960/17352 (86%)] Loss: -158741.953125\n",
      "Train Epoch: 31 [15040/17352 (87%)] Loss: -208032.828125\n",
      "Train Epoch: 31 [15120/17352 (87%)] Loss: -228086.531250\n",
      "Train Epoch: 31 [15200/17352 (88%)] Loss: -181694.859375\n",
      "Train Epoch: 31 [15280/17352 (88%)] Loss: -210633.390625\n",
      "Train Epoch: 31 [15360/17352 (89%)] Loss: -192391.921875\n",
      "Train Epoch: 31 [15440/17352 (89%)] Loss: -184828.812500\n",
      "Train Epoch: 31 [15520/17352 (89%)] Loss: -193786.078125\n",
      "Train Epoch: 31 [15600/17352 (90%)] Loss: -179886.031250\n",
      "Train Epoch: 31 [15680/17352 (90%)] Loss: -167029.625000\n",
      "Train Epoch: 31 [15760/17352 (91%)] Loss: -197096.156250\n",
      "Train Epoch: 31 [15840/17352 (91%)] Loss: -211092.562500\n",
      "Train Epoch: 31 [15920/17352 (92%)] Loss: -178560.187500\n",
      "Train Epoch: 31 [16000/17352 (92%)] Loss: -181750.796875\n",
      "Train Epoch: 31 [16080/17352 (93%)] Loss: -163245.187500\n",
      "Train Epoch: 31 [16160/17352 (93%)] Loss: -203430.437500\n",
      "Train Epoch: 31 [16240/17352 (94%)] Loss: -183916.968750\n",
      "Train Epoch: 31 [16320/17352 (94%)] Loss: -142616.828125\n",
      "Train Epoch: 31 [16400/17352 (95%)] Loss: -167871.234375\n",
      "Train Epoch: 31 [16480/17352 (95%)] Loss: -191965.343750\n",
      "Train Epoch: 31 [16560/17352 (95%)] Loss: -197337.812500\n",
      "Train Epoch: 31 [16640/17352 (96%)] Loss: -180527.906250\n",
      "Train Epoch: 31 [16720/17352 (96%)] Loss: -178624.859375\n",
      "Train Epoch: 31 [16800/17352 (97%)] Loss: -185263.562500\n",
      "Train Epoch: 31 [16880/17352 (97%)] Loss: -194044.953125\n",
      "Train Epoch: 31 [16960/17352 (98%)] Loss: -225309.718750\n",
      "Train Epoch: 31 [17040/17352 (98%)] Loss: -161957.000000\n",
      "Train Epoch: 31 [17120/17352 (99%)] Loss: -183157.640625\n",
      "Train Epoch: 31 [17200/17352 (99%)] Loss: -192121.859375\n",
      "Train Epoch: 31 [17280/17352 (100%)] Loss: -172233.531250\n",
      "Train Epoch: 31 [17360/17352 (100%)] Loss: -200414.218750\n",
      "    epoch          : 31\n",
      "    loss           : -189315.29033012083\n",
      "    val_loss       : -23715.239917808856\n",
      "Train Epoch: 32 [0/17352 (0%)] Loss: -230179.125000\n",
      "Train Epoch: 32 [80/17352 (0%)] Loss: -200596.140625\n",
      "Train Epoch: 32 [160/17352 (1%)] Loss: -201651.562500\n",
      "Train Epoch: 32 [240/17352 (1%)] Loss: -203260.312500\n",
      "Train Epoch: 32 [320/17352 (2%)] Loss: -218531.390625\n",
      "Train Epoch: 32 [400/17352 (2%)] Loss: -208377.812500\n",
      "Train Epoch: 32 [480/17352 (3%)] Loss: -212368.781250\n",
      "Train Epoch: 32 [560/17352 (3%)] Loss: -213321.546875\n",
      "Train Epoch: 32 [640/17352 (4%)] Loss: -186063.171875\n",
      "Train Epoch: 32 [720/17352 (4%)] Loss: -233741.984375\n",
      "Train Epoch: 32 [800/17352 (5%)] Loss: -204039.656250\n",
      "Train Epoch: 32 [880/17352 (5%)] Loss: -202222.968750\n",
      "Train Epoch: 32 [960/17352 (6%)] Loss: -199542.093750\n",
      "Train Epoch: 32 [1040/17352 (6%)] Loss: -205209.734375\n",
      "Train Epoch: 32 [1120/17352 (6%)] Loss: -187711.609375\n",
      "Train Epoch: 32 [1200/17352 (7%)] Loss: -193019.687500\n",
      "Train Epoch: 32 [1280/17352 (7%)] Loss: -212386.796875\n",
      "Train Epoch: 32 [1360/17352 (8%)] Loss: -215093.109375\n",
      "Train Epoch: 32 [1440/17352 (8%)] Loss: -214337.203125\n",
      "Train Epoch: 32 [1520/17352 (9%)] Loss: -202314.000000\n",
      "Train Epoch: 32 [1600/17352 (9%)] Loss: -210618.750000\n",
      "Train Epoch: 32 [1680/17352 (10%)] Loss: -213338.140625\n",
      "Train Epoch: 32 [1760/17352 (10%)] Loss: -207155.218750\n",
      "Train Epoch: 32 [1840/17352 (11%)] Loss: -205913.437500\n",
      "Train Epoch: 32 [1920/17352 (11%)] Loss: -224244.546875\n",
      "Train Epoch: 32 [2000/17352 (12%)] Loss: -198106.265625\n",
      "Train Epoch: 32 [2080/17352 (12%)] Loss: -210339.515625\n",
      "Train Epoch: 32 [2160/17352 (12%)] Loss: -210744.062500\n",
      "Train Epoch: 32 [2240/17352 (13%)] Loss: -185171.906250\n",
      "Train Epoch: 32 [2320/17352 (13%)] Loss: -184248.718750\n",
      "Train Epoch: 32 [2400/17352 (14%)] Loss: -186513.078125\n",
      "Train Epoch: 32 [2480/17352 (14%)] Loss: -181328.125000\n",
      "Train Epoch: 32 [2560/17352 (15%)] Loss: -182321.812500\n",
      "Train Epoch: 32 [2640/17352 (15%)] Loss: -176291.218750\n",
      "Train Epoch: 32 [2720/17352 (16%)] Loss: -180532.781250\n",
      "Train Epoch: 32 [2800/17352 (16%)] Loss: -203138.859375\n",
      "Train Epoch: 32 [2880/17352 (17%)] Loss: -191828.546875\n",
      "Train Epoch: 32 [2960/17352 (17%)] Loss: -151504.687500\n",
      "Train Epoch: 32 [3040/17352 (18%)] Loss: -186042.531250\n",
      "Train Epoch: 32 [3120/17352 (18%)] Loss: -164366.968750\n",
      "Train Epoch: 32 [3200/17352 (18%)] Loss: -171839.796875\n",
      "Train Epoch: 32 [3280/17352 (19%)] Loss: -208007.734375\n",
      "Train Epoch: 32 [3360/17352 (19%)] Loss: -187308.250000\n",
      "Train Epoch: 32 [3440/17352 (20%)] Loss: -184475.687500\n",
      "Train Epoch: 32 [3520/17352 (20%)] Loss: -174711.750000\n",
      "Train Epoch: 32 [3600/17352 (21%)] Loss: -169173.812500\n",
      "Train Epoch: 32 [3680/17352 (21%)] Loss: -184963.375000\n",
      "Train Epoch: 32 [3760/17352 (22%)] Loss: -181061.812500\n",
      "Train Epoch: 32 [3840/17352 (22%)] Loss: -176867.890625\n",
      "Train Epoch: 32 [3920/17352 (23%)] Loss: -195883.250000\n",
      "Train Epoch: 32 [4000/17352 (23%)] Loss: -190806.203125\n",
      "Train Epoch: 32 [4080/17352 (24%)] Loss: -173656.812500\n",
      "Train Epoch: 32 [4160/17352 (24%)] Loss: -166543.125000\n",
      "Train Epoch: 32 [4240/17352 (24%)] Loss: -182393.406250\n",
      "Train Epoch: 32 [4320/17352 (25%)] Loss: -166647.296875\n",
      "Train Epoch: 32 [4400/17352 (25%)] Loss: -187523.390625\n",
      "Train Epoch: 32 [4480/17352 (26%)] Loss: -175752.734375\n",
      "Train Epoch: 32 [4560/17352 (26%)] Loss: -179439.375000\n",
      "Train Epoch: 32 [4640/17352 (27%)] Loss: -185005.609375\n",
      "Train Epoch: 32 [4720/17352 (27%)] Loss: -149018.203125\n",
      "Train Epoch: 32 [4800/17352 (28%)] Loss: -170302.140625\n",
      "Train Epoch: 32 [4880/17352 (28%)] Loss: -188442.781250\n",
      "Train Epoch: 32 [4960/17352 (29%)] Loss: -200415.406250\n",
      "Train Epoch: 32 [5040/17352 (29%)] Loss: -203743.750000\n",
      "Train Epoch: 32 [5120/17352 (30%)] Loss: -176027.343750\n",
      "Train Epoch: 32 [5200/17352 (30%)] Loss: -204939.281250\n",
      "Train Epoch: 32 [5280/17352 (30%)] Loss: -191586.234375\n",
      "Train Epoch: 32 [5360/17352 (31%)] Loss: -187120.703125\n",
      "Train Epoch: 32 [5440/17352 (31%)] Loss: -180885.375000\n",
      "Train Epoch: 32 [5520/17352 (32%)] Loss: -209498.718750\n",
      "Train Epoch: 32 [5600/17352 (32%)] Loss: -209269.515625\n",
      "Train Epoch: 32 [5680/17352 (33%)] Loss: -189166.546875\n",
      "Train Epoch: 32 [5760/17352 (33%)] Loss: -177301.484375\n",
      "Train Epoch: 32 [5840/17352 (34%)] Loss: -209882.156250\n",
      "Train Epoch: 32 [5920/17352 (34%)] Loss: -196697.562500\n",
      "Train Epoch: 32 [6000/17352 (35%)] Loss: -185925.906250\n",
      "Train Epoch: 32 [6080/17352 (35%)] Loss: -209815.437500\n",
      "Train Epoch: 32 [6160/17352 (36%)] Loss: -199778.062500\n",
      "Train Epoch: 32 [6240/17352 (36%)] Loss: -184986.343750\n",
      "Train Epoch: 32 [6320/17352 (36%)] Loss: -158751.187500\n",
      "Train Epoch: 32 [6400/17352 (37%)] Loss: -201946.328125\n",
      "Train Epoch: 32 [6480/17352 (37%)] Loss: -173662.906250\n",
      "Train Epoch: 32 [6560/17352 (38%)] Loss: -193536.171875\n",
      "Train Epoch: 32 [6640/17352 (38%)] Loss: -195059.765625\n",
      "Train Epoch: 32 [6720/17352 (39%)] Loss: -192792.734375\n",
      "Train Epoch: 32 [6800/17352 (39%)] Loss: -220963.937500\n",
      "Train Epoch: 32 [6880/17352 (40%)] Loss: -215164.046875\n",
      "Train Epoch: 32 [6960/17352 (40%)] Loss: -183920.046875\n",
      "Train Epoch: 32 [7040/17352 (41%)] Loss: -196925.046875\n",
      "Train Epoch: 32 [7120/17352 (41%)] Loss: -196934.734375\n",
      "Train Epoch: 32 [7200/17352 (41%)] Loss: -211158.578125\n",
      "Train Epoch: 32 [7280/17352 (42%)] Loss: -217612.062500\n",
      "Train Epoch: 32 [7360/17352 (42%)] Loss: -167241.062500\n",
      "Train Epoch: 32 [7440/17352 (43%)] Loss: -195002.921875\n",
      "Train Epoch: 32 [7520/17352 (43%)] Loss: -175303.453125\n",
      "Train Epoch: 32 [7600/17352 (44%)] Loss: -187212.921875\n",
      "Train Epoch: 32 [7680/17352 (44%)] Loss: -202850.265625\n",
      "Train Epoch: 32 [7760/17352 (45%)] Loss: -142610.078125\n",
      "Train Epoch: 32 [7840/17352 (45%)] Loss: -170101.234375\n",
      "Train Epoch: 32 [7920/17352 (46%)] Loss: -134533.203125\n",
      "Train Epoch: 32 [8000/17352 (46%)] Loss: -201516.921875\n",
      "Train Epoch: 32 [8080/17352 (47%)] Loss: -181616.968750\n",
      "Train Epoch: 32 [8160/17352 (47%)] Loss: -172956.281250\n",
      "Train Epoch: 32 [8240/17352 (47%)] Loss: -191510.640625\n",
      "Train Epoch: 32 [8320/17352 (48%)] Loss: -151220.375000\n",
      "Train Epoch: 32 [8400/17352 (48%)] Loss: -138335.375000\n",
      "Train Epoch: 32 [8480/17352 (49%)] Loss: -171303.578125\n",
      "Train Epoch: 32 [8560/17352 (49%)] Loss: -196391.203125\n",
      "Train Epoch: 32 [8640/17352 (50%)] Loss: -205393.890625\n",
      "Train Epoch: 32 [8720/17352 (50%)] Loss: -148433.328125\n",
      "Train Epoch: 32 [8800/17352 (51%)] Loss: -180287.015625\n",
      "Train Epoch: 32 [8880/17352 (51%)] Loss: -196111.109375\n",
      "Train Epoch: 32 [8960/17352 (52%)] Loss: -196018.156250\n",
      "Train Epoch: 32 [9040/17352 (52%)] Loss: -192983.718750\n",
      "Train Epoch: 32 [9120/17352 (53%)] Loss: -180639.000000\n",
      "Train Epoch: 32 [9200/17352 (53%)] Loss: -195826.578125\n",
      "Train Epoch: 32 [9280/17352 (53%)] Loss: -190620.312500\n",
      "Train Epoch: 32 [9360/17352 (54%)] Loss: -228147.406250\n",
      "Train Epoch: 32 [9440/17352 (54%)] Loss: -181730.687500\n",
      "Train Epoch: 32 [9520/17352 (55%)] Loss: -195377.500000\n",
      "Train Epoch: 32 [9600/17352 (55%)] Loss: -189216.000000\n",
      "Train Epoch: 32 [9680/17352 (56%)] Loss: -176076.687500\n",
      "Train Epoch: 32 [9760/17352 (56%)] Loss: -194923.937500\n",
      "Train Epoch: 32 [9840/17352 (57%)] Loss: -181249.421875\n",
      "Train Epoch: 32 [9920/17352 (57%)] Loss: -168264.265625\n",
      "Train Epoch: 32 [10000/17352 (58%)] Loss: -163243.625000\n",
      "Train Epoch: 32 [10080/17352 (58%)] Loss: -145996.125000\n",
      "Train Epoch: 32 [10160/17352 (59%)] Loss: -180504.500000\n",
      "Train Epoch: 32 [10240/17352 (59%)] Loss: -204324.468750\n",
      "Train Epoch: 32 [10320/17352 (59%)] Loss: -156990.000000\n",
      "Train Epoch: 32 [10400/17352 (60%)] Loss: -203873.390625\n",
      "Train Epoch: 32 [10480/17352 (60%)] Loss: -178823.468750\n",
      "Train Epoch: 32 [10560/17352 (61%)] Loss: -194063.406250\n",
      "Train Epoch: 32 [10640/17352 (61%)] Loss: -187615.625000\n",
      "Train Epoch: 32 [10720/17352 (62%)] Loss: -170032.765625\n",
      "Train Epoch: 32 [10800/17352 (62%)] Loss: -178563.765625\n",
      "Train Epoch: 32 [10880/17352 (63%)] Loss: -172173.609375\n",
      "Train Epoch: 32 [10960/17352 (63%)] Loss: -148158.156250\n",
      "Train Epoch: 32 [11040/17352 (64%)] Loss: -204363.640625\n",
      "Train Epoch: 32 [11120/17352 (64%)] Loss: -197079.015625\n",
      "Train Epoch: 32 [11200/17352 (65%)] Loss: -188569.062500\n",
      "Train Epoch: 32 [11280/17352 (65%)] Loss: -184811.906250\n",
      "Train Epoch: 32 [11360/17352 (65%)] Loss: -192747.296875\n",
      "Train Epoch: 32 [11440/17352 (66%)] Loss: -188501.796875\n",
      "Train Epoch: 32 [11520/17352 (66%)] Loss: -184838.171875\n",
      "Train Epoch: 32 [11600/17352 (67%)] Loss: -199791.281250\n",
      "Train Epoch: 32 [11680/17352 (67%)] Loss: -160047.109375\n",
      "Train Epoch: 32 [11760/17352 (68%)] Loss: -173501.953125\n",
      "Train Epoch: 32 [11840/17352 (68%)] Loss: -188078.312500\n",
      "Train Epoch: 32 [11920/17352 (69%)] Loss: -191801.046875\n",
      "Train Epoch: 32 [12000/17352 (69%)] Loss: -168068.296875\n",
      "Train Epoch: 32 [12080/17352 (70%)] Loss: -163960.781250\n",
      "Train Epoch: 32 [12160/17352 (70%)] Loss: -180835.296875\n",
      "Train Epoch: 32 [12240/17352 (71%)] Loss: -188263.312500\n",
      "Train Epoch: 32 [12320/17352 (71%)] Loss: -196855.093750\n",
      "Train Epoch: 32 [12400/17352 (71%)] Loss: -179002.187500\n",
      "Train Epoch: 32 [12480/17352 (72%)] Loss: -200324.234375\n",
      "Train Epoch: 32 [12560/17352 (72%)] Loss: -174624.125000\n",
      "Train Epoch: 32 [12640/17352 (73%)] Loss: -182526.937500\n",
      "Train Epoch: 32 [12720/17352 (73%)] Loss: -170680.203125\n",
      "Train Epoch: 32 [12800/17352 (74%)] Loss: -163774.312500\n",
      "Train Epoch: 32 [12880/17352 (74%)] Loss: -159676.000000\n",
      "Train Epoch: 32 [12960/17352 (75%)] Loss: -227887.015625\n",
      "Train Epoch: 32 [13040/17352 (75%)] Loss: -142331.593750\n",
      "Train Epoch: 32 [13120/17352 (76%)] Loss: -189394.218750\n",
      "Train Epoch: 32 [13200/17352 (76%)] Loss: -166019.890625\n",
      "Train Epoch: 32 [13280/17352 (77%)] Loss: -191945.218750\n",
      "Train Epoch: 32 [13360/17352 (77%)] Loss: -177600.781250\n",
      "Train Epoch: 32 [13440/17352 (77%)] Loss: -199066.531250\n",
      "Train Epoch: 32 [13520/17352 (78%)] Loss: -175205.328125\n",
      "Train Epoch: 32 [13600/17352 (78%)] Loss: -183753.093750\n",
      "Train Epoch: 32 [13680/17352 (79%)] Loss: -178301.718750\n",
      "Train Epoch: 32 [13760/17352 (79%)] Loss: -183964.859375\n",
      "Train Epoch: 32 [13840/17352 (80%)] Loss: -149328.187500\n",
      "Train Epoch: 32 [13920/17352 (80%)] Loss: -200216.171875\n",
      "Train Epoch: 32 [14000/17352 (81%)] Loss: -188892.578125\n",
      "Train Epoch: 32 [14080/17352 (81%)] Loss: -205683.734375\n",
      "Train Epoch: 32 [14160/17352 (82%)] Loss: -200066.359375\n",
      "Train Epoch: 32 [14240/17352 (82%)] Loss: -200630.406250\n",
      "Train Epoch: 32 [14320/17352 (83%)] Loss: -190226.312500\n",
      "Train Epoch: 32 [14400/17352 (83%)] Loss: -185391.640625\n",
      "Train Epoch: 32 [14480/17352 (83%)] Loss: -167181.718750\n",
      "Train Epoch: 32 [14560/17352 (84%)] Loss: -191718.046875\n",
      "Train Epoch: 32 [14640/17352 (84%)] Loss: -183599.531250\n",
      "Train Epoch: 32 [14720/17352 (85%)] Loss: -189015.765625\n",
      "Train Epoch: 32 [14800/17352 (85%)] Loss: -143613.765625\n",
      "Train Epoch: 32 [14880/17352 (86%)] Loss: -171831.671875\n",
      "Train Epoch: 32 [14960/17352 (86%)] Loss: -181717.640625\n",
      "Train Epoch: 32 [15040/17352 (87%)] Loss: -180150.781250\n",
      "Train Epoch: 32 [15120/17352 (87%)] Loss: -176698.328125\n",
      "Train Epoch: 32 [15200/17352 (88%)] Loss: -209183.062500\n",
      "Train Epoch: 32 [15280/17352 (88%)] Loss: -177141.093750\n",
      "Train Epoch: 32 [15360/17352 (89%)] Loss: -199589.562500\n",
      "Train Epoch: 32 [15440/17352 (89%)] Loss: -175073.156250\n",
      "Train Epoch: 32 [15520/17352 (89%)] Loss: -187350.875000\n",
      "Train Epoch: 32 [15600/17352 (90%)] Loss: -144990.390625\n",
      "Train Epoch: 32 [15680/17352 (90%)] Loss: -189565.828125\n",
      "Train Epoch: 32 [15760/17352 (91%)] Loss: -203839.703125\n",
      "Train Epoch: 32 [15840/17352 (91%)] Loss: -177199.687500\n",
      "Train Epoch: 32 [15920/17352 (92%)] Loss: -191365.703125\n",
      "Train Epoch: 32 [16000/17352 (92%)] Loss: -180143.296875\n",
      "Train Epoch: 32 [16080/17352 (93%)] Loss: -183283.312500\n",
      "Train Epoch: 32 [16160/17352 (93%)] Loss: -192639.218750\n",
      "Train Epoch: 32 [16240/17352 (94%)] Loss: -184492.375000\n",
      "Train Epoch: 32 [16320/17352 (94%)] Loss: -181359.984375\n",
      "Train Epoch: 32 [16400/17352 (95%)] Loss: -223954.375000\n",
      "Train Epoch: 32 [16480/17352 (95%)] Loss: -204610.781250\n",
      "Train Epoch: 32 [16560/17352 (95%)] Loss: -151730.375000\n",
      "Train Epoch: 32 [16640/17352 (96%)] Loss: -213396.046875\n",
      "Train Epoch: 32 [16720/17352 (96%)] Loss: -174639.781250\n",
      "Train Epoch: 32 [16800/17352 (97%)] Loss: -165676.468750\n",
      "Train Epoch: 32 [16880/17352 (97%)] Loss: -174872.656250\n",
      "Train Epoch: 32 [16960/17352 (98%)] Loss: -176159.968750\n",
      "Train Epoch: 32 [17040/17352 (98%)] Loss: -168075.703125\n",
      "Train Epoch: 32 [17120/17352 (99%)] Loss: -187716.734375\n",
      "Train Epoch: 32 [17200/17352 (99%)] Loss: -192008.812500\n",
      "Train Epoch: 32 [17280/17352 (100%)] Loss: -179434.531250\n",
      "Train Epoch: 32 [17360/17352 (100%)] Loss: -212895.671875\n",
      "    epoch          : 32\n",
      "    loss           : -189058.88215621404\n",
      "    val_loss       : -23715.183597904976\n",
      "Train Epoch: 33 [0/17352 (0%)] Loss: -210215.437500\n",
      "Train Epoch: 33 [80/17352 (0%)] Loss: -206559.265625\n",
      "Train Epoch: 33 [160/17352 (1%)] Loss: -229946.656250\n",
      "Train Epoch: 33 [240/17352 (1%)] Loss: -210516.796875\n",
      "Train Epoch: 33 [320/17352 (2%)] Loss: -219662.109375\n",
      "Train Epoch: 33 [400/17352 (2%)] Loss: -196420.718750\n",
      "Train Epoch: 33 [480/17352 (3%)] Loss: -214403.281250\n",
      "Train Epoch: 33 [560/17352 (3%)] Loss: -212176.546875\n",
      "Train Epoch: 33 [640/17352 (4%)] Loss: -214504.875000\n",
      "Train Epoch: 33 [720/17352 (4%)] Loss: -214510.796875\n",
      "Train Epoch: 33 [800/17352 (5%)] Loss: -229229.078125\n",
      "Train Epoch: 33 [880/17352 (5%)] Loss: -213316.359375\n",
      "Train Epoch: 33 [960/17352 (6%)] Loss: -209782.218750\n",
      "Train Epoch: 33 [1040/17352 (6%)] Loss: -202029.843750\n",
      "Train Epoch: 33 [1120/17352 (6%)] Loss: -236499.921875\n",
      "Train Epoch: 33 [1200/17352 (7%)] Loss: -216096.687500\n",
      "Train Epoch: 33 [1280/17352 (7%)] Loss: -193021.796875\n",
      "Train Epoch: 33 [1360/17352 (8%)] Loss: -202314.281250\n",
      "Train Epoch: 33 [1440/17352 (8%)] Loss: -214457.062500\n",
      "Train Epoch: 33 [1520/17352 (9%)] Loss: -198106.640625\n",
      "Train Epoch: 33 [1600/17352 (9%)] Loss: -198759.484375\n",
      "Train Epoch: 33 [1680/17352 (10%)] Loss: -202263.500000\n",
      "Train Epoch: 33 [1760/17352 (10%)] Loss: -222996.328125\n",
      "Train Epoch: 33 [1840/17352 (11%)] Loss: -214329.421875\n",
      "Train Epoch: 33 [1920/17352 (11%)] Loss: -199903.531250\n",
      "Train Epoch: 33 [2000/17352 (12%)] Loss: -236625.187500\n",
      "Train Epoch: 33 [2080/17352 (12%)] Loss: -214707.953125\n",
      "Train Epoch: 33 [2160/17352 (12%)] Loss: -182779.546875\n",
      "Train Epoch: 33 [2240/17352 (13%)] Loss: -189506.484375\n",
      "Train Epoch: 33 [2320/17352 (13%)] Loss: -168071.125000\n",
      "Train Epoch: 33 [2400/17352 (14%)] Loss: -183606.031250\n",
      "Train Epoch: 33 [2480/17352 (14%)] Loss: -176037.328125\n",
      "Train Epoch: 33 [2560/17352 (15%)] Loss: -166784.843750\n",
      "Train Epoch: 33 [2640/17352 (15%)] Loss: -195097.718750\n",
      "Train Epoch: 33 [2720/17352 (16%)] Loss: -175506.265625\n",
      "Train Epoch: 33 [2800/17352 (16%)] Loss: -189729.468750\n",
      "Train Epoch: 33 [2880/17352 (17%)] Loss: -194221.093750\n",
      "Train Epoch: 33 [2960/17352 (17%)] Loss: -203426.609375\n",
      "Train Epoch: 33 [3040/17352 (18%)] Loss: -183256.218750\n",
      "Train Epoch: 33 [3120/17352 (18%)] Loss: -192320.906250\n",
      "Train Epoch: 33 [3200/17352 (18%)] Loss: -197570.796875\n",
      "Train Epoch: 33 [3280/17352 (19%)] Loss: -193155.468750\n",
      "Train Epoch: 33 [3360/17352 (19%)] Loss: -167246.312500\n",
      "Train Epoch: 33 [3440/17352 (20%)] Loss: -180543.765625\n",
      "Train Epoch: 33 [3520/17352 (20%)] Loss: -190800.187500\n",
      "Train Epoch: 33 [3600/17352 (21%)] Loss: -159745.578125\n",
      "Train Epoch: 33 [3680/17352 (21%)] Loss: -173833.250000\n",
      "Train Epoch: 33 [3760/17352 (22%)] Loss: -190990.515625\n",
      "Train Epoch: 33 [3840/17352 (22%)] Loss: -181002.734375\n",
      "Train Epoch: 33 [3920/17352 (23%)] Loss: -187299.109375\n",
      "Train Epoch: 33 [4000/17352 (23%)] Loss: -192859.234375\n",
      "Train Epoch: 33 [4080/17352 (24%)] Loss: -202190.187500\n",
      "Train Epoch: 33 [4160/17352 (24%)] Loss: -189159.218750\n",
      "Train Epoch: 33 [4240/17352 (24%)] Loss: -177626.781250\n",
      "Train Epoch: 33 [4320/17352 (25%)] Loss: -173008.015625\n",
      "Train Epoch: 33 [4400/17352 (25%)] Loss: -218464.718750\n",
      "Train Epoch: 33 [4480/17352 (26%)] Loss: -181974.593750\n",
      "Train Epoch: 33 [4560/17352 (26%)] Loss: -138323.640625\n",
      "Train Epoch: 33 [4640/17352 (27%)] Loss: -181003.328125\n",
      "Train Epoch: 33 [4720/17352 (27%)] Loss: -193790.578125\n",
      "Train Epoch: 33 [4800/17352 (28%)] Loss: -184165.671875\n",
      "Train Epoch: 33 [4880/17352 (28%)] Loss: -200641.437500\n",
      "Train Epoch: 33 [4960/17352 (29%)] Loss: -164793.890625\n",
      "Train Epoch: 33 [5040/17352 (29%)] Loss: -180992.796875\n",
      "Train Epoch: 33 [5120/17352 (30%)] Loss: -159322.531250\n",
      "Train Epoch: 33 [5200/17352 (30%)] Loss: -209179.546875\n",
      "Train Epoch: 33 [5280/17352 (30%)] Loss: -184998.984375\n",
      "Train Epoch: 33 [5360/17352 (31%)] Loss: -181534.109375\n",
      "Train Epoch: 33 [5440/17352 (31%)] Loss: -166450.218750\n",
      "Train Epoch: 33 [5520/17352 (32%)] Loss: -176149.281250\n",
      "Train Epoch: 33 [5600/17352 (32%)] Loss: -189783.843750\n",
      "Train Epoch: 33 [5680/17352 (33%)] Loss: -183778.562500\n",
      "Train Epoch: 33 [5760/17352 (33%)] Loss: -183580.640625\n",
      "Train Epoch: 33 [5840/17352 (34%)] Loss: -178729.125000\n",
      "Train Epoch: 33 [5920/17352 (34%)] Loss: -178308.234375\n",
      "Train Epoch: 33 [6000/17352 (35%)] Loss: -183927.000000\n",
      "Train Epoch: 33 [6080/17352 (35%)] Loss: -206228.453125\n",
      "Train Epoch: 33 [6160/17352 (36%)] Loss: -186163.671875\n",
      "Train Epoch: 33 [6240/17352 (36%)] Loss: -195375.109375\n",
      "Train Epoch: 33 [6320/17352 (36%)] Loss: -176593.843750\n",
      "Train Epoch: 33 [6400/17352 (37%)] Loss: -199768.265625\n",
      "Train Epoch: 33 [6480/17352 (37%)] Loss: -169975.625000\n",
      "Train Epoch: 33 [6560/17352 (38%)] Loss: -183368.718750\n",
      "Train Epoch: 33 [6640/17352 (38%)] Loss: -189397.562500\n",
      "Train Epoch: 33 [6720/17352 (39%)] Loss: -170677.500000\n",
      "Train Epoch: 33 [6800/17352 (39%)] Loss: -148504.765625\n",
      "Train Epoch: 33 [6880/17352 (40%)] Loss: -188443.515625\n",
      "Train Epoch: 33 [6960/17352 (40%)] Loss: -181919.359375\n",
      "Train Epoch: 33 [7040/17352 (41%)] Loss: -192957.828125\n",
      "Train Epoch: 33 [7120/17352 (41%)] Loss: -161962.734375\n",
      "Train Epoch: 33 [7200/17352 (41%)] Loss: -202307.421875\n",
      "Train Epoch: 33 [7280/17352 (42%)] Loss: -190375.250000\n",
      "Train Epoch: 33 [7360/17352 (42%)] Loss: -212891.437500\n",
      "Train Epoch: 33 [7440/17352 (43%)] Loss: -180518.671875\n",
      "Train Epoch: 33 [7520/17352 (43%)] Loss: -186485.250000\n",
      "Train Epoch: 33 [7600/17352 (44%)] Loss: -179474.671875\n",
      "Train Epoch: 33 [7680/17352 (44%)] Loss: -157487.953125\n",
      "Train Epoch: 33 [7760/17352 (45%)] Loss: -196026.281250\n",
      "Train Epoch: 33 [7840/17352 (45%)] Loss: -184753.296875\n",
      "Train Epoch: 33 [7920/17352 (46%)] Loss: -185359.687500\n",
      "Train Epoch: 33 [8000/17352 (46%)] Loss: -164986.828125\n",
      "Train Epoch: 33 [8080/17352 (47%)] Loss: -180096.468750\n",
      "Train Epoch: 33 [8160/17352 (47%)] Loss: -168043.562500\n",
      "Train Epoch: 33 [8240/17352 (47%)] Loss: -176287.937500\n",
      "Train Epoch: 33 [8320/17352 (48%)] Loss: -185781.437500\n",
      "Train Epoch: 33 [8400/17352 (48%)] Loss: -188675.578125\n",
      "Train Epoch: 33 [8480/17352 (49%)] Loss: -204332.984375\n",
      "Train Epoch: 33 [8560/17352 (49%)] Loss: -181422.468750\n",
      "Train Epoch: 33 [8640/17352 (50%)] Loss: -168759.187500\n",
      "Train Epoch: 33 [8720/17352 (50%)] Loss: -176493.328125\n",
      "Train Epoch: 33 [8800/17352 (51%)] Loss: -179923.859375\n",
      "Train Epoch: 33 [8880/17352 (51%)] Loss: -171421.656250\n",
      "Train Epoch: 33 [8960/17352 (52%)] Loss: -189533.718750\n",
      "Train Epoch: 33 [9040/17352 (52%)] Loss: -192281.515625\n",
      "Train Epoch: 33 [9120/17352 (53%)] Loss: -208719.484375\n",
      "Train Epoch: 33 [9200/17352 (53%)] Loss: -187313.078125\n",
      "Train Epoch: 33 [9280/17352 (53%)] Loss: -183752.500000\n",
      "Train Epoch: 33 [9360/17352 (54%)] Loss: -207821.765625\n",
      "Train Epoch: 33 [9440/17352 (54%)] Loss: -168998.796875\n",
      "Train Epoch: 33 [9520/17352 (55%)] Loss: -215176.359375\n",
      "Train Epoch: 33 [9600/17352 (55%)] Loss: -197327.937500\n",
      "Train Epoch: 33 [9680/17352 (56%)] Loss: -192631.218750\n",
      "Train Epoch: 33 [9760/17352 (56%)] Loss: -202785.593750\n",
      "Train Epoch: 33 [9840/17352 (57%)] Loss: -187210.796875\n",
      "Train Epoch: 33 [9920/17352 (57%)] Loss: -202232.937500\n",
      "Train Epoch: 33 [10000/17352 (58%)] Loss: -178874.437500\n",
      "Train Epoch: 33 [10080/17352 (58%)] Loss: -228253.062500\n",
      "Train Epoch: 33 [10160/17352 (59%)] Loss: -218743.703125\n",
      "Train Epoch: 33 [10240/17352 (59%)] Loss: -164362.171875\n",
      "Train Epoch: 33 [10320/17352 (59%)] Loss: -171835.437500\n",
      "Train Epoch: 33 [10400/17352 (60%)] Loss: -169437.562500\n",
      "Train Epoch: 33 [10480/17352 (60%)] Loss: -218401.546875\n",
      "Train Epoch: 33 [10560/17352 (61%)] Loss: -159678.718750\n",
      "Train Epoch: 33 [10640/17352 (61%)] Loss: -184062.406250\n",
      "Train Epoch: 33 [10720/17352 (62%)] Loss: -187351.703125\n",
      "Train Epoch: 33 [10800/17352 (62%)] Loss: -187404.234375\n",
      "Train Epoch: 33 [10880/17352 (63%)] Loss: -171313.468750\n",
      "Train Epoch: 33 [10960/17352 (63%)] Loss: -202475.593750\n",
      "Train Epoch: 33 [11040/17352 (64%)] Loss: -196148.671875\n",
      "Train Epoch: 33 [11120/17352 (64%)] Loss: -200325.234375\n",
      "Train Epoch: 33 [11200/17352 (65%)] Loss: -177478.671875\n",
      "Train Epoch: 33 [11280/17352 (65%)] Loss: -197303.718750\n",
      "Train Epoch: 33 [11360/17352 (65%)] Loss: -160100.500000\n",
      "Train Epoch: 33 [11440/17352 (66%)] Loss: -177070.781250\n",
      "Train Epoch: 33 [11520/17352 (66%)] Loss: -129697.484375\n",
      "Train Epoch: 33 [11600/17352 (67%)] Loss: -200158.828125\n",
      "Train Epoch: 33 [11680/17352 (67%)] Loss: -195881.109375\n",
      "Train Epoch: 33 [11760/17352 (68%)] Loss: -193533.343750\n",
      "Train Epoch: 33 [11840/17352 (68%)] Loss: -215406.703125\n",
      "Train Epoch: 33 [11920/17352 (69%)] Loss: -192783.812500\n",
      "Train Epoch: 33 [12000/17352 (69%)] Loss: -179167.000000\n",
      "Train Epoch: 33 [12080/17352 (70%)] Loss: -193362.968750\n",
      "Train Epoch: 33 [12160/17352 (70%)] Loss: -173661.015625\n",
      "Train Epoch: 33 [12240/17352 (71%)] Loss: -183868.312500\n",
      "Train Epoch: 33 [12320/17352 (71%)] Loss: -203741.656250\n",
      "Train Epoch: 33 [12400/17352 (71%)] Loss: -210547.328125\n",
      "Train Epoch: 33 [12480/17352 (72%)] Loss: -191948.953125\n",
      "Train Epoch: 33 [12560/17352 (72%)] Loss: -180695.375000\n",
      "Train Epoch: 33 [12640/17352 (73%)] Loss: -193260.406250\n",
      "Train Epoch: 33 [12720/17352 (73%)] Loss: -210258.265625\n",
      "Train Epoch: 33 [12800/17352 (74%)] Loss: -192954.812500\n",
      "Train Epoch: 33 [12880/17352 (74%)] Loss: -206085.843750\n",
      "Train Epoch: 33 [12960/17352 (75%)] Loss: -176583.015625\n",
      "Train Epoch: 33 [13040/17352 (75%)] Loss: -174725.750000\n",
      "Train Epoch: 33 [13120/17352 (76%)] Loss: -196440.500000\n",
      "Train Epoch: 33 [13200/17352 (76%)] Loss: -193193.750000\n",
      "Train Epoch: 33 [13280/17352 (77%)] Loss: -200860.656250\n",
      "Train Epoch: 33 [13360/17352 (77%)] Loss: -145997.078125\n",
      "Train Epoch: 33 [13440/17352 (77%)] Loss: -180906.375000\n",
      "Train Epoch: 33 [13520/17352 (78%)] Loss: -188900.000000\n",
      "Train Epoch: 33 [13600/17352 (78%)] Loss: -189559.796875\n",
      "Train Epoch: 33 [13680/17352 (79%)] Loss: -199789.281250\n",
      "Train Epoch: 33 [13760/17352 (79%)] Loss: -180289.984375\n",
      "Train Epoch: 33 [13840/17352 (80%)] Loss: -201256.359375\n",
      "Train Epoch: 33 [13920/17352 (80%)] Loss: -186032.343750\n",
      "Train Epoch: 33 [14000/17352 (81%)] Loss: -199594.125000\n",
      "Train Epoch: 33 [14080/17352 (81%)] Loss: -213229.484375\n",
      "Train Epoch: 33 [14160/17352 (82%)] Loss: -187265.593750\n",
      "Train Epoch: 33 [14240/17352 (82%)] Loss: -172891.218750\n",
      "Train Epoch: 33 [14320/17352 (83%)] Loss: -188499.265625\n",
      "Train Epoch: 33 [14400/17352 (83%)] Loss: -166244.656250\n",
      "Train Epoch: 33 [14480/17352 (83%)] Loss: -180237.968750\n",
      "Train Epoch: 33 [14560/17352 (84%)] Loss: -169159.546875\n",
      "Train Epoch: 33 [14640/17352 (84%)] Loss: -188801.328125\n",
      "Train Epoch: 33 [14720/17352 (85%)] Loss: -202083.812500\n",
      "Train Epoch: 33 [14800/17352 (85%)] Loss: -176919.406250\n",
      "Train Epoch: 33 [14880/17352 (86%)] Loss: -198290.406250\n",
      "Train Epoch: 33 [14960/17352 (86%)] Loss: -180964.218750\n",
      "Train Epoch: 33 [15040/17352 (87%)] Loss: -176274.421875\n",
      "Train Epoch: 33 [15120/17352 (87%)] Loss: -198805.640625\n",
      "Train Epoch: 33 [15200/17352 (88%)] Loss: -167237.656250\n",
      "Train Epoch: 33 [15280/17352 (88%)] Loss: -171706.875000\n",
      "Train Epoch: 33 [15360/17352 (89%)] Loss: -185047.859375\n",
      "Train Epoch: 33 [15440/17352 (89%)] Loss: -208022.468750\n",
      "Train Epoch: 33 [15520/17352 (89%)] Loss: -178202.296875\n",
      "Train Epoch: 33 [15600/17352 (90%)] Loss: -185561.734375\n",
      "Train Epoch: 33 [15680/17352 (90%)] Loss: -167797.281250\n",
      "Train Epoch: 33 [15760/17352 (91%)] Loss: -196946.031250\n",
      "Train Epoch: 33 [15840/17352 (91%)] Loss: -173283.859375\n",
      "Train Epoch: 33 [15920/17352 (92%)] Loss: -164503.890625\n",
      "Train Epoch: 33 [16000/17352 (92%)] Loss: -200305.078125\n",
      "Train Epoch: 33 [16080/17352 (93%)] Loss: -190465.312500\n",
      "Train Epoch: 33 [16160/17352 (93%)] Loss: -165732.546875\n",
      "Train Epoch: 33 [16240/17352 (94%)] Loss: -196032.171875\n",
      "Train Epoch: 33 [16320/17352 (94%)] Loss: -157590.843750\n",
      "Train Epoch: 33 [16400/17352 (95%)] Loss: -196187.687500\n",
      "Train Epoch: 33 [16480/17352 (95%)] Loss: -180747.375000\n",
      "Train Epoch: 33 [16560/17352 (95%)] Loss: -182385.828125\n",
      "Train Epoch: 33 [16640/17352 (96%)] Loss: -218832.453125\n",
      "Train Epoch: 33 [16720/17352 (96%)] Loss: -180833.937500\n",
      "Train Epoch: 33 [16800/17352 (97%)] Loss: -209820.406250\n",
      "Train Epoch: 33 [16880/17352 (97%)] Loss: -177195.421875\n",
      "Train Epoch: 33 [16960/17352 (98%)] Loss: -174489.781250\n",
      "Train Epoch: 33 [17040/17352 (98%)] Loss: -192282.203125\n",
      "Train Epoch: 33 [17120/17352 (99%)] Loss: -187528.531250\n",
      "Train Epoch: 33 [17200/17352 (99%)] Loss: -167480.843750\n",
      "Train Epoch: 33 [17280/17352 (100%)] Loss: -173933.921875\n",
      "Train Epoch: 33 [17360/17352 (100%)] Loss: -193945.125000\n",
      "    epoch          : 33\n",
      "    loss           : -189369.55088463752\n",
      "    val_loss       : -23715.393551392175\n",
      "Train Epoch: 34 [0/17352 (0%)] Loss: -202223.828125\n",
      "Train Epoch: 34 [80/17352 (0%)] Loss: -223008.046875\n",
      "Train Epoch: 34 [160/17352 (1%)] Loss: -185290.359375\n",
      "Train Epoch: 34 [240/17352 (1%)] Loss: -217584.781250\n",
      "Train Epoch: 34 [320/17352 (2%)] Loss: -206134.312500\n",
      "Train Epoch: 34 [400/17352 (2%)] Loss: -205073.343750\n",
      "Train Epoch: 34 [480/17352 (3%)] Loss: -214510.593750\n",
      "Train Epoch: 34 [560/17352 (3%)] Loss: -204354.218750\n",
      "Train Epoch: 34 [640/17352 (4%)] Loss: -224241.890625\n",
      "Train Epoch: 34 [720/17352 (4%)] Loss: -210623.234375\n",
      "Train Epoch: 34 [800/17352 (5%)] Loss: -229952.265625\n",
      "Train Epoch: 34 [880/17352 (5%)] Loss: -203732.437500\n",
      "Train Epoch: 34 [960/17352 (6%)] Loss: -213312.671875\n",
      "Train Epoch: 34 [1040/17352 (6%)] Loss: -206740.703125\n",
      "Train Epoch: 34 [1120/17352 (6%)] Loss: -214513.187500\n",
      "Train Epoch: 34 [1200/17352 (7%)] Loss: -212643.015625\n",
      "Train Epoch: 34 [1280/17352 (7%)] Loss: -236826.093750\n",
      "Train Epoch: 34 [1360/17352 (8%)] Loss: -191889.734375\n",
      "Train Epoch: 34 [1440/17352 (8%)] Loss: -206633.718750\n",
      "Train Epoch: 34 [1520/17352 (9%)] Loss: -213329.515625\n",
      "Train Epoch: 34 [1600/17352 (9%)] Loss: -236628.500000\n",
      "Train Epoch: 34 [1680/17352 (10%)] Loss: -236497.671875\n",
      "Train Epoch: 34 [1760/17352 (10%)] Loss: -230194.765625\n",
      "Train Epoch: 34 [1840/17352 (11%)] Loss: -199095.578125\n",
      "Train Epoch: 34 [1920/17352 (11%)] Loss: -215094.781250\n",
      "Train Epoch: 34 [2000/17352 (12%)] Loss: -188749.125000\n",
      "Train Epoch: 34 [2080/17352 (12%)] Loss: -204728.828125\n",
      "Train Epoch: 34 [2160/17352 (12%)] Loss: -216084.968750\n",
      "Train Epoch: 34 [2240/17352 (13%)] Loss: -180057.265625\n",
      "Train Epoch: 34 [2320/17352 (13%)] Loss: -197345.750000\n",
      "Train Epoch: 34 [2400/17352 (14%)] Loss: -181909.046875\n",
      "Train Epoch: 34 [2480/17352 (14%)] Loss: -189480.531250\n",
      "Train Epoch: 34 [2560/17352 (15%)] Loss: -195821.843750\n",
      "Train Epoch: 34 [2640/17352 (15%)] Loss: -136425.546875\n",
      "Train Epoch: 34 [2720/17352 (16%)] Loss: -180022.562500\n",
      "Train Epoch: 34 [2800/17352 (16%)] Loss: -164362.625000\n",
      "Train Epoch: 34 [2880/17352 (17%)] Loss: -194064.171875\n",
      "Train Epoch: 34 [2960/17352 (17%)] Loss: -192157.468750\n",
      "Train Epoch: 34 [3040/17352 (18%)] Loss: -201090.500000\n",
      "Train Epoch: 34 [3120/17352 (18%)] Loss: -174029.906250\n",
      "Train Epoch: 34 [3200/17352 (18%)] Loss: -185364.109375\n",
      "Train Epoch: 34 [3280/17352 (19%)] Loss: -187358.578125\n",
      "Train Epoch: 34 [3360/17352 (19%)] Loss: -178634.046875\n",
      "Train Epoch: 34 [3440/17352 (20%)] Loss: -203461.562500\n",
      "Train Epoch: 34 [3520/17352 (20%)] Loss: -190211.062500\n",
      "Train Epoch: 34 [3600/17352 (21%)] Loss: -184065.140625\n",
      "Train Epoch: 34 [3680/17352 (21%)] Loss: -163549.484375\n",
      "Train Epoch: 34 [3760/17352 (22%)] Loss: -167244.468750\n",
      "Train Epoch: 34 [3840/17352 (22%)] Loss: -200162.343750\n",
      "Train Epoch: 34 [3920/17352 (23%)] Loss: -175742.703125\n",
      "Train Epoch: 34 [4000/17352 (23%)] Loss: -185568.515625\n",
      "Train Epoch: 34 [4080/17352 (24%)] Loss: -168081.078125\n",
      "Train Epoch: 34 [4160/17352 (24%)] Loss: -183713.968750\n",
      "Train Epoch: 34 [4240/17352 (24%)] Loss: -163772.218750\n",
      "Train Epoch: 34 [4320/17352 (25%)] Loss: -196120.000000\n",
      "Train Epoch: 34 [4400/17352 (25%)] Loss: -212615.468750\n",
      "Train Epoch: 34 [4480/17352 (26%)] Loss: -191828.750000\n",
      "Train Epoch: 34 [4560/17352 (26%)] Loss: -165361.281250\n",
      "Train Epoch: 34 [4640/17352 (27%)] Loss: -203263.937500\n",
      "Train Epoch: 34 [4720/17352 (27%)] Loss: -193533.796875\n",
      "Train Epoch: 34 [4800/17352 (28%)] Loss: -209814.906250\n",
      "Train Epoch: 34 [4880/17352 (28%)] Loss: -186029.609375\n",
      "Train Epoch: 34 [4960/17352 (29%)] Loss: -159738.156250\n",
      "Train Epoch: 34 [5040/17352 (29%)] Loss: -176159.703125\n",
      "Train Epoch: 34 [5120/17352 (30%)] Loss: -185361.578125\n",
      "Train Epoch: 34 [5200/17352 (30%)] Loss: -163493.265625\n",
      "Train Epoch: 34 [5280/17352 (30%)] Loss: -203806.671875\n",
      "Train Epoch: 34 [5360/17352 (31%)] Loss: -202784.250000\n",
      "Train Epoch: 34 [5440/17352 (31%)] Loss: -192245.640625\n",
      "Train Epoch: 34 [5520/17352 (32%)] Loss: -177194.109375\n",
      "Train Epoch: 34 [5600/17352 (32%)] Loss: -180139.562500\n",
      "Train Epoch: 34 [5680/17352 (33%)] Loss: -177274.609375\n",
      "Train Epoch: 34 [5760/17352 (33%)] Loss: -165729.812500\n",
      "Train Epoch: 34 [5840/17352 (34%)] Loss: -188672.234375\n",
      "Train Epoch: 34 [5920/17352 (34%)] Loss: -182737.875000\n",
      "Train Epoch: 34 [6000/17352 (35%)] Loss: -178372.953125\n",
      "Train Epoch: 34 [6080/17352 (35%)] Loss: -189803.468750\n",
      "Train Epoch: 34 [6160/17352 (36%)] Loss: -187193.718750\n",
      "Train Epoch: 34 [6240/17352 (36%)] Loss: -192745.109375\n",
      "Train Epoch: 34 [6320/17352 (36%)] Loss: -201262.156250\n",
      "Train Epoch: 34 [6400/17352 (37%)] Loss: -168061.828125\n",
      "Train Epoch: 34 [6480/17352 (37%)] Loss: -200195.656250\n",
      "Train Epoch: 34 [6560/17352 (38%)] Loss: -185329.281250\n",
      "Train Epoch: 34 [6640/17352 (38%)] Loss: -228238.906250\n",
      "Train Epoch: 34 [6720/17352 (39%)] Loss: -183798.406250\n",
      "Train Epoch: 34 [6800/17352 (39%)] Loss: -210640.765625\n",
      "Train Epoch: 34 [6880/17352 (40%)] Loss: -180687.500000\n",
      "Train Epoch: 34 [6960/17352 (40%)] Loss: -203142.453125\n",
      "Train Epoch: 34 [7040/17352 (41%)] Loss: -202082.453125\n",
      "Train Epoch: 34 [7120/17352 (41%)] Loss: -183159.828125\n",
      "Train Epoch: 34 [7200/17352 (41%)] Loss: -208716.984375\n",
      "Train Epoch: 34 [7280/17352 (42%)] Loss: -189012.031250\n",
      "Train Epoch: 34 [7360/17352 (42%)] Loss: -193151.234375\n",
      "Train Epoch: 34 [7440/17352 (43%)] Loss: -190999.531250\n",
      "Train Epoch: 34 [7520/17352 (43%)] Loss: -192998.671875\n",
      "Train Epoch: 34 [7600/17352 (44%)] Loss: -168759.468750\n",
      "Train Epoch: 34 [7680/17352 (44%)] Loss: -186428.859375\n",
      "Train Epoch: 34 [7760/17352 (45%)] Loss: -176027.468750\n",
      "Train Epoch: 34 [7840/17352 (45%)] Loss: -183956.390625\n",
      "Train Epoch: 34 [7920/17352 (46%)] Loss: -177615.531250\n",
      "Train Epoch: 34 [8000/17352 (46%)] Loss: -205508.828125\n",
      "Train Epoch: 34 [8080/17352 (47%)] Loss: -187597.546875\n",
      "Train Epoch: 34 [8160/17352 (47%)] Loss: -192896.703125\n",
      "Train Epoch: 34 [8240/17352 (47%)] Loss: -138336.687500\n",
      "Train Epoch: 34 [8320/17352 (48%)] Loss: -200266.750000\n",
      "Train Epoch: 34 [8400/17352 (48%)] Loss: -131040.937500\n",
      "Train Epoch: 34 [8480/17352 (49%)] Loss: -192389.328125\n",
      "Train Epoch: 34 [8560/17352 (49%)] Loss: -172899.484375\n",
      "Train Epoch: 34 [8640/17352 (50%)] Loss: -175073.421875\n",
      "Train Epoch: 34 [8720/17352 (50%)] Loss: -176869.921875\n",
      "Train Epoch: 34 [8800/17352 (51%)] Loss: -193489.453125\n",
      "Train Epoch: 34 [8880/17352 (51%)] Loss: -197299.062500\n",
      "Train Epoch: 34 [8960/17352 (52%)] Loss: -142335.625000\n",
      "Train Epoch: 34 [9040/17352 (52%)] Loss: -188250.765625\n",
      "Train Epoch: 34 [9120/17352 (53%)] Loss: -195642.781250\n",
      "Train Epoch: 34 [9200/17352 (53%)] Loss: -201514.437500\n",
      "Train Epoch: 34 [9280/17352 (53%)] Loss: -208038.062500\n",
      "Train Epoch: 34 [9360/17352 (54%)] Loss: -209584.765625\n",
      "Train Epoch: 34 [9440/17352 (54%)] Loss: -180984.640625\n",
      "Train Epoch: 34 [9520/17352 (55%)] Loss: -176593.500000\n",
      "Train Epoch: 34 [9600/17352 (55%)] Loss: -187518.312500\n",
      "Train Epoch: 34 [9680/17352 (56%)] Loss: -178428.390625\n",
      "Train Epoch: 34 [9760/17352 (56%)] Loss: -189265.031250\n",
      "Train Epoch: 34 [9840/17352 (57%)] Loss: -213176.375000\n",
      "Train Epoch: 34 [9920/17352 (57%)] Loss: -221246.000000\n",
      "Train Epoch: 34 [10000/17352 (58%)] Loss: -191355.796875\n",
      "Train Epoch: 34 [10080/17352 (58%)] Loss: -171222.640625\n",
      "Train Epoch: 34 [10160/17352 (59%)] Loss: -214752.546875\n",
      "Train Epoch: 34 [10240/17352 (59%)] Loss: -148500.578125\n",
      "Train Epoch: 34 [10320/17352 (59%)] Loss: -210915.187500\n",
      "Train Epoch: 34 [10400/17352 (60%)] Loss: -180154.734375\n",
      "Train Epoch: 34 [10480/17352 (60%)] Loss: -213896.734375\n",
      "Train Epoch: 34 [10560/17352 (61%)] Loss: -174908.812500\n",
      "Train Epoch: 34 [10640/17352 (61%)] Loss: -169741.484375\n",
      "Train Epoch: 34 [10720/17352 (62%)] Loss: -204476.859375\n",
      "Train Epoch: 34 [10800/17352 (62%)] Loss: -231038.625000\n",
      "Train Epoch: 34 [10880/17352 (63%)] Loss: -179447.406250\n",
      "Train Epoch: 34 [10960/17352 (63%)] Loss: -148920.453125\n",
      "Train Epoch: 34 [11040/17352 (64%)] Loss: -178569.906250\n",
      "Train Epoch: 34 [11120/17352 (64%)] Loss: -184600.687500\n",
      "Train Epoch: 34 [11200/17352 (65%)] Loss: -201823.328125\n",
      "Train Epoch: 34 [11280/17352 (65%)] Loss: -178827.234375\n",
      "Train Epoch: 34 [11360/17352 (65%)] Loss: -215964.265625\n",
      "Train Epoch: 34 [11440/17352 (66%)] Loss: -199511.906250\n",
      "Train Epoch: 34 [11520/17352 (66%)] Loss: -169975.421875\n",
      "Train Epoch: 34 [11600/17352 (67%)] Loss: -187269.562500\n",
      "Train Epoch: 34 [11680/17352 (67%)] Loss: -202229.890625\n",
      "Train Epoch: 34 [11760/17352 (68%)] Loss: -151509.875000\n",
      "Train Epoch: 34 [11840/17352 (68%)] Loss: -175428.437500\n",
      "Train Epoch: 34 [11920/17352 (69%)] Loss: -196041.953125\n",
      "Train Epoch: 34 [12000/17352 (69%)] Loss: -163113.343750\n",
      "Train Epoch: 34 [12080/17352 (70%)] Loss: -163341.671875\n",
      "Train Epoch: 34 [12160/17352 (70%)] Loss: -178598.218750\n",
      "Train Epoch: 34 [12240/17352 (71%)] Loss: -192633.687500\n",
      "Train Epoch: 34 [12320/17352 (71%)] Loss: -183379.359375\n",
      "Train Epoch: 34 [12400/17352 (71%)] Loss: -204684.718750\n",
      "Train Epoch: 34 [12480/17352 (72%)] Loss: -188004.906250\n",
      "Train Epoch: 34 [12560/17352 (72%)] Loss: -172230.343750\n",
      "Train Epoch: 34 [12640/17352 (73%)] Loss: -202168.328125\n",
      "Train Epoch: 34 [12720/17352 (73%)] Loss: -164950.828125\n",
      "Train Epoch: 34 [12800/17352 (74%)] Loss: -179166.640625\n",
      "Train Epoch: 34 [12880/17352 (74%)] Loss: -173576.453125\n",
      "Train Epoch: 34 [12960/17352 (75%)] Loss: -180901.500000\n",
      "Train Epoch: 34 [13040/17352 (75%)] Loss: -205167.343750\n",
      "Train Epoch: 34 [13120/17352 (76%)] Loss: -196700.140625\n",
      "Train Epoch: 34 [13200/17352 (76%)] Loss: -215463.296875\n",
      "Train Epoch: 34 [13280/17352 (77%)] Loss: -180107.703125\n",
      "Train Epoch: 34 [13360/17352 (77%)] Loss: -192111.343750\n",
      "Train Epoch: 34 [13440/17352 (77%)] Loss: -178601.625000\n",
      "Train Epoch: 34 [13520/17352 (78%)] Loss: -194066.218750\n",
      "Train Epoch: 34 [13600/17352 (78%)] Loss: -206152.812500\n",
      "Train Epoch: 34 [13680/17352 (79%)] Loss: -190228.765625\n",
      "Train Epoch: 34 [13760/17352 (79%)] Loss: -199177.093750\n",
      "Train Epoch: 34 [13840/17352 (80%)] Loss: -208902.328125\n",
      "Train Epoch: 34 [13920/17352 (80%)] Loss: -190813.203125\n",
      "Train Epoch: 34 [14000/17352 (81%)] Loss: -173920.343750\n",
      "Train Epoch: 34 [14080/17352 (81%)] Loss: -185236.031250\n",
      "Train Epoch: 34 [14160/17352 (82%)] Loss: -184167.625000\n",
      "Train Epoch: 34 [14240/17352 (82%)] Loss: -186846.640625\n",
      "Train Epoch: 34 [14320/17352 (83%)] Loss: -148399.234375\n",
      "Train Epoch: 34 [14400/17352 (83%)] Loss: -200415.265625\n",
      "Train Epoch: 34 [14480/17352 (83%)] Loss: -178311.062500\n",
      "Train Epoch: 34 [14560/17352 (84%)] Loss: -197535.859375\n",
      "Train Epoch: 34 [14640/17352 (84%)] Loss: -194951.734375\n",
      "Train Epoch: 34 [14720/17352 (85%)] Loss: -176695.546875\n",
      "Train Epoch: 34 [14800/17352 (85%)] Loss: -193342.296875\n",
      "Train Epoch: 34 [14880/17352 (86%)] Loss: -179459.187500\n",
      "Train Epoch: 34 [14960/17352 (86%)] Loss: -179497.812500\n",
      "Train Epoch: 34 [15040/17352 (87%)] Loss: -180052.125000\n",
      "Train Epoch: 34 [15120/17352 (87%)] Loss: -188202.312500\n",
      "Train Epoch: 34 [15200/17352 (88%)] Loss: -203136.687500\n",
      "Train Epoch: 34 [15280/17352 (88%)] Loss: -187942.156250\n",
      "Train Epoch: 34 [15360/17352 (89%)] Loss: -202016.000000\n",
      "Train Epoch: 34 [15440/17352 (89%)] Loss: -192953.140625\n",
      "Train Epoch: 34 [15520/17352 (89%)] Loss: -169159.312500\n",
      "Train Epoch: 34 [15600/17352 (90%)] Loss: -210260.187500\n",
      "Train Epoch: 34 [15680/17352 (90%)] Loss: -210387.093750\n",
      "Train Epoch: 34 [15760/17352 (91%)] Loss: -188445.453125\n",
      "Train Epoch: 34 [15840/17352 (91%)] Loss: -184020.890625\n",
      "Train Epoch: 34 [15920/17352 (92%)] Loss: -183456.812500\n",
      "Train Epoch: 34 [16000/17352 (92%)] Loss: -177602.546875\n",
      "Train Epoch: 34 [16080/17352 (93%)] Loss: -180895.375000\n",
      "Train Epoch: 34 [16160/17352 (93%)] Loss: -184962.859375\n",
      "Train Epoch: 34 [16240/17352 (94%)] Loss: -180877.328125\n",
      "Train Epoch: 34 [16320/17352 (94%)] Loss: -204410.796875\n",
      "Train Epoch: 34 [16400/17352 (95%)] Loss: -187320.671875\n",
      "Train Epoch: 34 [16480/17352 (95%)] Loss: -198823.796875\n",
      "Train Epoch: 34 [16560/17352 (95%)] Loss: -185779.671875\n",
      "Train Epoch: 34 [16640/17352 (96%)] Loss: -179675.000000\n",
      "Train Epoch: 34 [16720/17352 (96%)] Loss: -194924.203125\n",
      "Train Epoch: 34 [16800/17352 (97%)] Loss: -195372.781250\n",
      "Train Epoch: 34 [16880/17352 (97%)] Loss: -180635.765625\n",
      "Train Epoch: 34 [16960/17352 (98%)] Loss: -187782.812500\n",
      "Train Epoch: 34 [17040/17352 (98%)] Loss: -197106.765625\n",
      "Train Epoch: 34 [17120/17352 (99%)] Loss: -192281.875000\n",
      "Train Epoch: 34 [17200/17352 (99%)] Loss: -179005.671875\n",
      "Train Epoch: 34 [17280/17352 (100%)] Loss: -164680.093750\n",
      "Train Epoch: 34 [17360/17352 (100%)] Loss: -176076.750000\n",
      "    epoch          : 34\n",
      "    loss           : -189416.79510392694\n",
      "    val_loss       : -23715.25532023112\n",
      "Train Epoch: 35 [0/17352 (0%)] Loss: -219655.031250\n",
      "Train Epoch: 35 [80/17352 (0%)] Loss: -208380.859375\n",
      "Train Epoch: 35 [160/17352 (1%)] Loss: -209548.218750\n",
      "Train Epoch: 35 [240/17352 (1%)] Loss: -204030.281250\n",
      "Train Epoch: 35 [320/17352 (2%)] Loss: -204701.453125\n",
      "Train Epoch: 35 [400/17352 (2%)] Loss: -206629.281250\n",
      "Train Epoch: 35 [480/17352 (3%)] Loss: -206559.562500\n",
      "Train Epoch: 35 [560/17352 (3%)] Loss: -193573.843750\n",
      "Train Epoch: 35 [640/17352 (4%)] Loss: -215820.140625\n",
      "Train Epoch: 35 [720/17352 (4%)] Loss: -214707.562500\n",
      "Train Epoch: 35 [800/17352 (5%)] Loss: -235584.515625\n",
      "Train Epoch: 35 [880/17352 (5%)] Loss: -202271.390625\n",
      "Train Epoch: 35 [960/17352 (6%)] Loss: -216213.531250\n",
      "Train Epoch: 35 [1040/17352 (6%)] Loss: -212368.328125\n",
      "Train Epoch: 35 [1120/17352 (6%)] Loss: -198766.281250\n",
      "Train Epoch: 35 [1200/17352 (7%)] Loss: -212701.046875\n",
      "Train Epoch: 35 [1280/17352 (7%)] Loss: -210210.187500\n",
      "Train Epoch: 35 [1360/17352 (8%)] Loss: -202037.000000\n",
      "Train Epoch: 35 [1440/17352 (8%)] Loss: -182764.328125\n",
      "Train Epoch: 35 [1520/17352 (9%)] Loss: -215480.250000\n",
      "Train Epoch: 35 [1600/17352 (9%)] Loss: -193705.843750\n",
      "Train Epoch: 35 [1680/17352 (10%)] Loss: -214406.468750\n",
      "Train Epoch: 35 [1760/17352 (10%)] Loss: -205926.437500\n",
      "Train Epoch: 35 [1840/17352 (11%)] Loss: -230187.125000\n",
      "Train Epoch: 35 [1920/17352 (11%)] Loss: -215086.890625\n",
      "Train Epoch: 35 [2000/17352 (12%)] Loss: -241895.609375\n",
      "Train Epoch: 35 [2080/17352 (12%)] Loss: -199103.484375\n",
      "Train Epoch: 35 [2160/17352 (12%)] Loss: -236834.984375\n",
      "Train Epoch: 35 [2240/17352 (13%)] Loss: -204207.000000\n",
      "Train Epoch: 35 [2320/17352 (13%)] Loss: -167869.359375\n",
      "Train Epoch: 35 [2400/17352 (14%)] Loss: -180894.265625\n",
      "Train Epoch: 35 [2480/17352 (14%)] Loss: -185925.984375\n",
      "Train Epoch: 35 [2560/17352 (15%)] Loss: -176588.046875\n",
      "Train Epoch: 35 [2640/17352 (15%)] Loss: -172177.734375\n",
      "Train Epoch: 35 [2720/17352 (16%)] Loss: -184834.109375\n",
      "Train Epoch: 35 [2800/17352 (16%)] Loss: -187403.296875\n",
      "Train Epoch: 35 [2880/17352 (17%)] Loss: -161095.656250\n",
      "Train Epoch: 35 [2960/17352 (17%)] Loss: -180255.546875\n",
      "Train Epoch: 35 [3040/17352 (18%)] Loss: -209189.187500\n",
      "Train Epoch: 35 [3120/17352 (18%)] Loss: -186945.421875\n",
      "Train Epoch: 35 [3200/17352 (18%)] Loss: -164364.218750\n",
      "Train Epoch: 35 [3280/17352 (19%)] Loss: -186430.531250\n",
      "Train Epoch: 35 [3360/17352 (19%)] Loss: -175414.875000\n",
      "Train Epoch: 35 [3440/17352 (20%)] Loss: -208723.265625\n",
      "Train Epoch: 35 [3520/17352 (20%)] Loss: -187641.312500\n",
      "Train Epoch: 35 [3600/17352 (21%)] Loss: -200167.703125\n",
      "Train Epoch: 35 [3680/17352 (21%)] Loss: -197078.390625\n",
      "Train Epoch: 35 [3760/17352 (22%)] Loss: -192786.015625\n",
      "Train Epoch: 35 [3840/17352 (22%)] Loss: -203845.468750\n",
      "Train Epoch: 35 [3920/17352 (23%)] Loss: -195100.875000\n",
      "Train Epoch: 35 [4000/17352 (23%)] Loss: -180301.109375\n",
      "Train Epoch: 35 [4080/17352 (24%)] Loss: -205811.312500\n",
      "Train Epoch: 35 [4160/17352 (24%)] Loss: -197524.625000\n",
      "Train Epoch: 35 [4240/17352 (24%)] Loss: -195508.687500\n",
      "Train Epoch: 35 [4320/17352 (25%)] Loss: -199889.718750\n",
      "Train Epoch: 35 [4400/17352 (25%)] Loss: -187264.625000\n",
      "Train Epoch: 35 [4480/17352 (26%)] Loss: -206465.625000\n",
      "Train Epoch: 35 [4560/17352 (26%)] Loss: -190080.437500\n",
      "Train Epoch: 35 [4640/17352 (27%)] Loss: -202308.609375\n",
      "Train Epoch: 35 [4720/17352 (27%)] Loss: -204596.265625\n",
      "Train Epoch: 35 [4800/17352 (28%)] Loss: -161682.843750\n",
      "Train Epoch: 35 [4880/17352 (28%)] Loss: -189723.062500\n",
      "Train Epoch: 35 [4960/17352 (29%)] Loss: -171841.625000\n",
      "Train Epoch: 35 [5040/17352 (29%)] Loss: -192110.640625\n",
      "Train Epoch: 35 [5120/17352 (30%)] Loss: -170306.625000\n",
      "Train Epoch: 35 [5200/17352 (30%)] Loss: -172546.343750\n",
      "Train Epoch: 35 [5280/17352 (30%)] Loss: -184452.515625\n",
      "Train Epoch: 35 [5360/17352 (31%)] Loss: -192246.468750\n",
      "Train Epoch: 35 [5440/17352 (31%)] Loss: -166666.093750\n",
      "Train Epoch: 35 [5520/17352 (32%)] Loss: -213907.812500\n",
      "Train Epoch: 35 [5600/17352 (32%)] Loss: -202232.968750\n",
      "Train Epoch: 35 [5680/17352 (33%)] Loss: -206693.125000\n",
      "Train Epoch: 35 [5760/17352 (33%)] Loss: -202599.156250\n",
      "Train Epoch: 35 [5840/17352 (34%)] Loss: -202012.531250\n",
      "Train Epoch: 35 [5920/17352 (34%)] Loss: -174511.250000\n",
      "Train Epoch: 35 [6000/17352 (35%)] Loss: -209891.468750\n",
      "Train Epoch: 35 [6080/17352 (35%)] Loss: -196190.312500\n",
      "Train Epoch: 35 [6160/17352 (36%)] Loss: -183223.890625\n",
      "Train Epoch: 35 [6240/17352 (36%)] Loss: -183805.656250\n",
      "Train Epoch: 35 [6320/17352 (36%)] Loss: -187312.250000\n",
      "Train Epoch: 35 [6400/17352 (37%)] Loss: -169969.421875\n",
      "Train Epoch: 35 [6480/17352 (37%)] Loss: -184958.375000\n",
      "Train Epoch: 35 [6560/17352 (38%)] Loss: -201924.593750\n",
      "Train Epoch: 35 [6640/17352 (38%)] Loss: -181665.421875\n",
      "Train Epoch: 35 [6720/17352 (39%)] Loss: -215957.328125\n",
      "Train Epoch: 35 [6800/17352 (39%)] Loss: -177459.203125\n",
      "Train Epoch: 35 [6880/17352 (40%)] Loss: -166993.781250\n",
      "Train Epoch: 35 [6960/17352 (40%)] Loss: -163201.671875\n",
      "Train Epoch: 35 [7040/17352 (41%)] Loss: -187709.515625\n",
      "Train Epoch: 35 [7120/17352 (41%)] Loss: -204688.984375\n",
      "Train Epoch: 35 [7200/17352 (41%)] Loss: -189256.312500\n",
      "Train Epoch: 35 [7280/17352 (42%)] Loss: -176876.234375\n",
      "Train Epoch: 35 [7360/17352 (42%)] Loss: -138330.500000\n",
      "Train Epoch: 35 [7440/17352 (43%)] Loss: -199784.656250\n",
      "Train Epoch: 35 [7520/17352 (43%)] Loss: -191942.296875\n",
      "Train Epoch: 35 [7600/17352 (44%)] Loss: -189508.625000\n",
      "Train Epoch: 35 [7680/17352 (44%)] Loss: -163348.515625\n",
      "Train Epoch: 35 [7760/17352 (45%)] Loss: -221255.937500\n",
      "Train Epoch: 35 [7840/17352 (45%)] Loss: -183759.984375\n",
      "Train Epoch: 35 [7920/17352 (46%)] Loss: -183959.562500\n",
      "Train Epoch: 35 [8000/17352 (46%)] Loss: -176900.593750\n",
      "Train Epoch: 35 [8080/17352 (47%)] Loss: -178727.812500\n",
      "Train Epoch: 35 [8160/17352 (47%)] Loss: -171830.218750\n",
      "Train Epoch: 35 [8240/17352 (47%)] Loss: -183771.140625\n",
      "Train Epoch: 35 [8320/17352 (48%)] Loss: -186188.359375\n",
      "Train Epoch: 35 [8400/17352 (48%)] Loss: -181757.312500\n",
      "Train Epoch: 35 [8480/17352 (49%)] Loss: -220977.828125\n",
      "Train Epoch: 35 [8560/17352 (49%)] Loss: -210257.515625\n",
      "Train Epoch: 35 [8640/17352 (50%)] Loss: -160051.421875\n",
      "Train Epoch: 35 [8720/17352 (50%)] Loss: -189475.328125\n",
      "Train Epoch: 35 [8800/17352 (51%)] Loss: -187590.765625\n",
      "Train Epoch: 35 [8880/17352 (51%)] Loss: -166650.046875\n",
      "Train Epoch: 35 [8960/17352 (52%)] Loss: -198693.953125\n",
      "Train Epoch: 35 [9040/17352 (52%)] Loss: -198261.671875\n",
      "Train Epoch: 35 [9120/17352 (53%)] Loss: -181715.859375\n",
      "Train Epoch: 35 [9200/17352 (53%)] Loss: -194929.640625\n",
      "Train Epoch: 35 [9280/17352 (53%)] Loss: -184268.062500\n",
      "Train Epoch: 35 [9360/17352 (54%)] Loss: -173304.531250\n",
      "Train Epoch: 35 [9440/17352 (54%)] Loss: -136422.031250\n",
      "Train Epoch: 35 [9520/17352 (55%)] Loss: -152902.250000\n",
      "Train Epoch: 35 [9600/17352 (55%)] Loss: -204329.093750\n",
      "Train Epoch: 35 [9680/17352 (56%)] Loss: -95257.765625\n",
      "Train Epoch: 35 [9760/17352 (56%)] Loss: -177599.953125\n",
      "Train Epoch: 35 [9840/17352 (57%)] Loss: -201373.875000\n",
      "Train Epoch: 35 [9920/17352 (57%)] Loss: -205689.375000\n",
      "Train Epoch: 35 [10000/17352 (58%)] Loss: -183065.734375\n",
      "Train Epoch: 35 [10080/17352 (58%)] Loss: -164135.250000\n",
      "Train Epoch: 35 [10160/17352 (59%)] Loss: -206344.156250\n",
      "Train Epoch: 35 [10240/17352 (59%)] Loss: -199060.343750\n",
      "Train Epoch: 35 [10320/17352 (59%)] Loss: -190509.625000\n",
      "Train Epoch: 35 [10400/17352 (60%)] Loss: -201117.843750\n",
      "Train Epoch: 35 [10480/17352 (60%)] Loss: -142327.843750\n",
      "Train Epoch: 35 [10560/17352 (61%)] Loss: -173433.062500\n",
      "Train Epoch: 35 [10640/17352 (61%)] Loss: -159086.453125\n",
      "Train Epoch: 35 [10720/17352 (62%)] Loss: -186681.062500\n",
      "Train Epoch: 35 [10800/17352 (62%)] Loss: -178131.406250\n",
      "Train Epoch: 35 [10880/17352 (63%)] Loss: -204341.890625\n",
      "Train Epoch: 35 [10960/17352 (63%)] Loss: -218844.968750\n",
      "Train Epoch: 35 [11040/17352 (64%)] Loss: -202171.000000\n",
      "Train Epoch: 35 [11120/17352 (64%)] Loss: -208310.671875\n",
      "Train Epoch: 35 [11200/17352 (65%)] Loss: -174720.062500\n",
      "Train Epoch: 35 [11280/17352 (65%)] Loss: -181973.562500\n",
      "Train Epoch: 35 [11360/17352 (65%)] Loss: -171425.312500\n",
      "Train Epoch: 35 [11440/17352 (66%)] Loss: -211717.718750\n",
      "Train Epoch: 35 [11520/17352 (66%)] Loss: -177299.453125\n",
      "Train Epoch: 35 [11600/17352 (67%)] Loss: -203670.640625\n",
      "Train Epoch: 35 [11680/17352 (67%)] Loss: -209503.609375\n",
      "Train Epoch: 35 [11760/17352 (68%)] Loss: -175407.953125\n",
      "Train Epoch: 35 [11840/17352 (68%)] Loss: -179380.343750\n",
      "Train Epoch: 35 [11920/17352 (69%)] Loss: -193789.843750\n",
      "Train Epoch: 35 [12000/17352 (69%)] Loss: -146860.000000\n",
      "Train Epoch: 35 [12080/17352 (70%)] Loss: -205521.296875\n",
      "Train Epoch: 35 [12160/17352 (70%)] Loss: -181728.375000\n",
      "Train Epoch: 35 [12240/17352 (71%)] Loss: -171579.406250\n",
      "Train Epoch: 35 [12320/17352 (71%)] Loss: -179925.406250\n",
      "Train Epoch: 35 [12400/17352 (71%)] Loss: -164072.750000\n",
      "Train Epoch: 35 [12480/17352 (72%)] Loss: -207115.000000\n",
      "Train Epoch: 35 [12560/17352 (72%)] Loss: -164800.546875\n",
      "Train Epoch: 35 [12640/17352 (73%)] Loss: -202984.593750\n",
      "Train Epoch: 35 [12720/17352 (73%)] Loss: -168069.500000\n",
      "Train Epoch: 35 [12800/17352 (74%)] Loss: -217619.468750\n",
      "Train Epoch: 35 [12880/17352 (74%)] Loss: -174451.125000\n",
      "Train Epoch: 35 [12960/17352 (75%)] Loss: -191509.375000\n",
      "Train Epoch: 35 [13040/17352 (75%)] Loss: -180836.234375\n",
      "Train Epoch: 35 [13120/17352 (76%)] Loss: -175667.390625\n",
      "Train Epoch: 35 [13200/17352 (76%)] Loss: -200420.078125\n",
      "Train Epoch: 35 [13280/17352 (77%)] Loss: -193908.937500\n",
      "Train Epoch: 35 [13360/17352 (77%)] Loss: -178875.718750\n",
      "Train Epoch: 35 [13440/17352 (77%)] Loss: -188861.531250\n",
      "Train Epoch: 35 [13520/17352 (78%)] Loss: -154605.031250\n",
      "Train Epoch: 35 [13600/17352 (78%)] Loss: -192949.687500\n",
      "Train Epoch: 35 [13680/17352 (79%)] Loss: -184072.812500\n",
      "Train Epoch: 35 [13760/17352 (79%)] Loss: -176916.421875\n",
      "Train Epoch: 35 [13840/17352 (80%)] Loss: -165859.187500\n",
      "Train Epoch: 35 [13920/17352 (80%)] Loss: -184983.515625\n",
      "Train Epoch: 35 [14000/17352 (81%)] Loss: -207820.187500\n",
      "Train Epoch: 35 [14080/17352 (81%)] Loss: -184242.765625\n",
      "Train Epoch: 35 [14160/17352 (82%)] Loss: -174145.765625\n",
      "Train Epoch: 35 [14240/17352 (82%)] Loss: -163249.968750\n",
      "Train Epoch: 35 [14320/17352 (83%)] Loss: -177979.609375\n",
      "Train Epoch: 35 [14400/17352 (83%)] Loss: -228249.718750\n",
      "Train Epoch: 35 [14480/17352 (83%)] Loss: -180050.234375\n",
      "Train Epoch: 35 [14560/17352 (84%)] Loss: -173003.562500\n",
      "Train Epoch: 35 [14640/17352 (84%)] Loss: -183713.640625\n",
      "Train Epoch: 35 [14720/17352 (85%)] Loss: -185162.296875\n",
      "Train Epoch: 35 [14800/17352 (85%)] Loss: -187771.859375\n",
      "Train Epoch: 35 [14880/17352 (86%)] Loss: -180548.781250\n",
      "Train Epoch: 35 [14960/17352 (86%)] Loss: -185546.140625\n",
      "Train Epoch: 35 [15040/17352 (87%)] Loss: -178874.187500\n",
      "Train Epoch: 35 [15120/17352 (87%)] Loss: -167726.000000\n",
      "Train Epoch: 35 [15200/17352 (88%)] Loss: -178306.296875\n",
      "Train Epoch: 35 [15280/17352 (88%)] Loss: -180969.656250\n",
      "Train Epoch: 35 [15360/17352 (89%)] Loss: -178422.015625\n",
      "Train Epoch: 35 [15440/17352 (89%)] Loss: -206090.296875\n",
      "Train Epoch: 35 [15520/17352 (89%)] Loss: -174934.937500\n",
      "Train Epoch: 35 [15600/17352 (90%)] Loss: -178799.937500\n",
      "Train Epoch: 35 [15680/17352 (90%)] Loss: -215417.828125\n",
      "Train Epoch: 35 [15760/17352 (91%)] Loss: -178196.546875\n",
      "Train Epoch: 35 [15840/17352 (91%)] Loss: -171723.062500\n",
      "Train Epoch: 35 [15920/17352 (92%)] Loss: -188492.078125\n",
      "Train Epoch: 35 [16000/17352 (92%)] Loss: -186028.421875\n",
      "Train Epoch: 35 [16080/17352 (93%)] Loss: -202187.609375\n",
      "Train Epoch: 35 [16160/17352 (93%)] Loss: -166253.968750\n",
      "Train Epoch: 35 [16240/17352 (94%)] Loss: -164952.984375\n",
      "Train Epoch: 35 [16320/17352 (94%)] Loss: -191677.984375\n",
      "Train Epoch: 35 [16400/17352 (95%)] Loss: -172188.000000\n",
      "Train Epoch: 35 [16480/17352 (95%)] Loss: -192263.453125\n",
      "Train Epoch: 35 [16560/17352 (95%)] Loss: -201083.750000\n",
      "Train Epoch: 35 [16640/17352 (96%)] Loss: -188050.359375\n",
      "Train Epoch: 35 [16720/17352 (96%)] Loss: -186546.906250\n",
      "Train Epoch: 35 [16800/17352 (97%)] Loss: -148147.375000\n",
      "Train Epoch: 35 [16880/17352 (97%)] Loss: -199447.140625\n",
      "Train Epoch: 35 [16960/17352 (98%)] Loss: -212651.203125\n",
      "Train Epoch: 35 [17040/17352 (98%)] Loss: -197312.875000\n",
      "Train Epoch: 35 [17120/17352 (99%)] Loss: -182743.734375\n",
      "Train Epoch: 35 [17200/17352 (99%)] Loss: -201330.750000\n",
      "Train Epoch: 35 [17280/17352 (100%)] Loss: -179163.015625\n",
      "Train Epoch: 35 [17360/17352 (100%)] Loss: -159674.062500\n",
      "    epoch          : 35\n",
      "    loss           : -188977.81537686996\n",
      "    val_loss       : -23715.318392471527\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch35.pth ...\n",
      "Train Epoch: 36 [0/17352 (0%)] Loss: -199098.906250\n",
      "Train Epoch: 36 [80/17352 (0%)] Loss: -217583.671875\n",
      "Train Epoch: 36 [160/17352 (1%)] Loss: -205923.296875\n",
      "Train Epoch: 36 [240/17352 (1%)] Loss: -241898.562500\n",
      "Train Epoch: 36 [320/17352 (2%)] Loss: -214454.468750\n",
      "Train Epoch: 36 [400/17352 (2%)] Loss: -187717.843750\n",
      "Train Epoch: 36 [480/17352 (3%)] Loss: -216098.843750\n",
      "Train Epoch: 36 [560/17352 (3%)] Loss: -203270.171875\n",
      "Train Epoch: 36 [640/17352 (4%)] Loss: -193017.031250\n",
      "Train Epoch: 36 [720/17352 (4%)] Loss: -230186.812500\n",
      "Train Epoch: 36 [800/17352 (5%)] Loss: -213332.453125\n",
      "Train Epoch: 36 [880/17352 (5%)] Loss: -218528.734375\n",
      "Train Epoch: 36 [960/17352 (6%)] Loss: -214515.500000\n",
      "Train Epoch: 36 [1040/17352 (6%)] Loss: -214707.640625\n",
      "Train Epoch: 36 [1120/17352 (6%)] Loss: -229233.734375\n",
      "Train Epoch: 36 [1200/17352 (7%)] Loss: -213312.031250\n",
      "Train Epoch: 36 [1280/17352 (7%)] Loss: -202029.437500\n",
      "Train Epoch: 36 [1360/17352 (8%)] Loss: -204356.281250\n",
      "Train Epoch: 36 [1440/17352 (8%)] Loss: -193577.906250\n",
      "Train Epoch: 36 [1520/17352 (9%)] Loss: -185290.312500\n",
      "Train Epoch: 36 [1600/17352 (9%)] Loss: -214513.140625\n",
      "Train Epoch: 36 [1680/17352 (10%)] Loss: -209553.156250\n",
      "Train Epoch: 36 [1760/17352 (10%)] Loss: -217620.000000\n",
      "Train Epoch: 36 [1840/17352 (11%)] Loss: -200602.468750\n",
      "Train Epoch: 36 [1920/17352 (11%)] Loss: -193406.890625\n",
      "Train Epoch: 36 [2000/17352 (12%)] Loss: -215829.578125\n",
      "Train Epoch: 36 [2080/17352 (12%)] Loss: -202312.718750\n",
      "Train Epoch: 36 [2160/17352 (12%)] Loss: -236831.062500\n",
      "Train Epoch: 36 [2240/17352 (13%)] Loss: -196123.156250\n",
      "Train Epoch: 36 [2320/17352 (13%)] Loss: -192242.171875\n",
      "Train Epoch: 36 [2400/17352 (14%)] Loss: -220973.718750\n",
      "Train Epoch: 36 [2480/17352 (14%)] Loss: -182731.718750\n",
      "Train Epoch: 36 [2560/17352 (15%)] Loss: -204339.484375\n",
      "Train Epoch: 36 [2640/17352 (15%)] Loss: -148156.843750\n",
      "Train Epoch: 36 [2720/17352 (16%)] Loss: -181922.062500\n",
      "Train Epoch: 36 [2800/17352 (16%)] Loss: -195050.984375\n",
      "Train Epoch: 36 [2880/17352 (17%)] Loss: -168194.000000\n",
      "Train Epoch: 36 [2960/17352 (17%)] Loss: -193360.468750\n",
      "Train Epoch: 36 [3040/17352 (18%)] Loss: -182772.375000\n",
      "Train Epoch: 36 [3120/17352 (18%)] Loss: -208030.593750\n",
      "Train Epoch: 36 [3200/17352 (18%)] Loss: -188864.187500\n",
      "Train Epoch: 36 [3280/17352 (19%)] Loss: -176964.625000\n",
      "Train Epoch: 36 [3360/17352 (19%)] Loss: -160045.828125\n",
      "Train Epoch: 36 [3440/17352 (20%)] Loss: -163775.562500\n",
      "Train Epoch: 36 [3520/17352 (20%)] Loss: -188671.718750\n",
      "Train Epoch: 36 [3600/17352 (21%)] Loss: -189477.437500\n",
      "Train Epoch: 36 [3680/17352 (21%)] Loss: -200110.515625\n",
      "Train Epoch: 36 [3760/17352 (22%)] Loss: -179733.171875\n",
      "Train Epoch: 36 [3840/17352 (22%)] Loss: -192007.468750\n",
      "Train Epoch: 36 [3920/17352 (23%)] Loss: -142612.062500\n",
      "Train Epoch: 36 [4000/17352 (23%)] Loss: -201373.421875\n",
      "Train Epoch: 36 [4080/17352 (24%)] Loss: -201120.296875\n",
      "Train Epoch: 36 [4160/17352 (24%)] Loss: -175403.796875\n",
      "Train Epoch: 36 [4240/17352 (24%)] Loss: -185435.359375\n",
      "Train Epoch: 36 [4320/17352 (25%)] Loss: -200418.453125\n",
      "Train Epoch: 36 [4400/17352 (25%)] Loss: -208016.343750\n",
      "Train Epoch: 36 [4480/17352 (26%)] Loss: -165797.250000\n",
      "Train Epoch: 36 [4560/17352 (26%)] Loss: -197541.937500\n",
      "Train Epoch: 36 [4640/17352 (27%)] Loss: -172887.781250\n",
      "Train Epoch: 36 [4720/17352 (27%)] Loss: -181007.437500\n",
      "Train Epoch: 36 [4800/17352 (28%)] Loss: -189785.484375\n",
      "Train Epoch: 36 [4880/17352 (28%)] Loss: -194601.921875\n",
      "Train Epoch: 36 [4960/17352 (29%)] Loss: -171434.062500\n",
      "Train Epoch: 36 [5040/17352 (29%)] Loss: -172236.375000\n",
      "Train Epoch: 36 [5120/17352 (30%)] Loss: -189533.156250\n",
      "Train Epoch: 36 [5200/17352 (30%)] Loss: -178805.984375\n",
      "Train Epoch: 36 [5280/17352 (30%)] Loss: -148829.296875\n",
      "Train Epoch: 36 [5360/17352 (31%)] Loss: -200166.078125\n",
      "Train Epoch: 36 [5440/17352 (31%)] Loss: -191882.484375\n",
      "Train Epoch: 36 [5520/17352 (32%)] Loss: -204942.937500\n",
      "Train Epoch: 36 [5600/17352 (32%)] Loss: -148446.359375\n",
      "Train Epoch: 36 [5680/17352 (33%)] Loss: -190803.281250\n",
      "Train Epoch: 36 [5760/17352 (33%)] Loss: -185789.359375\n",
      "Train Epoch: 36 [5840/17352 (34%)] Loss: -205806.234375\n",
      "Train Epoch: 36 [5920/17352 (34%)] Loss: -208719.171875\n",
      "Train Epoch: 36 [6000/17352 (35%)] Loss: -171718.437500\n",
      "Train Epoch: 36 [6080/17352 (35%)] Loss: -207091.843750\n",
      "Train Epoch: 36 [6160/17352 (36%)] Loss: -213236.562500\n",
      "Train Epoch: 36 [6240/17352 (36%)] Loss: -192385.109375\n",
      "Train Epoch: 36 [6320/17352 (36%)] Loss: -189484.937500\n",
      "Train Epoch: 36 [6400/17352 (37%)] Loss: -190082.687500\n",
      "Train Epoch: 36 [6480/17352 (37%)] Loss: -194939.296875\n",
      "Train Epoch: 36 [6560/17352 (38%)] Loss: -179383.656250\n",
      "Train Epoch: 36 [6640/17352 (38%)] Loss: -174141.031250\n",
      "Train Epoch: 36 [6720/17352 (39%)] Loss: -198832.234375\n",
      "Train Epoch: 36 [6800/17352 (39%)] Loss: -168671.296875\n",
      "Train Epoch: 36 [6880/17352 (40%)] Loss: -187261.796875\n",
      "Train Epoch: 36 [6960/17352 (40%)] Loss: -181339.250000\n",
      "Train Epoch: 36 [7040/17352 (41%)] Loss: -184477.281250\n",
      "Train Epoch: 36 [7120/17352 (41%)] Loss: -196446.109375\n",
      "Train Epoch: 36 [7200/17352 (41%)] Loss: -173842.937500\n",
      "Train Epoch: 36 [7280/17352 (42%)] Loss: -185497.031250\n",
      "Train Epoch: 36 [7360/17352 (42%)] Loss: -167872.375000\n",
      "Train Epoch: 36 [7440/17352 (43%)] Loss: -201322.046875\n",
      "Train Epoch: 36 [7520/17352 (43%)] Loss: -195828.281250\n",
      "Train Epoch: 36 [7600/17352 (44%)] Loss: -192279.187500\n",
      "Train Epoch: 36 [7680/17352 (44%)] Loss: -199510.453125\n",
      "Train Epoch: 36 [7760/17352 (45%)] Loss: -208299.390625\n",
      "Train Epoch: 36 [7840/17352 (45%)] Loss: -204491.500000\n",
      "Train Epoch: 36 [7920/17352 (46%)] Loss: -165736.031250\n",
      "Train Epoch: 36 [8000/17352 (46%)] Loss: -193047.937500\n",
      "Train Epoch: 36 [8080/17352 (47%)] Loss: -170527.671875\n",
      "Train Epoch: 36 [8160/17352 (47%)] Loss: -206243.453125\n",
      "Train Epoch: 36 [8240/17352 (47%)] Loss: -176039.593750\n",
      "Train Epoch: 36 [8320/17352 (48%)] Loss: -199446.140625\n",
      "Train Epoch: 36 [8400/17352 (48%)] Loss: -211168.375000\n",
      "Train Epoch: 36 [8480/17352 (49%)] Loss: -203508.125000\n",
      "Train Epoch: 36 [8560/17352 (49%)] Loss: -178727.453125\n",
      "Train Epoch: 36 [8640/17352 (50%)] Loss: -187491.015625\n",
      "Train Epoch: 36 [8720/17352 (50%)] Loss: -173662.015625\n",
      "Train Epoch: 36 [8800/17352 (51%)] Loss: -200400.859375\n",
      "Train Epoch: 36 [8880/17352 (51%)] Loss: -196191.765625\n",
      "Train Epoch: 36 [8960/17352 (52%)] Loss: -192108.062500\n",
      "Train Epoch: 36 [9040/17352 (52%)] Loss: -191669.265625\n",
      "Train Epoch: 36 [9120/17352 (53%)] Loss: -180830.375000\n",
      "Train Epoch: 36 [9200/17352 (53%)] Loss: -171416.781250\n",
      "Train Epoch: 36 [9280/17352 (53%)] Loss: -177728.000000\n",
      "Train Epoch: 36 [9360/17352 (54%)] Loss: -193044.437500\n",
      "Train Epoch: 36 [9440/17352 (54%)] Loss: -196945.906250\n",
      "Train Epoch: 36 [9520/17352 (55%)] Loss: -189018.203125\n",
      "Train Epoch: 36 [9600/17352 (55%)] Loss: -203259.312500\n",
      "Train Epoch: 36 [9680/17352 (56%)] Loss: -188972.187500\n",
      "Train Epoch: 36 [9760/17352 (56%)] Loss: -170103.640625\n",
      "Train Epoch: 36 [9840/17352 (57%)] Loss: -180162.671875\n",
      "Train Epoch: 36 [9920/17352 (57%)] Loss: -193180.421875\n",
      "Train Epoch: 36 [10000/17352 (58%)] Loss: -177192.937500\n",
      "Train Epoch: 36 [10080/17352 (58%)] Loss: -227883.828125\n",
      "Train Epoch: 36 [10160/17352 (59%)] Loss: -179498.890625\n",
      "Train Epoch: 36 [10240/17352 (59%)] Loss: -187273.515625\n",
      "Train Epoch: 36 [10320/17352 (59%)] Loss: -202598.093750\n",
      "Train Epoch: 36 [10400/17352 (60%)] Loss: -187307.843750\n",
      "Train Epoch: 36 [10480/17352 (60%)] Loss: -177165.468750\n",
      "Train Epoch: 36 [10560/17352 (61%)] Loss: -151509.625000\n",
      "Train Epoch: 36 [10640/17352 (61%)] Loss: -189596.578125\n",
      "Train Epoch: 36 [10720/17352 (62%)] Loss: -168956.750000\n",
      "Train Epoch: 36 [10800/17352 (62%)] Loss: -202871.796875\n",
      "Train Epoch: 36 [10880/17352 (63%)] Loss: -152903.703125\n",
      "Train Epoch: 36 [10960/17352 (63%)] Loss: -200635.296875\n",
      "Train Epoch: 36 [11040/17352 (64%)] Loss: -169943.671875\n",
      "Train Epoch: 36 [11120/17352 (64%)] Loss: -190007.078125\n",
      "Train Epoch: 36 [11200/17352 (65%)] Loss: -170305.234375\n",
      "Train Epoch: 36 [11280/17352 (65%)] Loss: -214641.562500\n",
      "Train Epoch: 36 [11360/17352 (65%)] Loss: -184752.718750\n",
      "Train Epoch: 36 [11440/17352 (66%)] Loss: -173301.656250\n",
      "Train Epoch: 36 [11520/17352 (66%)] Loss: -197089.484375\n",
      "Train Epoch: 36 [11600/17352 (67%)] Loss: -195502.875000\n",
      "Train Epoch: 36 [11680/17352 (67%)] Loss: -197297.875000\n",
      "Train Epoch: 36 [11760/17352 (68%)] Loss: -172181.343750\n",
      "Train Epoch: 36 [11840/17352 (68%)] Loss: -171304.390625\n",
      "Train Epoch: 36 [11920/17352 (69%)] Loss: -172549.765625\n",
      "Train Epoch: 36 [12000/17352 (69%)] Loss: -183497.531250\n",
      "Train Epoch: 36 [12080/17352 (70%)] Loss: -188261.328125\n",
      "Train Epoch: 36 [12160/17352 (70%)] Loss: -189395.406250\n",
      "Train Epoch: 36 [12240/17352 (71%)] Loss: -191563.312500\n",
      "Train Epoch: 36 [12320/17352 (71%)] Loss: -171547.906250\n",
      "Train Epoch: 36 [12400/17352 (71%)] Loss: -183606.453125\n",
      "Train Epoch: 36 [12480/17352 (72%)] Loss: -191811.656250\n",
      "Train Epoch: 36 [12560/17352 (72%)] Loss: -195719.234375\n",
      "Train Epoch: 36 [12640/17352 (73%)] Loss: -181750.015625\n",
      "Train Epoch: 36 [12720/17352 (73%)] Loss: -182321.765625\n",
      "Train Epoch: 36 [12800/17352 (74%)] Loss: -159743.781250\n",
      "Train Epoch: 36 [12880/17352 (74%)] Loss: -202980.453125\n",
      "Train Epoch: 36 [12960/17352 (75%)] Loss: -216312.359375\n",
      "Train Epoch: 36 [13040/17352 (75%)] Loss: -178815.781250\n",
      "Train Epoch: 36 [13120/17352 (76%)] Loss: -191354.375000\n",
      "Train Epoch: 36 [13200/17352 (76%)] Loss: -174189.843750\n",
      "Train Epoch: 36 [13280/17352 (77%)] Loss: -200976.890625\n",
      "Train Epoch: 36 [13360/17352 (77%)] Loss: -213737.671875\n",
      "Train Epoch: 36 [13440/17352 (77%)] Loss: -206149.437500\n",
      "Train Epoch: 36 [13520/17352 (78%)] Loss: -171894.937500\n",
      "Train Epoch: 36 [13600/17352 (78%)] Loss: -185592.578125\n",
      "Train Epoch: 36 [13680/17352 (79%)] Loss: -210148.656250\n",
      "Train Epoch: 36 [13760/17352 (79%)] Loss: -189799.000000\n",
      "Train Epoch: 36 [13840/17352 (80%)] Loss: -177782.296875\n",
      "Train Epoch: 36 [13920/17352 (80%)] Loss: -196728.265625\n",
      "Train Epoch: 36 [14000/17352 (81%)] Loss: -209187.062500\n",
      "Train Epoch: 36 [14080/17352 (81%)] Loss: -191826.968750\n",
      "Train Epoch: 36 [14160/17352 (82%)] Loss: -169964.765625\n",
      "Train Epoch: 36 [14240/17352 (82%)] Loss: -188271.421875\n",
      "Train Epoch: 36 [14320/17352 (83%)] Loss: -182734.218750\n",
      "Train Epoch: 36 [14400/17352 (83%)] Loss: -170678.906250\n",
      "Train Epoch: 36 [14480/17352 (83%)] Loss: -170233.406250\n",
      "Train Epoch: 36 [14560/17352 (84%)] Loss: -190997.718750\n",
      "Train Epoch: 36 [14640/17352 (84%)] Loss: -203463.484375\n",
      "Train Epoch: 36 [14720/17352 (85%)] Loss: -186562.312500\n",
      "Train Epoch: 36 [14800/17352 (85%)] Loss: -164824.687500\n",
      "Train Epoch: 36 [14880/17352 (86%)] Loss: -149439.843750\n",
      "Train Epoch: 36 [14960/17352 (86%)] Loss: -212969.734375\n",
      "Train Epoch: 36 [15040/17352 (87%)] Loss: -209816.875000\n",
      "Train Epoch: 36 [15120/17352 (87%)] Loss: -207851.437500\n",
      "Train Epoch: 36 [15200/17352 (88%)] Loss: -202940.453125\n",
      "Train Epoch: 36 [15280/17352 (88%)] Loss: -156470.984375\n",
      "Train Epoch: 36 [15360/17352 (89%)] Loss: -184596.234375\n",
      "Train Epoch: 36 [15440/17352 (89%)] Loss: -199172.484375\n",
      "Train Epoch: 36 [15520/17352 (89%)] Loss: -192122.328125\n",
      "Train Epoch: 36 [15600/17352 (90%)] Loss: -181338.234375\n",
      "Train Epoch: 36 [15680/17352 (90%)] Loss: -197944.671875\n",
      "Train Epoch: 36 [15760/17352 (91%)] Loss: -178366.812500\n",
      "Train Epoch: 36 [15840/17352 (91%)] Loss: -210260.390625\n",
      "Train Epoch: 36 [15920/17352 (92%)] Loss: -187313.796875\n",
      "Train Epoch: 36 [16000/17352 (92%)] Loss: -173584.031250\n",
      "Train Epoch: 36 [16080/17352 (93%)] Loss: -199601.890625\n",
      "Train Epoch: 36 [16160/17352 (93%)] Loss: -175594.859375\n",
      "Train Epoch: 36 [16240/17352 (94%)] Loss: -176140.343750\n",
      "Train Epoch: 36 [16320/17352 (94%)] Loss: -187531.031250\n",
      "Train Epoch: 36 [16400/17352 (95%)] Loss: -190912.062500\n",
      "Train Epoch: 36 [16480/17352 (95%)] Loss: -185234.671875\n",
      "Train Epoch: 36 [16560/17352 (95%)] Loss: -175502.343750\n",
      "Train Epoch: 36 [16640/17352 (96%)] Loss: -179311.890625\n",
      "Train Epoch: 36 [16720/17352 (96%)] Loss: -184163.296875\n",
      "Train Epoch: 36 [16800/17352 (97%)] Loss: -196250.062500\n",
      "Train Epoch: 36 [16880/17352 (97%)] Loss: -203883.750000\n",
      "Train Epoch: 36 [16960/17352 (98%)] Loss: -183050.500000\n",
      "Train Epoch: 36 [17040/17352 (98%)] Loss: -176902.000000\n",
      "Train Epoch: 36 [17120/17352 (99%)] Loss: -208758.218750\n",
      "Train Epoch: 36 [17200/17352 (99%)] Loss: -197586.843750\n",
      "Train Epoch: 36 [17280/17352 (100%)] Loss: -184250.718750\n",
      "Train Epoch: 36 [17360/17352 (100%)] Loss: -177766.000000\n",
      "    epoch          : 36\n",
      "    loss           : -189351.88852128884\n",
      "    val_loss       : -23715.484600514872\n",
      "Train Epoch: 37 [0/17352 (0%)] Loss: -215832.109375\n",
      "Train Epoch: 37 [80/17352 (0%)] Loss: -193570.671875\n",
      "Train Epoch: 37 [160/17352 (1%)] Loss: -206547.484375\n",
      "Train Epoch: 37 [240/17352 (1%)] Loss: -185294.578125\n",
      "Train Epoch: 37 [320/17352 (2%)] Loss: -218534.593750\n",
      "Train Epoch: 37 [400/17352 (2%)] Loss: -214404.578125\n",
      "Train Epoch: 37 [480/17352 (3%)] Loss: -216089.968750\n",
      "Train Epoch: 37 [560/17352 (3%)] Loss: -213317.953125\n",
      "Train Epoch: 37 [640/17352 (4%)] Loss: -206647.281250\n",
      "Train Epoch: 37 [720/17352 (4%)] Loss: -228022.078125\n",
      "Train Epoch: 37 [800/17352 (5%)] Loss: -204528.890625\n",
      "Train Epoch: 37 [880/17352 (5%)] Loss: -217622.687500\n",
      "Train Epoch: 37 [960/17352 (6%)] Loss: -182773.390625\n",
      "Train Epoch: 37 [1040/17352 (6%)] Loss: -193406.250000\n",
      "Train Epoch: 37 [1120/17352 (6%)] Loss: -219660.515625\n",
      "Train Epoch: 37 [1200/17352 (7%)] Loss: -185153.828125\n",
      "Train Epoch: 37 [1280/17352 (7%)] Loss: -214452.312500\n",
      "Train Epoch: 37 [1360/17352 (8%)] Loss: -210201.703125\n",
      "Train Epoch: 37 [1440/17352 (8%)] Loss: -206127.109375\n",
      "Train Epoch: 37 [1520/17352 (9%)] Loss: -224244.109375\n",
      "Train Epoch: 37 [1600/17352 (9%)] Loss: -199917.546875\n",
      "Train Epoch: 37 [1680/17352 (10%)] Loss: -214514.171875\n",
      "Train Epoch: 37 [1760/17352 (10%)] Loss: -236503.812500\n",
      "Train Epoch: 37 [1840/17352 (11%)] Loss: -219207.750000\n",
      "Train Epoch: 37 [1920/17352 (11%)] Loss: -196422.218750\n",
      "Train Epoch: 37 [2000/17352 (12%)] Loss: -213338.390625\n",
      "Train Epoch: 37 [2080/17352 (12%)] Loss: -212400.203125\n",
      "Train Epoch: 37 [2160/17352 (12%)] Loss: -214332.343750\n",
      "Train Epoch: 37 [2240/17352 (13%)] Loss: -173938.921875\n",
      "Train Epoch: 37 [2320/17352 (13%)] Loss: -186034.171875\n",
      "Train Epoch: 37 [2400/17352 (14%)] Loss: -222857.062500\n",
      "Train Epoch: 37 [2480/17352 (14%)] Loss: -196812.546875\n",
      "Train Epoch: 37 [2560/17352 (15%)] Loss: -183072.515625\n",
      "Train Epoch: 37 [2640/17352 (15%)] Loss: -208040.015625\n",
      "Train Epoch: 37 [2720/17352 (16%)] Loss: -216386.906250\n",
      "Train Epoch: 37 [2800/17352 (16%)] Loss: -163109.171875\n",
      "Train Epoch: 37 [2880/17352 (17%)] Loss: -199780.218750\n",
      "Train Epoch: 37 [2960/17352 (17%)] Loss: -193943.265625\n",
      "Train Epoch: 37 [3040/17352 (18%)] Loss: -231031.328125\n",
      "Train Epoch: 37 [3120/17352 (18%)] Loss: -192310.609375\n",
      "Train Epoch: 37 [3200/17352 (18%)] Loss: -202190.406250\n",
      "Train Epoch: 37 [3280/17352 (19%)] Loss: -175596.093750\n",
      "Train Epoch: 37 [3360/17352 (19%)] Loss: -214755.484375\n",
      "Train Epoch: 37 [3440/17352 (20%)] Loss: -192269.125000\n",
      "Train Epoch: 37 [3520/17352 (20%)] Loss: -206205.078125\n",
      "Train Epoch: 37 [3600/17352 (21%)] Loss: -188800.515625\n",
      "Train Epoch: 37 [3680/17352 (21%)] Loss: -205206.250000\n",
      "Train Epoch: 37 [3760/17352 (22%)] Loss: -173115.484375\n",
      "Train Epoch: 37 [3840/17352 (22%)] Loss: -200200.359375\n",
      "Train Epoch: 37 [3920/17352 (23%)] Loss: -212619.671875\n",
      "Train Epoch: 37 [4000/17352 (23%)] Loss: -173892.531250\n",
      "Train Epoch: 37 [4080/17352 (24%)] Loss: -177192.281250\n",
      "Train Epoch: 37 [4160/17352 (24%)] Loss: -203882.218750\n",
      "Train Epoch: 37 [4240/17352 (24%)] Loss: -178867.171875\n",
      "Train Epoch: 37 [4320/17352 (25%)] Loss: -168999.265625\n",
      "Train Epoch: 37 [4400/17352 (25%)] Loss: -179739.375000\n",
      "Train Epoch: 37 [4480/17352 (26%)] Loss: -198014.515625\n",
      "Train Epoch: 37 [4560/17352 (26%)] Loss: -171410.046875\n",
      "Train Epoch: 37 [4640/17352 (27%)] Loss: -159674.187500\n",
      "Train Epoch: 37 [4720/17352 (27%)] Loss: -197302.281250\n",
      "Train Epoch: 37 [4800/17352 (28%)] Loss: -201382.609375\n",
      "Train Epoch: 37 [4880/17352 (28%)] Loss: -209200.765625\n",
      "Train Epoch: 37 [4960/17352 (29%)] Loss: -192896.671875\n",
      "Train Epoch: 37 [5040/17352 (29%)] Loss: -203803.921875\n",
      "Train Epoch: 37 [5120/17352 (30%)] Loss: -205020.656250\n",
      "Train Epoch: 37 [5200/17352 (30%)] Loss: -197333.718750\n",
      "Train Epoch: 37 [5280/17352 (30%)] Loss: -217592.531250\n",
      "Train Epoch: 37 [5360/17352 (31%)] Loss: -192243.718750\n",
      "Train Epoch: 37 [5440/17352 (31%)] Loss: -214957.984375\n",
      "Train Epoch: 37 [5520/17352 (32%)] Loss: -185795.281250\n",
      "Train Epoch: 37 [5600/17352 (32%)] Loss: -184736.968750\n",
      "Train Epoch: 37 [5680/17352 (33%)] Loss: -183920.281250\n",
      "Train Epoch: 37 [5760/17352 (33%)] Loss: -187785.187500\n",
      "Train Epoch: 37 [5840/17352 (34%)] Loss: -177762.171875\n",
      "Train Epoch: 37 [5920/17352 (34%)] Loss: -189538.312500\n",
      "Train Epoch: 37 [6000/17352 (35%)] Loss: -170226.984375\n",
      "Train Epoch: 37 [6080/17352 (35%)] Loss: -194991.593750\n",
      "Train Epoch: 37 [6160/17352 (36%)] Loss: -189215.531250\n",
      "Train Epoch: 37 [6240/17352 (36%)] Loss: -201835.703125\n",
      "Train Epoch: 37 [6320/17352 (36%)] Loss: -191952.828125\n",
      "Train Epoch: 37 [6400/17352 (37%)] Loss: -193360.703125\n",
      "Train Epoch: 37 [6480/17352 (37%)] Loss: -160146.234375\n",
      "Train Epoch: 37 [6560/17352 (38%)] Loss: -201300.875000\n",
      "Train Epoch: 37 [6640/17352 (38%)] Loss: -177306.312500\n",
      "Train Epoch: 37 [6720/17352 (39%)] Loss: -185430.437500\n",
      "Train Epoch: 37 [6800/17352 (39%)] Loss: -173581.734375\n",
      "Train Epoch: 37 [6880/17352 (40%)] Loss: -187203.531250\n",
      "Train Epoch: 37 [6960/17352 (40%)] Loss: -188749.234375\n",
      "Train Epoch: 37 [7040/17352 (41%)] Loss: -201964.734375\n",
      "Train Epoch: 37 [7120/17352 (41%)] Loss: -190235.546875\n",
      "Train Epoch: 37 [7200/17352 (41%)] Loss: -200856.390625\n",
      "Train Epoch: 37 [7280/17352 (42%)] Loss: -183752.093750\n",
      "Train Epoch: 37 [7360/17352 (42%)] Loss: -179001.500000\n",
      "Train Epoch: 37 [7440/17352 (43%)] Loss: -156479.734375\n",
      "Train Epoch: 37 [7520/17352 (43%)] Loss: -191680.109375\n",
      "Train Epoch: 37 [7600/17352 (44%)] Loss: -200973.203125\n",
      "Train Epoch: 37 [7680/17352 (44%)] Loss: -170096.312500\n",
      "Train Epoch: 37 [7760/17352 (45%)] Loss: -178659.796875\n",
      "Train Epoch: 37 [7840/17352 (45%)] Loss: -159689.312500\n",
      "Train Epoch: 37 [7920/17352 (46%)] Loss: -201265.890625\n",
      "Train Epoch: 37 [8000/17352 (46%)] Loss: -178821.203125\n",
      "Train Epoch: 37 [8080/17352 (47%)] Loss: -183407.468750\n",
      "Train Epoch: 37 [8160/17352 (47%)] Loss: -165731.375000\n",
      "Train Epoch: 37 [8240/17352 (47%)] Loss: -179442.828125\n",
      "Train Epoch: 37 [8320/17352 (48%)] Loss: -172958.093750\n",
      "Train Epoch: 37 [8400/17352 (48%)] Loss: -157587.531250\n",
      "Train Epoch: 37 [8480/17352 (49%)] Loss: -167236.781250\n",
      "Train Epoch: 37 [8560/17352 (49%)] Loss: -188857.843750\n",
      "Train Epoch: 37 [8640/17352 (50%)] Loss: -179304.093750\n",
      "Train Epoch: 37 [8720/17352 (50%)] Loss: -158744.906250\n",
      "Train Epoch: 37 [8800/17352 (51%)] Loss: -170542.187500\n",
      "Train Epoch: 37 [8880/17352 (51%)] Loss: -201374.062500\n",
      "Train Epoch: 37 [8960/17352 (52%)] Loss: -188005.234375\n",
      "Train Epoch: 37 [9040/17352 (52%)] Loss: -185052.937500\n",
      "Train Epoch: 37 [9120/17352 (53%)] Loss: -191511.734375\n",
      "Train Epoch: 37 [9200/17352 (53%)] Loss: -204599.625000\n",
      "Train Epoch: 37 [9280/17352 (53%)] Loss: -165791.625000\n",
      "Train Epoch: 37 [9360/17352 (54%)] Loss: -200304.843750\n",
      "Train Epoch: 37 [9440/17352 (54%)] Loss: -190615.625000\n",
      "Train Epoch: 37 [9520/17352 (55%)] Loss: -152901.375000\n",
      "Train Epoch: 37 [9600/17352 (55%)] Loss: -168766.703125\n",
      "Train Epoch: 37 [9680/17352 (56%)] Loss: -206213.687500\n",
      "Train Epoch: 37 [9760/17352 (56%)] Loss: -179888.531250\n",
      "Train Epoch: 37 [9840/17352 (57%)] Loss: -183366.218750\n",
      "Train Epoch: 37 [9920/17352 (57%)] Loss: -164799.125000\n",
      "Train Epoch: 37 [10000/17352 (58%)] Loss: -201092.593750\n",
      "Train Epoch: 37 [10080/17352 (58%)] Loss: -207827.218750\n",
      "Train Epoch: 37 [10160/17352 (59%)] Loss: -186684.890625\n",
      "Train Epoch: 37 [10240/17352 (59%)] Loss: -198822.312500\n",
      "Train Epoch: 37 [10320/17352 (59%)] Loss: -196240.812500\n",
      "Train Epoch: 37 [10400/17352 (60%)] Loss: -151222.109375\n",
      "Train Epoch: 37 [10480/17352 (60%)] Loss: -220963.781250\n",
      "Train Epoch: 37 [10560/17352 (61%)] Loss: -178193.109375\n",
      "Train Epoch: 37 [10640/17352 (61%)] Loss: -166781.765625\n",
      "Train Epoch: 37 [10720/17352 (62%)] Loss: -199067.015625\n",
      "Train Epoch: 37 [10800/17352 (62%)] Loss: -193486.265625\n",
      "Train Epoch: 37 [10880/17352 (63%)] Loss: -181696.656250\n",
      "Train Epoch: 37 [10960/17352 (63%)] Loss: -188177.718750\n",
      "Train Epoch: 37 [11040/17352 (64%)] Loss: -188493.703125\n",
      "Train Epoch: 37 [11120/17352 (64%)] Loss: -192985.703125\n",
      "Train Epoch: 37 [11200/17352 (65%)] Loss: -190005.687500\n",
      "Train Epoch: 37 [11280/17352 (65%)] Loss: -165598.562500\n",
      "Train Epoch: 37 [11360/17352 (65%)] Loss: -205396.046875\n",
      "Train Epoch: 37 [11440/17352 (66%)] Loss: -197540.125000\n",
      "Train Epoch: 37 [11520/17352 (66%)] Loss: -169753.546875\n",
      "Train Epoch: 37 [11600/17352 (67%)] Loss: -169501.765625\n",
      "Train Epoch: 37 [11680/17352 (67%)] Loss: -175752.656250\n",
      "Train Epoch: 37 [11760/17352 (68%)] Loss: -190476.062500\n",
      "Train Epoch: 37 [11840/17352 (68%)] Loss: -187317.625000\n",
      "Train Epoch: 37 [11920/17352 (69%)] Loss: -170304.062500\n",
      "Train Epoch: 37 [12000/17352 (69%)] Loss: -172884.187500\n",
      "Train Epoch: 37 [12080/17352 (70%)] Loss: -199439.906250\n",
      "Train Epoch: 37 [12160/17352 (70%)] Loss: -174930.500000\n",
      "Train Epoch: 37 [12240/17352 (71%)] Loss: -207860.312500\n",
      "Train Epoch: 37 [12320/17352 (71%)] Loss: -164079.109375\n",
      "Train Epoch: 37 [12400/17352 (71%)] Loss: -188201.781250\n",
      "Train Epoch: 37 [12480/17352 (72%)] Loss: -190506.015625\n",
      "Train Epoch: 37 [12560/17352 (72%)] Loss: -159732.562500\n",
      "Train Epoch: 37 [12640/17352 (73%)] Loss: -189506.453125\n",
      "Train Epoch: 37 [12720/17352 (73%)] Loss: -184988.093750\n",
      "Train Epoch: 37 [12800/17352 (74%)] Loss: -148151.937500\n",
      "Train Epoch: 37 [12880/17352 (74%)] Loss: -173357.625000\n",
      "Train Epoch: 37 [12960/17352 (75%)] Loss: -194945.171875\n",
      "Train Epoch: 37 [13040/17352 (75%)] Loss: -173504.625000\n",
      "Train Epoch: 37 [13120/17352 (76%)] Loss: -205166.125000\n",
      "Train Epoch: 37 [13200/17352 (76%)] Loss: -189561.031250\n",
      "Train Epoch: 37 [13280/17352 (77%)] Loss: -180644.437500\n",
      "Train Epoch: 37 [13360/17352 (77%)] Loss: -175659.093750\n",
      "Train Epoch: 37 [13440/17352 (77%)] Loss: -189481.546875\n",
      "Train Epoch: 37 [13520/17352 (78%)] Loss: -218467.921875\n",
      "Train Epoch: 37 [13600/17352 (78%)] Loss: -209259.593750\n",
      "Train Epoch: 37 [13680/17352 (79%)] Loss: -191038.046875\n",
      "Train Epoch: 37 [13760/17352 (79%)] Loss: -162720.359375\n",
      "Train Epoch: 37 [13840/17352 (80%)] Loss: -175670.625000\n",
      "Train Epoch: 37 [13920/17352 (80%)] Loss: -159308.843750\n",
      "Train Epoch: 37 [14000/17352 (81%)] Loss: -186037.734375\n",
      "Train Epoch: 37 [14080/17352 (81%)] Loss: -213394.812500\n",
      "Train Epoch: 37 [14160/17352 (82%)] Loss: -225467.656250\n",
      "Train Epoch: 37 [14240/17352 (82%)] Loss: -168960.765625\n",
      "Train Epoch: 37 [14320/17352 (83%)] Loss: -192989.453125\n",
      "Train Epoch: 37 [14400/17352 (83%)] Loss: -192115.390625\n",
      "Train Epoch: 37 [14480/17352 (83%)] Loss: -199783.296875\n",
      "Train Epoch: 37 [14560/17352 (84%)] Loss: -218841.546875\n",
      "Train Epoch: 37 [14640/17352 (84%)] Loss: -131043.890625\n",
      "Train Epoch: 37 [14720/17352 (85%)] Loss: -177234.703125\n",
      "Train Epoch: 37 [14800/17352 (85%)] Loss: -202940.109375\n",
      "Train Epoch: 37 [14880/17352 (86%)] Loss: -183061.046875\n",
      "Train Epoch: 37 [14960/17352 (86%)] Loss: -207112.843750\n",
      "Train Epoch: 37 [15040/17352 (87%)] Loss: -185263.609375\n",
      "Train Epoch: 37 [15120/17352 (87%)] Loss: -167072.609375\n",
      "Train Epoch: 37 [15200/17352 (88%)] Loss: -200165.500000\n",
      "Train Epoch: 37 [15280/17352 (88%)] Loss: -200325.625000\n",
      "Train Epoch: 37 [15360/17352 (89%)] Loss: -151509.125000\n",
      "Train Epoch: 37 [15440/17352 (89%)] Loss: -193173.000000\n",
      "Train Epoch: 37 [15520/17352 (89%)] Loss: -227885.750000\n",
      "Train Epoch: 37 [15600/17352 (90%)] Loss: -174183.390625\n",
      "Train Epoch: 37 [15680/17352 (90%)] Loss: -171321.218750\n",
      "Train Epoch: 37 [15760/17352 (91%)] Loss: -163497.218750\n",
      "Train Epoch: 37 [15840/17352 (91%)] Loss: -166002.953125\n",
      "Train Epoch: 37 [15920/17352 (92%)] Loss: -203142.140625\n",
      "Train Epoch: 37 [16000/17352 (92%)] Loss: -179964.203125\n",
      "Train Epoch: 37 [16080/17352 (93%)] Loss: -221258.703125\n",
      "Train Epoch: 37 [16160/17352 (93%)] Loss: -181921.187500\n",
      "Train Epoch: 37 [16240/17352 (94%)] Loss: -165762.796875\n",
      "Train Epoch: 37 [16320/17352 (94%)] Loss: -172193.406250\n",
      "Train Epoch: 37 [16400/17352 (95%)] Loss: -196021.515625\n",
      "Train Epoch: 37 [16480/17352 (95%)] Loss: -148823.312500\n",
      "Train Epoch: 37 [16560/17352 (95%)] Loss: -183224.671875\n",
      "Train Epoch: 37 [16640/17352 (96%)] Loss: -200074.250000\n",
      "Train Epoch: 37 [16720/17352 (96%)] Loss: -182774.984375\n",
      "Train Epoch: 37 [16800/17352 (97%)] Loss: -178095.812500\n",
      "Train Epoch: 37 [16880/17352 (97%)] Loss: -171829.984375\n",
      "Train Epoch: 37 [16960/17352 (98%)] Loss: -173036.718750\n",
      "Train Epoch: 37 [17040/17352 (98%)] Loss: -167482.906250\n",
      "Train Epoch: 37 [17120/17352 (99%)] Loss: -180254.453125\n",
      "Train Epoch: 37 [17200/17352 (99%)] Loss: -184758.687500\n",
      "Train Epoch: 37 [17280/17352 (100%)] Loss: -208020.437500\n",
      "Train Epoch: 37 [17360/17352 (100%)] Loss: -187275.765625\n",
      "    epoch          : 37\n",
      "    loss           : -189646.9733350115\n",
      "    val_loss       : -23715.24604346047\n",
      "Train Epoch: 38 [0/17352 (0%)] Loss: -236825.000000\n",
      "Train Epoch: 38 [80/17352 (0%)] Loss: -221750.437500\n",
      "Train Epoch: 38 [160/17352 (1%)] Loss: -188746.937500\n",
      "Train Epoch: 38 [240/17352 (1%)] Loss: -212651.218750\n",
      "Train Epoch: 38 [320/17352 (2%)] Loss: -194484.156250\n",
      "Train Epoch: 38 [400/17352 (2%)] Loss: -193017.875000\n",
      "Train Epoch: 38 [480/17352 (3%)] Loss: -205929.812500\n",
      "Train Epoch: 38 [560/17352 (3%)] Loss: -208532.734375\n",
      "Train Epoch: 38 [640/17352 (4%)] Loss: -202028.671875\n",
      "Train Epoch: 38 [720/17352 (4%)] Loss: -216213.218750\n",
      "Train Epoch: 38 [800/17352 (5%)] Loss: -214456.593750\n",
      "Train Epoch: 38 [880/17352 (5%)] Loss: -185153.812500\n",
      "Train Epoch: 38 [960/17352 (6%)] Loss: -235577.953125\n",
      "Train Epoch: 38 [1040/17352 (6%)] Loss: -212251.843750\n",
      "Train Epoch: 38 [1120/17352 (6%)] Loss: -193705.906250\n",
      "Train Epoch: 38 [1200/17352 (7%)] Loss: -216096.562500\n",
      "Train Epoch: 38 [1280/17352 (7%)] Loss: -204518.390625\n",
      "Train Epoch: 38 [1360/17352 (8%)] Loss: -202326.578125\n",
      "Train Epoch: 38 [1440/17352 (8%)] Loss: -200595.843750\n",
      "Train Epoch: 38 [1520/17352 (9%)] Loss: -209557.437500\n",
      "Train Epoch: 38 [1600/17352 (9%)] Loss: -202231.500000\n",
      "Train Epoch: 38 [1680/17352 (10%)] Loss: -187710.093750\n",
      "Train Epoch: 38 [1760/17352 (10%)] Loss: -231324.234375\n",
      "Train Epoch: 38 [1840/17352 (11%)] Loss: -215094.062500\n",
      "Train Epoch: 38 [1920/17352 (11%)] Loss: -199806.390625\n",
      "Train Epoch: 38 [2000/17352 (12%)] Loss: -193408.437500\n",
      "Train Epoch: 38 [2080/17352 (12%)] Loss: -214337.343750\n",
      "Train Epoch: 38 [2160/17352 (12%)] Loss: -204032.765625\n",
      "Train Epoch: 38 [2240/17352 (13%)] Loss: -203265.968750\n",
      "Train Epoch: 38 [2320/17352 (13%)] Loss: -212892.812500\n",
      "Train Epoch: 38 [2400/17352 (14%)] Loss: -193168.812500\n",
      "Train Epoch: 38 [2480/17352 (14%)] Loss: -163100.796875\n",
      "Train Epoch: 38 [2560/17352 (15%)] Loss: -190796.031250\n",
      "Train Epoch: 38 [2640/17352 (15%)] Loss: -147415.687500\n",
      "Train Epoch: 38 [2720/17352 (16%)] Loss: -209270.156250\n",
      "Train Epoch: 38 [2800/17352 (16%)] Loss: -146865.765625\n",
      "Train Epoch: 38 [2880/17352 (17%)] Loss: -165793.093750\n",
      "Train Epoch: 38 [2960/17352 (17%)] Loss: -167293.562500\n",
      "Train Epoch: 38 [3040/17352 (18%)] Loss: -188561.890625\n",
      "Train Epoch: 38 [3120/17352 (18%)] Loss: -193258.687500\n",
      "Train Epoch: 38 [3200/17352 (18%)] Loss: -210486.578125\n",
      "Train Epoch: 38 [3280/17352 (19%)] Loss: -175002.734375\n",
      "Train Epoch: 38 [3360/17352 (19%)] Loss: -188436.640625\n",
      "Train Epoch: 38 [3440/17352 (20%)] Loss: -210781.656250\n",
      "Train Epoch: 38 [3520/17352 (20%)] Loss: -171233.343750\n",
      "Train Epoch: 38 [3600/17352 (21%)] Loss: -173574.281250\n",
      "Train Epoch: 38 [3680/17352 (21%)] Loss: -204994.125000\n",
      "Train Epoch: 38 [3760/17352 (22%)] Loss: -187642.312500\n",
      "Train Epoch: 38 [3840/17352 (22%)] Loss: -184471.062500\n",
      "Train Epoch: 38 [3920/17352 (23%)] Loss: -171900.875000\n",
      "Train Epoch: 38 [4000/17352 (23%)] Loss: -183615.453125\n",
      "Train Epoch: 38 [4080/17352 (24%)] Loss: -178194.671875\n",
      "Train Epoch: 38 [4160/17352 (24%)] Loss: -186616.015625\n",
      "Train Epoch: 38 [4240/17352 (24%)] Loss: -186494.218750\n",
      "Train Epoch: 38 [4320/17352 (25%)] Loss: -195878.250000\n",
      "Train Epoch: 38 [4400/17352 (25%)] Loss: -166512.421875\n",
      "Train Epoch: 38 [4480/17352 (26%)] Loss: -176153.093750\n",
      "Train Epoch: 38 [4560/17352 (26%)] Loss: -188803.562500\n",
      "Train Epoch: 38 [4640/17352 (27%)] Loss: -202518.312500\n",
      "Train Epoch: 38 [4720/17352 (27%)] Loss: -161682.781250\n",
      "Train Epoch: 38 [4800/17352 (28%)] Loss: -165998.250000\n",
      "Train Epoch: 38 [4880/17352 (28%)] Loss: -192394.453125\n",
      "Train Epoch: 38 [4960/17352 (29%)] Loss: -208010.765625\n",
      "Train Epoch: 38 [5040/17352 (29%)] Loss: -200125.937500\n",
      "Train Epoch: 38 [5120/17352 (30%)] Loss: -176143.875000\n",
      "Train Epoch: 38 [5200/17352 (30%)] Loss: -178308.687500\n",
      "Train Epoch: 38 [5280/17352 (30%)] Loss: -162966.812500\n",
      "Train Epoch: 38 [5360/17352 (31%)] Loss: -191309.296875\n",
      "Train Epoch: 38 [5440/17352 (31%)] Loss: -159661.984375\n",
      "Train Epoch: 38 [5520/17352 (32%)] Loss: -207089.890625\n",
      "Train Epoch: 38 [5600/17352 (32%)] Loss: -196731.906250\n",
      "Train Epoch: 38 [5680/17352 (33%)] Loss: -214962.015625\n",
      "Train Epoch: 38 [5760/17352 (33%)] Loss: -206557.890625\n",
      "Train Epoch: 38 [5840/17352 (34%)] Loss: -184452.343750\n",
      "Train Epoch: 38 [5920/17352 (34%)] Loss: -180051.703125\n",
      "Train Epoch: 38 [6000/17352 (35%)] Loss: -178591.859375\n",
      "Train Epoch: 38 [6080/17352 (35%)] Loss: -166444.125000\n",
      "Train Epoch: 38 [6160/17352 (36%)] Loss: -177230.062500\n",
      "Train Epoch: 38 [6240/17352 (36%)] Loss: -195374.234375\n",
      "Train Epoch: 38 [6320/17352 (36%)] Loss: -200211.500000\n",
      "Train Epoch: 38 [6400/17352 (37%)] Loss: -190467.703125\n",
      "Train Epoch: 38 [6480/17352 (37%)] Loss: -151738.265625\n",
      "Train Epoch: 38 [6560/17352 (38%)] Loss: -197657.234375\n",
      "Train Epoch: 38 [6640/17352 (38%)] Loss: -191558.703125\n",
      "Train Epoch: 38 [6720/17352 (39%)] Loss: -183362.937500\n",
      "Train Epoch: 38 [6800/17352 (39%)] Loss: -193056.750000\n",
      "Train Epoch: 38 [6880/17352 (40%)] Loss: -187719.265625\n",
      "Train Epoch: 38 [6960/17352 (40%)] Loss: -160041.312500\n",
      "Train Epoch: 38 [7040/17352 (41%)] Loss: -166787.265625\n",
      "Train Epoch: 38 [7120/17352 (41%)] Loss: -153314.953125\n",
      "Train Epoch: 38 [7200/17352 (41%)] Loss: -174631.718750\n",
      "Train Epoch: 38 [7280/17352 (42%)] Loss: -182773.437500\n",
      "Train Epoch: 38 [7360/17352 (42%)] Loss: -213397.578125\n",
      "Train Epoch: 38 [7440/17352 (43%)] Loss: -182564.140625\n",
      "Train Epoch: 38 [7520/17352 (43%)] Loss: -195710.453125\n",
      "Train Epoch: 38 [7600/17352 (44%)] Loss: -186507.156250\n",
      "Train Epoch: 38 [7680/17352 (44%)] Loss: -204366.046875\n",
      "Train Epoch: 38 [7760/17352 (45%)] Loss: -200856.500000\n",
      "Train Epoch: 38 [7840/17352 (45%)] Loss: -174540.312500\n",
      "Train Epoch: 38 [7920/17352 (46%)] Loss: -193039.796875\n",
      "Train Epoch: 38 [8000/17352 (46%)] Loss: -189565.625000\n",
      "Train Epoch: 38 [8080/17352 (47%)] Loss: -211159.890625\n",
      "Train Epoch: 38 [8160/17352 (47%)] Loss: -171436.687500\n",
      "Train Epoch: 38 [8240/17352 (47%)] Loss: -191811.703125\n",
      "Train Epoch: 38 [8320/17352 (48%)] Loss: -186718.734375\n",
      "Train Epoch: 38 [8400/17352 (48%)] Loss: -209419.968750\n",
      "Train Epoch: 38 [8480/17352 (49%)] Loss: -194063.906250\n",
      "Train Epoch: 38 [8560/17352 (49%)] Loss: -201372.109375\n",
      "Train Epoch: 38 [8640/17352 (50%)] Loss: -171315.109375\n",
      "Train Epoch: 38 [8720/17352 (50%)] Loss: -178316.796875\n",
      "Train Epoch: 38 [8800/17352 (51%)] Loss: -180107.500000\n",
      "Train Epoch: 38 [8880/17352 (51%)] Loss: -189403.421875\n",
      "Train Epoch: 38 [8960/17352 (52%)] Loss: -187773.468750\n",
      "Train Epoch: 38 [9040/17352 (52%)] Loss: -189542.250000\n",
      "Train Epoch: 38 [9120/17352 (53%)] Loss: -211091.078125\n",
      "Train Epoch: 38 [9200/17352 (53%)] Loss: -199513.593750\n",
      "Train Epoch: 38 [9280/17352 (53%)] Loss: -172550.984375\n",
      "Train Epoch: 38 [9360/17352 (54%)] Loss: -156998.687500\n",
      "Train Epoch: 38 [9440/17352 (54%)] Loss: -159732.906250\n",
      "Train Epoch: 38 [9520/17352 (55%)] Loss: -181254.265625\n",
      "Train Epoch: 38 [9600/17352 (55%)] Loss: -200463.125000\n",
      "Train Epoch: 38 [9680/17352 (56%)] Loss: -187538.343750\n",
      "Train Epoch: 38 [9760/17352 (56%)] Loss: -165762.515625\n",
      "Train Epoch: 38 [9840/17352 (57%)] Loss: -200332.156250\n",
      "Train Epoch: 38 [9920/17352 (57%)] Loss: -203481.187500\n",
      "Train Epoch: 38 [10000/17352 (58%)] Loss: -188670.453125\n",
      "Train Epoch: 38 [10080/17352 (58%)] Loss: -188051.921875\n",
      "Train Epoch: 38 [10160/17352 (59%)] Loss: -95253.437500\n",
      "Train Epoch: 38 [10240/17352 (59%)] Loss: -206358.593750\n",
      "Train Epoch: 38 [10320/17352 (59%)] Loss: -185005.203125\n",
      "Train Epoch: 38 [10400/17352 (60%)] Loss: -178629.984375\n",
      "Train Epoch: 38 [10480/17352 (60%)] Loss: -196498.328125\n",
      "Train Epoch: 38 [10560/17352 (61%)] Loss: -192230.625000\n",
      "Train Epoch: 38 [10640/17352 (61%)] Loss: -199780.031250\n",
      "Train Epoch: 38 [10720/17352 (62%)] Loss: -176954.328125\n",
      "Train Epoch: 38 [10800/17352 (62%)] Loss: -187612.468750\n",
      "Train Epoch: 38 [10880/17352 (63%)] Loss: -167188.296875\n",
      "Train Epoch: 38 [10960/17352 (63%)] Loss: -189023.812500\n",
      "Train Epoch: 38 [11040/17352 (64%)] Loss: -164950.375000\n",
      "Train Epoch: 38 [11120/17352 (64%)] Loss: -199802.250000\n",
      "Train Epoch: 38 [11200/17352 (65%)] Loss: -175422.500000\n",
      "Train Epoch: 38 [11280/17352 (65%)] Loss: -212131.234375\n",
      "Train Epoch: 38 [11360/17352 (65%)] Loss: -172220.312500\n",
      "Train Epoch: 38 [11440/17352 (66%)] Loss: -190621.171875\n",
      "Train Epoch: 38 [11520/17352 (66%)] Loss: -178658.000000\n",
      "Train Epoch: 38 [11600/17352 (67%)] Loss: -183916.437500\n",
      "Train Epoch: 38 [11680/17352 (67%)] Loss: -192949.125000\n",
      "Train Epoch: 38 [11760/17352 (68%)] Loss: -173360.171875\n",
      "Train Epoch: 38 [11840/17352 (68%)] Loss: -191631.859375\n",
      "Train Epoch: 38 [11920/17352 (69%)] Loss: -164741.453125\n",
      "Train Epoch: 38 [12000/17352 (69%)] Loss: -179006.906250\n",
      "Train Epoch: 38 [12080/17352 (70%)] Loss: -193135.296875\n",
      "Train Epoch: 38 [12160/17352 (70%)] Loss: -197544.968750\n",
      "Train Epoch: 38 [12240/17352 (71%)] Loss: -171852.890625\n",
      "Train Epoch: 38 [12320/17352 (71%)] Loss: -185501.437500\n",
      "Train Epoch: 38 [12400/17352 (71%)] Loss: -185400.609375\n",
      "Train Epoch: 38 [12480/17352 (72%)] Loss: -205635.171875\n",
      "Train Epoch: 38 [12560/17352 (72%)] Loss: -208728.796875\n",
      "Train Epoch: 38 [12640/17352 (73%)] Loss: -174481.218750\n",
      "Train Epoch: 38 [12720/17352 (73%)] Loss: -165805.562500\n",
      "Train Epoch: 38 [12800/17352 (74%)] Loss: -173890.265625\n",
      "Train Epoch: 38 [12880/17352 (74%)] Loss: -192951.265625\n",
      "Train Epoch: 38 [12960/17352 (75%)] Loss: -186033.734375\n",
      "Train Epoch: 38 [13040/17352 (75%)] Loss: -174136.343750\n",
      "Train Epoch: 38 [13120/17352 (76%)] Loss: -189262.031250\n",
      "Train Epoch: 38 [13200/17352 (76%)] Loss: -209271.468750\n",
      "Train Epoch: 38 [13280/17352 (77%)] Loss: -187880.906250\n",
      "Train Epoch: 38 [13360/17352 (77%)] Loss: -215415.656250\n",
      "Train Epoch: 38 [13440/17352 (77%)] Loss: -218516.937500\n",
      "Train Epoch: 38 [13520/17352 (78%)] Loss: -192313.546875\n",
      "Train Epoch: 38 [13600/17352 (78%)] Loss: -202077.750000\n",
      "Train Epoch: 38 [13680/17352 (79%)] Loss: -180254.359375\n",
      "Train Epoch: 38 [13760/17352 (79%)] Loss: -186186.218750\n",
      "Train Epoch: 38 [13840/17352 (80%)] Loss: -177771.921875\n",
      "Train Epoch: 38 [13920/17352 (80%)] Loss: -208126.468750\n",
      "Train Epoch: 38 [14000/17352 (81%)] Loss: -181972.578125\n",
      "Train Epoch: 38 [14080/17352 (81%)] Loss: -174505.750000\n",
      "Train Epoch: 38 [14160/17352 (82%)] Loss: -168053.828125\n",
      "Train Epoch: 38 [14240/17352 (82%)] Loss: -204946.546875\n",
      "Train Epoch: 38 [14320/17352 (83%)] Loss: -192685.109375\n",
      "Train Epoch: 38 [14400/17352 (83%)] Loss: -192987.093750\n",
      "Train Epoch: 38 [14480/17352 (83%)] Loss: -144986.812500\n",
      "Train Epoch: 38 [14560/17352 (84%)] Loss: -168081.218750\n",
      "Train Epoch: 38 [14640/17352 (84%)] Loss: -190206.687500\n",
      "Train Epoch: 38 [14720/17352 (85%)] Loss: -170250.000000\n",
      "Train Epoch: 38 [14800/17352 (85%)] Loss: -185167.062500\n",
      "Train Epoch: 38 [14880/17352 (86%)] Loss: -174614.968750\n",
      "Train Epoch: 38 [14960/17352 (86%)] Loss: -180506.656250\n",
      "Train Epoch: 38 [15040/17352 (87%)] Loss: -177782.593750\n",
      "Train Epoch: 38 [15120/17352 (87%)] Loss: -166459.953125\n",
      "Train Epoch: 38 [15200/17352 (88%)] Loss: -202231.031250\n",
      "Train Epoch: 38 [15280/17352 (88%)] Loss: -184917.296875\n",
      "Train Epoch: 38 [15360/17352 (89%)] Loss: -214675.921875\n",
      "Train Epoch: 38 [15440/17352 (89%)] Loss: -161961.031250\n",
      "Train Epoch: 38 [15520/17352 (89%)] Loss: -165392.062500\n",
      "Train Epoch: 38 [15600/17352 (90%)] Loss: -156597.609375\n",
      "Train Epoch: 38 [15680/17352 (90%)] Loss: -202851.750000\n",
      "Train Epoch: 38 [15760/17352 (91%)] Loss: -177306.062500\n",
      "Train Epoch: 38 [15840/17352 (91%)] Loss: -209812.359375\n",
      "Train Epoch: 38 [15920/17352 (92%)] Loss: -177144.015625\n",
      "Train Epoch: 38 [16000/17352 (92%)] Loss: -184606.281250\n",
      "Train Epoch: 38 [16080/17352 (93%)] Loss: -180877.750000\n",
      "Train Epoch: 38 [16160/17352 (93%)] Loss: -181916.500000\n",
      "Train Epoch: 38 [16240/17352 (94%)] Loss: -208040.671875\n",
      "Train Epoch: 38 [16320/17352 (94%)] Loss: -193164.984375\n",
      "Train Epoch: 38 [16400/17352 (95%)] Loss: -205409.156250\n",
      "Train Epoch: 38 [16480/17352 (95%)] Loss: -176585.890625\n",
      "Train Epoch: 38 [16560/17352 (95%)] Loss: -191997.781250\n",
      "Train Epoch: 38 [16640/17352 (96%)] Loss: -175592.781250\n",
      "Train Epoch: 38 [16720/17352 (96%)] Loss: -202478.437500\n",
      "Train Epoch: 38 [16800/17352 (97%)] Loss: -181961.671875\n",
      "Train Epoch: 38 [16880/17352 (97%)] Loss: -196438.906250\n",
      "Train Epoch: 38 [16960/17352 (98%)] Loss: -167035.546875\n",
      "Train Epoch: 38 [17040/17352 (98%)] Loss: -210157.531250\n",
      "Train Epoch: 38 [17120/17352 (99%)] Loss: -192284.250000\n",
      "Train Epoch: 38 [17200/17352 (99%)] Loss: -217619.171875\n",
      "Train Epoch: 38 [17280/17352 (100%)] Loss: -189484.218750\n",
      "Train Epoch: 38 [17360/17352 (100%)] Loss: -198313.906250\n",
      "    epoch          : 38\n",
      "    loss           : -189297.15541390967\n",
      "    val_loss       : -23715.414553503477\n",
      "Train Epoch: 39 [0/17352 (0%)] Loss: -219257.578125\n",
      "Train Epoch: 39 [80/17352 (0%)] Loss: -194286.500000\n",
      "Train Epoch: 39 [160/17352 (1%)] Loss: -217631.421875\n",
      "Train Epoch: 39 [240/17352 (1%)] Loss: -182781.781250\n",
      "Train Epoch: 39 [320/17352 (2%)] Loss: -221763.781250\n",
      "Train Epoch: 39 [400/17352 (2%)] Loss: -229953.718750\n",
      "Train Epoch: 39 [480/17352 (3%)] Loss: -216103.734375\n",
      "Train Epoch: 39 [560/17352 (3%)] Loss: -196920.187500\n",
      "Train Epoch: 39 [640/17352 (4%)] Loss: -203273.562500\n",
      "Train Epoch: 39 [720/17352 (4%)] Loss: -191883.890625\n",
      "Train Epoch: 39 [800/17352 (5%)] Loss: -212364.484375\n",
      "Train Epoch: 39 [880/17352 (5%)] Loss: -208381.125000\n",
      "Train Epoch: 39 [960/17352 (6%)] Loss: -215482.625000\n",
      "Train Epoch: 39 [1040/17352 (6%)] Loss: -206779.921875\n",
      "Train Epoch: 39 [1120/17352 (6%)] Loss: -193411.203125\n",
      "Train Epoch: 39 [1200/17352 (7%)] Loss: -213337.562500\n",
      "Train Epoch: 39 [1280/17352 (7%)] Loss: -214326.265625\n",
      "Train Epoch: 39 [1360/17352 (8%)] Loss: -228900.562500\n",
      "Train Epoch: 39 [1440/17352 (8%)] Loss: -222998.390625\n",
      "Train Epoch: 39 [1520/17352 (9%)] Loss: -233746.343750\n",
      "Train Epoch: 39 [1600/17352 (9%)] Loss: -217586.953125\n",
      "Train Epoch: 39 [1680/17352 (10%)] Loss: -219651.531250\n",
      "Train Epoch: 39 [1760/17352 (10%)] Loss: -205191.468750\n",
      "Train Epoch: 39 [1840/17352 (11%)] Loss: -202027.421875\n",
      "Train Epoch: 39 [1920/17352 (11%)] Loss: -212248.171875\n",
      "Train Epoch: 39 [2000/17352 (12%)] Loss: -206137.546875\n",
      "Train Epoch: 39 [2080/17352 (12%)] Loss: -204034.218750\n",
      "Train Epoch: 39 [2160/17352 (12%)] Loss: -187714.281250\n",
      "Train Epoch: 39 [2240/17352 (13%)] Loss: -178802.218750\n",
      "Train Epoch: 39 [2320/17352 (13%)] Loss: -189265.015625\n",
      "Train Epoch: 39 [2400/17352 (14%)] Loss: -192793.484375\n",
      "Train Epoch: 39 [2480/17352 (14%)] Loss: -163770.234375\n",
      "Train Epoch: 39 [2560/17352 (15%)] Loss: -163353.093750\n",
      "Train Epoch: 39 [2640/17352 (15%)] Loss: -197597.000000\n",
      "Train Epoch: 39 [2720/17352 (16%)] Loss: -194944.953125\n",
      "Train Epoch: 39 [2800/17352 (16%)] Loss: -190389.875000\n",
      "Train Epoch: 39 [2880/17352 (17%)] Loss: -179462.625000\n",
      "Train Epoch: 39 [2960/17352 (17%)] Loss: -200458.578125\n",
      "Train Epoch: 39 [3040/17352 (18%)] Loss: -181659.078125\n",
      "Train Epoch: 39 [3120/17352 (18%)] Loss: -213174.937500\n",
      "Train Epoch: 39 [3200/17352 (18%)] Loss: -185176.562500\n",
      "Train Epoch: 39 [3280/17352 (19%)] Loss: -213392.437500\n",
      "Train Epoch: 39 [3360/17352 (19%)] Loss: -204611.406250\n",
      "Train Epoch: 39 [3440/17352 (20%)] Loss: -194053.546875\n",
      "Train Epoch: 39 [3520/17352 (20%)] Loss: -193269.281250\n",
      "Train Epoch: 39 [3600/17352 (21%)] Loss: -210273.000000\n",
      "Train Epoch: 39 [3680/17352 (21%)] Loss: -170760.828125\n",
      "Train Epoch: 39 [3760/17352 (22%)] Loss: -209590.609375\n",
      "Train Epoch: 39 [3840/17352 (22%)] Loss: -152739.734375\n",
      "Train Epoch: 39 [3920/17352 (23%)] Loss: -151215.703125\n",
      "Train Epoch: 39 [4000/17352 (23%)] Loss: -165868.593750\n",
      "Train Epoch: 39 [4080/17352 (24%)] Loss: -196026.671875\n",
      "Train Epoch: 39 [4160/17352 (24%)] Loss: -159093.656250\n",
      "Train Epoch: 39 [4240/17352 (24%)] Loss: -199517.593750\n",
      "Train Epoch: 39 [4320/17352 (25%)] Loss: -185593.312500\n",
      "Train Epoch: 39 [4400/17352 (25%)] Loss: -201517.125000\n",
      "Train Epoch: 39 [4480/17352 (26%)] Loss: -166025.921875\n",
      "Train Epoch: 39 [4560/17352 (26%)] Loss: -214683.062500\n",
      "Train Epoch: 39 [4640/17352 (27%)] Loss: -208716.140625\n",
      "Train Epoch: 39 [4720/17352 (27%)] Loss: -192248.687500\n",
      "Train Epoch: 39 [4800/17352 (28%)] Loss: -177275.687500\n",
      "Train Epoch: 39 [4880/17352 (28%)] Loss: -179924.031250\n",
      "Train Epoch: 39 [4960/17352 (29%)] Loss: -173895.125000\n",
      "Train Epoch: 39 [5040/17352 (29%)] Loss: -183053.687500\n",
      "Train Epoch: 39 [5120/17352 (30%)] Loss: -198248.156250\n",
      "Train Epoch: 39 [5200/17352 (30%)] Loss: -217623.046875\n",
      "Train Epoch: 39 [5280/17352 (30%)] Loss: -157484.984375\n",
      "Train Epoch: 39 [5360/17352 (31%)] Loss: -212127.546875\n",
      "Train Epoch: 39 [5440/17352 (31%)] Loss: -181915.531250\n",
      "Train Epoch: 39 [5520/17352 (32%)] Loss: -202476.625000\n",
      "Train Epoch: 39 [5600/17352 (32%)] Loss: -165804.578125\n",
      "Train Epoch: 39 [5680/17352 (33%)] Loss: -193334.406250\n",
      "Train Epoch: 39 [5760/17352 (33%)] Loss: -179165.718750\n",
      "Train Epoch: 39 [5840/17352 (34%)] Loss: -184964.750000\n",
      "Train Epoch: 39 [5920/17352 (34%)] Loss: -176911.718750\n",
      "Train Epoch: 39 [6000/17352 (35%)] Loss: -176054.312500\n",
      "Train Epoch: 39 [6080/17352 (35%)] Loss: -166790.812500\n",
      "Train Epoch: 39 [6160/17352 (36%)] Loss: -166000.593750\n",
      "Train Epoch: 39 [6240/17352 (36%)] Loss: -148819.734375\n",
      "Train Epoch: 39 [6320/17352 (36%)] Loss: -178632.781250\n",
      "Train Epoch: 39 [6400/17352 (37%)] Loss: -193797.000000\n",
      "Train Epoch: 39 [6480/17352 (37%)] Loss: -189404.703125\n",
      "Train Epoch: 39 [6560/17352 (38%)] Loss: -190495.765625\n",
      "Train Epoch: 39 [6640/17352 (38%)] Loss: -194584.812500\n",
      "Train Epoch: 39 [6720/17352 (39%)] Loss: -190915.109375\n",
      "Train Epoch: 39 [6800/17352 (39%)] Loss: -186043.937500\n",
      "Train Epoch: 39 [6880/17352 (40%)] Loss: -184271.343750\n",
      "Train Epoch: 39 [6960/17352 (40%)] Loss: -188506.828125\n",
      "Train Epoch: 39 [7040/17352 (41%)] Loss: -177165.968750\n",
      "Train Epoch: 39 [7120/17352 (41%)] Loss: -192113.281250\n",
      "Train Epoch: 39 [7200/17352 (41%)] Loss: -185991.593750\n",
      "Train Epoch: 39 [7280/17352 (42%)] Loss: -200970.250000\n",
      "Train Epoch: 39 [7360/17352 (42%)] Loss: -200417.234375\n",
      "Train Epoch: 39 [7440/17352 (43%)] Loss: -149445.171875\n",
      "Train Epoch: 39 [7520/17352 (43%)] Loss: -179436.500000\n",
      "Train Epoch: 39 [7600/17352 (44%)] Loss: -176873.375000\n",
      "Train Epoch: 39 [7680/17352 (44%)] Loss: -220003.687500\n",
      "Train Epoch: 39 [7760/17352 (45%)] Loss: -169943.718750\n",
      "Train Epoch: 39 [7840/17352 (45%)] Loss: -173938.125000\n",
      "Train Epoch: 39 [7920/17352 (46%)] Loss: -193127.671875\n",
      "Train Epoch: 39 [8000/17352 (46%)] Loss: -209895.703125\n",
      "Train Epoch: 39 [8080/17352 (47%)] Loss: -187313.734375\n",
      "Train Epoch: 39 [8160/17352 (47%)] Loss: -170778.125000\n",
      "Train Epoch: 39 [8240/17352 (47%)] Loss: -188867.453125\n",
      "Train Epoch: 39 [8320/17352 (48%)] Loss: -167142.390625\n",
      "Train Epoch: 39 [8400/17352 (48%)] Loss: -172547.953125\n",
      "Train Epoch: 39 [8480/17352 (49%)] Loss: -208896.562500\n",
      "Train Epoch: 39 [8560/17352 (49%)] Loss: -174190.046875\n",
      "Train Epoch: 39 [8640/17352 (50%)] Loss: -179962.656250\n",
      "Train Epoch: 39 [8720/17352 (50%)] Loss: -180049.765625\n",
      "Train Epoch: 39 [8800/17352 (51%)] Loss: -189209.843750\n",
      "Train Epoch: 39 [8880/17352 (51%)] Loss: -129691.992188\n",
      "Train Epoch: 39 [8960/17352 (52%)] Loss: -171307.281250\n",
      "Train Epoch: 39 [9040/17352 (52%)] Loss: -187243.453125\n",
      "Train Epoch: 39 [9120/17352 (53%)] Loss: -201825.843750\n",
      "Train Epoch: 39 [9200/17352 (53%)] Loss: -199168.750000\n",
      "Train Epoch: 39 [9280/17352 (53%)] Loss: -184755.734375\n",
      "Train Epoch: 39 [9360/17352 (54%)] Loss: -205214.953125\n",
      "Train Epoch: 39 [9440/17352 (54%)] Loss: -162557.312500\n",
      "Train Epoch: 39 [9520/17352 (55%)] Loss: -200264.875000\n",
      "Train Epoch: 39 [9600/17352 (55%)] Loss: -209261.843750\n",
      "Train Epoch: 39 [9680/17352 (56%)] Loss: -192101.093750\n",
      "Train Epoch: 39 [9760/17352 (56%)] Loss: -187534.750000\n",
      "Train Epoch: 39 [9840/17352 (57%)] Loss: -148445.250000\n",
      "Train Epoch: 39 [9920/17352 (57%)] Loss: -188010.843750\n",
      "Train Epoch: 39 [10000/17352 (58%)] Loss: -193950.437500\n",
      "Train Epoch: 39 [10080/17352 (58%)] Loss: -188188.046875\n",
      "Train Epoch: 39 [10160/17352 (59%)] Loss: -202851.515625\n",
      "Train Epoch: 39 [10240/17352 (59%)] Loss: -199597.468750\n",
      "Train Epoch: 39 [10320/17352 (59%)] Loss: -176964.281250\n",
      "Train Epoch: 39 [10400/17352 (60%)] Loss: -204211.312500\n",
      "Train Epoch: 39 [10480/17352 (60%)] Loss: -183285.953125\n",
      "Train Epoch: 39 [10560/17352 (61%)] Loss: -168962.250000\n",
      "Train Epoch: 39 [10640/17352 (61%)] Loss: -189569.500000\n",
      "Train Epoch: 39 [10720/17352 (62%)] Loss: -174905.265625\n",
      "Train Epoch: 39 [10800/17352 (62%)] Loss: -202313.359375\n",
      "Train Epoch: 39 [10880/17352 (63%)] Loss: -175205.187500\n",
      "Train Epoch: 39 [10960/17352 (63%)] Loss: -207090.796875\n",
      "Train Epoch: 39 [11040/17352 (64%)] Loss: -197313.640625\n",
      "Train Epoch: 39 [11120/17352 (64%)] Loss: -195777.906250\n",
      "Train Epoch: 39 [11200/17352 (65%)] Loss: -176039.265625\n",
      "Train Epoch: 39 [11280/17352 (65%)] Loss: -205725.796875\n",
      "Train Epoch: 39 [11360/17352 (65%)] Loss: -193357.421875\n",
      "Train Epoch: 39 [11440/17352 (66%)] Loss: -146003.046875\n",
      "Train Epoch: 39 [11520/17352 (66%)] Loss: -227887.843750\n",
      "Train Epoch: 39 [11600/17352 (67%)] Loss: -199800.484375\n",
      "Train Epoch: 39 [11680/17352 (67%)] Loss: -208429.531250\n",
      "Train Epoch: 39 [11760/17352 (68%)] Loss: -182687.718750\n",
      "Train Epoch: 39 [11840/17352 (68%)] Loss: -165382.937500\n",
      "Train Epoch: 39 [11920/17352 (69%)] Loss: -166644.062500\n",
      "Train Epoch: 39 [12000/17352 (69%)] Loss: -192287.203125\n",
      "Train Epoch: 39 [12080/17352 (70%)] Loss: -192900.000000\n",
      "Train Epoch: 39 [12160/17352 (70%)] Loss: -201360.953125\n",
      "Train Epoch: 39 [12240/17352 (71%)] Loss: -205019.828125\n",
      "Train Epoch: 39 [12320/17352 (71%)] Loss: -197089.343750\n",
      "Train Epoch: 39 [12400/17352 (71%)] Loss: -201955.609375\n",
      "Train Epoch: 39 [12480/17352 (72%)] Loss: -185310.812500\n",
      "Train Epoch: 39 [12560/17352 (72%)] Loss: -166553.625000\n",
      "Train Epoch: 39 [12640/17352 (73%)] Loss: -190789.640625\n",
      "Train Epoch: 39 [12720/17352 (73%)] Loss: -191826.453125\n",
      "Train Epoch: 39 [12800/17352 (74%)] Loss: -189506.671875\n",
      "Train Epoch: 39 [12880/17352 (74%)] Loss: -164743.781250\n",
      "Train Epoch: 39 [12960/17352 (75%)] Loss: -190622.000000\n",
      "Train Epoch: 39 [13040/17352 (75%)] Loss: -202977.609375\n",
      "Train Epoch: 39 [13120/17352 (76%)] Loss: -173572.953125\n",
      "Train Epoch: 39 [13200/17352 (76%)] Loss: -167293.500000\n",
      "Train Epoch: 39 [13280/17352 (77%)] Loss: -189016.281250\n",
      "Train Epoch: 39 [13360/17352 (77%)] Loss: -165678.937500\n",
      "Train Epoch: 39 [13440/17352 (77%)] Loss: -163756.968750\n",
      "Train Epoch: 39 [13520/17352 (78%)] Loss: -195377.500000\n",
      "Train Epoch: 39 [13600/17352 (78%)] Loss: -185785.312500\n",
      "Train Epoch: 39 [13680/17352 (79%)] Loss: -181005.531250\n",
      "Train Epoch: 39 [13760/17352 (79%)] Loss: -174873.484375\n",
      "Train Epoch: 39 [13840/17352 (80%)] Loss: -192988.203125\n",
      "Train Epoch: 39 [13920/17352 (80%)] Loss: -185563.843750\n",
      "Train Epoch: 39 [14000/17352 (81%)] Loss: -210385.093750\n",
      "Train Epoch: 39 [14080/17352 (81%)] Loss: -201304.875000\n",
      "Train Epoch: 39 [14160/17352 (82%)] Loss: -181723.531250\n",
      "Train Epoch: 39 [14240/17352 (82%)] Loss: -201033.609375\n",
      "Train Epoch: 39 [14320/17352 (83%)] Loss: -187592.531250\n",
      "Train Epoch: 39 [14400/17352 (83%)] Loss: -180507.625000\n",
      "Train Epoch: 39 [14480/17352 (83%)] Loss: -170534.171875\n",
      "Train Epoch: 39 [14560/17352 (84%)] Loss: -181011.062500\n",
      "Train Epoch: 39 [14640/17352 (84%)] Loss: -206152.593750\n",
      "Train Epoch: 39 [14720/17352 (85%)] Loss: -189291.968750\n",
      "Train Epoch: 39 [14800/17352 (85%)] Loss: -223958.312500\n",
      "Train Epoch: 39 [14880/17352 (86%)] Loss: -191559.734375\n",
      "Train Epoch: 39 [14960/17352 (86%)] Loss: -194062.281250\n",
      "Train Epoch: 39 [15040/17352 (87%)] Loss: -195100.750000\n",
      "Train Epoch: 39 [15120/17352 (87%)] Loss: -212614.265625\n",
      "Train Epoch: 39 [15200/17352 (88%)] Loss: -177616.875000\n",
      "Train Epoch: 39 [15280/17352 (88%)] Loss: -181738.078125\n",
      "Train Epoch: 39 [15360/17352 (89%)] Loss: -164137.093750\n",
      "Train Epoch: 39 [15440/17352 (89%)] Loss: -168763.609375\n",
      "Train Epoch: 39 [15520/17352 (89%)] Loss: -185542.281250\n",
      "Train Epoch: 39 [15600/17352 (90%)] Loss: -201933.093750\n",
      "Train Epoch: 39 [15680/17352 (90%)] Loss: -198792.375000\n",
      "Train Epoch: 39 [15760/17352 (91%)] Loss: -185829.843750\n",
      "Train Epoch: 39 [15840/17352 (91%)] Loss: -155863.625000\n",
      "Train Epoch: 39 [15920/17352 (92%)] Loss: -202191.906250\n",
      "Train Epoch: 39 [16000/17352 (92%)] Loss: -186768.843750\n",
      "Train Epoch: 39 [16080/17352 (93%)] Loss: -168077.281250\n",
      "Train Epoch: 39 [16160/17352 (93%)] Loss: -180249.406250\n",
      "Train Epoch: 39 [16240/17352 (94%)] Loss: -183794.078125\n",
      "Train Epoch: 39 [16320/17352 (94%)] Loss: -184819.078125\n",
      "Train Epoch: 39 [16400/17352 (95%)] Loss: -203882.562500\n",
      "Train Epoch: 39 [16480/17352 (95%)] Loss: -164371.750000\n",
      "Train Epoch: 39 [16560/17352 (95%)] Loss: -173120.250000\n",
      "Train Epoch: 39 [16640/17352 (96%)] Loss: -172549.437500\n",
      "Train Epoch: 39 [16720/17352 (96%)] Loss: -190469.484375\n",
      "Train Epoch: 39 [16800/17352 (97%)] Loss: -174473.875000\n",
      "Train Epoch: 39 [16880/17352 (97%)] Loss: -163499.140625\n",
      "Train Epoch: 39 [16960/17352 (98%)] Loss: -167246.109375\n",
      "Train Epoch: 39 [17040/17352 (98%)] Loss: -179671.171875\n",
      "Train Epoch: 39 [17120/17352 (99%)] Loss: -160146.093750\n",
      "Train Epoch: 39 [17200/17352 (99%)] Loss: -199783.046875\n",
      "Train Epoch: 39 [17280/17352 (100%)] Loss: -183071.171875\n",
      "Train Epoch: 39 [17360/17352 (100%)] Loss: -202589.390625\n",
      "    epoch          : 39\n",
      "    loss           : -188838.31947640967\n",
      "    val_loss       : -23715.36879690824\n",
      "Train Epoch: 40 [0/17352 (0%)] Loss: -206785.953125\n",
      "Train Epoch: 40 [80/17352 (0%)] Loss: -236495.500000\n",
      "Train Epoch: 40 [160/17352 (1%)] Loss: -202221.875000\n",
      "Train Epoch: 40 [240/17352 (1%)] Loss: -205103.718750\n",
      "Train Epoch: 40 [320/17352 (2%)] Loss: -230185.312500\n",
      "Train Epoch: 40 [400/17352 (2%)] Loss: -199925.000000\n",
      "Train Epoch: 40 [480/17352 (3%)] Loss: -187717.718750\n",
      "Train Epoch: 40 [560/17352 (3%)] Loss: -212183.625000\n",
      "Train Epoch: 40 [640/17352 (4%)] Loss: -209542.703125\n",
      "Train Epoch: 40 [720/17352 (4%)] Loss: -223008.093750\n",
      "Train Epoch: 40 [800/17352 (5%)] Loss: -221754.171875\n",
      "Train Epoch: 40 [880/17352 (5%)] Loss: -217581.406250\n",
      "Train Epoch: 40 [960/17352 (6%)] Loss: -204704.625000\n",
      "Train Epoch: 40 [1040/17352 (6%)] Loss: -233728.343750\n",
      "Train Epoch: 40 [1120/17352 (6%)] Loss: -196419.328125\n",
      "Train Epoch: 40 [1200/17352 (7%)] Loss: -214709.984375\n",
      "Train Epoch: 40 [1280/17352 (7%)] Loss: -199531.828125\n",
      "Train Epoch: 40 [1360/17352 (8%)] Loss: -214413.937500\n",
      "Train Epoch: 40 [1440/17352 (8%)] Loss: -216096.921875\n",
      "Train Epoch: 40 [1520/17352 (9%)] Loss: -212650.500000\n",
      "Train Epoch: 40 [1600/17352 (9%)] Loss: -206143.390625\n",
      "Train Epoch: 40 [1680/17352 (10%)] Loss: -209646.625000\n",
      "Train Epoch: 40 [1760/17352 (10%)] Loss: -194483.796875\n",
      "Train Epoch: 40 [1840/17352 (11%)] Loss: -209776.500000\n",
      "Train Epoch: 40 [1920/17352 (11%)] Loss: -205071.359375\n",
      "Train Epoch: 40 [2000/17352 (12%)] Loss: -205559.687500\n",
      "Train Epoch: 40 [2080/17352 (12%)] Loss: -205207.390625\n",
      "Train Epoch: 40 [2160/17352 (12%)] Loss: -226095.875000\n",
      "Train Epoch: 40 [2240/17352 (13%)] Loss: -174479.578125\n",
      "Train Epoch: 40 [2320/17352 (13%)] Loss: -216318.656250\n",
      "Train Epoch: 40 [2400/17352 (14%)] Loss: -220963.171875\n",
      "Train Epoch: 40 [2480/17352 (14%)] Loss: -212140.140625\n",
      "Train Epoch: 40 [2560/17352 (15%)] Loss: -196728.890625\n",
      "Train Epoch: 40 [2640/17352 (15%)] Loss: -196933.593750\n",
      "Train Epoch: 40 [2720/17352 (16%)] Loss: -177199.140625\n",
      "Train Epoch: 40 [2800/17352 (16%)] Loss: -201320.000000\n",
      "Train Epoch: 40 [2880/17352 (17%)] Loss: -194584.921875\n",
      "Train Epoch: 40 [2960/17352 (17%)] Loss: -202191.140625\n",
      "Train Epoch: 40 [3040/17352 (18%)] Loss: -201366.656250\n",
      "Train Epoch: 40 [3120/17352 (18%)] Loss: -221253.109375\n",
      "Train Epoch: 40 [3200/17352 (18%)] Loss: -181012.687500\n",
      "Train Epoch: 40 [3280/17352 (19%)] Loss: -184468.843750\n",
      "Train Epoch: 40 [3360/17352 (19%)] Loss: -178198.718750\n",
      "Train Epoch: 40 [3440/17352 (20%)] Loss: -204369.953125\n",
      "Train Epoch: 40 [3520/17352 (20%)] Loss: -159723.171875\n",
      "Train Epoch: 40 [3600/17352 (21%)] Loss: -203512.843750\n",
      "Train Epoch: 40 [3680/17352 (21%)] Loss: -224858.687500\n",
      "Train Epoch: 40 [3760/17352 (22%)] Loss: -187783.562500\n",
      "Train Epoch: 40 [3840/17352 (22%)] Loss: -213177.093750\n",
      "Train Epoch: 40 [3920/17352 (23%)] Loss: -185337.796875\n",
      "Train Epoch: 40 [4000/17352 (23%)] Loss: -183919.359375\n",
      "Train Epoch: 40 [4080/17352 (24%)] Loss: -205402.875000\n",
      "Train Epoch: 40 [4160/17352 (24%)] Loss: -163959.578125\n",
      "Train Epoch: 40 [4240/17352 (24%)] Loss: -189483.781250\n",
      "Train Epoch: 40 [4320/17352 (25%)] Loss: -175072.312500\n",
      "Train Epoch: 40 [4400/17352 (25%)] Loss: -146857.906250\n",
      "Train Epoch: 40 [4480/17352 (26%)] Loss: -190470.500000\n",
      "Train Epoch: 40 [4560/17352 (26%)] Loss: -213405.406250\n",
      "Train Epoch: 40 [4640/17352 (27%)] Loss: -182740.000000\n",
      "Train Epoch: 40 [4720/17352 (27%)] Loss: -188854.078125\n",
      "Train Epoch: 40 [4800/17352 (28%)] Loss: -182530.375000\n",
      "Train Epoch: 40 [4880/17352 (28%)] Loss: -196438.718750\n",
      "Train Epoch: 40 [4960/17352 (29%)] Loss: -185795.906250\n",
      "Train Epoch: 40 [5040/17352 (29%)] Loss: -206924.187500\n",
      "Train Epoch: 40 [5120/17352 (30%)] Loss: -164991.078125\n",
      "Train Epoch: 40 [5200/17352 (30%)] Loss: -214686.140625\n",
      "Train Epoch: 40 [5280/17352 (30%)] Loss: -206085.234375\n",
      "Train Epoch: 40 [5360/17352 (31%)] Loss: -204342.750000\n",
      "Train Epoch: 40 [5440/17352 (31%)] Loss: -177598.656250\n",
      "Train Epoch: 40 [5520/17352 (32%)] Loss: -177144.265625\n",
      "Train Epoch: 40 [5600/17352 (32%)] Loss: -201371.296875\n",
      "Train Epoch: 40 [5680/17352 (33%)] Loss: -201012.375000\n",
      "Train Epoch: 40 [5760/17352 (33%)] Loss: -192222.703125\n",
      "Train Epoch: 40 [5840/17352 (34%)] Loss: -176545.468750\n",
      "Train Epoch: 40 [5920/17352 (34%)] Loss: -184598.031250\n",
      "Train Epoch: 40 [6000/17352 (35%)] Loss: -171897.671875\n",
      "Train Epoch: 40 [6080/17352 (35%)] Loss: -179928.015625\n",
      "Train Epoch: 40 [6160/17352 (36%)] Loss: -177734.281250\n",
      "Train Epoch: 40 [6240/17352 (36%)] Loss: -179497.031250\n",
      "Train Epoch: 40 [6320/17352 (36%)] Loss: -193789.546875\n",
      "Train Epoch: 40 [6400/17352 (37%)] Loss: -181162.875000\n",
      "Train Epoch: 40 [6480/17352 (37%)] Loss: -210638.750000\n",
      "Train Epoch: 40 [6560/17352 (38%)] Loss: -214633.765625\n",
      "Train Epoch: 40 [6640/17352 (38%)] Loss: -163752.250000\n",
      "Train Epoch: 40 [6720/17352 (39%)] Loss: -178730.062500\n",
      "Train Epoch: 40 [6800/17352 (39%)] Loss: -202599.328125\n",
      "Train Epoch: 40 [6880/17352 (40%)] Loss: -213231.734375\n",
      "Train Epoch: 40 [6960/17352 (40%)] Loss: -166999.281250\n",
      "Train Epoch: 40 [7040/17352 (41%)] Loss: -197380.718750\n",
      "Train Epoch: 40 [7120/17352 (41%)] Loss: -204998.906250\n",
      "Train Epoch: 40 [7200/17352 (41%)] Loss: -202990.750000\n",
      "Train Epoch: 40 [7280/17352 (42%)] Loss: -168191.937500\n",
      "Train Epoch: 40 [7360/17352 (42%)] Loss: -202792.875000\n",
      "Train Epoch: 40 [7440/17352 (43%)] Loss: -190992.046875\n",
      "Train Epoch: 40 [7520/17352 (43%)] Loss: -180308.718750\n",
      "Train Epoch: 40 [7600/17352 (44%)] Loss: -183918.546875\n",
      "Train Epoch: 40 [7680/17352 (44%)] Loss: -164834.859375\n",
      "Train Epoch: 40 [7760/17352 (45%)] Loss: -201091.609375\n",
      "Train Epoch: 40 [7840/17352 (45%)] Loss: -196202.218750\n",
      "Train Epoch: 40 [7920/17352 (46%)] Loss: -178624.093750\n",
      "Train Epoch: 40 [8000/17352 (46%)] Loss: -200074.187500\n",
      "Train Epoch: 40 [8080/17352 (47%)] Loss: -181882.734375\n",
      "Train Epoch: 40 [8160/17352 (47%)] Loss: -206356.750000\n",
      "Train Epoch: 40 [8240/17352 (47%)] Loss: -177579.015625\n",
      "Train Epoch: 40 [8320/17352 (48%)] Loss: -187265.015625\n",
      "Train Epoch: 40 [8400/17352 (48%)] Loss: -206242.765625\n",
      "Train Epoch: 40 [8480/17352 (49%)] Loss: -147424.281250\n",
      "Train Epoch: 40 [8560/17352 (49%)] Loss: -180537.890625\n",
      "Train Epoch: 40 [8640/17352 (50%)] Loss: -190792.343750\n",
      "Train Epoch: 40 [8720/17352 (50%)] Loss: -178877.062500\n",
      "Train Epoch: 40 [8800/17352 (51%)] Loss: -145992.421875\n",
      "Train Epoch: 40 [8880/17352 (51%)] Loss: -183398.781250\n",
      "Train Epoch: 40 [8960/17352 (52%)] Loss: -174919.843750\n",
      "Train Epoch: 40 [9040/17352 (52%)] Loss: -143621.531250\n",
      "Train Epoch: 40 [9120/17352 (53%)] Loss: -176275.593750\n",
      "Train Epoch: 40 [9200/17352 (53%)] Loss: -174877.562500\n",
      "Train Epoch: 40 [9280/17352 (53%)] Loss: -176592.937500\n",
      "Train Epoch: 40 [9360/17352 (54%)] Loss: -204324.171875\n",
      "Train Epoch: 40 [9440/17352 (54%)] Loss: -181615.718750\n",
      "Train Epoch: 40 [9520/17352 (55%)] Loss: -157588.531250\n",
      "Train Epoch: 40 [9600/17352 (55%)] Loss: -191341.531250\n",
      "Train Epoch: 40 [9680/17352 (56%)] Loss: -184926.750000\n",
      "Train Epoch: 40 [9760/17352 (56%)] Loss: -188899.109375\n",
      "Train Epoch: 40 [9840/17352 (57%)] Loss: -180795.250000\n",
      "Train Epoch: 40 [9920/17352 (57%)] Loss: -190498.953125\n",
      "Train Epoch: 40 [10000/17352 (58%)] Loss: -180697.671875\n",
      "Train Epoch: 40 [10080/17352 (58%)] Loss: -167477.984375\n",
      "Train Epoch: 40 [10160/17352 (59%)] Loss: -195785.968750\n",
      "Train Epoch: 40 [10240/17352 (59%)] Loss: -184753.546875\n",
      "Train Epoch: 40 [10320/17352 (59%)] Loss: -159667.703125\n",
      "Train Epoch: 40 [10400/17352 (60%)] Loss: -180156.562500\n",
      "Train Epoch: 40 [10480/17352 (60%)] Loss: -171304.109375\n",
      "Train Epoch: 40 [10560/17352 (61%)] Loss: -170773.843750\n",
      "Train Epoch: 40 [10640/17352 (61%)] Loss: -201828.593750\n",
      "Train Epoch: 40 [10720/17352 (62%)] Loss: -205644.140625\n",
      "Train Epoch: 40 [10800/17352 (62%)] Loss: -183495.500000\n",
      "Train Epoch: 40 [10880/17352 (63%)] Loss: -189217.578125\n",
      "Train Epoch: 40 [10960/17352 (63%)] Loss: -191358.953125\n",
      "Train Epoch: 40 [11040/17352 (64%)] Loss: -181333.218750\n",
      "Train Epoch: 40 [11120/17352 (64%)] Loss: -210919.390625\n",
      "Train Epoch: 40 [11200/17352 (65%)] Loss: -203453.000000\n",
      "Train Epoch: 40 [11280/17352 (65%)] Loss: -175020.046875\n",
      "Train Epoch: 40 [11360/17352 (65%)] Loss: -162550.281250\n",
      "Train Epoch: 40 [11440/17352 (66%)] Loss: -191964.937500\n",
      "Train Epoch: 40 [11520/17352 (66%)] Loss: -205685.921875\n",
      "Train Epoch: 40 [11600/17352 (67%)] Loss: -179415.234375\n",
      "Train Epoch: 40 [11680/17352 (67%)] Loss: -190232.546875\n",
      "Train Epoch: 40 [11760/17352 (68%)] Loss: -192101.203125\n",
      "Train Epoch: 40 [11840/17352 (68%)] Loss: -153883.812500\n",
      "Train Epoch: 40 [11920/17352 (69%)] Loss: -197560.375000\n",
      "Train Epoch: 40 [12000/17352 (69%)] Loss: -196127.781250\n",
      "Train Epoch: 40 [12080/17352 (70%)] Loss: -194073.296875\n",
      "Train Epoch: 40 [12160/17352 (70%)] Loss: -184022.328125\n",
      "Train Epoch: 40 [12240/17352 (71%)] Loss: -171846.625000\n",
      "Train Epoch: 40 [12320/17352 (71%)] Loss: -162963.875000\n",
      "Train Epoch: 40 [12400/17352 (71%)] Loss: -225468.937500\n",
      "Train Epoch: 40 [12480/17352 (72%)] Loss: -187259.531250\n",
      "Train Epoch: 40 [12560/17352 (72%)] Loss: -220017.718750\n",
      "Train Epoch: 40 [12640/17352 (73%)] Loss: -187309.531250\n",
      "Train Epoch: 40 [12720/17352 (73%)] Loss: -179005.671875\n",
      "Train Epoch: 40 [12800/17352 (74%)] Loss: -192280.015625\n",
      "Train Epoch: 40 [12880/17352 (74%)] Loss: -169745.921875\n",
      "Train Epoch: 40 [12960/17352 (75%)] Loss: -200419.031250\n",
      "Train Epoch: 40 [13040/17352 (75%)] Loss: -187219.875000\n",
      "Train Epoch: 40 [13120/17352 (76%)] Loss: -169499.359375\n",
      "Train Epoch: 40 [13200/17352 (76%)] Loss: -189562.671875\n",
      "Train Epoch: 40 [13280/17352 (77%)] Loss: -187713.843750\n",
      "Train Epoch: 40 [13360/17352 (77%)] Loss: -185545.125000\n",
      "Train Epoch: 40 [13440/17352 (77%)] Loss: -157488.250000\n",
      "Train Epoch: 40 [13520/17352 (78%)] Loss: -180836.968750\n",
      "Train Epoch: 40 [13600/17352 (78%)] Loss: -180048.109375\n",
      "Train Epoch: 40 [13680/17352 (79%)] Loss: -200216.343750\n",
      "Train Epoch: 40 [13760/17352 (79%)] Loss: -200295.921875\n",
      "Train Epoch: 40 [13840/17352 (80%)] Loss: -174551.609375\n",
      "Train Epoch: 40 [13920/17352 (80%)] Loss: -163347.031250\n",
      "Train Epoch: 40 [14000/17352 (81%)] Loss: -151509.546875\n",
      "Train Epoch: 40 [14080/17352 (81%)] Loss: -197436.625000\n",
      "Train Epoch: 40 [14160/17352 (82%)] Loss: -191509.312500\n",
      "Train Epoch: 40 [14240/17352 (82%)] Loss: -181253.156250\n",
      "Train Epoch: 40 [14320/17352 (83%)] Loss: -200167.953125\n",
      "Train Epoch: 40 [14400/17352 (83%)] Loss: -177465.187500\n",
      "Train Epoch: 40 [14480/17352 (83%)] Loss: -194230.218750\n",
      "Train Epoch: 40 [14560/17352 (84%)] Loss: -199147.671875\n",
      "Train Epoch: 40 [14640/17352 (84%)] Loss: -175207.187500\n",
      "Train Epoch: 40 [14720/17352 (85%)] Loss: -178132.187500\n",
      "Train Epoch: 40 [14800/17352 (85%)] Loss: -183067.187500\n",
      "Train Epoch: 40 [14880/17352 (86%)] Loss: -195713.437500\n",
      "Train Epoch: 40 [14960/17352 (86%)] Loss: -179001.375000\n",
      "Train Epoch: 40 [15040/17352 (87%)] Loss: -193501.843750\n",
      "Train Epoch: 40 [15120/17352 (87%)] Loss: -173508.421875\n",
      "Train Epoch: 40 [15200/17352 (88%)] Loss: -208723.000000\n",
      "Train Epoch: 40 [15280/17352 (88%)] Loss: -203439.562500\n",
      "Train Epoch: 40 [15360/17352 (89%)] Loss: -183781.296875\n",
      "Train Epoch: 40 [15440/17352 (89%)] Loss: -177306.171875\n",
      "Train Epoch: 40 [15520/17352 (89%)] Loss: -174183.875000\n",
      "Train Epoch: 40 [15600/17352 (90%)] Loss: -200868.000000\n",
      "Train Epoch: 40 [15680/17352 (90%)] Loss: -179311.921875\n",
      "Train Epoch: 40 [15760/17352 (91%)] Loss: -187510.078125\n",
      "Train Epoch: 40 [15840/17352 (91%)] Loss: -188665.046875\n",
      "Train Epoch: 40 [15920/17352 (92%)] Loss: -183286.156250\n",
      "Train Epoch: 40 [16000/17352 (92%)] Loss: -228105.546875\n",
      "Train Epoch: 40 [16080/17352 (93%)] Loss: -170675.265625\n",
      "Train Epoch: 40 [16160/17352 (93%)] Loss: -188498.343750\n",
      "Train Epoch: 40 [16240/17352 (94%)] Loss: -203131.437500\n",
      "Train Epoch: 40 [16320/17352 (94%)] Loss: -193485.937500\n",
      "Train Epoch: 40 [16400/17352 (95%)] Loss: -179897.718750\n",
      "Train Epoch: 40 [16480/17352 (95%)] Loss: -199414.546875\n",
      "Train Epoch: 40 [16560/17352 (95%)] Loss: -190209.093750\n",
      "Train Epoch: 40 [16640/17352 (96%)] Loss: -179975.640625\n",
      "Train Epoch: 40 [16720/17352 (96%)] Loss: -231036.859375\n",
      "Train Epoch: 40 [16800/17352 (97%)] Loss: -192244.484375\n",
      "Train Epoch: 40 [16880/17352 (97%)] Loss: -167954.062500\n",
      "Train Epoch: 40 [16960/17352 (98%)] Loss: -196939.312500\n",
      "Train Epoch: 40 [17040/17352 (98%)] Loss: -166411.296875\n",
      "Train Epoch: 40 [17120/17352 (99%)] Loss: -189162.625000\n",
      "Train Epoch: 40 [17200/17352 (99%)] Loss: -195059.984375\n",
      "Train Epoch: 40 [17280/17352 (100%)] Loss: -178201.781250\n",
      "Train Epoch: 40 [17360/17352 (100%)] Loss: -208756.203125\n",
      "    epoch          : 40\n",
      "    loss           : -189594.97198647872\n",
      "    val_loss       : -23715.562880610076\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch40.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 41 [0/17352 (0%)] Loss: -204399.093750\n",
      "Train Epoch: 41 [80/17352 (0%)] Loss: -233724.390625\n",
      "Train Epoch: 41 [160/17352 (1%)] Loss: -199538.640625\n",
      "Train Epoch: 41 [240/17352 (1%)] Loss: -199927.625000\n",
      "Train Epoch: 41 [320/17352 (2%)] Loss: -210754.906250\n",
      "Train Epoch: 41 [400/17352 (2%)] Loss: -208375.796875\n",
      "Train Epoch: 41 [480/17352 (3%)] Loss: -218559.593750\n",
      "Train Epoch: 41 [560/17352 (3%)] Loss: -194493.156250\n",
      "Train Epoch: 41 [640/17352 (4%)] Loss: -224247.812500\n",
      "Train Epoch: 41 [720/17352 (4%)] Loss: -199094.687500\n",
      "Train Epoch: 41 [800/17352 (5%)] Loss: -210347.375000\n",
      "Train Epoch: 41 [880/17352 (5%)] Loss: -206791.125000\n",
      "Train Epoch: 41 [960/17352 (6%)] Loss: -214457.796875\n",
      "Train Epoch: 41 [1040/17352 (6%)] Loss: -221480.093750\n",
      "Train Epoch: 41 [1120/17352 (6%)] Loss: -222511.546875\n",
      "Train Epoch: 41 [1200/17352 (7%)] Loss: -214508.000000\n",
      "Train Epoch: 41 [1280/17352 (7%)] Loss: -230400.093750\n",
      "Train Epoch: 41 [1360/17352 (8%)] Loss: -217587.640625\n",
      "Train Epoch: 41 [1440/17352 (8%)] Loss: -193022.171875\n",
      "Train Epoch: 41 [1520/17352 (9%)] Loss: -219242.781250\n",
      "Train Epoch: 41 [1600/17352 (9%)] Loss: -202321.625000\n",
      "Train Epoch: 41 [1680/17352 (10%)] Loss: -229231.390625\n",
      "Train Epoch: 41 [1760/17352 (10%)] Loss: -212251.312500\n",
      "Train Epoch: 41 [1840/17352 (11%)] Loss: -226098.468750\n",
      "Train Epoch: 41 [1920/17352 (11%)] Loss: -212367.218750\n",
      "Train Epoch: 41 [2000/17352 (12%)] Loss: -217630.187500\n",
      "Train Epoch: 41 [2080/17352 (12%)] Loss: -201655.265625\n",
      "Train Epoch: 41 [2160/17352 (12%)] Loss: -236511.140625\n",
      "Train Epoch: 41 [2240/17352 (13%)] Loss: -194994.515625\n",
      "Train Epoch: 41 [2320/17352 (13%)] Loss: -187639.562500\n",
      "Train Epoch: 41 [2400/17352 (14%)] Loss: -180646.734375\n",
      "Train Epoch: 41 [2480/17352 (14%)] Loss: -196402.265625\n",
      "Train Epoch: 41 [2560/17352 (15%)] Loss: -182741.562500\n",
      "Train Epoch: 41 [2640/17352 (15%)] Loss: -186489.343750\n",
      "Train Epoch: 41 [2720/17352 (16%)] Loss: -191558.078125\n",
      "Train Epoch: 41 [2800/17352 (16%)] Loss: -148441.984375\n",
      "Train Epoch: 41 [2880/17352 (17%)] Loss: -183370.812500\n",
      "Train Epoch: 41 [2960/17352 (17%)] Loss: -172238.390625\n",
      "Train Epoch: 41 [3040/17352 (18%)] Loss: -207829.250000\n",
      "Train Epoch: 41 [3120/17352 (18%)] Loss: -176975.375000\n",
      "Train Epoch: 41 [3200/17352 (18%)] Loss: -204346.468750\n",
      "Train Epoch: 41 [3280/17352 (19%)] Loss: -164885.609375\n",
      "Train Epoch: 41 [3360/17352 (19%)] Loss: -181752.265625\n",
      "Train Epoch: 41 [3440/17352 (20%)] Loss: -200063.765625\n",
      "Train Epoch: 41 [3520/17352 (20%)] Loss: -203845.953125\n",
      "Train Epoch: 41 [3600/17352 (21%)] Loss: -183723.000000\n",
      "Train Epoch: 41 [3680/17352 (21%)] Loss: -190993.890625\n",
      "Train Epoch: 41 [3760/17352 (22%)] Loss: -188564.265625\n",
      "Train Epoch: 41 [3840/17352 (22%)] Loss: -153323.921875\n",
      "Train Epoch: 41 [3920/17352 (23%)] Loss: -181427.062500\n",
      "Train Epoch: 41 [4000/17352 (23%)] Loss: -193363.250000\n",
      "Train Epoch: 41 [4080/17352 (24%)] Loss: -184166.375000\n",
      "Train Epoch: 41 [4160/17352 (24%)] Loss: -178430.062500\n",
      "Train Epoch: 41 [4240/17352 (24%)] Loss: -174549.078125\n",
      "Train Epoch: 41 [4320/17352 (25%)] Loss: -189505.671875\n",
      "Train Epoch: 41 [4400/17352 (25%)] Loss: -168504.750000\n",
      "Train Epoch: 41 [4480/17352 (26%)] Loss: -190909.906250\n",
      "Train Epoch: 41 [4560/17352 (26%)] Loss: -159729.234375\n",
      "Train Epoch: 41 [4640/17352 (27%)] Loss: -180962.312500\n",
      "Train Epoch: 41 [4720/17352 (27%)] Loss: -166454.046875\n",
      "Train Epoch: 41 [4800/17352 (28%)] Loss: -185544.562500\n",
      "Train Epoch: 41 [4880/17352 (28%)] Loss: -200999.984375\n",
      "Train Epoch: 41 [4960/17352 (29%)] Loss: -178634.734375\n",
      "Train Epoch: 41 [5040/17352 (29%)] Loss: -180696.296875\n",
      "Train Epoch: 41 [5120/17352 (30%)] Loss: -187719.750000\n",
      "Train Epoch: 41 [5200/17352 (30%)] Loss: -167204.781250\n",
      "Train Epoch: 41 [5280/17352 (30%)] Loss: -165599.000000\n",
      "Train Epoch: 41 [5360/17352 (31%)] Loss: -164825.812500\n",
      "Train Epoch: 41 [5440/17352 (31%)] Loss: -200406.796875\n",
      "Train Epoch: 41 [5520/17352 (32%)] Loss: -199803.890625\n",
      "Train Epoch: 41 [5600/17352 (32%)] Loss: -213232.125000\n",
      "Train Epoch: 41 [5680/17352 (33%)] Loss: -228152.250000\n",
      "Train Epoch: 41 [5760/17352 (33%)] Loss: -173438.312500\n",
      "Train Epoch: 41 [5840/17352 (34%)] Loss: -173129.593750\n",
      "Train Epoch: 41 [5920/17352 (34%)] Loss: -208123.937500\n",
      "Train Epoch: 41 [6000/17352 (35%)] Loss: -197318.390625\n",
      "Train Epoch: 41 [6080/17352 (35%)] Loss: -199895.718750\n",
      "Train Epoch: 41 [6160/17352 (36%)] Loss: -177171.562500\n",
      "Train Epoch: 41 [6240/17352 (36%)] Loss: -192883.375000\n",
      "Train Epoch: 41 [6320/17352 (36%)] Loss: -176595.968750\n",
      "Train Epoch: 41 [6400/17352 (37%)] Loss: -223955.781250\n",
      "Train Epoch: 41 [6480/17352 (37%)] Loss: -187769.953125\n",
      "Train Epoch: 41 [6560/17352 (38%)] Loss: -192747.734375\n",
      "Train Epoch: 41 [6640/17352 (38%)] Loss: -193045.375000\n",
      "Train Epoch: 41 [6720/17352 (39%)] Loss: -174944.156250\n",
      "Train Epoch: 41 [6800/17352 (39%)] Loss: -171223.750000\n",
      "Train Epoch: 41 [6880/17352 (40%)] Loss: -179672.000000\n",
      "Train Epoch: 41 [6960/17352 (40%)] Loss: -180028.765625\n",
      "Train Epoch: 41 [7040/17352 (41%)] Loss: -196027.750000\n",
      "Train Epoch: 41 [7120/17352 (41%)] Loss: -208792.609375\n",
      "Train Epoch: 41 [7200/17352 (41%)] Loss: -169611.421875\n",
      "Train Epoch: 41 [7280/17352 (42%)] Loss: -191804.734375\n",
      "Train Epoch: 41 [7360/17352 (42%)] Loss: -178873.484375\n",
      "Train Epoch: 41 [7440/17352 (43%)] Loss: -202188.656250\n",
      "Train Epoch: 41 [7520/17352 (43%)] Loss: -192314.640625\n",
      "Train Epoch: 41 [7600/17352 (44%)] Loss: -183781.031250\n",
      "Train Epoch: 41 [7680/17352 (44%)] Loss: -193355.250000\n",
      "Train Epoch: 41 [7760/17352 (45%)] Loss: -180844.578125\n",
      "Train Epoch: 41 [7840/17352 (45%)] Loss: -200153.609375\n",
      "Train Epoch: 41 [7920/17352 (46%)] Loss: -177598.265625\n",
      "Train Epoch: 41 [8000/17352 (46%)] Loss: -174912.671875\n",
      "Train Epoch: 41 [8080/17352 (47%)] Loss: -174940.406250\n",
      "Train Epoch: 41 [8160/17352 (47%)] Loss: -181539.140625\n",
      "Train Epoch: 41 [8240/17352 (47%)] Loss: -166661.093750\n",
      "Train Epoch: 41 [8320/17352 (48%)] Loss: -185797.078125\n",
      "Train Epoch: 41 [8400/17352 (48%)] Loss: -178210.125000\n",
      "Train Epoch: 41 [8480/17352 (49%)] Loss: -180907.671875\n",
      "Train Epoch: 41 [8560/17352 (49%)] Loss: -200633.140625\n",
      "Train Epoch: 41 [8640/17352 (50%)] Loss: -178803.796875\n",
      "Train Epoch: 41 [8720/17352 (50%)] Loss: -159752.312500\n",
      "Train Epoch: 41 [8800/17352 (51%)] Loss: -164071.921875\n",
      "Train Epoch: 41 [8880/17352 (51%)] Loss: -167734.671875\n",
      "Train Epoch: 41 [8960/17352 (52%)] Loss: -185367.984375\n",
      "Train Epoch: 41 [9040/17352 (52%)] Loss: -228252.046875\n",
      "Train Epoch: 41 [9120/17352 (53%)] Loss: -194929.859375\n",
      "Train Epoch: 41 [9200/17352 (53%)] Loss: -179448.625000\n",
      "Train Epoch: 41 [9280/17352 (53%)] Loss: -183384.812500\n",
      "Train Epoch: 41 [9360/17352 (54%)] Loss: -210559.796875\n",
      "Train Epoch: 41 [9440/17352 (54%)] Loss: -186160.875000\n",
      "Train Epoch: 41 [9520/17352 (55%)] Loss: -213905.109375\n",
      "Train Epoch: 41 [9600/17352 (55%)] Loss: -202243.359375\n",
      "Train Epoch: 41 [9680/17352 (56%)] Loss: -174622.218750\n",
      "Train Epoch: 41 [9760/17352 (56%)] Loss: -201111.718750\n",
      "Train Epoch: 41 [9840/17352 (57%)] Loss: -193353.515625\n",
      "Train Epoch: 41 [9920/17352 (57%)] Loss: -189727.125000\n",
      "Train Epoch: 41 [10000/17352 (58%)] Loss: -177311.890625\n",
      "Train Epoch: 41 [10080/17352 (58%)] Loss: -166031.218750\n",
      "Train Epoch: 41 [10160/17352 (59%)] Loss: -178326.500000\n",
      "Train Epoch: 41 [10240/17352 (59%)] Loss: -156603.937500\n",
      "Train Epoch: 41 [10320/17352 (59%)] Loss: -206596.203125\n",
      "Train Epoch: 41 [10400/17352 (60%)] Loss: -187321.515625\n",
      "Train Epoch: 41 [10480/17352 (60%)] Loss: -195826.781250\n",
      "Train Epoch: 41 [10560/17352 (61%)] Loss: -179017.546875\n",
      "Train Epoch: 41 [10640/17352 (61%)] Loss: -165732.375000\n",
      "Train Epoch: 41 [10720/17352 (62%)] Loss: -198254.234375\n",
      "Train Epoch: 41 [10800/17352 (62%)] Loss: -201932.453125\n",
      "Train Epoch: 41 [10880/17352 (63%)] Loss: -193508.875000\n",
      "Train Epoch: 41 [10960/17352 (63%)] Loss: -208720.171875\n",
      "Train Epoch: 41 [11040/17352 (64%)] Loss: -215461.593750\n",
      "Train Epoch: 41 [11120/17352 (64%)] Loss: -171706.234375\n",
      "Train Epoch: 41 [11200/17352 (65%)] Loss: -184968.437500\n",
      "Train Epoch: 41 [11280/17352 (65%)] Loss: -192290.250000\n",
      "Train Epoch: 41 [11360/17352 (65%)] Loss: -163760.687500\n",
      "Train Epoch: 41 [11440/17352 (66%)] Loss: -183261.062500\n",
      "Train Epoch: 41 [11520/17352 (66%)] Loss: -173931.843750\n",
      "Train Epoch: 41 [11600/17352 (67%)] Loss: -203276.546875\n",
      "Train Epoch: 41 [11680/17352 (67%)] Loss: -203459.250000\n",
      "Train Epoch: 41 [11760/17352 (68%)] Loss: -200327.281250\n",
      "Train Epoch: 41 [11840/17352 (68%)] Loss: -129691.031250\n",
      "Train Epoch: 41 [11920/17352 (69%)] Loss: -180510.421875\n",
      "Train Epoch: 41 [12000/17352 (69%)] Loss: -166514.187500\n",
      "Train Epoch: 41 [12080/17352 (70%)] Loss: -182557.828125\n",
      "Train Epoch: 41 [12160/17352 (70%)] Loss: -179308.015625\n",
      "Train Epoch: 41 [12240/17352 (71%)] Loss: -184834.062500\n",
      "Train Epoch: 41 [12320/17352 (71%)] Loss: -186042.968750\n",
      "Train Epoch: 41 [12400/17352 (71%)] Loss: -157593.359375\n",
      "Train Epoch: 41 [12480/17352 (72%)] Loss: -203151.031250\n",
      "Train Epoch: 41 [12560/17352 (72%)] Loss: -183726.203125\n",
      "Train Epoch: 41 [12640/17352 (73%)] Loss: -186716.984375\n",
      "Train Epoch: 41 [12720/17352 (73%)] Loss: -179018.218750\n",
      "Train Epoch: 41 [12800/17352 (74%)] Loss: -204337.000000\n",
      "Train Epoch: 41 [12880/17352 (74%)] Loss: -157493.125000\n",
      "Train Epoch: 41 [12960/17352 (75%)] Loss: -192989.953125\n",
      "Train Epoch: 41 [13040/17352 (75%)] Loss: -171317.281250\n",
      "Train Epoch: 41 [13120/17352 (76%)] Loss: -180045.687500\n",
      "Train Epoch: 41 [13200/17352 (76%)] Loss: -190995.250000\n",
      "Train Epoch: 41 [13280/17352 (77%)] Loss: -214675.375000\n",
      "Train Epoch: 41 [13360/17352 (77%)] Loss: -184813.625000\n",
      "Train Epoch: 41 [13440/17352 (77%)] Loss: -171418.062500\n",
      "Train Epoch: 41 [13520/17352 (78%)] Loss: -168763.343750\n",
      "Train Epoch: 41 [13600/17352 (78%)] Loss: -187400.140625\n",
      "Train Epoch: 41 [13680/17352 (79%)] Loss: -199783.671875\n",
      "Train Epoch: 41 [13760/17352 (79%)] Loss: -162558.640625\n",
      "Train Epoch: 41 [13840/17352 (80%)] Loss: -217606.656250\n",
      "Train Epoch: 41 [13920/17352 (80%)] Loss: -197946.234375\n",
      "Train Epoch: 41 [14000/17352 (81%)] Loss: -181255.125000\n",
      "Train Epoch: 41 [14080/17352 (81%)] Loss: -164949.000000\n",
      "Train Epoch: 41 [14160/17352 (82%)] Loss: -195782.296875\n",
      "Train Epoch: 41 [14240/17352 (82%)] Loss: -186512.750000\n",
      "Train Epoch: 41 [14320/17352 (83%)] Loss: -191621.687500\n",
      "Train Epoch: 41 [14400/17352 (83%)] Loss: -218514.109375\n",
      "Train Epoch: 41 [14480/17352 (83%)] Loss: -142340.687500\n",
      "Train Epoch: 41 [14560/17352 (84%)] Loss: -204599.468750\n",
      "Train Epoch: 41 [14640/17352 (84%)] Loss: -195286.453125\n",
      "Train Epoch: 41 [14720/17352 (85%)] Loss: -203802.218750\n",
      "Train Epoch: 41 [14800/17352 (85%)] Loss: -208430.218750\n",
      "Train Epoch: 41 [14880/17352 (86%)] Loss: -183287.703125\n",
      "Train Epoch: 41 [14960/17352 (86%)] Loss: -176869.421875\n",
      "Train Epoch: 41 [15040/17352 (87%)] Loss: -194954.531250\n",
      "Train Epoch: 41 [15120/17352 (87%)] Loss: -164131.906250\n",
      "Train Epoch: 41 [15200/17352 (88%)] Loss: -200631.343750\n",
      "Train Epoch: 41 [15280/17352 (88%)] Loss: -192683.437500\n",
      "Train Epoch: 41 [15360/17352 (89%)] Loss: -178577.734375\n",
      "Train Epoch: 41 [15440/17352 (89%)] Loss: -178658.062500\n",
      "Train Epoch: 41 [15520/17352 (89%)] Loss: -178133.984375\n",
      "Train Epoch: 41 [15600/17352 (90%)] Loss: -187525.437500\n",
      "Train Epoch: 41 [15680/17352 (90%)] Loss: -210491.656250\n",
      "Train Epoch: 41 [15760/17352 (91%)] Loss: -188001.812500\n",
      "Train Epoch: 41 [15840/17352 (91%)] Loss: -142610.484375\n",
      "Train Epoch: 41 [15920/17352 (92%)] Loss: -184842.937500\n",
      "Train Epoch: 41 [16000/17352 (92%)] Loss: -186035.328125\n",
      "Train Epoch: 41 [16080/17352 (93%)] Loss: -201367.859375\n",
      "Train Epoch: 41 [16160/17352 (93%)] Loss: -180751.671875\n",
      "Train Epoch: 41 [16240/17352 (94%)] Loss: -205511.078125\n",
      "Train Epoch: 41 [16320/17352 (94%)] Loss: -202936.359375\n",
      "Train Epoch: 41 [16400/17352 (95%)] Loss: -187950.562500\n",
      "Train Epoch: 41 [16480/17352 (95%)] Loss: -206352.531250\n",
      "Train Epoch: 41 [16560/17352 (95%)] Loss: -214745.125000\n",
      "Train Epoch: 41 [16640/17352 (96%)] Loss: -206147.281250\n",
      "Train Epoch: 41 [16720/17352 (96%)] Loss: -131045.429688\n",
      "Train Epoch: 41 [16800/17352 (97%)] Loss: -193264.671875\n",
      "Train Epoch: 41 [16880/17352 (97%)] Loss: -193190.468750\n",
      "Train Epoch: 41 [16960/17352 (98%)] Loss: -173567.000000\n",
      "Train Epoch: 41 [17040/17352 (98%)] Loss: -183922.968750\n",
      "Train Epoch: 41 [17120/17352 (99%)] Loss: -174475.437500\n",
      "Train Epoch: 41 [17200/17352 (99%)] Loss: -199450.453125\n",
      "Train Epoch: 41 [17280/17352 (100%)] Loss: -170779.687500\n",
      "Train Epoch: 41 [17360/17352 (100%)] Loss: -194066.375000\n",
      "    epoch          : 41\n",
      "    loss           : -189250.9205714183\n",
      "    val_loss       : -23715.638613132243\n",
      "Train Epoch: 42 [0/17352 (0%)] Loss: -213317.390625\n",
      "Train Epoch: 42 [80/17352 (0%)] Loss: -196936.812500\n",
      "Train Epoch: 42 [160/17352 (1%)] Loss: -203742.343750\n",
      "Train Epoch: 42 [240/17352 (1%)] Loss: -208526.578125\n",
      "Train Epoch: 42 [320/17352 (2%)] Loss: -218557.859375\n",
      "Train Epoch: 42 [400/17352 (2%)] Loss: -223001.312500\n",
      "Train Epoch: 42 [480/17352 (3%)] Loss: -202259.390625\n",
      "Train Epoch: 42 [560/17352 (3%)] Loss: -205550.156250\n",
      "Train Epoch: 42 [640/17352 (4%)] Loss: -226088.078125\n",
      "Train Epoch: 42 [720/17352 (4%)] Loss: -205186.500000\n",
      "Train Epoch: 42 [800/17352 (5%)] Loss: -209768.328125\n",
      "Train Epoch: 42 [880/17352 (5%)] Loss: -210343.125000\n",
      "Train Epoch: 42 [960/17352 (6%)] Loss: -210629.968750\n",
      "Train Epoch: 42 [1040/17352 (6%)] Loss: -210208.703125\n",
      "Train Epoch: 42 [1120/17352 (6%)] Loss: -217593.187500\n",
      "Train Epoch: 42 [1200/17352 (7%)] Loss: -204394.468750\n",
      "Train Epoch: 42 [1280/17352 (7%)] Loss: -194494.796875\n",
      "Train Epoch: 42 [1360/17352 (8%)] Loss: -211896.812500\n",
      "Train Epoch: 42 [1440/17352 (8%)] Loss: -204350.218750\n",
      "Train Epoch: 42 [1520/17352 (9%)] Loss: -219662.031250\n",
      "Train Epoch: 42 [1600/17352 (9%)] Loss: -229228.812500\n",
      "Train Epoch: 42 [1680/17352 (10%)] Loss: -202029.078125\n",
      "Train Epoch: 42 [1760/17352 (10%)] Loss: -221476.531250\n",
      "Train Epoch: 42 [1840/17352 (11%)] Loss: -206137.046875\n",
      "Train Epoch: 42 [1920/17352 (11%)] Loss: -233731.125000\n",
      "Train Epoch: 42 [2000/17352 (12%)] Loss: -185151.531250\n",
      "Train Epoch: 42 [2080/17352 (12%)] Loss: -208383.984375\n",
      "Train Epoch: 42 [2160/17352 (12%)] Loss: -224243.750000\n",
      "Train Epoch: 42 [2240/17352 (13%)] Loss: -196450.937500\n",
      "Train Epoch: 42 [2320/17352 (13%)] Loss: -173030.140625\n",
      "Train Epoch: 42 [2400/17352 (14%)] Loss: -190620.171875\n",
      "Train Epoch: 42 [2480/17352 (14%)] Loss: -173012.078125\n",
      "Train Epoch: 42 [2560/17352 (15%)] Loss: -197297.781250\n",
      "Train Epoch: 42 [2640/17352 (15%)] Loss: -188004.203125\n",
      "Train Epoch: 42 [2720/17352 (16%)] Loss: -191808.234375\n",
      "Train Epoch: 42 [2800/17352 (16%)] Loss: -163549.765625\n",
      "Train Epoch: 42 [2880/17352 (17%)] Loss: -204682.093750\n",
      "Train Epoch: 42 [2960/17352 (17%)] Loss: -194231.093750\n",
      "Train Epoch: 42 [3040/17352 (18%)] Loss: -207859.656250\n",
      "Train Epoch: 42 [3120/17352 (18%)] Loss: -187216.250000\n",
      "Train Epoch: 42 [3200/17352 (18%)] Loss: -182558.328125\n",
      "Train Epoch: 42 [3280/17352 (19%)] Loss: -181011.265625\n",
      "Train Epoch: 42 [3360/17352 (19%)] Loss: -211723.968750\n",
      "Train Epoch: 42 [3440/17352 (20%)] Loss: -178565.187500\n",
      "Train Epoch: 42 [3520/17352 (20%)] Loss: -161955.937500\n",
      "Train Epoch: 42 [3600/17352 (21%)] Loss: -185363.859375\n",
      "Train Epoch: 42 [3680/17352 (21%)] Loss: -215636.656250\n",
      "Train Epoch: 42 [3760/17352 (22%)] Loss: -203480.859375\n",
      "Train Epoch: 42 [3840/17352 (22%)] Loss: -193487.796875\n",
      "Train Epoch: 42 [3920/17352 (23%)] Loss: -177074.734375\n",
      "Train Epoch: 42 [4000/17352 (23%)] Loss: -183583.421875\n",
      "Train Epoch: 42 [4080/17352 (24%)] Loss: -188756.656250\n",
      "Train Epoch: 42 [4160/17352 (24%)] Loss: -201965.546875\n",
      "Train Epoch: 42 [4240/17352 (24%)] Loss: -192374.531250\n",
      "Train Epoch: 42 [4320/17352 (25%)] Loss: -194929.859375\n",
      "Train Epoch: 42 [4400/17352 (25%)] Loss: -157776.390625\n",
      "Train Epoch: 42 [4480/17352 (26%)] Loss: -177250.578125\n",
      "Train Epoch: 42 [4560/17352 (26%)] Loss: -200211.781250\n",
      "Train Epoch: 42 [4640/17352 (27%)] Loss: -206239.796875\n",
      "Train Epoch: 42 [4720/17352 (27%)] Loss: -188180.703125\n",
      "Train Epoch: 42 [4800/17352 (28%)] Loss: -176052.000000\n",
      "Train Epoch: 42 [4880/17352 (28%)] Loss: -179885.281250\n",
      "Train Epoch: 42 [4960/17352 (29%)] Loss: -181424.828125\n",
      "Train Epoch: 42 [5040/17352 (29%)] Loss: -164360.828125\n",
      "Train Epoch: 42 [5120/17352 (30%)] Loss: -171413.953125\n",
      "Train Epoch: 42 [5200/17352 (30%)] Loss: -176273.671875\n",
      "Train Epoch: 42 [5280/17352 (30%)] Loss: -183256.843750\n",
      "Train Epoch: 42 [5360/17352 (31%)] Loss: -174945.093750\n",
      "Train Epoch: 42 [5440/17352 (31%)] Loss: -186425.609375\n",
      "Train Epoch: 42 [5520/17352 (32%)] Loss: -167083.718750\n",
      "Train Epoch: 42 [5600/17352 (32%)] Loss: -188950.984375\n",
      "Train Epoch: 42 [5680/17352 (33%)] Loss: -159609.203125\n",
      "Train Epoch: 42 [5760/17352 (33%)] Loss: -153882.265625\n",
      "Train Epoch: 42 [5840/17352 (34%)] Loss: -180879.765625\n",
      "Train Epoch: 42 [5920/17352 (34%)] Loss: -200856.984375\n",
      "Train Epoch: 42 [6000/17352 (35%)] Loss: -185992.812500\n",
      "Train Epoch: 42 [6080/17352 (35%)] Loss: -212608.250000\n",
      "Train Epoch: 42 [6160/17352 (36%)] Loss: -170677.296875\n",
      "Train Epoch: 42 [6240/17352 (36%)] Loss: -190476.296875\n",
      "Train Epoch: 42 [6320/17352 (36%)] Loss: -156988.781250\n",
      "Train Epoch: 42 [6400/17352 (37%)] Loss: -196445.937500\n",
      "Train Epoch: 42 [6480/17352 (37%)] Loss: -192979.000000\n",
      "Train Epoch: 42 [6560/17352 (38%)] Loss: -184254.031250\n",
      "Train Epoch: 42 [6640/17352 (38%)] Loss: -202875.906250\n",
      "Train Epoch: 42 [6720/17352 (39%)] Loss: -215638.656250\n",
      "Train Epoch: 42 [6800/17352 (39%)] Loss: -167295.687500\n",
      "Train Epoch: 42 [6880/17352 (40%)] Loss: -162960.984375\n",
      "Train Epoch: 42 [6960/17352 (40%)] Loss: -172882.250000\n",
      "Train Epoch: 42 [7040/17352 (41%)] Loss: -180689.875000\n",
      "Train Epoch: 42 [7120/17352 (41%)] Loss: -165793.984375\n",
      "Train Epoch: 42 [7200/17352 (41%)] Loss: -173661.718750\n",
      "Train Epoch: 42 [7280/17352 (42%)] Loss: -199798.968750\n",
      "Train Epoch: 42 [7360/17352 (42%)] Loss: -166453.937500\n",
      "Train Epoch: 42 [7440/17352 (43%)] Loss: -205412.390625\n",
      "Train Epoch: 42 [7520/17352 (43%)] Loss: -220971.203125\n",
      "Train Epoch: 42 [7600/17352 (44%)] Loss: -179315.031250\n",
      "Train Epoch: 42 [7680/17352 (44%)] Loss: -164796.187500\n",
      "Train Epoch: 42 [7760/17352 (45%)] Loss: -207126.406250\n",
      "Train Epoch: 42 [7840/17352 (45%)] Loss: -180159.062500\n",
      "Train Epoch: 42 [7920/17352 (46%)] Loss: -144980.531250\n",
      "Train Epoch: 42 [8000/17352 (46%)] Loss: -148505.625000\n",
      "Train Epoch: 42 [8080/17352 (47%)] Loss: -185587.640625\n",
      "Train Epoch: 42 [8160/17352 (47%)] Loss: -210264.734375\n",
      "Train Epoch: 42 [8240/17352 (47%)] Loss: -195835.421875\n",
      "Train Epoch: 42 [8320/17352 (48%)] Loss: -179978.406250\n",
      "Train Epoch: 42 [8400/17352 (48%)] Loss: -188486.781250\n",
      "Train Epoch: 42 [8480/17352 (49%)] Loss: -187521.218750\n",
      "Train Epoch: 42 [8560/17352 (49%)] Loss: -209593.031250\n",
      "Train Epoch: 42 [8640/17352 (50%)] Loss: -175752.734375\n",
      "Train Epoch: 42 [8720/17352 (50%)] Loss: -166517.390625\n",
      "Train Epoch: 42 [8800/17352 (51%)] Loss: -210780.312500\n",
      "Train Epoch: 42 [8880/17352 (51%)] Loss: -149450.078125\n",
      "Train Epoch: 42 [8960/17352 (52%)] Loss: -204336.250000\n",
      "Train Epoch: 42 [9040/17352 (52%)] Loss: -196027.656250\n",
      "Train Epoch: 42 [9120/17352 (53%)] Loss: -198798.296875\n",
      "Train Epoch: 42 [9200/17352 (53%)] Loss: -175541.203125\n",
      "Train Epoch: 42 [9280/17352 (53%)] Loss: -185823.781250\n",
      "Train Epoch: 42 [9360/17352 (54%)] Loss: -172961.984375\n",
      "Train Epoch: 42 [9440/17352 (54%)] Loss: -175075.093750\n",
      "Train Epoch: 42 [9520/17352 (55%)] Loss: -191147.046875\n",
      "Train Epoch: 42 [9600/17352 (55%)] Loss: -197511.812500\n",
      "Train Epoch: 42 [9680/17352 (56%)] Loss: -159688.500000\n",
      "Train Epoch: 42 [9760/17352 (56%)] Loss: -191051.875000\n",
      "Train Epoch: 42 [9840/17352 (57%)] Loss: -177304.812500\n",
      "Train Epoch: 42 [9920/17352 (57%)] Loss: -134538.375000\n",
      "Train Epoch: 42 [10000/17352 (58%)] Loss: -176674.500000\n",
      "Train Epoch: 42 [10080/17352 (58%)] Loss: -208895.062500\n",
      "Train Epoch: 42 [10160/17352 (59%)] Loss: -184987.171875\n",
      "Train Epoch: 42 [10240/17352 (59%)] Loss: -201935.343750\n",
      "Train Epoch: 42 [10320/17352 (59%)] Loss: -190928.656250\n",
      "Train Epoch: 42 [10400/17352 (60%)] Loss: -173938.531250\n",
      "Train Epoch: 42 [10480/17352 (60%)] Loss: -148832.250000\n",
      "Train Epoch: 42 [10560/17352 (61%)] Loss: -199783.390625\n",
      "Train Epoch: 42 [10640/17352 (61%)] Loss: -193192.531250\n",
      "Train Epoch: 42 [10720/17352 (62%)] Loss: -187252.281250\n",
      "Train Epoch: 42 [10800/17352 (62%)] Loss: -218747.718750\n",
      "Train Epoch: 42 [10880/17352 (63%)] Loss: -204999.250000\n",
      "Train Epoch: 42 [10960/17352 (63%)] Loss: -163764.828125\n",
      "Train Epoch: 42 [11040/17352 (64%)] Loss: -142617.687500\n",
      "Train Epoch: 42 [11120/17352 (64%)] Loss: -185289.625000\n",
      "Train Epoch: 42 [11200/17352 (65%)] Loss: -174903.312500\n",
      "Train Epoch: 42 [11280/17352 (65%)] Loss: -166437.531250\n",
      "Train Epoch: 42 [11360/17352 (65%)] Loss: -184815.750000\n",
      "Train Epoch: 42 [11440/17352 (66%)] Loss: -171718.312500\n",
      "Train Epoch: 42 [11520/17352 (66%)] Loss: -165390.250000\n",
      "Train Epoch: 42 [11600/17352 (67%)] Loss: -200416.656250\n",
      "Train Epoch: 42 [11680/17352 (67%)] Loss: -193260.875000\n",
      "Train Epoch: 42 [11760/17352 (68%)] Loss: -186040.390625\n",
      "Train Epoch: 42 [11840/17352 (68%)] Loss: -214637.203125\n",
      "Train Epoch: 42 [11920/17352 (69%)] Loss: -159739.171875\n",
      "Train Epoch: 42 [12000/17352 (69%)] Loss: -206562.609375\n",
      "Train Epoch: 42 [12080/17352 (70%)] Loss: -163495.625000\n",
      "Train Epoch: 42 [12160/17352 (70%)] Loss: -180253.171875\n",
      "Train Epoch: 42 [12240/17352 (71%)] Loss: -202238.750000\n",
      "Train Epoch: 42 [12320/17352 (71%)] Loss: -155857.421875\n",
      "Train Epoch: 42 [12400/17352 (71%)] Loss: -195781.953125\n",
      "Train Epoch: 42 [12480/17352 (72%)] Loss: -165589.890625\n",
      "Train Epoch: 42 [12560/17352 (72%)] Loss: -168077.781250\n",
      "Train Epoch: 42 [12640/17352 (73%)] Loss: -174026.671875\n",
      "Train Epoch: 42 [12720/17352 (73%)] Loss: -171830.093750\n",
      "Train Epoch: 42 [12800/17352 (74%)] Loss: -194603.687500\n",
      "Train Epoch: 42 [12880/17352 (74%)] Loss: -95264.000000\n",
      "Train Epoch: 42 [12960/17352 (75%)] Loss: -193369.140625\n",
      "Train Epoch: 42 [13040/17352 (75%)] Loss: -221243.156250\n",
      "Train Epoch: 42 [13120/17352 (76%)] Loss: -177773.546875\n",
      "Train Epoch: 42 [13200/17352 (76%)] Loss: -196123.765625\n",
      "Train Epoch: 42 [13280/17352 (77%)] Loss: -186041.140625\n",
      "Train Epoch: 42 [13360/17352 (77%)] Loss: -181607.515625\n",
      "Train Epoch: 42 [13440/17352 (77%)] Loss: -163338.156250\n",
      "Train Epoch: 42 [13520/17352 (78%)] Loss: -215414.031250\n",
      "Train Epoch: 42 [13600/17352 (78%)] Loss: -187268.453125\n",
      "Train Epoch: 42 [13680/17352 (79%)] Loss: -153321.609375\n",
      "Train Epoch: 42 [13760/17352 (79%)] Loss: -201359.578125\n",
      "Train Epoch: 42 [13840/17352 (80%)] Loss: -187211.000000\n",
      "Train Epoch: 42 [13920/17352 (80%)] Loss: -191957.375000\n",
      "Train Epoch: 42 [14000/17352 (81%)] Loss: -172230.937500\n",
      "Train Epoch: 42 [14080/17352 (81%)] Loss: -189400.437500\n",
      "Train Epoch: 42 [14160/17352 (82%)] Loss: -182737.859375\n",
      "Train Epoch: 42 [14240/17352 (82%)] Loss: -178597.468750\n",
      "Train Epoch: 42 [14320/17352 (83%)] Loss: -209274.265625\n",
      "Train Epoch: 42 [14400/17352 (83%)] Loss: -192116.937500\n",
      "Train Epoch: 42 [14480/17352 (83%)] Loss: -196693.828125\n",
      "Train Epoch: 42 [14560/17352 (84%)] Loss: -165680.031250\n",
      "Train Epoch: 42 [14640/17352 (84%)] Loss: -184166.828125\n",
      "Train Epoch: 42 [14720/17352 (85%)] Loss: -199414.687500\n",
      "Train Epoch: 42 [14800/17352 (85%)] Loss: -148924.078125\n",
      "Train Epoch: 42 [14880/17352 (86%)] Loss: -207861.921875\n",
      "Train Epoch: 42 [14960/17352 (86%)] Loss: -198701.531250\n",
      "Train Epoch: 42 [15040/17352 (87%)] Loss: -180307.546875\n",
      "Train Epoch: 42 [15120/17352 (87%)] Loss: -200617.968750\n",
      "Train Epoch: 42 [15200/17352 (88%)] Loss: -156608.390625\n",
      "Train Epoch: 42 [15280/17352 (88%)] Loss: -200632.593750\n",
      "Train Epoch: 42 [15360/17352 (89%)] Loss: -170352.937500\n",
      "Train Epoch: 42 [15440/17352 (89%)] Loss: -202079.000000\n",
      "Train Epoch: 42 [15520/17352 (89%)] Loss: -179003.859375\n",
      "Train Epoch: 42 [15600/17352 (90%)] Loss: -193351.234375\n",
      "Train Epoch: 42 [15680/17352 (90%)] Loss: -224853.031250\n",
      "Train Epoch: 42 [15760/17352 (91%)] Loss: -159755.343750\n",
      "Train Epoch: 42 [15840/17352 (91%)] Loss: -178834.031250\n",
      "Train Epoch: 42 [15920/17352 (92%)] Loss: -152735.343750\n",
      "Train Epoch: 42 [16000/17352 (92%)] Loss: -198298.968750\n",
      "Train Epoch: 42 [16080/17352 (93%)] Loss: -227889.796875\n",
      "Train Epoch: 42 [16160/17352 (93%)] Loss: -199515.750000\n",
      "Train Epoch: 42 [16240/17352 (94%)] Loss: -174644.109375\n",
      "Train Epoch: 42 [16320/17352 (94%)] Loss: -190980.687500\n",
      "Train Epoch: 42 [16400/17352 (95%)] Loss: -170239.562500\n",
      "Train Epoch: 42 [16480/17352 (95%)] Loss: -194052.406250\n",
      "Train Epoch: 42 [16560/17352 (95%)] Loss: -171725.187500\n",
      "Train Epoch: 42 [16640/17352 (96%)] Loss: -192287.953125\n",
      "Train Epoch: 42 [16720/17352 (96%)] Loss: -202166.921875\n",
      "Train Epoch: 42 [16800/17352 (97%)] Loss: -181981.531250\n",
      "Train Epoch: 42 [16880/17352 (97%)] Loss: -173885.546875\n",
      "Train Epoch: 42 [16960/17352 (98%)] Loss: -201972.593750\n",
      "Train Epoch: 42 [17040/17352 (98%)] Loss: -189724.578125\n",
      "Train Epoch: 42 [17120/17352 (99%)] Loss: -170102.187500\n",
      "Train Epoch: 42 [17200/17352 (99%)] Loss: -175206.640625\n",
      "Train Epoch: 42 [17280/17352 (100%)] Loss: -183278.031250\n",
      "Train Epoch: 42 [17360/17352 (100%)] Loss: -198542.265625\n",
      "    epoch          : 42\n",
      "    loss           : -189367.4611712457\n",
      "    val_loss       : -23715.713956949297\n",
      "Train Epoch: 43 [0/17352 (0%)] Loss: -236628.718750\n",
      "Train Epoch: 43 [80/17352 (0%)] Loss: -205213.859375\n",
      "Train Epoch: 43 [160/17352 (1%)] Loss: -213338.031250\n",
      "Train Epoch: 43 [240/17352 (1%)] Loss: -193413.890625\n",
      "Train Epoch: 43 [320/17352 (2%)] Loss: -204359.781250\n",
      "Train Epoch: 43 [400/17352 (2%)] Loss: -210203.718750\n",
      "Train Epoch: 43 [480/17352 (3%)] Loss: -187720.828125\n",
      "Train Epoch: 43 [560/17352 (3%)] Loss: -216084.609375\n",
      "Train Epoch: 43 [640/17352 (4%)] Loss: -194499.781250\n",
      "Train Epoch: 43 [720/17352 (4%)] Loss: -210343.531250\n",
      "Train Epoch: 43 [800/17352 (5%)] Loss: -198767.421875\n",
      "Train Epoch: 43 [880/17352 (5%)] Loss: -199801.484375\n",
      "Train Epoch: 43 [960/17352 (6%)] Loss: -205105.562500\n",
      "Train Epoch: 43 [1040/17352 (6%)] Loss: -219253.921875\n",
      "Train Epoch: 43 [1120/17352 (6%)] Loss: -200593.765625\n",
      "Train Epoch: 43 [1200/17352 (7%)] Loss: -206747.171875\n",
      "Train Epoch: 43 [1280/17352 (7%)] Loss: -213822.218750\n",
      "Train Epoch: 43 [1360/17352 (8%)] Loss: -202258.796875\n",
      "Train Epoch: 43 [1440/17352 (8%)] Loss: -230183.437500\n",
      "Train Epoch: 43 [1520/17352 (9%)] Loss: -214512.531250\n",
      "Train Epoch: 43 [1600/17352 (9%)] Loss: -224245.984375\n",
      "Train Epoch: 43 [1680/17352 (10%)] Loss: -213326.156250\n",
      "Train Epoch: 43 [1760/17352 (10%)] Loss: -233736.921875\n",
      "Train Epoch: 43 [1840/17352 (11%)] Loss: -204402.406250\n",
      "Train Epoch: 43 [1920/17352 (11%)] Loss: -204522.531250\n",
      "Train Epoch: 43 [2000/17352 (12%)] Loss: -193570.093750\n",
      "Train Epoch: 43 [2080/17352 (12%)] Loss: -199118.437500\n",
      "Train Epoch: 43 [2160/17352 (12%)] Loss: -214418.843750\n",
      "Train Epoch: 43 [2240/17352 (13%)] Loss: -191627.687500\n",
      "Train Epoch: 43 [2320/17352 (13%)] Loss: -186419.390625\n",
      "Train Epoch: 43 [2400/17352 (14%)] Loss: -159312.734375\n",
      "Train Epoch: 43 [2480/17352 (14%)] Loss: -207093.296875\n",
      "Train Epoch: 43 [2560/17352 (15%)] Loss: -211728.062500\n",
      "Train Epoch: 43 [2640/17352 (15%)] Loss: -163254.765625\n",
      "Train Epoch: 43 [2720/17352 (16%)] Loss: -201362.937500\n",
      "Train Epoch: 43 [2800/17352 (16%)] Loss: -200401.500000\n",
      "Train Epoch: 43 [2880/17352 (17%)] Loss: -164141.421875\n",
      "Train Epoch: 43 [2960/17352 (17%)] Loss: -176876.093750\n",
      "Train Epoch: 43 [3040/17352 (18%)] Loss: -222863.375000\n",
      "Train Epoch: 43 [3120/17352 (18%)] Loss: -192647.250000\n",
      "Train Epoch: 43 [3200/17352 (18%)] Loss: -170346.640625\n",
      "Train Epoch: 43 [3280/17352 (19%)] Loss: -174908.812500\n",
      "Train Epoch: 43 [3360/17352 (19%)] Loss: -201260.734375\n",
      "Train Epoch: 43 [3440/17352 (20%)] Loss: -204691.687500\n",
      "Train Epoch: 43 [3520/17352 (20%)] Loss: -203269.218750\n",
      "Train Epoch: 43 [3600/17352 (21%)] Loss: -218746.125000\n",
      "Train Epoch: 43 [3680/17352 (21%)] Loss: -148505.265625\n",
      "Train Epoch: 43 [3760/17352 (22%)] Loss: -196120.968750\n",
      "Train Epoch: 43 [3840/17352 (22%)] Loss: -167091.984375\n",
      "Train Epoch: 43 [3920/17352 (23%)] Loss: -190933.500000\n",
      "Train Epoch: 43 [4000/17352 (23%)] Loss: -191835.156250\n",
      "Train Epoch: 43 [4080/17352 (24%)] Loss: -159728.515625\n",
      "Train Epoch: 43 [4160/17352 (24%)] Loss: -148923.718750\n",
      "Train Epoch: 43 [4240/17352 (24%)] Loss: -228090.968750\n",
      "Train Epoch: 43 [4320/17352 (25%)] Loss: -191804.375000\n",
      "Train Epoch: 43 [4400/17352 (25%)] Loss: -197592.109375\n",
      "Train Epoch: 43 [4480/17352 (26%)] Loss: -198257.531250\n",
      "Train Epoch: 43 [4560/17352 (26%)] Loss: -191945.593750\n",
      "Train Epoch: 43 [4640/17352 (27%)] Loss: -151509.843750\n",
      "Train Epoch: 43 [4720/17352 (27%)] Loss: -192891.937500\n",
      "Train Epoch: 43 [4800/17352 (28%)] Loss: -210910.093750\n",
      "Train Epoch: 43 [4880/17352 (28%)] Loss: -171727.546875\n",
      "Train Epoch: 43 [4960/17352 (29%)] Loss: -200849.078125\n",
      "Train Epoch: 43 [5040/17352 (29%)] Loss: -193170.406250\n",
      "Train Epoch: 43 [5120/17352 (30%)] Loss: -202091.281250\n",
      "Train Epoch: 43 [5200/17352 (30%)] Loss: -181687.468750\n",
      "Train Epoch: 43 [5280/17352 (30%)] Loss: -208021.406250\n",
      "Train Epoch: 43 [5360/17352 (31%)] Loss: -200191.234375\n",
      "Train Epoch: 43 [5440/17352 (31%)] Loss: -187712.890625\n",
      "Train Epoch: 43 [5520/17352 (32%)] Loss: -178206.140625\n",
      "Train Epoch: 43 [5600/17352 (32%)] Loss: -192949.906250\n",
      "Train Epoch: 43 [5680/17352 (33%)] Loss: -183775.687500\n",
      "Train Epoch: 43 [5760/17352 (33%)] Loss: -156477.109375\n",
      "Train Epoch: 43 [5840/17352 (34%)] Loss: -179675.546875\n",
      "Train Epoch: 43 [5920/17352 (34%)] Loss: -215964.500000\n",
      "Train Epoch: 43 [6000/17352 (35%)] Loss: -205215.750000\n",
      "Train Epoch: 43 [6080/17352 (35%)] Loss: -172958.781250\n",
      "Train Epoch: 43 [6160/17352 (36%)] Loss: -190979.312500\n",
      "Train Epoch: 43 [6240/17352 (36%)] Loss: -173940.250000\n",
      "Train Epoch: 43 [6320/17352 (36%)] Loss: -213402.015625\n",
      "Train Epoch: 43 [6400/17352 (37%)] Loss: -177461.812500\n",
      "Train Epoch: 43 [6480/17352 (37%)] Loss: -177598.000000\n",
      "Train Epoch: 43 [6560/17352 (38%)] Loss: -225319.125000\n",
      "Train Epoch: 43 [6640/17352 (38%)] Loss: -182739.500000\n",
      "Train Epoch: 43 [6720/17352 (39%)] Loss: -160149.359375\n",
      "Train Epoch: 43 [6800/17352 (39%)] Loss: -167039.406250\n",
      "Train Epoch: 43 [6880/17352 (40%)] Loss: -151218.812500\n",
      "Train Epoch: 43 [6960/17352 (40%)] Loss: -210400.937500\n",
      "Train Epoch: 43 [7040/17352 (41%)] Loss: -227881.593750\n",
      "Train Epoch: 43 [7120/17352 (41%)] Loss: -199410.453125\n",
      "Train Epoch: 43 [7200/17352 (41%)] Loss: -212971.734375\n",
      "Train Epoch: 43 [7280/17352 (42%)] Loss: -209506.046875\n",
      "Train Epoch: 43 [7360/17352 (42%)] Loss: -169003.921875\n",
      "Train Epoch: 43 [7440/17352 (43%)] Loss: -224860.265625\n",
      "Train Epoch: 43 [7520/17352 (43%)] Loss: -181012.859375\n",
      "Train Epoch: 43 [7600/17352 (44%)] Loss: -189481.609375\n",
      "Train Epoch: 43 [7680/17352 (44%)] Loss: -174516.062500\n",
      "Train Epoch: 43 [7760/17352 (45%)] Loss: -183609.406250\n",
      "Train Epoch: 43 [7840/17352 (45%)] Loss: -160102.156250\n",
      "Train Epoch: 43 [7920/17352 (46%)] Loss: -184845.531250\n",
      "Train Epoch: 43 [8000/17352 (46%)] Loss: -193800.875000\n",
      "Train Epoch: 43 [8080/17352 (47%)] Loss: -179023.093750\n",
      "Train Epoch: 43 [8160/17352 (47%)] Loss: -134538.812500\n",
      "Train Epoch: 43 [8240/17352 (47%)] Loss: -199062.875000\n",
      "Train Epoch: 43 [8320/17352 (48%)] Loss: -193041.000000\n",
      "Train Epoch: 43 [8400/17352 (48%)] Loss: -209193.828125\n",
      "Train Epoch: 43 [8480/17352 (49%)] Loss: -209819.937500\n",
      "Train Epoch: 43 [8560/17352 (49%)] Loss: -187210.281250\n",
      "Train Epoch: 43 [8640/17352 (50%)] Loss: -165604.921875\n",
      "Train Epoch: 43 [8720/17352 (50%)] Loss: -210485.718750\n",
      "Train Epoch: 43 [8800/17352 (51%)] Loss: -174989.703125\n",
      "Train Epoch: 43 [8880/17352 (51%)] Loss: -193051.953125\n",
      "Train Epoch: 43 [8960/17352 (52%)] Loss: -181915.000000\n",
      "Train Epoch: 43 [9040/17352 (52%)] Loss: -212616.390625\n",
      "Train Epoch: 43 [9120/17352 (53%)] Loss: -147405.578125\n",
      "Train Epoch: 43 [9200/17352 (53%)] Loss: -196813.031250\n",
      "Train Epoch: 43 [9280/17352 (53%)] Loss: -173037.156250\n",
      "Train Epoch: 43 [9360/17352 (54%)] Loss: -208304.328125\n",
      "Train Epoch: 43 [9440/17352 (54%)] Loss: -190587.937500\n",
      "Train Epoch: 43 [9520/17352 (55%)] Loss: -176277.187500\n",
      "Train Epoch: 43 [9600/17352 (55%)] Loss: -183506.750000\n",
      "Train Epoch: 43 [9680/17352 (56%)] Loss: -151731.593750\n",
      "Train Epoch: 43 [9760/17352 (56%)] Loss: -178817.281250\n",
      "Train Epoch: 43 [9840/17352 (57%)] Loss: -205392.562500\n",
      "Train Epoch: 43 [9920/17352 (57%)] Loss: -184021.390625\n",
      "Train Epoch: 43 [10000/17352 (58%)] Loss: -192686.531250\n",
      "Train Epoch: 43 [10080/17352 (58%)] Loss: -176674.484375\n",
      "Train Epoch: 43 [10160/17352 (59%)] Loss: -192004.031250\n",
      "Train Epoch: 43 [10240/17352 (59%)] Loss: -179961.328125\n",
      "Train Epoch: 43 [10320/17352 (59%)] Loss: -184593.500000\n",
      "Train Epoch: 43 [10400/17352 (60%)] Loss: -187121.062500\n",
      "Train Epoch: 43 [10480/17352 (60%)] Loss: -203674.609375\n",
      "Train Epoch: 43 [10560/17352 (61%)] Loss: -171320.468750\n",
      "Train Epoch: 43 [10640/17352 (61%)] Loss: -207830.015625\n",
      "Train Epoch: 43 [10720/17352 (62%)] Loss: -198305.781250\n",
      "Train Epoch: 43 [10800/17352 (62%)] Loss: -162563.656250\n",
      "Train Epoch: 43 [10880/17352 (63%)] Loss: -202195.984375\n",
      "Train Epoch: 43 [10960/17352 (63%)] Loss: -202478.828125\n",
      "Train Epoch: 43 [11040/17352 (64%)] Loss: -189562.578125\n",
      "Train Epoch: 43 [11120/17352 (64%)] Loss: -176031.046875\n",
      "Train Epoch: 43 [11200/17352 (65%)] Loss: -188563.921875\n",
      "Train Epoch: 43 [11280/17352 (65%)] Loss: -160051.046875\n",
      "Train Epoch: 43 [11360/17352 (65%)] Loss: -192243.437500\n",
      "Train Epoch: 43 [11440/17352 (66%)] Loss: -177304.140625\n",
      "Train Epoch: 43 [11520/17352 (66%)] Loss: -191560.218750\n",
      "Train Epoch: 43 [11600/17352 (67%)] Loss: -161091.125000\n",
      "Train Epoch: 43 [11680/17352 (67%)] Loss: -164989.843750\n",
      "Train Epoch: 43 [11760/17352 (68%)] Loss: -191673.828125\n",
      "Train Epoch: 43 [11840/17352 (68%)] Loss: -193126.687500\n",
      "Train Epoch: 43 [11920/17352 (69%)] Loss: -204598.781250\n",
      "Train Epoch: 43 [12000/17352 (69%)] Loss: -187348.656250\n",
      "Train Epoch: 43 [12080/17352 (70%)] Loss: -175321.953125\n",
      "Train Epoch: 43 [12160/17352 (70%)] Loss: -182779.406250\n",
      "Train Epoch: 43 [12240/17352 (71%)] Loss: -185826.187500\n",
      "Train Epoch: 43 [12320/17352 (71%)] Loss: -181153.546875\n",
      "Train Epoch: 43 [12400/17352 (71%)] Loss: -178822.984375\n",
      "Train Epoch: 43 [12480/17352 (72%)] Loss: -204361.812500\n",
      "Train Epoch: 43 [12560/17352 (72%)] Loss: -169189.593750\n",
      "Train Epoch: 43 [12640/17352 (73%)] Loss: -181614.140625\n",
      "Train Epoch: 43 [12720/17352 (73%)] Loss: -199174.734375\n",
      "Train Epoch: 43 [12800/17352 (74%)] Loss: -183720.921875\n",
      "Train Epoch: 43 [12880/17352 (74%)] Loss: -172542.625000\n",
      "Train Epoch: 43 [12960/17352 (75%)] Loss: -191592.906250\n",
      "Train Epoch: 43 [13040/17352 (75%)] Loss: -168069.750000\n",
      "Train Epoch: 43 [13120/17352 (76%)] Loss: -167304.796875\n",
      "Train Epoch: 43 [13200/17352 (76%)] Loss: -207773.843750\n",
      "Train Epoch: 43 [13280/17352 (77%)] Loss: -187639.296875\n",
      "Train Epoch: 43 [13360/17352 (77%)] Loss: -178427.640625\n",
      "Train Epoch: 43 [13440/17352 (77%)] Loss: -189015.828125\n",
      "Train Epoch: 43 [13520/17352 (78%)] Loss: -187886.265625\n",
      "Train Epoch: 43 [13600/17352 (78%)] Loss: -206602.062500\n",
      "Train Epoch: 43 [13680/17352 (79%)] Loss: -176598.640625\n",
      "Train Epoch: 43 [13760/17352 (79%)] Loss: -191723.437500\n",
      "Train Epoch: 43 [13840/17352 (80%)] Loss: -186780.312500\n",
      "Train Epoch: 43 [13920/17352 (80%)] Loss: -209592.921875\n",
      "Train Epoch: 43 [14000/17352 (81%)] Loss: -179389.078125\n",
      "Train Epoch: 43 [14080/17352 (81%)] Loss: -180916.546875\n",
      "Train Epoch: 43 [14160/17352 (82%)] Loss: -205022.843750\n",
      "Train Epoch: 43 [14240/17352 (82%)] Loss: -178657.250000\n",
      "Train Epoch: 43 [14320/17352 (83%)] Loss: -190232.328125\n",
      "Train Epoch: 43 [14400/17352 (83%)] Loss: -157591.031250\n",
      "Train Epoch: 43 [14480/17352 (83%)] Loss: -177306.328125\n",
      "Train Epoch: 43 [14560/17352 (84%)] Loss: -184470.390625\n",
      "Train Epoch: 43 [14640/17352 (84%)] Loss: -176078.468750\n",
      "Train Epoch: 43 [14720/17352 (85%)] Loss: -181758.531250\n",
      "Train Epoch: 43 [14800/17352 (85%)] Loss: -194050.312500\n",
      "Train Epoch: 43 [14880/17352 (86%)] Loss: -214746.750000\n",
      "Train Epoch: 43 [14960/17352 (86%)] Loss: -152901.000000\n",
      "Train Epoch: 43 [15040/17352 (87%)] Loss: -184954.875000\n",
      "Train Epoch: 43 [15120/17352 (87%)] Loss: -178799.078125\n",
      "Train Epoch: 43 [15200/17352 (88%)] Loss: -178727.953125\n",
      "Train Epoch: 43 [15280/17352 (88%)] Loss: -205638.640625\n",
      "Train Epoch: 43 [15360/17352 (89%)] Loss: -191157.593750\n",
      "Train Epoch: 43 [15440/17352 (89%)] Loss: -136429.781250\n",
      "Train Epoch: 43 [15520/17352 (89%)] Loss: -142336.421875\n",
      "Train Epoch: 43 [15600/17352 (90%)] Loss: -203513.296875\n",
      "Train Epoch: 43 [15680/17352 (90%)] Loss: -168048.890625\n",
      "Train Epoch: 43 [15760/17352 (91%)] Loss: -181417.203125\n",
      "Train Epoch: 43 [15840/17352 (91%)] Loss: -167249.968750\n",
      "Train Epoch: 43 [15920/17352 (92%)] Loss: -192782.734375\n",
      "Train Epoch: 43 [16000/17352 (92%)] Loss: -175662.984375\n",
      "Train Epoch: 43 [16080/17352 (93%)] Loss: -181004.859375\n",
      "Train Epoch: 43 [16160/17352 (93%)] Loss: -201089.343750\n",
      "Train Epoch: 43 [16240/17352 (94%)] Loss: -203435.640625\n",
      "Train Epoch: 43 [16320/17352 (94%)] Loss: -180642.625000\n",
      "Train Epoch: 43 [16400/17352 (95%)] Loss: -200327.781250\n",
      "Train Epoch: 43 [16480/17352 (95%)] Loss: -194071.328125\n",
      "Train Epoch: 43 [16560/17352 (95%)] Loss: -197317.703125\n",
      "Train Epoch: 43 [16640/17352 (96%)] Loss: -164953.375000\n",
      "Train Epoch: 43 [16720/17352 (96%)] Loss: -191333.062500\n",
      "Train Epoch: 43 [16800/17352 (97%)] Loss: -182729.546875\n",
      "Train Epoch: 43 [16880/17352 (97%)] Loss: -165760.687500\n",
      "Train Epoch: 43 [16960/17352 (98%)] Loss: -184457.359375\n",
      "Train Epoch: 43 [17040/17352 (98%)] Loss: -199784.828125\n",
      "Train Epoch: 43 [17120/17352 (99%)] Loss: -151508.046875\n",
      "Train Epoch: 43 [17200/17352 (99%)] Loss: -172890.640625\n",
      "Train Epoch: 43 [17280/17352 (100%)] Loss: -168250.468750\n",
      "Train Epoch: 43 [17360/17352 (100%)] Loss: -169170.765625\n",
      "    epoch          : 43\n",
      "    loss           : -189065.43886651323\n",
      "    val_loss       : -23715.401388965303\n",
      "Train Epoch: 44 [0/17352 (0%)] Loss: -212394.031250\n",
      "Train Epoch: 44 [80/17352 (0%)] Loss: -214511.265625\n",
      "Train Epoch: 44 [160/17352 (1%)] Loss: -211892.343750\n",
      "Train Epoch: 44 [240/17352 (1%)] Loss: -229229.750000\n",
      "Train Epoch: 44 [320/17352 (2%)] Loss: -217630.078125\n",
      "Train Epoch: 44 [400/17352 (2%)] Loss: -198115.562500\n",
      "Train Epoch: 44 [480/17352 (3%)] Loss: -213833.078125\n",
      "Train Epoch: 44 [560/17352 (3%)] Loss: -212251.687500\n",
      "Train Epoch: 44 [640/17352 (4%)] Loss: -196436.593750\n",
      "Train Epoch: 44 [720/17352 (4%)] Loss: -212697.453125\n",
      "Train Epoch: 44 [800/17352 (5%)] Loss: -236633.640625\n",
      "Train Epoch: 44 [880/17352 (5%)] Loss: -202274.046875\n",
      "Train Epoch: 44 [960/17352 (6%)] Loss: -185288.953125\n",
      "Train Epoch: 44 [1040/17352 (6%)] Loss: -204530.531250\n",
      "Train Epoch: 44 [1120/17352 (6%)] Loss: -199900.750000\n",
      "Train Epoch: 44 [1200/17352 (7%)] Loss: -216199.125000\n",
      "Train Epoch: 44 [1280/17352 (7%)] Loss: -199107.984375\n",
      "Train Epoch: 44 [1360/17352 (8%)] Loss: -204731.046875\n",
      "Train Epoch: 44 [1440/17352 (8%)] Loss: -210632.625000\n",
      "Train Epoch: 44 [1520/17352 (9%)] Loss: -210524.453125\n",
      "Train Epoch: 44 [1600/17352 (9%)] Loss: -215828.093750\n",
      "Train Epoch: 44 [1680/17352 (10%)] Loss: -224256.062500\n",
      "Train Epoch: 44 [1760/17352 (10%)] Loss: -193570.093750\n",
      "Train Epoch: 44 [1840/17352 (11%)] Loss: -193414.000000\n",
      "Train Epoch: 44 [1920/17352 (11%)] Loss: -196924.093750\n",
      "Train Epoch: 44 [2000/17352 (12%)] Loss: -201665.968750\n",
      "Train Epoch: 44 [2080/17352 (12%)] Loss: -210211.656250\n",
      "Train Epoch: 44 [2160/17352 (12%)] Loss: -193710.921875\n",
      "Train Epoch: 44 [2240/17352 (13%)] Loss: -206474.375000\n",
      "Train Epoch: 44 [2320/17352 (13%)] Loss: -202233.468750\n",
      "Train Epoch: 44 [2400/17352 (14%)] Loss: -194067.046875\n",
      "Train Epoch: 44 [2480/17352 (14%)] Loss: -189021.625000\n",
      "Train Epoch: 44 [2560/17352 (15%)] Loss: -186554.281250\n",
      "Train Epoch: 44 [2640/17352 (15%)] Loss: -188153.812500\n",
      "Train Epoch: 44 [2720/17352 (16%)] Loss: -206158.656250\n",
      "Train Epoch: 44 [2800/17352 (16%)] Loss: -200460.187500\n",
      "Train Epoch: 44 [2880/17352 (17%)] Loss: -164745.250000\n",
      "Train Epoch: 44 [2960/17352 (17%)] Loss: -164801.656250\n",
      "Train Epoch: 44 [3040/17352 (18%)] Loss: -173584.171875\n",
      "Train Epoch: 44 [3120/17352 (18%)] Loss: -186489.203125\n",
      "Train Epoch: 44 [3200/17352 (18%)] Loss: -169967.281250\n",
      "Train Epoch: 44 [3280/17352 (19%)] Loss: -155862.843750\n",
      "Train Epoch: 44 [3360/17352 (19%)] Loss: -181374.984375\n",
      "Train Epoch: 44 [3440/17352 (20%)] Loss: -205726.468750\n",
      "Train Epoch: 44 [3520/17352 (20%)] Loss: -185542.937500\n",
      "Train Epoch: 44 [3600/17352 (21%)] Loss: -208754.500000\n",
      "Train Epoch: 44 [3680/17352 (21%)] Loss: -191718.421875\n",
      "Train Epoch: 44 [3760/17352 (22%)] Loss: -187354.437500\n",
      "Train Epoch: 44 [3840/17352 (22%)] Loss: -208025.468750\n",
      "Train Epoch: 44 [3920/17352 (23%)] Loss: -174545.359375\n",
      "Train Epoch: 44 [4000/17352 (23%)] Loss: -215652.015625\n",
      "Train Epoch: 44 [4080/17352 (24%)] Loss: -187216.390625\n",
      "Train Epoch: 44 [4160/17352 (24%)] Loss: -201935.406250\n",
      "Train Epoch: 44 [4240/17352 (24%)] Loss: -172188.937500\n",
      "Train Epoch: 44 [4320/17352 (25%)] Loss: -178091.375000\n",
      "Train Epoch: 44 [4400/17352 (25%)] Loss: -175354.546875\n",
      "Train Epoch: 44 [4480/17352 (26%)] Loss: -210155.390625\n",
      "Train Epoch: 44 [4560/17352 (26%)] Loss: -223957.437500\n",
      "Train Epoch: 44 [4640/17352 (27%)] Loss: -212975.671875\n",
      "Train Epoch: 44 [4720/17352 (27%)] Loss: -209273.468750\n",
      "Train Epoch: 44 [4800/17352 (28%)] Loss: -225317.375000\n",
      "Train Epoch: 44 [4880/17352 (28%)] Loss: -185061.515625\n",
      "Train Epoch: 44 [4960/17352 (29%)] Loss: -175601.812500\n",
      "Train Epoch: 44 [5040/17352 (29%)] Loss: -208717.250000\n",
      "Train Epoch: 44 [5120/17352 (30%)] Loss: -182521.546875\n",
      "Train Epoch: 44 [5200/17352 (30%)] Loss: -178631.750000\n",
      "Train Epoch: 44 [5280/17352 (30%)] Loss: -193093.546875\n",
      "Train Epoch: 44 [5360/17352 (31%)] Loss: -186844.531250\n",
      "Train Epoch: 44 [5440/17352 (31%)] Loss: -177779.375000\n",
      "Train Epoch: 44 [5520/17352 (32%)] Loss: -179169.703125\n",
      "Train Epoch: 44 [5600/17352 (32%)] Loss: -193515.328125\n",
      "Train Epoch: 44 [5680/17352 (33%)] Loss: -211625.421875\n",
      "Train Epoch: 44 [5760/17352 (33%)] Loss: -200337.187500\n",
      "Train Epoch: 44 [5840/17352 (34%)] Loss: -181890.250000\n",
      "Train Epoch: 44 [5920/17352 (34%)] Loss: -172951.453125\n",
      "Train Epoch: 44 [6000/17352 (35%)] Loss: -205206.796875\n",
      "Train Epoch: 44 [6080/17352 (35%)] Loss: -195054.000000\n",
      "Train Epoch: 44 [6160/17352 (36%)] Loss: -216391.250000\n",
      "Train Epoch: 44 [6240/17352 (36%)] Loss: -179485.203125\n",
      "Train Epoch: 44 [6320/17352 (36%)] Loss: -203149.562500\n",
      "Train Epoch: 44 [6400/17352 (37%)] Loss: -185227.593750\n",
      "Train Epoch: 44 [6480/17352 (37%)] Loss: -173879.031250\n",
      "Train Epoch: 44 [6560/17352 (38%)] Loss: -178662.921875\n",
      "Train Epoch: 44 [6640/17352 (38%)] Loss: -176925.312500\n",
      "Train Epoch: 44 [6720/17352 (39%)] Loss: -172558.218750\n",
      "Train Epoch: 44 [6800/17352 (39%)] Loss: -182554.953125\n",
      "Train Epoch: 44 [6880/17352 (40%)] Loss: -197642.828125\n",
      "Train Epoch: 44 [6960/17352 (40%)] Loss: -146006.359375\n",
      "Train Epoch: 44 [7040/17352 (41%)] Loss: -188801.484375\n",
      "Train Epoch: 44 [7120/17352 (41%)] Loss: -191048.578125\n",
      "Train Epoch: 44 [7200/17352 (41%)] Loss: -195101.562500\n",
      "Train Epoch: 44 [7280/17352 (42%)] Loss: -210558.046875\n",
      "Train Epoch: 44 [7360/17352 (42%)] Loss: -189504.718750\n",
      "Train Epoch: 44 [7440/17352 (43%)] Loss: -188429.234375\n",
      "Train Epoch: 44 [7520/17352 (43%)] Loss: -183606.406250\n",
      "Train Epoch: 44 [7600/17352 (44%)] Loss: -192680.000000\n",
      "Train Epoch: 44 [7680/17352 (44%)] Loss: -180049.953125\n",
      "Train Epoch: 44 [7760/17352 (45%)] Loss: -175397.812500\n",
      "Train Epoch: 44 [7840/17352 (45%)] Loss: -180240.312500\n",
      "Train Epoch: 44 [7920/17352 (46%)] Loss: -174873.843750\n",
      "Train Epoch: 44 [8000/17352 (46%)] Loss: -167479.140625\n",
      "Train Epoch: 44 [8080/17352 (47%)] Loss: -179007.687500\n",
      "Train Epoch: 44 [8160/17352 (47%)] Loss: -163086.453125\n",
      "Train Epoch: 44 [8240/17352 (47%)] Loss: -208045.687500\n",
      "Train Epoch: 44 [8320/17352 (48%)] Loss: -186159.015625\n",
      "Train Epoch: 44 [8400/17352 (48%)] Loss: -178316.531250\n",
      "Train Epoch: 44 [8480/17352 (49%)] Loss: -194053.140625\n",
      "Train Epoch: 44 [8560/17352 (49%)] Loss: -177627.156250\n",
      "Train Epoch: 44 [8640/17352 (50%)] Loss: -201115.093750\n",
      "Train Epoch: 44 [8720/17352 (50%)] Loss: -200124.875000\n",
      "Train Epoch: 44 [8800/17352 (51%)] Loss: -220009.781250\n",
      "Train Epoch: 44 [8880/17352 (51%)] Loss: -201958.718750\n",
      "Train Epoch: 44 [8960/17352 (52%)] Loss: -165988.328125\n",
      "Train Epoch: 44 [9040/17352 (52%)] Loss: -154602.281250\n",
      "Train Epoch: 44 [9120/17352 (53%)] Loss: -183390.265625\n",
      "Train Epoch: 44 [9200/17352 (53%)] Loss: -185170.359375\n",
      "Train Epoch: 44 [9280/17352 (53%)] Loss: -177301.328125\n",
      "Train Epoch: 44 [9360/17352 (54%)] Loss: -170304.375000\n",
      "Train Epoch: 44 [9440/17352 (54%)] Loss: -199597.781250\n",
      "Train Epoch: 44 [9520/17352 (55%)] Loss: -206596.609375\n",
      "Train Epoch: 44 [9600/17352 (55%)] Loss: -177731.562500\n",
      "Train Epoch: 44 [9680/17352 (56%)] Loss: -163959.187500\n",
      "Train Epoch: 44 [9760/17352 (56%)] Loss: -221255.656250\n",
      "Train Epoch: 44 [9840/17352 (57%)] Loss: -173439.984375\n",
      "Train Epoch: 44 [9920/17352 (57%)] Loss: -199451.937500\n",
      "Train Epoch: 44 [10000/17352 (58%)] Loss: -167248.109375\n",
      "Train Epoch: 44 [10080/17352 (58%)] Loss: -179442.609375\n",
      "Train Epoch: 44 [10160/17352 (59%)] Loss: -175669.687500\n",
      "Train Epoch: 44 [10240/17352 (59%)] Loss: -167722.750000\n",
      "Train Epoch: 44 [10320/17352 (59%)] Loss: -202936.437500\n",
      "Train Epoch: 44 [10400/17352 (60%)] Loss: -195721.421875\n",
      "Train Epoch: 44 [10480/17352 (60%)] Loss: -202082.265625\n",
      "Train Epoch: 44 [10560/17352 (61%)] Loss: -174032.843750\n",
      "Train Epoch: 44 [10640/17352 (61%)] Loss: -210790.609375\n",
      "Train Epoch: 44 [10720/17352 (62%)] Loss: -159692.656250\n",
      "Train Epoch: 44 [10800/17352 (62%)] Loss: -185400.484375\n",
      "Train Epoch: 44 [10880/17352 (63%)] Loss: -204366.281250\n",
      "Train Epoch: 44 [10960/17352 (63%)] Loss: -170107.500000\n",
      "Train Epoch: 44 [11040/17352 (64%)] Loss: -223678.953125\n",
      "Train Epoch: 44 [11120/17352 (64%)] Loss: -149334.109375\n",
      "Train Epoch: 44 [11200/17352 (65%)] Loss: -194929.656250\n",
      "Train Epoch: 44 [11280/17352 (65%)] Loss: -195065.046875\n",
      "Train Epoch: 44 [11360/17352 (65%)] Loss: -197381.531250\n",
      "Train Epoch: 44 [11440/17352 (66%)] Loss: -176041.781250\n",
      "Train Epoch: 44 [11520/17352 (66%)] Loss: -185292.234375\n",
      "Train Epoch: 44 [11600/17352 (67%)] Loss: -195514.312500\n",
      "Train Epoch: 44 [11680/17352 (67%)] Loss: -157595.500000\n",
      "Train Epoch: 44 [11760/17352 (68%)] Loss: -184490.671875\n",
      "Train Epoch: 44 [11840/17352 (68%)] Loss: -207834.515625\n",
      "Train Epoch: 44 [11920/17352 (69%)] Loss: -171706.343750\n",
      "Train Epoch: 44 [12000/17352 (69%)] Loss: -170240.531250\n",
      "Train Epoch: 44 [12080/17352 (70%)] Loss: -192270.187500\n",
      "Train Epoch: 44 [12160/17352 (70%)] Loss: -184166.484375\n",
      "Train Epoch: 44 [12240/17352 (71%)] Loss: -225478.390625\n",
      "Train Epoch: 44 [12320/17352 (71%)] Loss: -186686.468750\n",
      "Train Epoch: 44 [12400/17352 (71%)] Loss: -171584.937500\n",
      "Train Epoch: 44 [12480/17352 (72%)] Loss: -157486.046875\n",
      "Train Epoch: 44 [12560/17352 (72%)] Loss: -205801.093750\n",
      "Train Epoch: 44 [12640/17352 (73%)] Loss: -170781.546875\n",
      "Train Epoch: 44 [12720/17352 (73%)] Loss: -197599.578125\n",
      "Train Epoch: 44 [12800/17352 (74%)] Loss: -218840.984375\n",
      "Train Epoch: 44 [12880/17352 (74%)] Loss: -202011.000000\n",
      "Train Epoch: 44 [12960/17352 (75%)] Loss: -196942.390625\n",
      "Train Epoch: 44 [13040/17352 (75%)] Loss: -199150.218750\n",
      "Train Epoch: 44 [13120/17352 (76%)] Loss: -166467.953125\n",
      "Train Epoch: 44 [13200/17352 (76%)] Loss: -196810.906250\n",
      "Train Epoch: 44 [13280/17352 (77%)] Loss: -196695.250000\n",
      "Train Epoch: 44 [13360/17352 (77%)] Loss: -180965.906250\n",
      "Train Epoch: 44 [13440/17352 (77%)] Loss: -179966.750000\n",
      "Train Epoch: 44 [13520/17352 (78%)] Loss: -176703.562500\n",
      "Train Epoch: 44 [13600/17352 (78%)] Loss: -180907.312500\n",
      "Train Epoch: 44 [13680/17352 (79%)] Loss: -184469.640625\n",
      "Train Epoch: 44 [13760/17352 (79%)] Loss: -219920.437500\n",
      "Train Epoch: 44 [13840/17352 (80%)] Loss: -174450.843750\n",
      "Train Epoch: 44 [13920/17352 (80%)] Loss: -196033.031250\n",
      "Train Epoch: 44 [14000/17352 (81%)] Loss: -169187.312500\n",
      "Train Epoch: 44 [14080/17352 (81%)] Loss: -204660.093750\n",
      "Train Epoch: 44 [14160/17352 (82%)] Loss: -148152.578125\n",
      "Train Epoch: 44 [14240/17352 (82%)] Loss: -184839.828125\n",
      "Train Epoch: 44 [14320/17352 (83%)] Loss: -185317.078125\n",
      "Train Epoch: 44 [14400/17352 (83%)] Loss: -158254.125000\n",
      "Train Epoch: 44 [14480/17352 (83%)] Loss: -202976.765625\n",
      "Train Epoch: 44 [14560/17352 (84%)] Loss: -187262.171875\n",
      "Train Epoch: 44 [14640/17352 (84%)] Loss: -173941.843750\n",
      "Train Epoch: 44 [14720/17352 (85%)] Loss: -195381.171875\n",
      "Train Epoch: 44 [14800/17352 (85%)] Loss: -164874.281250\n",
      "Train Epoch: 44 [14880/17352 (86%)] Loss: -178214.062500\n",
      "Train Epoch: 44 [14960/17352 (86%)] Loss: -181540.828125\n",
      "Train Epoch: 44 [15040/17352 (87%)] Loss: -231043.406250\n",
      "Train Epoch: 44 [15120/17352 (87%)] Loss: -202177.796875\n",
      "Train Epoch: 44 [15200/17352 (88%)] Loss: -185565.281250\n",
      "Train Epoch: 44 [15280/17352 (88%)] Loss: -163549.687500\n",
      "Train Epoch: 44 [15360/17352 (89%)] Loss: -192385.546875\n",
      "Train Epoch: 44 [15440/17352 (89%)] Loss: -192363.296875\n",
      "Train Epoch: 44 [15520/17352 (89%)] Loss: -148438.234375\n",
      "Train Epoch: 44 [15600/17352 (90%)] Loss: -209589.171875\n",
      "Train Epoch: 44 [15680/17352 (90%)] Loss: -218411.281250\n",
      "Train Epoch: 44 [15760/17352 (91%)] Loss: -210253.343750\n",
      "Train Epoch: 44 [15840/17352 (91%)] Loss: -186802.046875\n",
      "Train Epoch: 44 [15920/17352 (92%)] Loss: -199782.843750\n",
      "Train Epoch: 44 [16000/17352 (92%)] Loss: -228142.671875\n",
      "Train Epoch: 44 [16080/17352 (93%)] Loss: -196127.390625\n",
      "Train Epoch: 44 [16160/17352 (93%)] Loss: -143626.453125\n",
      "Train Epoch: 44 [16240/17352 (94%)] Loss: -164143.437500\n",
      "Train Epoch: 44 [16320/17352 (94%)] Loss: -180838.921875\n",
      "Train Epoch: 44 [16400/17352 (95%)] Loss: -196509.171875\n",
      "Train Epoch: 44 [16480/17352 (95%)] Loss: -173925.609375\n",
      "Train Epoch: 44 [16560/17352 (95%)] Loss: -187882.968750\n",
      "Train Epoch: 44 [16640/17352 (96%)] Loss: -190510.656250\n",
      "Train Epoch: 44 [16720/17352 (96%)] Loss: -174508.781250\n",
      "Train Epoch: 44 [16800/17352 (97%)] Loss: -187506.906250\n",
      "Train Epoch: 44 [16880/17352 (97%)] Loss: -173657.671875\n",
      "Train Epoch: 44 [16960/17352 (98%)] Loss: -179012.937500\n",
      "Train Epoch: 44 [17040/17352 (98%)] Loss: -180502.687500\n",
      "Train Epoch: 44 [17120/17352 (99%)] Loss: -203514.750000\n",
      "Train Epoch: 44 [17200/17352 (99%)] Loss: -187718.703125\n",
      "Train Epoch: 44 [17280/17352 (100%)] Loss: -183924.328125\n",
      "Train Epoch: 44 [17360/17352 (100%)] Loss: -170537.562500\n",
      "    epoch          : 44\n",
      "    loss           : -189541.59593462312\n",
      "    val_loss       : -23715.62514055279\n",
      "Train Epoch: 45 [0/17352 (0%)] Loss: -206559.515625\n",
      "Train Epoch: 45 [80/17352 (0%)] Loss: -206137.593750\n",
      "Train Epoch: 45 [160/17352 (1%)] Loss: -182778.921875\n",
      "Train Epoch: 45 [240/17352 (1%)] Loss: -204694.703125\n",
      "Train Epoch: 45 [320/17352 (2%)] Loss: -209546.656250\n",
      "Train Epoch: 45 [400/17352 (2%)] Loss: -213820.921875\n",
      "Train Epoch: 45 [480/17352 (3%)] Loss: -211897.359375\n",
      "Train Epoch: 45 [560/17352 (3%)] Loss: -229960.390625\n",
      "Train Epoch: 45 [640/17352 (4%)] Loss: -194486.484375\n",
      "Train Epoch: 45 [720/17352 (4%)] Loss: -208532.593750\n",
      "Train Epoch: 45 [800/17352 (5%)] Loss: -230189.703125\n",
      "Train Epoch: 45 [880/17352 (5%)] Loss: -219659.437500\n",
      "Train Epoch: 45 [960/17352 (6%)] Loss: -214703.765625\n",
      "Train Epoch: 45 [1040/17352 (6%)] Loss: -236515.656250\n",
      "Train Epoch: 45 [1120/17352 (6%)] Loss: -207166.421875\n",
      "Train Epoch: 45 [1200/17352 (7%)] Loss: -205188.000000\n",
      "Train Epoch: 45 [1280/17352 (7%)] Loss: -186069.421875\n",
      "Train Epoch: 45 [1360/17352 (8%)] Loss: -204401.593750\n",
      "Train Epoch: 45 [1440/17352 (8%)] Loss: -199811.218750\n",
      "Train Epoch: 45 [1520/17352 (9%)] Loss: -212250.656250\n",
      "Train Epoch: 45 [1600/17352 (9%)] Loss: -198112.390625\n",
      "Train Epoch: 45 [1680/17352 (10%)] Loss: -196421.859375\n",
      "Train Epoch: 45 [1760/17352 (10%)] Loss: -199536.453125\n",
      "Train Epoch: 45 [1840/17352 (11%)] Loss: -217938.578125\n",
      "Train Epoch: 45 [1920/17352 (11%)] Loss: -204361.000000\n",
      "Train Epoch: 45 [2000/17352 (12%)] Loss: -210625.359375\n",
      "Train Epoch: 45 [2080/17352 (12%)] Loss: -210519.578125\n",
      "Train Epoch: 45 [2160/17352 (12%)] Loss: -199103.812500\n",
      "Train Epoch: 45 [2240/17352 (13%)] Loss: -193919.171875\n",
      "Train Epoch: 45 [2320/17352 (13%)] Loss: -204493.859375\n",
      "Train Epoch: 45 [2400/17352 (14%)] Loss: -186040.453125\n",
      "Train Epoch: 45 [2480/17352 (14%)] Loss: -181721.906250\n",
      "Train Epoch: 45 [2560/17352 (15%)] Loss: -201376.250000\n",
      "Train Epoch: 45 [2640/17352 (15%)] Loss: -142327.375000\n",
      "Train Epoch: 45 [2720/17352 (16%)] Loss: -190472.406250\n",
      "Train Epoch: 45 [2800/17352 (16%)] Loss: -180885.359375\n",
      "Train Epoch: 45 [2880/17352 (17%)] Loss: -176705.093750\n",
      "Train Epoch: 45 [2960/17352 (17%)] Loss: -185513.468750\n",
      "Train Epoch: 45 [3040/17352 (18%)] Loss: -183392.890625\n",
      "Train Epoch: 45 [3120/17352 (18%)] Loss: -179015.218750\n",
      "Train Epoch: 45 [3200/17352 (18%)] Loss: -208796.140625\n",
      "Train Epoch: 45 [3280/17352 (19%)] Loss: -207865.468750\n",
      "Train Epoch: 45 [3360/17352 (19%)] Loss: -198543.718750\n",
      "Train Epoch: 45 [3440/17352 (20%)] Loss: -205169.281250\n",
      "Train Epoch: 45 [3520/17352 (20%)] Loss: -212647.250000\n",
      "Train Epoch: 45 [3600/17352 (21%)] Loss: -189533.062500\n",
      "Train Epoch: 45 [3680/17352 (21%)] Loss: -169157.875000\n",
      "Train Epoch: 45 [3760/17352 (22%)] Loss: -196935.218750\n",
      "Train Epoch: 45 [3840/17352 (22%)] Loss: -195829.421875\n",
      "Train Epoch: 45 [3920/17352 (23%)] Loss: -193001.859375\n",
      "Train Epoch: 45 [4000/17352 (23%)] Loss: -188157.046875\n",
      "Train Epoch: 45 [4080/17352 (24%)] Loss: -202571.406250\n",
      "Train Epoch: 45 [4160/17352 (24%)] Loss: -138334.281250\n",
      "Train Epoch: 45 [4240/17352 (24%)] Loss: -185998.734375\n",
      "Train Epoch: 45 [4320/17352 (25%)] Loss: -129699.390625\n",
      "Train Epoch: 45 [4400/17352 (25%)] Loss: -195053.125000\n",
      "Train Epoch: 45 [4480/17352 (26%)] Loss: -148401.328125\n",
      "Train Epoch: 45 [4560/17352 (26%)] Loss: -186682.484375\n",
      "Train Epoch: 45 [4640/17352 (27%)] Loss: -180971.140625\n",
      "Train Epoch: 45 [4720/17352 (27%)] Loss: -154600.906250\n",
      "Train Epoch: 45 [4800/17352 (28%)] Loss: -175402.171875\n",
      "Train Epoch: 45 [4880/17352 (28%)] Loss: -148444.296875\n",
      "Train Epoch: 45 [4960/17352 (29%)] Loss: -190237.328125\n",
      "Train Epoch: 45 [5040/17352 (29%)] Loss: -183777.953125\n",
      "Train Epoch: 45 [5120/17352 (30%)] Loss: -196112.140625\n",
      "Train Epoch: 45 [5200/17352 (30%)] Loss: -165801.593750\n",
      "Train Epoch: 45 [5280/17352 (30%)] Loss: -171227.062500\n",
      "Train Epoch: 45 [5360/17352 (31%)] Loss: -181373.500000\n",
      "Train Epoch: 45 [5440/17352 (31%)] Loss: -166667.968750\n",
      "Train Epoch: 45 [5520/17352 (32%)] Loss: -206692.312500\n",
      "Train Epoch: 45 [5600/17352 (32%)] Loss: -209418.781250\n",
      "Train Epoch: 45 [5680/17352 (33%)] Loss: -186549.000000\n",
      "Train Epoch: 45 [5760/17352 (33%)] Loss: -160142.359375\n",
      "Train Epoch: 45 [5840/17352 (34%)] Loss: -208337.250000\n",
      "Train Epoch: 45 [5920/17352 (34%)] Loss: -178134.156250\n",
      "Train Epoch: 45 [6000/17352 (35%)] Loss: -179737.937500\n",
      "Train Epoch: 45 [6080/17352 (35%)] Loss: -176533.625000\n",
      "Train Epoch: 45 [6160/17352 (36%)] Loss: -178869.359375\n",
      "Train Epoch: 45 [6240/17352 (36%)] Loss: -197078.156250\n",
      "Train Epoch: 45 [6320/17352 (36%)] Loss: -174513.593750\n",
      "Train Epoch: 45 [6400/17352 (37%)] Loss: -186782.062500\n",
      "Train Epoch: 45 [6480/17352 (37%)] Loss: -199149.390625\n",
      "Train Epoch: 45 [6560/17352 (38%)] Loss: -202941.828125\n",
      "Train Epoch: 45 [6640/17352 (38%)] Loss: -190916.390625\n",
      "Train Epoch: 45 [6720/17352 (39%)] Loss: -177606.656250\n",
      "Train Epoch: 45 [6800/17352 (39%)] Loss: -185570.343750\n",
      "Train Epoch: 45 [6880/17352 (40%)] Loss: -178823.437500\n",
      "Train Epoch: 45 [6960/17352 (40%)] Loss: -180745.687500\n",
      "Train Epoch: 45 [7040/17352 (41%)] Loss: -190387.796875\n",
      "Train Epoch: 45 [7120/17352 (41%)] Loss: -167301.328125\n",
      "Train Epoch: 45 [7200/17352 (41%)] Loss: -212128.609375\n",
      "Train Epoch: 45 [7280/17352 (42%)] Loss: -190501.687500\n",
      "Train Epoch: 45 [7360/17352 (42%)] Loss: -198699.796875\n",
      "Train Epoch: 45 [7440/17352 (43%)] Loss: -173008.921875\n",
      "Train Epoch: 45 [7520/17352 (43%)] Loss: -203882.531250\n",
      "Train Epoch: 45 [7600/17352 (44%)] Loss: -191887.265625\n",
      "Train Epoch: 45 [7680/17352 (44%)] Loss: -177252.265625\n",
      "Train Epoch: 45 [7760/17352 (45%)] Loss: -210554.562500\n",
      "Train Epoch: 45 [7840/17352 (45%)] Loss: -184598.906250\n",
      "Train Epoch: 45 [7920/17352 (46%)] Loss: -196943.515625\n",
      "Train Epoch: 45 [8000/17352 (46%)] Loss: -204649.281250\n",
      "Train Epoch: 45 [8080/17352 (47%)] Loss: -188270.359375\n",
      "Train Epoch: 45 [8160/17352 (47%)] Loss: -185333.109375\n",
      "Train Epoch: 45 [8240/17352 (47%)] Loss: -196501.609375\n",
      "Train Epoch: 45 [8320/17352 (48%)] Loss: -199791.718750\n",
      "Train Epoch: 45 [8400/17352 (48%)] Loss: -189013.359375\n",
      "Train Epoch: 45 [8480/17352 (49%)] Loss: -176585.656250\n",
      "Train Epoch: 45 [8560/17352 (49%)] Loss: -193507.140625\n",
      "Train Epoch: 45 [8640/17352 (50%)] Loss: -198294.843750\n",
      "Train Epoch: 45 [8720/17352 (50%)] Loss: -188210.750000\n",
      "Train Epoch: 45 [8800/17352 (51%)] Loss: -188968.687500\n",
      "Train Epoch: 45 [8880/17352 (51%)] Loss: -208424.812500\n",
      "Train Epoch: 45 [8960/17352 (52%)] Loss: -203485.609375\n",
      "Train Epoch: 45 [9040/17352 (52%)] Loss: -175494.843750\n",
      "Train Epoch: 45 [9120/17352 (53%)] Loss: -193486.656250\n",
      "Train Epoch: 45 [9200/17352 (53%)] Loss: -202847.125000\n",
      "Train Epoch: 45 [9280/17352 (53%)] Loss: -142617.875000\n",
      "Train Epoch: 45 [9360/17352 (54%)] Loss: -176682.078125\n",
      "Train Epoch: 45 [9440/17352 (54%)] Loss: -173033.375000\n",
      "Train Epoch: 45 [9520/17352 (55%)] Loss: -185316.015625\n",
      "Train Epoch: 45 [9600/17352 (55%)] Loss: -197590.015625\n",
      "Train Epoch: 45 [9680/17352 (56%)] Loss: -191721.687500\n",
      "Train Epoch: 45 [9760/17352 (56%)] Loss: -159672.156250\n",
      "Train Epoch: 45 [9840/17352 (57%)] Loss: -163971.046875\n",
      "Train Epoch: 45 [9920/17352 (57%)] Loss: -183797.875000\n",
      "Train Epoch: 45 [10000/17352 (58%)] Loss: -206162.546875\n",
      "Train Epoch: 45 [10080/17352 (58%)] Loss: -181979.781250\n",
      "Train Epoch: 45 [10160/17352 (59%)] Loss: -185790.281250\n",
      "Train Epoch: 45 [10240/17352 (59%)] Loss: -218515.031250\n",
      "Train Epoch: 45 [10320/17352 (59%)] Loss: -218405.625000\n",
      "Train Epoch: 45 [10400/17352 (60%)] Loss: -200629.765625\n",
      "Train Epoch: 45 [10480/17352 (60%)] Loss: -190213.031250\n",
      "Train Epoch: 45 [10560/17352 (61%)] Loss: -179457.234375\n",
      "Train Epoch: 45 [10640/17352 (61%)] Loss: -200203.250000\n",
      "Train Epoch: 45 [10720/17352 (62%)] Loss: -192396.843750\n",
      "Train Epoch: 45 [10800/17352 (62%)] Loss: -165358.062500\n",
      "Train Epoch: 45 [10880/17352 (63%)] Loss: -190082.031250\n",
      "Train Epoch: 45 [10960/17352 (63%)] Loss: -184985.921875\n",
      "Train Epoch: 45 [11040/17352 (64%)] Loss: -164876.640625\n",
      "Train Epoch: 45 [11120/17352 (64%)] Loss: -200838.890625\n",
      "Train Epoch: 45 [11200/17352 (65%)] Loss: -171906.921875\n",
      "Train Epoch: 45 [11280/17352 (65%)] Loss: -179894.796875\n",
      "Train Epoch: 45 [11360/17352 (65%)] Loss: -196302.609375\n",
      "Train Epoch: 45 [11440/17352 (66%)] Loss: -149030.500000\n",
      "Train Epoch: 45 [11520/17352 (66%)] Loss: -153320.359375\n",
      "Train Epoch: 45 [11600/17352 (67%)] Loss: -184750.906250\n",
      "Train Epoch: 45 [11680/17352 (67%)] Loss: -200170.218750\n",
      "Train Epoch: 45 [11760/17352 (68%)] Loss: -182394.953125\n",
      "Train Epoch: 45 [11840/17352 (68%)] Loss: -185437.187500\n",
      "Train Epoch: 45 [11920/17352 (69%)] Loss: -207835.031250\n",
      "Train Epoch: 45 [12000/17352 (69%)] Loss: -209819.359375\n",
      "Train Epoch: 45 [12080/17352 (70%)] Loss: -183057.921875\n",
      "Train Epoch: 45 [12160/17352 (70%)] Loss: -171852.000000\n",
      "Train Epoch: 45 [12240/17352 (71%)] Loss: -170042.718750\n",
      "Train Epoch: 45 [12320/17352 (71%)] Loss: -200614.015625\n",
      "Train Epoch: 45 [12400/17352 (71%)] Loss: -180050.062500\n",
      "Train Epoch: 45 [12480/17352 (72%)] Loss: -202971.437500\n",
      "Train Epoch: 45 [12560/17352 (72%)] Loss: -202309.109375\n",
      "Train Epoch: 45 [12640/17352 (73%)] Loss: -169752.015625\n",
      "Train Epoch: 45 [12720/17352 (73%)] Loss: -177578.984375\n",
      "Train Epoch: 45 [12800/17352 (74%)] Loss: -197103.828125\n",
      "Train Epoch: 45 [12880/17352 (74%)] Loss: -163756.359375\n",
      "Train Epoch: 45 [12960/17352 (75%)] Loss: -193132.593750\n",
      "Train Epoch: 45 [13040/17352 (75%)] Loss: -174030.937500\n",
      "Train Epoch: 45 [13120/17352 (76%)] Loss: -208008.203125\n",
      "Train Epoch: 45 [13200/17352 (76%)] Loss: -165996.640625\n",
      "Train Epoch: 45 [13280/17352 (77%)] Loss: -189164.921875\n",
      "Train Epoch: 45 [13360/17352 (77%)] Loss: -184475.203125\n",
      "Train Epoch: 45 [13440/17352 (77%)] Loss: -203429.812500\n",
      "Train Epoch: 45 [13520/17352 (78%)] Loss: -180254.984375\n",
      "Train Epoch: 45 [13600/17352 (78%)] Loss: -170242.500000\n",
      "Train Epoch: 45 [13680/17352 (79%)] Loss: -187941.546875\n",
      "Train Epoch: 45 [13760/17352 (79%)] Loss: -199178.203125\n",
      "Train Epoch: 45 [13840/17352 (80%)] Loss: -217620.453125\n",
      "Train Epoch: 45 [13920/17352 (80%)] Loss: -189604.593750\n",
      "Train Epoch: 45 [14000/17352 (81%)] Loss: -167191.437500\n",
      "Train Epoch: 45 [14080/17352 (81%)] Loss: -184959.781250\n",
      "Train Epoch: 45 [14160/17352 (82%)] Loss: -225473.234375\n",
      "Train Epoch: 45 [14240/17352 (82%)] Loss: -181692.609375\n",
      "Train Epoch: 45 [14320/17352 (83%)] Loss: -201321.250000\n",
      "Train Epoch: 45 [14400/17352 (83%)] Loss: -192242.031250\n",
      "Train Epoch: 45 [14480/17352 (83%)] Loss: -192115.359375\n",
      "Train Epoch: 45 [14560/17352 (84%)] Loss: -215966.546875\n",
      "Train Epoch: 45 [14640/17352 (84%)] Loss: -180791.625000\n",
      "Train Epoch: 45 [14720/17352 (85%)] Loss: -168256.750000\n",
      "Train Epoch: 45 [14800/17352 (85%)] Loss: -201829.093750\n",
      "Train Epoch: 45 [14880/17352 (86%)] Loss: -140589.984375\n",
      "Train Epoch: 45 [14960/17352 (86%)] Loss: -185541.156250\n",
      "Train Epoch: 45 [15040/17352 (87%)] Loss: -192947.453125\n",
      "Train Epoch: 45 [15120/17352 (87%)] Loss: -200870.546875\n",
      "Train Epoch: 45 [15200/17352 (88%)] Loss: -163249.562500\n",
      "Train Epoch: 45 [15280/17352 (88%)] Loss: -176029.437500\n",
      "Train Epoch: 45 [15360/17352 (89%)] Loss: -195063.968750\n",
      "Train Epoch: 45 [15440/17352 (89%)] Loss: -167865.906250\n",
      "Train Epoch: 45 [15520/17352 (89%)] Loss: -156470.484375\n",
      "Train Epoch: 45 [15600/17352 (90%)] Loss: -175667.562500\n",
      "Train Epoch: 45 [15680/17352 (90%)] Loss: -183160.843750\n",
      "Train Epoch: 45 [15760/17352 (91%)] Loss: -188056.328125\n",
      "Train Epoch: 45 [15840/17352 (91%)] Loss: -170785.656250\n",
      "Train Epoch: 45 [15920/17352 (92%)] Loss: -169439.390625\n",
      "Train Epoch: 45 [16000/17352 (92%)] Loss: -182683.015625\n",
      "Train Epoch: 45 [16080/17352 (93%)] Loss: -167729.750000\n",
      "Train Epoch: 45 [16160/17352 (93%)] Loss: -189218.062500\n",
      "Train Epoch: 45 [16240/17352 (94%)] Loss: -197521.531250\n",
      "Train Epoch: 45 [16320/17352 (94%)] Loss: -189293.375000\n",
      "Train Epoch: 45 [16400/17352 (95%)] Loss: -211633.843750\n",
      "Train Epoch: 45 [16480/17352 (95%)] Loss: -196038.078125\n",
      "Train Epoch: 45 [16560/17352 (95%)] Loss: -164942.750000\n",
      "Train Epoch: 45 [16640/17352 (96%)] Loss: -215643.078125\n",
      "Train Epoch: 45 [16720/17352 (96%)] Loss: -206085.750000\n",
      "Train Epoch: 45 [16800/17352 (97%)] Loss: -203142.796875\n",
      "Train Epoch: 45 [16880/17352 (97%)] Loss: -202174.562500\n",
      "Train Epoch: 45 [16960/17352 (98%)] Loss: -214685.203125\n",
      "Train Epoch: 45 [17040/17352 (98%)] Loss: -180299.218750\n",
      "Train Epoch: 45 [17120/17352 (99%)] Loss: -202076.328125\n",
      "Train Epoch: 45 [17200/17352 (99%)] Loss: -191584.453125\n",
      "Train Epoch: 45 [17280/17352 (100%)] Loss: -190497.546875\n",
      "Train Epoch: 45 [17360/17352 (100%)] Loss: -178730.375000\n",
      "    epoch          : 45\n",
      "    loss           : -188981.34638413406\n",
      "    val_loss       : -23715.37776334521\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch45.pth ...\n",
      "Train Epoch: 46 [0/17352 (0%)] Loss: -214412.484375\n",
      "Train Epoch: 46 [80/17352 (0%)] Loss: -211889.953125\n",
      "Train Epoch: 46 [160/17352 (1%)] Loss: -219198.921875\n",
      "Train Epoch: 46 [240/17352 (1%)] Loss: -205185.343750\n",
      "Train Epoch: 46 [320/17352 (2%)] Loss: -188747.609375\n",
      "Train Epoch: 46 [400/17352 (2%)] Loss: -214712.296875\n",
      "Train Epoch: 46 [480/17352 (3%)] Loss: -198110.343750\n",
      "Train Epoch: 46 [560/17352 (3%)] Loss: -207168.281250\n",
      "Train Epoch: 46 [640/17352 (4%)] Loss: -199534.296875\n",
      "Train Epoch: 46 [720/17352 (4%)] Loss: -209638.703125\n",
      "Train Epoch: 46 [800/17352 (5%)] Loss: -185148.062500\n",
      "Train Epoch: 46 [880/17352 (5%)] Loss: -199110.875000\n",
      "Train Epoch: 46 [960/17352 (6%)] Loss: -218540.062500\n",
      "Train Epoch: 46 [1040/17352 (6%)] Loss: -211105.906250\n",
      "Train Epoch: 46 [1120/17352 (6%)] Loss: -204361.328125\n",
      "Train Epoch: 46 [1200/17352 (7%)] Loss: -198760.000000\n",
      "Train Epoch: 46 [1280/17352 (7%)] Loss: -204734.593750\n",
      "Train Epoch: 46 [1360/17352 (8%)] Loss: -228910.015625\n",
      "Train Epoch: 46 [1440/17352 (8%)] Loss: -185288.468750\n",
      "Train Epoch: 46 [1520/17352 (9%)] Loss: -191870.640625\n",
      "Train Epoch: 46 [1600/17352 (9%)] Loss: -200605.218750\n",
      "Train Epoch: 46 [1680/17352 (10%)] Loss: -202318.015625\n",
      "Train Epoch: 46 [1760/17352 (10%)] Loss: -217931.593750\n",
      "Train Epoch: 46 [1840/17352 (11%)] Loss: -212700.812500\n",
      "Train Epoch: 46 [1920/17352 (11%)] Loss: -213339.250000\n",
      "Train Epoch: 46 [2000/17352 (12%)] Loss: -194288.187500\n",
      "Train Epoch: 46 [2080/17352 (12%)] Loss: -193406.093750\n",
      "Train Epoch: 46 [2160/17352 (12%)] Loss: -204530.031250\n",
      "Train Epoch: 46 [2240/17352 (13%)] Loss: -184985.187500\n",
      "Train Epoch: 46 [2320/17352 (13%)] Loss: -170776.046875\n",
      "Train Epoch: 46 [2400/17352 (14%)] Loss: -192110.734375\n",
      "Train Epoch: 46 [2480/17352 (14%)] Loss: -195721.453125\n",
      "Train Epoch: 46 [2560/17352 (15%)] Loss: -203844.093750\n",
      "Train Epoch: 46 [2640/17352 (15%)] Loss: -215643.625000\n",
      "Train Epoch: 46 [2720/17352 (16%)] Loss: -187322.140625\n",
      "Train Epoch: 46 [2800/17352 (16%)] Loss: -208037.296875\n",
      "Train Epoch: 46 [2880/17352 (17%)] Loss: -215641.453125\n",
      "Train Epoch: 46 [2960/17352 (17%)] Loss: -183721.109375\n",
      "Train Epoch: 46 [3040/17352 (18%)] Loss: -207092.578125\n",
      "Train Epoch: 46 [3120/17352 (18%)] Loss: -175405.125000\n",
      "Train Epoch: 46 [3200/17352 (18%)] Loss: -194070.921875\n",
      "Train Epoch: 46 [3280/17352 (19%)] Loss: -216385.796875\n",
      "Train Epoch: 46 [3360/17352 (19%)] Loss: -199787.859375\n",
      "Train Epoch: 46 [3440/17352 (20%)] Loss: -168680.312500\n",
      "Train Epoch: 46 [3520/17352 (20%)] Loss: -186684.375000\n",
      "Train Epoch: 46 [3600/17352 (21%)] Loss: -185437.468750\n",
      "Train Epoch: 46 [3680/17352 (21%)] Loss: -203141.687500\n",
      "Train Epoch: 46 [3760/17352 (22%)] Loss: -177488.203125\n",
      "Train Epoch: 46 [3840/17352 (22%)] Loss: -202083.125000\n",
      "Train Epoch: 46 [3920/17352 (23%)] Loss: -184253.703125\n",
      "Train Epoch: 46 [4000/17352 (23%)] Loss: -211719.781250\n",
      "Train Epoch: 46 [4080/17352 (24%)] Loss: -188000.437500\n",
      "Train Epoch: 46 [4160/17352 (24%)] Loss: -181674.828125\n",
      "Train Epoch: 46 [4240/17352 (24%)] Loss: -223956.625000\n",
      "Train Epoch: 46 [4320/17352 (25%)] Loss: -211623.343750\n",
      "Train Epoch: 46 [4400/17352 (25%)] Loss: -179462.781250\n",
      "Train Epoch: 46 [4480/17352 (26%)] Loss: -153885.468750\n",
      "Train Epoch: 46 [4560/17352 (26%)] Loss: -182102.609375\n",
      "Train Epoch: 46 [4640/17352 (27%)] Loss: -176036.421875\n",
      "Train Epoch: 46 [4720/17352 (27%)] Loss: -193517.281250\n",
      "Train Epoch: 46 [4800/17352 (28%)] Loss: -207860.031250\n",
      "Train Epoch: 46 [4880/17352 (28%)] Loss: -182732.078125\n",
      "Train Epoch: 46 [4960/17352 (29%)] Loss: -185538.546875\n",
      "Train Epoch: 46 [5040/17352 (29%)] Loss: -187324.015625\n",
      "Train Epoch: 46 [5120/17352 (30%)] Loss: -180963.171875\n",
      "Train Epoch: 46 [5200/17352 (30%)] Loss: -181541.750000\n",
      "Train Epoch: 46 [5280/17352 (30%)] Loss: -170317.968750\n",
      "Train Epoch: 46 [5360/17352 (31%)] Loss: -156475.000000\n",
      "Train Epoch: 46 [5440/17352 (31%)] Loss: -179301.500000\n",
      "Train Epoch: 46 [5520/17352 (32%)] Loss: -174543.609375\n",
      "Train Epoch: 46 [5600/17352 (32%)] Loss: -169617.640625\n",
      "Train Epoch: 46 [5680/17352 (33%)] Loss: -180256.656250\n",
      "Train Epoch: 46 [5760/17352 (33%)] Loss: -180164.062500\n",
      "Train Epoch: 46 [5840/17352 (34%)] Loss: -175596.375000\n",
      "Train Epoch: 46 [5920/17352 (34%)] Loss: -201378.046875\n",
      "Train Epoch: 46 [6000/17352 (35%)] Loss: -180148.781250\n",
      "Train Epoch: 46 [6080/17352 (35%)] Loss: -183058.437500\n",
      "Train Epoch: 46 [6160/17352 (36%)] Loss: -163754.203125\n",
      "Train Epoch: 46 [6240/17352 (36%)] Loss: -205168.250000\n",
      "Train Epoch: 46 [6320/17352 (36%)] Loss: -170104.843750\n",
      "Train Epoch: 46 [6400/17352 (37%)] Loss: -195827.015625\n",
      "Train Epoch: 46 [6480/17352 (37%)] Loss: -225318.453125\n",
      "Train Epoch: 46 [6560/17352 (38%)] Loss: -201956.109375\n",
      "Train Epoch: 46 [6640/17352 (38%)] Loss: -197380.515625\n",
      "Train Epoch: 46 [6720/17352 (39%)] Loss: -183387.312500\n",
      "Train Epoch: 46 [6800/17352 (39%)] Loss: -192999.328125\n",
      "Train Epoch: 46 [6880/17352 (40%)] Loss: -167731.500000\n",
      "Train Epoch: 46 [6960/17352 (40%)] Loss: -201365.000000\n",
      "Train Epoch: 46 [7040/17352 (41%)] Loss: -181968.312500\n",
      "Train Epoch: 46 [7120/17352 (41%)] Loss: -196286.359375\n",
      "Train Epoch: 46 [7200/17352 (41%)] Loss: -197561.859375\n",
      "Train Epoch: 46 [7280/17352 (42%)] Loss: -215962.593750\n",
      "Train Epoch: 46 [7360/17352 (42%)] Loss: -180254.656250\n",
      "Train Epoch: 46 [7440/17352 (43%)] Loss: -205397.031250\n",
      "Train Epoch: 46 [7520/17352 (43%)] Loss: -208002.062500\n",
      "Train Epoch: 46 [7600/17352 (44%)] Loss: -176285.218750\n",
      "Train Epoch: 46 [7680/17352 (44%)] Loss: -151515.031250\n",
      "Train Epoch: 46 [7760/17352 (45%)] Loss: -176167.078125\n",
      "Train Epoch: 46 [7840/17352 (45%)] Loss: -177300.718750\n",
      "Train Epoch: 46 [7920/17352 (46%)] Loss: -175065.687500\n",
      "Train Epoch: 46 [8000/17352 (46%)] Loss: -163769.046875\n",
      "Train Epoch: 46 [8080/17352 (47%)] Loss: -201940.187500\n",
      "Train Epoch: 46 [8160/17352 (47%)] Loss: -193050.359375\n",
      "Train Epoch: 46 [8240/17352 (47%)] Loss: -179739.531250\n",
      "Train Epoch: 46 [8320/17352 (48%)] Loss: -169001.093750\n",
      "Train Epoch: 46 [8400/17352 (48%)] Loss: -165801.906250\n",
      "Train Epoch: 46 [8480/17352 (49%)] Loss: -203750.312500\n",
      "Train Epoch: 46 [8560/17352 (49%)] Loss: -190980.265625\n",
      "Train Epoch: 46 [8640/17352 (50%)] Loss: -173919.906250\n",
      "Train Epoch: 46 [8720/17352 (50%)] Loss: -180105.031250\n",
      "Train Epoch: 46 [8800/17352 (51%)] Loss: -165860.218750\n",
      "Train Epoch: 46 [8880/17352 (51%)] Loss: -192954.703125\n",
      "Train Epoch: 46 [8960/17352 (52%)] Loss: -177247.265625\n",
      "Train Epoch: 46 [9040/17352 (52%)] Loss: -174990.515625\n",
      "Train Epoch: 46 [9120/17352 (53%)] Loss: -197941.406250\n",
      "Train Epoch: 46 [9200/17352 (53%)] Loss: -187306.828125\n",
      "Train Epoch: 46 [9280/17352 (53%)] Loss: -194589.671875\n",
      "Train Epoch: 46 [9360/17352 (54%)] Loss: -221258.390625\n",
      "Train Epoch: 46 [9440/17352 (54%)] Loss: -170036.375000\n",
      "Train Epoch: 46 [9520/17352 (55%)] Loss: -184956.687500\n",
      "Train Epoch: 46 [9600/17352 (55%)] Loss: -183620.203125\n",
      "Train Epoch: 46 [9680/17352 (56%)] Loss: -203509.046875\n",
      "Train Epoch: 46 [9760/17352 (56%)] Loss: -208016.218750\n",
      "Train Epoch: 46 [9840/17352 (57%)] Loss: -187718.109375\n",
      "Train Epoch: 46 [9920/17352 (57%)] Loss: -148151.171875\n",
      "Train Epoch: 46 [10000/17352 (58%)] Loss: -191513.875000\n",
      "Train Epoch: 46 [10080/17352 (58%)] Loss: -193093.890625\n",
      "Train Epoch: 46 [10160/17352 (59%)] Loss: -176681.812500\n",
      "Train Epoch: 46 [10240/17352 (59%)] Loss: -196811.203125\n",
      "Train Epoch: 46 [10320/17352 (59%)] Loss: -173367.812500\n",
      "Train Epoch: 46 [10400/17352 (60%)] Loss: -177575.625000\n",
      "Train Epoch: 46 [10480/17352 (60%)] Loss: -166514.359375\n",
      "Train Epoch: 46 [10560/17352 (61%)] Loss: -222855.578125\n",
      "Train Epoch: 46 [10640/17352 (61%)] Loss: -194068.609375\n",
      "Train Epoch: 46 [10720/17352 (62%)] Loss: -140583.015625\n",
      "Train Epoch: 46 [10800/17352 (62%)] Loss: -188750.453125\n",
      "Train Epoch: 46 [10880/17352 (63%)] Loss: -186798.062500\n",
      "Train Epoch: 46 [10960/17352 (63%)] Loss: -182555.578125\n",
      "Train Epoch: 46 [11040/17352 (64%)] Loss: -201969.968750\n",
      "Train Epoch: 46 [11120/17352 (64%)] Loss: -168250.937500\n",
      "Train Epoch: 46 [11200/17352 (65%)] Loss: -162717.265625\n",
      "Train Epoch: 46 [11280/17352 (65%)] Loss: -177093.640625\n",
      "Train Epoch: 46 [11360/17352 (65%)] Loss: -153318.953125\n",
      "Train Epoch: 46 [11440/17352 (66%)] Loss: -197087.718750\n",
      "Train Epoch: 46 [11520/17352 (66%)] Loss: -190003.578125\n",
      "Train Epoch: 46 [11600/17352 (67%)] Loss: -205512.296875\n",
      "Train Epoch: 46 [11680/17352 (67%)] Loss: -205727.437500\n",
      "Train Epoch: 46 [11760/17352 (68%)] Loss: -198004.593750\n",
      "Train Epoch: 46 [11840/17352 (68%)] Loss: -210640.421875\n",
      "Train Epoch: 46 [11920/17352 (69%)] Loss: -194949.500000\n",
      "Train Epoch: 46 [12000/17352 (69%)] Loss: -175539.953125\n",
      "Train Epoch: 46 [12080/17352 (70%)] Loss: -182326.343750\n",
      "Train Epoch: 46 [12160/17352 (70%)] Loss: -184611.093750\n",
      "Train Epoch: 46 [12240/17352 (71%)] Loss: -159086.984375\n",
      "Train Epoch: 46 [12320/17352 (71%)] Loss: -95263.882812\n",
      "Train Epoch: 46 [12400/17352 (71%)] Loss: -190211.921875\n",
      "Train Epoch: 46 [12480/17352 (72%)] Loss: -188496.906250\n",
      "Train Epoch: 46 [12560/17352 (72%)] Loss: -193494.625000\n",
      "Train Epoch: 46 [12640/17352 (73%)] Loss: -176703.875000\n",
      "Train Epoch: 46 [12720/17352 (73%)] Loss: -188815.984375\n",
      "Train Epoch: 46 [12800/17352 (74%)] Loss: -213233.671875\n",
      "Train Epoch: 46 [12880/17352 (74%)] Loss: -182774.703125\n",
      "Train Epoch: 46 [12960/17352 (75%)] Loss: -166665.765625\n",
      "Train Epoch: 46 [13040/17352 (75%)] Loss: -181252.062500\n",
      "Train Epoch: 46 [13120/17352 (76%)] Loss: -189505.375000\n",
      "Train Epoch: 46 [13200/17352 (76%)] Loss: -203678.046875\n",
      "Train Epoch: 46 [13280/17352 (77%)] Loss: -225462.593750\n",
      "Train Epoch: 46 [13360/17352 (77%)] Loss: -161966.906250\n",
      "Train Epoch: 46 [13440/17352 (77%)] Loss: -181732.140625\n",
      "Train Epoch: 46 [13520/17352 (78%)] Loss: -152738.562500\n",
      "Train Epoch: 46 [13600/17352 (78%)] Loss: -197446.046875\n",
      "Train Epoch: 46 [13680/17352 (79%)] Loss: -202187.140625\n",
      "Train Epoch: 46 [13760/17352 (79%)] Loss: -204938.640625\n",
      "Train Epoch: 46 [13840/17352 (80%)] Loss: -218837.015625\n",
      "Train Epoch: 46 [13920/17352 (80%)] Loss: -203131.531250\n",
      "Train Epoch: 46 [14000/17352 (81%)] Loss: -176596.921875\n",
      "Train Epoch: 46 [14080/17352 (81%)] Loss: -204595.843750\n",
      "Train Epoch: 46 [14160/17352 (82%)] Loss: -203483.781250\n",
      "Train Epoch: 46 [14240/17352 (82%)] Loss: -187531.796875\n",
      "Train Epoch: 46 [14320/17352 (83%)] Loss: -212134.843750\n",
      "Train Epoch: 46 [14400/17352 (83%)] Loss: -180881.312500\n",
      "Train Epoch: 46 [14480/17352 (83%)] Loss: -136427.296875\n",
      "Train Epoch: 46 [14560/17352 (84%)] Loss: -173572.968750\n",
      "Train Epoch: 46 [14640/17352 (84%)] Loss: -183966.140625\n",
      "Train Epoch: 46 [14720/17352 (85%)] Loss: -192004.875000\n",
      "Train Epoch: 46 [14800/17352 (85%)] Loss: -198701.062500\n",
      "Train Epoch: 46 [14880/17352 (86%)] Loss: -163249.515625\n",
      "Train Epoch: 46 [14960/17352 (86%)] Loss: -149022.546875\n",
      "Train Epoch: 46 [15040/17352 (87%)] Loss: -151208.359375\n",
      "Train Epoch: 46 [15120/17352 (87%)] Loss: -186028.562500\n",
      "Train Epoch: 46 [15200/17352 (88%)] Loss: -192990.500000\n",
      "Train Epoch: 46 [15280/17352 (88%)] Loss: -193366.921875\n",
      "Train Epoch: 46 [15360/17352 (89%)] Loss: -185796.750000\n",
      "Train Epoch: 46 [15440/17352 (89%)] Loss: -200166.984375\n",
      "Train Epoch: 46 [15520/17352 (89%)] Loss: -178632.578125\n",
      "Train Epoch: 46 [15600/17352 (90%)] Loss: -206159.843750\n",
      "Train Epoch: 46 [15680/17352 (90%)] Loss: -167955.687500\n",
      "Train Epoch: 46 [15760/17352 (91%)] Loss: -198547.437500\n",
      "Train Epoch: 46 [15840/17352 (91%)] Loss: -193504.921875\n",
      "Train Epoch: 46 [15920/17352 (92%)] Loss: -171548.500000\n",
      "Train Epoch: 46 [16000/17352 (92%)] Loss: -179163.421875\n",
      "Train Epoch: 46 [16080/17352 (93%)] Loss: -214678.187500\n",
      "Train Epoch: 46 [16160/17352 (93%)] Loss: -170229.125000\n",
      "Train Epoch: 46 [16240/17352 (94%)] Loss: -200294.687500\n",
      "Train Epoch: 46 [16320/17352 (94%)] Loss: -172892.203125\n",
      "Train Epoch: 46 [16400/17352 (95%)] Loss: -193125.890625\n",
      "Train Epoch: 46 [16480/17352 (95%)] Loss: -187774.843750\n",
      "Train Epoch: 46 [16560/17352 (95%)] Loss: -159737.500000\n",
      "Train Epoch: 46 [16640/17352 (96%)] Loss: -200486.140625\n",
      "Train Epoch: 46 [16720/17352 (96%)] Loss: -186190.953125\n",
      "Train Epoch: 46 [16800/17352 (97%)] Loss: -179310.437500\n",
      "Train Epoch: 46 [16880/17352 (97%)] Loss: -175310.015625\n",
      "Train Epoch: 46 [16960/17352 (98%)] Loss: -186510.546875\n",
      "Train Epoch: 46 [17040/17352 (98%)] Loss: -196192.359375\n",
      "Train Epoch: 46 [17120/17352 (99%)] Loss: -166248.187500\n",
      "Train Epoch: 46 [17200/17352 (99%)] Loss: -175215.046875\n",
      "Train Epoch: 46 [17280/17352 (100%)] Loss: -191880.906250\n",
      "Train Epoch: 46 [17360/17352 (100%)] Loss: -185232.828125\n",
      "    epoch          : 46\n",
      "    loss           : -189161.3882605725\n",
      "    val_loss       : -23715.719464082675\n",
      "Train Epoch: 47 [0/17352 (0%)] Loss: -236636.578125\n",
      "Train Epoch: 47 [80/17352 (0%)] Loss: -212375.593750\n",
      "Train Epoch: 47 [160/17352 (1%)] Loss: -194296.937500\n",
      "Train Epoch: 47 [240/17352 (1%)] Loss: -216209.234375\n",
      "Train Epoch: 47 [320/17352 (2%)] Loss: -182776.406250\n",
      "Train Epoch: 47 [400/17352 (2%)] Loss: -229234.843750\n",
      "Train Epoch: 47 [480/17352 (3%)] Loss: -213333.390625\n",
      "Train Epoch: 47 [560/17352 (3%)] Loss: -214330.265625\n",
      "Train Epoch: 47 [640/17352 (4%)] Loss: -214500.468750\n",
      "Train Epoch: 47 [720/17352 (4%)] Loss: -196420.343750\n",
      "Train Epoch: 47 [800/17352 (5%)] Loss: -222996.250000\n",
      "Train Epoch: 47 [880/17352 (5%)] Loss: -186078.531250\n",
      "Train Epoch: 47 [960/17352 (6%)] Loss: -233736.421875\n",
      "Train Epoch: 47 [1040/17352 (6%)] Loss: -202034.968750\n",
      "Train Epoch: 47 [1120/17352 (6%)] Loss: -188752.625000\n",
      "Train Epoch: 47 [1200/17352 (7%)] Loss: -226089.500000\n",
      "Train Epoch: 47 [1280/17352 (7%)] Loss: -212391.000000\n",
      "Train Epoch: 47 [1360/17352 (8%)] Loss: -199105.375000\n",
      "Train Epoch: 47 [1440/17352 (8%)] Loss: -208527.968750\n",
      "Train Epoch: 47 [1520/17352 (9%)] Loss: -210526.156250\n",
      "Train Epoch: 47 [1600/17352 (9%)] Loss: -230187.015625\n",
      "Train Epoch: 47 [1680/17352 (10%)] Loss: -185291.265625\n",
      "Train Epoch: 47 [1760/17352 (10%)] Loss: -206753.921875\n",
      "Train Epoch: 47 [1840/17352 (11%)] Loss: -193572.125000\n",
      "Train Epoch: 47 [1920/17352 (11%)] Loss: -228897.140625\n",
      "Train Epoch: 47 [2000/17352 (12%)] Loss: -206786.000000\n",
      "Train Epoch: 47 [2080/17352 (12%)] Loss: -213324.078125\n",
      "Train Epoch: 47 [2160/17352 (12%)] Loss: -205086.187500\n",
      "Train Epoch: 47 [2240/17352 (13%)] Loss: -188440.234375\n",
      "Train Epoch: 47 [2320/17352 (13%)] Loss: -205492.812500\n",
      "Train Epoch: 47 [2400/17352 (14%)] Loss: -176156.156250\n",
      "Train Epoch: 47 [2480/17352 (14%)] Loss: -180916.250000\n",
      "Train Epoch: 47 [2560/17352 (15%)] Loss: -196035.765625\n",
      "Train Epoch: 47 [2640/17352 (15%)] Loss: -196813.156250\n",
      "Train Epoch: 47 [2720/17352 (16%)] Loss: -209817.250000\n",
      "Train Epoch: 47 [2800/17352 (16%)] Loss: -191046.171875\n",
      "Train Epoch: 47 [2880/17352 (17%)] Loss: -217596.203125\n",
      "Train Epoch: 47 [2960/17352 (17%)] Loss: -178603.968750\n",
      "Train Epoch: 47 [3040/17352 (18%)] Loss: -202995.671875\n",
      "Train Epoch: 47 [3120/17352 (18%)] Loss: -163212.859375\n",
      "Train Epoch: 47 [3200/17352 (18%)] Loss: -178094.468750\n",
      "Train Epoch: 47 [3280/17352 (19%)] Loss: -175660.078125\n",
      "Train Epoch: 47 [3360/17352 (19%)] Loss: -183803.031250\n",
      "Train Epoch: 47 [3440/17352 (20%)] Loss: -188156.312500\n",
      "Train Epoch: 47 [3520/17352 (20%)] Loss: -199072.937500\n",
      "Train Epoch: 47 [3600/17352 (21%)] Loss: -163343.281250\n",
      "Train Epoch: 47 [3680/17352 (21%)] Loss: -180310.515625\n",
      "Train Epoch: 47 [3760/17352 (22%)] Loss: -198263.750000\n",
      "Train Epoch: 47 [3840/17352 (22%)] Loss: -171222.796875\n",
      "Train Epoch: 47 [3920/17352 (23%)] Loss: -204414.046875\n",
      "Train Epoch: 47 [4000/17352 (23%)] Loss: -201370.656250\n",
      "Train Epoch: 47 [4080/17352 (24%)] Loss: -188248.281250\n",
      "Train Epoch: 47 [4160/17352 (24%)] Loss: -192997.265625\n",
      "Train Epoch: 47 [4240/17352 (24%)] Loss: -198301.687500\n",
      "Train Epoch: 47 [4320/17352 (25%)] Loss: -192389.546875\n",
      "Train Epoch: 47 [4400/17352 (25%)] Loss: -193443.171875\n",
      "Train Epoch: 47 [4480/17352 (26%)] Loss: -184477.562500\n",
      "Train Epoch: 47 [4560/17352 (26%)] Loss: -192116.312500\n",
      "Train Epoch: 47 [4640/17352 (27%)] Loss: -170683.500000\n",
      "Train Epoch: 47 [4720/17352 (27%)] Loss: -186845.937500\n",
      "Train Epoch: 47 [4800/17352 (28%)] Loss: -220007.421875\n",
      "Train Epoch: 47 [4880/17352 (28%)] Loss: -185566.375000\n",
      "Train Epoch: 47 [4960/17352 (29%)] Loss: -200403.843750\n",
      "Train Epoch: 47 [5040/17352 (29%)] Loss: -180876.203125\n",
      "Train Epoch: 47 [5120/17352 (30%)] Loss: -95255.468750\n",
      "Train Epoch: 47 [5200/17352 (30%)] Loss: -164880.968750\n",
      "Train Epoch: 47 [5280/17352 (30%)] Loss: -204694.078125\n",
      "Train Epoch: 47 [5360/17352 (31%)] Loss: -172618.281250\n",
      "Train Epoch: 47 [5440/17352 (31%)] Loss: -188667.890625\n",
      "Train Epoch: 47 [5520/17352 (32%)] Loss: -174725.250000\n",
      "Train Epoch: 47 [5600/17352 (32%)] Loss: -176584.562500\n",
      "Train Epoch: 47 [5680/17352 (33%)] Loss: -215178.000000\n",
      "Train Epoch: 47 [5760/17352 (33%)] Loss: -187616.078125\n",
      "Train Epoch: 47 [5840/17352 (34%)] Loss: -183756.906250\n",
      "Train Epoch: 47 [5920/17352 (34%)] Loss: -202079.562500\n",
      "Train Epoch: 47 [6000/17352 (35%)] Loss: -177084.218750\n",
      "Train Epoch: 47 [6080/17352 (35%)] Loss: -188861.921875\n",
      "Train Epoch: 47 [6160/17352 (36%)] Loss: -180694.437500\n",
      "Train Epoch: 47 [6240/17352 (36%)] Loss: -184967.718750\n",
      "Train Epoch: 47 [6320/17352 (36%)] Loss: -148444.171875\n",
      "Train Epoch: 47 [6400/17352 (37%)] Loss: -205212.062500\n",
      "Train Epoch: 47 [6480/17352 (37%)] Loss: -187592.281250\n",
      "Train Epoch: 47 [6560/17352 (38%)] Loss: -210395.718750\n",
      "Train Epoch: 47 [6640/17352 (38%)] Loss: -206696.968750\n",
      "Train Epoch: 47 [6720/17352 (39%)] Loss: -167212.156250\n",
      "Train Epoch: 47 [6800/17352 (39%)] Loss: -181610.968750\n",
      "Train Epoch: 47 [6880/17352 (40%)] Loss: -207834.171875\n",
      "Train Epoch: 47 [6960/17352 (40%)] Loss: -192006.859375\n",
      "Train Epoch: 47 [7040/17352 (41%)] Loss: -183262.109375\n",
      "Train Epoch: 47 [7120/17352 (41%)] Loss: -171430.875000\n",
      "Train Epoch: 47 [7200/17352 (41%)] Loss: -208032.046875\n",
      "Train Epoch: 47 [7280/17352 (42%)] Loss: -173367.625000\n",
      "Train Epoch: 47 [7360/17352 (42%)] Loss: -159316.375000\n",
      "Train Epoch: 47 [7440/17352 (43%)] Loss: -195003.343750\n",
      "Train Epoch: 47 [7520/17352 (43%)] Loss: -186720.375000\n",
      "Train Epoch: 47 [7600/17352 (44%)] Loss: -204341.718750\n",
      "Train Epoch: 47 [7680/17352 (44%)] Loss: -187304.859375\n",
      "Train Epoch: 47 [7760/17352 (45%)] Loss: -206925.375000\n",
      "Train Epoch: 47 [7840/17352 (45%)] Loss: -185797.921875\n",
      "Train Epoch: 47 [7920/17352 (46%)] Loss: -159733.359375\n",
      "Train Epoch: 47 [8000/17352 (46%)] Loss: -204616.171875\n",
      "Train Epoch: 47 [8080/17352 (47%)] Loss: -179735.468750\n",
      "Train Epoch: 47 [8160/17352 (47%)] Loss: -208042.953125\n",
      "Train Epoch: 47 [8240/17352 (47%)] Loss: -192751.812500\n",
      "Train Epoch: 47 [8320/17352 (48%)] Loss: -168068.406250\n",
      "Train Epoch: 47 [8400/17352 (48%)] Loss: -196119.218750\n",
      "Train Epoch: 47 [8480/17352 (49%)] Loss: -199522.406250\n",
      "Train Epoch: 47 [8560/17352 (49%)] Loss: -198296.484375\n",
      "Train Epoch: 47 [8640/17352 (50%)] Loss: -200276.390625\n",
      "Train Epoch: 47 [8720/17352 (50%)] Loss: -206347.109375\n",
      "Train Epoch: 47 [8800/17352 (51%)] Loss: -180910.640625\n",
      "Train Epoch: 47 [8880/17352 (51%)] Loss: -183286.828125\n",
      "Train Epoch: 47 [8960/17352 (52%)] Loss: -178827.437500\n",
      "Train Epoch: 47 [9040/17352 (52%)] Loss: -166788.671875\n",
      "Train Epoch: 47 [9120/17352 (53%)] Loss: -178201.125000\n",
      "Train Epoch: 47 [9200/17352 (53%)] Loss: -189218.265625\n",
      "Train Epoch: 47 [9280/17352 (53%)] Loss: -188674.250000\n",
      "Train Epoch: 47 [9360/17352 (54%)] Loss: -183582.000000\n",
      "Train Epoch: 47 [9440/17352 (54%)] Loss: -191829.609375\n",
      "Train Epoch: 47 [9520/17352 (55%)] Loss: -178736.906250\n",
      "Train Epoch: 47 [9600/17352 (55%)] Loss: -165859.328125\n",
      "Train Epoch: 47 [9680/17352 (56%)] Loss: -155864.343750\n",
      "Train Epoch: 47 [9760/17352 (56%)] Loss: -171897.015625\n",
      "Train Epoch: 47 [9840/17352 (57%)] Loss: -161513.171875\n",
      "Train Epoch: 47 [9920/17352 (57%)] Loss: -158743.703125\n",
      "Train Epoch: 47 [10000/17352 (58%)] Loss: -200637.109375\n",
      "Train Epoch: 47 [10080/17352 (58%)] Loss: -203880.718750\n",
      "Train Epoch: 47 [10160/17352 (59%)] Loss: -223683.468750\n",
      "Train Epoch: 47 [10240/17352 (59%)] Loss: -151739.312500\n",
      "Train Epoch: 47 [10320/17352 (59%)] Loss: -201307.765625\n",
      "Train Epoch: 47 [10400/17352 (60%)] Loss: -212893.796875\n",
      "Train Epoch: 47 [10480/17352 (60%)] Loss: -187123.656250\n",
      "Train Epoch: 47 [10560/17352 (61%)] Loss: -213901.218750\n",
      "Train Epoch: 47 [10640/17352 (61%)] Loss: -190939.328125\n",
      "Train Epoch: 47 [10720/17352 (62%)] Loss: -174996.921875\n",
      "Train Epoch: 47 [10800/17352 (62%)] Loss: -176704.718750\n",
      "Train Epoch: 47 [10880/17352 (63%)] Loss: -174035.171875\n",
      "Train Epoch: 47 [10960/17352 (63%)] Loss: -197651.906250\n",
      "Train Epoch: 47 [11040/17352 (64%)] Loss: -165797.265625\n",
      "Train Epoch: 47 [11120/17352 (64%)] Loss: -180536.109375\n",
      "Train Epoch: 47 [11200/17352 (65%)] Loss: -181004.484375\n",
      "Train Epoch: 47 [11280/17352 (65%)] Loss: -177246.843750\n",
      "Train Epoch: 47 [11360/17352 (65%)] Loss: -197346.187500\n",
      "Train Epoch: 47 [11440/17352 (66%)] Loss: -196237.703125\n",
      "Train Epoch: 47 [11520/17352 (66%)] Loss: -169744.515625\n",
      "Train Epoch: 47 [11600/17352 (67%)] Loss: -179495.312500\n",
      "Train Epoch: 47 [11680/17352 (67%)] Loss: -218509.250000\n",
      "Train Epoch: 47 [11760/17352 (68%)] Loss: -164746.750000\n",
      "Train Epoch: 47 [11840/17352 (68%)] Loss: -202249.421875\n",
      "Train Epoch: 47 [11920/17352 (69%)] Loss: -187213.343750\n",
      "Train Epoch: 47 [12000/17352 (69%)] Loss: -153892.187500\n",
      "Train Epoch: 47 [12080/17352 (70%)] Loss: -214754.781250\n",
      "Train Epoch: 47 [12160/17352 (70%)] Loss: -166999.406250\n",
      "Train Epoch: 47 [12240/17352 (71%)] Loss: -197561.843750\n",
      "Train Epoch: 47 [12320/17352 (71%)] Loss: -200418.062500\n",
      "Train Epoch: 47 [12400/17352 (71%)] Loss: -136425.656250\n",
      "Train Epoch: 47 [12480/17352 (72%)] Loss: -205726.046875\n",
      "Train Epoch: 47 [12560/17352 (72%)] Loss: -208020.656250\n",
      "Train Epoch: 47 [12640/17352 (73%)] Loss: -174550.312500\n",
      "Train Epoch: 47 [12720/17352 (73%)] Loss: -210258.546875\n",
      "Train Epoch: 47 [12800/17352 (74%)] Loss: -156611.046875\n",
      "Train Epoch: 47 [12880/17352 (74%)] Loss: -190472.218750\n",
      "Train Epoch: 47 [12960/17352 (75%)] Loss: -183784.218750\n",
      "Train Epoch: 47 [13040/17352 (75%)] Loss: -182778.109375\n",
      "Train Epoch: 47 [13120/17352 (76%)] Loss: -192792.781250\n",
      "Train Epoch: 47 [13200/17352 (76%)] Loss: -176680.187500\n",
      "Train Epoch: 47 [13280/17352 (77%)] Loss: -169164.953125\n",
      "Train Epoch: 47 [13360/17352 (77%)] Loss: -205172.125000\n",
      "Train Epoch: 47 [13440/17352 (77%)] Loss: -202309.531250\n",
      "Train Epoch: 47 [13520/17352 (78%)] Loss: -228242.921875\n",
      "Train Epoch: 47 [13600/17352 (78%)] Loss: -190379.468750\n",
      "Train Epoch: 47 [13680/17352 (79%)] Loss: -197307.250000\n",
      "Train Epoch: 47 [13760/17352 (79%)] Loss: -159667.484375\n",
      "Train Epoch: 47 [13840/17352 (80%)] Loss: -180023.312500\n",
      "Train Epoch: 47 [13920/17352 (80%)] Loss: -179011.578125\n",
      "Train Epoch: 47 [14000/17352 (81%)] Loss: -159611.156250\n",
      "Train Epoch: 47 [14080/17352 (81%)] Loss: -208900.906250\n",
      "Train Epoch: 47 [14160/17352 (82%)] Loss: -196941.625000\n",
      "Train Epoch: 47 [14240/17352 (82%)] Loss: -206220.796875\n",
      "Train Epoch: 47 [14320/17352 (83%)] Loss: -164076.062500\n",
      "Train Epoch: 47 [14400/17352 (83%)] Loss: -200840.125000\n",
      "Train Epoch: 47 [14480/17352 (83%)] Loss: -163090.265625\n",
      "Train Epoch: 47 [14560/17352 (84%)] Loss: -192384.812500\n",
      "Train Epoch: 47 [14640/17352 (84%)] Loss: -179304.828125\n",
      "Train Epoch: 47 [14720/17352 (85%)] Loss: -167727.906250\n",
      "Train Epoch: 47 [14800/17352 (85%)] Loss: -173665.484375\n",
      "Train Epoch: 47 [14880/17352 (86%)] Loss: -162557.437500\n",
      "Train Epoch: 47 [14960/17352 (86%)] Loss: -167869.187500\n",
      "Train Epoch: 47 [15040/17352 (87%)] Loss: -179478.515625\n",
      "Train Epoch: 47 [15120/17352 (87%)] Loss: -203735.187500\n",
      "Train Epoch: 47 [15200/17352 (88%)] Loss: -208128.281250\n",
      "Train Epoch: 47 [15280/17352 (88%)] Loss: -192955.250000\n",
      "Train Epoch: 47 [15360/17352 (89%)] Loss: -157486.812500\n",
      "Train Epoch: 47 [15440/17352 (89%)] Loss: -184602.984375\n",
      "Train Epoch: 47 [15520/17352 (89%)] Loss: -204660.703125\n",
      "Train Epoch: 47 [15600/17352 (90%)] Loss: -191302.875000\n",
      "Train Epoch: 47 [15680/17352 (90%)] Loss: -169004.125000\n",
      "Train Epoch: 47 [15760/17352 (91%)] Loss: -185334.250000\n",
      "Train Epoch: 47 [15840/17352 (91%)] Loss: -180258.281250\n",
      "Train Epoch: 47 [15920/17352 (92%)] Loss: -172553.359375\n",
      "Train Epoch: 47 [16000/17352 (92%)] Loss: -181977.421875\n",
      "Train Epoch: 47 [16080/17352 (93%)] Loss: -159677.687500\n",
      "Train Epoch: 47 [16160/17352 (93%)] Loss: -186944.546875\n",
      "Train Epoch: 47 [16240/17352 (94%)] Loss: -184066.796875\n",
      "Train Epoch: 47 [16320/17352 (94%)] Loss: -195714.421875\n",
      "Train Epoch: 47 [16400/17352 (95%)] Loss: -193002.109375\n",
      "Train Epoch: 47 [16480/17352 (95%)] Loss: -161681.031250\n",
      "Train Epoch: 47 [16560/17352 (95%)] Loss: -176081.703125\n",
      "Train Epoch: 47 [16640/17352 (96%)] Loss: -186039.937500\n",
      "Train Epoch: 47 [16720/17352 (96%)] Loss: -190797.937500\n",
      "Train Epoch: 47 [16800/17352 (97%)] Loss: -179968.437500\n",
      "Train Epoch: 47 [16880/17352 (97%)] Loss: -199003.765625\n",
      "Train Epoch: 47 [16960/17352 (98%)] Loss: -184846.531250\n",
      "Train Epoch: 47 [17040/17352 (98%)] Loss: -175409.984375\n",
      "Train Epoch: 47 [17120/17352 (99%)] Loss: -168051.484375\n",
      "Train Epoch: 47 [17200/17352 (99%)] Loss: -185055.640625\n",
      "Train Epoch: 47 [17280/17352 (100%)] Loss: -207087.437500\n",
      "Train Epoch: 47 [17360/17352 (100%)] Loss: -180515.234375\n",
      "    epoch          : 47\n",
      "    loss           : -189341.17156933257\n",
      "    val_loss       : -23715.94739356959\n",
      "Train Epoch: 48 [0/17352 (0%)] Loss: -187716.062500\n",
      "Train Epoch: 48 [80/17352 (0%)] Loss: -230404.578125\n",
      "Train Epoch: 48 [160/17352 (1%)] Loss: -212372.875000\n",
      "Train Epoch: 48 [240/17352 (1%)] Loss: -213325.203125\n",
      "Train Epoch: 48 [320/17352 (2%)] Loss: -193405.046875\n",
      "Train Epoch: 48 [400/17352 (2%)] Loss: -211099.734375\n",
      "Train Epoch: 48 [480/17352 (3%)] Loss: -204701.156250\n",
      "Train Epoch: 48 [560/17352 (3%)] Loss: -199901.406250\n",
      "Train Epoch: 48 [640/17352 (4%)] Loss: -215484.046875\n",
      "Train Epoch: 48 [720/17352 (4%)] Loss: -196442.406250\n",
      "Train Epoch: 48 [800/17352 (5%)] Loss: -202318.750000\n",
      "Train Epoch: 48 [880/17352 (5%)] Loss: -198763.406250\n",
      "Train Epoch: 48 [960/17352 (6%)] Loss: -236626.750000\n",
      "Train Epoch: 48 [1040/17352 (6%)] Loss: -212663.718750\n",
      "Train Epoch: 48 [1120/17352 (6%)] Loss: -228911.656250\n",
      "Train Epoch: 48 [1200/17352 (7%)] Loss: -214508.437500\n",
      "Train Epoch: 48 [1280/17352 (7%)] Loss: -229236.609375\n",
      "Train Epoch: 48 [1360/17352 (8%)] Loss: -208377.718750\n",
      "Train Epoch: 48 [1440/17352 (8%)] Loss: -203747.218750\n",
      "Train Epoch: 48 [1520/17352 (9%)] Loss: -196921.625000\n",
      "Train Epoch: 48 [1600/17352 (9%)] Loss: -216108.718750\n",
      "Train Epoch: 48 [1680/17352 (10%)] Loss: -229956.796875\n",
      "Train Epoch: 48 [1760/17352 (10%)] Loss: -201667.609375\n",
      "Train Epoch: 48 [1840/17352 (11%)] Loss: -218569.187500\n",
      "Train Epoch: 48 [1920/17352 (11%)] Loss: -199106.265625\n",
      "Train Epoch: 48 [2000/17352 (12%)] Loss: -231326.031250\n",
      "Train Epoch: 48 [2080/17352 (12%)] Loss: -186067.078125\n",
      "Train Epoch: 48 [2160/17352 (12%)] Loss: -213315.984375\n",
      "Train Epoch: 48 [2240/17352 (13%)] Loss: -177279.984375\n",
      "Train Epoch: 48 [2320/17352 (13%)] Loss: -209891.437500\n",
      "Train Epoch: 48 [2400/17352 (14%)] Loss: -178212.625000\n",
      "Train Epoch: 48 [2480/17352 (14%)] Loss: -185006.843750\n",
      "Train Epoch: 48 [2560/17352 (15%)] Loss: -181725.375000\n",
      "Train Epoch: 48 [2640/17352 (15%)] Loss: -195832.171875\n",
      "Train Epoch: 48 [2720/17352 (16%)] Loss: -216322.531250\n",
      "Train Epoch: 48 [2800/17352 (16%)] Loss: -195712.484375\n",
      "Train Epoch: 48 [2880/17352 (17%)] Loss: -197954.625000\n",
      "Train Epoch: 48 [2960/17352 (17%)] Loss: -193354.265625\n",
      "Train Epoch: 48 [3040/17352 (18%)] Loss: -190913.250000\n",
      "Train Epoch: 48 [3120/17352 (18%)] Loss: -155864.843750\n",
      "Train Epoch: 48 [3200/17352 (18%)] Loss: -179497.812500\n",
      "Train Epoch: 48 [3280/17352 (19%)] Loss: -212902.921875\n",
      "Train Epoch: 48 [3360/17352 (19%)] Loss: -210387.046875\n",
      "Train Epoch: 48 [3440/17352 (20%)] Loss: -159664.187500\n",
      "Train Epoch: 48 [3520/17352 (20%)] Loss: -184170.171875\n",
      "Train Epoch: 48 [3600/17352 (21%)] Loss: -184487.750000\n",
      "Train Epoch: 48 [3680/17352 (21%)] Loss: -181918.593750\n",
      "Train Epoch: 48 [3760/17352 (22%)] Loss: -177095.234375\n",
      "Train Epoch: 48 [3840/17352 (22%)] Loss: -140589.390625\n",
      "Train Epoch: 48 [3920/17352 (23%)] Loss: -180993.000000\n",
      "Train Epoch: 48 [4000/17352 (23%)] Loss: -175408.625000\n",
      "Train Epoch: 48 [4080/17352 (24%)] Loss: -196815.500000\n",
      "Train Epoch: 48 [4160/17352 (24%)] Loss: -207864.000000\n",
      "Train Epoch: 48 [4240/17352 (24%)] Loss: -174873.296875\n",
      "Train Epoch: 48 [4320/17352 (25%)] Loss: -192685.968750\n",
      "Train Epoch: 48 [4400/17352 (25%)] Loss: -176582.843750\n",
      "Train Epoch: 48 [4480/17352 (26%)] Loss: -177728.906250\n",
      "Train Epoch: 48 [4560/17352 (26%)] Loss: -173832.046875\n",
      "Train Epoch: 48 [4640/17352 (27%)] Loss: -196119.578125\n",
      "Train Epoch: 48 [4720/17352 (27%)] Loss: -163545.250000\n",
      "Train Epoch: 48 [4800/17352 (28%)] Loss: -146006.656250\n",
      "Train Epoch: 48 [4880/17352 (28%)] Loss: -179007.406250\n",
      "Train Epoch: 48 [4960/17352 (29%)] Loss: -180506.781250\n",
      "Train Epoch: 48 [5040/17352 (29%)] Loss: -185568.171875\n",
      "Train Epoch: 48 [5120/17352 (30%)] Loss: -184256.031250\n",
      "Train Epoch: 48 [5200/17352 (30%)] Loss: -201946.000000\n",
      "Train Epoch: 48 [5280/17352 (30%)] Loss: -200635.562500\n",
      "Train Epoch: 48 [5360/17352 (31%)] Loss: -161091.640625\n",
      "Train Epoch: 48 [5440/17352 (31%)] Loss: -190577.265625\n",
      "Train Epoch: 48 [5520/17352 (32%)] Loss: -161965.265625\n",
      "Train Epoch: 48 [5600/17352 (32%)] Loss: -187786.875000\n",
      "Train Epoch: 48 [5680/17352 (33%)] Loss: -148823.000000\n",
      "Train Epoch: 48 [5760/17352 (33%)] Loss: -175365.703125\n",
      "Train Epoch: 48 [5840/17352 (34%)] Loss: -198256.015625\n",
      "Train Epoch: 48 [5920/17352 (34%)] Loss: -179382.796875\n",
      "Train Epoch: 48 [6000/17352 (35%)] Loss: -163204.453125\n",
      "Train Epoch: 48 [6080/17352 (35%)] Loss: -184459.703125\n",
      "Train Epoch: 48 [6160/17352 (36%)] Loss: -178137.328125\n",
      "Train Epoch: 48 [6240/17352 (36%)] Loss: -179962.437500\n",
      "Train Epoch: 48 [6320/17352 (36%)] Loss: -142610.265625\n",
      "Train Epoch: 48 [6400/17352 (37%)] Loss: -138338.984375\n",
      "Train Epoch: 48 [6480/17352 (37%)] Loss: -181701.265625\n",
      "Train Epoch: 48 [6560/17352 (38%)] Loss: -181338.312500\n",
      "Train Epoch: 48 [6640/17352 (38%)] Loss: -210483.421875\n",
      "Train Epoch: 48 [6720/17352 (39%)] Loss: -154595.515625\n",
      "Train Epoch: 48 [6800/17352 (39%)] Loss: -197087.765625\n",
      "Train Epoch: 48 [6880/17352 (40%)] Loss: -208311.593750\n",
      "Train Epoch: 48 [6960/17352 (40%)] Loss: -196280.796875\n",
      "Train Epoch: 48 [7040/17352 (41%)] Loss: -203507.500000\n",
      "Train Epoch: 48 [7120/17352 (41%)] Loss: -193506.531250\n",
      "Train Epoch: 48 [7200/17352 (41%)] Loss: -169508.031250\n",
      "Train Epoch: 48 [7280/17352 (42%)] Loss: -189398.109375\n",
      "Train Epoch: 48 [7360/17352 (42%)] Loss: -163965.390625\n",
      "Train Epoch: 48 [7440/17352 (43%)] Loss: -186796.015625\n",
      "Train Epoch: 48 [7520/17352 (43%)] Loss: -162558.875000\n",
      "Train Epoch: 48 [7600/17352 (44%)] Loss: -215640.718750\n",
      "Train Epoch: 48 [7680/17352 (44%)] Loss: -171850.718750\n",
      "Train Epoch: 48 [7760/17352 (45%)] Loss: -184925.734375\n",
      "Train Epoch: 48 [7840/17352 (45%)] Loss: -175747.453125\n",
      "Train Epoch: 48 [7920/17352 (46%)] Loss: -196508.640625\n",
      "Train Epoch: 48 [8000/17352 (46%)] Loss: -165595.812500\n",
      "Train Epoch: 48 [8080/17352 (47%)] Loss: -165767.406250\n",
      "Train Epoch: 48 [8160/17352 (47%)] Loss: -196697.562500\n",
      "Train Epoch: 48 [8240/17352 (47%)] Loss: -192750.000000\n",
      "Train Epoch: 48 [8320/17352 (48%)] Loss: -158248.437500\n",
      "Train Epoch: 48 [8400/17352 (48%)] Loss: -173572.718750\n",
      "Train Epoch: 48 [8480/17352 (49%)] Loss: -176487.906250\n",
      "Train Epoch: 48 [8560/17352 (49%)] Loss: -178804.000000\n",
      "Train Epoch: 48 [8640/17352 (50%)] Loss: -191336.375000\n",
      "Train Epoch: 48 [8720/17352 (50%)] Loss: -148400.078125\n",
      "Train Epoch: 48 [8800/17352 (51%)] Loss: -181918.062500\n",
      "Train Epoch: 48 [8880/17352 (51%)] Loss: -177465.687500\n",
      "Train Epoch: 48 [8960/17352 (52%)] Loss: -184740.015625\n",
      "Train Epoch: 48 [9040/17352 (52%)] Loss: -193176.187500\n",
      "Train Epoch: 48 [9120/17352 (53%)] Loss: -185361.875000\n",
      "Train Epoch: 48 [9200/17352 (53%)] Loss: -180694.078125\n",
      "Train Epoch: 48 [9280/17352 (53%)] Loss: -171414.015625\n",
      "Train Epoch: 48 [9360/17352 (54%)] Loss: -157492.843750\n",
      "Train Epoch: 48 [9440/17352 (54%)] Loss: -181065.453125\n",
      "Train Epoch: 48 [9520/17352 (55%)] Loss: -152898.140625\n",
      "Train Epoch: 48 [9600/17352 (55%)] Loss: -203134.406250\n",
      "Train Epoch: 48 [9680/17352 (56%)] Loss: -144991.046875\n",
      "Train Epoch: 48 [9760/17352 (56%)] Loss: -173915.968750\n",
      "Train Epoch: 48 [9840/17352 (57%)] Loss: -160096.390625\n",
      "Train Epoch: 48 [9920/17352 (57%)] Loss: -163097.968750\n",
      "Train Epoch: 48 [10000/17352 (58%)] Loss: -190079.312500\n",
      "Train Epoch: 48 [10080/17352 (58%)] Loss: -193055.625000\n",
      "Train Epoch: 48 [10160/17352 (59%)] Loss: -177626.140625\n",
      "Train Epoch: 48 [10240/17352 (59%)] Loss: -187709.718750\n",
      "Train Epoch: 48 [10320/17352 (59%)] Loss: -163107.750000\n",
      "Train Epoch: 48 [10400/17352 (60%)] Loss: -195515.765625\n",
      "Train Epoch: 48 [10480/17352 (60%)] Loss: -188259.671875\n",
      "Train Epoch: 48 [10560/17352 (61%)] Loss: -175595.031250\n",
      "Train Epoch: 48 [10640/17352 (61%)] Loss: -182678.625000\n",
      "Train Epoch: 48 [10720/17352 (62%)] Loss: -180689.078125\n",
      "Train Epoch: 48 [10800/17352 (62%)] Loss: -218466.546875\n",
      "Train Epoch: 48 [10880/17352 (63%)] Loss: -215452.328125\n",
      "Train Epoch: 48 [10960/17352 (63%)] Loss: -199805.390625\n",
      "Train Epoch: 48 [11040/17352 (64%)] Loss: -217603.187500\n",
      "Train Epoch: 48 [11120/17352 (64%)] Loss: -181372.687500\n",
      "Train Epoch: 48 [11200/17352 (65%)] Loss: -205025.578125\n",
      "Train Epoch: 48 [11280/17352 (65%)] Loss: -174979.953125\n",
      "Train Epoch: 48 [11360/17352 (65%)] Loss: -203750.218750\n",
      "Train Epoch: 48 [11440/17352 (66%)] Loss: -183077.343750\n",
      "Train Epoch: 48 [11520/17352 (66%)] Loss: -176969.218750\n",
      "Train Epoch: 48 [11600/17352 (67%)] Loss: -228152.265625\n",
      "Train Epoch: 48 [11680/17352 (67%)] Loss: -148500.078125\n",
      "Train Epoch: 48 [11760/17352 (68%)] Loss: -187535.812500\n",
      "Train Epoch: 48 [11840/17352 (68%)] Loss: -173660.015625\n",
      "Train Epoch: 48 [11920/17352 (69%)] Loss: -201119.937500\n",
      "Train Epoch: 48 [12000/17352 (69%)] Loss: -174915.000000\n",
      "Train Epoch: 48 [12080/17352 (70%)] Loss: -149331.234375\n",
      "Train Epoch: 48 [12160/17352 (70%)] Loss: -180790.671875\n",
      "Train Epoch: 48 [12240/17352 (71%)] Loss: -202229.109375\n",
      "Train Epoch: 48 [12320/17352 (71%)] Loss: -175683.656250\n",
      "Train Epoch: 48 [12400/17352 (71%)] Loss: -199772.437500\n",
      "Train Epoch: 48 [12480/17352 (72%)] Loss: -187355.296875\n",
      "Train Epoch: 48 [12560/17352 (72%)] Loss: -166031.265625\n",
      "Train Epoch: 48 [12640/17352 (73%)] Loss: -182566.015625\n",
      "Train Epoch: 48 [12720/17352 (73%)] Loss: -202017.187500\n",
      "Train Epoch: 48 [12800/17352 (74%)] Loss: -177306.687500\n",
      "Train Epoch: 48 [12880/17352 (74%)] Loss: -191550.671875\n",
      "Train Epoch: 48 [12960/17352 (75%)] Loss: -146851.734375\n",
      "Train Epoch: 48 [13040/17352 (75%)] Loss: -193053.421875\n",
      "Train Epoch: 48 [13120/17352 (76%)] Loss: -165740.125000\n",
      "Train Epoch: 48 [13200/17352 (76%)] Loss: -176046.156250\n",
      "Train Epoch: 48 [13280/17352 (77%)] Loss: -185832.468750\n",
      "Train Epoch: 48 [13360/17352 (77%)] Loss: -188050.703125\n",
      "Train Epoch: 48 [13440/17352 (77%)] Loss: -168077.453125\n",
      "Train Epoch: 48 [13520/17352 (78%)] Loss: -192118.609375\n",
      "Train Epoch: 48 [13600/17352 (78%)] Loss: -182773.171875\n",
      "Train Epoch: 48 [13680/17352 (79%)] Loss: -192379.312500\n",
      "Train Epoch: 48 [13760/17352 (79%)] Loss: -159730.046875\n",
      "Train Epoch: 48 [13840/17352 (80%)] Loss: -164953.000000\n",
      "Train Epoch: 48 [13920/17352 (80%)] Loss: -228251.468750\n",
      "Train Epoch: 48 [14000/17352 (81%)] Loss: -208013.000000\n",
      "Train Epoch: 48 [14080/17352 (81%)] Loss: -170782.921875\n",
      "Train Epoch: 48 [14160/17352 (82%)] Loss: -215413.484375\n",
      "Train Epoch: 48 [14240/17352 (82%)] Loss: -213750.093750\n",
      "Train Epoch: 48 [14320/17352 (83%)] Loss: -202569.859375\n",
      "Train Epoch: 48 [14400/17352 (83%)] Loss: -183227.578125\n",
      "Train Epoch: 48 [14480/17352 (83%)] Loss: -185039.390625\n",
      "Train Epoch: 48 [14560/17352 (84%)] Loss: -182095.531250\n",
      "Train Epoch: 48 [14640/17352 (84%)] Loss: -212663.656250\n",
      "Train Epoch: 48 [14720/17352 (85%)] Loss: -201025.062500\n",
      "Train Epoch: 48 [14800/17352 (85%)] Loss: -188673.187500\n",
      "Train Epoch: 48 [14880/17352 (86%)] Loss: -200199.593750\n",
      "Train Epoch: 48 [14960/17352 (86%)] Loss: -189608.734375\n",
      "Train Epoch: 48 [15040/17352 (87%)] Loss: -201366.640625\n",
      "Train Epoch: 48 [15120/17352 (87%)] Loss: -192010.875000\n",
      "Train Epoch: 48 [15200/17352 (88%)] Loss: -196866.093750\n",
      "Train Epoch: 48 [15280/17352 (88%)] Loss: -185176.500000\n",
      "Train Epoch: 48 [15360/17352 (89%)] Loss: -205510.406250\n",
      "Train Epoch: 48 [15440/17352 (89%)] Loss: -179671.312500\n",
      "Train Epoch: 48 [15520/17352 (89%)] Loss: -175669.625000\n",
      "Train Epoch: 48 [15600/17352 (90%)] Loss: -205527.187500\n",
      "Train Epoch: 48 [15680/17352 (90%)] Loss: -208802.437500\n",
      "Train Epoch: 48 [15760/17352 (91%)] Loss: -181981.375000\n",
      "Train Epoch: 48 [15840/17352 (91%)] Loss: -195100.859375\n",
      "Train Epoch: 48 [15920/17352 (92%)] Loss: -171222.484375\n",
      "Train Epoch: 48 [16000/17352 (92%)] Loss: -191509.937500\n",
      "Train Epoch: 48 [16080/17352 (93%)] Loss: -183067.593750\n",
      "Train Epoch: 48 [16160/17352 (93%)] Loss: -170768.796875\n",
      "Train Epoch: 48 [16240/17352 (94%)] Loss: -186037.968750\n",
      "Train Epoch: 48 [16320/17352 (94%)] Loss: -205726.375000\n",
      "Train Epoch: 48 [16400/17352 (95%)] Loss: -202940.906250\n",
      "Train Epoch: 48 [16480/17352 (95%)] Loss: -197106.546875\n",
      "Train Epoch: 48 [16560/17352 (95%)] Loss: -175419.015625\n",
      "Train Epoch: 48 [16640/17352 (96%)] Loss: -176700.625000\n",
      "Train Epoch: 48 [16720/17352 (96%)] Loss: -177237.000000\n",
      "Train Epoch: 48 [16800/17352 (97%)] Loss: -186495.265625\n",
      "Train Epoch: 48 [16880/17352 (97%)] Loss: -192307.218750\n",
      "Train Epoch: 48 [16960/17352 (98%)] Loss: -183927.515625\n",
      "Train Epoch: 48 [17040/17352 (98%)] Loss: -227895.984375\n",
      "Train Epoch: 48 [17120/17352 (99%)] Loss: -192392.890625\n",
      "Train Epoch: 48 [17200/17352 (99%)] Loss: -156608.703125\n",
      "Train Epoch: 48 [17280/17352 (100%)] Loss: -187306.703125\n",
      "Train Epoch: 48 [17360/17352 (100%)] Loss: -183628.140625\n",
      "    epoch          : 48\n",
      "    loss           : -189238.155962313\n",
      "    val_loss       : -23715.85921782731\n",
      "Train Epoch: 49 [0/17352 (0%)] Loss: -215825.859375\n",
      "Train Epoch: 49 [80/17352 (0%)] Loss: -187712.093750\n",
      "Train Epoch: 49 [160/17352 (1%)] Loss: -233746.359375\n",
      "Train Epoch: 49 [240/17352 (1%)] Loss: -193415.406250\n",
      "Train Epoch: 49 [320/17352 (2%)] Loss: -199925.859375\n",
      "Train Epoch: 49 [400/17352 (2%)] Loss: -212178.265625\n",
      "Train Epoch: 49 [480/17352 (3%)] Loss: -212661.750000\n",
      "Train Epoch: 49 [560/17352 (3%)] Loss: -224348.765625\n",
      "Train Epoch: 49 [640/17352 (4%)] Loss: -213824.390625\n",
      "Train Epoch: 49 [720/17352 (4%)] Loss: -228906.656250\n",
      "Train Epoch: 49 [800/17352 (5%)] Loss: -185290.203125\n",
      "Train Epoch: 49 [880/17352 (5%)] Loss: -213329.718750\n",
      "Train Epoch: 49 [960/17352 (6%)] Loss: -199811.015625\n",
      "Train Epoch: 49 [1040/17352 (6%)] Loss: -199896.796875\n",
      "Train Epoch: 49 [1120/17352 (6%)] Loss: -204521.531250\n",
      "Train Epoch: 49 [1200/17352 (7%)] Loss: -206568.203125\n",
      "Train Epoch: 49 [1280/17352 (7%)] Loss: -213335.046875\n",
      "Train Epoch: 49 [1360/17352 (8%)] Loss: -193713.078125\n",
      "Train Epoch: 49 [1440/17352 (8%)] Loss: -222523.921875\n",
      "Train Epoch: 49 [1520/17352 (9%)] Loss: -209641.578125\n",
      "Train Epoch: 49 [1600/17352 (9%)] Loss: -214336.796875\n",
      "Train Epoch: 49 [1680/17352 (10%)] Loss: -203272.625000\n",
      "Train Epoch: 49 [1760/17352 (10%)] Loss: -199114.796875\n",
      "Train Epoch: 49 [1840/17352 (11%)] Loss: -194287.625000\n",
      "Train Epoch: 49 [1920/17352 (11%)] Loss: -205553.078125\n",
      "Train Epoch: 49 [2000/17352 (12%)] Loss: -205078.015625\n",
      "Train Epoch: 49 [2080/17352 (12%)] Loss: -200601.843750\n",
      "Train Epoch: 49 [2160/17352 (12%)] Loss: -236834.937500\n",
      "Train Epoch: 49 [2240/17352 (13%)] Loss: -175013.968750\n",
      "Train Epoch: 49 [2320/17352 (13%)] Loss: -165729.718750\n",
      "Train Epoch: 49 [2400/17352 (14%)] Loss: -206473.718750\n",
      "Train Epoch: 49 [2480/17352 (14%)] Loss: -177242.078125\n",
      "Train Epoch: 49 [2560/17352 (15%)] Loss: -180516.468750\n",
      "Train Epoch: 49 [2640/17352 (15%)] Loss: -178801.328125\n",
      "Train Epoch: 49 [2720/17352 (16%)] Loss: -210268.609375\n",
      "Train Epoch: 49 [2800/17352 (16%)] Loss: -179013.468750\n",
      "Train Epoch: 49 [2880/17352 (17%)] Loss: -199006.015625\n",
      "Train Epoch: 49 [2960/17352 (17%)] Loss: -185504.578125\n",
      "Train Epoch: 49 [3040/17352 (18%)] Loss: -160092.593750\n",
      "Train Epoch: 49 [3120/17352 (18%)] Loss: -193264.953125\n",
      "Train Epoch: 49 [3200/17352 (18%)] Loss: -170535.703125\n",
      "Train Epoch: 49 [3280/17352 (19%)] Loss: -201320.593750\n",
      "Train Epoch: 49 [3360/17352 (19%)] Loss: -171316.125000\n",
      "Train Epoch: 49 [3440/17352 (20%)] Loss: -203885.375000\n",
      "Train Epoch: 49 [3520/17352 (20%)] Loss: -222858.437500\n",
      "Train Epoch: 49 [3600/17352 (21%)] Loss: -178310.218750\n",
      "Train Epoch: 49 [3680/17352 (21%)] Loss: -169442.828125\n",
      "Train Epoch: 49 [3760/17352 (22%)] Loss: -177490.312500\n",
      "Train Epoch: 49 [3840/17352 (22%)] Loss: -196565.078125\n",
      "Train Epoch: 49 [3920/17352 (23%)] Loss: -169002.000000\n",
      "Train Epoch: 49 [4000/17352 (23%)] Loss: -197334.500000\n",
      "Train Epoch: 49 [4080/17352 (24%)] Loss: -180876.546875\n",
      "Train Epoch: 49 [4160/17352 (24%)] Loss: -173009.718750\n",
      "Train Epoch: 49 [4240/17352 (24%)] Loss: -203506.468750\n",
      "Train Epoch: 49 [4320/17352 (25%)] Loss: -177588.328125\n",
      "Train Epoch: 49 [4400/17352 (25%)] Loss: -167090.078125\n",
      "Train Epoch: 49 [4480/17352 (26%)] Loss: -185316.031250\n",
      "Train Epoch: 49 [4560/17352 (26%)] Loss: -183162.140625\n",
      "Train Epoch: 49 [4640/17352 (27%)] Loss: -142337.906250\n",
      "Train Epoch: 49 [4720/17352 (27%)] Loss: -203146.671875\n",
      "Train Epoch: 49 [4800/17352 (28%)] Loss: -184030.546875\n",
      "Train Epoch: 49 [4880/17352 (28%)] Loss: -192167.421875\n",
      "Train Epoch: 49 [4960/17352 (29%)] Loss: -189797.312500\n",
      "Train Epoch: 49 [5040/17352 (29%)] Loss: -191889.609375\n",
      "Train Epoch: 49 [5120/17352 (30%)] Loss: -186429.093750\n",
      "Train Epoch: 49 [5200/17352 (30%)] Loss: -179436.875000\n",
      "Train Epoch: 49 [5280/17352 (30%)] Loss: -171546.250000\n",
      "Train Epoch: 49 [5360/17352 (31%)] Loss: -185258.609375\n",
      "Train Epoch: 49 [5440/17352 (31%)] Loss: -173892.265625\n",
      "Train Epoch: 49 [5520/17352 (32%)] Loss: -142606.312500\n",
      "Train Epoch: 49 [5600/17352 (32%)] Loss: -177310.593750\n",
      "Train Epoch: 49 [5680/17352 (33%)] Loss: -176965.843750\n",
      "Train Epoch: 49 [5760/17352 (33%)] Loss: -148927.484375\n",
      "Train Epoch: 49 [5840/17352 (34%)] Loss: -177299.984375\n",
      "Train Epoch: 49 [5920/17352 (34%)] Loss: -223955.265625\n",
      "Train Epoch: 49 [6000/17352 (35%)] Loss: -201957.296875\n",
      "Train Epoch: 49 [6080/17352 (35%)] Loss: -186045.406250\n",
      "Train Epoch: 49 [6160/17352 (36%)] Loss: -185539.218750\n",
      "Train Epoch: 49 [6240/17352 (36%)] Loss: -165600.437500\n",
      "Train Epoch: 49 [6320/17352 (36%)] Loss: -178633.031250\n",
      "Train Epoch: 49 [6400/17352 (37%)] Loss: -169950.125000\n",
      "Train Epoch: 49 [6480/17352 (37%)] Loss: -208715.312500\n",
      "Train Epoch: 49 [6560/17352 (38%)] Loss: -167188.937500\n",
      "Train Epoch: 49 [6640/17352 (38%)] Loss: -196153.812500\n",
      "Train Epoch: 49 [6720/17352 (39%)] Loss: -198000.093750\n",
      "Train Epoch: 49 [6800/17352 (39%)] Loss: -200870.640625\n",
      "Train Epoch: 49 [6880/17352 (40%)] Loss: -177776.781250\n",
      "Train Epoch: 49 [6960/17352 (40%)] Loss: -182736.515625\n",
      "Train Epoch: 49 [7040/17352 (41%)] Loss: -213180.906250\n",
      "Train Epoch: 49 [7120/17352 (41%)] Loss: -181332.875000\n",
      "Train Epoch: 49 [7200/17352 (41%)] Loss: -180117.531250\n",
      "Train Epoch: 49 [7280/17352 (42%)] Loss: -191674.953125\n",
      "Train Epoch: 49 [7360/17352 (42%)] Loss: -202517.812500\n",
      "Train Epoch: 49 [7440/17352 (43%)] Loss: -169610.093750\n",
      "Train Epoch: 49 [7520/17352 (43%)] Loss: -176914.265625\n",
      "Train Epoch: 49 [7600/17352 (44%)] Loss: -218523.062500\n",
      "Train Epoch: 49 [7680/17352 (44%)] Loss: -174535.359375\n",
      "Train Epoch: 49 [7760/17352 (45%)] Loss: -206088.171875\n",
      "Train Epoch: 49 [7840/17352 (45%)] Loss: -151741.656250\n",
      "Train Epoch: 49 [7920/17352 (46%)] Loss: -180839.656250\n",
      "Train Epoch: 49 [8000/17352 (46%)] Loss: -182924.406250\n",
      "Train Epoch: 49 [8080/17352 (47%)] Loss: -176699.031250\n",
      "Train Epoch: 49 [8160/17352 (47%)] Loss: -182558.968750\n",
      "Train Epoch: 49 [8240/17352 (47%)] Loss: -166439.484375\n",
      "Train Epoch: 49 [8320/17352 (48%)] Loss: -172956.296875\n",
      "Train Epoch: 49 [8400/17352 (48%)] Loss: -206207.578125\n",
      "Train Epoch: 49 [8480/17352 (49%)] Loss: -206151.312500\n",
      "Train Epoch: 49 [8560/17352 (49%)] Loss: -196121.390625\n",
      "Train Epoch: 49 [8640/17352 (50%)] Loss: -181333.812500\n",
      "Train Epoch: 49 [8720/17352 (50%)] Loss: -181692.234375\n",
      "Train Epoch: 49 [8800/17352 (51%)] Loss: -203130.265625\n",
      "Train Epoch: 49 [8880/17352 (51%)] Loss: -201938.531250\n",
      "Train Epoch: 49 [8960/17352 (52%)] Loss: -183930.375000\n",
      "Train Epoch: 49 [9040/17352 (52%)] Loss: -176594.703125\n",
      "Train Epoch: 49 [9120/17352 (53%)] Loss: -166406.468750\n",
      "Train Epoch: 49 [9200/17352 (53%)] Loss: -179388.093750\n",
      "Train Epoch: 49 [9280/17352 (53%)] Loss: -193491.812500\n",
      "Train Epoch: 49 [9360/17352 (54%)] Loss: -167725.921875\n",
      "Train Epoch: 49 [9440/17352 (54%)] Loss: -188508.062500\n",
      "Train Epoch: 49 [9520/17352 (55%)] Loss: -174514.171875\n",
      "Train Epoch: 49 [9600/17352 (55%)] Loss: -202991.312500\n",
      "Train Epoch: 49 [9680/17352 (56%)] Loss: -203871.125000\n",
      "Train Epoch: 49 [9760/17352 (56%)] Loss: -187254.890625\n",
      "Train Epoch: 49 [9840/17352 (57%)] Loss: -196813.562500\n",
      "Train Epoch: 49 [9920/17352 (57%)] Loss: -149449.375000\n",
      "Train Epoch: 49 [10000/17352 (58%)] Loss: -191045.750000\n",
      "Train Epoch: 49 [10080/17352 (58%)] Loss: -203428.921875\n",
      "Train Epoch: 49 [10160/17352 (59%)] Loss: -162724.437500\n",
      "Train Epoch: 49 [10240/17352 (59%)] Loss: -176584.859375\n",
      "Train Epoch: 49 [10320/17352 (59%)] Loss: -195101.812500\n",
      "Train Epoch: 49 [10400/17352 (60%)] Loss: -192008.109375\n",
      "Train Epoch: 49 [10480/17352 (60%)] Loss: -164991.078125\n",
      "Train Epoch: 49 [10560/17352 (61%)] Loss: -195786.343750\n",
      "Train Epoch: 49 [10640/17352 (61%)] Loss: -221260.953125\n",
      "Train Epoch: 49 [10720/17352 (62%)] Loss: -208758.406250\n",
      "Train Epoch: 49 [10800/17352 (62%)] Loss: -171837.250000\n",
      "Train Epoch: 49 [10880/17352 (63%)] Loss: -196439.718750\n",
      "Train Epoch: 49 [10960/17352 (63%)] Loss: -204612.281250\n",
      "Train Epoch: 49 [11040/17352 (64%)] Loss: -174036.875000\n",
      "Train Epoch: 49 [11120/17352 (64%)] Loss: -172613.421875\n",
      "Train Epoch: 49 [11200/17352 (65%)] Loss: -195516.406250\n",
      "Train Epoch: 49 [11280/17352 (65%)] Loss: -192750.437500\n",
      "Train Epoch: 49 [11360/17352 (65%)] Loss: -177458.000000\n",
      "Train Epoch: 49 [11440/17352 (66%)] Loss: -217597.640625\n",
      "Train Epoch: 49 [11520/17352 (66%)] Loss: -195639.546875\n",
      "Train Epoch: 49 [11600/17352 (67%)] Loss: -208899.796875\n",
      "Train Epoch: 49 [11680/17352 (67%)] Loss: -186846.140625\n",
      "Train Epoch: 49 [11760/17352 (68%)] Loss: -152895.171875\n",
      "Train Epoch: 49 [11840/17352 (68%)] Loss: -202847.531250\n",
      "Train Epoch: 49 [11920/17352 (69%)] Loss: -178824.906250\n",
      "Train Epoch: 49 [12000/17352 (69%)] Loss: -186157.406250\n",
      "Train Epoch: 49 [12080/17352 (70%)] Loss: -180256.125000\n",
      "Train Epoch: 49 [12160/17352 (70%)] Loss: -187204.796875\n",
      "Train Epoch: 49 [12240/17352 (71%)] Loss: -183504.093750\n",
      "Train Epoch: 49 [12320/17352 (71%)] Loss: -167249.750000\n",
      "Train Epoch: 49 [12400/17352 (71%)] Loss: -152744.578125\n",
      "Train Epoch: 49 [12480/17352 (72%)] Loss: -163347.390625\n",
      "Train Epoch: 49 [12560/17352 (72%)] Loss: -195830.875000\n",
      "Train Epoch: 49 [12640/17352 (73%)] Loss: -183608.984375\n",
      "Train Epoch: 49 [12720/17352 (73%)] Loss: -170776.546875\n",
      "Train Epoch: 49 [12800/17352 (74%)] Loss: -209413.343750\n",
      "Train Epoch: 49 [12880/17352 (74%)] Loss: -172541.968750\n",
      "Train Epoch: 49 [12960/17352 (75%)] Loss: -196285.031250\n",
      "Train Epoch: 49 [13040/17352 (75%)] Loss: -185924.109375\n",
      "Train Epoch: 49 [13120/17352 (76%)] Loss: -192119.203125\n",
      "Train Epoch: 49 [13200/17352 (76%)] Loss: -170108.468750\n",
      "Train Epoch: 49 [13280/17352 (77%)] Loss: -215454.578125\n",
      "Train Epoch: 49 [13360/17352 (77%)] Loss: -198547.156250\n",
      "Train Epoch: 49 [13440/17352 (77%)] Loss: -225472.218750\n",
      "Train Epoch: 49 [13520/17352 (78%)] Loss: -163210.750000\n",
      "Train Epoch: 49 [13600/17352 (78%)] Loss: -175424.078125\n",
      "Train Epoch: 49 [13680/17352 (79%)] Loss: -228151.031250\n",
      "Train Epoch: 49 [13760/17352 (79%)] Loss: -155863.859375\n",
      "Train Epoch: 49 [13840/17352 (80%)] Loss: -197509.765625\n",
      "Train Epoch: 49 [13920/17352 (80%)] Loss: -200644.500000\n",
      "Train Epoch: 49 [14000/17352 (81%)] Loss: -218463.937500\n",
      "Train Epoch: 49 [14080/17352 (81%)] Loss: -175313.390625\n",
      "Train Epoch: 49 [14160/17352 (82%)] Loss: -204342.265625\n",
      "Train Epoch: 49 [14240/17352 (82%)] Loss: -193083.437500\n",
      "Train Epoch: 49 [14320/17352 (83%)] Loss: -147416.484375\n",
      "Train Epoch: 49 [14400/17352 (83%)] Loss: -212610.546875\n",
      "Train Epoch: 49 [14480/17352 (83%)] Loss: -172234.234375\n",
      "Train Epoch: 49 [14560/17352 (84%)] Loss: -186000.109375\n",
      "Train Epoch: 49 [14640/17352 (84%)] Loss: -185342.109375\n",
      "Train Epoch: 49 [14720/17352 (85%)] Loss: -203810.671875\n",
      "Train Epoch: 49 [14800/17352 (85%)] Loss: -201521.281250\n",
      "Train Epoch: 49 [14880/17352 (86%)] Loss: -209266.046875\n",
      "Train Epoch: 49 [14960/17352 (86%)] Loss: -179170.875000\n",
      "Train Epoch: 49 [15040/17352 (87%)] Loss: -183376.406250\n",
      "Train Epoch: 49 [15120/17352 (87%)] Loss: -179979.843750\n",
      "Train Epoch: 49 [15200/17352 (88%)] Loss: -190793.671875\n",
      "Train Epoch: 49 [15280/17352 (88%)] Loss: -166030.703125\n",
      "Train Epoch: 49 [15360/17352 (89%)] Loss: -200463.312500\n",
      "Train Epoch: 49 [15440/17352 (89%)] Loss: -184964.437500\n",
      "Train Epoch: 49 [15520/17352 (89%)] Loss: -210485.734375\n",
      "Train Epoch: 49 [15600/17352 (90%)] Loss: -178568.203125\n",
      "Train Epoch: 49 [15680/17352 (90%)] Loss: -177307.343750\n",
      "Train Epoch: 49 [15760/17352 (91%)] Loss: -167037.640625\n",
      "Train Epoch: 49 [15840/17352 (91%)] Loss: -171846.968750\n",
      "Train Epoch: 49 [15920/17352 (92%)] Loss: -198261.421875\n",
      "Train Epoch: 49 [16000/17352 (92%)] Loss: -210158.140625\n",
      "Train Epoch: 49 [16080/17352 (93%)] Loss: -184740.312500\n",
      "Train Epoch: 49 [16160/17352 (93%)] Loss: -228093.796875\n",
      "Train Epoch: 49 [16240/17352 (94%)] Loss: -200226.796875\n",
      "Train Epoch: 49 [16320/17352 (94%)] Loss: -203882.281250\n",
      "Train Epoch: 49 [16400/17352 (95%)] Loss: -182777.718750\n",
      "Train Epoch: 49 [16480/17352 (95%)] Loss: -177093.765625\n",
      "Train Epoch: 49 [16560/17352 (95%)] Loss: -187886.390625\n",
      "Train Epoch: 49 [16640/17352 (96%)] Loss: -186513.312500\n",
      "Train Epoch: 49 [16720/17352 (96%)] Loss: -193801.593750\n",
      "Train Epoch: 49 [16800/17352 (97%)] Loss: -199595.312500\n",
      "Train Epoch: 49 [16880/17352 (97%)] Loss: -189292.921875\n",
      "Train Epoch: 49 [16960/17352 (98%)] Loss: -143620.593750\n",
      "Train Epoch: 49 [17040/17352 (98%)] Loss: -196032.968750\n",
      "Train Epoch: 49 [17120/17352 (99%)] Loss: -166513.468750\n",
      "Train Epoch: 49 [17200/17352 (99%)] Loss: -206240.828125\n",
      "Train Epoch: 49 [17280/17352 (100%)] Loss: -193488.250000\n",
      "Train Epoch: 49 [17360/17352 (100%)] Loss: -177241.843750\n",
      "    epoch          : 49\n",
      "    loss           : -189329.01401575087\n",
      "    val_loss       : -23715.801765047887\n",
      "Train Epoch: 50 [0/17352 (0%)] Loss: -236631.640625\n",
      "Train Epoch: 50 [80/17352 (0%)] Loss: -204534.625000\n",
      "Train Epoch: 50 [160/17352 (1%)] Loss: -198768.718750\n",
      "Train Epoch: 50 [240/17352 (1%)] Loss: -185159.218750\n",
      "Train Epoch: 50 [320/17352 (2%)] Loss: -206138.453125\n",
      "Train Epoch: 50 [400/17352 (2%)] Loss: -228903.468750\n",
      "Train Epoch: 50 [480/17352 (3%)] Loss: -205109.875000\n",
      "Train Epoch: 50 [560/17352 (3%)] Loss: -224355.406250\n",
      "Train Epoch: 50 [640/17352 (4%)] Loss: -229236.078125\n",
      "Train Epoch: 50 [720/17352 (4%)] Loss: -215824.875000\n",
      "Train Epoch: 50 [800/17352 (5%)] Loss: -202232.000000\n",
      "Train Epoch: 50 [880/17352 (5%)] Loss: -210633.828125\n",
      "Train Epoch: 50 [960/17352 (6%)] Loss: -214514.328125\n",
      "Train Epoch: 50 [1040/17352 (6%)] Loss: -191874.609375\n",
      "Train Epoch: 50 [1120/17352 (6%)] Loss: -241904.406250\n",
      "Train Epoch: 50 [1200/17352 (7%)] Loss: -204022.671875\n",
      "Train Epoch: 50 [1280/17352 (7%)] Loss: -202322.125000\n",
      "Train Epoch: 50 [1360/17352 (8%)] Loss: -224251.687500\n",
      "Train Epoch: 50 [1440/17352 (8%)] Loss: -201660.375000\n",
      "Train Epoch: 50 [1520/17352 (9%)] Loss: -203744.062500\n",
      "Train Epoch: 50 [1600/17352 (9%)] Loss: -214701.890625\n",
      "Train Epoch: 50 [1680/17352 (10%)] Loss: -212703.218750\n",
      "Train Epoch: 50 [1760/17352 (10%)] Loss: -217935.765625\n",
      "Train Epoch: 50 [1840/17352 (11%)] Loss: -209642.140625\n",
      "Train Epoch: 50 [1920/17352 (11%)] Loss: -219656.906250\n",
      "Train Epoch: 50 [2000/17352 (12%)] Loss: -212260.078125\n",
      "Train Epoch: 50 [2080/17352 (12%)] Loss: -215484.656250\n",
      "Train Epoch: 50 [2160/17352 (12%)] Loss: -205210.515625\n",
      "Train Epoch: 50 [2240/17352 (13%)] Loss: -167871.046875\n",
      "Train Epoch: 50 [2320/17352 (13%)] Loss: -211725.890625\n",
      "Train Epoch: 50 [2400/17352 (14%)] Loss: -151213.234375\n",
      "Train Epoch: 50 [2480/17352 (14%)] Loss: -169188.656250\n",
      "Train Epoch: 50 [2560/17352 (15%)] Loss: -189011.125000\n",
      "Train Epoch: 50 [2640/17352 (15%)] Loss: -187883.500000\n",
      "Train Epoch: 50 [2720/17352 (16%)] Loss: -192120.187500\n",
      "Train Epoch: 50 [2800/17352 (16%)] Loss: -180150.062500\n",
      "Train Epoch: 50 [2880/17352 (17%)] Loss: -204596.750000\n",
      "Train Epoch: 50 [2960/17352 (17%)] Loss: -187202.484375\n",
      "Train Epoch: 50 [3040/17352 (18%)] Loss: -175366.125000\n",
      "Train Epoch: 50 [3120/17352 (18%)] Loss: -179421.546875\n",
      "Train Epoch: 50 [3200/17352 (18%)] Loss: -201308.703125\n",
      "Train Epoch: 50 [3280/17352 (19%)] Loss: -148824.453125\n",
      "Train Epoch: 50 [3360/17352 (19%)] Loss: -180521.203125\n",
      "Train Epoch: 50 [3440/17352 (20%)] Loss: -177277.500000\n",
      "Train Epoch: 50 [3520/17352 (20%)] Loss: -190808.828125\n",
      "Train Epoch: 50 [3600/17352 (21%)] Loss: -196447.265625\n",
      "Train Epoch: 50 [3680/17352 (21%)] Loss: -174987.296875\n",
      "Train Epoch: 50 [3760/17352 (22%)] Loss: -188445.921875\n",
      "Train Epoch: 50 [3840/17352 (22%)] Loss: -195294.562500\n",
      "Train Epoch: 50 [3920/17352 (23%)] Loss: -193364.796875\n",
      "Train Epoch: 50 [4000/17352 (23%)] Loss: -183794.687500\n",
      "Train Epoch: 50 [4080/17352 (24%)] Loss: -174632.359375\n",
      "Train Epoch: 50 [4160/17352 (24%)] Loss: -210153.734375\n",
      "Train Epoch: 50 [4240/17352 (24%)] Loss: -191561.656250\n",
      "Train Epoch: 50 [4320/17352 (25%)] Loss: -191963.093750\n",
      "Train Epoch: 50 [4400/17352 (25%)] Loss: -208901.828125\n",
      "Train Epoch: 50 [4480/17352 (26%)] Loss: -187647.078125\n",
      "Train Epoch: 50 [4560/17352 (26%)] Loss: -203670.562500\n",
      "Train Epoch: 50 [4640/17352 (27%)] Loss: -170354.843750\n",
      "Train Epoch: 50 [4720/17352 (27%)] Loss: -219920.046875\n",
      "Train Epoch: 50 [4800/17352 (28%)] Loss: -192692.062500\n",
      "Train Epoch: 50 [4880/17352 (28%)] Loss: -187235.046875\n",
      "Train Epoch: 50 [4960/17352 (29%)] Loss: -192370.671875\n",
      "Train Epoch: 50 [5040/17352 (29%)] Loss: -165393.125000\n",
      "Train Epoch: 50 [5120/17352 (30%)] Loss: -200970.625000\n",
      "Train Epoch: 50 [5200/17352 (30%)] Loss: -208801.000000\n",
      "Train Epoch: 50 [5280/17352 (30%)] Loss: -227888.203125\n",
      "Train Epoch: 50 [5360/17352 (31%)] Loss: -163763.000000\n",
      "Train Epoch: 50 [5440/17352 (31%)] Loss: -174914.015625\n",
      "Train Epoch: 50 [5520/17352 (32%)] Loss: -185312.921875\n",
      "Train Epoch: 50 [5600/17352 (32%)] Loss: -177141.109375\n",
      "Train Epoch: 50 [5680/17352 (33%)] Loss: -181738.250000\n",
      "Train Epoch: 50 [5760/17352 (33%)] Loss: -185510.921875\n",
      "Train Epoch: 50 [5840/17352 (34%)] Loss: -129695.656250\n",
      "Train Epoch: 50 [5920/17352 (34%)] Loss: -192952.281250\n",
      "Train Epoch: 50 [6000/17352 (35%)] Loss: -175206.515625\n",
      "Train Epoch: 50 [6080/17352 (35%)] Loss: -181260.984375\n",
      "Train Epoch: 50 [6160/17352 (36%)] Loss: -165679.359375\n",
      "Train Epoch: 50 [6240/17352 (36%)] Loss: -152897.906250\n",
      "Train Epoch: 50 [6320/17352 (36%)] Loss: -200404.218750\n",
      "Train Epoch: 50 [6400/17352 (37%)] Loss: -138336.156250\n",
      "Train Epoch: 50 [6480/17352 (37%)] Loss: -193169.109375\n",
      "Train Epoch: 50 [6560/17352 (38%)] Loss: -215414.046875\n",
      "Train Epoch: 50 [6640/17352 (38%)] Loss: -194944.312500\n",
      "Train Epoch: 50 [6720/17352 (39%)] Loss: -185338.984375\n",
      "Train Epoch: 50 [6800/17352 (39%)] Loss: -196200.265625\n",
      "Train Epoch: 50 [6880/17352 (40%)] Loss: -176703.125000\n",
      "Train Epoch: 50 [6960/17352 (40%)] Loss: -197946.890625\n",
      "Train Epoch: 50 [7040/17352 (41%)] Loss: -213237.875000\n",
      "Train Epoch: 50 [7120/17352 (41%)] Loss: -208724.406250\n",
      "Train Epoch: 50 [7200/17352 (41%)] Loss: -224864.453125\n",
      "Train Epoch: 50 [7280/17352 (42%)] Loss: -159689.578125\n",
      "Train Epoch: 50 [7360/17352 (42%)] Loss: -166665.031250\n",
      "Train Epoch: 50 [7440/17352 (43%)] Loss: -185366.093750\n",
      "Train Epoch: 50 [7520/17352 (43%)] Loss: -185264.515625\n",
      "Train Epoch: 50 [7600/17352 (44%)] Loss: -153326.296875\n",
      "Train Epoch: 50 [7680/17352 (44%)] Loss: -180160.718750\n",
      "Train Epoch: 50 [7760/17352 (45%)] Loss: -186853.359375\n",
      "Train Epoch: 50 [7840/17352 (45%)] Loss: -190227.843750\n",
      "Train Epoch: 50 [7920/17352 (46%)] Loss: -206093.718750\n",
      "Train Epoch: 50 [8000/17352 (46%)] Loss: -199886.625000\n",
      "Train Epoch: 50 [8080/17352 (47%)] Loss: -184258.531250\n",
      "Train Epoch: 50 [8160/17352 (47%)] Loss: -167184.750000\n",
      "Train Epoch: 50 [8240/17352 (47%)] Loss: -134538.015625\n",
      "Train Epoch: 50 [8320/17352 (48%)] Loss: -210916.062500\n",
      "Train Epoch: 50 [8400/17352 (48%)] Loss: -188862.953125\n",
      "Train Epoch: 50 [8480/17352 (49%)] Loss: -159612.234375\n",
      "Train Epoch: 50 [8560/17352 (49%)] Loss: -205168.656250\n",
      "Train Epoch: 50 [8640/17352 (50%)] Loss: -147418.562500\n",
      "Train Epoch: 50 [8720/17352 (50%)] Loss: -148927.828125\n",
      "Train Epoch: 50 [8800/17352 (51%)] Loss: -167302.734375\n",
      "Train Epoch: 50 [8880/17352 (51%)] Loss: -196861.218750\n",
      "Train Epoch: 50 [8960/17352 (52%)] Loss: -188961.781250\n",
      "Train Epoch: 50 [9040/17352 (52%)] Loss: -187133.359375\n",
      "Train Epoch: 50 [9120/17352 (53%)] Loss: -173665.140625\n",
      "Train Epoch: 50 [9200/17352 (53%)] Loss: -176056.750000\n",
      "Train Epoch: 50 [9280/17352 (53%)] Loss: -184948.687500\n",
      "Train Epoch: 50 [9360/17352 (54%)] Loss: -177619.843750\n",
      "Train Epoch: 50 [9440/17352 (54%)] Loss: -192642.125000\n",
      "Train Epoch: 50 [9520/17352 (55%)] Loss: -179013.906250\n",
      "Train Epoch: 50 [9600/17352 (55%)] Loss: -170241.906250\n",
      "Train Epoch: 50 [9680/17352 (56%)] Loss: -199441.906250\n",
      "Train Epoch: 50 [9760/17352 (56%)] Loss: -178204.437500\n",
      "Train Epoch: 50 [9840/17352 (57%)] Loss: -181539.812500\n",
      "Train Epoch: 50 [9920/17352 (57%)] Loss: -200333.890625\n",
      "Train Epoch: 50 [10000/17352 (58%)] Loss: -140585.437500\n",
      "Train Epoch: 50 [10080/17352 (58%)] Loss: -192011.906250\n",
      "Train Epoch: 50 [10160/17352 (59%)] Loss: -203144.718750\n",
      "Train Epoch: 50 [10240/17352 (59%)] Loss: -169610.812500\n",
      "Train Epoch: 50 [10320/17352 (59%)] Loss: -183602.156250\n",
      "Train Epoch: 50 [10400/17352 (60%)] Loss: -165757.703125\n",
      "Train Epoch: 50 [10480/17352 (60%)] Loss: -165728.671875\n",
      "Train Epoch: 50 [10560/17352 (61%)] Loss: -167257.046875\n",
      "Train Epoch: 50 [10640/17352 (61%)] Loss: -165731.250000\n",
      "Train Epoch: 50 [10720/17352 (62%)] Loss: -208726.609375\n",
      "Train Epoch: 50 [10800/17352 (62%)] Loss: -173654.593750\n",
      "Train Epoch: 50 [10880/17352 (63%)] Loss: -187306.109375\n",
      "Train Epoch: 50 [10960/17352 (63%)] Loss: -177305.171875\n",
      "Train Epoch: 50 [11040/17352 (64%)] Loss: -192959.906250\n",
      "Train Epoch: 50 [11120/17352 (64%)] Loss: -166447.765625\n",
      "Train Epoch: 50 [11200/17352 (65%)] Loss: -185172.406250\n",
      "Train Epoch: 50 [11280/17352 (65%)] Loss: -212652.000000\n",
      "Train Epoch: 50 [11360/17352 (65%)] Loss: -203814.140625\n",
      "Train Epoch: 50 [11440/17352 (66%)] Loss: -170780.046875\n",
      "Train Epoch: 50 [11520/17352 (66%)] Loss: -186722.500000\n",
      "Train Epoch: 50 [11600/17352 (67%)] Loss: -203885.046875\n",
      "Train Epoch: 50 [11680/17352 (67%)] Loss: -175402.375000\n",
      "Train Epoch: 50 [11760/17352 (68%)] Loss: -183590.250000\n",
      "Train Epoch: 50 [11840/17352 (68%)] Loss: -193952.796875\n",
      "Train Epoch: 50 [11920/17352 (69%)] Loss: -167481.531250\n",
      "Train Epoch: 50 [12000/17352 (69%)] Loss: -217604.156250\n",
      "Train Epoch: 50 [12080/17352 (70%)] Loss: -195711.687500\n",
      "Train Epoch: 50 [12160/17352 (70%)] Loss: -170234.375000\n",
      "Train Epoch: 50 [12240/17352 (71%)] Loss: -190946.859375\n",
      "Train Epoch: 50 [12320/17352 (71%)] Loss: -188149.375000\n",
      "Train Epoch: 50 [12400/17352 (71%)] Loss: -174949.296875\n",
      "Train Epoch: 50 [12480/17352 (72%)] Loss: -166029.406250\n",
      "Train Epoch: 50 [12560/17352 (72%)] Loss: -197994.640625\n",
      "Train Epoch: 50 [12640/17352 (73%)] Loss: -179012.421875\n",
      "Train Epoch: 50 [12720/17352 (73%)] Loss: -183259.640625\n",
      "Train Epoch: 50 [12800/17352 (74%)] Loss: -192221.312500\n",
      "Train Epoch: 50 [12880/17352 (74%)] Loss: -188246.687500\n",
      "Train Epoch: 50 [12960/17352 (75%)] Loss: -186797.437500\n",
      "Train Epoch: 50 [13040/17352 (75%)] Loss: -174877.687500\n",
      "Train Epoch: 50 [13120/17352 (76%)] Loss: -201514.000000\n",
      "Train Epoch: 50 [13200/17352 (76%)] Loss: -177612.312500\n",
      "Train Epoch: 50 [13280/17352 (77%)] Loss: -206550.609375\n",
      "Train Epoch: 50 [13360/17352 (77%)] Loss: -183068.156250\n",
      "Train Epoch: 50 [13440/17352 (77%)] Loss: -200997.531250\n",
      "Train Epoch: 50 [13520/17352 (78%)] Loss: -159307.687500\n",
      "Train Epoch: 50 [13600/17352 (78%)] Loss: -209893.218750\n",
      "Train Epoch: 50 [13680/17352 (79%)] Loss: -164826.109375\n",
      "Train Epoch: 50 [13760/17352 (79%)] Loss: -195055.359375\n",
      "Train Epoch: 50 [13840/17352 (80%)] Loss: -202790.671875\n",
      "Train Epoch: 50 [13920/17352 (80%)] Loss: -215463.453125\n",
      "Train Epoch: 50 [14000/17352 (81%)] Loss: -164370.406250\n",
      "Train Epoch: 50 [14080/17352 (81%)] Loss: -198547.562500\n",
      "Train Epoch: 50 [14160/17352 (82%)] Loss: -181335.312500\n",
      "Train Epoch: 50 [14240/17352 (82%)] Loss: -191004.750000\n",
      "Train Epoch: 50 [14320/17352 (83%)] Loss: -183870.500000\n",
      "Train Epoch: 50 [14400/17352 (83%)] Loss: -181914.375000\n",
      "Train Epoch: 50 [14480/17352 (83%)] Loss: -196202.906250\n",
      "Train Epoch: 50 [14560/17352 (84%)] Loss: -183058.390625\n",
      "Train Epoch: 50 [14640/17352 (84%)] Loss: -186155.828125\n",
      "Train Epoch: 50 [14720/17352 (85%)] Loss: -194931.906250\n",
      "Train Epoch: 50 [14800/17352 (85%)] Loss: -170099.859375\n",
      "Train Epoch: 50 [14880/17352 (86%)] Loss: -148396.609375\n",
      "Train Epoch: 50 [14960/17352 (86%)] Loss: -184180.234375\n",
      "Train Epoch: 50 [15040/17352 (87%)] Loss: -194579.687500\n",
      "Train Epoch: 50 [15120/17352 (87%)] Loss: -143617.515625\n",
      "Train Epoch: 50 [15200/17352 (88%)] Loss: -201260.437500\n",
      "Train Epoch: 50 [15280/17352 (88%)] Loss: -173943.125000\n",
      "Train Epoch: 50 [15360/17352 (89%)] Loss: -160097.250000\n",
      "Train Epoch: 50 [15440/17352 (89%)] Loss: -173889.640625\n",
      "Train Epoch: 50 [15520/17352 (89%)] Loss: -205401.234375\n",
      "Train Epoch: 50 [15600/17352 (90%)] Loss: -198807.000000\n",
      "Train Epoch: 50 [15680/17352 (90%)] Loss: -178664.546875\n",
      "Train Epoch: 50 [15760/17352 (91%)] Loss: -177251.187500\n",
      "Train Epoch: 50 [15840/17352 (91%)] Loss: -199775.171875\n",
      "Train Epoch: 50 [15920/17352 (92%)] Loss: -194605.281250\n",
      "Train Epoch: 50 [16000/17352 (92%)] Loss: -189507.093750\n",
      "Train Epoch: 50 [16080/17352 (93%)] Loss: -185365.218750\n",
      "Train Epoch: 50 [16160/17352 (93%)] Loss: -201320.500000\n",
      "Train Epoch: 50 [16240/17352 (94%)] Loss: -211085.468750\n",
      "Train Epoch: 50 [16320/17352 (94%)] Loss: -186608.859375\n",
      "Train Epoch: 50 [16400/17352 (95%)] Loss: -199796.265625\n",
      "Train Epoch: 50 [16480/17352 (95%)] Loss: -193356.937500\n",
      "Train Epoch: 50 [16560/17352 (95%)] Loss: -197596.265625\n",
      "Train Epoch: 50 [16640/17352 (96%)] Loss: -178599.890625\n",
      "Train Epoch: 50 [16720/17352 (96%)] Loss: -176084.531250\n",
      "Train Epoch: 50 [16800/17352 (97%)] Loss: -203890.921875\n",
      "Train Epoch: 50 [16880/17352 (97%)] Loss: -185542.406250\n",
      "Train Epoch: 50 [16960/17352 (98%)] Loss: -178425.593750\n",
      "Train Epoch: 50 [17040/17352 (98%)] Loss: -165996.718750\n",
      "Train Epoch: 50 [17120/17352 (99%)] Loss: -192388.796875\n",
      "Train Epoch: 50 [17200/17352 (99%)] Loss: -180109.906250\n",
      "Train Epoch: 50 [17280/17352 (100%)] Loss: -162970.796875\n",
      "Train Epoch: 50 [17360/17352 (100%)] Loss: -202313.843750\n",
      "    epoch          : 50\n",
      "    loss           : -189146.05273662254\n",
      "    val_loss       : -23715.805971387406\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch50.pth ...\n",
      "Train Epoch: 51 [0/17352 (0%)] Loss: -223007.000000\n",
      "Train Epoch: 51 [80/17352 (0%)] Loss: -202264.281250\n",
      "Train Epoch: 51 [160/17352 (1%)] Loss: -214522.375000\n",
      "Train Epoch: 51 [240/17352 (1%)] Loss: -221766.234375\n",
      "Train Epoch: 51 [320/17352 (2%)] Loss: -204535.000000\n",
      "Train Epoch: 51 [400/17352 (2%)] Loss: -214514.109375\n",
      "Train Epoch: 51 [480/17352 (3%)] Loss: -193571.718750\n",
      "Train Epoch: 51 [560/17352 (3%)] Loss: -196924.109375\n",
      "Train Epoch: 51 [640/17352 (4%)] Loss: -214703.718750\n",
      "Train Epoch: 51 [720/17352 (4%)] Loss: -215484.796875\n",
      "Train Epoch: 51 [800/17352 (5%)] Loss: -217580.718750\n",
      "Train Epoch: 51 [880/17352 (5%)] Loss: -205207.500000\n",
      "Train Epoch: 51 [960/17352 (6%)] Loss: -193410.000000\n",
      "Train Epoch: 51 [1040/17352 (6%)] Loss: -210746.781250\n",
      "Train Epoch: 51 [1120/17352 (6%)] Loss: -202023.453125\n",
      "Train Epoch: 51 [1200/17352 (7%)] Loss: -224351.890625\n",
      "Train Epoch: 51 [1280/17352 (7%)] Loss: -182782.078125\n",
      "Train Epoch: 51 [1360/17352 (8%)] Loss: -212693.234375\n",
      "Train Epoch: 51 [1440/17352 (8%)] Loss: -193023.015625\n",
      "Train Epoch: 51 [1520/17352 (9%)] Loss: -229963.265625\n",
      "Train Epoch: 51 [1600/17352 (9%)] Loss: -228010.000000\n",
      "Train Epoch: 51 [1680/17352 (10%)] Loss: -229230.500000\n",
      "Train Epoch: 51 [1760/17352 (10%)] Loss: -187721.656250\n",
      "Train Epoch: 51 [1840/17352 (11%)] Loss: -209780.578125\n",
      "Train Epoch: 51 [1920/17352 (11%)] Loss: -204354.375000\n",
      "Train Epoch: 51 [2000/17352 (12%)] Loss: -206139.765625\n",
      "Train Epoch: 51 [2080/17352 (12%)] Loss: -205191.765625\n",
      "Train Epoch: 51 [2160/17352 (12%)] Loss: -233727.718750\n",
      "Train Epoch: 51 [2240/17352 (13%)] Loss: -192792.093750\n",
      "Train Epoch: 51 [2320/17352 (13%)] Loss: -189599.968750\n",
      "Train Epoch: 51 [2400/17352 (14%)] Loss: -210629.890625\n",
      "Train Epoch: 51 [2480/17352 (14%)] Loss: -174481.718750\n",
      "Train Epoch: 51 [2560/17352 (15%)] Loss: -197334.343750\n",
      "Train Epoch: 51 [2640/17352 (15%)] Loss: -168998.578125\n",
      "Train Epoch: 51 [2720/17352 (16%)] Loss: -183806.859375\n",
      "Train Epoch: 51 [2800/17352 (16%)] Loss: -160102.093750\n",
      "Train Epoch: 51 [2880/17352 (17%)] Loss: -181427.281250\n",
      "Train Epoch: 51 [2960/17352 (17%)] Loss: -176881.718750\n",
      "Train Epoch: 51 [3040/17352 (18%)] Loss: -172889.140625\n",
      "Train Epoch: 51 [3120/17352 (18%)] Loss: -208024.390625\n",
      "Train Epoch: 51 [3200/17352 (18%)] Loss: -177306.296875\n",
      "Train Epoch: 51 [3280/17352 (19%)] Loss: -179389.015625\n",
      "Train Epoch: 51 [3360/17352 (19%)] Loss: -164882.750000\n",
      "Train Epoch: 51 [3440/17352 (20%)] Loss: -200207.703125\n",
      "Train Epoch: 51 [3520/17352 (20%)] Loss: -167041.031250\n",
      "Train Epoch: 51 [3600/17352 (21%)] Loss: -175013.375000\n",
      "Train Epoch: 51 [3680/17352 (21%)] Loss: -169190.640625\n",
      "Train Epoch: 51 [3760/17352 (22%)] Loss: -211164.062500\n",
      "Train Epoch: 51 [3840/17352 (22%)] Loss: -200171.640625\n",
      "Train Epoch: 51 [3920/17352 (23%)] Loss: -167487.156250\n",
      "Train Epoch: 51 [4000/17352 (23%)] Loss: -199784.750000\n",
      "Train Epoch: 51 [4080/17352 (24%)] Loss: -186051.656250\n",
      "Train Epoch: 51 [4160/17352 (24%)] Loss: -210392.609375\n",
      "Train Epoch: 51 [4240/17352 (24%)] Loss: -187538.031250\n",
      "Train Epoch: 51 [4320/17352 (25%)] Loss: -183168.921875\n",
      "Train Epoch: 51 [4400/17352 (25%)] Loss: -194587.515625\n",
      "Train Epoch: 51 [4480/17352 (26%)] Loss: -178312.109375\n",
      "Train Epoch: 51 [4560/17352 (26%)] Loss: -169166.968750\n",
      "Train Epoch: 51 [4640/17352 (27%)] Loss: -178870.406250\n",
      "Train Epoch: 51 [4720/17352 (27%)] Loss: -180249.625000\n",
      "Train Epoch: 51 [4800/17352 (28%)] Loss: -185365.375000\n",
      "Train Epoch: 51 [4880/17352 (28%)] Loss: -196449.875000\n",
      "Train Epoch: 51 [4960/17352 (29%)] Loss: -181733.406250\n",
      "Train Epoch: 51 [5040/17352 (29%)] Loss: -156995.796875\n",
      "Train Epoch: 51 [5120/17352 (30%)] Loss: -203882.484375\n",
      "Train Epoch: 51 [5200/17352 (30%)] Loss: -185008.453125\n",
      "Train Epoch: 51 [5280/17352 (30%)] Loss: -179500.359375\n",
      "Train Epoch: 51 [5360/17352 (31%)] Loss: -185988.187500\n",
      "Train Epoch: 51 [5440/17352 (31%)] Loss: -173305.750000\n",
      "Train Epoch: 51 [5520/17352 (32%)] Loss: -195511.390625\n",
      "Train Epoch: 51 [5600/17352 (32%)] Loss: -192680.968750\n",
      "Train Epoch: 51 [5680/17352 (33%)] Loss: -189536.734375\n",
      "Train Epoch: 51 [5760/17352 (33%)] Loss: -181917.906250\n",
      "Train Epoch: 51 [5840/17352 (34%)] Loss: -188430.875000\n",
      "Train Epoch: 51 [5920/17352 (34%)] Loss: -190915.359375\n",
      "Train Epoch: 51 [6000/17352 (35%)] Loss: -187707.921875\n",
      "Train Epoch: 51 [6080/17352 (35%)] Loss: -151515.562500\n",
      "Train Epoch: 51 [6160/17352 (36%)] Loss: -188268.890625\n",
      "Train Epoch: 51 [6240/17352 (36%)] Loss: -182683.546875\n",
      "Train Epoch: 51 [6320/17352 (36%)] Loss: -207863.781250\n",
      "Train Epoch: 51 [6400/17352 (37%)] Loss: -168512.625000\n",
      "Train Epoch: 51 [6480/17352 (37%)] Loss: -177573.093750\n",
      "Train Epoch: 51 [6560/17352 (38%)] Loss: -208043.734375\n",
      "Train Epoch: 51 [6640/17352 (38%)] Loss: -191593.718750\n",
      "Train Epoch: 51 [6720/17352 (39%)] Loss: -176705.171875\n",
      "Train Epoch: 51 [6800/17352 (39%)] Loss: -191883.562500\n",
      "Train Epoch: 51 [6880/17352 (40%)] Loss: -168249.218750\n",
      "Train Epoch: 51 [6960/17352 (40%)] Loss: -157491.593750\n",
      "Train Epoch: 51 [7040/17352 (41%)] Loss: -194074.765625\n",
      "Train Epoch: 51 [7120/17352 (41%)] Loss: -163206.984375\n",
      "Train Epoch: 51 [7200/17352 (41%)] Loss: -212977.453125\n",
      "Train Epoch: 51 [7280/17352 (42%)] Loss: -192007.656250\n",
      "Train Epoch: 51 [7360/17352 (42%)] Loss: -165362.156250\n",
      "Train Epoch: 51 [7440/17352 (43%)] Loss: -191561.031250\n",
      "Train Epoch: 51 [7520/17352 (43%)] Loss: -201378.421875\n",
      "Train Epoch: 51 [7600/17352 (44%)] Loss: -183070.203125\n",
      "Train Epoch: 51 [7680/17352 (44%)] Loss: -199789.765625\n",
      "Train Epoch: 51 [7760/17352 (45%)] Loss: -170313.453125\n",
      "Train Epoch: 51 [7840/17352 (45%)] Loss: -222862.296875\n",
      "Train Epoch: 51 [7920/17352 (46%)] Loss: -186158.625000\n",
      "Train Epoch: 51 [8000/17352 (46%)] Loss: -148153.718750\n",
      "Train Epoch: 51 [8080/17352 (47%)] Loss: -202086.265625\n",
      "Train Epoch: 51 [8160/17352 (47%)] Loss: -200118.031250\n",
      "Train Epoch: 51 [8240/17352 (47%)] Loss: -177735.515625\n",
      "Train Epoch: 51 [8320/17352 (48%)] Loss: -183727.515625\n",
      "Train Epoch: 51 [8400/17352 (48%)] Loss: -140588.593750\n",
      "Train Epoch: 51 [8480/17352 (49%)] Loss: -171419.578125\n",
      "Train Epoch: 51 [8560/17352 (49%)] Loss: -172609.625000\n",
      "Train Epoch: 51 [8640/17352 (50%)] Loss: -183224.953125\n",
      "Train Epoch: 51 [8720/17352 (50%)] Loss: -215970.546875\n",
      "Train Epoch: 51 [8800/17352 (51%)] Loss: -195648.406250\n",
      "Train Epoch: 51 [8880/17352 (51%)] Loss: -200633.375000\n",
      "Train Epoch: 51 [8960/17352 (52%)] Loss: -186499.375000\n",
      "Train Epoch: 51 [9040/17352 (52%)] Loss: -196811.812500\n",
      "Train Epoch: 51 [9120/17352 (53%)] Loss: -204656.125000\n",
      "Train Epoch: 51 [9200/17352 (53%)] Loss: -153323.453125\n",
      "Train Epoch: 51 [9280/17352 (53%)] Loss: -198696.500000\n",
      "Train Epoch: 51 [9360/17352 (54%)] Loss: -187720.000000\n",
      "Train Epoch: 51 [9440/17352 (54%)] Loss: -193355.734375\n",
      "Train Epoch: 51 [9520/17352 (55%)] Loss: -170096.093750\n",
      "Train Epoch: 51 [9600/17352 (55%)] Loss: -192951.937500\n",
      "Train Epoch: 51 [9680/17352 (56%)] Loss: -194995.046875\n",
      "Train Epoch: 51 [9760/17352 (56%)] Loss: -189405.984375\n",
      "Train Epoch: 51 [9840/17352 (57%)] Loss: -159313.828125\n",
      "Train Epoch: 51 [9920/17352 (57%)] Loss: -189213.156250\n",
      "Train Epoch: 51 [10000/17352 (58%)] Loss: -191804.609375\n",
      "Train Epoch: 51 [10080/17352 (58%)] Loss: -170355.109375\n",
      "Train Epoch: 51 [10160/17352 (59%)] Loss: -177979.109375\n",
      "Train Epoch: 51 [10240/17352 (59%)] Loss: -210264.421875\n",
      "Train Epoch: 51 [10320/17352 (59%)] Loss: -184067.453125\n",
      "Train Epoch: 51 [10400/17352 (60%)] Loss: -184252.578125\n",
      "Train Epoch: 51 [10480/17352 (60%)] Loss: -208807.750000\n",
      "Train Epoch: 51 [10560/17352 (61%)] Loss: -209268.984375\n",
      "Train Epoch: 51 [10640/17352 (61%)] Loss: -166519.656250\n",
      "Train Epoch: 51 [10720/17352 (62%)] Loss: -200398.718750\n",
      "Train Epoch: 51 [10800/17352 (62%)] Loss: -206688.078125\n",
      "Train Epoch: 51 [10880/17352 (63%)] Loss: -194936.093750\n",
      "Train Epoch: 51 [10960/17352 (63%)] Loss: -174946.046875\n",
      "Train Epoch: 51 [11040/17352 (64%)] Loss: -193958.656250\n",
      "Train Epoch: 51 [11120/17352 (64%)] Loss: -200196.187500\n",
      "Train Epoch: 51 [11200/17352 (65%)] Loss: -213178.578125\n",
      "Train Epoch: 51 [11280/17352 (65%)] Loss: -200840.562500\n",
      "Train Epoch: 51 [11360/17352 (65%)] Loss: -173122.796875\n",
      "Train Epoch: 51 [11440/17352 (66%)] Loss: -191831.218750\n",
      "Train Epoch: 51 [11520/17352 (66%)] Loss: -171836.234375\n",
      "Train Epoch: 51 [11600/17352 (67%)] Loss: -207782.234375\n",
      "Train Epoch: 51 [11680/17352 (67%)] Loss: -181726.031250\n",
      "Train Epoch: 51 [11760/17352 (68%)] Loss: -179450.250000\n",
      "Train Epoch: 51 [11840/17352 (68%)] Loss: -175507.500000\n",
      "Train Epoch: 51 [11920/17352 (69%)] Loss: -191954.031250\n",
      "Train Epoch: 51 [12000/17352 (69%)] Loss: -204613.109375\n",
      "Train Epoch: 51 [12080/17352 (70%)] Loss: -162567.359375\n",
      "Train Epoch: 51 [12160/17352 (70%)] Loss: -189510.843750\n",
      "Train Epoch: 51 [12240/17352 (71%)] Loss: -175401.796875\n",
      "Train Epoch: 51 [12320/17352 (71%)] Loss: -201934.890625\n",
      "Train Epoch: 51 [12400/17352 (71%)] Loss: -181979.937500\n",
      "Train Epoch: 51 [12480/17352 (72%)] Loss: -194068.109375\n",
      "Train Epoch: 51 [12560/17352 (72%)] Loss: -193134.234375\n",
      "Train Epoch: 51 [12640/17352 (73%)] Loss: -184479.843750\n",
      "Train Epoch: 51 [12720/17352 (73%)] Loss: -200867.359375\n",
      "Train Epoch: 51 [12800/17352 (74%)] Loss: -174140.531250\n",
      "Train Epoch: 51 [12880/17352 (74%)] Loss: -194228.093750\n",
      "Train Epoch: 51 [12960/17352 (75%)] Loss: -187123.750000\n",
      "Train Epoch: 51 [13040/17352 (75%)] Loss: -170681.671875\n",
      "Train Epoch: 51 [13120/17352 (76%)] Loss: -210159.406250\n",
      "Train Epoch: 51 [13200/17352 (76%)] Loss: -181759.265625\n",
      "Train Epoch: 51 [13280/17352 (77%)] Loss: -190077.484375\n",
      "Train Epoch: 51 [13360/17352 (77%)] Loss: -177619.718750\n",
      "Train Epoch: 51 [13440/17352 (77%)] Loss: -159691.000000\n",
      "Train Epoch: 51 [13520/17352 (78%)] Loss: -185230.015625\n",
      "Train Epoch: 51 [13600/17352 (78%)] Loss: -220008.359375\n",
      "Train Epoch: 51 [13680/17352 (79%)] Loss: -174453.906250\n",
      "Train Epoch: 51 [13760/17352 (79%)] Loss: -185785.062500\n",
      "Train Epoch: 51 [13840/17352 (80%)] Loss: -180146.843750\n",
      "Train Epoch: 51 [13920/17352 (80%)] Loss: -191362.953125\n",
      "Train Epoch: 51 [14000/17352 (81%)] Loss: -185374.375000\n",
      "Train Epoch: 51 [14080/17352 (81%)] Loss: -175070.593750\n",
      "Train Epoch: 51 [14160/17352 (82%)] Loss: -182559.406250\n",
      "Train Epoch: 51 [14240/17352 (82%)] Loss: -204339.234375\n",
      "Train Epoch: 51 [14320/17352 (83%)] Loss: -213912.828125\n",
      "Train Epoch: 51 [14400/17352 (83%)] Loss: -185591.421875\n",
      "Train Epoch: 51 [14480/17352 (83%)] Loss: -205679.500000\n",
      "Train Epoch: 51 [14560/17352 (84%)] Loss: -202845.906250\n",
      "Train Epoch: 51 [14640/17352 (84%)] Loss: -208036.625000\n",
      "Train Epoch: 51 [14720/17352 (85%)] Loss: -174507.875000\n",
      "Train Epoch: 51 [14800/17352 (85%)] Loss: -187410.937500\n",
      "Train Epoch: 51 [14880/17352 (86%)] Loss: -197565.625000\n",
      "Train Epoch: 51 [14960/17352 (86%)] Loss: -174982.328125\n",
      "Train Epoch: 51 [15040/17352 (87%)] Loss: -165726.140625\n",
      "Train Epoch: 51 [15120/17352 (87%)] Loss: -181538.843750\n",
      "Train Epoch: 51 [15200/17352 (88%)] Loss: -196023.875000\n",
      "Train Epoch: 51 [15280/17352 (88%)] Loss: -131047.679688\n",
      "Train Epoch: 51 [15360/17352 (89%)] Loss: -171895.546875\n",
      "Train Epoch: 51 [15440/17352 (89%)] Loss: -191719.343750\n",
      "Train Epoch: 51 [15520/17352 (89%)] Loss: -166028.515625\n",
      "Train Epoch: 51 [15600/17352 (90%)] Loss: -183364.953125\n",
      "Train Epoch: 51 [15680/17352 (90%)] Loss: -218409.593750\n",
      "Train Epoch: 51 [15760/17352 (91%)] Loss: -180046.125000\n",
      "Train Epoch: 51 [15840/17352 (91%)] Loss: -177236.390625\n",
      "Train Epoch: 51 [15920/17352 (92%)] Loss: -205514.937500\n",
      "Train Epoch: 51 [16000/17352 (92%)] Loss: -172196.250000\n",
      "Train Epoch: 51 [16080/17352 (93%)] Loss: -183257.421875\n",
      "Train Epoch: 51 [16160/17352 (93%)] Loss: -183062.218750\n",
      "Train Epoch: 51 [16240/17352 (94%)] Loss: -203740.718750\n",
      "Train Epoch: 51 [16320/17352 (94%)] Loss: -169952.093750\n",
      "Train Epoch: 51 [16400/17352 (95%)] Loss: -190377.156250\n",
      "Train Epoch: 51 [16480/17352 (95%)] Loss: -214750.281250\n",
      "Train Epoch: 51 [16560/17352 (95%)] Loss: -209192.015625\n",
      "Train Epoch: 51 [16640/17352 (96%)] Loss: -206092.406250\n",
      "Train Epoch: 51 [16720/17352 (96%)] Loss: -171192.421875\n",
      "Train Epoch: 51 [16800/17352 (97%)] Loss: -196862.406250\n",
      "Train Epoch: 51 [16880/17352 (97%)] Loss: -186846.796875\n",
      "Train Epoch: 51 [16960/17352 (98%)] Loss: -159668.718750\n",
      "Train Epoch: 51 [17040/17352 (98%)] Loss: -201112.406250\n",
      "Train Epoch: 51 [17120/17352 (99%)] Loss: -168048.500000\n",
      "Train Epoch: 51 [17200/17352 (99%)] Loss: -203511.640625\n",
      "Train Epoch: 51 [17280/17352 (100%)] Loss: -190236.875000\n",
      "Train Epoch: 51 [17360/17352 (100%)] Loss: -185924.625000\n",
      "    epoch          : 51\n",
      "    loss           : -189314.08841880035\n",
      "    val_loss       : -23715.900093974084\n",
      "Train Epoch: 52 [0/17352 (0%)] Loss: -211899.593750\n",
      "Train Epoch: 52 [80/17352 (0%)] Loss: -205930.828125\n",
      "Train Epoch: 52 [160/17352 (1%)] Loss: -214520.796875\n",
      "Train Epoch: 52 [240/17352 (1%)] Loss: -218529.640625\n",
      "Train Epoch: 52 [320/17352 (2%)] Loss: -231325.578125\n",
      "Train Epoch: 52 [400/17352 (2%)] Loss: -213331.218750\n",
      "Train Epoch: 52 [480/17352 (3%)] Loss: -230413.281250\n",
      "Train Epoch: 52 [560/17352 (3%)] Loss: -219658.703125\n",
      "Train Epoch: 52 [640/17352 (4%)] Loss: -224351.000000\n",
      "Train Epoch: 52 [720/17352 (4%)] Loss: -205210.453125\n",
      "Train Epoch: 52 [800/17352 (5%)] Loss: -204024.968750\n",
      "Train Epoch: 52 [880/17352 (5%)] Loss: -209642.203125\n",
      "Train Epoch: 52 [960/17352 (6%)] Loss: -216215.687500\n",
      "Train Epoch: 52 [1040/17352 (6%)] Loss: -214513.250000\n",
      "Train Epoch: 52 [1120/17352 (6%)] Loss: -214709.640625\n",
      "Train Epoch: 52 [1200/17352 (7%)] Loss: -210629.562500\n",
      "Train Epoch: 52 [1280/17352 (7%)] Loss: -236637.234375\n",
      "Train Epoch: 52 [1360/17352 (8%)] Loss: -202232.453125\n",
      "Train Epoch: 52 [1440/17352 (8%)] Loss: -194305.718750\n",
      "Train Epoch: 52 [1520/17352 (9%)] Loss: -206782.562500\n",
      "Train Epoch: 52 [1600/17352 (9%)] Loss: -196446.437500\n",
      "Train Epoch: 52 [1680/17352 (10%)] Loss: -208377.015625\n",
      "Train Epoch: 52 [1760/17352 (10%)] Loss: -205555.515625\n",
      "Train Epoch: 52 [1840/17352 (11%)] Loss: -224245.718750\n",
      "Train Epoch: 52 [1920/17352 (11%)] Loss: -205191.187500\n",
      "Train Epoch: 52 [2000/17352 (12%)] Loss: -210347.890625\n",
      "Train Epoch: 52 [2080/17352 (12%)] Loss: -210744.203125\n",
      "Train Epoch: 52 [2160/17352 (12%)] Loss: -204359.937500\n",
      "Train Epoch: 52 [2240/17352 (13%)] Loss: -205645.171875\n",
      "Train Epoch: 52 [2320/17352 (13%)] Loss: -167868.765625\n",
      "Train Epoch: 52 [2400/17352 (14%)] Loss: -215639.468750\n",
      "Train Epoch: 52 [2480/17352 (14%)] Loss: -191587.515625\n",
      "Train Epoch: 52 [2560/17352 (15%)] Loss: -179303.625000\n",
      "Train Epoch: 52 [2640/17352 (15%)] Loss: -188272.468750\n",
      "Train Epoch: 52 [2720/17352 (16%)] Loss: -163553.171875\n",
      "Train Epoch: 52 [2800/17352 (16%)] Loss: -167735.921875\n",
      "Train Epoch: 52 [2880/17352 (17%)] Loss: -189599.406250\n",
      "Train Epoch: 52 [2960/17352 (17%)] Loss: -95258.617188\n",
      "Train Epoch: 52 [3040/17352 (18%)] Loss: -190008.203125\n",
      "Train Epoch: 52 [3120/17352 (18%)] Loss: -171720.093750\n",
      "Train Epoch: 52 [3200/17352 (18%)] Loss: -208334.171875\n",
      "Train Epoch: 52 [3280/17352 (19%)] Loss: -192993.312500\n",
      "Train Epoch: 52 [3360/17352 (19%)] Loss: -190982.296875\n",
      "Train Epoch: 52 [3440/17352 (20%)] Loss: -199411.078125\n",
      "Train Epoch: 52 [3520/17352 (20%)] Loss: -192686.703125\n",
      "Train Epoch: 52 [3600/17352 (21%)] Loss: -197115.312500\n",
      "Train Epoch: 52 [3680/17352 (21%)] Loss: -163958.906250\n",
      "Train Epoch: 52 [3760/17352 (22%)] Loss: -176895.109375\n",
      "Train Epoch: 52 [3840/17352 (22%)] Loss: -218750.531250\n",
      "Train Epoch: 52 [3920/17352 (23%)] Loss: -174514.656250\n",
      "Train Epoch: 52 [4000/17352 (23%)] Loss: -174517.015625\n",
      "Train Epoch: 52 [4080/17352 (24%)] Loss: -149329.453125\n",
      "Train Epoch: 52 [4160/17352 (24%)] Loss: -171447.234375\n",
      "Train Epoch: 52 [4240/17352 (24%)] Loss: -198000.468750\n",
      "Train Epoch: 52 [4320/17352 (25%)] Loss: -193493.906250\n",
      "Train Epoch: 52 [4400/17352 (25%)] Loss: -197947.781250\n",
      "Train Epoch: 52 [4480/17352 (26%)] Loss: -193508.828125\n",
      "Train Epoch: 52 [4560/17352 (26%)] Loss: -189171.515625\n",
      "Train Epoch: 52 [4640/17352 (27%)] Loss: -192901.000000\n",
      "Train Epoch: 52 [4720/17352 (27%)] Loss: -182526.843750\n",
      "Train Epoch: 52 [4800/17352 (28%)] Loss: -199177.140625\n",
      "Train Epoch: 52 [4880/17352 (28%)] Loss: -180310.562500\n",
      "Train Epoch: 52 [4960/17352 (29%)] Loss: -184596.406250\n",
      "Train Epoch: 52 [5040/17352 (29%)] Loss: -173364.625000\n",
      "Train Epoch: 52 [5120/17352 (30%)] Loss: -200296.375000\n",
      "Train Epoch: 52 [5200/17352 (30%)] Loss: -192106.203125\n",
      "Train Epoch: 52 [5280/17352 (30%)] Loss: -171221.656250\n",
      "Train Epoch: 52 [5360/17352 (31%)] Loss: -197592.843750\n",
      "Train Epoch: 52 [5440/17352 (31%)] Loss: -205158.171875\n",
      "Train Epoch: 52 [5520/17352 (32%)] Loss: -178824.859375\n",
      "Train Epoch: 52 [5600/17352 (32%)] Loss: -183629.078125\n",
      "Train Epoch: 52 [5680/17352 (33%)] Loss: -185926.609375\n",
      "Train Epoch: 52 [5760/17352 (33%)] Loss: -184475.265625\n",
      "Train Epoch: 52 [5840/17352 (34%)] Loss: -159695.781250\n",
      "Train Epoch: 52 [5920/17352 (34%)] Loss: -151220.437500\n",
      "Train Epoch: 52 [6000/17352 (35%)] Loss: -159603.296875\n",
      "Train Epoch: 52 [6080/17352 (35%)] Loss: -213236.500000\n",
      "Train Epoch: 52 [6160/17352 (36%)] Loss: -183055.750000\n",
      "Train Epoch: 52 [6240/17352 (36%)] Loss: -203513.281250\n",
      "Train Epoch: 52 [6320/17352 (36%)] Loss: -190085.171875\n",
      "Train Epoch: 52 [6400/17352 (37%)] Loss: -180837.406250\n",
      "Train Epoch: 52 [6480/17352 (37%)] Loss: -178326.828125\n",
      "Train Epoch: 52 [6560/17352 (38%)] Loss: -200405.984375\n",
      "Train Epoch: 52 [6640/17352 (38%)] Loss: -147421.046875\n",
      "Train Epoch: 52 [6720/17352 (39%)] Loss: -196730.140625\n",
      "Train Epoch: 52 [6800/17352 (39%)] Loss: -212980.843750\n",
      "Train Epoch: 52 [6880/17352 (40%)] Loss: -199068.796875\n",
      "Train Epoch: 52 [6960/17352 (40%)] Loss: -183260.000000\n",
      "Train Epoch: 52 [7040/17352 (41%)] Loss: -201964.390625\n",
      "Train Epoch: 52 [7120/17352 (41%)] Loss: -165594.281250\n",
      "Train Epoch: 52 [7200/17352 (41%)] Loss: -208801.187500\n",
      "Train Epoch: 52 [7280/17352 (42%)] Loss: -178597.171875\n",
      "Train Epoch: 52 [7360/17352 (42%)] Loss: -201390.828125\n",
      "Train Epoch: 52 [7440/17352 (43%)] Loss: -175540.656250\n",
      "Train Epoch: 52 [7520/17352 (43%)] Loss: -148153.156250\n",
      "Train Epoch: 52 [7600/17352 (44%)] Loss: -201381.328125\n",
      "Train Epoch: 52 [7680/17352 (44%)] Loss: -173941.375000\n",
      "Train Epoch: 52 [7760/17352 (45%)] Loss: -197574.375000\n",
      "Train Epoch: 52 [7840/17352 (45%)] Loss: -183078.156250\n",
      "Train Epoch: 52 [7920/17352 (46%)] Loss: -192005.390625\n",
      "Train Epoch: 52 [8000/17352 (46%)] Loss: -208906.812500\n",
      "Train Epoch: 52 [8080/17352 (47%)] Loss: -180904.687500\n",
      "Train Epoch: 52 [8160/17352 (47%)] Loss: -195052.218750\n",
      "Train Epoch: 52 [8240/17352 (47%)] Loss: -178570.187500\n",
      "Train Epoch: 52 [8320/17352 (48%)] Loss: -185832.531250\n",
      "Train Epoch: 52 [8400/17352 (48%)] Loss: -148443.046875\n",
      "Train Epoch: 52 [8480/17352 (49%)] Loss: -207786.234375\n",
      "Train Epoch: 52 [8560/17352 (49%)] Loss: -159308.140625\n",
      "Train Epoch: 52 [8640/17352 (50%)] Loss: -200464.312500\n",
      "Train Epoch: 52 [8720/17352 (50%)] Loss: -187213.156250\n",
      "Train Epoch: 52 [8800/17352 (51%)] Loss: -188748.296875\n",
      "Train Epoch: 52 [8880/17352 (51%)] Loss: -179474.015625\n",
      "Train Epoch: 52 [8960/17352 (52%)] Loss: -195061.312500\n",
      "Train Epoch: 52 [9040/17352 (52%)] Loss: -204654.000000\n",
      "Train Epoch: 52 [9120/17352 (53%)] Loss: -177488.406250\n",
      "Train Epoch: 52 [9200/17352 (53%)] Loss: -194934.468750\n",
      "Train Epoch: 52 [9280/17352 (53%)] Loss: -210384.234375\n",
      "Train Epoch: 52 [9360/17352 (54%)] Loss: -228152.796875\n",
      "Train Epoch: 52 [9440/17352 (54%)] Loss: -207856.156250\n",
      "Train Epoch: 52 [9520/17352 (55%)] Loss: -183612.828125\n",
      "Train Epoch: 52 [9600/17352 (55%)] Loss: -180114.750000\n",
      "Train Epoch: 52 [9680/17352 (56%)] Loss: -180237.000000\n",
      "Train Epoch: 52 [9760/17352 (56%)] Loss: -160053.843750\n",
      "Train Epoch: 52 [9840/17352 (57%)] Loss: -184956.031250\n",
      "Train Epoch: 52 [9920/17352 (57%)] Loss: -179014.843750\n",
      "Train Epoch: 52 [10000/17352 (58%)] Loss: -138342.859375\n",
      "Train Epoch: 52 [10080/17352 (58%)] Loss: -153323.015625\n",
      "Train Epoch: 52 [10160/17352 (59%)] Loss: -172189.203125\n",
      "Train Epoch: 52 [10240/17352 (59%)] Loss: -207823.875000\n",
      "Train Epoch: 52 [10320/17352 (59%)] Loss: -182325.328125\n",
      "Train Epoch: 52 [10400/17352 (60%)] Loss: -208008.109375\n",
      "Train Epoch: 52 [10480/17352 (60%)] Loss: -167184.640625\n",
      "Train Epoch: 52 [10560/17352 (61%)] Loss: -185004.000000\n",
      "Train Epoch: 52 [10640/17352 (61%)] Loss: -175206.218750\n",
      "Train Epoch: 52 [10720/17352 (62%)] Loss: -166650.640625\n",
      "Train Epoch: 52 [10800/17352 (62%)] Loss: -156609.968750\n",
      "Train Epoch: 52 [10880/17352 (63%)] Loss: -197332.437500\n",
      "Train Epoch: 52 [10960/17352 (63%)] Loss: -182765.125000\n",
      "Train Epoch: 52 [11040/17352 (64%)] Loss: -203848.875000\n",
      "Train Epoch: 52 [11120/17352 (64%)] Loss: -182553.140625\n",
      "Train Epoch: 52 [11200/17352 (65%)] Loss: -187525.546875\n",
      "Train Epoch: 52 [11280/17352 (65%)] Loss: -162969.515625\n",
      "Train Epoch: 52 [11360/17352 (65%)] Loss: -209275.640625\n",
      "Train Epoch: 52 [11440/17352 (66%)] Loss: -196120.875000\n",
      "Train Epoch: 52 [11520/17352 (66%)] Loss: -190493.375000\n",
      "Train Epoch: 52 [11600/17352 (67%)] Loss: -188182.828125\n",
      "Train Epoch: 52 [11680/17352 (67%)] Loss: -176586.250000\n",
      "Train Epoch: 52 [11760/17352 (68%)] Loss: -173508.640625\n",
      "Train Epoch: 52 [11840/17352 (68%)] Loss: -175020.437500\n",
      "Train Epoch: 52 [11920/17352 (69%)] Loss: -181329.000000\n",
      "Train Epoch: 52 [12000/17352 (69%)] Loss: -201112.093750\n",
      "Train Epoch: 52 [12080/17352 (70%)] Loss: -187132.859375\n",
      "Train Epoch: 52 [12160/17352 (70%)] Loss: -181615.750000\n",
      "Train Epoch: 52 [12240/17352 (71%)] Loss: -180512.718750\n",
      "Train Epoch: 52 [12320/17352 (71%)] Loss: -185437.250000\n",
      "Train Epoch: 52 [12400/17352 (71%)] Loss: -209496.640625\n",
      "Train Epoch: 52 [12480/17352 (72%)] Loss: -179672.453125\n",
      "Train Epoch: 52 [12560/17352 (72%)] Loss: -204613.250000\n",
      "Train Epoch: 52 [12640/17352 (73%)] Loss: -187538.390625\n",
      "Train Epoch: 52 [12720/17352 (73%)] Loss: -156471.250000\n",
      "Train Epoch: 52 [12800/17352 (74%)] Loss: -177469.000000\n",
      "Train Epoch: 52 [12880/17352 (74%)] Loss: -213400.156250\n",
      "Train Epoch: 52 [12960/17352 (75%)] Loss: -200634.734375\n",
      "Train Epoch: 52 [13040/17352 (75%)] Loss: -162712.250000\n",
      "Train Epoch: 52 [13120/17352 (76%)] Loss: -169449.250000\n",
      "Train Epoch: 52 [13200/17352 (76%)] Loss: -201033.890625\n",
      "Train Epoch: 52 [13280/17352 (77%)] Loss: -206226.140625\n",
      "Train Epoch: 52 [13360/17352 (77%)] Loss: -188089.156250\n",
      "Train Epoch: 52 [13440/17352 (77%)] Loss: -202607.859375\n",
      "Train Epoch: 52 [13520/17352 (78%)] Loss: -180253.906250\n",
      "Train Epoch: 52 [13600/17352 (78%)] Loss: -172552.781250\n",
      "Train Epoch: 52 [13680/17352 (79%)] Loss: -186038.328125\n",
      "Train Epoch: 52 [13760/17352 (79%)] Loss: -185786.750000\n",
      "Train Epoch: 52 [13840/17352 (80%)] Loss: -174538.796875\n",
      "Train Epoch: 52 [13920/17352 (80%)] Loss: -171186.000000\n",
      "Train Epoch: 52 [14000/17352 (81%)] Loss: -200068.984375\n",
      "Train Epoch: 52 [14080/17352 (81%)] Loss: -176483.218750\n",
      "Train Epoch: 52 [14160/17352 (82%)] Loss: -179310.937500\n",
      "Train Epoch: 52 [14240/17352 (82%)] Loss: -180693.812500\n",
      "Train Epoch: 52 [14320/17352 (83%)] Loss: -206092.718750\n",
      "Train Epoch: 52 [14400/17352 (83%)] Loss: -208719.453125\n",
      "Train Epoch: 52 [14480/17352 (83%)] Loss: -174727.125000\n",
      "Train Epoch: 52 [14560/17352 (84%)] Loss: -176286.375000\n",
      "Train Epoch: 52 [14640/17352 (84%)] Loss: -204347.187500\n",
      "Train Epoch: 52 [14720/17352 (85%)] Loss: -174453.718750\n",
      "Train Epoch: 52 [14800/17352 (85%)] Loss: -169501.828125\n",
      "Train Epoch: 52 [14880/17352 (86%)] Loss: -201093.734375\n",
      "Train Epoch: 52 [14960/17352 (86%)] Loss: -183796.906250\n",
      "Train Epoch: 52 [15040/17352 (87%)] Loss: -196565.937500\n",
      "Train Epoch: 52 [15120/17352 (87%)] Loss: -187206.796875\n",
      "Train Epoch: 52 [15200/17352 (88%)] Loss: -169740.875000\n",
      "Train Epoch: 52 [15280/17352 (88%)] Loss: -177305.203125\n",
      "Train Epoch: 52 [15360/17352 (89%)] Loss: -195830.359375\n",
      "Train Epoch: 52 [15440/17352 (89%)] Loss: -185173.000000\n",
      "Train Epoch: 52 [15520/17352 (89%)] Loss: -165860.781250\n",
      "Train Epoch: 52 [15600/17352 (90%)] Loss: -168193.546875\n",
      "Train Epoch: 52 [15680/17352 (90%)] Loss: -184834.031250\n",
      "Train Epoch: 52 [15760/17352 (91%)] Loss: -178099.031250\n",
      "Train Epoch: 52 [15840/17352 (91%)] Loss: -177097.671875\n",
      "Train Epoch: 52 [15920/17352 (92%)] Loss: -179925.515625\n",
      "Train Epoch: 52 [16000/17352 (92%)] Loss: -209265.515625\n",
      "Train Epoch: 52 [16080/17352 (93%)] Loss: -186045.968750\n",
      "Train Epoch: 52 [16160/17352 (93%)] Loss: -205685.156250\n",
      "Train Epoch: 52 [16240/17352 (94%)] Loss: -191831.625000\n",
      "Train Epoch: 52 [16320/17352 (94%)] Loss: -205523.718750\n",
      "Train Epoch: 52 [16400/17352 (95%)] Loss: -171730.859375\n",
      "Train Epoch: 52 [16480/17352 (95%)] Loss: -164799.265625\n",
      "Train Epoch: 52 [16560/17352 (95%)] Loss: -199711.875000\n",
      "Train Epoch: 52 [16640/17352 (96%)] Loss: -177143.187500\n",
      "Train Epoch: 52 [16720/17352 (96%)] Loss: -177171.062500\n",
      "Train Epoch: 52 [16800/17352 (97%)] Loss: -192950.859375\n",
      "Train Epoch: 52 [16880/17352 (97%)] Loss: -174185.687500\n",
      "Train Epoch: 52 [16960/17352 (98%)] Loss: -179974.656250\n",
      "Train Epoch: 52 [17040/17352 (98%)] Loss: -182922.750000\n",
      "Train Epoch: 52 [17120/17352 (99%)] Loss: -153893.046875\n",
      "Train Epoch: 52 [17200/17352 (99%)] Loss: -173660.968750\n",
      "Train Epoch: 52 [17280/17352 (100%)] Loss: -196286.718750\n",
      "Train Epoch: 52 [17360/17352 (100%)] Loss: -207859.906250\n",
      "    epoch          : 52\n",
      "    loss           : -189174.42430235902\n",
      "    val_loss       : -23715.493487792395\n",
      "Train Epoch: 53 [0/17352 (0%)] Loss: -217626.750000\n",
      "Train Epoch: 53 [80/17352 (0%)] Loss: -205195.906250\n",
      "Train Epoch: 53 [160/17352 (1%)] Loss: -196440.218750\n",
      "Train Epoch: 53 [240/17352 (1%)] Loss: -236510.625000\n",
      "Train Epoch: 53 [320/17352 (2%)] Loss: -215487.031250\n",
      "Train Epoch: 53 [400/17352 (2%)] Loss: -204734.328125\n",
      "Train Epoch: 53 [480/17352 (3%)] Loss: -210208.859375\n",
      "Train Epoch: 53 [560/17352 (3%)] Loss: -196411.781250\n",
      "Train Epoch: 53 [640/17352 (4%)] Loss: -185158.968750\n",
      "Train Epoch: 53 [720/17352 (4%)] Loss: -182777.468750\n",
      "Train Epoch: 53 [800/17352 (5%)] Loss: -204407.953125\n",
      "Train Epoch: 53 [880/17352 (5%)] Loss: -230407.828125\n",
      "Train Epoch: 53 [960/17352 (6%)] Loss: -221760.109375\n",
      "Train Epoch: 53 [1040/17352 (6%)] Loss: -233733.031250\n",
      "Train Epoch: 53 [1120/17352 (6%)] Loss: -199807.140625\n",
      "Train Epoch: 53 [1200/17352 (7%)] Loss: -202231.312500\n",
      "Train Epoch: 53 [1280/17352 (7%)] Loss: -215823.703125\n",
      "Train Epoch: 53 [1360/17352 (8%)] Loss: -213321.625000\n",
      "Train Epoch: 53 [1440/17352 (8%)] Loss: -214455.796875\n",
      "Train Epoch: 53 [1520/17352 (9%)] Loss: -211107.328125\n",
      "Train Epoch: 53 [1600/17352 (9%)] Loss: -207157.703125\n",
      "Train Epoch: 53 [1680/17352 (10%)] Loss: -205113.718750\n",
      "Train Epoch: 53 [1760/17352 (10%)] Loss: -204354.109375\n",
      "Train Epoch: 53 [1840/17352 (11%)] Loss: -203270.406250\n",
      "Train Epoch: 53 [1920/17352 (11%)] Loss: -202262.812500\n",
      "Train Epoch: 53 [2000/17352 (12%)] Loss: -201662.453125\n",
      "Train Epoch: 53 [2080/17352 (12%)] Loss: -210626.828125\n",
      "Train Epoch: 53 [2160/17352 (12%)] Loss: -231331.031250\n",
      "Train Epoch: 53 [2240/17352 (13%)] Loss: -196866.203125\n",
      "Train Epoch: 53 [2320/17352 (13%)] Loss: -188810.453125\n",
      "Train Epoch: 53 [2400/17352 (14%)] Loss: -175682.953125\n",
      "Train Epoch: 53 [2480/17352 (14%)] Loss: -209273.671875\n",
      "Train Epoch: 53 [2560/17352 (15%)] Loss: -208038.062500\n",
      "Train Epoch: 53 [2640/17352 (15%)] Loss: -186042.734375\n",
      "Train Epoch: 53 [2720/17352 (16%)] Loss: -205634.828125\n",
      "Train Epoch: 53 [2800/17352 (16%)] Loss: -208798.265625\n",
      "Train Epoch: 53 [2880/17352 (17%)] Loss: -182335.031250\n",
      "Train Epoch: 53 [2960/17352 (17%)] Loss: -180143.296875\n",
      "Train Epoch: 53 [3040/17352 (18%)] Loss: -179484.546875\n",
      "Train Epoch: 53 [3120/17352 (18%)] Loss: -181724.890625\n",
      "Train Epoch: 53 [3200/17352 (18%)] Loss: -204349.031250\n",
      "Train Epoch: 53 [3280/17352 (19%)] Loss: -159735.000000\n",
      "Train Epoch: 53 [3360/17352 (19%)] Loss: -184497.359375\n",
      "Train Epoch: 53 [3440/17352 (20%)] Loss: -170231.312500\n",
      "Train Epoch: 53 [3520/17352 (20%)] Loss: -177471.968750\n",
      "Train Epoch: 53 [3600/17352 (21%)] Loss: -193052.859375\n",
      "Train Epoch: 53 [3680/17352 (21%)] Loss: -181734.265625\n",
      "Train Epoch: 53 [3760/17352 (22%)] Loss: -186944.437500\n",
      "Train Epoch: 53 [3840/17352 (22%)] Loss: -164828.921875\n",
      "Train Epoch: 53 [3920/17352 (23%)] Loss: -187319.781250\n",
      "Train Epoch: 53 [4000/17352 (23%)] Loss: -189480.218750\n",
      "Train Epoch: 53 [4080/17352 (24%)] Loss: -165732.593750\n",
      "Train Epoch: 53 [4160/17352 (24%)] Loss: -215969.156250\n",
      "Train Epoch: 53 [4240/17352 (24%)] Loss: -191889.109375\n",
      "Train Epoch: 53 [4320/17352 (25%)] Loss: -175325.984375\n",
      "Train Epoch: 53 [4400/17352 (25%)] Loss: -208036.484375\n",
      "Train Epoch: 53 [4480/17352 (26%)] Loss: -183612.281250\n",
      "Train Epoch: 53 [4560/17352 (26%)] Loss: -192229.562500\n",
      "Train Epoch: 53 [4640/17352 (27%)] Loss: -174905.437500\n",
      "Train Epoch: 53 [4720/17352 (27%)] Loss: -173130.406250\n",
      "Train Epoch: 53 [4800/17352 (28%)] Loss: -164745.921875\n",
      "Train Epoch: 53 [4880/17352 (28%)] Loss: -179970.109375\n",
      "Train Epoch: 53 [4960/17352 (29%)] Loss: -212659.500000\n",
      "Train Epoch: 53 [5040/17352 (29%)] Loss: -201940.968750\n",
      "Train Epoch: 53 [5120/17352 (30%)] Loss: -188211.156250\n",
      "Train Epoch: 53 [5200/17352 (30%)] Loss: -191164.250000\n",
      "Train Epoch: 53 [5280/17352 (30%)] Loss: -179440.875000\n",
      "Train Epoch: 53 [5360/17352 (31%)] Loss: -178305.218750\n",
      "Train Epoch: 53 [5440/17352 (31%)] Loss: -197649.468750\n",
      "Train Epoch: 53 [5520/17352 (32%)] Loss: -185598.140625\n",
      "Train Epoch: 53 [5600/17352 (32%)] Loss: -203139.953125\n",
      "Train Epoch: 53 [5680/17352 (33%)] Loss: -180263.484375\n",
      "Train Epoch: 53 [5760/17352 (33%)] Loss: -179385.375000\n",
      "Train Epoch: 53 [5840/17352 (34%)] Loss: -182738.625000\n",
      "Train Epoch: 53 [5920/17352 (34%)] Loss: -190215.656250\n",
      "Train Epoch: 53 [6000/17352 (35%)] Loss: -170770.500000\n",
      "Train Epoch: 53 [6080/17352 (35%)] Loss: -208160.875000\n",
      "Train Epoch: 53 [6160/17352 (36%)] Loss: -140585.921875\n",
      "Train Epoch: 53 [6240/17352 (36%)] Loss: -179410.640625\n",
      "Train Epoch: 53 [6320/17352 (36%)] Loss: -183080.093750\n",
      "Train Epoch: 53 [6400/17352 (37%)] Loss: -192391.312500\n",
      "Train Epoch: 53 [6480/17352 (37%)] Loss: -178568.750000\n",
      "Train Epoch: 53 [6560/17352 (38%)] Loss: -204942.812500\n",
      "Train Epoch: 53 [6640/17352 (38%)] Loss: -210152.843750\n",
      "Train Epoch: 53 [6720/17352 (39%)] Loss: -180545.609375\n",
      "Train Epoch: 53 [6800/17352 (39%)] Loss: -194054.375000\n",
      "Train Epoch: 53 [6880/17352 (40%)] Loss: -200407.906250\n",
      "Train Epoch: 53 [6960/17352 (40%)] Loss: -166460.718750\n",
      "Train Epoch: 53 [7040/17352 (41%)] Loss: -147415.781250\n",
      "Train Epoch: 53 [7120/17352 (41%)] Loss: -202238.515625\n",
      "Train Epoch: 53 [7200/17352 (41%)] Loss: -181618.218750\n",
      "Train Epoch: 53 [7280/17352 (42%)] Loss: -172889.468750\n",
      "Train Epoch: 53 [7360/17352 (42%)] Loss: -204422.703125\n",
      "Train Epoch: 53 [7440/17352 (43%)] Loss: -172614.968750\n",
      "Train Epoch: 53 [7520/17352 (43%)] Loss: -149324.703125\n",
      "Train Epoch: 53 [7600/17352 (44%)] Loss: -178870.546875\n",
      "Train Epoch: 53 [7680/17352 (44%)] Loss: -183973.203125\n",
      "Train Epoch: 53 [7760/17352 (45%)] Loss: -173574.250000\n",
      "Train Epoch: 53 [7840/17352 (45%)] Loss: -177767.312500\n",
      "Train Epoch: 53 [7920/17352 (46%)] Loss: -188449.093750\n",
      "Train Epoch: 53 [8000/17352 (46%)] Loss: -180752.484375\n",
      "Train Epoch: 53 [8080/17352 (47%)] Loss: -183367.140625\n",
      "Train Epoch: 53 [8160/17352 (47%)] Loss: -179009.890625\n",
      "Train Epoch: 53 [8240/17352 (47%)] Loss: -193447.203125\n",
      "Train Epoch: 53 [8320/17352 (48%)] Loss: -174139.546875\n",
      "Train Epoch: 53 [8400/17352 (48%)] Loss: -163094.265625\n",
      "Train Epoch: 53 [8480/17352 (49%)] Loss: -171325.187500\n",
      "Train Epoch: 53 [8560/17352 (49%)] Loss: -166997.828125\n",
      "Train Epoch: 53 [8640/17352 (50%)] Loss: -184750.234375\n",
      "Train Epoch: 53 [8720/17352 (50%)] Loss: -167041.562500\n",
      "Train Epoch: 53 [8800/17352 (51%)] Loss: -184999.875000\n",
      "Train Epoch: 53 [8880/17352 (51%)] Loss: -159665.625000\n",
      "Train Epoch: 53 [8960/17352 (52%)] Loss: -183462.890625\n",
      "Train Epoch: 53 [9040/17352 (52%)] Loss: -144986.562500\n",
      "Train Epoch: 53 [9120/17352 (53%)] Loss: -180522.984375\n",
      "Train Epoch: 53 [9200/17352 (53%)] Loss: -192694.625000\n",
      "Train Epoch: 53 [9280/17352 (53%)] Loss: -180988.328125\n",
      "Train Epoch: 53 [9360/17352 (54%)] Loss: -193513.265625\n",
      "Train Epoch: 53 [9440/17352 (54%)] Loss: -190236.125000\n",
      "Train Epoch: 53 [9520/17352 (55%)] Loss: -186152.078125\n",
      "Train Epoch: 53 [9600/17352 (55%)] Loss: -217623.609375\n",
      "Train Epoch: 53 [9680/17352 (56%)] Loss: -193009.687500\n",
      "Train Epoch: 53 [9760/17352 (56%)] Loss: -225464.609375\n",
      "Train Epoch: 53 [9840/17352 (57%)] Loss: -157770.234375\n",
      "Train Epoch: 53 [9920/17352 (57%)] Loss: -181888.000000\n",
      "Train Epoch: 53 [10000/17352 (58%)] Loss: -184837.562500\n",
      "Train Epoch: 53 [10080/17352 (58%)] Loss: -171845.500000\n",
      "Train Epoch: 53 [10160/17352 (59%)] Loss: -196297.375000\n",
      "Train Epoch: 53 [10240/17352 (59%)] Loss: -196124.500000\n",
      "Train Epoch: 53 [10320/17352 (59%)] Loss: -200966.984375\n",
      "Train Epoch: 53 [10400/17352 (60%)] Loss: -163769.937500\n",
      "Train Epoch: 53 [10480/17352 (60%)] Loss: -191805.000000\n",
      "Train Epoch: 53 [10560/17352 (61%)] Loss: -172553.109375\n",
      "Train Epoch: 53 [10640/17352 (61%)] Loss: -214637.421875\n",
      "Train Epoch: 53 [10720/17352 (62%)] Loss: -223961.609375\n",
      "Train Epoch: 53 [10800/17352 (62%)] Loss: -186499.562500\n",
      "Train Epoch: 53 [10880/17352 (63%)] Loss: -192958.281250\n",
      "Train Epoch: 53 [10960/17352 (63%)] Loss: -185804.843750\n",
      "Train Epoch: 53 [11040/17352 (64%)] Loss: -174719.796875\n",
      "Train Epoch: 53 [11120/17352 (64%)] Loss: -206225.484375\n",
      "Train Epoch: 53 [11200/17352 (65%)] Loss: -180512.484375\n",
      "Train Epoch: 53 [11280/17352 (65%)] Loss: -205406.062500\n",
      "Train Epoch: 53 [11360/17352 (65%)] Loss: -224863.281250\n",
      "Train Epoch: 53 [11440/17352 (66%)] Loss: -182099.140625\n",
      "Train Epoch: 53 [11520/17352 (66%)] Loss: -218455.281250\n",
      "Train Epoch: 53 [11600/17352 (67%)] Loss: -190998.234375\n",
      "Train Epoch: 53 [11680/17352 (67%)] Loss: -163752.640625\n",
      "Train Epoch: 53 [11760/17352 (68%)] Loss: -188966.687500\n",
      "Train Epoch: 53 [11840/17352 (68%)] Loss: -174185.437500\n",
      "Train Epoch: 53 [11920/17352 (69%)] Loss: -159693.546875\n",
      "Train Epoch: 53 [12000/17352 (69%)] Loss: -189297.359375\n",
      "Train Epoch: 53 [12080/17352 (70%)] Loss: -169188.515625\n",
      "Train Epoch: 53 [12160/17352 (70%)] Loss: -183782.906250\n",
      "Train Epoch: 53 [12240/17352 (71%)] Loss: -168075.140625\n",
      "Train Epoch: 53 [12320/17352 (71%)] Loss: -212978.546875\n",
      "Train Epoch: 53 [12400/17352 (71%)] Loss: -183163.015625\n",
      "Train Epoch: 53 [12480/17352 (72%)] Loss: -181257.734375\n",
      "Train Epoch: 53 [12560/17352 (72%)] Loss: -219926.796875\n",
      "Train Epoch: 53 [12640/17352 (73%)] Loss: -185789.640625\n",
      "Train Epoch: 53 [12720/17352 (73%)] Loss: -174991.000000\n",
      "Train Epoch: 53 [12800/17352 (74%)] Loss: -180638.671875\n",
      "Train Epoch: 53 [12880/17352 (74%)] Loss: -198827.093750\n",
      "Train Epoch: 53 [12960/17352 (75%)] Loss: -194946.000000\n",
      "Train Epoch: 53 [13040/17352 (75%)] Loss: -228155.484375\n",
      "Train Epoch: 53 [13120/17352 (76%)] Loss: -184064.687500\n",
      "Train Epoch: 53 [13200/17352 (76%)] Loss: -205213.984375\n",
      "Train Epoch: 53 [13280/17352 (77%)] Loss: -155866.281250\n",
      "Train Epoch: 53 [13360/17352 (77%)] Loss: -148922.156250\n",
      "Train Epoch: 53 [13440/17352 (77%)] Loss: -162556.812500\n",
      "Train Epoch: 53 [13520/17352 (78%)] Loss: -172192.687500\n",
      "Train Epoch: 53 [13600/17352 (78%)] Loss: -165997.250000\n",
      "Train Epoch: 53 [13680/17352 (79%)] Loss: -151507.593750\n",
      "Train Epoch: 53 [13760/17352 (79%)] Loss: -189601.796875\n",
      "Train Epoch: 53 [13840/17352 (80%)] Loss: -193357.562500\n",
      "Train Epoch: 53 [13920/17352 (80%)] Loss: -189174.234375\n",
      "Train Epoch: 53 [14000/17352 (81%)] Loss: -166513.562500\n",
      "Train Epoch: 53 [14080/17352 (81%)] Loss: -183720.093750\n",
      "Train Epoch: 53 [14160/17352 (82%)] Loss: -188185.640625\n",
      "Train Epoch: 53 [14240/17352 (82%)] Loss: -213911.250000\n",
      "Train Epoch: 53 [14320/17352 (83%)] Loss: -167247.640625\n",
      "Train Epoch: 53 [14400/17352 (83%)] Loss: -174643.578125\n",
      "Train Epoch: 53 [14480/17352 (83%)] Loss: -168667.718750\n",
      "Train Epoch: 53 [14560/17352 (84%)] Loss: -196731.328125\n",
      "Train Epoch: 53 [14640/17352 (84%)] Loss: -201825.687500\n",
      "Train Epoch: 53 [14720/17352 (85%)] Loss: -178093.156250\n",
      "Train Epoch: 53 [14800/17352 (85%)] Loss: -183260.812500\n",
      "Train Epoch: 53 [14880/17352 (86%)] Loss: -197439.765625\n",
      "Train Epoch: 53 [14960/17352 (86%)] Loss: -181972.031250\n",
      "Train Epoch: 53 [15040/17352 (87%)] Loss: -149031.281250\n",
      "Train Epoch: 53 [15120/17352 (87%)] Loss: -193492.515625\n",
      "Train Epoch: 53 [15200/17352 (88%)] Loss: -203880.265625\n",
      "Train Epoch: 53 [15280/17352 (88%)] Loss: -189604.812500\n",
      "Train Epoch: 53 [15360/17352 (89%)] Loss: -156608.468750\n",
      "Train Epoch: 53 [15440/17352 (89%)] Loss: -197379.625000\n",
      "Train Epoch: 53 [15520/17352 (89%)] Loss: -163493.140625\n",
      "Train Epoch: 53 [15600/17352 (90%)] Loss: -181002.765625\n",
      "Train Epoch: 53 [15680/17352 (90%)] Loss: -206208.390625\n",
      "Train Epoch: 53 [15760/17352 (91%)] Loss: -184740.593750\n",
      "Train Epoch: 53 [15840/17352 (91%)] Loss: -178599.375000\n",
      "Train Epoch: 53 [15920/17352 (92%)] Loss: -205687.468750\n",
      "Train Epoch: 53 [16000/17352 (92%)] Loss: -163115.078125\n",
      "Train Epoch: 53 [16080/17352 (93%)] Loss: -169616.031250\n",
      "Train Epoch: 53 [16160/17352 (93%)] Loss: -185921.546875\n",
      "Train Epoch: 53 [16240/17352 (94%)] Loss: -177077.937500\n",
      "Train Epoch: 53 [16320/17352 (94%)] Loss: -191840.906250\n",
      "Train Epoch: 53 [16400/17352 (95%)] Loss: -168505.125000\n",
      "Train Epoch: 53 [16480/17352 (95%)] Loss: -205169.671875\n",
      "Train Epoch: 53 [16560/17352 (95%)] Loss: -181918.781250\n",
      "Train Epoch: 53 [16640/17352 (96%)] Loss: -190799.453125\n",
      "Train Epoch: 53 [16720/17352 (96%)] Loss: -174453.796875\n",
      "Train Epoch: 53 [16800/17352 (97%)] Loss: -202232.562500\n",
      "Train Epoch: 53 [16880/17352 (97%)] Loss: -136431.000000\n",
      "Train Epoch: 53 [16960/17352 (98%)] Loss: -178213.625000\n",
      "Train Epoch: 53 [17040/17352 (98%)] Loss: -185436.593750\n",
      "Train Epoch: 53 [17120/17352 (99%)] Loss: -171727.234375\n",
      "Train Epoch: 53 [17200/17352 (99%)] Loss: -211171.703125\n",
      "Train Epoch: 53 [17280/17352 (100%)] Loss: -199786.906250\n",
      "Train Epoch: 53 [17360/17352 (100%)] Loss: -200270.781250\n",
      "    epoch          : 53\n",
      "    loss           : -189298.08279991368\n",
      "    val_loss       : -23715.88520848807\n",
      "Train Epoch: 54 [0/17352 (0%)] Loss: -205082.875000\n",
      "Train Epoch: 54 [80/17352 (0%)] Loss: -208387.421875\n",
      "Train Epoch: 54 [160/17352 (1%)] Loss: -203750.140625\n",
      "Train Epoch: 54 [240/17352 (1%)] Loss: -193026.500000\n",
      "Train Epoch: 54 [320/17352 (2%)] Loss: -210521.250000\n",
      "Train Epoch: 54 [400/17352 (2%)] Loss: -230190.625000\n",
      "Train Epoch: 54 [480/17352 (3%)] Loss: -221754.937500\n",
      "Train Epoch: 54 [560/17352 (3%)] Loss: -223000.906250\n",
      "Train Epoch: 54 [640/17352 (4%)] Loss: -214417.656250\n",
      "Train Epoch: 54 [720/17352 (4%)] Loss: -199113.343750\n",
      "Train Epoch: 54 [800/17352 (5%)] Loss: -214716.859375\n",
      "Train Epoch: 54 [880/17352 (5%)] Loss: -213335.031250\n",
      "Train Epoch: 54 [960/17352 (6%)] Loss: -219664.500000\n",
      "Train Epoch: 54 [1040/17352 (6%)] Loss: -198110.234375\n",
      "Train Epoch: 54 [1120/17352 (6%)] Loss: -200604.750000\n",
      "Train Epoch: 54 [1200/17352 (7%)] Loss: -218562.562500\n",
      "Train Epoch: 54 [1280/17352 (7%)] Loss: -205189.843750\n",
      "Train Epoch: 54 [1360/17352 (8%)] Loss: -199910.890625\n",
      "Train Epoch: 54 [1440/17352 (8%)] Loss: -193582.296875\n",
      "Train Epoch: 54 [1520/17352 (9%)] Loss: -196923.968750\n",
      "Train Epoch: 54 [1600/17352 (9%)] Loss: -202033.796875\n",
      "Train Epoch: 54 [1680/17352 (10%)] Loss: -217935.281250\n",
      "Train Epoch: 54 [1760/17352 (10%)] Loss: -194498.250000\n",
      "Train Epoch: 54 [1840/17352 (11%)] Loss: -211103.125000\n",
      "Train Epoch: 54 [1920/17352 (11%)] Loss: -228901.937500\n",
      "Train Epoch: 54 [2000/17352 (12%)] Loss: -204029.203125\n",
      "Train Epoch: 54 [2080/17352 (12%)] Loss: -185152.562500\n",
      "Train Epoch: 54 [2160/17352 (12%)] Loss: -211901.109375\n",
      "Train Epoch: 54 [2240/17352 (13%)] Loss: -205516.687500\n",
      "Train Epoch: 54 [2320/17352 (13%)] Loss: -205698.500000\n",
      "Train Epoch: 54 [2400/17352 (14%)] Loss: -144991.906250\n",
      "Train Epoch: 54 [2480/17352 (14%)] Loss: -186804.312500\n",
      "Train Epoch: 54 [2560/17352 (15%)] Loss: -180965.296875\n",
      "Train Epoch: 54 [2640/17352 (15%)] Loss: -189481.265625\n",
      "Train Epoch: 54 [2720/17352 (16%)] Loss: -217609.062500\n",
      "Train Epoch: 54 [2800/17352 (16%)] Loss: -180250.890625\n",
      "Train Epoch: 54 [2880/17352 (17%)] Loss: -228246.734375\n",
      "Train Epoch: 54 [2960/17352 (17%)] Loss: -223685.828125\n",
      "Train Epoch: 54 [3040/17352 (18%)] Loss: -146856.250000\n",
      "Train Epoch: 54 [3120/17352 (18%)] Loss: -210633.625000\n",
      "Train Epoch: 54 [3200/17352 (18%)] Loss: -186158.593750\n",
      "Train Epoch: 54 [3280/17352 (19%)] Loss: -210393.156250\n",
      "Train Epoch: 54 [3360/17352 (19%)] Loss: -164991.125000\n",
      "Train Epoch: 54 [3440/17352 (20%)] Loss: -173006.562500\n",
      "Train Epoch: 54 [3520/17352 (20%)] Loss: -203144.140625\n",
      "Train Epoch: 54 [3600/17352 (21%)] Loss: -190230.750000\n",
      "Train Epoch: 54 [3680/17352 (21%)] Loss: -163751.625000\n",
      "Train Epoch: 54 [3760/17352 (22%)] Loss: -188747.000000\n",
      "Train Epoch: 54 [3840/17352 (22%)] Loss: -175600.140625\n",
      "Train Epoch: 54 [3920/17352 (23%)] Loss: -184819.875000\n",
      "Train Epoch: 54 [4000/17352 (23%)] Loss: -191888.500000\n",
      "Train Epoch: 54 [4080/17352 (24%)] Loss: -168082.656250\n",
      "Train Epoch: 54 [4160/17352 (24%)] Loss: -196722.015625\n",
      "Train Epoch: 54 [4240/17352 (24%)] Loss: -181375.906250\n",
      "Train Epoch: 54 [4320/17352 (25%)] Loss: -184743.437500\n",
      "Train Epoch: 54 [4400/17352 (25%)] Loss: -221256.750000\n",
      "Train Epoch: 54 [4480/17352 (26%)] Loss: -212620.687500\n",
      "Train Epoch: 54 [4560/17352 (26%)] Loss: -181716.328125\n",
      "Train Epoch: 54 [4640/17352 (27%)] Loss: -177577.843750\n",
      "Train Epoch: 54 [4720/17352 (27%)] Loss: -182741.843750\n",
      "Train Epoch: 54 [4800/17352 (28%)] Loss: -186035.531250\n",
      "Train Epoch: 54 [4880/17352 (28%)] Loss: -223957.671875\n",
      "Train Epoch: 54 [4960/17352 (29%)] Loss: -209827.437500\n",
      "Train Epoch: 54 [5040/17352 (29%)] Loss: -162558.687500\n",
      "Train Epoch: 54 [5120/17352 (30%)] Loss: -185793.156250\n",
      "Train Epoch: 54 [5200/17352 (30%)] Loss: -188561.375000\n",
      "Train Epoch: 54 [5280/17352 (30%)] Loss: -161086.203125\n",
      "Train Epoch: 54 [5360/17352 (31%)] Loss: -203675.875000\n",
      "Train Epoch: 54 [5440/17352 (31%)] Loss: -181697.093750\n",
      "Train Epoch: 54 [5520/17352 (32%)] Loss: -197439.671875\n",
      "Train Epoch: 54 [5600/17352 (32%)] Loss: -182098.718750\n",
      "Train Epoch: 54 [5680/17352 (33%)] Loss: -188086.578125\n",
      "Train Epoch: 54 [5760/17352 (33%)] Loss: -195001.812500\n",
      "Train Epoch: 54 [5840/17352 (34%)] Loss: -174981.921875\n",
      "Train Epoch: 54 [5920/17352 (34%)] Loss: -167248.640625\n",
      "Train Epoch: 54 [6000/17352 (35%)] Loss: -204212.109375\n",
      "Train Epoch: 54 [6080/17352 (35%)] Loss: -152735.765625\n",
      "Train Epoch: 54 [6160/17352 (36%)] Loss: -166666.843750\n",
      "Train Epoch: 54 [6240/17352 (36%)] Loss: -178571.812500\n",
      "Train Epoch: 54 [6320/17352 (36%)] Loss: -187271.062500\n",
      "Train Epoch: 54 [6400/17352 (37%)] Loss: -205495.890625\n",
      "Train Epoch: 54 [6480/17352 (37%)] Loss: -176289.156250\n",
      "Train Epoch: 54 [6560/17352 (38%)] Loss: -187457.546875\n",
      "Train Epoch: 54 [6640/17352 (38%)] Loss: -171713.890625\n",
      "Train Epoch: 54 [6720/17352 (39%)] Loss: -178600.812500\n",
      "Train Epoch: 54 [6800/17352 (39%)] Loss: -190507.578125\n",
      "Train Epoch: 54 [6880/17352 (40%)] Loss: -190080.562500\n",
      "Train Epoch: 54 [6960/17352 (40%)] Loss: -209584.406250\n",
      "Train Epoch: 54 [7040/17352 (41%)] Loss: -190002.062500\n",
      "Train Epoch: 54 [7120/17352 (41%)] Loss: -183913.000000\n",
      "Train Epoch: 54 [7200/17352 (41%)] Loss: -192267.031250\n",
      "Train Epoch: 54 [7280/17352 (42%)] Loss: -202189.406250\n",
      "Train Epoch: 54 [7360/17352 (42%)] Loss: -193093.875000\n",
      "Train Epoch: 54 [7440/17352 (43%)] Loss: -181541.781250\n",
      "Train Epoch: 54 [7520/17352 (43%)] Loss: -201519.281250\n",
      "Train Epoch: 54 [7600/17352 (44%)] Loss: -163766.265625\n",
      "Train Epoch: 54 [7680/17352 (44%)] Loss: -192952.234375\n",
      "Train Epoch: 54 [7760/17352 (45%)] Loss: -177779.750000\n",
      "Train Epoch: 54 [7840/17352 (45%)] Loss: -188003.703125\n",
      "Train Epoch: 54 [7920/17352 (46%)] Loss: -159690.531250\n",
      "Train Epoch: 54 [8000/17352 (46%)] Loss: -175318.609375\n",
      "Train Epoch: 54 [8080/17352 (47%)] Loss: -164829.281250\n",
      "Train Epoch: 54 [8160/17352 (47%)] Loss: -189727.187500\n",
      "Train Epoch: 54 [8240/17352 (47%)] Loss: -177265.906250\n",
      "Train Epoch: 54 [8320/17352 (48%)] Loss: -175409.171875\n",
      "Train Epoch: 54 [8400/17352 (48%)] Loss: -203873.031250\n",
      "Train Epoch: 54 [8480/17352 (49%)] Loss: -183496.484375\n",
      "Train Epoch: 54 [8560/17352 (49%)] Loss: -198998.796875\n",
      "Train Epoch: 54 [8640/17352 (50%)] Loss: -168077.125000\n",
      "Train Epoch: 54 [8720/17352 (50%)] Loss: -180263.437500\n",
      "Train Epoch: 54 [8800/17352 (51%)] Loss: -173510.984375\n",
      "Train Epoch: 54 [8880/17352 (51%)] Loss: -178824.796875\n",
      "Train Epoch: 54 [8960/17352 (52%)] Loss: -204664.750000\n",
      "Train Epoch: 54 [9040/17352 (52%)] Loss: -145999.328125\n",
      "Train Epoch: 54 [9120/17352 (53%)] Loss: -187528.187500\n",
      "Train Epoch: 54 [9200/17352 (53%)] Loss: -197543.578125\n",
      "Train Epoch: 54 [9280/17352 (53%)] Loss: -200478.265625\n",
      "Train Epoch: 54 [9360/17352 (54%)] Loss: -181251.859375\n",
      "Train Epoch: 54 [9440/17352 (54%)] Loss: -200459.515625\n",
      "Train Epoch: 54 [9520/17352 (55%)] Loss: -184969.078125\n",
      "Train Epoch: 54 [9600/17352 (55%)] Loss: -188424.281250\n",
      "Train Epoch: 54 [9680/17352 (56%)] Loss: -171894.625000\n",
      "Train Epoch: 54 [9760/17352 (56%)] Loss: -217617.703125\n",
      "Train Epoch: 54 [9840/17352 (57%)] Loss: -172899.484375\n",
      "Train Epoch: 54 [9920/17352 (57%)] Loss: -163347.484375\n",
      "Train Epoch: 54 [10000/17352 (58%)] Loss: -183922.343750\n",
      "Train Epoch: 54 [10080/17352 (58%)] Loss: -210157.546875\n",
      "Train Epoch: 54 [10160/17352 (59%)] Loss: -188442.703125\n",
      "Train Epoch: 54 [10240/17352 (59%)] Loss: -165358.437500\n",
      "Train Epoch: 54 [10320/17352 (59%)] Loss: -186560.078125\n",
      "Train Epoch: 54 [10400/17352 (60%)] Loss: -196283.859375\n",
      "Train Epoch: 54 [10480/17352 (60%)] Loss: -186685.734375\n",
      "Train Epoch: 54 [10560/17352 (61%)] Loss: -174550.171875\n",
      "Train Epoch: 54 [10640/17352 (61%)] Loss: -201090.062500\n",
      "Train Epoch: 54 [10720/17352 (62%)] Loss: -166995.890625\n",
      "Train Epoch: 54 [10800/17352 (62%)] Loss: -185540.156250\n",
      "Train Epoch: 54 [10880/17352 (63%)] Loss: -177099.187500\n",
      "Train Epoch: 54 [10960/17352 (63%)] Loss: -183459.062500\n",
      "Train Epoch: 54 [11040/17352 (64%)] Loss: -197300.406250\n",
      "Train Epoch: 54 [11120/17352 (64%)] Loss: -181735.609375\n",
      "Train Epoch: 54 [11200/17352 (65%)] Loss: -197107.343750\n",
      "Train Epoch: 54 [11280/17352 (65%)] Loss: -159093.406250\n",
      "Train Epoch: 54 [11360/17352 (65%)] Loss: -177463.515625\n",
      "Train Epoch: 54 [11440/17352 (66%)] Loss: -173583.921875\n",
      "Train Epoch: 54 [11520/17352 (66%)] Loss: -166512.031250\n",
      "Train Epoch: 54 [11600/17352 (67%)] Loss: -180117.578125\n",
      "Train Epoch: 54 [11680/17352 (67%)] Loss: -170033.046875\n",
      "Train Epoch: 54 [11760/17352 (68%)] Loss: -193948.812500\n",
      "Train Epoch: 54 [11840/17352 (68%)] Loss: -205017.625000\n",
      "Train Epoch: 54 [11920/17352 (69%)] Loss: -213231.500000\n",
      "Train Epoch: 54 [12000/17352 (69%)] Loss: -183387.203125\n",
      "Train Epoch: 54 [12080/17352 (70%)] Loss: -191336.781250\n",
      "Train Epoch: 54 [12160/17352 (70%)] Loss: -171839.796875\n",
      "Train Epoch: 54 [12240/17352 (71%)] Loss: -183264.578125\n",
      "Train Epoch: 54 [12320/17352 (71%)] Loss: -169602.781250\n",
      "Train Epoch: 54 [12400/17352 (71%)] Loss: -194060.578125\n",
      "Train Epoch: 54 [12480/17352 (72%)] Loss: -178800.656250\n",
      "Train Epoch: 54 [12560/17352 (72%)] Loss: -188683.531250\n",
      "Train Epoch: 54 [12640/17352 (73%)] Loss: -202991.359375\n",
      "Train Epoch: 54 [12720/17352 (73%)] Loss: -207131.984375\n",
      "Train Epoch: 54 [12800/17352 (74%)] Loss: -180904.734375\n",
      "Train Epoch: 54 [12880/17352 (74%)] Loss: -168767.875000\n",
      "Train Epoch: 54 [12960/17352 (75%)] Loss: -184760.656250\n",
      "Train Epoch: 54 [13040/17352 (75%)] Loss: -159754.921875\n",
      "Train Epoch: 54 [13120/17352 (76%)] Loss: -164744.390625\n",
      "Train Epoch: 54 [13200/17352 (76%)] Loss: -203509.875000\n",
      "Train Epoch: 54 [13280/17352 (77%)] Loss: -169503.343750\n",
      "Train Epoch: 54 [13360/17352 (77%)] Loss: -173124.890625\n",
      "Train Epoch: 54 [13440/17352 (77%)] Loss: -175425.140625\n",
      "Train Epoch: 54 [13520/17352 (78%)] Loss: -218518.796875\n",
      "Train Epoch: 54 [13600/17352 (78%)] Loss: -202481.921875\n",
      "Train Epoch: 54 [13680/17352 (79%)] Loss: -211164.500000\n",
      "Train Epoch: 54 [13760/17352 (79%)] Loss: -209902.078125\n",
      "Train Epoch: 54 [13840/17352 (80%)] Loss: -190625.171875\n",
      "Train Epoch: 54 [13920/17352 (80%)] Loss: -209418.265625\n",
      "Train Epoch: 54 [14000/17352 (81%)] Loss: -184842.500000\n",
      "Train Epoch: 54 [14080/17352 (81%)] Loss: -161960.281250\n",
      "Train Epoch: 54 [14160/17352 (82%)] Loss: -176085.890625\n",
      "Train Epoch: 54 [14240/17352 (82%)] Loss: -185824.937500\n",
      "Train Epoch: 54 [14320/17352 (83%)] Loss: -190475.281250\n",
      "Train Epoch: 54 [14400/17352 (83%)] Loss: -176490.875000\n",
      "Train Epoch: 54 [14480/17352 (83%)] Loss: -212902.343750\n",
      "Train Epoch: 54 [14560/17352 (84%)] Loss: -187245.109375\n",
      "Train Epoch: 54 [14640/17352 (84%)] Loss: -209273.250000\n",
      "Train Epoch: 54 [14720/17352 (85%)] Loss: -183613.687500\n",
      "Train Epoch: 54 [14800/17352 (85%)] Loss: -180244.984375\n",
      "Train Epoch: 54 [14880/17352 (86%)] Loss: -180909.906250\n",
      "Train Epoch: 54 [14960/17352 (86%)] Loss: -231036.187500\n",
      "Train Epoch: 54 [15040/17352 (87%)] Loss: -192391.562500\n",
      "Train Epoch: 54 [15120/17352 (87%)] Loss: -177620.046875\n",
      "Train Epoch: 54 [15200/17352 (88%)] Loss: -176597.031250\n",
      "Train Epoch: 54 [15280/17352 (88%)] Loss: -205643.953125\n",
      "Train Epoch: 54 [15360/17352 (89%)] Loss: -167796.875000\n",
      "Train Epoch: 54 [15440/17352 (89%)] Loss: -180137.687500\n",
      "Train Epoch: 54 [15520/17352 (89%)] Loss: -163097.437500\n",
      "Train Epoch: 54 [15600/17352 (90%)] Loss: -184172.546875\n",
      "Train Epoch: 54 [15680/17352 (90%)] Loss: -175544.765625\n",
      "Train Epoch: 54 [15760/17352 (91%)] Loss: -202312.156250\n",
      "Train Epoch: 54 [15840/17352 (91%)] Loss: -177469.093750\n",
      "Train Epoch: 54 [15920/17352 (92%)] Loss: -196296.437500\n",
      "Train Epoch: 54 [16000/17352 (92%)] Loss: -194932.421875\n",
      "Train Epoch: 54 [16080/17352 (93%)] Loss: -180836.453125\n",
      "Train Epoch: 54 [16160/17352 (93%)] Loss: -212131.171875\n",
      "Train Epoch: 54 [16240/17352 (94%)] Loss: -170536.046875\n",
      "Train Epoch: 54 [16320/17352 (94%)] Loss: -202791.890625\n",
      "Train Epoch: 54 [16400/17352 (95%)] Loss: -188154.734375\n",
      "Train Epoch: 54 [16480/17352 (95%)] Loss: -191361.187500\n",
      "Train Epoch: 54 [16560/17352 (95%)] Loss: -188681.609375\n",
      "Train Epoch: 54 [16640/17352 (96%)] Loss: -165994.984375\n",
      "Train Epoch: 54 [16720/17352 (96%)] Loss: -193054.109375\n",
      "Train Epoch: 54 [16800/17352 (97%)] Loss: -186191.187500\n",
      "Train Epoch: 54 [16880/17352 (97%)] Loss: -157589.531250\n",
      "Train Epoch: 54 [16960/17352 (98%)] Loss: -195059.781250\n",
      "Train Epoch: 54 [17040/17352 (98%)] Loss: -191156.015625\n",
      "Train Epoch: 54 [17120/17352 (99%)] Loss: -194230.375000\n",
      "Train Epoch: 54 [17200/17352 (99%)] Loss: -203483.906250\n",
      "Train Epoch: 54 [17280/17352 (100%)] Loss: -195837.937500\n",
      "Train Epoch: 54 [17360/17352 (100%)] Loss: -184032.671875\n",
      "    epoch          : 54\n",
      "    loss           : -189382.71794088033\n",
      "    val_loss       : -23715.804078581186\n",
      "Train Epoch: 55 [0/17352 (0%)] Loss: -199816.781250\n",
      "Train Epoch: 55 [80/17352 (0%)] Loss: -212244.812500\n",
      "Train Epoch: 55 [160/17352 (1%)] Loss: -205217.562500\n",
      "Train Epoch: 55 [240/17352 (1%)] Loss: -223003.671875\n",
      "Train Epoch: 55 [320/17352 (2%)] Loss: -186075.171875\n",
      "Train Epoch: 55 [400/17352 (2%)] Loss: -203741.812500\n",
      "Train Epoch: 55 [480/17352 (3%)] Loss: -198116.125000\n",
      "Train Epoch: 55 [560/17352 (3%)] Loss: -206571.437500\n",
      "Train Epoch: 55 [640/17352 (4%)] Loss: -187714.250000\n",
      "Train Epoch: 55 [720/17352 (4%)] Loss: -204528.953125\n",
      "Train Epoch: 55 [800/17352 (5%)] Loss: -231325.125000\n",
      "Train Epoch: 55 [880/17352 (5%)] Loss: -212176.750000\n",
      "Train Epoch: 55 [960/17352 (6%)] Loss: -185156.468750\n",
      "Train Epoch: 55 [1040/17352 (6%)] Loss: -203278.578125\n",
      "Train Epoch: 55 [1120/17352 (6%)] Loss: -188744.593750\n",
      "Train Epoch: 55 [1200/17352 (7%)] Loss: -194290.609375\n",
      "Train Epoch: 55 [1280/17352 (7%)] Loss: -216098.171875\n",
      "Train Epoch: 55 [1360/17352 (8%)] Loss: -206741.921875\n",
      "Train Epoch: 55 [1440/17352 (8%)] Loss: -206650.937500\n",
      "Train Epoch: 55 [1520/17352 (9%)] Loss: -196439.453125\n",
      "Train Epoch: 55 [1600/17352 (9%)] Loss: -218536.984375\n",
      "Train Epoch: 55 [1680/17352 (10%)] Loss: -228905.062500\n",
      "Train Epoch: 55 [1760/17352 (10%)] Loss: -202319.906250\n",
      "Train Epoch: 55 [1840/17352 (11%)] Loss: -215098.593750\n",
      "Train Epoch: 55 [1920/17352 (11%)] Loss: -193030.718750\n",
      "Train Epoch: 55 [2000/17352 (12%)] Loss: -194501.609375\n",
      "Train Epoch: 55 [2080/17352 (12%)] Loss: -199089.468750\n",
      "Train Epoch: 55 [2160/17352 (12%)] Loss: -204696.500000\n",
      "Train Epoch: 55 [2240/17352 (13%)] Loss: -192094.656250\n",
      "Train Epoch: 55 [2320/17352 (13%)] Loss: -174491.656250\n",
      "Train Epoch: 55 [2400/17352 (14%)] Loss: -184735.890625\n",
      "Train Epoch: 55 [2480/17352 (14%)] Loss: -165641.156250\n",
      "Train Epoch: 55 [2560/17352 (15%)] Loss: -166661.250000\n",
      "Train Epoch: 55 [2640/17352 (15%)] Loss: -203880.937500\n",
      "Train Epoch: 55 [2720/17352 (16%)] Loss: -176527.359375\n",
      "Train Epoch: 55 [2800/17352 (16%)] Loss: -203463.906250\n",
      "Train Epoch: 55 [2880/17352 (17%)] Loss: -178657.625000\n",
      "Train Epoch: 55 [2960/17352 (17%)] Loss: -168669.109375\n",
      "Train Epoch: 55 [3040/17352 (18%)] Loss: -189570.843750\n",
      "Train Epoch: 55 [3120/17352 (18%)] Loss: -178822.281250\n",
      "Train Epoch: 55 [3200/17352 (18%)] Loss: -151501.250000\n",
      "Train Epoch: 55 [3280/17352 (19%)] Loss: -180908.078125\n",
      "Train Epoch: 55 [3360/17352 (19%)] Loss: -200837.578125\n",
      "Train Epoch: 55 [3440/17352 (20%)] Loss: -185432.343750\n",
      "Train Epoch: 55 [3520/17352 (20%)] Loss: -178131.406250\n",
      "Train Epoch: 55 [3600/17352 (21%)] Loss: -180104.796875\n",
      "Train Epoch: 55 [3680/17352 (21%)] Loss: -186729.312500\n",
      "Train Epoch: 55 [3760/17352 (22%)] Loss: -203811.375000\n",
      "Train Epoch: 55 [3840/17352 (22%)] Loss: -200461.468750\n",
      "Train Epoch: 55 [3920/17352 (23%)] Loss: -189797.953125\n",
      "Train Epoch: 55 [4000/17352 (23%)] Loss: -196250.578125\n",
      "Train Epoch: 55 [4080/17352 (24%)] Loss: -152898.281250\n",
      "Train Epoch: 55 [4160/17352 (24%)] Loss: -205210.218750\n",
      "Train Epoch: 55 [4240/17352 (24%)] Loss: -176590.984375\n",
      "Train Epoch: 55 [4320/17352 (25%)] Loss: -187774.578125\n",
      "Train Epoch: 55 [4400/17352 (25%)] Loss: -191509.109375\n",
      "Train Epoch: 55 [4480/17352 (26%)] Loss: -190991.875000\n",
      "Train Epoch: 55 [4560/17352 (26%)] Loss: -176703.953125\n",
      "Train Epoch: 55 [4640/17352 (27%)] Loss: -208338.718750\n",
      "Train Epoch: 55 [4720/17352 (27%)] Loss: -180791.953125\n",
      "Train Epoch: 55 [4800/17352 (28%)] Loss: -188214.031250\n",
      "Train Epoch: 55 [4880/17352 (28%)] Loss: -154603.718750\n",
      "Train Epoch: 55 [4960/17352 (29%)] Loss: -148506.171875\n",
      "Train Epoch: 55 [5040/17352 (29%)] Loss: -194047.687500\n",
      "Train Epoch: 55 [5120/17352 (30%)] Loss: -171544.187500\n",
      "Train Epoch: 55 [5200/17352 (30%)] Loss: -171226.562500\n",
      "Train Epoch: 55 [5280/17352 (30%)] Loss: -177302.703125\n",
      "Train Epoch: 55 [5360/17352 (31%)] Loss: -177571.812500\n",
      "Train Epoch: 55 [5440/17352 (31%)] Loss: -184165.671875\n",
      "Train Epoch: 55 [5520/17352 (32%)] Loss: -159749.515625\n",
      "Train Epoch: 55 [5600/17352 (32%)] Loss: -184742.187500\n",
      "Train Epoch: 55 [5680/17352 (33%)] Loss: -190376.328125\n",
      "Train Epoch: 55 [5760/17352 (33%)] Loss: -189502.328125\n",
      "Train Epoch: 55 [5840/17352 (34%)] Loss: -148922.593750\n",
      "Train Epoch: 55 [5920/17352 (34%)] Loss: -185056.312500\n",
      "Train Epoch: 55 [6000/17352 (35%)] Loss: -198313.421875\n",
      "Train Epoch: 55 [6080/17352 (35%)] Loss: -189160.718750\n",
      "Train Epoch: 55 [6160/17352 (36%)] Loss: -187718.718750\n",
      "Train Epoch: 55 [6240/17352 (36%)] Loss: -165864.625000\n",
      "Train Epoch: 55 [6320/17352 (36%)] Loss: -188456.437500\n",
      "Train Epoch: 55 [6400/17352 (37%)] Loss: -174620.812500\n",
      "Train Epoch: 55 [6480/17352 (37%)] Loss: -199888.015625\n",
      "Train Epoch: 55 [6560/17352 (38%)] Loss: -196560.390625\n",
      "Train Epoch: 55 [6640/17352 (38%)] Loss: -163772.593750\n",
      "Train Epoch: 55 [6720/17352 (39%)] Loss: -197384.187500\n",
      "Train Epoch: 55 [6800/17352 (39%)] Loss: -228140.875000\n",
      "Train Epoch: 55 [6880/17352 (40%)] Loss: -204417.156250\n",
      "Train Epoch: 55 [6960/17352 (40%)] Loss: -164362.890625\n",
      "Train Epoch: 55 [7040/17352 (41%)] Loss: -201119.031250\n",
      "Train Epoch: 55 [7120/17352 (41%)] Loss: -151738.265625\n",
      "Train Epoch: 55 [7200/17352 (41%)] Loss: -168195.734375\n",
      "Train Epoch: 55 [7280/17352 (42%)] Loss: -177596.359375\n",
      "Train Epoch: 55 [7360/17352 (42%)] Loss: -231028.156250\n",
      "Train Epoch: 55 [7440/17352 (43%)] Loss: -201973.296875\n",
      "Train Epoch: 55 [7520/17352 (43%)] Loss: -180993.531250\n",
      "Train Epoch: 55 [7600/17352 (44%)] Loss: -171304.390625\n",
      "Train Epoch: 55 [7680/17352 (44%)] Loss: -172612.343750\n",
      "Train Epoch: 55 [7760/17352 (45%)] Loss: -201314.296875\n",
      "Train Epoch: 55 [7840/17352 (45%)] Loss: -176583.500000\n",
      "Train Epoch: 55 [7920/17352 (46%)] Loss: -179963.734375\n",
      "Train Epoch: 55 [8000/17352 (46%)] Loss: -184492.062500\n",
      "Train Epoch: 55 [8080/17352 (47%)] Loss: -178089.031250\n",
      "Train Epoch: 55 [8160/17352 (47%)] Loss: -199514.843750\n",
      "Train Epoch: 55 [8240/17352 (47%)] Loss: -203873.187500\n",
      "Train Epoch: 55 [8320/17352 (48%)] Loss: -171434.187500\n",
      "Train Epoch: 55 [8400/17352 (48%)] Loss: -147418.765625\n",
      "Train Epoch: 55 [8480/17352 (49%)] Loss: -187455.328125\n",
      "Train Epoch: 55 [8560/17352 (49%)] Loss: -216398.453125\n",
      "Train Epoch: 55 [8640/17352 (50%)] Loss: -192883.812500\n",
      "Train Epoch: 55 [8720/17352 (50%)] Loss: -205023.718750\n",
      "Train Epoch: 55 [8800/17352 (51%)] Loss: -183780.359375\n",
      "Train Epoch: 55 [8880/17352 (51%)] Loss: -198700.625000\n",
      "Train Epoch: 55 [8960/17352 (52%)] Loss: -201096.343750\n",
      "Train Epoch: 55 [9040/17352 (52%)] Loss: -185242.343750\n",
      "Train Epoch: 55 [9120/17352 (53%)] Loss: -187591.531250\n",
      "Train Epoch: 55 [9200/17352 (53%)] Loss: -195379.656250\n",
      "Train Epoch: 55 [9280/17352 (53%)] Loss: -191889.968750\n",
      "Train Epoch: 55 [9360/17352 (54%)] Loss: -169611.750000\n",
      "Train Epoch: 55 [9440/17352 (54%)] Loss: -142338.921875\n",
      "Train Epoch: 55 [9520/17352 (55%)] Loss: -173840.953125\n",
      "Train Epoch: 55 [9600/17352 (55%)] Loss: -182771.765625\n",
      "Train Epoch: 55 [9680/17352 (56%)] Loss: -185836.546875\n",
      "Train Epoch: 55 [9760/17352 (56%)] Loss: -183079.437500\n",
      "Train Epoch: 55 [9840/17352 (57%)] Loss: -202481.406250\n",
      "Train Epoch: 55 [9920/17352 (57%)] Loss: -187126.187500\n",
      "Train Epoch: 55 [10000/17352 (58%)] Loss: -171186.171875\n",
      "Train Epoch: 55 [10080/17352 (58%)] Loss: -191232.765625\n",
      "Train Epoch: 55 [10160/17352 (59%)] Loss: -190917.578125\n",
      "Train Epoch: 55 [10240/17352 (59%)] Loss: -188433.375000\n",
      "Train Epoch: 55 [10320/17352 (59%)] Loss: -178315.343750\n",
      "Train Epoch: 55 [10400/17352 (60%)] Loss: -181426.421875\n",
      "Train Epoch: 55 [10480/17352 (60%)] Loss: -203887.328125\n",
      "Train Epoch: 55 [10560/17352 (61%)] Loss: -201366.765625\n",
      "Train Epoch: 55 [10640/17352 (61%)] Loss: -215465.515625\n",
      "Train Epoch: 55 [10720/17352 (62%)] Loss: -200195.687500\n",
      "Train Epoch: 55 [10800/17352 (62%)] Loss: -207083.796875\n",
      "Train Epoch: 55 [10880/17352 (63%)] Loss: -144985.671875\n",
      "Train Epoch: 55 [10960/17352 (63%)] Loss: -163350.062500\n",
      "Train Epoch: 55 [11040/17352 (64%)] Loss: -186031.140625\n",
      "Train Epoch: 55 [11120/17352 (64%)] Loss: -181668.828125\n",
      "Train Epoch: 55 [11200/17352 (65%)] Loss: -174642.171875\n",
      "Train Epoch: 55 [11280/17352 (65%)] Loss: -199598.796875\n",
      "Train Epoch: 55 [11360/17352 (65%)] Loss: -186613.343750\n",
      "Train Epoch: 55 [11440/17352 (66%)] Loss: -188272.953125\n",
      "Train Epoch: 55 [11520/17352 (66%)] Loss: -171897.093750\n",
      "Train Epoch: 55 [11600/17352 (67%)] Loss: -163549.328125\n",
      "Train Epoch: 55 [11680/17352 (67%)] Loss: -157005.296875\n",
      "Train Epoch: 55 [11760/17352 (68%)] Loss: -153319.750000\n",
      "Train Epoch: 55 [11840/17352 (68%)] Loss: -208008.375000\n",
      "Train Epoch: 55 [11920/17352 (69%)] Loss: -196034.578125\n",
      "Train Epoch: 55 [12000/17352 (69%)] Loss: -197316.921875\n",
      "Train Epoch: 55 [12080/17352 (70%)] Loss: -166465.781250\n",
      "Train Epoch: 55 [12160/17352 (70%)] Loss: -173362.562500\n",
      "Train Epoch: 55 [12240/17352 (71%)] Loss: -186160.296875\n",
      "Train Epoch: 55 [12320/17352 (71%)] Loss: -225471.937500\n",
      "Train Epoch: 55 [12400/17352 (71%)] Loss: -188511.125000\n",
      "Train Epoch: 55 [12480/17352 (72%)] Loss: -163493.765625\n",
      "Train Epoch: 55 [12560/17352 (72%)] Loss: -199713.390625\n",
      "Train Epoch: 55 [12640/17352 (73%)] Loss: -192994.750000\n",
      "Train Epoch: 55 [12720/17352 (73%)] Loss: -179454.281250\n",
      "Train Epoch: 55 [12800/17352 (74%)] Loss: -191592.500000\n",
      "Train Epoch: 55 [12880/17352 (74%)] Loss: -210481.453125\n",
      "Train Epoch: 55 [12960/17352 (75%)] Loss: -215412.343750\n",
      "Train Epoch: 55 [13040/17352 (75%)] Loss: -159698.812500\n",
      "Train Epoch: 55 [13120/17352 (76%)] Loss: -197540.109375\n",
      "Train Epoch: 55 [13200/17352 (76%)] Loss: -196499.640625\n",
      "Train Epoch: 55 [13280/17352 (77%)] Loss: -194069.593750\n",
      "Train Epoch: 55 [13360/17352 (77%)] Loss: -164825.687500\n",
      "Train Epoch: 55 [13440/17352 (77%)] Loss: -183289.093750\n",
      "Train Epoch: 55 [13520/17352 (78%)] Loss: -184963.765625\n",
      "Train Epoch: 55 [13600/17352 (78%)] Loss: -213179.703125\n",
      "Train Epoch: 55 [13680/17352 (79%)] Loss: -192949.406250\n",
      "Train Epoch: 55 [13760/17352 (79%)] Loss: -176493.218750\n",
      "Train Epoch: 55 [13840/17352 (80%)] Loss: -165794.515625\n",
      "Train Epoch: 55 [13920/17352 (80%)] Loss: -183920.343750\n",
      "Train Epoch: 55 [14000/17352 (81%)] Loss: -203479.718750\n",
      "Train Epoch: 55 [14080/17352 (81%)] Loss: -168766.468750\n",
      "Train Epoch: 55 [14160/17352 (82%)] Loss: -198541.843750\n",
      "Train Epoch: 55 [14240/17352 (82%)] Loss: -131047.375000\n",
      "Train Epoch: 55 [14320/17352 (83%)] Loss: -180900.296875\n",
      "Train Epoch: 55 [14400/17352 (83%)] Loss: -182100.984375\n",
      "Train Epoch: 55 [14480/17352 (83%)] Loss: -189270.046875\n",
      "Train Epoch: 55 [14560/17352 (84%)] Loss: -169446.890625\n",
      "Train Epoch: 55 [14640/17352 (84%)] Loss: -192228.609375\n",
      "Train Epoch: 55 [14720/17352 (85%)] Loss: -198001.968750\n",
      "Train Epoch: 55 [14800/17352 (85%)] Loss: -195101.500000\n",
      "Train Epoch: 55 [14880/17352 (86%)] Loss: -209266.281250\n",
      "Train Epoch: 55 [14960/17352 (86%)] Loss: -209815.671875\n",
      "Train Epoch: 55 [15040/17352 (87%)] Loss: -177731.781250\n",
      "Train Epoch: 55 [15120/17352 (87%)] Loss: -184072.515625\n",
      "Train Epoch: 55 [15200/17352 (88%)] Loss: -222853.515625\n",
      "Train Epoch: 55 [15280/17352 (88%)] Loss: -176272.468750\n",
      "Train Epoch: 55 [15360/17352 (89%)] Loss: -193002.765625\n",
      "Train Epoch: 55 [15440/17352 (89%)] Loss: -170031.656250\n",
      "Train Epoch: 55 [15520/17352 (89%)] Loss: -155869.718750\n",
      "Train Epoch: 55 [15600/17352 (90%)] Loss: -190803.062500\n",
      "Train Epoch: 55 [15680/17352 (90%)] Loss: -199800.187500\n",
      "Train Epoch: 55 [15760/17352 (91%)] Loss: -176881.828125\n",
      "Train Epoch: 55 [15840/17352 (91%)] Loss: -180913.859375\n",
      "Train Epoch: 55 [15920/17352 (92%)] Loss: -195842.703125\n",
      "Train Epoch: 55 [16000/17352 (92%)] Loss: -192269.046875\n",
      "Train Epoch: 55 [16080/17352 (93%)] Loss: -170775.078125\n",
      "Train Epoch: 55 [16160/17352 (93%)] Loss: -182397.890625\n",
      "Train Epoch: 55 [16240/17352 (94%)] Loss: -196114.343750\n",
      "Train Epoch: 55 [16320/17352 (94%)] Loss: -209276.968750\n",
      "Train Epoch: 55 [16400/17352 (95%)] Loss: -175540.625000\n",
      "Train Epoch: 55 [16480/17352 (95%)] Loss: -192384.000000\n",
      "Train Epoch: 55 [16560/17352 (95%)] Loss: -201002.921875\n",
      "Train Epoch: 55 [16640/17352 (96%)] Loss: -176673.156250\n",
      "Train Epoch: 55 [16720/17352 (96%)] Loss: -181977.828125\n",
      "Train Epoch: 55 [16800/17352 (97%)] Loss: -198258.953125\n",
      "Train Epoch: 55 [16880/17352 (97%)] Loss: -177309.828125\n",
      "Train Epoch: 55 [16960/17352 (98%)] Loss: -212904.687500\n",
      "Train Epoch: 55 [17040/17352 (98%)] Loss: -170354.015625\n",
      "Train Epoch: 55 [17120/17352 (99%)] Loss: -146002.468750\n",
      "Train Epoch: 55 [17200/17352 (99%)] Loss: -193048.921875\n",
      "Train Epoch: 55 [17280/17352 (100%)] Loss: -199173.671875\n",
      "Train Epoch: 55 [17360/17352 (100%)] Loss: -192644.906250\n",
      "    epoch          : 55\n",
      "    loss           : -189099.56873921174\n",
      "    val_loss       : -23715.92333676334\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch55.pth ...\n",
      "Train Epoch: 56 [0/17352 (0%)] Loss: -211104.546875\n",
      "Train Epoch: 56 [80/17352 (0%)] Loss: -212386.328125\n",
      "Train Epoch: 56 [160/17352 (1%)] Loss: -206558.984375\n",
      "Train Epoch: 56 [240/17352 (1%)] Loss: -212376.500000\n",
      "Train Epoch: 56 [320/17352 (2%)] Loss: -202030.718750\n",
      "Train Epoch: 56 [400/17352 (2%)] Loss: -202262.375000\n",
      "Train Epoch: 56 [480/17352 (3%)] Loss: -228015.343750\n",
      "Train Epoch: 56 [560/17352 (3%)] Loss: -209640.796875\n",
      "Train Epoch: 56 [640/17352 (4%)] Loss: -221763.843750\n",
      "Train Epoch: 56 [720/17352 (4%)] Loss: -185152.656250\n",
      "Train Epoch: 56 [800/17352 (5%)] Loss: -193709.187500\n",
      "Train Epoch: 56 [880/17352 (5%)] Loss: -204734.343750\n",
      "Train Epoch: 56 [960/17352 (6%)] Loss: -204021.515625\n",
      "Train Epoch: 56 [1040/17352 (6%)] Loss: -206783.390625\n",
      "Train Epoch: 56 [1120/17352 (6%)] Loss: -219260.656250\n",
      "Train Epoch: 56 [1200/17352 (7%)] Loss: -205556.937500\n",
      "Train Epoch: 56 [1280/17352 (7%)] Loss: -202319.296875\n",
      "Train Epoch: 56 [1360/17352 (8%)] Loss: -219199.906250\n",
      "Train Epoch: 56 [1440/17352 (8%)] Loss: -204540.109375\n",
      "Train Epoch: 56 [1520/17352 (9%)] Loss: -212186.109375\n",
      "Train Epoch: 56 [1600/17352 (9%)] Loss: -214708.421875\n",
      "Train Epoch: 56 [1680/17352 (10%)] Loss: -196420.531250\n",
      "Train Epoch: 56 [1760/17352 (10%)] Loss: -224249.812500\n",
      "Train Epoch: 56 [1840/17352 (11%)] Loss: -206748.015625\n",
      "Train Epoch: 56 [1920/17352 (11%)] Loss: -233731.156250\n",
      "Train Epoch: 56 [2000/17352 (12%)] Loss: -217627.343750\n",
      "Train Epoch: 56 [2080/17352 (12%)] Loss: -204712.796875\n",
      "Train Epoch: 56 [2160/17352 (12%)] Loss: -217587.593750\n",
      "Train Epoch: 56 [2240/17352 (13%)] Loss: -175551.953125\n",
      "Train Epoch: 56 [2320/17352 (13%)] Loss: -189262.015625\n",
      "Train Epoch: 56 [2400/17352 (14%)] Loss: -212661.046875\n",
      "Train Epoch: 56 [2480/17352 (14%)] Loss: -184751.890625\n",
      "Train Epoch: 56 [2560/17352 (15%)] Loss: -196560.843750\n",
      "Train Epoch: 56 [2640/17352 (15%)] Loss: -199782.875000\n",
      "Train Epoch: 56 [2720/17352 (16%)] Loss: -184753.984375\n",
      "Train Epoch: 56 [2800/17352 (16%)] Loss: -184740.093750\n",
      "Train Epoch: 56 [2880/17352 (17%)] Loss: -176896.578125\n",
      "Train Epoch: 56 [2960/17352 (17%)] Loss: -188750.656250\n",
      "Train Epoch: 56 [3040/17352 (18%)] Loss: -210556.578125\n",
      "Train Epoch: 56 [3120/17352 (18%)] Loss: -202237.171875\n",
      "Train Epoch: 56 [3200/17352 (18%)] Loss: -207833.937500\n",
      "Train Epoch: 56 [3280/17352 (19%)] Loss: -176081.687500\n",
      "Train Epoch: 56 [3360/17352 (19%)] Loss: -170310.421875\n",
      "Train Epoch: 56 [3440/17352 (20%)] Loss: -187310.406250\n",
      "Train Epoch: 56 [3520/17352 (20%)] Loss: -166998.468750\n",
      "Train Epoch: 56 [3600/17352 (21%)] Loss: -180912.656250\n",
      "Train Epoch: 56 [3680/17352 (21%)] Loss: -183607.296875\n",
      "Train Epoch: 56 [3760/17352 (22%)] Loss: -217598.953125\n",
      "Train Epoch: 56 [3840/17352 (22%)] Loss: -173507.109375\n",
      "Train Epoch: 56 [3920/17352 (23%)] Loss: -167216.156250\n",
      "Train Epoch: 56 [4000/17352 (23%)] Loss: -193924.437500\n",
      "Train Epoch: 56 [4080/17352 (24%)] Loss: -164991.859375\n",
      "Train Epoch: 56 [4160/17352 (24%)] Loss: -170777.718750\n",
      "Train Epoch: 56 [4240/17352 (24%)] Loss: -209266.718750\n",
      "Train Epoch: 56 [4320/17352 (25%)] Loss: -223681.359375\n",
      "Train Epoch: 56 [4400/17352 (25%)] Loss: -173362.140625\n",
      "Train Epoch: 56 [4480/17352 (26%)] Loss: -190933.937500\n",
      "Train Epoch: 56 [4560/17352 (26%)] Loss: -188502.453125\n",
      "Train Epoch: 56 [4640/17352 (27%)] Loss: -171322.906250\n",
      "Train Epoch: 56 [4720/17352 (27%)] Loss: -170767.218750\n",
      "Train Epoch: 56 [4800/17352 (28%)] Loss: -187789.796875\n",
      "Train Epoch: 56 [4880/17352 (28%)] Loss: -181962.171875\n",
      "Train Epoch: 56 [4960/17352 (29%)] Loss: -187319.968750\n",
      "Train Epoch: 56 [5040/17352 (29%)] Loss: -207125.562500\n",
      "Train Epoch: 56 [5120/17352 (30%)] Loss: -164880.843750\n",
      "Train Epoch: 56 [5200/17352 (30%)] Loss: -183064.593750\n",
      "Train Epoch: 56 [5280/17352 (30%)] Loss: -189600.750000\n",
      "Train Epoch: 56 [5360/17352 (31%)] Loss: -190237.937500\n",
      "Train Epoch: 56 [5440/17352 (31%)] Loss: -169006.625000\n",
      "Train Epoch: 56 [5520/17352 (32%)] Loss: -196931.718750\n",
      "Train Epoch: 56 [5600/17352 (32%)] Loss: -193507.843750\n",
      "Train Epoch: 56 [5680/17352 (33%)] Loss: -210918.609375\n",
      "Train Epoch: 56 [5760/17352 (33%)] Loss: -178320.343750\n",
      "Train Epoch: 56 [5840/17352 (34%)] Loss: -208032.578125\n",
      "Train Epoch: 56 [5920/17352 (34%)] Loss: -167866.531250\n",
      "Train Epoch: 56 [6000/17352 (35%)] Loss: -203479.875000\n",
      "Train Epoch: 56 [6080/17352 (35%)] Loss: -183167.312500\n",
      "Train Epoch: 56 [6160/17352 (36%)] Loss: -183228.750000\n",
      "Train Epoch: 56 [6240/17352 (36%)] Loss: -195720.390625\n",
      "Train Epoch: 56 [6320/17352 (36%)] Loss: -176879.000000\n",
      "Train Epoch: 56 [6400/17352 (37%)] Loss: -164145.140625\n",
      "Train Epoch: 56 [6480/17352 (37%)] Loss: -175667.312500\n",
      "Train Epoch: 56 [6560/17352 (38%)] Loss: -193169.937500\n",
      "Train Epoch: 56 [6640/17352 (38%)] Loss: -171188.656250\n",
      "Train Epoch: 56 [6720/17352 (39%)] Loss: -159315.843750\n",
      "Train Epoch: 56 [6800/17352 (39%)] Loss: -167954.093750\n",
      "Train Epoch: 56 [6880/17352 (40%)] Loss: -163962.781250\n",
      "Train Epoch: 56 [6960/17352 (40%)] Loss: -157498.875000\n",
      "Train Epoch: 56 [7040/17352 (41%)] Loss: -165597.812500\n",
      "Train Epoch: 56 [7120/17352 (41%)] Loss: -193048.234375\n",
      "Train Epoch: 56 [7200/17352 (41%)] Loss: -196395.515625\n",
      "Train Epoch: 56 [7280/17352 (42%)] Loss: -192388.687500\n",
      "Train Epoch: 56 [7360/17352 (42%)] Loss: -200860.312500\n",
      "Train Epoch: 56 [7440/17352 (43%)] Loss: -187500.765625\n",
      "Train Epoch: 56 [7520/17352 (43%)] Loss: -174030.531250\n",
      "Train Epoch: 56 [7600/17352 (44%)] Loss: -189403.781250\n",
      "Train Epoch: 56 [7680/17352 (44%)] Loss: -170104.906250\n",
      "Train Epoch: 56 [7760/17352 (45%)] Loss: -208017.468750\n",
      "Train Epoch: 56 [7840/17352 (45%)] Loss: -205019.203125\n",
      "Train Epoch: 56 [7920/17352 (46%)] Loss: -205638.625000\n",
      "Train Epoch: 56 [8000/17352 (46%)] Loss: -176590.687500\n",
      "Train Epoch: 56 [8080/17352 (47%)] Loss: -178134.375000\n",
      "Train Epoch: 56 [8160/17352 (47%)] Loss: -176147.953125\n",
      "Train Epoch: 56 [8240/17352 (47%)] Loss: -210481.640625\n",
      "Train Epoch: 56 [8320/17352 (48%)] Loss: -185338.906250\n",
      "Train Epoch: 56 [8400/17352 (48%)] Loss: -208722.765625\n",
      "Train Epoch: 56 [8480/17352 (49%)] Loss: -215170.218750\n",
      "Train Epoch: 56 [8560/17352 (49%)] Loss: -184832.750000\n",
      "Train Epoch: 56 [8640/17352 (50%)] Loss: -186614.031250\n",
      "Train Epoch: 56 [8720/17352 (50%)] Loss: -183967.812500\n",
      "Train Epoch: 56 [8800/17352 (51%)] Loss: -162716.515625\n",
      "Train Epoch: 56 [8880/17352 (51%)] Loss: -178597.906250\n",
      "Train Epoch: 56 [8960/17352 (52%)] Loss: -175403.312500\n",
      "Train Epoch: 56 [9040/17352 (52%)] Loss: -191162.359375\n",
      "Train Epoch: 56 [9120/17352 (53%)] Loss: -161515.515625\n",
      "Train Epoch: 56 [9200/17352 (53%)] Loss: -187526.390625\n",
      "Train Epoch: 56 [9280/17352 (53%)] Loss: -205725.218750\n",
      "Train Epoch: 56 [9360/17352 (54%)] Loss: -216397.468750\n",
      "Train Epoch: 56 [9440/17352 (54%)] Loss: -196727.375000\n",
      "Train Epoch: 56 [9520/17352 (55%)] Loss: -182326.046875\n",
      "Train Epoch: 56 [9600/17352 (55%)] Loss: -201521.562500\n",
      "Train Epoch: 56 [9680/17352 (56%)] Loss: -165998.531250\n",
      "Train Epoch: 56 [9760/17352 (56%)] Loss: -176487.031250\n",
      "Train Epoch: 56 [9840/17352 (57%)] Loss: -213226.546875\n",
      "Train Epoch: 56 [9920/17352 (57%)] Loss: -183388.953125\n",
      "Train Epoch: 56 [10000/17352 (58%)] Loss: -213183.890625\n",
      "Train Epoch: 56 [10080/17352 (58%)] Loss: -184948.921875\n",
      "Train Epoch: 56 [10160/17352 (59%)] Loss: -173448.531250\n",
      "Train Epoch: 56 [10240/17352 (59%)] Loss: -149445.250000\n",
      "Train Epoch: 56 [10320/17352 (59%)] Loss: -188432.406250\n",
      "Train Epoch: 56 [10400/17352 (60%)] Loss: -181617.046875\n",
      "Train Epoch: 56 [10480/17352 (60%)] Loss: -187201.296875\n",
      "Train Epoch: 56 [10560/17352 (61%)] Loss: -214750.593750\n",
      "Train Epoch: 56 [10640/17352 (61%)] Loss: -154601.406250\n",
      "Train Epoch: 56 [10720/17352 (62%)] Loss: -174510.234375\n",
      "Train Epoch: 56 [10800/17352 (62%)] Loss: -180514.078125\n",
      "Train Epoch: 56 [10880/17352 (63%)] Loss: -209414.109375\n",
      "Train Epoch: 56 [10960/17352 (63%)] Loss: -220018.781250\n",
      "Train Epoch: 56 [11040/17352 (64%)] Loss: -159696.375000\n",
      "Train Epoch: 56 [11120/17352 (64%)] Loss: -164681.109375\n",
      "Train Epoch: 56 [11200/17352 (65%)] Loss: -202791.484375\n",
      "Train Epoch: 56 [11280/17352 (65%)] Loss: -175675.484375\n",
      "Train Epoch: 56 [11360/17352 (65%)] Loss: -147414.234375\n",
      "Train Epoch: 56 [11440/17352 (66%)] Loss: -178826.234375\n",
      "Train Epoch: 56 [11520/17352 (66%)] Loss: -161679.765625\n",
      "Train Epoch: 56 [11600/17352 (67%)] Loss: -184948.984375\n",
      "Train Epoch: 56 [11680/17352 (67%)] Loss: -191950.515625\n",
      "Train Epoch: 56 [11760/17352 (68%)] Loss: -203143.421875\n",
      "Train Epoch: 56 [11840/17352 (68%)] Loss: -185241.250000\n",
      "Train Epoch: 56 [11920/17352 (69%)] Loss: -169172.171875\n",
      "Train Epoch: 56 [12000/17352 (69%)] Loss: -186038.890625\n",
      "Train Epoch: 56 [12080/17352 (70%)] Loss: -176974.578125\n",
      "Train Epoch: 56 [12160/17352 (70%)] Loss: -182535.390625\n",
      "Train Epoch: 56 [12240/17352 (71%)] Loss: -200459.484375\n",
      "Train Epoch: 56 [12320/17352 (71%)] Loss: -201973.531250\n",
      "Train Epoch: 56 [12400/17352 (71%)] Loss: -210160.453125\n",
      "Train Epoch: 56 [12480/17352 (72%)] Loss: -144993.234375\n",
      "Train Epoch: 56 [12560/17352 (72%)] Loss: -204366.000000\n",
      "Train Epoch: 56 [12640/17352 (73%)] Loss: -140584.187500\n",
      "Train Epoch: 56 [12720/17352 (73%)] Loss: -184277.656250\n",
      "Train Epoch: 56 [12800/17352 (74%)] Loss: -175504.484375\n",
      "Train Epoch: 56 [12880/17352 (74%)] Loss: -179319.343750\n",
      "Train Epoch: 56 [12960/17352 (75%)] Loss: -184475.125000\n",
      "Train Epoch: 56 [13040/17352 (75%)] Loss: -188500.281250\n",
      "Train Epoch: 56 [13120/17352 (76%)] Loss: -196857.500000\n",
      "Train Epoch: 56 [13200/17352 (76%)] Loss: -190622.546875\n",
      "Train Epoch: 56 [13280/17352 (77%)] Loss: -182402.406250\n",
      "Train Epoch: 56 [13360/17352 (77%)] Loss: -194231.406250\n",
      "Train Epoch: 56 [13440/17352 (77%)] Loss: -205405.140625\n",
      "Train Epoch: 56 [13520/17352 (78%)] Loss: -180993.562500\n",
      "Train Epoch: 56 [13600/17352 (78%)] Loss: -188046.937500\n",
      "Train Epoch: 56 [13680/17352 (79%)] Loss: -189565.468750\n",
      "Train Epoch: 56 [13760/17352 (79%)] Loss: -190988.109375\n",
      "Train Epoch: 56 [13840/17352 (80%)] Loss: -163110.609375\n",
      "Train Epoch: 56 [13920/17352 (80%)] Loss: -174141.593750\n",
      "Train Epoch: 56 [14000/17352 (81%)] Loss: -189501.390625\n",
      "Train Epoch: 56 [14080/17352 (81%)] Loss: -192118.375000\n",
      "Train Epoch: 56 [14160/17352 (82%)] Loss: -179449.078125\n",
      "Train Epoch: 56 [14240/17352 (82%)] Loss: -177239.421875\n",
      "Train Epoch: 56 [14320/17352 (83%)] Loss: -186943.984375\n",
      "Train Epoch: 56 [14400/17352 (83%)] Loss: -176913.500000\n",
      "Train Epoch: 56 [14480/17352 (83%)] Loss: -191674.906250\n",
      "Train Epoch: 56 [14560/17352 (84%)] Loss: -213749.687500\n",
      "Train Epoch: 56 [14640/17352 (84%)] Loss: -163248.593750\n",
      "Train Epoch: 56 [14720/17352 (85%)] Loss: -161965.062500\n",
      "Train Epoch: 56 [14800/17352 (85%)] Loss: -172188.171875\n",
      "Train Epoch: 56 [14880/17352 (86%)] Loss: -180750.937500\n",
      "Train Epoch: 56 [14960/17352 (86%)] Loss: -204948.875000\n",
      "Train Epoch: 56 [15040/17352 (87%)] Loss: -180294.343750\n",
      "Train Epoch: 56 [15120/17352 (87%)] Loss: -206354.312500\n",
      "Train Epoch: 56 [15200/17352 (88%)] Loss: -196120.703125\n",
      "Train Epoch: 56 [15280/17352 (88%)] Loss: -193132.609375\n",
      "Train Epoch: 56 [15360/17352 (89%)] Loss: -215416.921875\n",
      "Train Epoch: 56 [15440/17352 (89%)] Loss: -148503.968750\n",
      "Train Epoch: 56 [15520/17352 (89%)] Loss: -171829.937500\n",
      "Train Epoch: 56 [15600/17352 (90%)] Loss: -193947.656250\n",
      "Train Epoch: 56 [15680/17352 (90%)] Loss: -181372.281250\n",
      "Train Epoch: 56 [15760/17352 (91%)] Loss: -208303.953125\n",
      "Train Epoch: 56 [15840/17352 (91%)] Loss: -222857.984375\n",
      "Train Epoch: 56 [15920/17352 (92%)] Loss: -200221.093750\n",
      "Train Epoch: 56 [16000/17352 (92%)] Loss: -187351.750000\n",
      "Train Epoch: 56 [16080/17352 (93%)] Loss: -192385.750000\n",
      "Train Epoch: 56 [16160/17352 (93%)] Loss: -191234.062500\n",
      "Train Epoch: 56 [16240/17352 (94%)] Loss: -218837.406250\n",
      "Train Epoch: 56 [16320/17352 (94%)] Loss: -165867.765625\n",
      "Train Epoch: 56 [16400/17352 (95%)] Loss: -203431.843750\n",
      "Train Epoch: 56 [16480/17352 (95%)] Loss: -203508.828125\n",
      "Train Epoch: 56 [16560/17352 (95%)] Loss: -164503.781250\n",
      "Train Epoch: 56 [16640/17352 (96%)] Loss: -187771.687500\n",
      "Train Epoch: 56 [16720/17352 (96%)] Loss: -193492.328125\n",
      "Train Epoch: 56 [16800/17352 (97%)] Loss: -195829.515625\n",
      "Train Epoch: 56 [16880/17352 (97%)] Loss: -201097.656250\n",
      "Train Epoch: 56 [16960/17352 (98%)] Loss: -210786.640625\n",
      "Train Epoch: 56 [17040/17352 (98%)] Loss: -201039.234375\n",
      "Train Epoch: 56 [17120/17352 (99%)] Loss: -200420.093750\n",
      "Train Epoch: 56 [17200/17352 (99%)] Loss: -174453.843750\n",
      "Train Epoch: 56 [17280/17352 (100%)] Loss: -164079.359375\n",
      "Train Epoch: 56 [17360/17352 (100%)] Loss: -200837.875000\n",
      "    epoch          : 56\n",
      "    loss           : -189517.55617088606\n",
      "    val_loss       : -23715.88134686824\n",
      "Train Epoch: 57 [0/17352 (0%)] Loss: -218555.421875\n",
      "Train Epoch: 57 [80/17352 (0%)] Loss: -193413.484375\n",
      "Train Epoch: 57 [160/17352 (1%)] Loss: -205560.078125\n",
      "Train Epoch: 57 [240/17352 (1%)] Loss: -212399.156250\n",
      "Train Epoch: 57 [320/17352 (2%)] Loss: -219198.921875\n",
      "Train Epoch: 57 [400/17352 (2%)] Loss: -204026.062500\n",
      "Train Epoch: 57 [480/17352 (3%)] Loss: -205103.937500\n",
      "Train Epoch: 57 [560/17352 (3%)] Loss: -206776.656250\n",
      "Train Epoch: 57 [640/17352 (4%)] Loss: -231327.656250\n",
      "Train Epoch: 57 [720/17352 (4%)] Loss: -208536.656250\n",
      "Train Epoch: 57 [800/17352 (5%)] Loss: -201662.468750\n",
      "Train Epoch: 57 [880/17352 (5%)] Loss: -196915.859375\n",
      "Train Epoch: 57 [960/17352 (6%)] Loss: -202234.203125\n",
      "Train Epoch: 57 [1040/17352 (6%)] Loss: -206566.843750\n",
      "Train Epoch: 57 [1120/17352 (6%)] Loss: -209553.890625\n",
      "Train Epoch: 57 [1200/17352 (7%)] Loss: -203734.421875\n",
      "Train Epoch: 57 [1280/17352 (7%)] Loss: -209637.718750\n",
      "Train Epoch: 57 [1360/17352 (8%)] Loss: -202024.312500\n",
      "Train Epoch: 57 [1440/17352 (8%)] Loss: -198768.515625\n",
      "Train Epoch: 57 [1520/17352 (9%)] Loss: -199905.968750\n",
      "Train Epoch: 57 [1600/17352 (9%)] Loss: -182777.015625\n",
      "Train Epoch: 57 [1680/17352 (10%)] Loss: -215096.046875\n",
      "Train Epoch: 57 [1760/17352 (10%)] Loss: -222514.531250\n",
      "Train Epoch: 57 [1840/17352 (11%)] Loss: -236638.515625\n",
      "Train Epoch: 57 [1920/17352 (11%)] Loss: -206641.765625\n",
      "Train Epoch: 57 [2000/17352 (12%)] Loss: -204353.750000\n",
      "Train Epoch: 57 [2080/17352 (12%)] Loss: -224348.093750\n",
      "Train Epoch: 57 [2160/17352 (12%)] Loss: -230188.265625\n",
      "Train Epoch: 57 [2240/17352 (13%)] Loss: -169945.671875\n",
      "Train Epoch: 57 [2320/17352 (13%)] Loss: -193360.593750\n",
      "Train Epoch: 57 [2400/17352 (14%)] Loss: -186848.812500\n",
      "Train Epoch: 57 [2480/17352 (14%)] Loss: -191346.250000\n",
      "Train Epoch: 57 [2560/17352 (15%)] Loss: -177203.875000\n",
      "Train Epoch: 57 [2640/17352 (15%)] Loss: -165384.812500\n",
      "Train Epoch: 57 [2720/17352 (16%)] Loss: -183393.328125\n",
      "Train Epoch: 57 [2800/17352 (16%)] Loss: -202180.906250\n",
      "Train Epoch: 57 [2880/17352 (17%)] Loss: -183795.718750\n",
      "Train Epoch: 57 [2960/17352 (17%)] Loss: -168672.343750\n",
      "Train Epoch: 57 [3040/17352 (18%)] Loss: -186191.593750\n",
      "Train Epoch: 57 [3120/17352 (18%)] Loss: -184840.109375\n",
      "Train Epoch: 57 [3200/17352 (18%)] Loss: -207088.484375\n",
      "Train Epoch: 57 [3280/17352 (19%)] Loss: -170035.609375\n",
      "Train Epoch: 57 [3360/17352 (19%)] Loss: -211159.156250\n",
      "Train Epoch: 57 [3440/17352 (20%)] Loss: -187254.187500\n",
      "Train Epoch: 57 [3520/17352 (20%)] Loss: -185240.546875\n",
      "Train Epoch: 57 [3600/17352 (21%)] Loss: -148439.921875\n",
      "Train Epoch: 57 [3680/17352 (21%)] Loss: -178328.562500\n",
      "Train Epoch: 57 [3760/17352 (22%)] Loss: -218415.281250\n",
      "Train Epoch: 57 [3840/17352 (22%)] Loss: -192224.015625\n",
      "Train Epoch: 57 [3920/17352 (23%)] Loss: -186544.187500\n",
      "Train Epoch: 57 [4000/17352 (23%)] Loss: -168067.031250\n",
      "Train Epoch: 57 [4080/17352 (24%)] Loss: -164079.546875\n",
      "Train Epoch: 57 [4160/17352 (24%)] Loss: -190220.484375\n",
      "Train Epoch: 57 [4240/17352 (24%)] Loss: -163093.921875\n",
      "Train Epoch: 57 [4320/17352 (25%)] Loss: -195057.984375\n",
      "Train Epoch: 57 [4400/17352 (25%)] Loss: -175671.250000\n",
      "Train Epoch: 57 [4480/17352 (26%)] Loss: -202598.734375\n",
      "Train Epoch: 57 [4560/17352 (26%)] Loss: -210921.156250\n",
      "Train Epoch: 57 [4640/17352 (27%)] Loss: -166004.421875\n",
      "Train Epoch: 57 [4720/17352 (27%)] Loss: -221251.843750\n",
      "Train Epoch: 57 [4800/17352 (28%)] Loss: -190214.562500\n",
      "Train Epoch: 57 [4880/17352 (28%)] Loss: -200835.234375\n",
      "Train Epoch: 57 [4960/17352 (29%)] Loss: -218519.843750\n",
      "Train Epoch: 57 [5040/17352 (29%)] Loss: -182918.468750\n",
      "Train Epoch: 57 [5120/17352 (30%)] Loss: -181921.500000\n",
      "Train Epoch: 57 [5200/17352 (30%)] Loss: -195649.765625\n",
      "Train Epoch: 57 [5280/17352 (30%)] Loss: -188206.359375\n",
      "Train Epoch: 57 [5360/17352 (31%)] Loss: -172892.125000\n",
      "Train Epoch: 57 [5440/17352 (31%)] Loss: -171422.468750\n",
      "Train Epoch: 57 [5520/17352 (32%)] Loss: -156997.484375\n",
      "Train Epoch: 57 [5600/17352 (32%)] Loss: -148824.953125\n",
      "Train Epoch: 57 [5680/17352 (33%)] Loss: -196506.906250\n",
      "Train Epoch: 57 [5760/17352 (33%)] Loss: -159698.375000\n",
      "Train Epoch: 57 [5840/17352 (34%)] Loss: -169443.687500\n",
      "Train Epoch: 57 [5920/17352 (34%)] Loss: -192952.031250\n",
      "Train Epoch: 57 [6000/17352 (35%)] Loss: -179967.156250\n",
      "Train Epoch: 57 [6080/17352 (35%)] Loss: -183262.656250\n",
      "Train Epoch: 57 [6160/17352 (36%)] Loss: -183458.765625\n",
      "Train Epoch: 57 [6240/17352 (36%)] Loss: -192747.937500\n",
      "Train Epoch: 57 [6320/17352 (36%)] Loss: -188007.109375\n",
      "Train Epoch: 57 [6400/17352 (37%)] Loss: -206475.328125\n",
      "Train Epoch: 57 [6480/17352 (37%)] Loss: -168767.140625\n",
      "Train Epoch: 57 [6560/17352 (38%)] Loss: -179315.906250\n",
      "Train Epoch: 57 [6640/17352 (38%)] Loss: -213178.656250\n",
      "Train Epoch: 57 [6720/17352 (39%)] Loss: -188671.609375\n",
      "Train Epoch: 57 [6800/17352 (39%)] Loss: -203457.453125\n",
      "Train Epoch: 57 [6880/17352 (40%)] Loss: -210782.968750\n",
      "Train Epoch: 57 [6960/17352 (40%)] Loss: -185231.937500\n",
      "Train Epoch: 57 [7040/17352 (41%)] Loss: -178201.796875\n",
      "Train Epoch: 57 [7120/17352 (41%)] Loss: -200478.515625\n",
      "Train Epoch: 57 [7200/17352 (41%)] Loss: -196444.765625\n",
      "Train Epoch: 57 [7280/17352 (42%)] Loss: -166026.296875\n",
      "Train Epoch: 57 [7360/17352 (42%)] Loss: -164684.750000\n",
      "Train Epoch: 57 [7440/17352 (43%)] Loss: -192372.125000\n",
      "Train Epoch: 57 [7520/17352 (43%)] Loss: -176964.390625\n",
      "Train Epoch: 57 [7600/17352 (44%)] Loss: -169749.062500\n",
      "Train Epoch: 57 [7680/17352 (44%)] Loss: -213237.484375\n",
      "Train Epoch: 57 [7760/17352 (45%)] Loss: -227891.312500\n",
      "Train Epoch: 57 [7840/17352 (45%)] Loss: -178865.406250\n",
      "Train Epoch: 57 [7920/17352 (46%)] Loss: -188566.828125\n",
      "Train Epoch: 57 [8000/17352 (46%)] Loss: -196703.265625\n",
      "Train Epoch: 57 [8080/17352 (47%)] Loss: -164502.968750\n",
      "Train Epoch: 57 [8160/17352 (47%)] Loss: -179380.531250\n",
      "Train Epoch: 57 [8240/17352 (47%)] Loss: -181985.015625\n",
      "Train Epoch: 57 [8320/17352 (48%)] Loss: -200306.125000\n",
      "Train Epoch: 57 [8400/17352 (48%)] Loss: -214753.109375\n",
      "Train Epoch: 57 [8480/17352 (49%)] Loss: -129692.656250\n",
      "Train Epoch: 57 [8560/17352 (49%)] Loss: -200168.312500\n",
      "Train Epoch: 57 [8640/17352 (50%)] Loss: -199783.859375\n",
      "Train Epoch: 57 [8720/17352 (50%)] Loss: -167302.343750\n",
      "Train Epoch: 57 [8800/17352 (51%)] Loss: -203674.640625\n",
      "Train Epoch: 57 [8880/17352 (51%)] Loss: -206562.296875\n",
      "Train Epoch: 57 [8960/17352 (52%)] Loss: -192955.109375\n",
      "Train Epoch: 57 [9040/17352 (52%)] Loss: -197518.562500\n",
      "Train Epoch: 57 [9120/17352 (53%)] Loss: -199774.156250\n",
      "Train Epoch: 57 [9200/17352 (53%)] Loss: -177276.343750\n",
      "Train Epoch: 57 [9280/17352 (53%)] Loss: -167084.703125\n",
      "Train Epoch: 57 [9360/17352 (54%)] Loss: -140582.656250\n",
      "Train Epoch: 57 [9440/17352 (54%)] Loss: -179014.234375\n",
      "Train Epoch: 57 [9520/17352 (55%)] Loss: -149028.890625\n",
      "Train Epoch: 57 [9600/17352 (55%)] Loss: -176146.265625\n",
      "Train Epoch: 57 [9680/17352 (56%)] Loss: -209187.203125\n",
      "Train Epoch: 57 [9760/17352 (56%)] Loss: -173509.890625\n",
      "Train Epoch: 57 [9840/17352 (57%)] Loss: -178730.421875\n",
      "Train Epoch: 57 [9920/17352 (57%)] Loss: -187323.593750\n",
      "Train Epoch: 57 [10000/17352 (58%)] Loss: -203144.906250\n",
      "Train Epoch: 57 [10080/17352 (58%)] Loss: -177303.375000\n",
      "Train Epoch: 57 [10160/17352 (59%)] Loss: -165803.437500\n",
      "Train Epoch: 57 [10240/17352 (59%)] Loss: -210153.546875\n",
      "Train Epoch: 57 [10320/17352 (59%)] Loss: -165606.468750\n",
      "Train Epoch: 57 [10400/17352 (60%)] Loss: -207854.656250\n",
      "Train Epoch: 57 [10480/17352 (60%)] Loss: -197946.296875\n",
      "Train Epoch: 57 [10560/17352 (61%)] Loss: -193005.484375\n",
      "Train Epoch: 57 [10640/17352 (61%)] Loss: -151517.328125\n",
      "Train Epoch: 57 [10720/17352 (62%)] Loss: -169978.640625\n",
      "Train Epoch: 57 [10800/17352 (62%)] Loss: -189564.796875\n",
      "Train Epoch: 57 [10880/17352 (63%)] Loss: -163498.000000\n",
      "Train Epoch: 57 [10960/17352 (63%)] Loss: -184919.328125\n",
      "Train Epoch: 57 [11040/17352 (64%)] Loss: -181724.187500\n",
      "Train Epoch: 57 [11120/17352 (64%)] Loss: -171720.859375\n",
      "Train Epoch: 57 [11200/17352 (65%)] Loss: -196256.375000\n",
      "Train Epoch: 57 [11280/17352 (65%)] Loss: -172961.625000\n",
      "Train Epoch: 57 [11360/17352 (65%)] Loss: -196119.218750\n",
      "Train Epoch: 57 [11440/17352 (66%)] Loss: -184956.968750\n",
      "Train Epoch: 57 [11520/17352 (66%)] Loss: -208722.140625\n",
      "Train Epoch: 57 [11600/17352 (67%)] Loss: -168262.578125\n",
      "Train Epoch: 57 [11680/17352 (67%)] Loss: -196931.281250\n",
      "Train Epoch: 57 [11760/17352 (68%)] Loss: -190085.953125\n",
      "Train Epoch: 57 [11840/17352 (68%)] Loss: -152902.312500\n",
      "Train Epoch: 57 [11920/17352 (69%)] Loss: -188810.046875\n",
      "Train Epoch: 57 [12000/17352 (69%)] Loss: -185051.484375\n",
      "Train Epoch: 57 [12080/17352 (70%)] Loss: -171329.500000\n",
      "Train Epoch: 57 [12160/17352 (70%)] Loss: -153888.765625\n",
      "Train Epoch: 57 [12240/17352 (71%)] Loss: -142611.406250\n",
      "Train Epoch: 57 [12320/17352 (71%)] Loss: -205528.406250\n",
      "Train Epoch: 57 [12400/17352 (71%)] Loss: -206152.656250\n",
      "Train Epoch: 57 [12480/17352 (72%)] Loss: -180257.250000\n",
      "Train Epoch: 57 [12560/17352 (72%)] Loss: -204613.656250\n",
      "Train Epoch: 57 [12640/17352 (73%)] Loss: -173034.984375\n",
      "Train Epoch: 57 [12720/17352 (73%)] Loss: -177771.031250\n",
      "Train Epoch: 57 [12800/17352 (74%)] Loss: -173886.156250\n",
      "Train Epoch: 57 [12880/17352 (74%)] Loss: -185992.843750\n",
      "Train Epoch: 57 [12960/17352 (75%)] Loss: -179735.625000\n",
      "Train Epoch: 57 [13040/17352 (75%)] Loss: -185395.890625\n",
      "Train Epoch: 57 [13120/17352 (76%)] Loss: -144992.593750\n",
      "Train Epoch: 57 [13200/17352 (76%)] Loss: -167186.156250\n",
      "Train Epoch: 57 [13280/17352 (77%)] Loss: -175358.609375\n",
      "Train Epoch: 57 [13360/17352 (77%)] Loss: -192128.718750\n",
      "Train Epoch: 57 [13440/17352 (77%)] Loss: -192391.109375\n",
      "Train Epoch: 57 [13520/17352 (78%)] Loss: -206688.687500\n",
      "Train Epoch: 57 [13600/17352 (78%)] Loss: -183872.984375\n",
      "Train Epoch: 57 [13680/17352 (79%)] Loss: -179312.375000\n",
      "Train Epoch: 57 [13760/17352 (79%)] Loss: -189599.750000\n",
      "Train Epoch: 57 [13840/17352 (80%)] Loss: -170102.375000\n",
      "Train Epoch: 57 [13920/17352 (80%)] Loss: -203880.312500\n",
      "Train Epoch: 57 [14000/17352 (81%)] Loss: -181611.859375\n",
      "Train Epoch: 57 [14080/17352 (81%)] Loss: -188275.734375\n",
      "Train Epoch: 57 [14160/17352 (82%)] Loss: -187399.140625\n",
      "Train Epoch: 57 [14240/17352 (82%)] Loss: -200975.781250\n",
      "Train Epoch: 57 [14320/17352 (83%)] Loss: -225326.562500\n",
      "Train Epoch: 57 [14400/17352 (83%)] Loss: -216321.859375\n",
      "Train Epoch: 57 [14480/17352 (83%)] Loss: -180049.812500\n",
      "Train Epoch: 57 [14560/17352 (84%)] Loss: -178431.828125\n",
      "Train Epoch: 57 [14640/17352 (84%)] Loss: -190003.687500\n",
      "Train Epoch: 57 [14720/17352 (85%)] Loss: -181261.953125\n",
      "Train Epoch: 57 [14800/17352 (85%)] Loss: -197565.812500\n",
      "Train Epoch: 57 [14880/17352 (86%)] Loss: -202988.078125\n",
      "Train Epoch: 57 [14960/17352 (86%)] Loss: -207790.406250\n",
      "Train Epoch: 57 [15040/17352 (87%)] Loss: -217597.968750\n",
      "Train Epoch: 57 [15120/17352 (87%)] Loss: -159755.390625\n",
      "Train Epoch: 57 [15200/17352 (88%)] Loss: -184453.734375\n",
      "Train Epoch: 57 [15280/17352 (88%)] Loss: -191001.156250\n",
      "Train Epoch: 57 [15360/17352 (89%)] Loss: -148402.375000\n",
      "Train Epoch: 57 [15440/17352 (89%)] Loss: -146862.875000\n",
      "Train Epoch: 57 [15520/17352 (89%)] Loss: -191952.671875\n",
      "Train Epoch: 57 [15600/17352 (90%)] Loss: -179475.703125\n",
      "Train Epoch: 57 [15680/17352 (90%)] Loss: -202846.828125\n",
      "Train Epoch: 57 [15760/17352 (91%)] Loss: -190914.937500\n",
      "Train Epoch: 57 [15840/17352 (91%)] Loss: -195107.390625\n",
      "Train Epoch: 57 [15920/17352 (92%)] Loss: -166553.109375\n",
      "Train Epoch: 57 [16000/17352 (92%)] Loss: -166255.375000\n",
      "Train Epoch: 57 [16080/17352 (93%)] Loss: -165806.000000\n",
      "Train Epoch: 57 [16160/17352 (93%)] Loss: -183224.171875\n",
      "Train Epoch: 57 [16240/17352 (94%)] Loss: -180964.500000\n",
      "Train Epoch: 57 [16320/17352 (94%)] Loss: -174456.234375\n",
      "Train Epoch: 57 [16400/17352 (95%)] Loss: -212987.953125\n",
      "Train Epoch: 57 [16480/17352 (95%)] Loss: -184998.296875\n",
      "Train Epoch: 57 [16560/17352 (95%)] Loss: -184176.250000\n",
      "Train Epoch: 57 [16640/17352 (96%)] Loss: -189506.671875\n",
      "Train Epoch: 57 [16720/17352 (96%)] Loss: -184254.125000\n",
      "Train Epoch: 57 [16800/17352 (97%)] Loss: -182775.046875\n",
      "Train Epoch: 57 [16880/17352 (97%)] Loss: -196295.546875\n",
      "Train Epoch: 57 [16960/17352 (98%)] Loss: -171834.500000\n",
      "Train Epoch: 57 [17040/17352 (98%)] Loss: -199446.453125\n",
      "Train Epoch: 57 [17120/17352 (99%)] Loss: -185835.921875\n",
      "Train Epoch: 57 [17200/17352 (99%)] Loss: -167880.781250\n",
      "Train Epoch: 57 [17280/17352 (100%)] Loss: -231036.359375\n",
      "Train Epoch: 57 [17360/17352 (100%)] Loss: -185338.046875\n",
      "    epoch          : 57\n",
      "    loss           : -189334.5065179085\n",
      "    val_loss       : -23715.95546668684\n",
      "Train Epoch: 58 [0/17352 (0%)] Loss: -186079.000000\n",
      "Train Epoch: 58 [80/17352 (0%)] Loss: -201667.453125\n",
      "Train Epoch: 58 [160/17352 (1%)] Loss: -224256.796875\n",
      "Train Epoch: 58 [240/17352 (1%)] Loss: -204402.265625\n",
      "Train Epoch: 58 [320/17352 (2%)] Loss: -204736.625000\n",
      "Train Epoch: 58 [400/17352 (2%)] Loss: -217934.093750\n",
      "Train Epoch: 58 [480/17352 (3%)] Loss: -211904.937500\n",
      "Train Epoch: 58 [560/17352 (3%)] Loss: -226091.968750\n",
      "Train Epoch: 58 [640/17352 (4%)] Loss: -214523.718750\n",
      "Train Epoch: 58 [720/17352 (4%)] Loss: -188738.640625\n",
      "Train Epoch: 58 [800/17352 (5%)] Loss: -196925.656250\n",
      "Train Epoch: 58 [880/17352 (5%)] Loss: -198110.031250\n",
      "Train Epoch: 58 [960/17352 (6%)] Loss: -213325.562500\n",
      "Train Epoch: 58 [1040/17352 (6%)] Loss: -203736.609375\n",
      "Train Epoch: 58 [1120/17352 (6%)] Loss: -193023.812500\n",
      "Train Epoch: 58 [1200/17352 (7%)] Loss: -205554.281250\n",
      "Train Epoch: 58 [1280/17352 (7%)] Loss: -206148.109375\n",
      "Train Epoch: 58 [1360/17352 (8%)] Loss: -229230.453125\n",
      "Train Epoch: 58 [1440/17352 (8%)] Loss: -199912.625000\n",
      "Train Epoch: 58 [1520/17352 (9%)] Loss: -185155.203125\n",
      "Train Epoch: 58 [1600/17352 (9%)] Loss: -228902.859375\n",
      "Train Epoch: 58 [1680/17352 (10%)] Loss: -214415.453125\n",
      "Train Epoch: 58 [1760/17352 (10%)] Loss: -210199.828125\n",
      "Train Epoch: 58 [1840/17352 (11%)] Loss: -216101.375000\n",
      "Train Epoch: 58 [1920/17352 (11%)] Loss: -230404.562500\n",
      "Train Epoch: 58 [2000/17352 (12%)] Loss: -214456.203125\n",
      "Train Epoch: 58 [2080/17352 (12%)] Loss: -222513.984375\n",
      "Train Epoch: 58 [2160/17352 (12%)] Loss: -204529.703125\n",
      "Train Epoch: 58 [2240/17352 (13%)] Loss: -168259.921875\n",
      "Train Epoch: 58 [2320/17352 (13%)] Loss: -186154.859375\n",
      "Train Epoch: 58 [2400/17352 (14%)] Loss: -197545.875000\n",
      "Train Epoch: 58 [2480/17352 (14%)] Loss: -201381.187500\n",
      "Train Epoch: 58 [2560/17352 (15%)] Loss: -205694.515625\n",
      "Train Epoch: 58 [2640/17352 (15%)] Loss: -165798.718750\n",
      "Train Epoch: 58 [2720/17352 (16%)] Loss: -177476.250000\n",
      "Train Epoch: 58 [2800/17352 (16%)] Loss: -175417.171875\n",
      "Train Epoch: 58 [2880/17352 (17%)] Loss: -184846.781250\n",
      "Train Epoch: 58 [2960/17352 (17%)] Loss: -184759.703125\n",
      "Train Epoch: 58 [3040/17352 (18%)] Loss: -202188.531250\n",
      "Train Epoch: 58 [3120/17352 (18%)] Loss: -163107.421875\n",
      "Train Epoch: 58 [3200/17352 (18%)] Loss: -205804.281250\n",
      "Train Epoch: 58 [3280/17352 (19%)] Loss: -182679.765625\n",
      "Train Epoch: 58 [3360/17352 (19%)] Loss: -209267.437500\n",
      "Train Epoch: 58 [3440/17352 (20%)] Loss: -181980.109375\n",
      "Train Epoch: 58 [3520/17352 (20%)] Loss: -195782.531250\n",
      "Train Epoch: 58 [3600/17352 (21%)] Loss: -179675.640625\n",
      "Train Epoch: 58 [3680/17352 (21%)] Loss: -183787.546875\n",
      "Train Epoch: 58 [3760/17352 (22%)] Loss: -202316.765625\n",
      "Train Epoch: 58 [3840/17352 (22%)] Loss: -169977.171875\n",
      "Train Epoch: 58 [3920/17352 (23%)] Loss: -185444.859375\n",
      "Train Epoch: 58 [4000/17352 (23%)] Loss: -175747.906250\n",
      "Train Epoch: 58 [4080/17352 (24%)] Loss: -196125.453125\n",
      "Train Epoch: 58 [4160/17352 (24%)] Loss: -187314.500000\n",
      "Train Epoch: 58 [4240/17352 (24%)] Loss: -209184.015625\n",
      "Train Epoch: 58 [4320/17352 (25%)] Loss: -183786.828125\n",
      "Train Epoch: 58 [4400/17352 (25%)] Loss: -191512.046875\n",
      "Train Epoch: 58 [4480/17352 (26%)] Loss: -154601.500000\n",
      "Train Epoch: 58 [4560/17352 (26%)] Loss: -166549.078125\n",
      "Train Epoch: 58 [4640/17352 (27%)] Loss: -157593.156250\n",
      "Train Epoch: 58 [4720/17352 (27%)] Loss: -204338.328125\n",
      "Train Epoch: 58 [4800/17352 (28%)] Loss: -174454.015625\n",
      "Train Epoch: 58 [4880/17352 (28%)] Loss: -196814.140625\n",
      "Train Epoch: 58 [4960/17352 (29%)] Loss: -167487.031250\n",
      "Train Epoch: 58 [5040/17352 (29%)] Loss: -165395.015625\n",
      "Train Epoch: 58 [5120/17352 (30%)] Loss: -178595.921875\n",
      "Train Epoch: 58 [5200/17352 (30%)] Loss: -195296.625000\n",
      "Train Epoch: 58 [5280/17352 (30%)] Loss: -179315.468750\n",
      "Train Epoch: 58 [5360/17352 (31%)] Loss: -175684.062500\n",
      "Train Epoch: 58 [5440/17352 (31%)] Loss: -215417.140625\n",
      "Train Epoch: 58 [5520/17352 (32%)] Loss: -183224.546875\n",
      "Train Epoch: 58 [5600/17352 (32%)] Loss: -190579.109375\n",
      "Train Epoch: 58 [5680/17352 (33%)] Loss: -208127.265625\n",
      "Train Epoch: 58 [5760/17352 (33%)] Loss: -171840.328125\n",
      "Train Epoch: 58 [5840/17352 (34%)] Loss: -193169.875000\n",
      "Train Epoch: 58 [5920/17352 (34%)] Loss: -186038.687500\n",
      "Train Epoch: 58 [6000/17352 (35%)] Loss: -172233.937500\n",
      "Train Epoch: 58 [6080/17352 (35%)] Loss: -159611.562500\n",
      "Train Epoch: 58 [6160/17352 (36%)] Loss: -180255.406250\n",
      "Train Epoch: 58 [6240/17352 (36%)] Loss: -193131.718750\n",
      "Train Epoch: 58 [6320/17352 (36%)] Loss: -169006.046875\n",
      "Train Epoch: 58 [6400/17352 (37%)] Loss: -191556.218750\n",
      "Train Epoch: 58 [6480/17352 (37%)] Loss: -168504.312500\n",
      "Train Epoch: 58 [6560/17352 (38%)] Loss: -203142.875000\n",
      "Train Epoch: 58 [6640/17352 (38%)] Loss: -183065.109375\n",
      "Train Epoch: 58 [6720/17352 (39%)] Loss: -167142.937500\n",
      "Train Epoch: 58 [6800/17352 (39%)] Loss: -177270.687500\n",
      "Train Epoch: 58 [6880/17352 (40%)] Loss: -168078.000000\n",
      "Train Epoch: 58 [6960/17352 (40%)] Loss: -176083.328125\n",
      "Train Epoch: 58 [7040/17352 (41%)] Loss: -172557.296875\n",
      "Train Epoch: 58 [7120/17352 (41%)] Loss: -160053.265625\n",
      "Train Epoch: 58 [7200/17352 (41%)] Loss: -187262.359375\n",
      "Train Epoch: 58 [7280/17352 (42%)] Loss: -186853.390625\n",
      "Train Epoch: 58 [7360/17352 (42%)] Loss: -216323.171875\n",
      "Train Epoch: 58 [7440/17352 (43%)] Loss: -185374.218750\n",
      "Train Epoch: 58 [7520/17352 (43%)] Loss: -188214.656250\n",
      "Train Epoch: 58 [7600/17352 (44%)] Loss: -170778.609375\n",
      "Train Epoch: 58 [7680/17352 (44%)] Loss: -184282.250000\n",
      "Train Epoch: 58 [7760/17352 (45%)] Loss: -153313.406250\n",
      "Train Epoch: 58 [7840/17352 (45%)] Loss: -174879.921875\n",
      "Train Epoch: 58 [7920/17352 (46%)] Loss: -181006.968750\n",
      "Train Epoch: 58 [8000/17352 (46%)] Loss: -201363.015625\n",
      "Train Epoch: 58 [8080/17352 (47%)] Loss: -202981.718750\n",
      "Train Epoch: 58 [8160/17352 (47%)] Loss: -196728.296875\n",
      "Train Epoch: 58 [8240/17352 (47%)] Loss: -217599.187500\n",
      "Train Epoch: 58 [8320/17352 (48%)] Loss: -188431.515625\n",
      "Train Epoch: 58 [8400/17352 (48%)] Loss: -190216.453125\n",
      "Train Epoch: 58 [8480/17352 (49%)] Loss: -199784.968750\n",
      "Train Epoch: 58 [8560/17352 (49%)] Loss: -192281.625000\n",
      "Train Epoch: 58 [8640/17352 (50%)] Loss: -199415.406250\n",
      "Train Epoch: 58 [8720/17352 (50%)] Loss: -198692.265625\n",
      "Train Epoch: 58 [8800/17352 (51%)] Loss: -205640.515625\n",
      "Train Epoch: 58 [8880/17352 (51%)] Loss: -171226.500000\n",
      "Train Epoch: 58 [8960/17352 (52%)] Loss: -177774.296875\n",
      "Train Epoch: 58 [9040/17352 (52%)] Loss: -174187.781250\n",
      "Train Epoch: 58 [9120/17352 (53%)] Loss: -165864.343750\n",
      "Train Epoch: 58 [9200/17352 (53%)] Loss: -191626.093750\n",
      "Train Epoch: 58 [9280/17352 (53%)] Loss: -189170.328125\n",
      "Train Epoch: 58 [9360/17352 (54%)] Loss: -200286.640625\n",
      "Train Epoch: 58 [9440/17352 (54%)] Loss: -200197.875000\n",
      "Train Epoch: 58 [9520/17352 (55%)] Loss: -192686.140625\n",
      "Train Epoch: 58 [9600/17352 (55%)] Loss: -210789.062500\n",
      "Train Epoch: 58 [9680/17352 (56%)] Loss: -184950.796875\n",
      "Train Epoch: 58 [9760/17352 (56%)] Loss: -171319.812500\n",
      "Train Epoch: 58 [9840/17352 (57%)] Loss: -197345.828125\n",
      "Train Epoch: 58 [9920/17352 (57%)] Loss: -168763.515625\n",
      "Train Epoch: 58 [10000/17352 (58%)] Loss: -200172.687500\n",
      "Train Epoch: 58 [10080/17352 (58%)] Loss: -206091.906250\n",
      "Train Epoch: 58 [10160/17352 (59%)] Loss: -189510.765625\n",
      "Train Epoch: 58 [10240/17352 (59%)] Loss: -174642.015625\n",
      "Train Epoch: 58 [10320/17352 (59%)] Loss: -217621.921875\n",
      "Train Epoch: 58 [10400/17352 (60%)] Loss: -182739.859375\n",
      "Train Epoch: 58 [10480/17352 (60%)] Loss: -178131.531250\n",
      "Train Epoch: 58 [10560/17352 (61%)] Loss: -185317.000000\n",
      "Train Epoch: 58 [10640/17352 (61%)] Loss: -201096.265625\n",
      "Train Epoch: 58 [10720/17352 (62%)] Loss: -165363.312500\n",
      "Train Epoch: 58 [10800/17352 (62%)] Loss: -193505.500000\n",
      "Train Epoch: 58 [10880/17352 (63%)] Loss: -191834.921875\n",
      "Train Epoch: 58 [10960/17352 (63%)] Loss: -175207.718750\n",
      "Train Epoch: 58 [11040/17352 (64%)] Loss: -205021.437500\n",
      "Train Epoch: 58 [11120/17352 (64%)] Loss: -184837.187500\n",
      "Train Epoch: 58 [11200/17352 (65%)] Loss: -190995.968750\n",
      "Train Epoch: 58 [11280/17352 (65%)] Loss: -162711.343750\n",
      "Train Epoch: 58 [11360/17352 (65%)] Loss: -200327.031250\n",
      "Train Epoch: 58 [11440/17352 (66%)] Loss: -185051.609375\n",
      "Train Epoch: 58 [11520/17352 (66%)] Loss: -193173.828125\n",
      "Train Epoch: 58 [11600/17352 (67%)] Loss: -164832.046875\n",
      "Train Epoch: 58 [11680/17352 (67%)] Loss: -228248.687500\n",
      "Train Epoch: 58 [11760/17352 (68%)] Loss: -151508.078125\n",
      "Train Epoch: 58 [11840/17352 (68%)] Loss: -187771.515625\n",
      "Train Epoch: 58 [11920/17352 (69%)] Loss: -196248.234375\n",
      "Train Epoch: 58 [12000/17352 (69%)] Loss: -197380.046875\n",
      "Train Epoch: 58 [12080/17352 (70%)] Loss: -196193.062500\n",
      "Train Epoch: 58 [12160/17352 (70%)] Loss: -193370.250000\n",
      "Train Epoch: 58 [12240/17352 (71%)] Loss: -164367.406250\n",
      "Train Epoch: 58 [12320/17352 (71%)] Loss: -172964.718750\n",
      "Train Epoch: 58 [12400/17352 (71%)] Loss: -171542.140625\n",
      "Train Epoch: 58 [12480/17352 (72%)] Loss: -197436.843750\n",
      "Train Epoch: 58 [12560/17352 (72%)] Loss: -177306.109375\n",
      "Train Epoch: 58 [12640/17352 (73%)] Loss: -180314.937500\n",
      "Train Epoch: 58 [12720/17352 (73%)] Loss: -181011.937500\n",
      "Train Epoch: 58 [12800/17352 (74%)] Loss: -178826.781250\n",
      "Train Epoch: 58 [12880/17352 (74%)] Loss: -173671.671875\n",
      "Train Epoch: 58 [12960/17352 (75%)] Loss: -159694.718750\n",
      "Train Epoch: 58 [13040/17352 (75%)] Loss: -173924.406250\n",
      "Train Epoch: 58 [13120/17352 (76%)] Loss: -183867.484375\n",
      "Train Epoch: 58 [13200/17352 (76%)] Loss: -184820.171875\n",
      "Train Epoch: 58 [13280/17352 (77%)] Loss: -149031.859375\n",
      "Train Epoch: 58 [13360/17352 (77%)] Loss: -161682.968750\n",
      "Train Epoch: 58 [13440/17352 (77%)] Loss: -206598.625000\n",
      "Train Epoch: 58 [13520/17352 (78%)] Loss: -179019.015625\n",
      "Train Epoch: 58 [13600/17352 (78%)] Loss: -190224.109375\n",
      "Train Epoch: 58 [13680/17352 (79%)] Loss: -205004.062500\n",
      "Train Epoch: 58 [13760/17352 (79%)] Loss: -136430.703125\n",
      "Train Epoch: 58 [13840/17352 (80%)] Loss: -213906.578125\n",
      "Train Epoch: 58 [13920/17352 (80%)] Loss: -192227.109375\n",
      "Train Epoch: 58 [14000/17352 (81%)] Loss: -174930.093750\n",
      "Train Epoch: 58 [14080/17352 (81%)] Loss: -177308.890625\n",
      "Train Epoch: 58 [14160/17352 (82%)] Loss: -202988.609375\n",
      "Train Epoch: 58 [14240/17352 (82%)] Loss: -199717.750000\n",
      "Train Epoch: 58 [14320/17352 (83%)] Loss: -168077.765625\n",
      "Train Epoch: 58 [14400/17352 (83%)] Loss: -152731.843750\n",
      "Train Epoch: 58 [14480/17352 (83%)] Loss: -164747.625000\n",
      "Train Epoch: 58 [14560/17352 (84%)] Loss: -187218.609375\n",
      "Train Epoch: 58 [14640/17352 (84%)] Loss: -204492.062500\n",
      "Train Epoch: 58 [14720/17352 (85%)] Loss: -198000.812500\n",
      "Train Epoch: 58 [14800/17352 (85%)] Loss: -181329.828125\n",
      "Train Epoch: 58 [14880/17352 (86%)] Loss: -191966.671875\n",
      "Train Epoch: 58 [14960/17352 (86%)] Loss: -191592.390625\n",
      "Train Epoch: 58 [15040/17352 (87%)] Loss: -175074.843750\n",
      "Train Epoch: 58 [15120/17352 (87%)] Loss: -176035.484375\n",
      "Train Epoch: 58 [15200/17352 (88%)] Loss: -207087.828125\n",
      "Train Epoch: 58 [15280/17352 (88%)] Loss: -169447.093750\n",
      "Train Epoch: 58 [15360/17352 (89%)] Loss: -195650.953125\n",
      "Train Epoch: 58 [15440/17352 (89%)] Loss: -189560.562500\n",
      "Train Epoch: 58 [15520/17352 (89%)] Loss: -192001.562500\n",
      "Train Epoch: 58 [15600/17352 (90%)] Loss: -166509.109375\n",
      "Train Epoch: 58 [15680/17352 (90%)] Loss: -183282.390625\n",
      "Train Epoch: 58 [15760/17352 (91%)] Loss: -183609.250000\n",
      "Train Epoch: 58 [15840/17352 (91%)] Loss: -170762.046875\n",
      "Train Epoch: 58 [15920/17352 (92%)] Loss: -174140.906250\n",
      "Train Epoch: 58 [16000/17352 (92%)] Loss: -180802.562500\n",
      "Train Epoch: 58 [16080/17352 (93%)] Loss: -205401.281250\n",
      "Train Epoch: 58 [16160/17352 (93%)] Loss: -178373.078125\n",
      "Train Epoch: 58 [16240/17352 (94%)] Loss: -214956.515625\n",
      "Train Epoch: 58 [16320/17352 (94%)] Loss: -185579.171875\n",
      "Train Epoch: 58 [16400/17352 (95%)] Loss: -183763.312500\n",
      "Train Epoch: 58 [16480/17352 (95%)] Loss: -206358.343750\n",
      "Train Epoch: 58 [16560/17352 (95%)] Loss: -193198.343750\n",
      "Train Epoch: 58 [16640/17352 (96%)] Loss: -211632.984375\n",
      "Train Epoch: 58 [16720/17352 (96%)] Loss: -221252.625000\n",
      "Train Epoch: 58 [16800/17352 (97%)] Loss: -176897.953125\n",
      "Train Epoch: 58 [16880/17352 (97%)] Loss: -181162.890625\n",
      "Train Epoch: 58 [16960/17352 (98%)] Loss: -131046.093750\n",
      "Train Epoch: 58 [17040/17352 (98%)] Loss: -208727.140625\n",
      "Train Epoch: 58 [17120/17352 (99%)] Loss: -166791.203125\n",
      "Train Epoch: 58 [17200/17352 (99%)] Loss: -202601.718750\n",
      "Train Epoch: 58 [17280/17352 (100%)] Loss: -174725.875000\n",
      "Train Epoch: 58 [17360/17352 (100%)] Loss: -197599.406250\n",
      "    epoch          : 58\n",
      "    loss           : -189309.65698719793\n",
      "    val_loss       : -23715.956645410384\n",
      "Train Epoch: 59 [0/17352 (0%)] Loss: -204734.062500\n",
      "Train Epoch: 59 [80/17352 (0%)] Loss: -206141.921875\n",
      "Train Epoch: 59 [160/17352 (1%)] Loss: -205102.062500\n",
      "Train Epoch: 59 [240/17352 (1%)] Loss: -202228.625000\n",
      "Train Epoch: 59 [320/17352 (2%)] Loss: -206567.156250\n",
      "Train Epoch: 59 [400/17352 (2%)] Loss: -224251.562500\n",
      "Train Epoch: 59 [480/17352 (3%)] Loss: -210754.421875\n",
      "Train Epoch: 59 [560/17352 (3%)] Loss: -204529.625000\n",
      "Train Epoch: 59 [640/17352 (4%)] Loss: -217936.562500\n",
      "Train Epoch: 59 [720/17352 (4%)] Loss: -229237.296875\n",
      "Train Epoch: 59 [800/17352 (5%)] Loss: -210521.468750\n",
      "Train Epoch: 59 [880/17352 (5%)] Loss: -215097.625000\n",
      "Train Epoch: 59 [960/17352 (6%)] Loss: -236634.812500\n",
      "Train Epoch: 59 [1040/17352 (6%)] Loss: -205555.687500\n",
      "Train Epoch: 59 [1120/17352 (6%)] Loss: -210342.859375\n",
      "Train Epoch: 59 [1200/17352 (7%)] Loss: -209779.359375\n",
      "Train Epoch: 59 [1280/17352 (7%)] Loss: -207165.015625\n",
      "Train Epoch: 59 [1360/17352 (8%)] Loss: -203740.375000\n",
      "Train Epoch: 59 [1440/17352 (8%)] Loss: -185292.968750\n",
      "Train Epoch: 59 [1520/17352 (9%)] Loss: -205198.937500\n",
      "Train Epoch: 59 [1600/17352 (9%)] Loss: -212188.531250\n",
      "Train Epoch: 59 [1680/17352 (10%)] Loss: -217590.140625\n",
      "Train Epoch: 59 [1760/17352 (10%)] Loss: -213824.656250\n",
      "Train Epoch: 59 [1840/17352 (11%)] Loss: -219200.640625\n",
      "Train Epoch: 59 [1920/17352 (11%)] Loss: -209557.156250\n",
      "Train Epoch: 59 [2000/17352 (12%)] Loss: -194491.062500\n",
      "Train Epoch: 59 [2080/17352 (12%)] Loss: -203274.531250\n",
      "Train Epoch: 59 [2160/17352 (12%)] Loss: -210206.359375\n",
      "Train Epoch: 59 [2240/17352 (13%)] Loss: -200120.906250\n",
      "Train Epoch: 59 [2320/17352 (13%)] Loss: -190005.671875\n",
      "Train Epoch: 59 [2400/17352 (14%)] Loss: -203811.406250\n",
      "Train Epoch: 59 [2480/17352 (14%)] Loss: -184839.562500\n",
      "Train Epoch: 59 [2560/17352 (15%)] Loss: -191050.734375\n",
      "Train Epoch: 59 [2640/17352 (15%)] Loss: -203751.984375\n",
      "Train Epoch: 59 [2720/17352 (16%)] Loss: -195289.578125\n",
      "Train Epoch: 59 [2800/17352 (16%)] Loss: -161093.921875\n",
      "Train Epoch: 59 [2880/17352 (17%)] Loss: -212139.218750\n",
      "Train Epoch: 59 [2960/17352 (17%)] Loss: -183616.687500\n",
      "Train Epoch: 59 [3040/17352 (18%)] Loss: -189216.781250\n",
      "Train Epoch: 59 [3120/17352 (18%)] Loss: -182742.515625\n",
      "Train Epoch: 59 [3200/17352 (18%)] Loss: -196700.453125\n",
      "Train Epoch: 59 [3280/17352 (19%)] Loss: -149443.062500\n",
      "Train Epoch: 59 [3360/17352 (19%)] Loss: -204613.703125\n",
      "Train Epoch: 59 [3440/17352 (20%)] Loss: -186551.640625\n",
      "Train Epoch: 59 [3520/17352 (20%)] Loss: -181256.375000\n",
      "Train Epoch: 59 [3600/17352 (21%)] Loss: -168079.015625\n",
      "Train Epoch: 59 [3680/17352 (21%)] Loss: -185266.765625\n",
      "Train Epoch: 59 [3760/17352 (22%)] Loss: -165869.921875\n",
      "Train Epoch: 59 [3840/17352 (22%)] Loss: -190807.343750\n",
      "Train Epoch: 59 [3920/17352 (23%)] Loss: -181336.250000\n",
      "Train Epoch: 59 [4000/17352 (23%)] Loss: -169504.906250\n",
      "Train Epoch: 59 [4080/17352 (24%)] Loss: -200169.171875\n",
      "Train Epoch: 59 [4160/17352 (24%)] Loss: -201526.953125\n",
      "Train Epoch: 59 [4240/17352 (24%)] Loss: -177144.562500\n",
      "Train Epoch: 59 [4320/17352 (25%)] Loss: -215182.671875\n",
      "Train Epoch: 59 [4400/17352 (25%)] Loss: -181917.234375\n",
      "Train Epoch: 59 [4480/17352 (26%)] Loss: -162713.234375\n",
      "Train Epoch: 59 [4560/17352 (26%)] Loss: -198018.265625\n",
      "Train Epoch: 59 [4640/17352 (27%)] Loss: -175685.296875\n",
      "Train Epoch: 59 [4720/17352 (27%)] Loss: -189609.890625\n",
      "Train Epoch: 59 [4800/17352 (28%)] Loss: -171716.593750\n",
      "Train Epoch: 59 [4880/17352 (28%)] Loss: -166025.625000\n",
      "Train Epoch: 59 [4960/17352 (29%)] Loss: -202170.218750\n",
      "Train Epoch: 59 [5040/17352 (29%)] Loss: -197076.015625\n",
      "Train Epoch: 59 [5120/17352 (30%)] Loss: -171310.625000\n",
      "Train Epoch: 59 [5200/17352 (30%)] Loss: -184752.234375\n",
      "Train Epoch: 59 [5280/17352 (30%)] Loss: -183465.484375\n",
      "Train Epoch: 59 [5360/17352 (31%)] Loss: -218403.203125\n",
      "Train Epoch: 59 [5440/17352 (31%)] Loss: -172195.781250\n",
      "Train Epoch: 59 [5520/17352 (32%)] Loss: -166515.875000\n",
      "Train Epoch: 59 [5600/17352 (32%)] Loss: -196562.984375\n",
      "Train Epoch: 59 [5680/17352 (33%)] Loss: -176045.765625\n",
      "Train Epoch: 59 [5760/17352 (33%)] Loss: -185336.031250\n",
      "Train Epoch: 59 [5840/17352 (34%)] Loss: -171892.875000\n",
      "Train Epoch: 59 [5920/17352 (34%)] Loss: -148397.750000\n",
      "Train Epoch: 59 [6000/17352 (35%)] Loss: -201256.953125\n",
      "Train Epoch: 59 [6080/17352 (35%)] Loss: -187321.140625\n",
      "Train Epoch: 59 [6160/17352 (36%)] Loss: -183166.265625\n",
      "Train Epoch: 59 [6240/17352 (36%)] Loss: -155864.781250\n",
      "Train Epoch: 59 [6320/17352 (36%)] Loss: -218749.171875\n",
      "Train Epoch: 59 [6400/17352 (37%)] Loss: -171186.046875\n",
      "Train Epoch: 59 [6480/17352 (37%)] Loss: -204344.390625\n",
      "Train Epoch: 59 [6560/17352 (38%)] Loss: -190919.468750\n",
      "Train Epoch: 59 [6640/17352 (38%)] Loss: -201972.796875\n",
      "Train Epoch: 59 [6720/17352 (39%)] Loss: -181721.718750\n",
      "Train Epoch: 59 [6800/17352 (39%)] Loss: -183225.406250\n",
      "Train Epoch: 59 [6880/17352 (40%)] Loss: -153317.468750\n",
      "Train Epoch: 59 [6960/17352 (40%)] Loss: -202570.734375\n",
      "Train Epoch: 59 [7040/17352 (41%)] Loss: -175201.437500\n",
      "Train Epoch: 59 [7120/17352 (41%)] Loss: -197598.468750\n",
      "Train Epoch: 59 [7200/17352 (41%)] Loss: -184477.937500\n",
      "Train Epoch: 59 [7280/17352 (42%)] Loss: -173301.421875\n",
      "Train Epoch: 59 [7360/17352 (42%)] Loss: -187310.125000\n",
      "Train Epoch: 59 [7440/17352 (43%)] Loss: -171836.406250\n",
      "Train Epoch: 59 [7520/17352 (43%)] Loss: -177471.859375\n",
      "Train Epoch: 59 [7600/17352 (44%)] Loss: -193193.078125\n",
      "Train Epoch: 59 [7680/17352 (44%)] Loss: -212615.390625\n",
      "Train Epoch: 59 [7760/17352 (45%)] Loss: -201383.421875\n",
      "Train Epoch: 59 [7840/17352 (45%)] Loss: -152748.828125\n",
      "Train Epoch: 59 [7920/17352 (46%)] Loss: -176483.187500\n",
      "Train Epoch: 59 [8000/17352 (46%)] Loss: -129698.031250\n",
      "Train Epoch: 59 [8080/17352 (47%)] Loss: -152901.703125\n",
      "Train Epoch: 59 [8160/17352 (47%)] Loss: -187206.562500\n",
      "Train Epoch: 59 [8240/17352 (47%)] Loss: -169976.140625\n",
      "Train Epoch: 59 [8320/17352 (48%)] Loss: -189487.765625\n",
      "Train Epoch: 59 [8400/17352 (48%)] Loss: -163968.453125\n",
      "Train Epoch: 59 [8480/17352 (49%)] Loss: -183593.390625\n",
      "Train Epoch: 59 [8560/17352 (49%)] Loss: -203139.593750\n",
      "Train Epoch: 59 [8640/17352 (50%)] Loss: -181011.765625\n",
      "Train Epoch: 59 [8720/17352 (50%)] Loss: -192862.375000\n",
      "Train Epoch: 59 [8800/17352 (51%)] Loss: -151509.765625\n",
      "Train Epoch: 59 [8880/17352 (51%)] Loss: -193917.843750\n",
      "Train Epoch: 59 [8960/17352 (52%)] Loss: -173841.765625\n",
      "Train Epoch: 59 [9040/17352 (52%)] Loss: -209273.218750\n",
      "Train Epoch: 59 [9120/17352 (53%)] Loss: -171848.250000\n",
      "Train Epoch: 59 [9200/17352 (53%)] Loss: -174638.265625\n",
      "Train Epoch: 59 [9280/17352 (53%)] Loss: -207862.406250\n",
      "Train Epoch: 59 [9360/17352 (54%)] Loss: -178313.296875\n",
      "Train Epoch: 59 [9440/17352 (54%)] Loss: -183505.531250\n",
      "Train Epoch: 59 [9520/17352 (55%)] Loss: -215645.187500\n",
      "Train Epoch: 59 [9600/17352 (55%)] Loss: -169613.140625\n",
      "Train Epoch: 59 [9680/17352 (56%)] Loss: -228094.734375\n",
      "Train Epoch: 59 [9760/17352 (56%)] Loss: -187506.375000\n",
      "Train Epoch: 59 [9840/17352 (57%)] Loss: -180547.375000\n",
      "Train Epoch: 59 [9920/17352 (57%)] Loss: -183754.343750\n",
      "Train Epoch: 59 [10000/17352 (58%)] Loss: -148158.593750\n",
      "Train Epoch: 59 [10080/17352 (58%)] Loss: -167211.250000\n",
      "Train Epoch: 59 [10160/17352 (59%)] Loss: -183287.765625\n",
      "Train Epoch: 59 [10240/17352 (59%)] Loss: -173375.312500\n",
      "Train Epoch: 59 [10320/17352 (59%)] Loss: -180751.625000\n",
      "Train Epoch: 59 [10400/17352 (60%)] Loss: -205812.953125\n",
      "Train Epoch: 59 [10480/17352 (60%)] Loss: -134538.968750\n",
      "Train Epoch: 59 [10560/17352 (61%)] Loss: -174976.781250\n",
      "Train Epoch: 59 [10640/17352 (61%)] Loss: -182399.343750\n",
      "Train Epoch: 59 [10720/17352 (62%)] Loss: -184603.468750\n",
      "Train Epoch: 59 [10800/17352 (62%)] Loss: -175505.953125\n",
      "Train Epoch: 59 [10880/17352 (63%)] Loss: -178869.531250\n",
      "Train Epoch: 59 [10960/17352 (63%)] Loss: -192641.750000\n",
      "Train Epoch: 59 [11040/17352 (64%)] Loss: -200832.734375\n",
      "Train Epoch: 59 [11120/17352 (64%)] Loss: -191955.203125\n",
      "Train Epoch: 59 [11200/17352 (65%)] Loss: -207830.515625\n",
      "Train Epoch: 59 [11280/17352 (65%)] Loss: -174448.890625\n",
      "Train Epoch: 59 [11360/17352 (65%)] Loss: -195379.187500\n",
      "Train Epoch: 59 [11440/17352 (66%)] Loss: -184174.953125\n",
      "Train Epoch: 59 [11520/17352 (66%)] Loss: -174030.734375\n",
      "Train Epoch: 59 [11600/17352 (67%)] Loss: -197525.328125\n",
      "Train Epoch: 59 [11680/17352 (67%)] Loss: -194061.140625\n",
      "Train Epoch: 59 [11760/17352 (68%)] Loss: -163548.500000\n",
      "Train Epoch: 59 [11840/17352 (68%)] Loss: -165678.265625\n",
      "Train Epoch: 59 [11920/17352 (69%)] Loss: -178322.906250\n",
      "Train Epoch: 59 [12000/17352 (69%)] Loss: -182744.468750\n",
      "Train Epoch: 59 [12080/17352 (70%)] Loss: -176150.781250\n",
      "Train Epoch: 59 [12160/17352 (70%)] Loss: -193508.921875\n",
      "Train Epoch: 59 [12240/17352 (71%)] Loss: -95257.523438\n",
      "Train Epoch: 59 [12320/17352 (71%)] Loss: -200199.218750\n",
      "Train Epoch: 59 [12400/17352 (71%)] Loss: -207123.781250\n",
      "Train Epoch: 59 [12480/17352 (72%)] Loss: -175421.093750\n",
      "Train Epoch: 59 [12560/17352 (72%)] Loss: -193044.859375\n",
      "Train Epoch: 59 [12640/17352 (73%)] Loss: -209418.515625\n",
      "Train Epoch: 59 [12720/17352 (73%)] Loss: -147417.171875\n",
      "Train Epoch: 59 [12800/17352 (74%)] Loss: -183385.828125\n",
      "Train Epoch: 59 [12880/17352 (74%)] Loss: -200842.765625\n",
      "Train Epoch: 59 [12960/17352 (75%)] Loss: -186684.406250\n",
      "Train Epoch: 59 [13040/17352 (75%)] Loss: -180052.546875\n",
      "Train Epoch: 59 [13120/17352 (76%)] Loss: -200622.296875\n",
      "Train Epoch: 59 [13200/17352 (76%)] Loss: -164074.828125\n",
      "Train Epoch: 59 [13280/17352 (77%)] Loss: -191677.656250\n",
      "Train Epoch: 59 [13360/17352 (77%)] Loss: -176056.609375\n",
      "Train Epoch: 59 [13440/17352 (77%)] Loss: -208727.109375\n",
      "Train Epoch: 59 [13520/17352 (78%)] Loss: -169752.406250\n",
      "Train Epoch: 59 [13600/17352 (78%)] Loss: -202524.046875\n",
      "Train Epoch: 59 [13680/17352 (79%)] Loss: -190482.890625\n",
      "Train Epoch: 59 [13760/17352 (79%)] Loss: -219926.218750\n",
      "Train Epoch: 59 [13840/17352 (80%)] Loss: -167956.109375\n",
      "Train Epoch: 59 [13920/17352 (80%)] Loss: -192175.703125\n",
      "Train Epoch: 59 [14000/17352 (81%)] Loss: -167300.171875\n",
      "Train Epoch: 59 [14080/17352 (81%)] Loss: -205172.625000\n",
      "Train Epoch: 59 [14160/17352 (82%)] Loss: -170681.578125\n",
      "Train Epoch: 59 [14240/17352 (82%)] Loss: -208334.906250\n",
      "Train Epoch: 59 [14320/17352 (83%)] Loss: -189534.234375\n",
      "Train Epoch: 59 [14400/17352 (83%)] Loss: -197955.031250\n",
      "Train Epoch: 59 [14480/17352 (83%)] Loss: -208039.343750\n",
      "Train Epoch: 59 [14560/17352 (84%)] Loss: -187527.765625\n",
      "Train Epoch: 59 [14640/17352 (84%)] Loss: -187316.515625\n",
      "Train Epoch: 59 [14720/17352 (85%)] Loss: -208123.046875\n",
      "Train Epoch: 59 [14800/17352 (85%)] Loss: -159688.187500\n",
      "Train Epoch: 59 [14880/17352 (86%)] Loss: -174627.859375\n",
      "Train Epoch: 59 [14960/17352 (86%)] Loss: -203435.187500\n",
      "Train Epoch: 59 [15040/17352 (87%)] Loss: -181891.640625\n",
      "Train Epoch: 59 [15120/17352 (87%)] Loss: -183925.062500\n",
      "Train Epoch: 59 [15200/17352 (88%)] Loss: -204664.250000\n",
      "Train Epoch: 59 [15280/17352 (88%)] Loss: -185789.562500\n",
      "Train Epoch: 59 [15360/17352 (89%)] Loss: -187130.546875\n",
      "Train Epoch: 59 [15440/17352 (89%)] Loss: -190617.953125\n",
      "Train Epoch: 59 [15520/17352 (89%)] Loss: -204216.375000\n",
      "Train Epoch: 59 [15600/17352 (90%)] Loss: -189294.156250\n",
      "Train Epoch: 59 [15680/17352 (90%)] Loss: -199011.562500\n",
      "Train Epoch: 59 [15760/17352 (91%)] Loss: -215959.625000\n",
      "Train Epoch: 59 [15840/17352 (91%)] Loss: -165388.828125\n",
      "Train Epoch: 59 [15920/17352 (92%)] Loss: -197649.796875\n",
      "Train Epoch: 59 [16000/17352 (92%)] Loss: -165732.812500\n",
      "Train Epoch: 59 [16080/17352 (93%)] Loss: -191886.984375\n",
      "Train Epoch: 59 [16160/17352 (93%)] Loss: -188681.234375\n",
      "Train Epoch: 59 [16240/17352 (94%)] Loss: -198313.125000\n",
      "Train Epoch: 59 [16320/17352 (94%)] Loss: -208905.921875\n",
      "Train Epoch: 59 [16400/17352 (95%)] Loss: -199722.890625\n",
      "Train Epoch: 59 [16480/17352 (95%)] Loss: -164074.656250\n",
      "Train Epoch: 59 [16560/17352 (95%)] Loss: -176702.281250\n",
      "Train Epoch: 59 [16640/17352 (96%)] Loss: -180839.140625\n",
      "Train Epoch: 59 [16720/17352 (96%)] Loss: -154600.546875\n",
      "Train Epoch: 59 [16800/17352 (97%)] Loss: -218523.609375\n",
      "Train Epoch: 59 [16880/17352 (97%)] Loss: -204496.312500\n",
      "Train Epoch: 59 [16960/17352 (98%)] Loss: -168672.859375\n",
      "Train Epoch: 59 [17040/17352 (98%)] Loss: -189165.953125\n",
      "Train Epoch: 59 [17120/17352 (99%)] Loss: -176964.218750\n",
      "Train Epoch: 59 [17200/17352 (99%)] Loss: -182766.781250\n",
      "Train Epoch: 59 [17280/17352 (100%)] Loss: -173127.218750\n",
      "Train Epoch: 59 [17360/17352 (100%)] Loss: -196864.093750\n",
      "    epoch          : 59\n",
      "    loss           : -189187.76218174625\n",
      "    val_loss       : -23715.93405215841\n",
      "Train Epoch: 60 [0/17352 (0%)] Loss: -191879.406250\n",
      "Train Epoch: 60 [80/17352 (0%)] Loss: -213826.546875\n",
      "Train Epoch: 60 [160/17352 (1%)] Loss: -204404.500000\n",
      "Train Epoch: 60 [240/17352 (1%)] Loss: -212374.296875\n",
      "Train Epoch: 60 [320/17352 (2%)] Loss: -207166.109375\n",
      "Train Epoch: 60 [400/17352 (2%)] Loss: -214417.187500\n",
      "Train Epoch: 60 [480/17352 (3%)] Loss: -210528.906250\n",
      "Train Epoch: 60 [560/17352 (3%)] Loss: -212703.343750\n",
      "Train Epoch: 60 [640/17352 (4%)] Loss: -218563.468750\n",
      "Train Epoch: 60 [720/17352 (4%)] Loss: -199533.203125\n",
      "Train Epoch: 60 [800/17352 (5%)] Loss: -219193.609375\n",
      "Train Epoch: 60 [880/17352 (5%)] Loss: -206639.500000\n",
      "Train Epoch: 60 [960/17352 (6%)] Loss: -202231.718750\n",
      "Train Epoch: 60 [1040/17352 (6%)] Loss: -193023.640625\n",
      "Train Epoch: 60 [1120/17352 (6%)] Loss: -204361.390625\n",
      "Train Epoch: 60 [1200/17352 (7%)] Loss: -202029.734375\n",
      "Train Epoch: 60 [1280/17352 (7%)] Loss: -215096.750000\n",
      "Train Epoch: 60 [1360/17352 (8%)] Loss: -224249.359375\n",
      "Train Epoch: 60 [1440/17352 (8%)] Loss: -224253.078125\n",
      "Train Epoch: 60 [1520/17352 (9%)] Loss: -206789.296875\n",
      "Train Epoch: 60 [1600/17352 (9%)] Loss: -215824.578125\n",
      "Train Epoch: 60 [1680/17352 (10%)] Loss: -217940.109375\n",
      "Train Epoch: 60 [1760/17352 (10%)] Loss: -211097.968750\n",
      "Train Epoch: 60 [1840/17352 (11%)] Loss: -210354.015625\n",
      "Train Epoch: 60 [1920/17352 (11%)] Loss: -222513.406250\n",
      "Train Epoch: 60 [2000/17352 (12%)] Loss: -221473.765625\n",
      "Train Epoch: 60 [2080/17352 (12%)] Loss: -230188.312500\n",
      "Train Epoch: 60 [2160/17352 (12%)] Loss: -187719.234375\n",
      "Train Epoch: 60 [2240/17352 (13%)] Loss: -217606.125000\n",
      "Train Epoch: 60 [2320/17352 (13%)] Loss: -199175.625000\n",
      "Train Epoch: 60 [2400/17352 (14%)] Loss: -204366.406250\n",
      "Train Epoch: 60 [2480/17352 (14%)] Loss: -186515.765625\n",
      "Train Epoch: 60 [2560/17352 (15%)] Loss: -178731.390625\n",
      "Train Epoch: 60 [2640/17352 (15%)] Loss: -197568.468750\n",
      "Train Epoch: 60 [2720/17352 (16%)] Loss: -159668.187500\n",
      "Train Epoch: 60 [2800/17352 (16%)] Loss: -176592.234375\n",
      "Train Epoch: 60 [2880/17352 (17%)] Loss: -189598.796875\n",
      "Train Epoch: 60 [2960/17352 (17%)] Loss: -177167.453125\n",
      "Train Epoch: 60 [3040/17352 (18%)] Loss: -193347.250000\n",
      "Train Epoch: 60 [3120/17352 (18%)] Loss: -199891.062500\n",
      "Train Epoch: 60 [3200/17352 (18%)] Loss: -197646.125000\n",
      "Train Epoch: 60 [3280/17352 (19%)] Loss: -180695.921875\n",
      "Train Epoch: 60 [3360/17352 (19%)] Loss: -170539.843750\n",
      "Train Epoch: 60 [3440/17352 (20%)] Loss: -174481.578125\n",
      "Train Epoch: 60 [3520/17352 (20%)] Loss: -191328.406250\n",
      "Train Epoch: 60 [3600/17352 (21%)] Loss: -180763.734375\n",
      "Train Epoch: 60 [3680/17352 (21%)] Loss: -205726.906250\n",
      "Train Epoch: 60 [3760/17352 (22%)] Loss: -184028.765625\n",
      "Train Epoch: 60 [3840/17352 (22%)] Loss: -196567.234375\n",
      "Train Epoch: 60 [3920/17352 (23%)] Loss: -175315.703125\n",
      "Train Epoch: 60 [4000/17352 (23%)] Loss: -197999.531250\n",
      "Train Epoch: 60 [4080/17352 (24%)] Loss: -192883.375000\n",
      "Train Epoch: 60 [4160/17352 (24%)] Loss: -184963.687500\n",
      "Train Epoch: 60 [4240/17352 (24%)] Loss: -181744.968750\n",
      "Train Epoch: 60 [4320/17352 (25%)] Loss: -164508.250000\n",
      "Train Epoch: 60 [4400/17352 (25%)] Loss: -175010.953125\n",
      "Train Epoch: 60 [4480/17352 (26%)] Loss: -188429.218750\n",
      "Train Epoch: 60 [4560/17352 (26%)] Loss: -203145.312500\n",
      "Train Epoch: 60 [4640/17352 (27%)] Loss: -180541.500000\n",
      "Train Epoch: 60 [4720/17352 (27%)] Loss: -195058.000000\n",
      "Train Epoch: 60 [4800/17352 (28%)] Loss: -207089.078125\n",
      "Train Epoch: 60 [4880/17352 (28%)] Loss: -166518.421875\n",
      "Train Epoch: 60 [4960/17352 (29%)] Loss: -158602.843750\n",
      "Train Epoch: 60 [5040/17352 (29%)] Loss: -210486.140625\n",
      "Train Epoch: 60 [5120/17352 (30%)] Loss: -176084.562500\n",
      "Train Epoch: 60 [5200/17352 (30%)] Loss: -188675.687500\n",
      "Train Epoch: 60 [5280/17352 (30%)] Loss: -178430.906250\n",
      "Train Epoch: 60 [5360/17352 (31%)] Loss: -192640.875000\n",
      "Train Epoch: 60 [5440/17352 (31%)] Loss: -163489.984375\n",
      "Train Epoch: 60 [5520/17352 (32%)] Loss: -167241.656250\n",
      "Train Epoch: 60 [5600/17352 (32%)] Loss: -196511.531250\n",
      "Train Epoch: 60 [5680/17352 (33%)] Loss: -178198.390625\n",
      "Train Epoch: 60 [5760/17352 (33%)] Loss: -185826.765625\n",
      "Train Epoch: 60 [5840/17352 (34%)] Loss: -187400.093750\n",
      "Train Epoch: 60 [5920/17352 (34%)] Loss: -162557.828125\n",
      "Train Epoch: 60 [6000/17352 (35%)] Loss: -201973.484375\n",
      "Train Epoch: 60 [6080/17352 (35%)] Loss: -182395.609375\n",
      "Train Epoch: 60 [6160/17352 (36%)] Loss: -194587.187500\n",
      "Train Epoch: 60 [6240/17352 (36%)] Loss: -147420.000000\n",
      "Train Epoch: 60 [6320/17352 (36%)] Loss: -179728.093750\n",
      "Train Epoch: 60 [6400/17352 (37%)] Loss: -175075.296875\n",
      "Train Epoch: 60 [6480/17352 (37%)] Loss: -178569.765625\n",
      "Train Epoch: 60 [6560/17352 (38%)] Loss: -214679.078125\n",
      "Train Epoch: 60 [6640/17352 (38%)] Loss: -175503.531250\n",
      "Train Epoch: 60 [6720/17352 (39%)] Loss: -185401.734375\n",
      "Train Epoch: 60 [6800/17352 (39%)] Loss: -189795.859375\n",
      "Train Epoch: 60 [6880/17352 (40%)] Loss: -196300.093750\n",
      "Train Epoch: 60 [6960/17352 (40%)] Loss: -197596.687500\n",
      "Train Epoch: 60 [7040/17352 (41%)] Loss: -193444.171875\n",
      "Train Epoch: 60 [7120/17352 (41%)] Loss: -187773.984375\n",
      "Train Epoch: 60 [7200/17352 (41%)] Loss: -183725.437500\n",
      "Train Epoch: 60 [7280/17352 (42%)] Loss: -170102.765625\n",
      "Train Epoch: 60 [7360/17352 (42%)] Loss: -155872.546875\n",
      "Train Epoch: 60 [7440/17352 (43%)] Loss: -174187.937500\n",
      "Train Epoch: 60 [7520/17352 (43%)] Loss: -184457.031250\n",
      "Train Epoch: 60 [7600/17352 (44%)] Loss: -160146.609375\n",
      "Train Epoch: 60 [7680/17352 (44%)] Loss: -205527.406250\n",
      "Train Epoch: 60 [7760/17352 (45%)] Loss: -179007.484375\n",
      "Train Epoch: 60 [7840/17352 (45%)] Loss: -189402.640625\n",
      "Train Epoch: 60 [7920/17352 (46%)] Loss: -203274.187500\n",
      "Train Epoch: 60 [8000/17352 (46%)] Loss: -198296.484375\n",
      "Train Epoch: 60 [8080/17352 (47%)] Loss: -209506.125000\n",
      "Train Epoch: 60 [8160/17352 (47%)] Loss: -196737.906250\n",
      "Train Epoch: 60 [8240/17352 (47%)] Loss: -173510.437500\n",
      "Train Epoch: 60 [8320/17352 (48%)] Loss: -173030.484375\n",
      "Train Epoch: 60 [8400/17352 (48%)] Loss: -161961.625000\n",
      "Train Epoch: 60 [8480/17352 (49%)] Loss: -157589.453125\n",
      "Train Epoch: 60 [8560/17352 (49%)] Loss: -199005.906250\n",
      "Train Epoch: 60 [8640/17352 (50%)] Loss: -188805.671875\n",
      "Train Epoch: 60 [8720/17352 (50%)] Loss: -195831.125000\n",
      "Train Epoch: 60 [8800/17352 (51%)] Loss: -220971.500000\n",
      "Train Epoch: 60 [8880/17352 (51%)] Loss: -181973.890625\n",
      "Train Epoch: 60 [8960/17352 (52%)] Loss: -207834.750000\n",
      "Train Epoch: 60 [9040/17352 (52%)] Loss: -179683.656250\n",
      "Train Epoch: 60 [9120/17352 (53%)] Loss: -209582.406250\n",
      "Train Epoch: 60 [9200/17352 (53%)] Loss: -192246.453125\n",
      "Train Epoch: 60 [9280/17352 (53%)] Loss: -172550.750000\n",
      "Train Epoch: 60 [9360/17352 (54%)] Loss: -183805.515625\n",
      "Train Epoch: 60 [9440/17352 (54%)] Loss: -181372.484375\n",
      "Train Epoch: 60 [9520/17352 (55%)] Loss: -188209.968750\n",
      "Train Epoch: 60 [9600/17352 (55%)] Loss: -160094.906250\n",
      "Train Epoch: 60 [9680/17352 (56%)] Loss: -193182.578125\n",
      "Train Epoch: 60 [9760/17352 (56%)] Loss: -173932.687500\n",
      "Train Epoch: 60 [9840/17352 (57%)] Loss: -166653.437500\n",
      "Train Epoch: 60 [9920/17352 (57%)] Loss: -200071.453125\n",
      "Train Epoch: 60 [10000/17352 (58%)] Loss: -215632.734375\n",
      "Train Epoch: 60 [10080/17352 (58%)] Loss: -196038.250000\n",
      "Train Epoch: 60 [10160/17352 (59%)] Loss: -177302.468750\n",
      "Train Epoch: 60 [10240/17352 (59%)] Loss: -188755.031250\n",
      "Train Epoch: 60 [10320/17352 (59%)] Loss: -207857.234375\n",
      "Train Epoch: 60 [10400/17352 (60%)] Loss: -195517.281250\n",
      "Train Epoch: 60 [10480/17352 (60%)] Loss: -204996.531250\n",
      "Train Epoch: 60 [10560/17352 (61%)] Loss: -169621.640625\n",
      "Train Epoch: 60 [10640/17352 (61%)] Loss: -181921.531250\n",
      "Train Epoch: 60 [10720/17352 (62%)] Loss: -177275.437500\n",
      "Train Epoch: 60 [10800/17352 (62%)] Loss: -210562.343750\n",
      "Train Epoch: 60 [10880/17352 (63%)] Loss: -174029.031250\n",
      "Train Epoch: 60 [10960/17352 (63%)] Loss: -184921.046875\n",
      "Train Epoch: 60 [11040/17352 (64%)] Loss: -193531.125000\n",
      "Train Epoch: 60 [11120/17352 (64%)] Loss: -184066.421875\n",
      "Train Epoch: 60 [11200/17352 (65%)] Loss: -193263.343750\n",
      "Train Epoch: 60 [11280/17352 (65%)] Loss: -215463.406250\n",
      "Train Epoch: 60 [11360/17352 (65%)] Loss: -179461.187500\n",
      "Train Epoch: 60 [11440/17352 (66%)] Loss: -189538.062500\n",
      "Train Epoch: 60 [11520/17352 (66%)] Loss: -210779.765625\n",
      "Train Epoch: 60 [11600/17352 (67%)] Loss: -178871.812500\n",
      "Train Epoch: 60 [11680/17352 (67%)] Loss: -173438.984375\n",
      "Train Epoch: 60 [11760/17352 (68%)] Loss: -192287.203125\n",
      "Train Epoch: 60 [11840/17352 (68%)] Loss: -211724.562500\n",
      "Train Epoch: 60 [11920/17352 (69%)] Loss: -175367.234375\n",
      "Train Epoch: 60 [12000/17352 (69%)] Loss: -202789.765625\n",
      "Train Epoch: 60 [12080/17352 (70%)] Loss: -158254.359375\n",
      "Train Epoch: 60 [12160/17352 (70%)] Loss: -175547.468750\n",
      "Train Epoch: 60 [12240/17352 (71%)] Loss: -197380.484375\n",
      "Train Epoch: 60 [12320/17352 (71%)] Loss: -143619.968750\n",
      "Train Epoch: 60 [12400/17352 (71%)] Loss: -201385.937500\n",
      "Train Epoch: 60 [12480/17352 (72%)] Loss: -196813.750000\n",
      "Train Epoch: 60 [12560/17352 (72%)] Loss: -214645.859375\n",
      "Train Epoch: 60 [12640/17352 (73%)] Loss: -163965.515625\n",
      "Train Epoch: 60 [12720/17352 (73%)] Loss: -146858.406250\n",
      "Train Epoch: 60 [12800/17352 (74%)] Loss: -173665.140625\n",
      "Train Epoch: 60 [12880/17352 (74%)] Loss: -168999.546875\n",
      "Train Epoch: 60 [12960/17352 (75%)] Loss: -207788.781250\n",
      "Train Epoch: 60 [13040/17352 (75%)] Loss: -192125.375000\n",
      "Train Epoch: 60 [13120/17352 (76%)] Loss: -176704.937500\n",
      "Train Epoch: 60 [13200/17352 (76%)] Loss: -187789.500000\n",
      "Train Epoch: 60 [13280/17352 (77%)] Loss: -201829.296875\n",
      "Train Epoch: 60 [13360/17352 (77%)] Loss: -193046.359375\n",
      "Train Epoch: 60 [13440/17352 (77%)] Loss: -200196.390625\n",
      "Train Epoch: 60 [13520/17352 (78%)] Loss: -218516.078125\n",
      "Train Epoch: 60 [13600/17352 (78%)] Loss: -195644.562500\n",
      "Train Epoch: 60 [13680/17352 (79%)] Loss: -201933.000000\n",
      "Train Epoch: 60 [13760/17352 (79%)] Loss: -170037.484375\n",
      "Train Epoch: 60 [13840/17352 (80%)] Loss: -204602.468750\n",
      "Train Epoch: 60 [13920/17352 (80%)] Loss: -161511.343750\n",
      "Train Epoch: 60 [14000/17352 (81%)] Loss: -190796.140625\n",
      "Train Epoch: 60 [14080/17352 (81%)] Loss: -188489.750000\n",
      "Train Epoch: 60 [14160/17352 (82%)] Loss: -187359.296875\n",
      "Train Epoch: 60 [14240/17352 (82%)] Loss: -202189.531250\n",
      "Train Epoch: 60 [14320/17352 (83%)] Loss: -185269.265625\n",
      "Train Epoch: 60 [14400/17352 (83%)] Loss: -206235.062500\n",
      "Train Epoch: 60 [14480/17352 (83%)] Loss: -218754.796875\n",
      "Train Epoch: 60 [14560/17352 (84%)] Loss: -206205.703125\n",
      "Train Epoch: 60 [14640/17352 (84%)] Loss: -208806.078125\n",
      "Train Epoch: 60 [14720/17352 (85%)] Loss: -181616.328125\n",
      "Train Epoch: 60 [14800/17352 (85%)] Loss: -183759.984375\n",
      "Train Epoch: 60 [14880/17352 (86%)] Loss: -186774.703125\n",
      "Train Epoch: 60 [14960/17352 (86%)] Loss: -193129.281250\n",
      "Train Epoch: 60 [15040/17352 (87%)] Loss: -202020.109375\n",
      "Train Epoch: 60 [15120/17352 (87%)] Loss: -209198.421875\n",
      "Train Epoch: 60 [15200/17352 (88%)] Loss: -182742.296875\n",
      "Train Epoch: 60 [15280/17352 (88%)] Loss: -164369.859375\n",
      "Train Epoch: 60 [15360/17352 (89%)] Loss: -140588.234375\n",
      "Train Epoch: 60 [15440/17352 (89%)] Loss: -169974.203125\n",
      "Train Epoch: 60 [15520/17352 (89%)] Loss: -212986.031250\n",
      "Train Epoch: 60 [15600/17352 (90%)] Loss: -224862.562500\n",
      "Train Epoch: 60 [15680/17352 (90%)] Loss: -165732.343750\n",
      "Train Epoch: 60 [15760/17352 (91%)] Loss: -191042.984375\n",
      "Train Epoch: 60 [15840/17352 (91%)] Loss: -194067.421875\n",
      "Train Epoch: 60 [15920/17352 (92%)] Loss: -169175.890625\n",
      "Train Epoch: 60 [16000/17352 (92%)] Loss: -186851.250000\n",
      "Train Epoch: 60 [16080/17352 (93%)] Loss: -217620.718750\n",
      "Train Epoch: 60 [16160/17352 (93%)] Loss: -204952.187500\n",
      "Train Epoch: 60 [16240/17352 (94%)] Loss: -148509.625000\n",
      "Train Epoch: 60 [16320/17352 (94%)] Loss: -174632.171875\n",
      "Train Epoch: 60 [16400/17352 (95%)] Loss: -186556.296875\n",
      "Train Epoch: 60 [16480/17352 (95%)] Loss: -174976.500000\n",
      "Train Epoch: 60 [16560/17352 (95%)] Loss: -195376.265625\n",
      "Train Epoch: 60 [16640/17352 (96%)] Loss: -184756.359375\n",
      "Train Epoch: 60 [16720/17352 (96%)] Loss: -163755.281250\n",
      "Train Epoch: 60 [16800/17352 (97%)] Loss: -176965.859375\n",
      "Train Epoch: 60 [16880/17352 (97%)] Loss: -188566.453125\n",
      "Train Epoch: 60 [16960/17352 (98%)] Loss: -192120.000000\n",
      "Train Epoch: 60 [17040/17352 (98%)] Loss: -197301.531250\n",
      "Train Epoch: 60 [17120/17352 (99%)] Loss: -195057.843750\n",
      "Train Epoch: 60 [17200/17352 (99%)] Loss: -176282.859375\n",
      "Train Epoch: 60 [17280/17352 (100%)] Loss: -181541.234375\n",
      "Train Epoch: 60 [17360/17352 (100%)] Loss: -165728.500000\n",
      "    epoch          : 60\n",
      "    loss           : -189247.22138413406\n",
      "    val_loss       : -23715.98418559043\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch60.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 61 [0/17352 (0%)] Loss: -199928.484375\n",
      "Train Epoch: 61 [80/17352 (0%)] Loss: -187715.781250\n",
      "Train Epoch: 61 [160/17352 (1%)] Loss: -214338.187500\n",
      "Train Epoch: 61 [240/17352 (1%)] Loss: -218540.125000\n",
      "Train Epoch: 61 [320/17352 (2%)] Loss: -212704.234375\n",
      "Train Epoch: 61 [400/17352 (2%)] Loss: -216106.640625\n",
      "Train Epoch: 61 [480/17352 (3%)] Loss: -199907.843750\n",
      "Train Epoch: 61 [560/17352 (3%)] Loss: -212182.984375\n",
      "Train Epoch: 61 [640/17352 (4%)] Loss: -186075.421875\n",
      "Train Epoch: 61 [720/17352 (4%)] Loss: -214457.015625\n",
      "Train Epoch: 61 [800/17352 (5%)] Loss: -212390.265625\n",
      "Train Epoch: 61 [880/17352 (5%)] Loss: -193411.562500\n",
      "Train Epoch: 61 [960/17352 (6%)] Loss: -201661.000000\n",
      "Train Epoch: 61 [1040/17352 (6%)] Loss: -215482.625000\n",
      "Train Epoch: 61 [1120/17352 (6%)] Loss: -199106.953125\n",
      "Train Epoch: 61 [1200/17352 (7%)] Loss: -210351.500000\n",
      "Train Epoch: 61 [1280/17352 (7%)] Loss: -236509.015625\n",
      "Train Epoch: 61 [1360/17352 (8%)] Loss: -224356.156250\n",
      "Train Epoch: 61 [1440/17352 (8%)] Loss: -209636.343750\n",
      "Train Epoch: 61 [1520/17352 (9%)] Loss: -217629.750000\n",
      "Train Epoch: 61 [1600/17352 (9%)] Loss: -221773.531250\n",
      "Train Epoch: 61 [1680/17352 (10%)] Loss: -210206.187500\n",
      "Train Epoch: 61 [1760/17352 (10%)] Loss: -185155.281250\n",
      "Train Epoch: 61 [1840/17352 (11%)] Loss: -210520.812500\n",
      "Train Epoch: 61 [1920/17352 (11%)] Loss: -205198.562500\n",
      "Train Epoch: 61 [2000/17352 (12%)] Loss: -233735.687500\n",
      "Train Epoch: 61 [2080/17352 (12%)] Loss: -204533.390625\n",
      "Train Epoch: 61 [2160/17352 (12%)] Loss: -241916.343750\n",
      "Train Epoch: 61 [2240/17352 (13%)] Loss: -160049.500000\n",
      "Train Epoch: 61 [2320/17352 (13%)] Loss: -193362.078125\n",
      "Train Epoch: 61 [2400/17352 (14%)] Loss: -228094.843750\n",
      "Train Epoch: 61 [2480/17352 (14%)] Loss: -185436.234375\n",
      "Train Epoch: 61 [2560/17352 (15%)] Loss: -191632.187500\n",
      "Train Epoch: 61 [2640/17352 (15%)] Loss: -178804.078125\n",
      "Train Epoch: 61 [2720/17352 (16%)] Loss: -169947.828125\n",
      "Train Epoch: 61 [2800/17352 (16%)] Loss: -203807.953125\n",
      "Train Epoch: 61 [2880/17352 (17%)] Loss: -199787.843750\n",
      "Train Epoch: 61 [2960/17352 (17%)] Loss: -204688.031250\n",
      "Train Epoch: 61 [3040/17352 (18%)] Loss: -186685.140625\n",
      "Train Epoch: 61 [3120/17352 (18%)] Loss: -193174.359375\n",
      "Train Epoch: 61 [3200/17352 (18%)] Loss: -210393.703125\n",
      "Train Epoch: 61 [3280/17352 (19%)] Loss: -166551.437500\n",
      "Train Epoch: 61 [3360/17352 (19%)] Loss: -162563.031250\n",
      "Train Epoch: 61 [3440/17352 (20%)] Loss: -181754.312500\n",
      "Train Epoch: 61 [3520/17352 (20%)] Loss: -171181.406250\n",
      "Train Epoch: 61 [3600/17352 (21%)] Loss: -179972.109375\n",
      "Train Epoch: 61 [3680/17352 (21%)] Loss: -200166.421875\n",
      "Train Epoch: 61 [3760/17352 (22%)] Loss: -199143.625000\n",
      "Train Epoch: 61 [3840/17352 (22%)] Loss: -202518.437500\n",
      "Train Epoch: 61 [3920/17352 (23%)] Loss: -159752.984375\n",
      "Train Epoch: 61 [4000/17352 (23%)] Loss: -183165.515625\n",
      "Train Epoch: 61 [4080/17352 (24%)] Loss: -202784.687500\n",
      "Train Epoch: 61 [4160/17352 (24%)] Loss: -189018.578125\n",
      "Train Epoch: 61 [4240/17352 (24%)] Loss: -163105.765625\n",
      "Train Epoch: 61 [4320/17352 (25%)] Loss: -187358.031250\n",
      "Train Epoch: 61 [4400/17352 (25%)] Loss: -183771.609375\n",
      "Train Epoch: 61 [4480/17352 (26%)] Loss: -178734.718750\n",
      "Train Epoch: 61 [4560/17352 (26%)] Loss: -185171.109375\n",
      "Train Epoch: 61 [4640/17352 (27%)] Loss: -208306.765625\n",
      "Train Epoch: 61 [4720/17352 (27%)] Loss: -209196.093750\n",
      "Train Epoch: 61 [4800/17352 (28%)] Loss: -200202.984375\n",
      "Train Epoch: 61 [4880/17352 (28%)] Loss: -225476.906250\n",
      "Train Epoch: 61 [4960/17352 (29%)] Loss: -199898.046875\n",
      "Train Epoch: 61 [5040/17352 (29%)] Loss: -181981.500000\n",
      "Train Epoch: 61 [5120/17352 (30%)] Loss: -205695.359375\n",
      "Train Epoch: 61 [5200/17352 (30%)] Loss: -181622.390625\n",
      "Train Epoch: 61 [5280/17352 (30%)] Loss: -166411.296875\n",
      "Train Epoch: 61 [5360/17352 (31%)] Loss: -192171.468750\n",
      "Train Epoch: 61 [5440/17352 (31%)] Loss: -201364.296875\n",
      "Train Epoch: 61 [5520/17352 (32%)] Loss: -166654.921875\n",
      "Train Epoch: 61 [5600/17352 (32%)] Loss: -180915.515625\n",
      "Train Epoch: 61 [5680/17352 (33%)] Loss: -186157.921875\n",
      "Train Epoch: 61 [5760/17352 (33%)] Loss: -179305.031250\n",
      "Train Epoch: 61 [5840/17352 (34%)] Loss: -210548.437500\n",
      "Train Epoch: 61 [5920/17352 (34%)] Loss: -223688.218750\n",
      "Train Epoch: 61 [6000/17352 (35%)] Loss: -223958.468750\n",
      "Train Epoch: 61 [6080/17352 (35%)] Loss: -212618.906250\n",
      "Train Epoch: 61 [6160/17352 (36%)] Loss: -196287.453125\n",
      "Train Epoch: 61 [6240/17352 (36%)] Loss: -188516.000000\n",
      "Train Epoch: 61 [6320/17352 (36%)] Loss: -203876.437500\n",
      "Train Epoch: 61 [6400/17352 (37%)] Loss: -203487.265625\n",
      "Train Epoch: 61 [6480/17352 (37%)] Loss: -175406.515625\n",
      "Train Epoch: 61 [6560/17352 (38%)] Loss: -202237.359375\n",
      "Train Epoch: 61 [6640/17352 (38%)] Loss: -191890.125000\n",
      "Train Epoch: 61 [6720/17352 (39%)] Loss: -173663.125000\n",
      "Train Epoch: 61 [6800/17352 (39%)] Loss: -183918.343750\n",
      "Train Epoch: 61 [6880/17352 (40%)] Loss: -157487.625000\n",
      "Train Epoch: 61 [6960/17352 (40%)] Loss: -178378.390625\n",
      "Train Epoch: 61 [7040/17352 (41%)] Loss: -179744.390625\n",
      "Train Epoch: 61 [7120/17352 (41%)] Loss: -180692.562500\n",
      "Train Epoch: 61 [7200/17352 (41%)] Loss: -172553.218750\n",
      "Train Epoch: 61 [7280/17352 (42%)] Loss: -183786.593750\n",
      "Train Epoch: 61 [7360/17352 (42%)] Loss: -169502.734375\n",
      "Train Epoch: 61 [7440/17352 (43%)] Loss: -155867.156250\n",
      "Train Epoch: 61 [7520/17352 (43%)] Loss: -182733.921875\n",
      "Train Epoch: 61 [7600/17352 (44%)] Loss: -218515.578125\n",
      "Train Epoch: 61 [7680/17352 (44%)] Loss: -177786.062500\n",
      "Train Epoch: 61 [7760/17352 (45%)] Loss: -197315.718750\n",
      "Train Epoch: 61 [7840/17352 (45%)] Loss: -181540.312500\n",
      "Train Epoch: 61 [7920/17352 (46%)] Loss: -217619.359375\n",
      "Train Epoch: 61 [8000/17352 (46%)] Loss: -190942.218750\n",
      "Train Epoch: 61 [8080/17352 (47%)] Loss: -205729.828125\n",
      "Train Epoch: 61 [8160/17352 (47%)] Loss: -175312.109375\n",
      "Train Epoch: 61 [8240/17352 (47%)] Loss: -170357.406250\n",
      "Train Epoch: 61 [8320/17352 (48%)] Loss: -205023.531250\n",
      "Train Epoch: 61 [8400/17352 (48%)] Loss: -185059.671875\n",
      "Train Epoch: 61 [8480/17352 (49%)] Loss: -186554.375000\n",
      "Train Epoch: 61 [8560/17352 (49%)] Loss: -184756.031250\n",
      "Train Epoch: 61 [8640/17352 (50%)] Loss: -180059.031250\n",
      "Train Epoch: 61 [8720/17352 (50%)] Loss: -188964.265625\n",
      "Train Epoch: 61 [8800/17352 (51%)] Loss: -189533.109375\n",
      "Train Epoch: 61 [8880/17352 (51%)] Loss: -191055.906250\n",
      "Train Epoch: 61 [8960/17352 (52%)] Loss: -183504.234375\n",
      "Train Epoch: 61 [9040/17352 (52%)] Loss: -169748.578125\n",
      "Train Epoch: 61 [9120/17352 (53%)] Loss: -161969.468750\n",
      "Train Epoch: 61 [9200/17352 (53%)] Loss: -200421.515625\n",
      "Train Epoch: 61 [9280/17352 (53%)] Loss: -189292.578125\n",
      "Train Epoch: 61 [9360/17352 (54%)] Loss: -179012.218750\n",
      "Train Epoch: 61 [9440/17352 (54%)] Loss: -185920.390625\n",
      "Train Epoch: 61 [9520/17352 (55%)] Loss: -169194.031250\n",
      "Train Epoch: 61 [9600/17352 (55%)] Loss: -196121.125000\n",
      "Train Epoch: 61 [9680/17352 (56%)] Loss: -215967.906250\n",
      "Train Epoch: 61 [9760/17352 (56%)] Loss: -165768.250000\n",
      "Train Epoch: 61 [9840/17352 (57%)] Loss: -201002.515625\n",
      "Train Epoch: 61 [9920/17352 (57%)] Loss: -181889.687500\n",
      "Train Epoch: 61 [10000/17352 (58%)] Loss: -164951.671875\n",
      "Train Epoch: 61 [10080/17352 (58%)] Loss: -178656.296875\n",
      "Train Epoch: 61 [10160/17352 (59%)] Loss: -187718.281250\n",
      "Train Epoch: 61 [10240/17352 (59%)] Loss: -208901.578125\n",
      "Train Epoch: 61 [10320/17352 (59%)] Loss: -171848.140625\n",
      "Train Epoch: 61 [10400/17352 (60%)] Loss: -159694.765625\n",
      "Train Epoch: 61 [10480/17352 (60%)] Loss: -195834.312500\n",
      "Train Epoch: 61 [10560/17352 (61%)] Loss: -177273.250000\n",
      "Train Epoch: 61 [10640/17352 (61%)] Loss: -184957.312500\n",
      "Train Epoch: 61 [10720/17352 (62%)] Loss: -181923.234375\n",
      "Train Epoch: 61 [10800/17352 (62%)] Loss: -193788.796875\n",
      "Train Epoch: 61 [10880/17352 (63%)] Loss: -186045.593750\n",
      "Train Epoch: 61 [10960/17352 (63%)] Loss: -209265.515625\n",
      "Train Epoch: 61 [11040/17352 (64%)] Loss: -176964.437500\n",
      "Train Epoch: 61 [11120/17352 (64%)] Loss: -181695.609375\n",
      "Train Epoch: 61 [11200/17352 (65%)] Loss: -151517.921875\n",
      "Train Epoch: 61 [11280/17352 (65%)] Loss: -187264.656250\n",
      "Train Epoch: 61 [11360/17352 (65%)] Loss: -184738.109375\n",
      "Train Epoch: 61 [11440/17352 (66%)] Loss: -188678.984375\n",
      "Train Epoch: 61 [11520/17352 (66%)] Loss: -196244.453125\n",
      "Train Epoch: 61 [11600/17352 (67%)] Loss: -170682.328125\n",
      "Train Epoch: 61 [11680/17352 (67%)] Loss: -197524.703125\n",
      "Train Epoch: 61 [11760/17352 (68%)] Loss: -202936.828125\n",
      "Train Epoch: 61 [11840/17352 (68%)] Loss: -164987.625000\n",
      "Train Epoch: 61 [11920/17352 (69%)] Loss: -196161.906250\n",
      "Train Epoch: 61 [12000/17352 (69%)] Loss: -187717.734375\n",
      "Train Epoch: 61 [12080/17352 (70%)] Loss: -166435.828125\n",
      "Train Epoch: 61 [12160/17352 (70%)] Loss: -184834.765625\n",
      "Train Epoch: 61 [12240/17352 (71%)] Loss: -193053.546875\n",
      "Train Epoch: 61 [12320/17352 (71%)] Loss: -179672.109375\n",
      "Train Epoch: 61 [12400/17352 (71%)] Loss: -183271.734375\n",
      "Train Epoch: 61 [12480/17352 (72%)] Loss: -156478.765625\n",
      "Train Epoch: 61 [12560/17352 (72%)] Loss: -204337.546875\n",
      "Train Epoch: 61 [12640/17352 (73%)] Loss: -162715.265625\n",
      "Train Epoch: 61 [12720/17352 (73%)] Loss: -177980.312500\n",
      "Train Epoch: 61 [12800/17352 (74%)] Loss: -185543.375000\n",
      "Train Epoch: 61 [12880/17352 (74%)] Loss: -138339.234375\n",
      "Train Epoch: 61 [12960/17352 (75%)] Loss: -195105.703125\n",
      "Train Epoch: 61 [13040/17352 (75%)] Loss: -189608.531250\n",
      "Train Epoch: 61 [13120/17352 (76%)] Loss: -152733.609375\n",
      "Train Epoch: 61 [13200/17352 (76%)] Loss: -187524.625000\n",
      "Train Epoch: 61 [13280/17352 (77%)] Loss: -199005.296875\n",
      "Train Epoch: 61 [13360/17352 (77%)] Loss: -191962.625000\n",
      "Train Epoch: 61 [13440/17352 (77%)] Loss: -176281.984375\n",
      "Train Epoch: 61 [13520/17352 (78%)] Loss: -171307.484375\n",
      "Train Epoch: 61 [13600/17352 (78%)] Loss: -153888.937500\n",
      "Train Epoch: 61 [13680/17352 (79%)] Loss: -184844.421875\n",
      "Train Epoch: 61 [13760/17352 (79%)] Loss: -161098.140625\n",
      "Train Epoch: 61 [13840/17352 (80%)] Loss: -168080.562500\n",
      "Train Epoch: 61 [13920/17352 (80%)] Loss: -170768.687500\n",
      "Train Epoch: 61 [14000/17352 (81%)] Loss: -178826.484375\n",
      "Train Epoch: 61 [14080/17352 (81%)] Loss: -175506.812500\n",
      "Train Epoch: 61 [14160/17352 (82%)] Loss: -192117.656250\n",
      "Train Epoch: 61 [14240/17352 (82%)] Loss: -192286.453125\n",
      "Train Epoch: 61 [14320/17352 (83%)] Loss: -203144.750000\n",
      "Train Epoch: 61 [14400/17352 (83%)] Loss: -176912.187500\n",
      "Train Epoch: 61 [14480/17352 (83%)] Loss: -188082.546875\n",
      "Train Epoch: 61 [14560/17352 (84%)] Loss: -180747.343750\n",
      "Train Epoch: 61 [14640/17352 (84%)] Loss: -164681.562500\n",
      "Train Epoch: 61 [14720/17352 (85%)] Loss: -190910.953125\n",
      "Train Epoch: 61 [14800/17352 (85%)] Loss: -173127.609375\n",
      "Train Epoch: 61 [14880/17352 (86%)] Loss: -146857.390625\n",
      "Train Epoch: 61 [14960/17352 (86%)] Loss: -196930.078125\n",
      "Train Epoch: 61 [15040/17352 (87%)] Loss: -200174.062500\n",
      "Train Epoch: 61 [15120/17352 (87%)] Loss: -170533.687500\n",
      "Train Epoch: 61 [15200/17352 (88%)] Loss: -197955.421875\n",
      "Train Epoch: 61 [15280/17352 (88%)] Loss: -185791.265625\n",
      "Train Epoch: 61 [15360/17352 (89%)] Loss: -218844.375000\n",
      "Train Epoch: 61 [15440/17352 (89%)] Loss: -200634.890625\n",
      "Train Epoch: 61 [15520/17352 (89%)] Loss: -194065.484375\n",
      "Train Epoch: 61 [15600/17352 (90%)] Loss: -205509.640625\n",
      "Train Epoch: 61 [15680/17352 (90%)] Loss: -175074.750000\n",
      "Train Epoch: 61 [15760/17352 (91%)] Loss: -210269.984375\n",
      "Train Epoch: 61 [15840/17352 (91%)] Loss: -198543.515625\n",
      "Train Epoch: 61 [15920/17352 (92%)] Loss: -202991.171875\n",
      "Train Epoch: 61 [16000/17352 (92%)] Loss: -192954.625000\n",
      "Train Epoch: 61 [16080/17352 (93%)] Loss: -201030.765625\n",
      "Train Epoch: 61 [16160/17352 (93%)] Loss: -187324.734375\n",
      "Train Epoch: 61 [16240/17352 (94%)] Loss: -198018.921875\n",
      "Train Epoch: 61 [16320/17352 (94%)] Loss: -200616.625000\n",
      "Train Epoch: 61 [16400/17352 (95%)] Loss: -174648.968750\n",
      "Train Epoch: 61 [16480/17352 (95%)] Loss: -197597.171875\n",
      "Train Epoch: 61 [16560/17352 (95%)] Loss: -220009.328125\n",
      "Train Epoch: 61 [16640/17352 (96%)] Loss: -176158.031250\n",
      "Train Epoch: 61 [16720/17352 (96%)] Loss: -214673.656250\n",
      "Train Epoch: 61 [16800/17352 (97%)] Loss: -173583.484375\n",
      "Train Epoch: 61 [16880/17352 (97%)] Loss: -134535.000000\n",
      "Train Epoch: 61 [16960/17352 (98%)] Loss: -180696.343750\n",
      "Train Epoch: 61 [17040/17352 (98%)] Loss: -206217.921875\n",
      "Train Epoch: 61 [17120/17352 (99%)] Loss: -218470.359375\n",
      "Train Epoch: 61 [17200/17352 (99%)] Loss: -193188.234375\n",
      "Train Epoch: 61 [17280/17352 (100%)] Loss: -173446.890625\n",
      "Train Epoch: 61 [17360/17352 (100%)] Loss: -205501.687500\n",
      "    epoch          : 61\n",
      "    loss           : -188958.37838931242\n",
      "    val_loss       : -23715.991529796047\n",
      "Train Epoch: 62 [0/17352 (0%)] Loss: -209643.500000\n",
      "Train Epoch: 62 [80/17352 (0%)] Loss: -205197.703125\n",
      "Train Epoch: 62 [160/17352 (1%)] Loss: -208377.375000\n",
      "Train Epoch: 62 [240/17352 (1%)] Loss: -186072.921875\n",
      "Train Epoch: 62 [320/17352 (2%)] Loss: -204731.406250\n",
      "Train Epoch: 62 [400/17352 (2%)] Loss: -187716.593750\n",
      "Train Epoch: 62 [480/17352 (3%)] Loss: -212259.578125\n",
      "Train Epoch: 62 [560/17352 (3%)] Loss: -204034.281250\n",
      "Train Epoch: 62 [640/17352 (4%)] Loss: -203747.203125\n",
      "Train Epoch: 62 [720/17352 (4%)] Loss: -202237.734375\n",
      "Train Epoch: 62 [800/17352 (5%)] Loss: -213831.578125\n",
      "Train Epoch: 62 [880/17352 (5%)] Loss: -215089.109375\n",
      "Train Epoch: 62 [960/17352 (6%)] Loss: -196925.906250\n",
      "Train Epoch: 62 [1040/17352 (6%)] Loss: -218538.187500\n",
      "Train Epoch: 62 [1120/17352 (6%)] Loss: -233737.656250\n",
      "Train Epoch: 62 [1200/17352 (7%)] Loss: -205930.203125\n",
      "Train Epoch: 62 [1280/17352 (7%)] Loss: -212185.843750\n",
      "Train Epoch: 62 [1360/17352 (8%)] Loss: -241897.218750\n",
      "Train Epoch: 62 [1440/17352 (8%)] Loss: -229234.125000\n",
      "Train Epoch: 62 [1520/17352 (9%)] Loss: -228905.562500\n",
      "Train Epoch: 62 [1600/17352 (9%)] Loss: -193416.921875\n",
      "Train Epoch: 62 [1680/17352 (10%)] Loss: -217945.250000\n",
      "Train Epoch: 62 [1760/17352 (10%)] Loss: -216093.062500\n",
      "Train Epoch: 62 [1840/17352 (11%)] Loss: -223003.750000\n",
      "Train Epoch: 62 [1920/17352 (11%)] Loss: -185158.828125\n",
      "Train Epoch: 62 [2000/17352 (12%)] Loss: -206137.953125\n",
      "Train Epoch: 62 [2080/17352 (12%)] Loss: -230408.296875\n",
      "Train Epoch: 62 [2160/17352 (12%)] Loss: -235586.843750\n",
      "Train Epoch: 62 [2240/17352 (13%)] Loss: -186796.750000\n",
      "Train Epoch: 62 [2320/17352 (13%)] Loss: -188678.296875\n",
      "Train Epoch: 62 [2400/17352 (14%)] Loss: -181372.953125\n",
      "Train Epoch: 62 [2480/17352 (14%)] Loss: -184255.843750\n",
      "Train Epoch: 62 [2560/17352 (15%)] Loss: -196031.750000\n",
      "Train Epoch: 62 [2640/17352 (15%)] Loss: -192368.062500\n",
      "Train Epoch: 62 [2720/17352 (16%)] Loss: -175361.046875\n",
      "Train Epoch: 62 [2800/17352 (16%)] Loss: -177311.312500\n",
      "Train Epoch: 62 [2880/17352 (17%)] Loss: -202243.171875\n",
      "Train Epoch: 62 [2960/17352 (17%)] Loss: -187775.406250\n",
      "Train Epoch: 62 [3040/17352 (18%)] Loss: -185322.609375\n",
      "Train Epoch: 62 [3120/17352 (18%)] Loss: -190005.468750\n",
      "Train Epoch: 62 [3200/17352 (18%)] Loss: -185403.140625\n",
      "Train Epoch: 62 [3280/17352 (19%)] Loss: -208047.765625\n",
      "Train Epoch: 62 [3360/17352 (19%)] Loss: -197441.875000\n",
      "Train Epoch: 62 [3440/17352 (20%)] Loss: -186605.437500\n",
      "Train Epoch: 62 [3520/17352 (20%)] Loss: -188818.859375\n",
      "Train Epoch: 62 [3600/17352 (21%)] Loss: -183782.046875\n",
      "Train Epoch: 62 [3680/17352 (21%)] Loss: -205803.109375\n",
      "Train Epoch: 62 [3760/17352 (22%)] Loss: -213753.203125\n",
      "Train Epoch: 62 [3840/17352 (22%)] Loss: -180549.156250\n",
      "Train Epoch: 62 [3920/17352 (23%)] Loss: -187710.109375\n",
      "Train Epoch: 62 [4000/17352 (23%)] Loss: -188674.296875\n",
      "Train Epoch: 62 [4080/17352 (24%)] Loss: -171897.703125\n",
      "Train Epoch: 62 [4160/17352 (24%)] Loss: -178605.500000\n",
      "Train Epoch: 62 [4240/17352 (24%)] Loss: -171437.781250\n",
      "Train Epoch: 62 [4320/17352 (25%)] Loss: -192285.984375\n",
      "Train Epoch: 62 [4400/17352 (25%)] Loss: -184067.984375\n",
      "Train Epoch: 62 [4480/17352 (26%)] Loss: -180306.578125\n",
      "Train Epoch: 62 [4560/17352 (26%)] Loss: -174141.578125\n",
      "Train Epoch: 62 [4640/17352 (27%)] Loss: -167958.421875\n",
      "Train Epoch: 62 [4720/17352 (27%)] Loss: -191843.812500\n",
      "Train Epoch: 62 [4800/17352 (28%)] Loss: -165807.265625\n",
      "Train Epoch: 62 [4880/17352 (28%)] Loss: -200220.109375\n",
      "Train Epoch: 62 [4960/17352 (29%)] Loss: -195059.218750\n",
      "Train Epoch: 62 [5040/17352 (29%)] Loss: -203267.390625\n",
      "Train Epoch: 62 [5120/17352 (30%)] Loss: -176902.484375\n",
      "Train Epoch: 62 [5200/17352 (30%)] Loss: -199519.046875\n",
      "Train Epoch: 62 [5280/17352 (30%)] Loss: -192251.718750\n",
      "Train Epoch: 62 [5360/17352 (31%)] Loss: -183162.343750\n",
      "Train Epoch: 62 [5440/17352 (31%)] Loss: -198295.921875\n",
      "Train Epoch: 62 [5520/17352 (32%)] Loss: -183917.203125\n",
      "Train Epoch: 62 [5600/17352 (32%)] Loss: -184747.750000\n",
      "Train Epoch: 62 [5680/17352 (33%)] Loss: -214684.343750\n",
      "Train Epoch: 62 [5760/17352 (33%)] Loss: -184821.546875\n",
      "Train Epoch: 62 [5840/17352 (34%)] Loss: -186041.437500\n",
      "Train Epoch: 62 [5920/17352 (34%)] Loss: -187216.671875\n",
      "Train Epoch: 62 [6000/17352 (35%)] Loss: -159093.062500\n",
      "Train Epoch: 62 [6080/17352 (35%)] Loss: -174452.187500\n",
      "Train Epoch: 62 [6160/17352 (36%)] Loss: -198827.953125\n",
      "Train Epoch: 62 [6240/17352 (36%)] Loss: -210261.656250\n",
      "Train Epoch: 62 [6320/17352 (36%)] Loss: -210482.875000\n",
      "Train Epoch: 62 [6400/17352 (37%)] Loss: -186423.500000\n",
      "Train Epoch: 62 [6480/17352 (37%)] Loss: -183081.000000\n",
      "Train Epoch: 62 [6560/17352 (38%)] Loss: -192173.656250\n",
      "Train Epoch: 62 [6640/17352 (38%)] Loss: -156608.343750\n",
      "Train Epoch: 62 [6720/17352 (39%)] Loss: -201971.531250\n",
      "Train Epoch: 62 [6800/17352 (39%)] Loss: -199773.437500\n",
      "Train Epoch: 62 [6880/17352 (40%)] Loss: -177978.671875\n",
      "Train Epoch: 62 [6960/17352 (40%)] Loss: -163343.515625\n",
      "Train Epoch: 62 [7040/17352 (41%)] Loss: -188211.781250\n",
      "Train Epoch: 62 [7120/17352 (41%)] Loss: -194951.203125\n",
      "Train Epoch: 62 [7200/17352 (41%)] Loss: -201327.875000\n",
      "Train Epoch: 62 [7280/17352 (42%)] Loss: -177242.343750\n",
      "Train Epoch: 62 [7360/17352 (42%)] Loss: -148511.000000\n",
      "Train Epoch: 62 [7440/17352 (43%)] Loss: -197997.781250\n",
      "Train Epoch: 62 [7520/17352 (43%)] Loss: -200835.843750\n",
      "Train Epoch: 62 [7600/17352 (44%)] Loss: -171549.640625\n",
      "Train Epoch: 62 [7680/17352 (44%)] Loss: -180116.359375\n",
      "Train Epoch: 62 [7760/17352 (45%)] Loss: -164509.593750\n",
      "Train Epoch: 62 [7840/17352 (45%)] Loss: -179893.828125\n",
      "Train Epoch: 62 [7920/17352 (46%)] Loss: -169168.421875\n",
      "Train Epoch: 62 [8000/17352 (46%)] Loss: -176148.437500\n",
      "Train Epoch: 62 [8080/17352 (47%)] Loss: -179008.000000\n",
      "Train Epoch: 62 [8160/17352 (47%)] Loss: -218459.187500\n",
      "Train Epoch: 62 [8240/17352 (47%)] Loss: -184831.093750\n",
      "Train Epoch: 62 [8320/17352 (48%)] Loss: -202872.218750\n",
      "Train Epoch: 62 [8400/17352 (48%)] Loss: -178598.906250\n",
      "Train Epoch: 62 [8480/17352 (49%)] Loss: -169980.062500\n",
      "Train Epoch: 62 [8560/17352 (49%)] Loss: -194590.265625\n",
      "Train Epoch: 62 [8640/17352 (50%)] Loss: -216398.312500\n",
      "Train Epoch: 62 [8720/17352 (50%)] Loss: -193134.109375\n",
      "Train Epoch: 62 [8800/17352 (51%)] Loss: -211095.609375\n",
      "Train Epoch: 62 [8880/17352 (51%)] Loss: -184925.765625\n",
      "Train Epoch: 62 [8960/17352 (52%)] Loss: -177198.875000\n",
      "Train Epoch: 62 [9040/17352 (52%)] Loss: -194232.500000\n",
      "Train Epoch: 62 [9120/17352 (53%)] Loss: -191042.531250\n",
      "Train Epoch: 62 [9200/17352 (53%)] Loss: -180878.812500\n",
      "Train Epoch: 62 [9280/17352 (53%)] Loss: -179924.015625\n",
      "Train Epoch: 62 [9360/17352 (54%)] Loss: -179475.687500\n",
      "Train Epoch: 62 [9440/17352 (54%)] Loss: -176534.453125\n",
      "Train Epoch: 62 [9520/17352 (55%)] Loss: -207860.750000\n",
      "Train Epoch: 62 [9600/17352 (55%)] Loss: -198802.531250\n",
      "Train Epoch: 62 [9680/17352 (56%)] Loss: -185592.625000\n",
      "Train Epoch: 62 [9760/17352 (56%)] Loss: -181977.328125\n",
      "Train Epoch: 62 [9840/17352 (57%)] Loss: -181336.312500\n",
      "Train Epoch: 62 [9920/17352 (57%)] Loss: -220009.718750\n",
      "Train Epoch: 62 [10000/17352 (58%)] Loss: -205508.500000\n",
      "Train Epoch: 62 [10080/17352 (58%)] Loss: -182549.312500\n",
      "Train Epoch: 62 [10160/17352 (59%)] Loss: -159692.781250\n",
      "Train Epoch: 62 [10240/17352 (59%)] Loss: -201832.703125\n",
      "Train Epoch: 62 [10320/17352 (59%)] Loss: -166434.906250\n",
      "Train Epoch: 62 [10400/17352 (60%)] Loss: -186037.484375\n",
      "Train Epoch: 62 [10480/17352 (60%)] Loss: -176273.625000\n",
      "Train Epoch: 62 [10560/17352 (61%)] Loss: -167183.937500\n",
      "Train Epoch: 62 [10640/17352 (61%)] Loss: -202983.796875\n",
      "Train Epoch: 62 [10720/17352 (62%)] Loss: -193002.359375\n",
      "Train Epoch: 62 [10800/17352 (62%)] Loss: -223689.765625\n",
      "Train Epoch: 62 [10880/17352 (63%)] Loss: -185504.296875\n",
      "Train Epoch: 62 [10960/17352 (63%)] Loss: -202597.875000\n",
      "Train Epoch: 62 [11040/17352 (64%)] Loss: -163556.921875\n",
      "Train Epoch: 62 [11120/17352 (64%)] Loss: -178824.656250\n",
      "Train Epoch: 62 [11200/17352 (65%)] Loss: -176047.625000\n",
      "Train Epoch: 62 [11280/17352 (65%)] Loss: -182777.343750\n",
      "Train Epoch: 62 [11360/17352 (65%)] Loss: -206160.468750\n",
      "Train Epoch: 62 [11440/17352 (66%)] Loss: -170539.875000\n",
      "Train Epoch: 62 [11520/17352 (66%)] Loss: -197087.671875\n",
      "Train Epoch: 62 [11600/17352 (67%)] Loss: -197342.984375\n",
      "Train Epoch: 62 [11680/17352 (67%)] Loss: -195106.125000\n",
      "Train Epoch: 62 [11760/17352 (68%)] Loss: -181621.265625\n",
      "Train Epoch: 62 [11840/17352 (68%)] Loss: -177783.078125\n",
      "Train Epoch: 62 [11920/17352 (69%)] Loss: -184967.640625\n",
      "Train Epoch: 62 [12000/17352 (69%)] Loss: -188754.343750\n",
      "Train Epoch: 62 [12080/17352 (70%)] Loss: -177485.062500\n",
      "Train Epoch: 62 [12160/17352 (70%)] Loss: -176700.578125\n",
      "Train Epoch: 62 [12240/17352 (71%)] Loss: -198263.609375\n",
      "Train Epoch: 62 [12320/17352 (71%)] Loss: -208726.062500\n",
      "Train Epoch: 62 [12400/17352 (71%)] Loss: -205168.812500\n",
      "Train Epoch: 62 [12480/17352 (72%)] Loss: -178209.406250\n",
      "Train Epoch: 62 [12560/17352 (72%)] Loss: -170780.500000\n",
      "Train Epoch: 62 [12640/17352 (73%)] Loss: -185165.875000\n",
      "Train Epoch: 62 [12720/17352 (73%)] Loss: -165734.859375\n",
      "Train Epoch: 62 [12800/17352 (74%)] Loss: -163772.390625\n",
      "Train Epoch: 62 [12880/17352 (74%)] Loss: -196865.000000\n",
      "Train Epoch: 62 [12960/17352 (75%)] Loss: -148923.500000\n",
      "Train Epoch: 62 [13040/17352 (75%)] Loss: -205637.890625\n",
      "Train Epoch: 62 [13120/17352 (76%)] Loss: -182920.531250\n",
      "Train Epoch: 62 [13200/17352 (76%)] Loss: -193449.750000\n",
      "Train Epoch: 62 [13280/17352 (77%)] Loss: -198017.640625\n",
      "Train Epoch: 62 [13360/17352 (77%)] Loss: -189726.781250\n",
      "Train Epoch: 62 [13440/17352 (77%)] Loss: -181011.156250\n",
      "Train Epoch: 62 [13520/17352 (78%)] Loss: -163250.500000\n",
      "Train Epoch: 62 [13600/17352 (78%)] Loss: -174624.921875\n",
      "Train Epoch: 62 [13680/17352 (79%)] Loss: -179451.406250\n",
      "Train Epoch: 62 [13760/17352 (79%)] Loss: -190223.734375\n",
      "Train Epoch: 62 [13840/17352 (80%)] Loss: -178735.781250\n",
      "Train Epoch: 62 [13920/17352 (80%)] Loss: -153889.750000\n",
      "Train Epoch: 62 [14000/17352 (81%)] Loss: -200636.546875\n",
      "Train Epoch: 62 [14080/17352 (81%)] Loss: -181741.437500\n",
      "Train Epoch: 62 [14160/17352 (82%)] Loss: -181161.765625\n",
      "Train Epoch: 62 [14240/17352 (82%)] Loss: -151220.765625\n",
      "Train Epoch: 62 [14320/17352 (83%)] Loss: -201307.015625\n",
      "Train Epoch: 62 [14400/17352 (83%)] Loss: -190504.406250\n",
      "Train Epoch: 62 [14480/17352 (83%)] Loss: -165353.828125\n",
      "Train Epoch: 62 [14560/17352 (84%)] Loss: -178870.312500\n",
      "Train Epoch: 62 [14640/17352 (84%)] Loss: -192860.437500\n",
      "Train Epoch: 62 [14720/17352 (85%)] Loss: -201388.796875\n",
      "Train Epoch: 62 [14800/17352 (85%)] Loss: -187269.250000\n",
      "Train Epoch: 62 [14880/17352 (86%)] Loss: -184482.656250\n",
      "Train Epoch: 62 [14960/17352 (86%)] Loss: -208040.359375\n",
      "Train Epoch: 62 [15040/17352 (87%)] Loss: -197081.500000\n",
      "Train Epoch: 62 [15120/17352 (87%)] Loss: -188013.265625\n",
      "Train Epoch: 62 [15200/17352 (88%)] Loss: -194053.843750\n",
      "Train Epoch: 62 [15280/17352 (88%)] Loss: -199175.656250\n",
      "Train Epoch: 62 [15360/17352 (89%)] Loss: -215643.562500\n",
      "Train Epoch: 62 [15440/17352 (89%)] Loss: -210272.859375\n",
      "Train Epoch: 62 [15520/17352 (89%)] Loss: -199457.578125\n",
      "Train Epoch: 62 [15600/17352 (90%)] Loss: -157485.734375\n",
      "Train Epoch: 62 [15680/17352 (90%)] Loss: -164679.375000\n",
      "Train Epoch: 62 [15760/17352 (91%)] Loss: -215411.187500\n",
      "Train Epoch: 62 [15840/17352 (91%)] Loss: -206557.453125\n",
      "Train Epoch: 62 [15920/17352 (92%)] Loss: -170308.875000\n",
      "Train Epoch: 62 [16000/17352 (92%)] Loss: -204600.656250\n",
      "Train Epoch: 62 [16080/17352 (93%)] Loss: -225474.125000\n",
      "Train Epoch: 62 [16160/17352 (93%)] Loss: -187887.500000\n",
      "Train Epoch: 62 [16240/17352 (94%)] Loss: -166024.734375\n",
      "Train Epoch: 62 [16320/17352 (94%)] Loss: -152903.156250\n",
      "Train Epoch: 62 [16400/17352 (95%)] Loss: -151506.921875\n",
      "Train Epoch: 62 [16480/17352 (95%)] Loss: -197572.953125\n",
      "Train Epoch: 62 [16560/17352 (95%)] Loss: -178138.109375\n",
      "Train Epoch: 62 [16640/17352 (96%)] Loss: -204658.562500\n",
      "Train Epoch: 62 [16720/17352 (96%)] Loss: -142615.171875\n",
      "Train Epoch: 62 [16800/17352 (97%)] Loss: -204997.296875\n",
      "Train Epoch: 62 [16880/17352 (97%)] Loss: -187322.906250\n",
      "Train Epoch: 62 [16960/17352 (98%)] Loss: -159315.343750\n",
      "Train Epoch: 62 [17040/17352 (98%)] Loss: -180798.843750\n",
      "Train Epoch: 62 [17120/17352 (99%)] Loss: -174188.781250\n",
      "Train Epoch: 62 [17200/17352 (99%)] Loss: -183927.843750\n",
      "Train Epoch: 62 [17280/17352 (100%)] Loss: -179417.703125\n",
      "Train Epoch: 62 [17360/17352 (100%)] Loss: -179027.343750\n",
      "    epoch          : 62\n",
      "    loss           : -189157.52520857306\n",
      "    val_loss       : -23716.031063384293\n",
      "Train Epoch: 63 [0/17352 (0%)] Loss: -206788.828125\n",
      "Train Epoch: 63 [80/17352 (0%)] Loss: -194295.875000\n",
      "Train Epoch: 63 [160/17352 (1%)] Loss: -182783.578125\n",
      "Train Epoch: 63 [240/17352 (1%)] Loss: -200603.703125\n",
      "Train Epoch: 63 [320/17352 (2%)] Loss: -214414.062500\n",
      "Train Epoch: 63 [400/17352 (2%)] Loss: -215090.109375\n",
      "Train Epoch: 63 [480/17352 (3%)] Loss: -186074.156250\n",
      "Train Epoch: 63 [560/17352 (3%)] Loss: -241903.203125\n",
      "Train Epoch: 63 [640/17352 (4%)] Loss: -229960.984375\n",
      "Train Epoch: 63 [720/17352 (4%)] Loss: -214454.484375\n",
      "Train Epoch: 63 [800/17352 (5%)] Loss: -214520.750000\n",
      "Train Epoch: 63 [880/17352 (5%)] Loss: -222513.609375\n",
      "Train Epoch: 63 [960/17352 (6%)] Loss: -210630.500000\n",
      "Train Epoch: 63 [1040/17352 (6%)] Loss: -199925.593750\n",
      "Train Epoch: 63 [1120/17352 (6%)] Loss: -226103.828125\n",
      "Train Epoch: 63 [1200/17352 (7%)] Loss: -193708.312500\n",
      "Train Epoch: 63 [1280/17352 (7%)] Loss: -203269.640625\n",
      "Train Epoch: 63 [1360/17352 (8%)] Loss: -210209.015625\n",
      "Train Epoch: 63 [1440/17352 (8%)] Loss: -221754.500000\n",
      "Train Epoch: 63 [1520/17352 (9%)] Loss: -210748.531250\n",
      "Train Epoch: 63 [1600/17352 (9%)] Loss: -203736.906250\n",
      "Train Epoch: 63 [1680/17352 (10%)] Loss: -224258.046875\n",
      "Train Epoch: 63 [1760/17352 (10%)] Loss: -198774.000000\n",
      "Train Epoch: 63 [1840/17352 (11%)] Loss: -188753.296875\n",
      "Train Epoch: 63 [1920/17352 (11%)] Loss: -215825.328125\n",
      "Train Epoch: 63 [2000/17352 (12%)] Loss: -219664.312500\n",
      "Train Epoch: 63 [2080/17352 (12%)] Loss: -204358.328125\n",
      "Train Epoch: 63 [2160/17352 (12%)] Loss: -204404.437500\n",
      "Train Epoch: 63 [2240/17352 (13%)] Loss: -200967.312500\n",
      "Train Epoch: 63 [2320/17352 (13%)] Loss: -206362.750000\n",
      "Train Epoch: 63 [2400/17352 (14%)] Loss: -184476.125000\n",
      "Train Epoch: 63 [2480/17352 (14%)] Loss: -209510.171875\n",
      "Train Epoch: 63 [2560/17352 (15%)] Loss: -167872.812500\n",
      "Train Epoch: 63 [2640/17352 (15%)] Loss: -180798.250000\n",
      "Train Epoch: 63 [2720/17352 (16%)] Loss: -188209.687500\n",
      "Train Epoch: 63 [2800/17352 (16%)] Loss: -136430.515625\n",
      "Train Epoch: 63 [2880/17352 (17%)] Loss: -165733.859375\n",
      "Train Epoch: 63 [2960/17352 (17%)] Loss: -181911.953125\n",
      "Train Epoch: 63 [3040/17352 (18%)] Loss: -188153.953125\n",
      "Train Epoch: 63 [3120/17352 (18%)] Loss: -180248.906250\n",
      "Train Epoch: 63 [3200/17352 (18%)] Loss: -203845.500000\n",
      "Train Epoch: 63 [3280/17352 (19%)] Loss: -191676.796875\n",
      "Train Epoch: 63 [3360/17352 (19%)] Loss: -173663.578125\n",
      "Train Epoch: 63 [3440/17352 (20%)] Loss: -199080.531250\n",
      "Train Epoch: 63 [3520/17352 (20%)] Loss: -188861.796875\n",
      "Train Epoch: 63 [3600/17352 (21%)] Loss: -187599.171875\n",
      "Train Epoch: 63 [3680/17352 (21%)] Loss: -167080.671875\n",
      "Train Epoch: 63 [3760/17352 (22%)] Loss: -179420.156250\n",
      "Train Epoch: 63 [3840/17352 (22%)] Loss: -169979.875000\n",
      "Train Epoch: 63 [3920/17352 (23%)] Loss: -180258.203125\n",
      "Train Epoch: 63 [4000/17352 (23%)] Loss: -194065.359375\n",
      "Train Epoch: 63 [4080/17352 (24%)] Loss: -192231.890625\n",
      "Train Epoch: 63 [4160/17352 (24%)] Loss: -180522.265625\n",
      "Train Epoch: 63 [4240/17352 (24%)] Loss: -173891.453125\n",
      "Train Epoch: 63 [4320/17352 (25%)] Loss: -164805.109375\n",
      "Train Epoch: 63 [4400/17352 (25%)] Loss: -204344.578125\n",
      "Train Epoch: 63 [4480/17352 (26%)] Loss: -174032.781250\n",
      "Train Epoch: 63 [4560/17352 (26%)] Loss: -162557.109375\n",
      "Train Epoch: 63 [4640/17352 (27%)] Loss: -163496.578125\n",
      "Train Epoch: 63 [4720/17352 (27%)] Loss: -198264.531250\n",
      "Train Epoch: 63 [4800/17352 (28%)] Loss: -201971.343750\n",
      "Train Epoch: 63 [4880/17352 (28%)] Loss: -186783.328125\n",
      "Train Epoch: 63 [4960/17352 (29%)] Loss: -180902.437500\n",
      "Train Epoch: 63 [5040/17352 (29%)] Loss: -155862.812500\n",
      "Train Epoch: 63 [5120/17352 (30%)] Loss: -195510.437500\n",
      "Train Epoch: 63 [5200/17352 (30%)] Loss: -222855.812500\n",
      "Train Epoch: 63 [5280/17352 (30%)] Loss: -188504.312500\n",
      "Train Epoch: 63 [5360/17352 (31%)] Loss: -187360.921875\n",
      "Train Epoch: 63 [5440/17352 (31%)] Loss: -177277.750000\n",
      "Train Epoch: 63 [5520/17352 (32%)] Loss: -187260.812500\n",
      "Train Epoch: 63 [5600/17352 (32%)] Loss: -223958.562500\n",
      "Train Epoch: 63 [5680/17352 (33%)] Loss: -218748.359375\n",
      "Train Epoch: 63 [5760/17352 (33%)] Loss: -207857.250000\n",
      "Train Epoch: 63 [5840/17352 (34%)] Loss: -178571.343750\n",
      "Train Epoch: 63 [5920/17352 (34%)] Loss: -173936.515625\n",
      "Train Epoch: 63 [6000/17352 (35%)] Loss: -177080.890625\n",
      "Train Epoch: 63 [6080/17352 (35%)] Loss: -210554.968750\n",
      "Train Epoch: 63 [6160/17352 (36%)] Loss: -187456.171875\n",
      "Train Epoch: 63 [6240/17352 (36%)] Loss: -191885.734375\n",
      "Train Epoch: 63 [6320/17352 (36%)] Loss: -197336.765625\n",
      "Train Epoch: 63 [6400/17352 (37%)] Loss: -178323.234375\n",
      "Train Epoch: 63 [6480/17352 (37%)] Loss: -163211.109375\n",
      "Train Epoch: 63 [6560/17352 (38%)] Loss: -188451.156250\n",
      "Train Epoch: 63 [6640/17352 (38%)] Loss: -196455.921875\n",
      "Train Epoch: 63 [6720/17352 (39%)] Loss: -169745.046875\n",
      "Train Epoch: 63 [6800/17352 (39%)] Loss: -192954.906250\n",
      "Train Epoch: 63 [6880/17352 (40%)] Loss: -220967.296875\n",
      "Train Epoch: 63 [6960/17352 (40%)] Loss: -157773.078125\n",
      "Train Epoch: 63 [7040/17352 (41%)] Loss: -192314.265625\n",
      "Train Epoch: 63 [7120/17352 (41%)] Loss: -171193.015625\n",
      "Train Epoch: 63 [7200/17352 (41%)] Loss: -171546.953125\n",
      "Train Epoch: 63 [7280/17352 (42%)] Loss: -202567.234375\n",
      "Train Epoch: 63 [7360/17352 (42%)] Loss: -192394.593750\n",
      "Train Epoch: 63 [7440/17352 (43%)] Loss: -159674.687500\n",
      "Train Epoch: 63 [7520/17352 (43%)] Loss: -200633.406250\n",
      "Train Epoch: 63 [7600/17352 (44%)] Loss: -177781.234375\n",
      "Train Epoch: 63 [7680/17352 (44%)] Loss: -197553.156250\n",
      "Train Epoch: 63 [7760/17352 (45%)] Loss: -173580.500000\n",
      "Train Epoch: 63 [7840/17352 (45%)] Loss: -156997.796875\n",
      "Train Epoch: 63 [7920/17352 (46%)] Loss: -176270.437500\n",
      "Train Epoch: 63 [8000/17352 (46%)] Loss: -184019.328125\n",
      "Train Epoch: 63 [8080/17352 (47%)] Loss: -178599.015625\n",
      "Train Epoch: 63 [8160/17352 (47%)] Loss: -167241.406250\n",
      "Train Epoch: 63 [8240/17352 (47%)] Loss: -198820.984375\n",
      "Train Epoch: 63 [8320/17352 (48%)] Loss: -223688.125000\n",
      "Train Epoch: 63 [8400/17352 (48%)] Loss: -215461.703125\n",
      "Train Epoch: 63 [8480/17352 (49%)] Loss: -145997.781250\n",
      "Train Epoch: 63 [8560/17352 (49%)] Loss: -208725.437500\n",
      "Train Epoch: 63 [8640/17352 (50%)] Loss: -187717.046875\n",
      "Train Epoch: 63 [8720/17352 (50%)] Loss: -205529.328125\n",
      "Train Epoch: 63 [8800/17352 (51%)] Loss: -200297.250000\n",
      "Train Epoch: 63 [8880/17352 (51%)] Loss: -205687.218750\n",
      "Train Epoch: 63 [8960/17352 (52%)] Loss: -181339.125000\n",
      "Train Epoch: 63 [9040/17352 (52%)] Loss: -186687.000000\n",
      "Train Epoch: 63 [9120/17352 (53%)] Loss: -169439.484375\n",
      "Train Epoch: 63 [9200/17352 (53%)] Loss: -190226.921875\n",
      "Train Epoch: 63 [9280/17352 (53%)] Loss: -185550.859375\n",
      "Train Epoch: 63 [9360/17352 (54%)] Loss: -189509.625000\n",
      "Train Epoch: 63 [9440/17352 (54%)] Loss: -204660.562500\n",
      "Train Epoch: 63 [9520/17352 (55%)] Loss: -196697.781250\n",
      "Train Epoch: 63 [9600/17352 (55%)] Loss: -173579.171875\n",
      "Train Epoch: 63 [9680/17352 (56%)] Loss: -220013.875000\n",
      "Train Epoch: 63 [9760/17352 (56%)] Loss: -210912.390625\n",
      "Train Epoch: 63 [9840/17352 (57%)] Loss: -209276.531250\n",
      "Train Epoch: 63 [9920/17352 (57%)] Loss: -204370.250000\n",
      "Train Epoch: 63 [10000/17352 (58%)] Loss: -148155.031250\n",
      "Train Epoch: 63 [10080/17352 (58%)] Loss: -160052.234375\n",
      "Train Epoch: 63 [10160/17352 (59%)] Loss: -217605.625000\n",
      "Train Epoch: 63 [10240/17352 (59%)] Loss: -208904.593750\n",
      "Train Epoch: 63 [10320/17352 (59%)] Loss: -208800.953125\n",
      "Train Epoch: 63 [10400/17352 (60%)] Loss: -172181.703125\n",
      "Train Epoch: 63 [10480/17352 (60%)] Loss: -184968.281250\n",
      "Train Epoch: 63 [10560/17352 (61%)] Loss: -213901.937500\n",
      "Train Epoch: 63 [10640/17352 (61%)] Loss: -178811.031250\n",
      "Train Epoch: 63 [10720/17352 (62%)] Loss: -171717.390625\n",
      "Train Epoch: 63 [10800/17352 (62%)] Loss: -176053.312500\n",
      "Train Epoch: 63 [10880/17352 (63%)] Loss: -182687.000000\n",
      "Train Epoch: 63 [10960/17352 (63%)] Loss: -163771.765625\n",
      "Train Epoch: 63 [11040/17352 (64%)] Loss: -200868.562500\n",
      "Train Epoch: 63 [11120/17352 (64%)] Loss: -197080.250000\n",
      "Train Epoch: 63 [11200/17352 (65%)] Loss: -173507.906250\n",
      "Train Epoch: 63 [11280/17352 (65%)] Loss: -166258.593750\n",
      "Train Epoch: 63 [11360/17352 (65%)] Loss: -193912.484375\n",
      "Train Epoch: 63 [11440/17352 (66%)] Loss: -196126.625000\n",
      "Train Epoch: 63 [11520/17352 (66%)] Loss: -191966.437500\n",
      "Train Epoch: 63 [11600/17352 (67%)] Loss: -189790.062500\n",
      "Train Epoch: 63 [11680/17352 (67%)] Loss: -191306.781250\n",
      "Train Epoch: 63 [11760/17352 (68%)] Loss: -168085.890625\n",
      "Train Epoch: 63 [11840/17352 (68%)] Loss: -166033.140625\n",
      "Train Epoch: 63 [11920/17352 (69%)] Loss: -152905.296875\n",
      "Train Epoch: 63 [12000/17352 (69%)] Loss: -179303.140625\n",
      "Train Epoch: 63 [12080/17352 (70%)] Loss: -142616.468750\n",
      "Train Epoch: 63 [12160/17352 (70%)] Loss: -176971.375000\n",
      "Train Epoch: 63 [12240/17352 (71%)] Loss: -177305.046875\n",
      "Train Epoch: 63 [12320/17352 (71%)] Loss: -187650.796875\n",
      "Train Epoch: 63 [12400/17352 (71%)] Loss: -209900.906250\n",
      "Train Epoch: 63 [12480/17352 (72%)] Loss: -146851.234375\n",
      "Train Epoch: 63 [12560/17352 (72%)] Loss: -189599.656250\n",
      "Train Epoch: 63 [12640/17352 (73%)] Loss: -179930.468750\n",
      "Train Epoch: 63 [12720/17352 (73%)] Loss: -180117.328125\n",
      "Train Epoch: 63 [12800/17352 (74%)] Loss: -183082.046875\n",
      "Train Epoch: 63 [12880/17352 (74%)] Loss: -177239.875000\n",
      "Train Epoch: 63 [12960/17352 (75%)] Loss: -183919.843750\n",
      "Train Epoch: 63 [13040/17352 (75%)] Loss: -184990.437500\n",
      "Train Epoch: 63 [13120/17352 (76%)] Loss: -204329.859375\n",
      "Train Epoch: 63 [13200/17352 (76%)] Loss: -180057.781250\n",
      "Train Epoch: 63 [13280/17352 (77%)] Loss: -183720.250000\n",
      "Train Epoch: 63 [13360/17352 (77%)] Loss: -178819.875000\n",
      "Train Epoch: 63 [13440/17352 (77%)] Loss: -181263.015625\n",
      "Train Epoch: 63 [13520/17352 (78%)] Loss: -203674.562500\n",
      "Train Epoch: 63 [13600/17352 (78%)] Loss: -176286.921875\n",
      "Train Epoch: 63 [13680/17352 (79%)] Loss: -190789.640625\n",
      "Train Epoch: 63 [13760/17352 (79%)] Loss: -187307.671875\n",
      "Train Epoch: 63 [13840/17352 (80%)] Loss: -196401.453125\n",
      "Train Epoch: 63 [13920/17352 (80%)] Loss: -218402.609375\n",
      "Train Epoch: 63 [14000/17352 (81%)] Loss: -194933.453125\n",
      "Train Epoch: 63 [14080/17352 (81%)] Loss: -205401.718750\n",
      "Train Epoch: 63 [14160/17352 (82%)] Loss: -196809.609375\n",
      "Train Epoch: 63 [14240/17352 (82%)] Loss: -199718.593750\n",
      "Train Epoch: 63 [14320/17352 (83%)] Loss: -163759.718750\n",
      "Train Epoch: 63 [14400/17352 (83%)] Loss: -199803.109375\n",
      "Train Epoch: 63 [14480/17352 (83%)] Loss: -210159.375000\n",
      "Train Epoch: 63 [14560/17352 (84%)] Loss: -165998.015625\n",
      "Train Epoch: 63 [14640/17352 (84%)] Loss: -198800.812500\n",
      "Train Epoch: 63 [14720/17352 (85%)] Loss: -203146.937500\n",
      "Train Epoch: 63 [14800/17352 (85%)] Loss: -179168.921875\n",
      "Train Epoch: 63 [14880/17352 (86%)] Loss: -178734.828125\n",
      "Train Epoch: 63 [14960/17352 (86%)] Loss: -196732.484375\n",
      "Train Epoch: 63 [15040/17352 (87%)] Loss: -178098.000000\n",
      "Train Epoch: 63 [15120/17352 (87%)] Loss: -181015.406250\n",
      "Train Epoch: 63 [15200/17352 (88%)] Loss: -148823.718750\n",
      "Train Epoch: 63 [15280/17352 (88%)] Loss: -174517.984375\n",
      "Train Epoch: 63 [15360/17352 (89%)] Loss: -179019.625000\n",
      "Train Epoch: 63 [15440/17352 (89%)] Loss: -172890.656250\n",
      "Train Epoch: 63 [15520/17352 (89%)] Loss: -192641.734375\n",
      "Train Epoch: 63 [15600/17352 (90%)] Loss: -208034.843750\n",
      "Train Epoch: 63 [15680/17352 (90%)] Loss: -180875.406250\n",
      "Train Epoch: 63 [15760/17352 (91%)] Loss: -182103.093750\n",
      "Train Epoch: 63 [15840/17352 (91%)] Loss: -176540.437500\n",
      "Train Epoch: 63 [15920/17352 (92%)] Loss: -196867.125000\n",
      "Train Epoch: 63 [16000/17352 (92%)] Loss: -159675.859375\n",
      "Train Epoch: 63 [16080/17352 (93%)] Loss: -176701.734375\n",
      "Train Epoch: 63 [16160/17352 (93%)] Loss: -200075.281250\n",
      "Train Epoch: 63 [16240/17352 (94%)] Loss: -201369.906250\n",
      "Train Epoch: 63 [16320/17352 (94%)] Loss: -193048.843750\n",
      "Train Epoch: 63 [16400/17352 (95%)] Loss: -202988.062500\n",
      "Train Epoch: 63 [16480/17352 (95%)] Loss: -189217.203125\n",
      "Train Epoch: 63 [16560/17352 (95%)] Loss: -165734.312500\n",
      "Train Epoch: 63 [16640/17352 (96%)] Loss: -201938.265625\n",
      "Train Epoch: 63 [16720/17352 (96%)] Loss: -181538.843750\n",
      "Train Epoch: 63 [16800/17352 (97%)] Loss: -143621.484375\n",
      "Train Epoch: 63 [16880/17352 (97%)] Loss: -193357.265625\n",
      "Train Epoch: 63 [16960/17352 (98%)] Loss: -178204.875000\n",
      "Train Epoch: 63 [17040/17352 (98%)] Loss: -183965.703125\n",
      "Train Epoch: 63 [17120/17352 (99%)] Loss: -170310.140625\n",
      "Train Epoch: 63 [17200/17352 (99%)] Loss: -206600.656250\n",
      "Train Epoch: 63 [17280/17352 (100%)] Loss: -188809.281250\n",
      "Train Epoch: 63 [17360/17352 (100%)] Loss: -185324.296875\n",
      "    epoch          : 63\n",
      "    loss           : -189348.69485399884\n",
      "    val_loss       : -23715.9589717668\n",
      "Train Epoch: 64 [0/17352 (0%)] Loss: -219261.968750\n",
      "Train Epoch: 64 [80/17352 (0%)] Loss: -210202.421875\n",
      "Train Epoch: 64 [160/17352 (1%)] Loss: -185299.093750\n",
      "Train Epoch: 64 [240/17352 (1%)] Loss: -198119.203125\n",
      "Train Epoch: 64 [320/17352 (2%)] Loss: -215100.640625\n",
      "Train Epoch: 64 [400/17352 (2%)] Loss: -205081.796875\n",
      "Train Epoch: 64 [480/17352 (3%)] Loss: -204730.875000\n",
      "Train Epoch: 64 [560/17352 (3%)] Loss: -213325.937500\n",
      "Train Epoch: 64 [640/17352 (4%)] Loss: -203743.859375\n",
      "Train Epoch: 64 [720/17352 (4%)] Loss: -209779.484375\n",
      "Train Epoch: 64 [800/17352 (5%)] Loss: -223000.250000\n",
      "Train Epoch: 64 [880/17352 (5%)] Loss: -219660.828125\n",
      "Train Epoch: 64 [960/17352 (6%)] Loss: -201670.468750\n",
      "Train Epoch: 64 [1040/17352 (6%)] Loss: -214466.968750\n",
      "Train Epoch: 64 [1120/17352 (6%)] Loss: -204534.109375\n",
      "Train Epoch: 64 [1200/17352 (7%)] Loss: -229959.000000\n",
      "Train Epoch: 64 [1280/17352 (7%)] Loss: -233732.875000\n",
      "Train Epoch: 64 [1360/17352 (8%)] Loss: -224250.968750\n",
      "Train Epoch: 64 [1440/17352 (8%)] Loss: -230190.265625\n",
      "Train Epoch: 64 [1520/17352 (9%)] Loss: -208535.031250\n",
      "Train Epoch: 64 [1600/17352 (9%)] Loss: -216212.671875\n",
      "Train Epoch: 64 [1680/17352 (10%)] Loss: -199105.750000\n",
      "Train Epoch: 64 [1760/17352 (10%)] Loss: -217634.156250\n",
      "Train Epoch: 64 [1840/17352 (11%)] Loss: -186076.546875\n",
      "Train Epoch: 64 [1920/17352 (11%)] Loss: -236834.640625\n",
      "Train Epoch: 64 [2000/17352 (12%)] Loss: -217943.921875\n",
      "Train Epoch: 64 [2080/17352 (12%)] Loss: -198769.109375\n",
      "Train Epoch: 64 [2160/17352 (12%)] Loss: -214714.359375\n",
      "Train Epoch: 64 [2240/17352 (13%)] Loss: -210556.000000\n",
      "Train Epoch: 64 [2320/17352 (13%)] Loss: -170106.187500\n",
      "Train Epoch: 64 [2400/17352 (14%)] Loss: -188004.750000\n",
      "Train Epoch: 64 [2480/17352 (14%)] Loss: -204349.609375\n",
      "Train Epoch: 64 [2560/17352 (15%)] Loss: -206470.906250\n",
      "Train Epoch: 64 [2640/17352 (15%)] Loss: -182923.531250\n",
      "Train Epoch: 64 [2720/17352 (16%)] Loss: -168048.265625\n",
      "Train Epoch: 64 [2800/17352 (16%)] Loss: -194057.500000\n",
      "Train Epoch: 64 [2880/17352 (17%)] Loss: -196817.187500\n",
      "Train Epoch: 64 [2960/17352 (17%)] Loss: -184831.718750\n",
      "Train Epoch: 64 [3040/17352 (18%)] Loss: -180746.453125\n",
      "Train Epoch: 64 [3120/17352 (18%)] Loss: -190231.515625\n",
      "Train Epoch: 64 [3200/17352 (18%)] Loss: -204601.875000\n",
      "Train Epoch: 64 [3280/17352 (19%)] Loss: -171421.375000\n",
      "Train Epoch: 64 [3360/17352 (19%)] Loss: -183257.531250\n",
      "Train Epoch: 64 [3440/17352 (20%)] Loss: -189604.046875\n",
      "Train Epoch: 64 [3520/17352 (20%)] Loss: -191043.109375\n",
      "Train Epoch: 64 [3600/17352 (21%)] Loss: -192242.531250\n",
      "Train Epoch: 64 [3680/17352 (21%)] Loss: -152902.484375\n",
      "Train Epoch: 64 [3760/17352 (22%)] Loss: -159678.421875\n",
      "Train Epoch: 64 [3840/17352 (22%)] Loss: -184480.625000\n",
      "Train Epoch: 64 [3920/17352 (23%)] Loss: -183798.125000\n",
      "Train Epoch: 64 [4000/17352 (23%)] Loss: -166463.046875\n",
      "Train Epoch: 64 [4080/17352 (24%)] Loss: -187948.921875\n",
      "Train Epoch: 64 [4160/17352 (24%)] Loss: -164683.687500\n",
      "Train Epoch: 64 [4240/17352 (24%)] Loss: -193486.703125\n",
      "Train Epoch: 64 [4320/17352 (25%)] Loss: -192283.453125\n",
      "Train Epoch: 64 [4400/17352 (25%)] Loss: -211160.000000\n",
      "Train Epoch: 64 [4480/17352 (26%)] Loss: -179166.515625\n",
      "Train Epoch: 64 [4560/17352 (26%)] Loss: -151516.812500\n",
      "Train Epoch: 64 [4640/17352 (27%)] Loss: -195837.375000\n",
      "Train Epoch: 64 [4720/17352 (27%)] Loss: -199517.812500\n",
      "Train Epoch: 64 [4800/17352 (28%)] Loss: -167181.328125\n",
      "Train Epoch: 64 [4880/17352 (28%)] Loss: -228253.812500\n",
      "Train Epoch: 64 [4960/17352 (29%)] Loss: -165394.750000\n",
      "Train Epoch: 64 [5040/17352 (29%)] Loss: -195648.796875\n",
      "Train Epoch: 64 [5120/17352 (30%)] Loss: -176586.500000\n",
      "Train Epoch: 64 [5200/17352 (30%)] Loss: -181963.140625\n",
      "Train Epoch: 64 [5280/17352 (30%)] Loss: -153325.703125\n",
      "Train Epoch: 64 [5360/17352 (31%)] Loss: -192879.093750\n",
      "Train Epoch: 64 [5440/17352 (31%)] Loss: -197383.937500\n",
      "Train Epoch: 64 [5520/17352 (32%)] Loss: -169002.796875\n",
      "Train Epoch: 64 [5600/17352 (32%)] Loss: -174946.687500\n",
      "Train Epoch: 64 [5680/17352 (33%)] Loss: -180023.281250\n",
      "Train Epoch: 64 [5760/17352 (33%)] Loss: -210912.750000\n",
      "Train Epoch: 64 [5840/17352 (34%)] Loss: -216395.359375\n",
      "Train Epoch: 64 [5920/17352 (34%)] Loss: -215178.953125\n",
      "Train Epoch: 64 [6000/17352 (35%)] Loss: -199415.640625\n",
      "Train Epoch: 64 [6080/17352 (35%)] Loss: -175686.046875\n",
      "Train Epoch: 64 [6160/17352 (36%)] Loss: -168073.156250\n",
      "Train Epoch: 64 [6240/17352 (36%)] Loss: -173585.328125\n",
      "Train Epoch: 64 [6320/17352 (36%)] Loss: -173661.046875\n",
      "Train Epoch: 64 [6400/17352 (37%)] Loss: -196951.500000\n",
      "Train Epoch: 64 [6480/17352 (37%)] Loss: -182732.984375\n",
      "Train Epoch: 64 [6560/17352 (38%)] Loss: -173925.093750\n",
      "Train Epoch: 64 [6640/17352 (38%)] Loss: -179735.453125\n",
      "Train Epoch: 64 [6720/17352 (39%)] Loss: -188678.343750\n",
      "Train Epoch: 64 [6800/17352 (39%)] Loss: -185272.968750\n",
      "Train Epoch: 64 [6880/17352 (40%)] Loss: -185929.640625\n",
      "Train Epoch: 64 [6960/17352 (40%)] Loss: -192947.984375\n",
      "Train Epoch: 64 [7040/17352 (41%)] Loss: -160100.781250\n",
      "Train Epoch: 64 [7120/17352 (41%)] Loss: -167244.546875\n",
      "Train Epoch: 64 [7200/17352 (41%)] Loss: -194071.968750\n",
      "Train Epoch: 64 [7280/17352 (42%)] Loss: -185827.046875\n",
      "Train Epoch: 64 [7360/17352 (42%)] Loss: -182398.421875\n",
      "Train Epoch: 64 [7440/17352 (43%)] Loss: -192899.531250\n",
      "Train Epoch: 64 [7520/17352 (43%)] Loss: -205630.375000\n",
      "Train Epoch: 64 [7600/17352 (44%)] Loss: -204343.484375\n",
      "Train Epoch: 64 [7680/17352 (44%)] Loss: -173941.125000\n",
      "Train Epoch: 64 [7760/17352 (45%)] Loss: -187132.546875\n",
      "Train Epoch: 64 [7840/17352 (45%)] Loss: -223964.578125\n",
      "Train Epoch: 64 [7920/17352 (46%)] Loss: -204999.531250\n",
      "Train Epoch: 64 [8000/17352 (46%)] Loss: -209281.171875\n",
      "Train Epoch: 64 [8080/17352 (47%)] Loss: -178309.421875\n",
      "Train Epoch: 64 [8160/17352 (47%)] Loss: -196296.843750\n",
      "Train Epoch: 64 [8240/17352 (47%)] Loss: -184761.484375\n",
      "Train Epoch: 64 [8320/17352 (48%)] Loss: -151509.093750\n",
      "Train Epoch: 64 [8400/17352 (48%)] Loss: -196192.578125\n",
      "Train Epoch: 64 [8480/17352 (49%)] Loss: -208130.796875\n",
      "Train Epoch: 64 [8560/17352 (49%)] Loss: -215412.968750\n",
      "Train Epoch: 64 [8640/17352 (50%)] Loss: -179306.906250\n",
      "Train Epoch: 64 [8720/17352 (50%)] Loss: -179018.640625\n",
      "Train Epoch: 64 [8800/17352 (51%)] Loss: -187210.906250\n",
      "Train Epoch: 64 [8880/17352 (51%)] Loss: -192233.515625\n",
      "Train Epoch: 64 [8960/17352 (52%)] Loss: -203818.234375\n",
      "Train Epoch: 64 [9040/17352 (52%)] Loss: -200268.937500\n",
      "Train Epoch: 64 [9120/17352 (53%)] Loss: -184963.375000\n",
      "Train Epoch: 64 [9200/17352 (53%)] Loss: -173440.671875\n",
      "Train Epoch: 64 [9280/17352 (53%)] Loss: -185573.796875\n",
      "Train Epoch: 64 [9360/17352 (54%)] Loss: -134540.343750\n",
      "Train Epoch: 64 [9440/17352 (54%)] Loss: -166443.515625\n",
      "Train Epoch: 64 [9520/17352 (55%)] Loss: -218464.468750\n",
      "Train Epoch: 64 [9600/17352 (55%)] Loss: -176971.421875\n",
      "Train Epoch: 64 [9680/17352 (56%)] Loss: -176925.718750\n",
      "Train Epoch: 64 [9760/17352 (56%)] Loss: -173890.906250\n",
      "Train Epoch: 64 [9840/17352 (57%)] Loss: -185593.281250\n",
      "Train Epoch: 64 [9920/17352 (57%)] Loss: -164511.937500\n",
      "Train Epoch: 64 [10000/17352 (58%)] Loss: -175402.109375\n",
      "Train Epoch: 64 [10080/17352 (58%)] Loss: -203744.859375\n",
      "Train Epoch: 64 [10160/17352 (59%)] Loss: -170243.281250\n",
      "Train Epoch: 64 [10240/17352 (59%)] Loss: -187886.328125\n",
      "Train Epoch: 64 [10320/17352 (59%)] Loss: -206096.796875\n",
      "Train Epoch: 64 [10400/17352 (60%)] Loss: -200623.234375\n",
      "Train Epoch: 64 [10480/17352 (60%)] Loss: -177200.078125\n",
      "Train Epoch: 64 [10560/17352 (61%)] Loss: -179004.546875\n",
      "Train Epoch: 64 [10640/17352 (61%)] Loss: -183370.921875\n",
      "Train Epoch: 64 [10720/17352 (62%)] Loss: -142618.234375\n",
      "Train Epoch: 64 [10800/17352 (62%)] Loss: -192318.515625\n",
      "Train Epoch: 64 [10880/17352 (63%)] Loss: -190931.187500\n",
      "Train Epoch: 64 [10960/17352 (63%)] Loss: -193506.328125\n",
      "Train Epoch: 64 [11040/17352 (64%)] Loss: -168193.031250\n",
      "Train Epoch: 64 [11120/17352 (64%)] Loss: -207827.406250\n",
      "Train Epoch: 64 [11200/17352 (65%)] Loss: -193001.015625\n",
      "Train Epoch: 64 [11280/17352 (65%)] Loss: -202581.656250\n",
      "Train Epoch: 64 [11360/17352 (65%)] Loss: -187209.453125\n",
      "Train Epoch: 64 [11440/17352 (66%)] Loss: -181420.562500\n",
      "Train Epoch: 64 [11520/17352 (66%)] Loss: -207126.718750\n",
      "Train Epoch: 64 [11600/17352 (67%)] Loss: -181891.875000\n",
      "Train Epoch: 64 [11680/17352 (67%)] Loss: -202599.328125\n",
      "Train Epoch: 64 [11760/17352 (68%)] Loss: -185002.515625\n",
      "Train Epoch: 64 [11840/17352 (68%)] Loss: -172551.281250\n",
      "Train Epoch: 64 [11920/17352 (69%)] Loss: -205403.578125\n",
      "Train Epoch: 64 [12000/17352 (69%)] Loss: -163252.156250\n",
      "Train Epoch: 64 [12080/17352 (70%)] Loss: -216322.515625\n",
      "Train Epoch: 64 [12160/17352 (70%)] Loss: -194581.437500\n",
      "Train Epoch: 64 [12240/17352 (71%)] Loss: -204697.203125\n",
      "Train Epoch: 64 [12320/17352 (71%)] Loss: -156994.062500\n",
      "Train Epoch: 64 [12400/17352 (71%)] Loss: -191805.703125\n",
      "Train Epoch: 64 [12480/17352 (72%)] Loss: -168676.531250\n",
      "Train Epoch: 64 [12560/17352 (72%)] Loss: -202868.812500\n",
      "Train Epoch: 64 [12640/17352 (73%)] Loss: -201962.921875\n",
      "Train Epoch: 64 [12720/17352 (73%)] Loss: -177252.500000\n",
      "Train Epoch: 64 [12800/17352 (74%)] Loss: -185508.750000\n",
      "Train Epoch: 64 [12880/17352 (74%)] Loss: -178659.156250\n",
      "Train Epoch: 64 [12960/17352 (75%)] Loss: -179437.390625\n",
      "Train Epoch: 64 [13040/17352 (75%)] Loss: -148925.796875\n",
      "Train Epoch: 64 [13120/17352 (76%)] Loss: -214748.000000\n",
      "Train Epoch: 64 [13200/17352 (76%)] Loss: -191358.468750\n",
      "Train Epoch: 64 [13280/17352 (77%)] Loss: -195108.062500\n",
      "Train Epoch: 64 [13360/17352 (77%)] Loss: -202180.359375\n",
      "Train Epoch: 64 [13440/17352 (77%)] Loss: -181370.609375\n",
      "Train Epoch: 64 [13520/17352 (78%)] Loss: -192369.859375\n",
      "Train Epoch: 64 [13600/17352 (78%)] Loss: -181340.906250\n",
      "Train Epoch: 64 [13680/17352 (79%)] Loss: -185393.671875\n",
      "Train Epoch: 64 [13760/17352 (79%)] Loss: -187498.218750\n",
      "Train Epoch: 64 [13840/17352 (80%)] Loss: -192645.843750\n",
      "Train Epoch: 64 [13920/17352 (80%)] Loss: -177194.953125\n",
      "Train Epoch: 64 [14000/17352 (81%)] Loss: -136431.031250\n",
      "Train Epoch: 64 [14080/17352 (81%)] Loss: -217619.484375\n",
      "Train Epoch: 64 [14160/17352 (82%)] Loss: -184919.953125\n",
      "Train Epoch: 64 [14240/17352 (82%)] Loss: -179413.437500\n",
      "Train Epoch: 64 [14320/17352 (83%)] Loss: -188448.187500\n",
      "Train Epoch: 64 [14400/17352 (83%)] Loss: -192859.234375\n",
      "Train Epoch: 64 [14480/17352 (83%)] Loss: -144989.812500\n",
      "Train Epoch: 64 [14560/17352 (84%)] Loss: -185294.500000\n",
      "Train Epoch: 64 [14640/17352 (84%)] Loss: -186846.609375\n",
      "Train Epoch: 64 [14720/17352 (85%)] Loss: -179319.359375\n",
      "Train Epoch: 64 [14800/17352 (85%)] Loss: -191165.390625\n",
      "Train Epoch: 64 [14880/17352 (86%)] Loss: -218513.546875\n",
      "Train Epoch: 64 [14960/17352 (86%)] Loss: -138334.000000\n",
      "Train Epoch: 64 [15040/17352 (87%)] Loss: -194930.328125\n",
      "Train Epoch: 64 [15120/17352 (87%)] Loss: -193367.515625\n",
      "Train Epoch: 64 [15200/17352 (88%)] Loss: -191333.750000\n",
      "Train Epoch: 64 [15280/17352 (88%)] Loss: -167222.593750\n",
      "Train Epoch: 64 [15360/17352 (89%)] Loss: -202787.062500\n",
      "Train Epoch: 64 [15440/17352 (89%)] Loss: -149446.906250\n",
      "Train Epoch: 64 [15520/17352 (89%)] Loss: -189509.500000\n",
      "Train Epoch: 64 [15600/17352 (90%)] Loss: -181692.218750\n",
      "Train Epoch: 64 [15680/17352 (90%)] Loss: -191958.406250\n",
      "Train Epoch: 64 [15760/17352 (91%)] Loss: -209266.515625\n",
      "Train Epoch: 64 [15840/17352 (91%)] Loss: -163098.781250\n",
      "Train Epoch: 64 [15920/17352 (92%)] Loss: -180137.890625\n",
      "Train Epoch: 64 [16000/17352 (92%)] Loss: -146857.796875\n",
      "Train Epoch: 64 [16080/17352 (93%)] Loss: -193005.968750\n",
      "Train Epoch: 64 [16160/17352 (93%)] Loss: -223688.156250\n",
      "Train Epoch: 64 [16240/17352 (94%)] Loss: -169611.328125\n",
      "Train Epoch: 64 [16320/17352 (94%)] Loss: -200117.875000\n",
      "Train Epoch: 64 [16400/17352 (95%)] Loss: -179896.531250\n",
      "Train Epoch: 64 [16480/17352 (95%)] Loss: -208339.843750\n",
      "Train Epoch: 64 [16560/17352 (95%)] Loss: -192266.140625\n",
      "Train Epoch: 64 [16640/17352 (96%)] Loss: -188260.218750\n",
      "Train Epoch: 64 [16720/17352 (96%)] Loss: -205692.843750\n",
      "Train Epoch: 64 [16800/17352 (97%)] Loss: -187270.078125\n",
      "Train Epoch: 64 [16880/17352 (97%)] Loss: -191235.500000\n",
      "Train Epoch: 64 [16960/17352 (98%)] Loss: -184172.593750\n",
      "Train Epoch: 64 [17040/17352 (98%)] Loss: -199008.546875\n",
      "Train Epoch: 64 [17120/17352 (99%)] Loss: -161684.296875\n",
      "Train Epoch: 64 [17200/17352 (99%)] Loss: -156473.953125\n",
      "Train Epoch: 64 [17280/17352 (100%)] Loss: -192175.093750\n",
      "Train Epoch: 64 [17360/17352 (100%)] Loss: -177178.843750\n",
      "    epoch          : 64\n",
      "    loss           : -189246.9670688291\n",
      "    val_loss       : -23716.154634932398\n",
      "Train Epoch: 65 [0/17352 (0%)] Loss: -214459.890625\n",
      "Train Epoch: 65 [80/17352 (0%)] Loss: -216099.062500\n",
      "Train Epoch: 65 [160/17352 (1%)] Loss: -212177.906250\n",
      "Train Epoch: 65 [240/17352 (1%)] Loss: -206139.343750\n",
      "Train Epoch: 65 [320/17352 (2%)] Loss: -217935.093750\n",
      "Train Epoch: 65 [400/17352 (2%)] Loss: -205559.375000\n",
      "Train Epoch: 65 [480/17352 (3%)] Loss: -212389.031250\n",
      "Train Epoch: 65 [560/17352 (3%)] Loss: -236509.734375\n",
      "Train Epoch: 65 [640/17352 (4%)] Loss: -209773.250000\n",
      "Train Epoch: 65 [720/17352 (4%)] Loss: -204534.593750\n",
      "Train Epoch: 65 [800/17352 (5%)] Loss: -214704.828125\n",
      "Train Epoch: 65 [880/17352 (5%)] Loss: -202033.734375\n",
      "Train Epoch: 65 [960/17352 (6%)] Loss: -187717.390625\n",
      "Train Epoch: 65 [1040/17352 (6%)] Loss: -203750.156250\n",
      "Train Epoch: 65 [1120/17352 (6%)] Loss: -235584.218750\n",
      "Train Epoch: 65 [1200/17352 (7%)] Loss: -199925.984375\n",
      "Train Epoch: 65 [1280/17352 (7%)] Loss: -228016.718750\n",
      "Train Epoch: 65 [1360/17352 (8%)] Loss: -217580.218750\n",
      "Train Epoch: 65 [1440/17352 (8%)] Loss: -196927.609375\n",
      "Train Epoch: 65 [1520/17352 (9%)] Loss: -230191.781250\n",
      "Train Epoch: 65 [1600/17352 (9%)] Loss: -224355.937500\n",
      "Train Epoch: 65 [1680/17352 (10%)] Loss: -206562.437500\n",
      "Train Epoch: 65 [1760/17352 (10%)] Loss: -206794.734375\n",
      "Train Epoch: 65 [1840/17352 (11%)] Loss: -198111.718750\n",
      "Train Epoch: 65 [1920/17352 (11%)] Loss: -214337.015625\n",
      "Train Epoch: 65 [2000/17352 (12%)] Loss: -219199.625000\n",
      "Train Epoch: 65 [2080/17352 (12%)] Loss: -210526.906250\n",
      "Train Epoch: 65 [2160/17352 (12%)] Loss: -214425.484375\n",
      "Train Epoch: 65 [2240/17352 (13%)] Loss: -165997.187500\n",
      "Train Epoch: 65 [2320/17352 (13%)] Loss: -197105.468750\n",
      "Train Epoch: 65 [2400/17352 (14%)] Loss: -185576.781250\n",
      "Train Epoch: 65 [2480/17352 (14%)] Loss: -170776.265625\n",
      "Train Epoch: 65 [2560/17352 (15%)] Loss: -210789.843750\n",
      "Train Epoch: 65 [2640/17352 (15%)] Loss: -205216.250000\n",
      "Train Epoch: 65 [2720/17352 (16%)] Loss: -179169.125000\n",
      "Train Epoch: 65 [2800/17352 (16%)] Loss: -200636.796875\n",
      "Train Epoch: 65 [2880/17352 (17%)] Loss: -192996.234375\n",
      "Train Epoch: 65 [2960/17352 (17%)] Loss: -204624.062500\n",
      "Train Epoch: 65 [3040/17352 (18%)] Loss: -162716.656250\n",
      "Train Epoch: 65 [3120/17352 (18%)] Loss: -160103.515625\n",
      "Train Epoch: 65 [3200/17352 (18%)] Loss: -146000.625000\n",
      "Train Epoch: 65 [3280/17352 (19%)] Loss: -188900.296875\n",
      "Train Epoch: 65 [3360/17352 (19%)] Loss: -181735.671875\n",
      "Train Epoch: 65 [3440/17352 (20%)] Loss: -176059.781250\n",
      "Train Epoch: 65 [3520/17352 (20%)] Loss: -184737.703125\n",
      "Train Epoch: 65 [3600/17352 (21%)] Loss: -175665.859375\n",
      "Train Epoch: 65 [3680/17352 (21%)] Loss: -167954.203125\n",
      "Train Epoch: 65 [3760/17352 (22%)] Loss: -170784.375000\n",
      "Train Epoch: 65 [3840/17352 (22%)] Loss: -183064.781250\n",
      "Train Epoch: 65 [3920/17352 (23%)] Loss: -177147.609375\n",
      "Train Epoch: 65 [4000/17352 (23%)] Loss: -179482.546875\n",
      "Train Epoch: 65 [4080/17352 (24%)] Loss: -187451.468750\n",
      "Train Epoch: 65 [4160/17352 (24%)] Loss: -209189.421875\n",
      "Train Epoch: 65 [4240/17352 (24%)] Loss: -191958.984375\n",
      "Train Epoch: 65 [4320/17352 (25%)] Loss: -95258.093750\n",
      "Train Epoch: 65 [4400/17352 (25%)] Loss: -187717.890625\n",
      "Train Epoch: 65 [4480/17352 (26%)] Loss: -198308.031250\n",
      "Train Epoch: 65 [4560/17352 (26%)] Loss: -196289.703125\n",
      "Train Epoch: 65 [4640/17352 (27%)] Loss: -181009.937500\n",
      "Train Epoch: 65 [4720/17352 (27%)] Loss: -167249.218750\n",
      "Train Epoch: 65 [4800/17352 (28%)] Loss: -187270.093750\n",
      "Train Epoch: 65 [4880/17352 (28%)] Loss: -190798.390625\n",
      "Train Epoch: 65 [4960/17352 (29%)] Loss: -187400.406250\n",
      "Train Epoch: 65 [5040/17352 (29%)] Loss: -199003.546875\n",
      "Train Epoch: 65 [5120/17352 (30%)] Loss: -181009.796875\n",
      "Train Epoch: 65 [5200/17352 (30%)] Loss: -165739.203125\n",
      "Train Epoch: 65 [5280/17352 (30%)] Loss: -175209.640625\n",
      "Train Epoch: 65 [5360/17352 (31%)] Loss: -208308.765625\n",
      "Train Epoch: 65 [5440/17352 (31%)] Loss: -197082.531250\n",
      "Train Epoch: 65 [5520/17352 (32%)] Loss: -183778.968750\n",
      "Train Epoch: 65 [5600/17352 (32%)] Loss: -156614.859375\n",
      "Train Epoch: 65 [5680/17352 (33%)] Loss: -167802.078125\n",
      "Train Epoch: 65 [5760/17352 (33%)] Loss: -185827.937500\n",
      "Train Epoch: 65 [5840/17352 (34%)] Loss: -178214.171875\n",
      "Train Epoch: 65 [5920/17352 (34%)] Loss: -208041.421875\n",
      "Train Epoch: 65 [6000/17352 (35%)] Loss: -211724.125000\n",
      "Train Epoch: 65 [6080/17352 (35%)] Loss: -181917.750000\n",
      "Train Epoch: 65 [6160/17352 (36%)] Loss: -196126.187500\n",
      "Train Epoch: 65 [6240/17352 (36%)] Loss: -179966.859375\n",
      "Train Epoch: 65 [6320/17352 (36%)] Loss: -180753.218750\n",
      "Train Epoch: 65 [6400/17352 (37%)] Loss: -180146.265625\n",
      "Train Epoch: 65 [6480/17352 (37%)] Loss: -209269.921875\n",
      "Train Epoch: 65 [6560/17352 (38%)] Loss: -173939.296875\n",
      "Train Epoch: 65 [6640/17352 (38%)] Loss: -187319.359375\n",
      "Train Epoch: 65 [6720/17352 (39%)] Loss: -184836.828125\n",
      "Train Epoch: 65 [6800/17352 (39%)] Loss: -190585.296875\n",
      "Train Epoch: 65 [6880/17352 (40%)] Loss: -193506.546875\n",
      "Train Epoch: 65 [6960/17352 (40%)] Loss: -191687.781250\n",
      "Train Epoch: 65 [7040/17352 (41%)] Loss: -159095.781250\n",
      "Train Epoch: 65 [7120/17352 (41%)] Loss: -201519.640625\n",
      "Train Epoch: 65 [7200/17352 (41%)] Loss: -202938.312500\n",
      "Train Epoch: 65 [7280/17352 (42%)] Loss: -165806.109375\n",
      "Train Epoch: 65 [7360/17352 (42%)] Loss: -170239.312500\n",
      "Train Epoch: 65 [7440/17352 (43%)] Loss: -188500.828125\n",
      "Train Epoch: 65 [7520/17352 (43%)] Loss: -167865.250000\n",
      "Train Epoch: 65 [7600/17352 (44%)] Loss: -183609.578125\n",
      "Train Epoch: 65 [7680/17352 (44%)] Loss: -192887.312500\n",
      "Train Epoch: 65 [7760/17352 (45%)] Loss: -182681.843750\n",
      "Train Epoch: 65 [7840/17352 (45%)] Loss: -208015.968750\n",
      "Train Epoch: 65 [7920/17352 (46%)] Loss: -173840.031250\n",
      "Train Epoch: 65 [8000/17352 (46%)] Loss: -188049.671875\n",
      "Train Epoch: 65 [8080/17352 (47%)] Loss: -180117.906250\n",
      "Train Epoch: 65 [8160/17352 (47%)] Loss: -175396.171875\n",
      "Train Epoch: 65 [8240/17352 (47%)] Loss: -198297.000000\n",
      "Train Epoch: 65 [8320/17352 (48%)] Loss: -185995.718750\n",
      "Train Epoch: 65 [8400/17352 (48%)] Loss: -201387.890625\n",
      "Train Epoch: 65 [8480/17352 (49%)] Loss: -203144.796875\n",
      "Train Epoch: 65 [8560/17352 (49%)] Loss: -196509.328125\n",
      "Train Epoch: 65 [8640/17352 (50%)] Loss: -196040.468750\n",
      "Train Epoch: 65 [8720/17352 (50%)] Loss: -188083.187500\n",
      "Train Epoch: 65 [8800/17352 (51%)] Loss: -197516.718750\n",
      "Train Epoch: 65 [8880/17352 (51%)] Loss: -171839.765625\n",
      "Train Epoch: 65 [8960/17352 (52%)] Loss: -179312.718750\n",
      "Train Epoch: 65 [9040/17352 (52%)] Loss: -202598.140625\n",
      "Train Epoch: 65 [9120/17352 (53%)] Loss: -163493.500000\n",
      "Train Epoch: 65 [9200/17352 (53%)] Loss: -207833.671875\n",
      "Train Epoch: 65 [9280/17352 (53%)] Loss: -164371.171875\n",
      "Train Epoch: 65 [9360/17352 (54%)] Loss: -200331.296875\n",
      "Train Epoch: 65 [9440/17352 (54%)] Loss: -166794.093750\n",
      "Train Epoch: 65 [9520/17352 (55%)] Loss: -168964.593750\n",
      "Train Epoch: 65 [9600/17352 (55%)] Loss: -193367.640625\n",
      "Train Epoch: 65 [9680/17352 (56%)] Loss: -177315.671875\n",
      "Train Epoch: 65 [9760/17352 (56%)] Loss: -183797.828125\n",
      "Train Epoch: 65 [9840/17352 (57%)] Loss: -197345.937500\n",
      "Train Epoch: 65 [9920/17352 (57%)] Loss: -158605.953125\n",
      "Train Epoch: 65 [10000/17352 (58%)] Loss: -192287.250000\n",
      "Train Epoch: 65 [10080/17352 (58%)] Loss: -187641.234375\n",
      "Train Epoch: 65 [10160/17352 (59%)] Loss: -175319.359375\n",
      "Train Epoch: 65 [10240/17352 (59%)] Loss: -211161.375000\n",
      "Train Epoch: 65 [10320/17352 (59%)] Loss: -174992.796875\n",
      "Train Epoch: 65 [10400/17352 (60%)] Loss: -208153.500000\n",
      "Train Epoch: 65 [10480/17352 (60%)] Loss: -209509.640625\n",
      "Train Epoch: 65 [10560/17352 (61%)] Loss: -184484.109375\n",
      "Train Epoch: 65 [10640/17352 (61%)] Loss: -180258.843750\n",
      "Train Epoch: 65 [10720/17352 (62%)] Loss: -208723.093750\n",
      "Train Epoch: 65 [10800/17352 (62%)] Loss: -169503.359375\n",
      "Train Epoch: 65 [10880/17352 (63%)] Loss: -193139.671875\n",
      "Train Epoch: 65 [10960/17352 (63%)] Loss: -168503.171875\n",
      "Train Epoch: 65 [11040/17352 (64%)] Loss: -181428.140625\n",
      "Train Epoch: 65 [11120/17352 (64%)] Loss: -191966.500000\n",
      "Train Epoch: 65 [11200/17352 (65%)] Loss: -174938.312500\n",
      "Train Epoch: 65 [11280/17352 (65%)] Loss: -192375.390625\n",
      "Train Epoch: 65 [11360/17352 (65%)] Loss: -173451.093750\n",
      "Train Epoch: 65 [11440/17352 (66%)] Loss: -189602.531250\n",
      "Train Epoch: 65 [11520/17352 (66%)] Loss: -207090.953125\n",
      "Train Epoch: 65 [11600/17352 (67%)] Loss: -196159.265625\n",
      "Train Epoch: 65 [11680/17352 (67%)] Loss: -195101.812500\n",
      "Train Epoch: 65 [11760/17352 (68%)] Loss: -177606.187500\n",
      "Train Epoch: 65 [11840/17352 (68%)] Loss: -185549.921875\n",
      "Train Epoch: 65 [11920/17352 (69%)] Loss: -154598.171875\n",
      "Train Epoch: 65 [12000/17352 (69%)] Loss: -198015.093750\n",
      "Train Epoch: 65 [12080/17352 (70%)] Loss: -178873.140625\n",
      "Train Epoch: 65 [12160/17352 (70%)] Loss: -155861.234375\n",
      "Train Epoch: 65 [12240/17352 (71%)] Loss: -205168.281250\n",
      "Train Epoch: 65 [12320/17352 (71%)] Loss: -199454.953125\n",
      "Train Epoch: 65 [12400/17352 (71%)] Loss: -172889.156250\n",
      "Train Epoch: 65 [12480/17352 (72%)] Loss: -185044.531250\n",
      "Train Epoch: 65 [12560/17352 (72%)] Loss: -222861.625000\n",
      "Train Epoch: 65 [12640/17352 (73%)] Loss: -190918.328125\n",
      "Train Epoch: 65 [12720/17352 (73%)] Loss: -187523.765625\n",
      "Train Epoch: 65 [12800/17352 (74%)] Loss: -199146.968750\n",
      "Train Epoch: 65 [12880/17352 (74%)] Loss: -180908.656250\n",
      "Train Epoch: 65 [12960/17352 (75%)] Loss: -187620.375000\n",
      "Train Epoch: 65 [13040/17352 (75%)] Loss: -203479.546875\n",
      "Train Epoch: 65 [13120/17352 (76%)] Loss: -184843.062500\n",
      "Train Epoch: 65 [13200/17352 (76%)] Loss: -180024.937500\n",
      "Train Epoch: 65 [13280/17352 (77%)] Loss: -163776.000000\n",
      "Train Epoch: 65 [13360/17352 (77%)] Loss: -190501.312500\n",
      "Train Epoch: 65 [13440/17352 (77%)] Loss: -189022.031250\n",
      "Train Epoch: 65 [13520/17352 (78%)] Loss: -196128.078125\n",
      "Train Epoch: 65 [13600/17352 (78%)] Loss: -203876.015625\n",
      "Train Epoch: 65 [13680/17352 (79%)] Loss: -148925.468750\n",
      "Train Epoch: 65 [13760/17352 (79%)] Loss: -186782.515625\n",
      "Train Epoch: 65 [13840/17352 (80%)] Loss: -191507.859375\n",
      "Train Epoch: 65 [13920/17352 (80%)] Loss: -177302.000000\n",
      "Train Epoch: 65 [14000/17352 (81%)] Loss: -209412.546875\n",
      "Train Epoch: 65 [14080/17352 (81%)] Loss: -199175.750000\n",
      "Train Epoch: 65 [14160/17352 (82%)] Loss: -185062.031250\n",
      "Train Epoch: 65 [14240/17352 (82%)] Loss: -159318.859375\n",
      "Train Epoch: 65 [14320/17352 (83%)] Loss: -200485.375000\n",
      "Train Epoch: 65 [14400/17352 (83%)] Loss: -183371.859375\n",
      "Train Epoch: 65 [14480/17352 (83%)] Loss: -178641.375000\n",
      "Train Epoch: 65 [14560/17352 (84%)] Loss: -169949.781250\n",
      "Train Epoch: 65 [14640/17352 (84%)] Loss: -184073.109375\n",
      "Train Epoch: 65 [14720/17352 (85%)] Loss: -189503.750000\n",
      "Train Epoch: 65 [14800/17352 (85%)] Loss: -157771.546875\n",
      "Train Epoch: 65 [14880/17352 (86%)] Loss: -181962.171875\n",
      "Train Epoch: 65 [14960/17352 (86%)] Loss: -213748.718750\n",
      "Train Epoch: 65 [15040/17352 (87%)] Loss: -204600.531250\n",
      "Train Epoch: 65 [15120/17352 (87%)] Loss: -175013.718750\n",
      "Train Epoch: 65 [15200/17352 (88%)] Loss: -164957.000000\n",
      "Train Epoch: 65 [15280/17352 (88%)] Loss: -195062.187500\n",
      "Train Epoch: 65 [15360/17352 (89%)] Loss: -201968.218750\n",
      "Train Epoch: 65 [15440/17352 (89%)] Loss: -176680.921875\n",
      "Train Epoch: 65 [15520/17352 (89%)] Loss: -182737.453125\n",
      "Train Epoch: 65 [15600/17352 (90%)] Loss: -198825.968750\n",
      "Train Epoch: 65 [15680/17352 (90%)] Loss: -183167.718750\n",
      "Train Epoch: 65 [15760/17352 (91%)] Loss: -203880.812500\n",
      "Train Epoch: 65 [15840/17352 (91%)] Loss: -189215.453125\n",
      "Train Epoch: 65 [15920/17352 (92%)] Loss: -185796.093750\n",
      "Train Epoch: 65 [16000/17352 (92%)] Loss: -217600.796875\n",
      "Train Epoch: 65 [16080/17352 (93%)] Loss: -227889.218750\n",
      "Train Epoch: 65 [16160/17352 (93%)] Loss: -203883.734375\n",
      "Train Epoch: 65 [16240/17352 (94%)] Loss: -167301.937500\n",
      "Train Epoch: 65 [16320/17352 (94%)] Loss: -220012.843750\n",
      "Train Epoch: 65 [16400/17352 (95%)] Loss: -180541.921875\n",
      "Train Epoch: 65 [16480/17352 (95%)] Loss: -182325.421875\n",
      "Train Epoch: 65 [16560/17352 (95%)] Loss: -166516.093750\n",
      "Train Epoch: 65 [16640/17352 (96%)] Loss: -225327.734375\n",
      "Train Epoch: 65 [16720/17352 (96%)] Loss: -164828.000000\n",
      "Train Epoch: 65 [16800/17352 (97%)] Loss: -176534.812500\n",
      "Train Epoch: 65 [16880/17352 (97%)] Loss: -178737.156250\n",
      "Train Epoch: 65 [16960/17352 (98%)] Loss: -189170.312500\n",
      "Train Epoch: 65 [17040/17352 (98%)] Loss: -183729.343750\n",
      "Train Epoch: 65 [17120/17352 (99%)] Loss: -205001.078125\n",
      "Train Epoch: 65 [17200/17352 (99%)] Loss: -196703.218750\n",
      "Train Epoch: 65 [17280/17352 (100%)] Loss: -173296.203125\n",
      "Train Epoch: 65 [17360/17352 (100%)] Loss: -218404.421875\n",
      "    epoch          : 65\n",
      "    loss           : -189306.93183616226\n",
      "    val_loss       : -23716.142331405426\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch65.pth ...\n",
      "Train Epoch: 66 [0/17352 (0%)] Loss: -205207.140625\n",
      "Train Epoch: 66 [80/17352 (0%)] Loss: -216211.453125\n",
      "Train Epoch: 66 [160/17352 (1%)] Loss: -194292.578125\n",
      "Train Epoch: 66 [240/17352 (1%)] Loss: -193585.828125\n",
      "Train Epoch: 66 [320/17352 (2%)] Loss: -185150.078125\n",
      "Train Epoch: 66 [400/17352 (2%)] Loss: -221771.468750\n",
      "Train Epoch: 66 [480/17352 (3%)] Loss: -214457.812500\n",
      "Train Epoch: 66 [560/17352 (3%)] Loss: -218533.093750\n",
      "Train Epoch: 66 [640/17352 (4%)] Loss: -191883.140625\n",
      "Train Epoch: 66 [720/17352 (4%)] Loss: -215097.593750\n",
      "Train Epoch: 66 [800/17352 (5%)] Loss: -206747.750000\n",
      "Train Epoch: 66 [880/17352 (5%)] Loss: -205110.687500\n",
      "Train Epoch: 66 [960/17352 (6%)] Loss: -208530.937500\n",
      "Train Epoch: 66 [1040/17352 (6%)] Loss: -203270.828125\n",
      "Train Epoch: 66 [1120/17352 (6%)] Loss: -193715.234375\n",
      "Train Epoch: 66 [1200/17352 (7%)] Loss: -196925.562500\n",
      "Train Epoch: 66 [1280/17352 (7%)] Loss: -213338.500000\n",
      "Train Epoch: 66 [1360/17352 (8%)] Loss: -185294.734375\n",
      "Train Epoch: 66 [1440/17352 (8%)] Loss: -236636.593750\n",
      "Train Epoch: 66 [1520/17352 (9%)] Loss: -199807.953125\n",
      "Train Epoch: 66 [1600/17352 (9%)] Loss: -203751.265625\n",
      "Train Epoch: 66 [1680/17352 (10%)] Loss: -212373.140625\n",
      "Train Epoch: 66 [1760/17352 (10%)] Loss: -187726.109375\n",
      "Train Epoch: 66 [1840/17352 (11%)] Loss: -204730.843750\n",
      "Train Epoch: 66 [1920/17352 (11%)] Loss: -198765.515625\n",
      "Train Epoch: 66 [2000/17352 (12%)] Loss: -198117.812500\n",
      "Train Epoch: 66 [2080/17352 (12%)] Loss: -182772.890625\n",
      "Train Epoch: 66 [2160/17352 (12%)] Loss: -205188.812500\n",
      "Train Epoch: 66 [2240/17352 (13%)] Loss: -178666.078125\n",
      "Train Epoch: 66 [2320/17352 (13%)] Loss: -180257.312500\n",
      "Train Epoch: 66 [2400/17352 (14%)] Loss: -180692.000000\n",
      "Train Epoch: 66 [2480/17352 (14%)] Loss: -181956.218750\n",
      "Train Epoch: 66 [2560/17352 (15%)] Loss: -188498.687500\n",
      "Train Epoch: 66 [2640/17352 (15%)] Loss: -205685.453125\n",
      "Train Epoch: 66 [2720/17352 (16%)] Loss: -163210.562500\n",
      "Train Epoch: 66 [2800/17352 (16%)] Loss: -191344.375000\n",
      "Train Epoch: 66 [2880/17352 (17%)] Loss: -162566.265625\n",
      "Train Epoch: 66 [2960/17352 (17%)] Loss: -171191.796875\n",
      "Train Epoch: 66 [3040/17352 (18%)] Loss: -225472.500000\n",
      "Train Epoch: 66 [3120/17352 (18%)] Loss: -180310.187500\n",
      "Train Epoch: 66 [3200/17352 (18%)] Loss: -220969.343750\n",
      "Train Epoch: 66 [3280/17352 (19%)] Loss: -197438.500000\n",
      "Train Epoch: 66 [3360/17352 (19%)] Loss: -183913.921875\n",
      "Train Epoch: 66 [3440/17352 (20%)] Loss: -201375.843750\n",
      "Train Epoch: 66 [3520/17352 (20%)] Loss: -194232.578125\n",
      "Train Epoch: 66 [3600/17352 (21%)] Loss: -165676.937500\n",
      "Train Epoch: 66 [3680/17352 (21%)] Loss: -176151.234375\n",
      "Train Epoch: 66 [3760/17352 (22%)] Loss: -179481.140625\n",
      "Train Epoch: 66 [3840/17352 (22%)] Loss: -202237.437500\n",
      "Train Epoch: 66 [3920/17352 (23%)] Loss: -210492.687500\n",
      "Train Epoch: 66 [4000/17352 (23%)] Loss: -209597.843750\n",
      "Train Epoch: 66 [4080/17352 (24%)] Loss: -173581.187500\n",
      "Train Epoch: 66 [4160/17352 (24%)] Loss: -197592.843750\n",
      "Train Epoch: 66 [4240/17352 (24%)] Loss: -179384.109375\n",
      "Train Epoch: 66 [4320/17352 (25%)] Loss: -209202.250000\n",
      "Train Epoch: 66 [4400/17352 (25%)] Loss: -188263.468750\n",
      "Train Epoch: 66 [4480/17352 (26%)] Loss: -192994.281250\n",
      "Train Epoch: 66 [4560/17352 (26%)] Loss: -203875.546875\n",
      "Train Epoch: 66 [4640/17352 (27%)] Loss: -177249.343750\n",
      "Train Epoch: 66 [4720/17352 (27%)] Loss: -174184.437500\n",
      "Train Epoch: 66 [4800/17352 (28%)] Loss: -174458.109375\n",
      "Train Epoch: 66 [4880/17352 (28%)] Loss: -216399.703125\n",
      "Train Epoch: 66 [4960/17352 (29%)] Loss: -186516.093750\n",
      "Train Epoch: 66 [5040/17352 (29%)] Loss: -193200.828125\n",
      "Train Epoch: 66 [5120/17352 (30%)] Loss: -196704.640625\n",
      "Train Epoch: 66 [5200/17352 (30%)] Loss: -197089.796875\n",
      "Train Epoch: 66 [5280/17352 (30%)] Loss: -173662.093750\n",
      "Train Epoch: 66 [5360/17352 (31%)] Loss: -193175.718750\n",
      "Train Epoch: 66 [5440/17352 (31%)] Loss: -178873.890625\n",
      "Train Epoch: 66 [5520/17352 (32%)] Loss: -164071.921875\n",
      "Train Epoch: 66 [5600/17352 (32%)] Loss: -190939.140625\n",
      "Train Epoch: 66 [5680/17352 (33%)] Loss: -183791.109375\n",
      "Train Epoch: 66 [5760/17352 (33%)] Loss: -187240.187500\n",
      "Train Epoch: 66 [5840/17352 (34%)] Loss: -187532.484375\n",
      "Train Epoch: 66 [5920/17352 (34%)] Loss: -194955.062500\n",
      "Train Epoch: 66 [6000/17352 (35%)] Loss: -193438.031250\n",
      "Train Epoch: 66 [6080/17352 (35%)] Loss: -174136.984375\n",
      "Train Epoch: 66 [6160/17352 (36%)] Loss: -193538.906250\n",
      "Train Epoch: 66 [6240/17352 (36%)] Loss: -190619.375000\n",
      "Train Epoch: 66 [6320/17352 (36%)] Loss: -181918.593750\n",
      "Train Epoch: 66 [6400/17352 (37%)] Loss: -188902.328125\n",
      "Train Epoch: 66 [6480/17352 (37%)] Loss: -185173.640625\n",
      "Train Epoch: 66 [6560/17352 (38%)] Loss: -147423.937500\n",
      "Train Epoch: 66 [6640/17352 (38%)] Loss: -181982.656250\n",
      "Train Epoch: 66 [6720/17352 (39%)] Loss: -201362.281250\n",
      "Train Epoch: 66 [6800/17352 (39%)] Loss: -178805.093750\n",
      "Train Epoch: 66 [6880/17352 (40%)] Loss: -184496.953125\n",
      "Train Epoch: 66 [6960/17352 (40%)] Loss: -228099.109375\n",
      "Train Epoch: 66 [7040/17352 (41%)] Loss: -163770.671875\n",
      "Train Epoch: 66 [7120/17352 (41%)] Loss: -220009.609375\n",
      "Train Epoch: 66 [7200/17352 (41%)] Loss: -193097.906250\n",
      "Train Epoch: 66 [7280/17352 (42%)] Loss: -184274.421875\n",
      "Train Epoch: 66 [7360/17352 (42%)] Loss: -210793.296875\n",
      "Train Epoch: 66 [7440/17352 (43%)] Loss: -148446.593750\n",
      "Train Epoch: 66 [7520/17352 (43%)] Loss: -175692.171875\n",
      "Train Epoch: 66 [7600/17352 (44%)] Loss: -205002.578125\n",
      "Train Epoch: 66 [7680/17352 (44%)] Loss: -159604.937500\n",
      "Train Epoch: 66 [7760/17352 (45%)] Loss: -196947.453125\n",
      "Train Epoch: 66 [7840/17352 (45%)] Loss: -184761.593750\n",
      "Train Epoch: 66 [7920/17352 (46%)] Loss: -183407.125000\n",
      "Train Epoch: 66 [8000/17352 (46%)] Loss: -170684.250000\n",
      "Train Epoch: 66 [8080/17352 (47%)] Loss: -203270.890625\n",
      "Train Epoch: 66 [8160/17352 (47%)] Loss: -198015.406250\n",
      "Train Epoch: 66 [8240/17352 (47%)] Loss: -205024.968750\n",
      "Train Epoch: 66 [8320/17352 (48%)] Loss: -183059.687500\n",
      "Train Epoch: 66 [8400/17352 (48%)] Loss: -208017.343750\n",
      "Train Epoch: 66 [8480/17352 (49%)] Loss: -201836.109375\n",
      "Train Epoch: 66 [8560/17352 (49%)] Loss: -200072.734375\n",
      "Train Epoch: 66 [8640/17352 (50%)] Loss: -193915.578125\n",
      "Train Epoch: 66 [8720/17352 (50%)] Loss: -183926.609375\n",
      "Train Epoch: 66 [8800/17352 (51%)] Loss: -171836.000000\n",
      "Train Epoch: 66 [8880/17352 (51%)] Loss: -176919.468750\n",
      "Train Epoch: 66 [8960/17352 (52%)] Loss: -191951.109375\n",
      "Train Epoch: 66 [9040/17352 (52%)] Loss: -193052.296875\n",
      "Train Epoch: 66 [9120/17352 (53%)] Loss: -197542.718750\n",
      "Train Epoch: 66 [9200/17352 (53%)] Loss: -170315.781250\n",
      "Train Epoch: 66 [9280/17352 (53%)] Loss: -157491.312500\n",
      "Train Epoch: 66 [9360/17352 (54%)] Loss: -186032.203125\n",
      "Train Epoch: 66 [9440/17352 (54%)] Loss: -182398.703125\n",
      "Train Epoch: 66 [9520/17352 (55%)] Loss: -206925.953125\n",
      "Train Epoch: 66 [9600/17352 (55%)] Loss: -148923.671875\n",
      "Train Epoch: 66 [9680/17352 (56%)] Loss: -218469.484375\n",
      "Train Epoch: 66 [9760/17352 (56%)] Loss: -168051.531250\n",
      "Train Epoch: 66 [9840/17352 (57%)] Loss: -201520.968750\n",
      "Train Epoch: 66 [9920/17352 (57%)] Loss: -171441.343750\n",
      "Train Epoch: 66 [10000/17352 (58%)] Loss: -177302.078125\n",
      "Train Epoch: 66 [10080/17352 (58%)] Loss: -223963.187500\n",
      "Train Epoch: 66 [10160/17352 (59%)] Loss: -190497.765625\n",
      "Train Epoch: 66 [10240/17352 (59%)] Loss: -164749.281250\n",
      "Train Epoch: 66 [10320/17352 (59%)] Loss: -205400.984375\n",
      "Train Epoch: 66 [10400/17352 (60%)] Loss: -189598.687500\n",
      "Train Epoch: 66 [10480/17352 (60%)] Loss: -185323.906250\n",
      "Train Epoch: 66 [10560/17352 (61%)] Loss: -186044.703125\n",
      "Train Epoch: 66 [10640/17352 (61%)] Loss: -198001.218750\n",
      "Train Epoch: 66 [10720/17352 (62%)] Loss: -195646.140625\n",
      "Train Epoch: 66 [10800/17352 (62%)] Loss: -195829.750000\n",
      "Train Epoch: 66 [10880/17352 (63%)] Loss: -185508.765625\n",
      "Train Epoch: 66 [10960/17352 (63%)] Loss: -177972.687500\n",
      "Train Epoch: 66 [11040/17352 (64%)] Loss: -199776.281250\n",
      "Train Epoch: 66 [11120/17352 (64%)] Loss: -173363.234375\n",
      "Train Epoch: 66 [11200/17352 (65%)] Loss: -175420.296875\n",
      "Train Epoch: 66 [11280/17352 (65%)] Loss: -187885.468750\n",
      "Train Epoch: 66 [11360/17352 (65%)] Loss: -192751.453125\n",
      "Train Epoch: 66 [11440/17352 (66%)] Loss: -177308.046875\n",
      "Train Epoch: 66 [11520/17352 (66%)] Loss: -196562.265625\n",
      "Train Epoch: 66 [11600/17352 (67%)] Loss: -186687.500000\n",
      "Train Epoch: 66 [11680/17352 (67%)] Loss: -215414.078125\n",
      "Train Epoch: 66 [11760/17352 (68%)] Loss: -199593.031250\n",
      "Train Epoch: 66 [11840/17352 (68%)] Loss: -196154.734375\n",
      "Train Epoch: 66 [11920/17352 (69%)] Loss: -191006.484375\n",
      "Train Epoch: 66 [12000/17352 (69%)] Loss: -164685.796875\n",
      "Train Epoch: 66 [12080/17352 (70%)] Loss: -187403.046875\n",
      "Train Epoch: 66 [12160/17352 (70%)] Loss: -179895.375000\n",
      "Train Epoch: 66 [12240/17352 (71%)] Loss: -209186.312500\n",
      "Train Epoch: 66 [12320/17352 (71%)] Loss: -168256.078125\n",
      "Train Epoch: 66 [12400/17352 (71%)] Loss: -200170.312500\n",
      "Train Epoch: 66 [12480/17352 (72%)] Loss: -166025.250000\n",
      "Train Epoch: 66 [12560/17352 (72%)] Loss: -221249.093750\n",
      "Train Epoch: 66 [12640/17352 (73%)] Loss: -183609.718750\n",
      "Train Epoch: 66 [12720/17352 (73%)] Loss: -198707.812500\n",
      "Train Epoch: 66 [12800/17352 (74%)] Loss: -195509.828125\n",
      "Train Epoch: 66 [12880/17352 (74%)] Loss: -200829.468750\n",
      "Train Epoch: 66 [12960/17352 (75%)] Loss: -202015.609375\n",
      "Train Epoch: 66 [13040/17352 (75%)] Loss: -151221.578125\n",
      "Train Epoch: 66 [13120/17352 (76%)] Loss: -151510.984375\n",
      "Train Epoch: 66 [13200/17352 (76%)] Loss: -183291.000000\n",
      "Train Epoch: 66 [13280/17352 (77%)] Loss: -189480.437500\n",
      "Train Epoch: 66 [13360/17352 (77%)] Loss: -184030.125000\n",
      "Train Epoch: 66 [13440/17352 (77%)] Loss: -184848.000000\n",
      "Train Epoch: 66 [13520/17352 (78%)] Loss: -162968.906250\n",
      "Train Epoch: 66 [13600/17352 (78%)] Loss: -178310.921875\n",
      "Train Epoch: 66 [13680/17352 (79%)] Loss: -200331.984375\n",
      "Train Epoch: 66 [13760/17352 (79%)] Loss: -204365.734375\n",
      "Train Epoch: 66 [13840/17352 (80%)] Loss: -177236.421875\n",
      "Train Epoch: 66 [13920/17352 (80%)] Loss: -196932.343750\n",
      "Train Epoch: 66 [14000/17352 (81%)] Loss: -219924.593750\n",
      "Train Epoch: 66 [14080/17352 (81%)] Loss: -168079.828125\n",
      "Train Epoch: 66 [14160/17352 (82%)] Loss: -208752.906250\n",
      "Train Epoch: 66 [14240/17352 (82%)] Loss: -213396.890625\n",
      "Train Epoch: 66 [14320/17352 (83%)] Loss: -188754.937500\n",
      "Train Epoch: 66 [14400/17352 (83%)] Loss: -189598.609375\n",
      "Train Epoch: 66 [14480/17352 (83%)] Loss: -173945.562500\n",
      "Train Epoch: 66 [14560/17352 (84%)] Loss: -181331.406250\n",
      "Train Epoch: 66 [14640/17352 (84%)] Loss: -200977.031250\n",
      "Train Epoch: 66 [14720/17352 (85%)] Loss: -193052.125000\n",
      "Train Epoch: 66 [14800/17352 (85%)] Loss: -179737.093750\n",
      "Train Epoch: 66 [14880/17352 (86%)] Loss: -178829.015625\n",
      "Train Epoch: 66 [14960/17352 (86%)] Loss: -180059.000000\n",
      "Train Epoch: 66 [15040/17352 (87%)] Loss: -188437.234375\n",
      "Train Epoch: 66 [15120/17352 (87%)] Loss: -174546.093750\n",
      "Train Epoch: 66 [15200/17352 (88%)] Loss: -189538.578125\n",
      "Train Epoch: 66 [15280/17352 (88%)] Loss: -183870.312500\n",
      "Train Epoch: 66 [15360/17352 (89%)] Loss: -181738.906250\n",
      "Train Epoch: 66 [15440/17352 (89%)] Loss: -180881.156250\n",
      "Train Epoch: 66 [15520/17352 (89%)] Loss: -199895.515625\n",
      "Train Epoch: 66 [15600/17352 (90%)] Loss: -199786.921875\n",
      "Train Epoch: 66 [15680/17352 (90%)] Loss: -206355.453125\n",
      "Train Epoch: 66 [15760/17352 (91%)] Loss: -176587.125000\n",
      "Train Epoch: 66 [15840/17352 (91%)] Loss: -180241.000000\n",
      "Train Epoch: 66 [15920/17352 (92%)] Loss: -178096.640625\n",
      "Train Epoch: 66 [16000/17352 (92%)] Loss: -181753.578125\n",
      "Train Epoch: 66 [16080/17352 (93%)] Loss: -166651.875000\n",
      "Train Epoch: 66 [16160/17352 (93%)] Loss: -224863.109375\n",
      "Train Epoch: 66 [16240/17352 (94%)] Loss: -210270.281250\n",
      "Train Epoch: 66 [16320/17352 (94%)] Loss: -177617.937500\n",
      "Train Epoch: 66 [16400/17352 (95%)] Loss: -166000.343750\n",
      "Train Epoch: 66 [16480/17352 (95%)] Loss: -184940.156250\n",
      "Train Epoch: 66 [16560/17352 (95%)] Loss: -152738.000000\n",
      "Train Epoch: 66 [16640/17352 (96%)] Loss: -173008.937500\n",
      "Train Epoch: 66 [16720/17352 (96%)] Loss: -195289.796875\n",
      "Train Epoch: 66 [16800/17352 (97%)] Loss: -187455.468750\n",
      "Train Epoch: 66 [16880/17352 (97%)] Loss: -163100.484375\n",
      "Train Epoch: 66 [16960/17352 (98%)] Loss: -173891.593750\n",
      "Train Epoch: 66 [17040/17352 (98%)] Loss: -167952.828125\n",
      "Train Epoch: 66 [17120/17352 (99%)] Loss: -196405.906250\n",
      "Train Epoch: 66 [17200/17352 (99%)] Loss: -184483.328125\n",
      "Train Epoch: 66 [17280/17352 (100%)] Loss: -176060.781250\n",
      "Train Epoch: 66 [17360/17352 (100%)] Loss: -210916.562500\n",
      "    epoch          : 66\n",
      "    loss           : -189490.49781537688\n",
      "    val_loss       : -23716.05862276319\n",
      "Train Epoch: 67 [0/17352 (0%)] Loss: -217941.796875\n",
      "Train Epoch: 67 [80/17352 (0%)] Loss: -202322.421875\n",
      "Train Epoch: 67 [160/17352 (1%)] Loss: -216105.093750\n",
      "Train Epoch: 67 [240/17352 (1%)] Loss: -224248.984375\n",
      "Train Epoch: 67 [320/17352 (2%)] Loss: -200599.812500\n",
      "Train Epoch: 67 [400/17352 (2%)] Loss: -209554.468750\n",
      "Train Epoch: 67 [480/17352 (3%)] Loss: -233737.781250\n",
      "Train Epoch: 67 [560/17352 (3%)] Loss: -205107.671875\n",
      "Train Epoch: 67 [640/17352 (4%)] Loss: -210204.031250\n",
      "Train Epoch: 67 [720/17352 (4%)] Loss: -230412.546875\n",
      "Train Epoch: 67 [800/17352 (5%)] Loss: -214514.765625\n",
      "Train Epoch: 67 [880/17352 (5%)] Loss: -229948.453125\n",
      "Train Epoch: 67 [960/17352 (6%)] Loss: -229239.046875\n",
      "Train Epoch: 67 [1040/17352 (6%)] Loss: -203742.468750\n",
      "Train Epoch: 67 [1120/17352 (6%)] Loss: -211903.828125\n",
      "Train Epoch: 67 [1200/17352 (7%)] Loss: -205086.437500\n",
      "Train Epoch: 67 [1280/17352 (7%)] Loss: -182781.687500\n",
      "Train Epoch: 67 [1360/17352 (8%)] Loss: -206570.078125\n",
      "Train Epoch: 67 [1440/17352 (8%)] Loss: -217593.640625\n",
      "Train Epoch: 67 [1520/17352 (9%)] Loss: -221755.875000\n",
      "Train Epoch: 67 [1600/17352 (9%)] Loss: -231325.500000\n",
      "Train Epoch: 67 [1680/17352 (10%)] Loss: -207162.093750\n",
      "Train Epoch: 67 [1760/17352 (10%)] Loss: -236636.984375\n",
      "Train Epoch: 67 [1840/17352 (11%)] Loss: -216085.484375\n",
      "Train Epoch: 67 [1920/17352 (11%)] Loss: -188749.265625\n",
      "Train Epoch: 67 [2000/17352 (12%)] Loss: -218536.109375\n",
      "Train Epoch: 67 [2080/17352 (12%)] Loss: -196422.406250\n",
      "Train Epoch: 67 [2160/17352 (12%)] Loss: -219259.359375\n",
      "Train Epoch: 67 [2240/17352 (13%)] Loss: -202090.578125\n",
      "Train Epoch: 67 [2320/17352 (13%)] Loss: -171440.703125\n",
      "Train Epoch: 67 [2400/17352 (14%)] Loss: -168759.625000\n",
      "Train Epoch: 67 [2480/17352 (14%)] Loss: -189291.234375\n",
      "Train Epoch: 67 [2560/17352 (15%)] Loss: -163757.593750\n",
      "Train Epoch: 67 [2640/17352 (15%)] Loss: -204651.437500\n",
      "Train Epoch: 67 [2720/17352 (16%)] Loss: -148162.578125\n",
      "Train Epoch: 67 [2800/17352 (16%)] Loss: -204490.937500\n",
      "Train Epoch: 67 [2880/17352 (17%)] Loss: -170363.140625\n",
      "Train Epoch: 67 [2960/17352 (17%)] Loss: -202993.218750\n",
      "Train Epoch: 67 [3040/17352 (18%)] Loss: -184271.312500\n",
      "Train Epoch: 67 [3120/17352 (18%)] Loss: -136430.203125\n",
      "Train Epoch: 67 [3200/17352 (18%)] Loss: -179469.453125\n",
      "Train Epoch: 67 [3280/17352 (19%)] Loss: -183463.968750\n",
      "Train Epoch: 67 [3360/17352 (19%)] Loss: -178657.406250\n",
      "Train Epoch: 67 [3440/17352 (20%)] Loss: -192643.671875\n",
      "Train Epoch: 67 [3520/17352 (20%)] Loss: -191724.343750\n",
      "Train Epoch: 67 [3600/17352 (21%)] Loss: -185596.750000\n",
      "Train Epoch: 67 [3680/17352 (21%)] Loss: -190507.453125\n",
      "Train Epoch: 67 [3760/17352 (22%)] Loss: -164148.953125\n",
      "Train Epoch: 67 [3840/17352 (22%)] Loss: -160054.687500\n",
      "Train Epoch: 67 [3920/17352 (23%)] Loss: -215639.359375\n",
      "Train Epoch: 67 [4000/17352 (23%)] Loss: -173005.125000\n",
      "Train Epoch: 67 [4080/17352 (24%)] Loss: -179964.484375\n",
      "Train Epoch: 67 [4160/17352 (24%)] Loss: -159095.890625\n",
      "Train Epoch: 67 [4240/17352 (24%)] Loss: -202518.750000\n",
      "Train Epoch: 67 [4320/17352 (25%)] Loss: -151515.718750\n",
      "Train Epoch: 67 [4400/17352 (25%)] Loss: -171321.562500\n",
      "Train Epoch: 67 [4480/17352 (26%)] Loss: -197345.187500\n",
      "Train Epoch: 67 [4560/17352 (26%)] Loss: -217621.046875\n",
      "Train Epoch: 67 [4640/17352 (27%)] Loss: -181890.609375\n",
      "Train Epoch: 67 [4720/17352 (27%)] Loss: -196122.796875\n",
      "Train Epoch: 67 [4800/17352 (28%)] Loss: -192692.812500\n",
      "Train Epoch: 67 [4880/17352 (28%)] Loss: -177171.828125\n",
      "Train Epoch: 67 [4960/17352 (29%)] Loss: -193055.843750\n",
      "Train Epoch: 67 [5040/17352 (29%)] Loss: -166524.796875\n",
      "Train Epoch: 67 [5120/17352 (30%)] Loss: -184064.031250\n",
      "Train Epoch: 67 [5200/17352 (30%)] Loss: -205641.531250\n",
      "Train Epoch: 67 [5280/17352 (30%)] Loss: -206245.578125\n",
      "Train Epoch: 67 [5360/17352 (31%)] Loss: -200118.781250\n",
      "Train Epoch: 67 [5440/17352 (31%)] Loss: -203850.984375\n",
      "Train Epoch: 67 [5520/17352 (32%)] Loss: -204600.656250\n",
      "Train Epoch: 67 [5600/17352 (32%)] Loss: -181909.531250\n",
      "Train Epoch: 67 [5680/17352 (33%)] Loss: -179445.968750\n",
      "Train Epoch: 67 [5760/17352 (33%)] Loss: -201959.093750\n",
      "Train Epoch: 67 [5840/17352 (34%)] Loss: -197950.218750\n",
      "Train Epoch: 67 [5920/17352 (34%)] Loss: -182560.000000\n",
      "Train Epoch: 67 [6000/17352 (35%)] Loss: -206089.875000\n",
      "Train Epoch: 67 [6080/17352 (35%)] Loss: -180836.625000\n",
      "Train Epoch: 67 [6160/17352 (36%)] Loss: -181954.843750\n",
      "Train Epoch: 67 [6240/17352 (36%)] Loss: -202599.046875\n",
      "Train Epoch: 67 [6320/17352 (36%)] Loss: -195513.031250\n",
      "Train Epoch: 67 [6400/17352 (37%)] Loss: -200164.046875\n",
      "Train Epoch: 67 [6480/17352 (37%)] Loss: -222860.062500\n",
      "Train Epoch: 67 [6560/17352 (38%)] Loss: -206600.218750\n",
      "Train Epoch: 67 [6640/17352 (38%)] Loss: -173844.203125\n",
      "Train Epoch: 67 [6720/17352 (39%)] Loss: -206927.187500\n",
      "Train Epoch: 67 [6800/17352 (39%)] Loss: -164953.093750\n",
      "Train Epoch: 67 [6880/17352 (40%)] Loss: -170768.187500\n",
      "Train Epoch: 67 [6960/17352 (40%)] Loss: -181738.906250\n",
      "Train Epoch: 67 [7040/17352 (41%)] Loss: -208730.218750\n",
      "Train Epoch: 67 [7120/17352 (41%)] Loss: -181427.921875\n",
      "Train Epoch: 67 [7200/17352 (41%)] Loss: -188430.359375\n",
      "Train Epoch: 67 [7280/17352 (42%)] Loss: -188812.625000\n",
      "Train Epoch: 67 [7360/17352 (42%)] Loss: -173940.781250\n",
      "Train Epoch: 67 [7440/17352 (43%)] Loss: -200198.843750\n",
      "Train Epoch: 67 [7520/17352 (43%)] Loss: -202938.984375\n",
      "Train Epoch: 67 [7600/17352 (44%)] Loss: -204211.093750\n",
      "Train Epoch: 67 [7680/17352 (44%)] Loss: -171899.890625\n",
      "Train Epoch: 67 [7760/17352 (45%)] Loss: -186945.734375\n",
      "Train Epoch: 67 [7840/17352 (45%)] Loss: -181917.296875\n",
      "Train Epoch: 67 [7920/17352 (46%)] Loss: -203742.250000\n",
      "Train Epoch: 67 [8000/17352 (46%)] Loss: -192291.406250\n",
      "Train Epoch: 67 [8080/17352 (47%)] Loss: -186192.281250\n",
      "Train Epoch: 67 [8160/17352 (47%)] Loss: -199716.515625\n",
      "Train Epoch: 67 [8240/17352 (47%)] Loss: -184985.609375\n",
      "Train Epoch: 67 [8320/17352 (48%)] Loss: -179730.921875\n",
      "Train Epoch: 67 [8400/17352 (48%)] Loss: -146009.484375\n",
      "Train Epoch: 67 [8480/17352 (49%)] Loss: -180144.031250\n",
      "Train Epoch: 67 [8560/17352 (49%)] Loss: -196251.375000\n",
      "Train Epoch: 67 [8640/17352 (50%)] Loss: -192374.062500\n",
      "Train Epoch: 67 [8720/17352 (50%)] Loss: -188006.656250\n",
      "Train Epoch: 67 [8800/17352 (51%)] Loss: -213182.718750\n",
      "Train Epoch: 67 [8880/17352 (51%)] Loss: -204419.562500\n",
      "Train Epoch: 67 [8960/17352 (52%)] Loss: -205024.968750\n",
      "Train Epoch: 67 [9040/17352 (52%)] Loss: -195060.140625\n",
      "Train Epoch: 67 [9120/17352 (53%)] Loss: -181014.812500\n",
      "Train Epoch: 67 [9200/17352 (53%)] Loss: -163773.437500\n",
      "Train Epoch: 67 [9280/17352 (53%)] Loss: -166442.859375\n",
      "Train Epoch: 67 [9360/17352 (54%)] Loss: -196729.562500\n",
      "Train Epoch: 67 [9440/17352 (54%)] Loss: -192886.968750\n",
      "Train Epoch: 67 [9520/17352 (55%)] Loss: -188875.515625\n",
      "Train Epoch: 67 [9600/17352 (55%)] Loss: -208756.828125\n",
      "Train Epoch: 67 [9680/17352 (56%)] Loss: -178729.156250\n",
      "Train Epoch: 67 [9760/17352 (56%)] Loss: -181166.875000\n",
      "Train Epoch: 67 [9840/17352 (57%)] Loss: -165742.140625\n",
      "Train Epoch: 67 [9920/17352 (57%)] Loss: -175308.703125\n",
      "Train Epoch: 67 [10000/17352 (58%)] Loss: -165803.390625\n",
      "Train Epoch: 67 [10080/17352 (58%)] Loss: -175679.656250\n",
      "Train Epoch: 67 [10160/17352 (59%)] Loss: -215650.468750\n",
      "Train Epoch: 67 [10240/17352 (59%)] Loss: -190998.937500\n",
      "Train Epoch: 67 [10320/17352 (59%)] Loss: -178198.781250\n",
      "Train Epoch: 67 [10400/17352 (60%)] Loss: -175506.546875\n",
      "Train Epoch: 67 [10480/17352 (60%)] Loss: -179002.953125\n",
      "Train Epoch: 67 [10560/17352 (61%)] Loss: -178830.968750\n",
      "Train Epoch: 67 [10640/17352 (61%)] Loss: -205162.656250\n",
      "Train Epoch: 67 [10720/17352 (62%)] Loss: -184488.890625\n",
      "Train Epoch: 67 [10800/17352 (62%)] Loss: -200827.031250\n",
      "Train Epoch: 67 [10880/17352 (63%)] Loss: -197546.703125\n",
      "Train Epoch: 67 [10960/17352 (63%)] Loss: -177981.953125\n",
      "Train Epoch: 67 [11040/17352 (64%)] Loss: -192958.984375\n",
      "Train Epoch: 67 [11120/17352 (64%)] Loss: -189530.609375\n",
      "Train Epoch: 67 [11200/17352 (65%)] Loss: -193515.984375\n",
      "Train Epoch: 67 [11280/17352 (65%)] Loss: -189406.046875\n",
      "Train Epoch: 67 [11360/17352 (65%)] Loss: -173304.062500\n",
      "Train Epoch: 67 [11440/17352 (66%)] Loss: -181016.484375\n",
      "Train Epoch: 67 [11520/17352 (66%)] Loss: -177581.484375\n",
      "Train Epoch: 67 [11600/17352 (67%)] Loss: -177242.015625\n",
      "Train Epoch: 67 [11680/17352 (67%)] Loss: -198545.203125\n",
      "Train Epoch: 67 [11760/17352 (68%)] Loss: -163965.171875\n",
      "Train Epoch: 67 [11840/17352 (68%)] Loss: -180110.234375\n",
      "Train Epoch: 67 [11920/17352 (69%)] Loss: -189264.562500\n",
      "Train Epoch: 67 [12000/17352 (69%)] Loss: -213745.250000\n",
      "Train Epoch: 67 [12080/17352 (70%)] Loss: -162560.531250\n",
      "Train Epoch: 67 [12160/17352 (70%)] Loss: -169447.937500\n",
      "Train Epoch: 67 [12240/17352 (71%)] Loss: -185056.531250\n",
      "Train Epoch: 67 [12320/17352 (71%)] Loss: -194606.375000\n",
      "Train Epoch: 67 [12400/17352 (71%)] Loss: -223955.734375\n",
      "Train Epoch: 67 [12480/17352 (72%)] Loss: -148500.406250\n",
      "Train Epoch: 67 [12560/17352 (72%)] Loss: -180048.796875\n",
      "Train Epoch: 67 [12640/17352 (73%)] Loss: -175417.859375\n",
      "Train Epoch: 67 [12720/17352 (73%)] Loss: -183408.750000\n",
      "Train Epoch: 67 [12800/17352 (74%)] Loss: -196153.468750\n",
      "Train Epoch: 67 [12880/17352 (74%)] Loss: -155868.437500\n",
      "Train Epoch: 67 [12960/17352 (75%)] Loss: -208007.031250\n",
      "Train Epoch: 67 [13040/17352 (75%)] Loss: -192116.671875\n",
      "Train Epoch: 67 [13120/17352 (76%)] Loss: -198828.937500\n",
      "Train Epoch: 67 [13200/17352 (76%)] Loss: -177313.468750\n",
      "Train Epoch: 67 [13280/17352 (77%)] Loss: -198002.156250\n",
      "Train Epoch: 67 [13360/17352 (77%)] Loss: -185371.984375\n",
      "Train Epoch: 67 [13440/17352 (77%)] Loss: -201324.000000\n",
      "Train Epoch: 67 [13520/17352 (78%)] Loss: -170783.531250\n",
      "Train Epoch: 67 [13600/17352 (78%)] Loss: -173512.953125\n",
      "Train Epoch: 67 [13680/17352 (79%)] Loss: -158252.781250\n",
      "Train Epoch: 67 [13760/17352 (79%)] Loss: -192791.796875\n",
      "Train Epoch: 67 [13840/17352 (80%)] Loss: -201376.265625\n",
      "Train Epoch: 67 [13920/17352 (80%)] Loss: -197644.093750\n",
      "Train Epoch: 67 [14000/17352 (81%)] Loss: -174187.062500\n",
      "Train Epoch: 67 [14080/17352 (81%)] Loss: -185923.796875\n",
      "Train Epoch: 67 [14160/17352 (82%)] Loss: -199068.531250\n",
      "Train Epoch: 67 [14240/17352 (82%)] Loss: -205532.328125\n",
      "Train Epoch: 67 [14320/17352 (83%)] Loss: -200303.093750\n",
      "Train Epoch: 67 [14400/17352 (83%)] Loss: -184460.796875\n",
      "Train Epoch: 67 [14480/17352 (83%)] Loss: -170034.328125\n",
      "Train Epoch: 67 [14560/17352 (84%)] Loss: -180526.234375\n",
      "Train Epoch: 67 [14640/17352 (84%)] Loss: -177201.531250\n",
      "Train Epoch: 67 [14720/17352 (85%)] Loss: -196193.468750\n",
      "Train Epoch: 67 [14800/17352 (85%)] Loss: -175601.312500\n",
      "Train Epoch: 67 [14880/17352 (86%)] Loss: -208041.421875\n",
      "Train Epoch: 67 [14960/17352 (86%)] Loss: -189796.468750\n",
      "Train Epoch: 67 [15040/17352 (87%)] Loss: -177145.000000\n",
      "Train Epoch: 67 [15120/17352 (87%)] Loss: -190080.906250\n",
      "Train Epoch: 67 [15200/17352 (88%)] Loss: -196508.000000\n",
      "Train Epoch: 67 [15280/17352 (88%)] Loss: -191230.890625\n",
      "Train Epoch: 67 [15360/17352 (89%)] Loss: -183927.078125\n",
      "Train Epoch: 67 [15440/17352 (89%)] Loss: -205809.781250\n",
      "Train Epoch: 67 [15520/17352 (89%)] Loss: -202983.187500\n",
      "Train Epoch: 67 [15600/17352 (90%)] Loss: -183369.656250\n",
      "Train Epoch: 67 [15680/17352 (90%)] Loss: -204696.000000\n",
      "Train Epoch: 67 [15760/17352 (91%)] Loss: -180509.937500\n",
      "Train Epoch: 67 [15840/17352 (91%)] Loss: -159610.015625\n",
      "Train Epoch: 67 [15920/17352 (92%)] Loss: -177768.093750\n",
      "Train Epoch: 67 [16000/17352 (92%)] Loss: -198259.937500\n",
      "Train Epoch: 67 [16080/17352 (93%)] Loss: -163112.125000\n",
      "Train Epoch: 67 [16160/17352 (93%)] Loss: -186849.968750\n",
      "Train Epoch: 67 [16240/17352 (94%)] Loss: -186682.421875\n",
      "Train Epoch: 67 [16320/17352 (94%)] Loss: -160155.375000\n",
      "Train Epoch: 67 [16400/17352 (95%)] Loss: -210785.921875\n",
      "Train Epoch: 67 [16480/17352 (95%)] Loss: -178871.062500\n",
      "Train Epoch: 67 [16560/17352 (95%)] Loss: -183797.656250\n",
      "Train Epoch: 67 [16640/17352 (96%)] Loss: -191807.515625\n",
      "Train Epoch: 67 [16720/17352 (96%)] Loss: -223685.203125\n",
      "Train Epoch: 67 [16800/17352 (97%)] Loss: -189798.984375\n",
      "Train Epoch: 67 [16880/17352 (97%)] Loss: -164499.484375\n",
      "Train Epoch: 67 [16960/17352 (98%)] Loss: -196932.468750\n",
      "Train Epoch: 67 [17040/17352 (98%)] Loss: -168503.875000\n",
      "Train Epoch: 67 [17120/17352 (99%)] Loss: -182917.875000\n",
      "Train Epoch: 67 [17200/17352 (99%)] Loss: -194069.375000\n",
      "Train Epoch: 67 [17280/17352 (100%)] Loss: -202482.015625\n",
      "Train Epoch: 67 [17360/17352 (100%)] Loss: -200618.546875\n",
      "    epoch          : 67\n",
      "    loss           : -189636.17338535673\n",
      "    val_loss       : -23716.11920989847\n",
      "Train Epoch: 68 [0/17352 (0%)] Loss: -187719.593750\n",
      "Train Epoch: 68 [80/17352 (0%)] Loss: -202040.000000\n",
      "Train Epoch: 68 [160/17352 (1%)] Loss: -212187.390625\n",
      "Train Epoch: 68 [240/17352 (1%)] Loss: -229237.015625\n",
      "Train Epoch: 68 [320/17352 (2%)] Loss: -209559.843750\n",
      "Train Epoch: 68 [400/17352 (2%)] Loss: -214418.640625\n",
      "Train Epoch: 68 [480/17352 (3%)] Loss: -206788.218750\n",
      "Train Epoch: 68 [560/17352 (3%)] Loss: -199540.812500\n",
      "Train Epoch: 68 [640/17352 (4%)] Loss: -205208.812500\n",
      "Train Epoch: 68 [720/17352 (4%)] Loss: -200607.515625\n",
      "Train Epoch: 68 [800/17352 (5%)] Loss: -210627.828125\n",
      "Train Epoch: 68 [880/17352 (5%)] Loss: -214713.000000\n",
      "Train Epoch: 68 [960/17352 (6%)] Loss: -235581.468750\n",
      "Train Epoch: 68 [1040/17352 (6%)] Loss: -236632.062500\n",
      "Train Epoch: 68 [1120/17352 (6%)] Loss: -212652.937500\n",
      "Train Epoch: 68 [1200/17352 (7%)] Loss: -185289.703125\n",
      "Train Epoch: 68 [1280/17352 (7%)] Loss: -202269.843750\n",
      "Train Epoch: 68 [1360/17352 (8%)] Loss: -213327.109375\n",
      "Train Epoch: 68 [1440/17352 (8%)] Loss: -204407.234375\n",
      "Train Epoch: 68 [1520/17352 (9%)] Loss: -199809.968750\n",
      "Train Epoch: 68 [1600/17352 (9%)] Loss: -236839.640625\n",
      "Train Epoch: 68 [1680/17352 (10%)] Loss: -217588.796875\n",
      "Train Epoch: 68 [1760/17352 (10%)] Loss: -224250.781250\n",
      "Train Epoch: 68 [1840/17352 (11%)] Loss: -214512.265625\n",
      "Train Epoch: 68 [1920/17352 (11%)] Loss: -233732.937500\n",
      "Train Epoch: 68 [2000/17352 (12%)] Loss: -214526.828125\n",
      "Train Epoch: 68 [2080/17352 (12%)] Loss: -206645.781250\n",
      "Train Epoch: 68 [2160/17352 (12%)] Loss: -206151.421875\n",
      "Train Epoch: 68 [2240/17352 (13%)] Loss: -184482.125000\n",
      "Train Epoch: 68 [2320/17352 (13%)] Loss: -184949.296875\n",
      "Train Epoch: 68 [2400/17352 (14%)] Loss: -173919.390625\n",
      "Train Epoch: 68 [2480/17352 (14%)] Loss: -175540.093750\n",
      "Train Epoch: 68 [2560/17352 (15%)] Loss: -171301.000000\n",
      "Train Epoch: 68 [2640/17352 (15%)] Loss: -148161.656250\n",
      "Train Epoch: 68 [2720/17352 (16%)] Loss: -199516.859375\n",
      "Train Epoch: 68 [2800/17352 (16%)] Loss: -210159.515625\n",
      "Train Epoch: 68 [2880/17352 (17%)] Loss: -201312.484375\n",
      "Train Epoch: 68 [2960/17352 (17%)] Loss: -185327.359375\n",
      "Train Epoch: 68 [3040/17352 (18%)] Loss: -153321.421875\n",
      "Train Epoch: 68 [3120/17352 (18%)] Loss: -177091.890625\n",
      "Train Epoch: 68 [3200/17352 (18%)] Loss: -208042.687500\n",
      "Train Epoch: 68 [3280/17352 (19%)] Loss: -184252.359375\n",
      "Train Epoch: 68 [3360/17352 (19%)] Loss: -180843.421875\n",
      "Train Epoch: 68 [3440/17352 (20%)] Loss: -204660.750000\n",
      "Train Epoch: 68 [3520/17352 (20%)] Loss: -148918.406250\n",
      "Train Epoch: 68 [3600/17352 (21%)] Loss: -200615.328125\n",
      "Train Epoch: 68 [3680/17352 (21%)] Loss: -171850.218750\n",
      "Train Epoch: 68 [3760/17352 (22%)] Loss: -221246.250000\n",
      "Train Epoch: 68 [3840/17352 (22%)] Loss: -166996.890625\n",
      "Train Epoch: 68 [3920/17352 (23%)] Loss: -169981.406250\n",
      "Train Epoch: 68 [4000/17352 (23%)] Loss: -196700.890625\n",
      "Train Epoch: 68 [4080/17352 (24%)] Loss: -203853.515625\n",
      "Train Epoch: 68 [4160/17352 (24%)] Loss: -177303.031250\n",
      "Train Epoch: 68 [4240/17352 (24%)] Loss: -223687.062500\n",
      "Train Epoch: 68 [4320/17352 (25%)] Loss: -202176.453125\n",
      "Train Epoch: 68 [4400/17352 (25%)] Loss: -149445.453125\n",
      "Train Epoch: 68 [4480/17352 (26%)] Loss: -186039.953125\n",
      "Train Epoch: 68 [4560/17352 (26%)] Loss: -184750.109375\n",
      "Train Epoch: 68 [4640/17352 (27%)] Loss: -171326.593750\n",
      "Train Epoch: 68 [4720/17352 (27%)] Loss: -168049.187500\n",
      "Train Epoch: 68 [4800/17352 (28%)] Loss: -200632.546875\n",
      "Train Epoch: 68 [4880/17352 (28%)] Loss: -192105.421875\n",
      "Train Epoch: 68 [4960/17352 (29%)] Loss: -215428.765625\n",
      "Train Epoch: 68 [5040/17352 (29%)] Loss: -188500.531250\n",
      "Train Epoch: 68 [5120/17352 (30%)] Loss: -183371.687500\n",
      "Train Epoch: 68 [5200/17352 (30%)] Loss: -180255.750000\n",
      "Train Epoch: 68 [5280/17352 (30%)] Loss: -178824.234375\n",
      "Train Epoch: 68 [5360/17352 (31%)] Loss: -177461.125000\n",
      "Train Epoch: 68 [5440/17352 (31%)] Loss: -197435.937500\n",
      "Train Epoch: 68 [5520/17352 (32%)] Loss: -176676.078125\n",
      "Train Epoch: 68 [5600/17352 (32%)] Loss: -173584.578125\n",
      "Train Epoch: 68 [5680/17352 (33%)] Loss: -177177.203125\n",
      "Train Epoch: 68 [5760/17352 (33%)] Loss: -204342.171875\n",
      "Train Epoch: 68 [5840/17352 (34%)] Loss: -189023.906250\n",
      "Train Epoch: 68 [5920/17352 (34%)] Loss: -181336.609375\n",
      "Train Epoch: 68 [6000/17352 (35%)] Loss: -183921.656250\n",
      "Train Epoch: 68 [6080/17352 (35%)] Loss: -202235.359375\n",
      "Train Epoch: 68 [6160/17352 (36%)] Loss: -194582.218750\n",
      "Train Epoch: 68 [6240/17352 (36%)] Loss: -207861.000000\n",
      "Train Epoch: 68 [6320/17352 (36%)] Loss: -198702.218750\n",
      "Train Epoch: 68 [6400/17352 (37%)] Loss: -197571.953125\n",
      "Train Epoch: 68 [6480/17352 (37%)] Loss: -185060.171875\n",
      "Train Epoch: 68 [6560/17352 (38%)] Loss: -179017.796875\n",
      "Train Epoch: 68 [6640/17352 (38%)] Loss: -177198.250000\n",
      "Train Epoch: 68 [6720/17352 (39%)] Loss: -156993.171875\n",
      "Train Epoch: 68 [6800/17352 (39%)] Loss: -196933.906250\n",
      "Train Epoch: 68 [6880/17352 (40%)] Loss: -191037.437500\n",
      "Train Epoch: 68 [6960/17352 (40%)] Loss: -200204.562500\n",
      "Train Epoch: 68 [7040/17352 (41%)] Loss: -202878.640625\n",
      "Train Epoch: 68 [7120/17352 (41%)] Loss: -175413.812500\n",
      "Train Epoch: 68 [7200/17352 (41%)] Loss: -183225.531250\n",
      "Train Epoch: 68 [7280/17352 (42%)] Loss: -176158.468750\n",
      "Train Epoch: 68 [7360/17352 (42%)] Loss: -208160.234375\n",
      "Train Epoch: 68 [7440/17352 (43%)] Loss: -180263.859375\n",
      "Train Epoch: 68 [7520/17352 (43%)] Loss: -157771.593750\n",
      "Train Epoch: 68 [7600/17352 (44%)] Loss: -163103.296875\n",
      "Train Epoch: 68 [7680/17352 (44%)] Loss: -192130.000000\n",
      "Train Epoch: 68 [7760/17352 (45%)] Loss: -186943.218750\n",
      "Train Epoch: 68 [7840/17352 (45%)] Loss: -163553.250000\n",
      "Train Epoch: 68 [7920/17352 (46%)] Loss: -167958.812500\n",
      "Train Epoch: 68 [8000/17352 (46%)] Loss: -200464.812500\n",
      "Train Epoch: 68 [8080/17352 (47%)] Loss: -210915.171875\n",
      "Train Epoch: 68 [8160/17352 (47%)] Loss: -143627.546875\n",
      "Train Epoch: 68 [8240/17352 (47%)] Loss: -183057.203125\n",
      "Train Epoch: 68 [8320/17352 (48%)] Loss: -187319.734375\n",
      "Train Epoch: 68 [8400/17352 (48%)] Loss: -206242.328125\n",
      "Train Epoch: 68 [8480/17352 (49%)] Loss: -164365.656250\n",
      "Train Epoch: 68 [8560/17352 (49%)] Loss: -181719.796875\n",
      "Train Epoch: 68 [8640/17352 (50%)] Loss: -163219.375000\n",
      "Train Epoch: 68 [8720/17352 (50%)] Loss: -192243.609375\n",
      "Train Epoch: 68 [8800/17352 (51%)] Loss: -182683.703125\n",
      "Train Epoch: 68 [8880/17352 (51%)] Loss: -212661.375000\n",
      "Train Epoch: 68 [8960/17352 (52%)] Loss: -185239.062500\n",
      "Train Epoch: 68 [9040/17352 (52%)] Loss: -194935.140625\n",
      "Train Epoch: 68 [9120/17352 (53%)] Loss: -171549.234375\n",
      "Train Epoch: 68 [9200/17352 (53%)] Loss: -199893.531250\n",
      "Train Epoch: 68 [9280/17352 (53%)] Loss: -199452.031250\n",
      "Train Epoch: 68 [9360/17352 (54%)] Loss: -199725.687500\n",
      "Train Epoch: 68 [9440/17352 (54%)] Loss: -192746.546875\n",
      "Train Epoch: 68 [9520/17352 (55%)] Loss: -189486.812500\n",
      "Train Epoch: 68 [9600/17352 (55%)] Loss: -203144.531250\n",
      "Train Epoch: 68 [9680/17352 (56%)] Loss: -186163.734375\n",
      "Train Epoch: 68 [9760/17352 (56%)] Loss: -197653.609375\n",
      "Train Epoch: 68 [9840/17352 (57%)] Loss: -155861.828125\n",
      "Train Epoch: 68 [9920/17352 (57%)] Loss: -189297.921875\n",
      "Train Epoch: 68 [10000/17352 (58%)] Loss: -169440.125000\n",
      "Train Epoch: 68 [10080/17352 (58%)] Loss: -201114.578125\n",
      "Train Epoch: 68 [10160/17352 (59%)] Loss: -176967.890625\n",
      "Train Epoch: 68 [10240/17352 (59%)] Loss: -205021.890625\n",
      "Train Epoch: 68 [10320/17352 (59%)] Loss: -198299.906250\n",
      "Train Epoch: 68 [10400/17352 (60%)] Loss: -182780.093750\n",
      "Train Epoch: 68 [10480/17352 (60%)] Loss: -148506.046875\n",
      "Train Epoch: 68 [10560/17352 (61%)] Loss: -158744.140625\n",
      "Train Epoch: 68 [10640/17352 (61%)] Loss: -198260.875000\n",
      "Train Epoch: 68 [10720/17352 (62%)] Loss: -184755.296875\n",
      "Train Epoch: 68 [10800/17352 (62%)] Loss: -210491.656250\n",
      "Train Epoch: 68 [10880/17352 (63%)] Loss: -203886.500000\n",
      "Train Epoch: 68 [10960/17352 (63%)] Loss: -200399.156250\n",
      "Train Epoch: 68 [11040/17352 (64%)] Loss: -196298.875000\n",
      "Train Epoch: 68 [11120/17352 (64%)] Loss: -190503.156250\n",
      "Train Epoch: 68 [11200/17352 (65%)] Loss: -166648.062500\n",
      "Train Epoch: 68 [11280/17352 (65%)] Loss: -187325.390625\n",
      "Train Epoch: 68 [11360/17352 (65%)] Loss: -203747.156250\n",
      "Train Epoch: 68 [11440/17352 (66%)] Loss: -185370.640625\n",
      "Train Epoch: 68 [11520/17352 (66%)] Loss: -186427.906250\n",
      "Train Epoch: 68 [11600/17352 (67%)] Loss: -185828.015625\n",
      "Train Epoch: 68 [11680/17352 (67%)] Loss: -179006.859375\n",
      "Train Epoch: 68 [11760/17352 (68%)] Loss: -192313.000000\n",
      "Train Epoch: 68 [11840/17352 (68%)] Loss: -201320.468750\n",
      "Train Epoch: 68 [11920/17352 (69%)] Loss: -190231.750000\n",
      "Train Epoch: 68 [12000/17352 (69%)] Loss: -210792.468750\n",
      "Train Epoch: 68 [12080/17352 (70%)] Loss: -206358.156250\n",
      "Train Epoch: 68 [12160/17352 (70%)] Loss: -171440.968750\n",
      "Train Epoch: 68 [12240/17352 (71%)] Loss: -180507.468750\n",
      "Train Epoch: 68 [12320/17352 (71%)] Loss: -173123.000000\n",
      "Train Epoch: 68 [12400/17352 (71%)] Loss: -163757.359375\n",
      "Train Epoch: 68 [12480/17352 (72%)] Loss: -220013.890625\n",
      "Train Epoch: 68 [12560/17352 (72%)] Loss: -212906.875000\n",
      "Train Epoch: 68 [12640/17352 (73%)] Loss: -186040.515625\n",
      "Train Epoch: 68 [12720/17352 (73%)] Loss: -196042.171875\n",
      "Train Epoch: 68 [12800/17352 (74%)] Loss: -207093.984375\n",
      "Train Epoch: 68 [12880/17352 (74%)] Loss: -217600.781250\n",
      "Train Epoch: 68 [12960/17352 (75%)] Loss: -199784.718750\n",
      "Train Epoch: 68 [13040/17352 (75%)] Loss: -180117.921875\n",
      "Train Epoch: 68 [13120/17352 (76%)] Loss: -185824.093750\n",
      "Train Epoch: 68 [13200/17352 (76%)] Loss: -190505.718750\n",
      "Train Epoch: 68 [13280/17352 (77%)] Loss: -191970.359375\n",
      "Train Epoch: 68 [13360/17352 (77%)] Loss: -164740.953125\n",
      "Train Epoch: 68 [13440/17352 (77%)] Loss: -192992.906250\n",
      "Train Epoch: 68 [13520/17352 (78%)] Loss: -173508.875000\n",
      "Train Epoch: 68 [13600/17352 (78%)] Loss: -183165.578125\n",
      "Train Epoch: 68 [13680/17352 (79%)] Loss: -151512.937500\n",
      "Train Epoch: 68 [13760/17352 (79%)] Loss: -148828.671875\n",
      "Train Epoch: 68 [13840/17352 (80%)] Loss: -176043.875000\n",
      "Train Epoch: 68 [13920/17352 (80%)] Loss: -174948.937500\n",
      "Train Epoch: 68 [14000/17352 (81%)] Loss: -183871.453125\n",
      "Train Epoch: 68 [14080/17352 (81%)] Loss: -199062.328125\n",
      "Train Epoch: 68 [14160/17352 (82%)] Loss: -179390.343750\n",
      "Train Epoch: 68 [14240/17352 (82%)] Loss: -178327.609375\n",
      "Train Epoch: 68 [14320/17352 (83%)] Loss: -175012.828125\n",
      "Train Epoch: 68 [14400/17352 (83%)] Loss: -159607.625000\n",
      "Train Epoch: 68 [14480/17352 (83%)] Loss: -188180.656250\n",
      "Train Epoch: 68 [14560/17352 (84%)] Loss: -142619.750000\n",
      "Train Epoch: 68 [14640/17352 (84%)] Loss: -185575.468750\n",
      "Train Epoch: 68 [14720/17352 (85%)] Loss: -192985.765625\n",
      "Train Epoch: 68 [14800/17352 (85%)] Loss: -193353.390625\n",
      "Train Epoch: 68 [14880/17352 (86%)] Loss: -171192.343750\n",
      "Train Epoch: 68 [14960/17352 (86%)] Loss: -187952.234375\n",
      "Train Epoch: 68 [15040/17352 (87%)] Loss: -174033.656250\n",
      "Train Epoch: 68 [15120/17352 (87%)] Loss: -204348.546875\n",
      "Train Epoch: 68 [15200/17352 (88%)] Loss: -165761.484375\n",
      "Train Epoch: 68 [15280/17352 (88%)] Loss: -196453.437500\n",
      "Train Epoch: 68 [15360/17352 (89%)] Loss: -191005.468750\n",
      "Train Epoch: 68 [15440/17352 (89%)] Loss: -165730.453125\n",
      "Train Epoch: 68 [15520/17352 (89%)] Loss: -200481.859375\n",
      "Train Epoch: 68 [15600/17352 (90%)] Loss: -196867.218750\n",
      "Train Epoch: 68 [15680/17352 (90%)] Loss: -205727.125000\n",
      "Train Epoch: 68 [15760/17352 (91%)] Loss: -169614.531250\n",
      "Train Epoch: 68 [15840/17352 (91%)] Loss: -180244.734375\n",
      "Train Epoch: 68 [15920/17352 (92%)] Loss: -200127.140625\n",
      "Train Epoch: 68 [16000/17352 (92%)] Loss: -218845.562500\n",
      "Train Epoch: 68 [16080/17352 (93%)] Loss: -178207.156250\n",
      "Train Epoch: 68 [16160/17352 (93%)] Loss: -202985.218750\n",
      "Train Epoch: 68 [16240/17352 (94%)] Loss: -95261.500000\n",
      "Train Epoch: 68 [16320/17352 (94%)] Loss: -191043.375000\n",
      "Train Epoch: 68 [16400/17352 (95%)] Loss: -178597.781250\n",
      "Train Epoch: 68 [16480/17352 (95%)] Loss: -200870.437500\n",
      "Train Epoch: 68 [16560/17352 (95%)] Loss: -171832.984375\n",
      "Train Epoch: 68 [16640/17352 (96%)] Loss: -183386.109375\n",
      "Train Epoch: 68 [16720/17352 (96%)] Loss: -165867.109375\n",
      "Train Epoch: 68 [16800/17352 (97%)] Loss: -187504.640625\n",
      "Train Epoch: 68 [16880/17352 (97%)] Loss: -213906.203125\n",
      "Train Epoch: 68 [16960/17352 (98%)] Loss: -148397.015625\n",
      "Train Epoch: 68 [17040/17352 (98%)] Loss: -196248.734375\n",
      "Train Epoch: 68 [17120/17352 (99%)] Loss: -173033.953125\n",
      "Train Epoch: 68 [17200/17352 (99%)] Loss: -170764.781250\n",
      "Train Epoch: 68 [17280/17352 (100%)] Loss: -180992.281250\n",
      "Train Epoch: 68 [17360/17352 (100%)] Loss: -190083.187500\n",
      "    epoch          : 68\n",
      "    loss           : -189825.89504818758\n",
      "    val_loss       : -23716.195131472017\n",
      "Train Epoch: 69 [0/17352 (0%)] Loss: -193578.468750\n",
      "Train Epoch: 69 [80/17352 (0%)] Loss: -196419.671875\n",
      "Train Epoch: 69 [160/17352 (1%)] Loss: -204710.578125\n",
      "Train Epoch: 69 [240/17352 (1%)] Loss: -214338.578125\n",
      "Train Epoch: 69 [320/17352 (2%)] Loss: -210206.343750\n",
      "Train Epoch: 69 [400/17352 (2%)] Loss: -212182.390625\n",
      "Train Epoch: 69 [480/17352 (3%)] Loss: -196445.593750\n",
      "Train Epoch: 69 [560/17352 (3%)] Loss: -182773.750000\n",
      "Train Epoch: 69 [640/17352 (4%)] Loss: -202323.281250\n",
      "Train Epoch: 69 [720/17352 (4%)] Loss: -214519.296875\n",
      "Train Epoch: 69 [800/17352 (5%)] Loss: -236838.781250\n",
      "Train Epoch: 69 [880/17352 (5%)] Loss: -214411.843750\n",
      "Train Epoch: 69 [960/17352 (6%)] Loss: -218553.109375\n",
      "Train Epoch: 69 [1040/17352 (6%)] Loss: -210525.609375\n",
      "Train Epoch: 69 [1120/17352 (6%)] Loss: -205195.453125\n",
      "Train Epoch: 69 [1200/17352 (7%)] Loss: -204407.171875\n",
      "Train Epoch: 69 [1280/17352 (7%)] Loss: -228015.359375\n",
      "Train Epoch: 69 [1360/17352 (8%)] Loss: -202271.203125\n",
      "Train Epoch: 69 [1440/17352 (8%)] Loss: -213327.484375\n",
      "Train Epoch: 69 [1520/17352 (9%)] Loss: -205923.281250\n",
      "Train Epoch: 69 [1600/17352 (9%)] Loss: -194293.765625\n",
      "Train Epoch: 69 [1680/17352 (10%)] Loss: -213830.906250\n",
      "Train Epoch: 69 [1760/17352 (10%)] Loss: -185302.640625\n",
      "Train Epoch: 69 [1840/17352 (11%)] Loss: -206792.703125\n",
      "Train Epoch: 69 [1920/17352 (11%)] Loss: -214458.296875\n",
      "Train Epoch: 69 [2000/17352 (12%)] Loss: -199110.703125\n",
      "Train Epoch: 69 [2080/17352 (12%)] Loss: -199910.531250\n",
      "Train Epoch: 69 [2160/17352 (12%)] Loss: -219662.687500\n",
      "Train Epoch: 69 [2240/17352 (13%)] Loss: -167248.281250\n",
      "Train Epoch: 69 [2320/17352 (13%)] Loss: -208760.078125\n",
      "Train Epoch: 69 [2400/17352 (14%)] Loss: -160147.468750\n",
      "Train Epoch: 69 [2480/17352 (14%)] Loss: -166029.250000\n",
      "Train Epoch: 69 [2560/17352 (15%)] Loss: -189567.531250\n",
      "Train Epoch: 69 [2640/17352 (15%)] Loss: -210159.281250\n",
      "Train Epoch: 69 [2720/17352 (16%)] Loss: -202985.125000\n",
      "Train Epoch: 69 [2800/17352 (16%)] Loss: -183757.046875\n",
      "Train Epoch: 69 [2880/17352 (17%)] Loss: -178824.531250\n",
      "Train Epoch: 69 [2960/17352 (17%)] Loss: -165801.343750\n",
      "Train Epoch: 69 [3040/17352 (18%)] Loss: -194952.546875\n",
      "Train Epoch: 69 [3120/17352 (18%)] Loss: -176085.718750\n",
      "Train Epoch: 69 [3200/17352 (18%)] Loss: -181009.609375\n",
      "Train Epoch: 69 [3280/17352 (19%)] Loss: -201379.531250\n",
      "Train Epoch: 69 [3360/17352 (19%)] Loss: -192981.484375\n",
      "Train Epoch: 69 [3440/17352 (20%)] Loss: -167483.093750\n",
      "Train Epoch: 69 [3520/17352 (20%)] Loss: -200467.359375\n",
      "Train Epoch: 69 [3600/17352 (21%)] Loss: -183223.328125\n",
      "Train Epoch: 69 [3680/17352 (21%)] Loss: -159612.859375\n",
      "Train Epoch: 69 [3760/17352 (22%)] Loss: -193050.375000\n",
      "Train Epoch: 69 [3840/17352 (22%)] Loss: -189800.015625\n",
      "Train Epoch: 69 [3920/17352 (23%)] Loss: -202605.046875\n",
      "Train Epoch: 69 [4000/17352 (23%)] Loss: -173893.812500\n",
      "Train Epoch: 69 [4080/17352 (24%)] Loss: -190477.250000\n",
      "Train Epoch: 69 [4160/17352 (24%)] Loss: -181917.437500\n",
      "Train Epoch: 69 [4240/17352 (24%)] Loss: -184253.687500\n",
      "Train Epoch: 69 [4320/17352 (25%)] Loss: -170682.265625\n",
      "Train Epoch: 69 [4400/17352 (25%)] Loss: -213233.218750\n",
      "Train Epoch: 69 [4480/17352 (26%)] Loss: -204492.859375\n",
      "Train Epoch: 69 [4560/17352 (26%)] Loss: -167870.750000\n",
      "Train Epoch: 69 [4640/17352 (27%)] Loss: -169505.671875\n",
      "Train Epoch: 69 [4720/17352 (27%)] Loss: -168503.812500\n",
      "Train Epoch: 69 [4800/17352 (28%)] Loss: -205694.687500\n",
      "Train Epoch: 69 [4880/17352 (28%)] Loss: -196200.515625\n",
      "Train Epoch: 69 [4960/17352 (29%)] Loss: -148924.343750\n",
      "Train Epoch: 69 [5040/17352 (29%)] Loss: -180290.046875\n",
      "Train Epoch: 69 [5120/17352 (30%)] Loss: -202013.546875\n",
      "Train Epoch: 69 [5200/17352 (30%)] Loss: -175071.656250\n",
      "Train Epoch: 69 [5280/17352 (30%)] Loss: -188674.968750\n",
      "Train Epoch: 69 [5360/17352 (31%)] Loss: -186686.203125\n",
      "Train Epoch: 69 [5440/17352 (31%)] Loss: -208430.828125\n",
      "Train Epoch: 69 [5520/17352 (32%)] Loss: -163960.625000\n",
      "Train Epoch: 69 [5600/17352 (32%)] Loss: -165803.187500\n",
      "Train Epoch: 69 [5680/17352 (33%)] Loss: -195063.843750\n",
      "Train Epoch: 69 [5760/17352 (33%)] Loss: -214640.406250\n",
      "Train Epoch: 69 [5840/17352 (34%)] Loss: -197521.562500\n",
      "Train Epoch: 69 [5920/17352 (34%)] Loss: -190007.781250\n",
      "Train Epoch: 69 [6000/17352 (35%)] Loss: -184988.296875\n",
      "Train Epoch: 69 [6080/17352 (35%)] Loss: -176703.703125\n",
      "Train Epoch: 69 [6160/17352 (36%)] Loss: -176683.656250\n",
      "Train Epoch: 69 [6240/17352 (36%)] Loss: -178730.640625\n",
      "Train Epoch: 69 [6320/17352 (36%)] Loss: -149446.484375\n",
      "Train Epoch: 69 [6400/17352 (37%)] Loss: -175670.125000\n",
      "Train Epoch: 69 [6480/17352 (37%)] Loss: -165735.703125\n",
      "Train Epoch: 69 [6560/17352 (38%)] Loss: -203877.609375\n",
      "Train Epoch: 69 [6640/17352 (38%)] Loss: -181543.203125\n",
      "Train Epoch: 69 [6720/17352 (39%)] Loss: -190384.359375\n",
      "Train Epoch: 69 [6800/17352 (39%)] Loss: -177146.156250\n",
      "Train Epoch: 69 [6880/17352 (40%)] Loss: -167735.296875\n",
      "Train Epoch: 69 [6960/17352 (40%)] Loss: -171730.937500\n",
      "Train Epoch: 69 [7040/17352 (41%)] Loss: -179422.953125\n",
      "Train Epoch: 69 [7120/17352 (41%)] Loss: -183922.281250\n",
      "Train Epoch: 69 [7200/17352 (41%)] Loss: -184739.687500\n",
      "Train Epoch: 69 [7280/17352 (42%)] Loss: -188763.890625\n",
      "Train Epoch: 69 [7360/17352 (42%)] Loss: -204997.312500\n",
      "Train Epoch: 69 [7440/17352 (43%)] Loss: -190501.906250\n",
      "Train Epoch: 69 [7520/17352 (43%)] Loss: -200404.312500\n",
      "Train Epoch: 69 [7600/17352 (44%)] Loss: -149033.421875\n",
      "Train Epoch: 69 [7680/17352 (44%)] Loss: -202939.125000\n",
      "Train Epoch: 69 [7760/17352 (45%)] Loss: -185338.750000\n",
      "Train Epoch: 69 [7840/17352 (45%)] Loss: -176965.296875\n",
      "Train Epoch: 69 [7920/17352 (46%)] Loss: -192952.625000\n",
      "Train Epoch: 69 [8000/17352 (46%)] Loss: -211635.125000\n",
      "Train Epoch: 69 [8080/17352 (47%)] Loss: -171189.640625\n",
      "Train Epoch: 69 [8160/17352 (47%)] Loss: -181434.000000\n",
      "Train Epoch: 69 [8240/17352 (47%)] Loss: -193538.703125\n",
      "Train Epoch: 69 [8320/17352 (48%)] Loss: -190794.750000\n",
      "Train Epoch: 69 [8400/17352 (48%)] Loss: -185590.843750\n",
      "Train Epoch: 69 [8480/17352 (49%)] Loss: -200639.531250\n",
      "Train Epoch: 69 [8560/17352 (49%)] Loss: -189301.562500\n",
      "Train Epoch: 69 [8640/17352 (50%)] Loss: -166550.921875\n",
      "Train Epoch: 69 [8720/17352 (50%)] Loss: -164750.687500\n",
      "Train Epoch: 69 [8800/17352 (51%)] Loss: -206211.265625\n",
      "Train Epoch: 69 [8880/17352 (51%)] Loss: -200170.531250\n",
      "Train Epoch: 69 [8960/17352 (52%)] Loss: -197571.281250\n",
      "Train Epoch: 69 [9040/17352 (52%)] Loss: -190633.093750\n",
      "Train Epoch: 69 [9120/17352 (53%)] Loss: -181696.578125\n",
      "Train Epoch: 69 [9200/17352 (53%)] Loss: -182920.406250\n",
      "Train Epoch: 69 [9280/17352 (53%)] Loss: -201115.062500\n",
      "Train Epoch: 69 [9360/17352 (54%)] Loss: -185366.015625\n",
      "Train Epoch: 69 [9440/17352 (54%)] Loss: -224860.406250\n",
      "Train Epoch: 69 [9520/17352 (55%)] Loss: -167210.031250\n",
      "Train Epoch: 69 [9600/17352 (55%)] Loss: -211159.046875\n",
      "Train Epoch: 69 [9680/17352 (56%)] Loss: -193175.140625\n",
      "Train Epoch: 69 [9760/17352 (56%)] Loss: -173924.984375\n",
      "Train Epoch: 69 [9840/17352 (57%)] Loss: -209275.156250\n",
      "Train Epoch: 69 [9920/17352 (57%)] Loss: -206925.281250\n",
      "Train Epoch: 69 [10000/17352 (58%)] Loss: -173666.703125\n",
      "Train Epoch: 69 [10080/17352 (58%)] Loss: -190813.046875\n",
      "Train Epoch: 69 [10160/17352 (59%)] Loss: -164879.843750\n",
      "Train Epoch: 69 [10240/17352 (59%)] Loss: -200200.906250\n",
      "Train Epoch: 69 [10320/17352 (59%)] Loss: -188009.765625\n",
      "Train Epoch: 69 [10400/17352 (60%)] Loss: -178604.390625\n",
      "Train Epoch: 69 [10480/17352 (60%)] Loss: -187328.687500\n",
      "Train Epoch: 69 [10560/17352 (61%)] Loss: -163774.484375\n",
      "Train Epoch: 69 [10640/17352 (61%)] Loss: -181735.015625\n",
      "Train Epoch: 69 [10720/17352 (62%)] Loss: -180111.921875\n",
      "Train Epoch: 69 [10800/17352 (62%)] Loss: -169000.000000\n",
      "Train Epoch: 69 [10880/17352 (63%)] Loss: -199172.031250\n",
      "Train Epoch: 69 [10960/17352 (63%)] Loss: -187317.015625\n",
      "Train Epoch: 69 [11040/17352 (64%)] Loss: -177306.187500\n",
      "Train Epoch: 69 [11120/17352 (64%)] Loss: -177465.656250\n",
      "Train Epoch: 69 [11200/17352 (65%)] Loss: -210274.031250\n",
      "Train Epoch: 69 [11280/17352 (65%)] Loss: -178568.921875\n",
      "Train Epoch: 69 [11360/17352 (65%)] Loss: -196700.296875\n",
      "Train Epoch: 69 [11440/17352 (66%)] Loss: -153320.921875\n",
      "Train Epoch: 69 [11520/17352 (66%)] Loss: -203142.734375\n",
      "Train Epoch: 69 [11600/17352 (67%)] Loss: -198830.125000\n",
      "Train Epoch: 69 [11680/17352 (67%)] Loss: -192789.656250\n",
      "Train Epoch: 69 [11760/17352 (68%)] Loss: -178329.734375\n",
      "Train Epoch: 69 [11840/17352 (68%)] Loss: -142335.468750\n",
      "Train Epoch: 69 [11920/17352 (69%)] Loss: -157779.125000\n",
      "Train Epoch: 69 [12000/17352 (69%)] Loss: -186043.187500\n",
      "Train Epoch: 69 [12080/17352 (70%)] Loss: -179386.156250\n",
      "Train Epoch: 69 [12160/17352 (70%)] Loss: -169745.968750\n",
      "Train Epoch: 69 [12240/17352 (71%)] Loss: -170106.546875\n",
      "Train Epoch: 69 [12320/17352 (71%)] Loss: -196043.234375\n",
      "Train Epoch: 69 [12400/17352 (71%)] Loss: -167081.859375\n",
      "Train Epoch: 69 [12480/17352 (72%)] Loss: -166651.453125\n",
      "Train Epoch: 69 [12560/17352 (72%)] Loss: -160051.796875\n",
      "Train Epoch: 69 [12640/17352 (73%)] Loss: -188436.546875\n",
      "Train Epoch: 69 [12720/17352 (73%)] Loss: -173311.578125\n",
      "Train Epoch: 69 [12800/17352 (74%)] Loss: -159674.156250\n",
      "Train Epoch: 69 [12880/17352 (74%)] Loss: -191625.218750\n",
      "Train Epoch: 69 [12960/17352 (75%)] Loss: -187350.125000\n",
      "Train Epoch: 69 [13040/17352 (75%)] Loss: -173008.968750\n",
      "Train Epoch: 69 [13120/17352 (76%)] Loss: -168189.250000\n",
      "Train Epoch: 69 [13200/17352 (76%)] Loss: -202575.953125\n",
      "Train Epoch: 69 [13280/17352 (77%)] Loss: -187880.140625\n",
      "Train Epoch: 69 [13360/17352 (77%)] Loss: -164829.671875\n",
      "Train Epoch: 69 [13440/17352 (77%)] Loss: -223685.625000\n",
      "Train Epoch: 69 [13520/17352 (78%)] Loss: -188868.593750\n",
      "Train Epoch: 69 [13600/17352 (78%)] Loss: -196285.671875\n",
      "Train Epoch: 69 [13680/17352 (79%)] Loss: -161684.515625\n",
      "Train Epoch: 69 [13760/17352 (79%)] Loss: -191676.812500\n",
      "Train Epoch: 69 [13840/17352 (80%)] Loss: -186550.843750\n",
      "Train Epoch: 69 [13920/17352 (80%)] Loss: -169171.828125\n",
      "Train Epoch: 69 [14000/17352 (81%)] Loss: -185576.765625\n",
      "Train Epoch: 69 [14080/17352 (81%)] Loss: -159731.640625\n",
      "Train Epoch: 69 [14160/17352 (82%)] Loss: -206691.500000\n",
      "Train Epoch: 69 [14240/17352 (82%)] Loss: -181374.578125\n",
      "Train Epoch: 69 [14320/17352 (83%)] Loss: -201386.953125\n",
      "Train Epoch: 69 [14400/17352 (83%)] Loss: -166438.546875\n",
      "Train Epoch: 69 [14480/17352 (83%)] Loss: -183716.968750\n",
      "Train Epoch: 69 [14560/17352 (84%)] Loss: -180305.453125\n",
      "Train Epoch: 69 [14640/17352 (84%)] Loss: -205494.031250\n",
      "Train Epoch: 69 [14720/17352 (85%)] Loss: -165868.468750\n",
      "Train Epoch: 69 [14800/17352 (85%)] Loss: -175502.156250\n",
      "Train Epoch: 69 [14880/17352 (86%)] Loss: -202241.281250\n",
      "Train Epoch: 69 [14960/17352 (86%)] Loss: -212901.203125\n",
      "Train Epoch: 69 [15040/17352 (87%)] Loss: -161093.062500\n",
      "Train Epoch: 69 [15120/17352 (87%)] Loss: -193515.390625\n",
      "Train Epoch: 69 [15200/17352 (88%)] Loss: -204413.750000\n",
      "Train Epoch: 69 [15280/17352 (88%)] Loss: -183287.453125\n",
      "Train Epoch: 69 [15360/17352 (89%)] Loss: -193352.484375\n",
      "Train Epoch: 69 [15440/17352 (89%)] Loss: -196727.578125\n",
      "Train Epoch: 69 [15520/17352 (89%)] Loss: -205514.781250\n",
      "Train Epoch: 69 [15600/17352 (90%)] Loss: -177081.140625\n",
      "Train Epoch: 69 [15680/17352 (90%)] Loss: -158252.531250\n",
      "Train Epoch: 69 [15760/17352 (91%)] Loss: -194588.781250\n",
      "Train Epoch: 69 [15840/17352 (91%)] Loss: -191836.468750\n",
      "Train Epoch: 69 [15920/17352 (92%)] Loss: -174638.656250\n",
      "Train Epoch: 69 [16000/17352 (92%)] Loss: -183624.421875\n",
      "Train Epoch: 69 [16080/17352 (93%)] Loss: -184036.562500\n",
      "Train Epoch: 69 [16160/17352 (93%)] Loss: -213748.859375\n",
      "Train Epoch: 69 [16240/17352 (94%)] Loss: -179499.453125\n",
      "Train Epoch: 69 [16320/17352 (94%)] Loss: -171852.093750\n",
      "Train Epoch: 69 [16400/17352 (95%)] Loss: -184274.140625\n",
      "Train Epoch: 69 [16480/17352 (95%)] Loss: -218469.406250\n",
      "Train Epoch: 69 [16560/17352 (95%)] Loss: -159752.109375\n",
      "Train Epoch: 69 [16640/17352 (96%)] Loss: -176165.156250\n",
      "Train Epoch: 69 [16720/17352 (96%)] Loss: -182109.031250\n",
      "Train Epoch: 69 [16800/17352 (97%)] Loss: -203884.531250\n",
      "Train Epoch: 69 [16880/17352 (97%)] Loss: -207088.390625\n",
      "Train Epoch: 69 [16960/17352 (98%)] Loss: -185242.125000\n",
      "Train Epoch: 69 [17040/17352 (98%)] Loss: -168672.078125\n",
      "Train Epoch: 69 [17120/17352 (99%)] Loss: -138336.343750\n",
      "Train Epoch: 69 [17200/17352 (99%)] Loss: -217618.265625\n",
      "Train Epoch: 69 [17280/17352 (100%)] Loss: -196870.437500\n",
      "Train Epoch: 69 [17360/17352 (100%)] Loss: -188258.343750\n",
      "    epoch          : 69\n",
      "    loss           : -189222.09613240795\n",
      "    val_loss       : -23716.079127925103\n",
      "Train Epoch: 70 [0/17352 (0%)] Loss: -219666.750000\n",
      "Train Epoch: 70 [80/17352 (0%)] Loss: -206145.390625\n",
      "Train Epoch: 70 [160/17352 (1%)] Loss: -229955.218750\n",
      "Train Epoch: 70 [240/17352 (1%)] Loss: -209639.078125\n",
      "Train Epoch: 70 [320/17352 (2%)] Loss: -212178.515625\n",
      "Train Epoch: 70 [400/17352 (2%)] Loss: -236830.328125\n",
      "Train Epoch: 70 [480/17352 (3%)] Loss: -199103.218750\n",
      "Train Epoch: 70 [560/17352 (3%)] Loss: -205109.296875\n",
      "Train Epoch: 70 [640/17352 (4%)] Loss: -194294.406250\n",
      "Train Epoch: 70 [720/17352 (4%)] Loss: -216099.687500\n",
      "Train Epoch: 70 [800/17352 (5%)] Loss: -210204.046875\n",
      "Train Epoch: 70 [880/17352 (5%)] Loss: -214518.187500\n",
      "Train Epoch: 70 [960/17352 (6%)] Loss: -198771.765625\n",
      "Train Epoch: 70 [1040/17352 (6%)] Loss: -214722.718750\n",
      "Train Epoch: 70 [1120/17352 (6%)] Loss: -185153.937500\n",
      "Train Epoch: 70 [1200/17352 (7%)] Loss: -193407.312500\n",
      "Train Epoch: 70 [1280/17352 (7%)] Loss: -205557.281250\n",
      "Train Epoch: 70 [1360/17352 (8%)] Loss: -205194.812500\n",
      "Train Epoch: 70 [1440/17352 (8%)] Loss: -202027.046875\n",
      "Train Epoch: 70 [1520/17352 (9%)] Loss: -226095.062500\n",
      "Train Epoch: 70 [1600/17352 (9%)] Loss: -205930.828125\n",
      "Train Epoch: 70 [1680/17352 (10%)] Loss: -212396.875000\n",
      "Train Epoch: 70 [1760/17352 (10%)] Loss: -193709.171875\n",
      "Train Epoch: 70 [1840/17352 (11%)] Loss: -230412.265625\n",
      "Train Epoch: 70 [1920/17352 (11%)] Loss: -219201.890625\n",
      "Train Epoch: 70 [2000/17352 (12%)] Loss: -193017.796875\n",
      "Train Epoch: 70 [2080/17352 (12%)] Loss: -224343.546875\n",
      "Train Epoch: 70 [2160/17352 (12%)] Loss: -204358.796875\n",
      "Train Epoch: 70 [2240/17352 (13%)] Loss: -174515.734375\n",
      "Train Epoch: 70 [2320/17352 (13%)] Loss: -206242.156250\n",
      "Train Epoch: 70 [2400/17352 (14%)] Loss: -203889.187500\n",
      "Train Epoch: 70 [2480/17352 (14%)] Loss: -202991.781250\n",
      "Train Epoch: 70 [2560/17352 (15%)] Loss: -199597.171875\n",
      "Train Epoch: 70 [2640/17352 (15%)] Loss: -186798.968750\n",
      "Train Epoch: 70 [2720/17352 (16%)] Loss: -180965.000000\n",
      "Train Epoch: 70 [2800/17352 (16%)] Loss: -211166.343750\n",
      "Train Epoch: 70 [2880/17352 (17%)] Loss: -183876.718750\n",
      "Train Epoch: 70 [2960/17352 (17%)] Loss: -180698.687500\n",
      "Train Epoch: 70 [3040/17352 (18%)] Loss: -203814.578125\n",
      "Train Epoch: 70 [3120/17352 (18%)] Loss: -199418.312500\n",
      "Train Epoch: 70 [3200/17352 (18%)] Loss: -177592.234375\n",
      "Train Epoch: 70 [3280/17352 (19%)] Loss: -193518.312500\n",
      "Train Epoch: 70 [3360/17352 (19%)] Loss: -177103.906250\n",
      "Train Epoch: 70 [3440/17352 (20%)] Loss: -169173.109375\n",
      "Train Epoch: 70 [3520/17352 (20%)] Loss: -172560.937500\n",
      "Train Epoch: 70 [3600/17352 (21%)] Loss: -188180.437500\n",
      "Train Epoch: 70 [3680/17352 (21%)] Loss: -162725.859375\n",
      "Train Epoch: 70 [3760/17352 (22%)] Loss: -205409.250000\n",
      "Train Epoch: 70 [3840/17352 (22%)] Loss: -178667.171875\n",
      "Train Epoch: 70 [3920/17352 (23%)] Loss: -188213.375000\n",
      "Train Epoch: 70 [4000/17352 (23%)] Loss: -203517.078125\n",
      "Train Epoch: 70 [4080/17352 (24%)] Loss: -166261.343750\n",
      "Train Epoch: 70 [4160/17352 (24%)] Loss: -174634.140625\n",
      "Train Epoch: 70 [4240/17352 (24%)] Loss: -170686.390625\n",
      "Train Epoch: 70 [4320/17352 (25%)] Loss: -207127.296875\n",
      "Train Epoch: 70 [4400/17352 (25%)] Loss: -192955.703125\n",
      "Train Epoch: 70 [4480/17352 (26%)] Loss: -187400.484375\n",
      "Train Epoch: 70 [4560/17352 (26%)] Loss: -189490.453125\n",
      "Train Epoch: 70 [4640/17352 (27%)] Loss: -175508.578125\n",
      "Train Epoch: 70 [4720/17352 (27%)] Loss: -192271.890625\n",
      "Train Epoch: 70 [4800/17352 (28%)] Loss: -168089.359375\n",
      "Train Epoch: 70 [4880/17352 (28%)] Loss: -176707.453125\n",
      "Train Epoch: 70 [4960/17352 (29%)] Loss: -181072.078125\n",
      "Train Epoch: 70 [5040/17352 (29%)] Loss: -194933.468750\n",
      "Train Epoch: 70 [5120/17352 (30%)] Loss: -185828.328125\n",
      "Train Epoch: 70 [5200/17352 (30%)] Loss: -175601.343750\n",
      "Train Epoch: 70 [5280/17352 (30%)] Loss: -187354.875000\n",
      "Train Epoch: 70 [5360/17352 (31%)] Loss: -195064.046875\n",
      "Train Epoch: 70 [5440/17352 (31%)] Loss: -174032.718750\n",
      "Train Epoch: 70 [5520/17352 (32%)] Loss: -165362.078125\n",
      "Train Epoch: 70 [5600/17352 (32%)] Loss: -209589.906250\n",
      "Train Epoch: 70 [5680/17352 (33%)] Loss: -175416.687500\n",
      "Train Epoch: 70 [5760/17352 (33%)] Loss: -201117.687500\n",
      "Train Epoch: 70 [5840/17352 (34%)] Loss: -171736.562500\n",
      "Train Epoch: 70 [5920/17352 (34%)] Loss: -179502.000000\n",
      "Train Epoch: 70 [6000/17352 (35%)] Loss: -185366.125000\n",
      "Train Epoch: 70 [6080/17352 (35%)] Loss: -199178.468750\n",
      "Train Epoch: 70 [6160/17352 (36%)] Loss: -205021.984375\n",
      "Train Epoch: 70 [6240/17352 (36%)] Loss: -201324.906250\n",
      "Train Epoch: 70 [6320/17352 (36%)] Loss: -167214.000000\n",
      "Train Epoch: 70 [6400/17352 (37%)] Loss: -184921.796875\n",
      "Train Epoch: 70 [6480/17352 (37%)] Loss: -201092.812500\n",
      "Train Epoch: 70 [6560/17352 (38%)] Loss: -200121.609375\n",
      "Train Epoch: 70 [6640/17352 (38%)] Loss: -184479.812500\n",
      "Train Epoch: 70 [6720/17352 (39%)] Loss: -190382.015625\n",
      "Train Epoch: 70 [6800/17352 (39%)] Loss: -187614.234375\n",
      "Train Epoch: 70 [6880/17352 (40%)] Loss: -192964.703125\n",
      "Train Epoch: 70 [6960/17352 (40%)] Loss: -168681.468750\n",
      "Train Epoch: 70 [7040/17352 (41%)] Loss: -197517.765625\n",
      "Train Epoch: 70 [7120/17352 (41%)] Loss: -187785.468750\n",
      "Train Epoch: 70 [7200/17352 (41%)] Loss: -165598.906250\n",
      "Train Epoch: 70 [7280/17352 (42%)] Loss: -184820.125000\n",
      "Train Epoch: 70 [7360/17352 (42%)] Loss: -179676.671875\n",
      "Train Epoch: 70 [7440/17352 (43%)] Loss: -175749.671875\n",
      "Train Epoch: 70 [7520/17352 (43%)] Loss: -212900.671875\n",
      "Train Epoch: 70 [7600/17352 (44%)] Loss: -146005.781250\n",
      "Train Epoch: 70 [7680/17352 (44%)] Loss: -184257.937500\n",
      "Train Epoch: 70 [7760/17352 (45%)] Loss: -176588.093750\n",
      "Train Epoch: 70 [7840/17352 (45%)] Loss: -192644.265625\n",
      "Train Epoch: 70 [7920/17352 (46%)] Loss: -231040.562500\n",
      "Train Epoch: 70 [8000/17352 (46%)] Loss: -166029.468750\n",
      "Train Epoch: 70 [8080/17352 (47%)] Loss: -202171.453125\n",
      "Train Epoch: 70 [8160/17352 (47%)] Loss: -171307.437500\n",
      "Train Epoch: 70 [8240/17352 (47%)] Loss: -163503.390625\n",
      "Train Epoch: 70 [8320/17352 (48%)] Loss: -176164.812500\n",
      "Train Epoch: 70 [8400/17352 (48%)] Loss: -178807.734375\n",
      "Train Epoch: 70 [8480/17352 (49%)] Loss: -174941.390625\n",
      "Train Epoch: 70 [8560/17352 (49%)] Loss: -172968.421875\n",
      "Train Epoch: 70 [8640/17352 (50%)] Loss: -176286.125000\n",
      "Train Epoch: 70 [8720/17352 (50%)] Loss: -183070.593750\n",
      "Train Epoch: 70 [8800/17352 (51%)] Loss: -228101.812500\n",
      "Train Epoch: 70 [8880/17352 (51%)] Loss: -211723.937500\n",
      "Train Epoch: 70 [8960/17352 (52%)] Loss: -184459.171875\n",
      "Train Epoch: 70 [9040/17352 (52%)] Loss: -160104.890625\n",
      "Train Epoch: 70 [9120/17352 (53%)] Loss: -192859.625000\n",
      "Train Epoch: 70 [9200/17352 (53%)] Loss: -188058.078125\n",
      "Train Epoch: 70 [9280/17352 (53%)] Loss: -199070.250000\n",
      "Train Epoch: 70 [9360/17352 (54%)] Loss: -182772.515625\n",
      "Train Epoch: 70 [9440/17352 (54%)] Loss: -186688.062500\n",
      "Train Epoch: 70 [9520/17352 (55%)] Loss: -191802.328125\n",
      "Train Epoch: 70 [9600/17352 (55%)] Loss: -202872.625000\n",
      "Train Epoch: 70 [9680/17352 (56%)] Loss: -200864.437500\n",
      "Train Epoch: 70 [9760/17352 (56%)] Loss: -202932.843750\n",
      "Train Epoch: 70 [9840/17352 (57%)] Loss: -187266.000000\n",
      "Train Epoch: 70 [9920/17352 (57%)] Loss: -187779.328125\n",
      "Train Epoch: 70 [10000/17352 (58%)] Loss: -200333.406250\n",
      "Train Epoch: 70 [10080/17352 (58%)] Loss: -178318.531250\n",
      "Train Epoch: 70 [10160/17352 (59%)] Loss: -161965.093750\n",
      "Train Epoch: 70 [10240/17352 (59%)] Loss: -214644.250000\n",
      "Train Epoch: 70 [10320/17352 (59%)] Loss: -215972.218750\n",
      "Train Epoch: 70 [10400/17352 (60%)] Loss: -178143.078125\n",
      "Train Epoch: 70 [10480/17352 (60%)] Loss: -180244.328125\n",
      "Train Epoch: 70 [10560/17352 (61%)] Loss: -201005.406250\n",
      "Train Epoch: 70 [10640/17352 (61%)] Loss: -187538.906250\n",
      "Train Epoch: 70 [10720/17352 (62%)] Loss: -168189.500000\n",
      "Train Epoch: 70 [10800/17352 (62%)] Loss: -177783.828125\n",
      "Train Epoch: 70 [10880/17352 (63%)] Loss: -215462.140625\n",
      "Train Epoch: 70 [10960/17352 (63%)] Loss: -182737.421875\n",
      "Train Epoch: 70 [11040/17352 (64%)] Loss: -181689.296875\n",
      "Train Epoch: 70 [11120/17352 (64%)] Loss: -168258.640625\n",
      "Train Epoch: 70 [11200/17352 (65%)] Loss: -180053.718750\n",
      "Train Epoch: 70 [11280/17352 (65%)] Loss: -193495.921875\n",
      "Train Epoch: 70 [11360/17352 (65%)] Loss: -180159.781250\n",
      "Train Epoch: 70 [11440/17352 (66%)] Loss: -188909.234375\n",
      "Train Epoch: 70 [11520/17352 (66%)] Loss: -172234.562500\n",
      "Train Epoch: 70 [11600/17352 (67%)] Loss: -192953.687500\n",
      "Train Epoch: 70 [11680/17352 (67%)] Loss: -192114.296875\n",
      "Train Epoch: 70 [11760/17352 (68%)] Loss: -158257.609375\n",
      "Train Epoch: 70 [11840/17352 (68%)] Loss: -204208.953125\n",
      "Train Epoch: 70 [11920/17352 (69%)] Loss: -189305.796875\n",
      "Train Epoch: 70 [12000/17352 (69%)] Loss: -185832.765625\n",
      "Train Epoch: 70 [12080/17352 (70%)] Loss: -216386.015625\n",
      "Train Epoch: 70 [12160/17352 (70%)] Loss: -199802.078125\n",
      "Train Epoch: 70 [12240/17352 (71%)] Loss: -184489.843750\n",
      "Train Epoch: 70 [12320/17352 (71%)] Loss: -206207.062500\n",
      "Train Epoch: 70 [12400/17352 (71%)] Loss: -173042.453125\n",
      "Train Epoch: 70 [12480/17352 (72%)] Loss: -178426.156250\n",
      "Train Epoch: 70 [12560/17352 (72%)] Loss: -166441.968750\n",
      "Train Epoch: 70 [12640/17352 (73%)] Loss: -184606.218750\n",
      "Train Epoch: 70 [12720/17352 (73%)] Loss: -182565.421875\n",
      "Train Epoch: 70 [12800/17352 (74%)] Loss: -177580.125000\n",
      "Train Epoch: 70 [12880/17352 (74%)] Loss: -176275.625000\n",
      "Train Epoch: 70 [12960/17352 (75%)] Loss: -159316.750000\n",
      "Train Epoch: 70 [13040/17352 (75%)] Loss: -190621.093750\n",
      "Train Epoch: 70 [13120/17352 (76%)] Loss: -190798.703125\n",
      "Train Epoch: 70 [13200/17352 (76%)] Loss: -221258.296875\n",
      "Train Epoch: 70 [13280/17352 (77%)] Loss: -187119.468750\n",
      "Train Epoch: 70 [13360/17352 (77%)] Loss: -183058.406250\n",
      "Train Epoch: 70 [13440/17352 (77%)] Loss: -206604.937500\n",
      "Train Epoch: 70 [13520/17352 (78%)] Loss: -189485.843750\n",
      "Train Epoch: 70 [13600/17352 (78%)] Loss: -179482.921875\n",
      "Train Epoch: 70 [13680/17352 (79%)] Loss: -185547.734375\n",
      "Train Epoch: 70 [13760/17352 (79%)] Loss: -169615.437500\n",
      "Train Epoch: 70 [13840/17352 (80%)] Loss: -201827.015625\n",
      "Train Epoch: 70 [13920/17352 (80%)] Loss: -183224.468750\n",
      "Train Epoch: 70 [14000/17352 (81%)] Loss: -187206.281250\n",
      "Train Epoch: 70 [14080/17352 (81%)] Loss: -175401.109375\n",
      "Train Epoch: 70 [14160/17352 (82%)] Loss: -175073.484375\n",
      "Train Epoch: 70 [14240/17352 (82%)] Loss: -185801.875000\n",
      "Train Epoch: 70 [14320/17352 (83%)] Loss: -163751.828125\n",
      "Train Epoch: 70 [14400/17352 (83%)] Loss: -197540.765625\n",
      "Train Epoch: 70 [14480/17352 (83%)] Loss: -213183.703125\n",
      "Train Epoch: 70 [14560/17352 (84%)] Loss: -183284.953125\n",
      "Train Epoch: 70 [14640/17352 (84%)] Loss: -212661.765625\n",
      "Train Epoch: 70 [14720/17352 (85%)] Loss: -195787.421875\n",
      "Train Epoch: 70 [14800/17352 (85%)] Loss: -178608.375000\n",
      "Train Epoch: 70 [14880/17352 (86%)] Loss: -170358.312500\n",
      "Train Epoch: 70 [14960/17352 (86%)] Loss: -176699.375000\n",
      "Train Epoch: 70 [15040/17352 (87%)] Loss: -175671.968750\n",
      "Train Epoch: 70 [15120/17352 (87%)] Loss: -173893.015625\n",
      "Train Epoch: 70 [15200/17352 (88%)] Loss: -195102.859375\n",
      "Train Epoch: 70 [15280/17352 (88%)] Loss: -159089.921875\n",
      "Train Epoch: 70 [15360/17352 (89%)] Loss: -179897.265625\n",
      "Train Epoch: 70 [15440/17352 (89%)] Loss: -167036.828125\n",
      "Train Epoch: 70 [15520/17352 (89%)] Loss: -188266.875000\n",
      "Train Epoch: 70 [15600/17352 (90%)] Loss: -186611.593750\n",
      "Train Epoch: 70 [15680/17352 (90%)] Loss: -218751.515625\n",
      "Train Epoch: 70 [15760/17352 (91%)] Loss: -193451.515625\n",
      "Train Epoch: 70 [15840/17352 (91%)] Loss: -178212.656250\n",
      "Train Epoch: 70 [15920/17352 (92%)] Loss: -208748.015625\n",
      "Train Epoch: 70 [16000/17352 (92%)] Loss: -192098.328125\n",
      "Train Epoch: 70 [16080/17352 (93%)] Loss: -215177.890625\n",
      "Train Epoch: 70 [16160/17352 (93%)] Loss: -206476.156250\n",
      "Train Epoch: 70 [16240/17352 (94%)] Loss: -173576.453125\n",
      "Train Epoch: 70 [16320/17352 (94%)] Loss: -190912.250000\n",
      "Train Epoch: 70 [16400/17352 (95%)] Loss: -192172.890625\n",
      "Train Epoch: 70 [16480/17352 (95%)] Loss: -205690.109375\n",
      "Train Epoch: 70 [16560/17352 (95%)] Loss: -191561.875000\n",
      "Train Epoch: 70 [16640/17352 (96%)] Loss: -185174.718750\n",
      "Train Epoch: 70 [16720/17352 (96%)] Loss: -174988.234375\n",
      "Train Epoch: 70 [16800/17352 (97%)] Loss: -210489.703125\n",
      "Train Epoch: 70 [16880/17352 (97%)] Loss: -167875.343750\n",
      "Train Epoch: 70 [16960/17352 (98%)] Loss: -187710.468750\n",
      "Train Epoch: 70 [17040/17352 (98%)] Loss: -166650.906250\n",
      "Train Epoch: 70 [17120/17352 (99%)] Loss: -192248.031250\n",
      "Train Epoch: 70 [17200/17352 (99%)] Loss: -173669.250000\n",
      "Train Epoch: 70 [17280/17352 (100%)] Loss: -223961.390625\n",
      "Train Epoch: 70 [17360/17352 (100%)] Loss: -177307.843750\n",
      "    epoch          : 70\n",
      "    loss           : -189134.22777617953\n",
      "    val_loss       : -23716.095970332903\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch70.pth ...\n",
      "Train Epoch: 71 [0/17352 (0%)] Loss: -199807.468750\n",
      "Train Epoch: 71 [80/17352 (0%)] Loss: -185150.109375\n",
      "Train Epoch: 71 [160/17352 (1%)] Loss: -215099.312500\n",
      "Train Epoch: 71 [240/17352 (1%)] Loss: -221480.734375\n",
      "Train Epoch: 71 [320/17352 (2%)] Loss: -193418.328125\n",
      "Train Epoch: 71 [400/17352 (2%)] Loss: -226096.234375\n",
      "Train Epoch: 71 [480/17352 (3%)] Loss: -214340.015625\n",
      "Train Epoch: 71 [560/17352 (3%)] Loss: -217626.578125\n",
      "Train Epoch: 71 [640/17352 (4%)] Loss: -209779.906250\n",
      "Train Epoch: 71 [720/17352 (4%)] Loss: -193711.609375\n",
      "Train Epoch: 71 [800/17352 (5%)] Loss: -182777.625000\n",
      "Train Epoch: 71 [880/17352 (5%)] Loss: -206148.796875\n",
      "Train Epoch: 71 [960/17352 (6%)] Loss: -203743.093750\n",
      "Train Epoch: 71 [1040/17352 (6%)] Loss: -200607.640625\n",
      "Train Epoch: 71 [1120/17352 (6%)] Loss: -209634.890625\n",
      "Train Epoch: 71 [1200/17352 (7%)] Loss: -187721.093750\n",
      "Train Epoch: 71 [1280/17352 (7%)] Loss: -215487.250000\n",
      "Train Epoch: 71 [1360/17352 (8%)] Loss: -224244.718750\n",
      "Train Epoch: 71 [1440/17352 (8%)] Loss: -205102.687500\n",
      "Train Epoch: 71 [1520/17352 (9%)] Loss: -208384.968750\n",
      "Train Epoch: 71 [1600/17352 (9%)] Loss: -224348.968750\n",
      "Train Epoch: 71 [1680/17352 (10%)] Loss: -212376.875000\n",
      "Train Epoch: 71 [1760/17352 (10%)] Loss: -209558.687500\n",
      "Train Epoch: 71 [1840/17352 (11%)] Loss: -204532.578125\n",
      "Train Epoch: 71 [1920/17352 (11%)] Loss: -210524.468750\n",
      "Train Epoch: 71 [2000/17352 (12%)] Loss: -206566.437500\n",
      "Train Epoch: 71 [2080/17352 (12%)] Loss: -208542.718750\n",
      "Train Epoch: 71 [2160/17352 (12%)] Loss: -205932.859375\n",
      "Train Epoch: 71 [2240/17352 (13%)] Loss: -149332.125000\n",
      "Train Epoch: 71 [2320/17352 (13%)] Loss: -186562.984375\n",
      "Train Epoch: 71 [2400/17352 (14%)] Loss: -175012.203125\n",
      "Train Epoch: 71 [2480/17352 (14%)] Loss: -192373.406250\n",
      "Train Epoch: 71 [2560/17352 (15%)] Loss: -188676.718750\n",
      "Train Epoch: 71 [2640/17352 (15%)] Loss: -191803.968750\n",
      "Train Epoch: 71 [2720/17352 (16%)] Loss: -151735.937500\n",
      "Train Epoch: 71 [2800/17352 (16%)] Loss: -151514.000000\n",
      "Train Epoch: 71 [2880/17352 (17%)] Loss: -182554.218750\n",
      "Train Epoch: 71 [2960/17352 (17%)] Loss: -200334.468750\n",
      "Train Epoch: 71 [3040/17352 (18%)] Loss: -202482.359375\n",
      "Train Epoch: 71 [3120/17352 (18%)] Loss: -191327.718750\n",
      "Train Epoch: 71 [3200/17352 (18%)] Loss: -169446.437500\n",
      "Train Epoch: 71 [3280/17352 (19%)] Loss: -179462.031250\n",
      "Train Epoch: 71 [3360/17352 (19%)] Loss: -174483.562500\n",
      "Train Epoch: 71 [3440/17352 (20%)] Loss: -206096.234375\n",
      "Train Epoch: 71 [3520/17352 (20%)] Loss: -190082.921875\n",
      "Train Epoch: 71 [3600/17352 (21%)] Loss: -186038.562500\n",
      "Train Epoch: 71 [3680/17352 (21%)] Loss: -202789.390625\n",
      "Train Epoch: 71 [3760/17352 (22%)] Loss: -188491.578125\n",
      "Train Epoch: 71 [3840/17352 (22%)] Loss: -166409.500000\n",
      "Train Epoch: 71 [3920/17352 (23%)] Loss: -197317.234375\n",
      "Train Epoch: 71 [4000/17352 (23%)] Loss: -166439.968750\n",
      "Train Epoch: 71 [4080/17352 (24%)] Loss: -177779.765625\n",
      "Train Epoch: 71 [4160/17352 (24%)] Loss: -189607.515625\n",
      "Train Epoch: 71 [4240/17352 (24%)] Loss: -180311.656250\n",
      "Train Epoch: 71 [4320/17352 (25%)] Loss: -185176.859375\n",
      "Train Epoch: 71 [4400/17352 (25%)] Loss: -160055.468750\n",
      "Train Epoch: 71 [4480/17352 (26%)] Loss: -189218.109375\n",
      "Train Epoch: 71 [4560/17352 (26%)] Loss: -196297.500000\n",
      "Train Epoch: 71 [4640/17352 (27%)] Loss: -181920.093750\n",
      "Train Epoch: 71 [4720/17352 (27%)] Loss: -180050.343750\n",
      "Train Epoch: 71 [4800/17352 (28%)] Loss: -166553.140625\n",
      "Train Epoch: 71 [4880/17352 (28%)] Loss: -183764.343750\n",
      "Train Epoch: 71 [4960/17352 (29%)] Loss: -147418.312500\n",
      "Train Epoch: 71 [5040/17352 (29%)] Loss: -174915.578125\n",
      "Train Epoch: 71 [5120/17352 (30%)] Loss: -192288.093750\n",
      "Train Epoch: 71 [5200/17352 (30%)] Loss: -193496.843750\n",
      "Train Epoch: 71 [5280/17352 (30%)] Loss: -181896.421875\n",
      "Train Epoch: 71 [5360/17352 (31%)] Loss: -186948.375000\n",
      "Train Epoch: 71 [5440/17352 (31%)] Loss: -192125.453125\n",
      "Train Epoch: 71 [5520/17352 (32%)] Loss: -191963.296875\n",
      "Train Epoch: 71 [5600/17352 (32%)] Loss: -186782.093750\n",
      "Train Epoch: 71 [5680/17352 (33%)] Loss: -213745.625000\n",
      "Train Epoch: 71 [5760/17352 (33%)] Loss: -184070.687500\n",
      "Train Epoch: 71 [5840/17352 (34%)] Loss: -204349.109375\n",
      "Train Epoch: 71 [5920/17352 (34%)] Loss: -171441.640625\n",
      "Train Epoch: 71 [6000/17352 (35%)] Loss: -203515.359375\n",
      "Train Epoch: 71 [6080/17352 (35%)] Loss: -199421.640625\n",
      "Train Epoch: 71 [6160/17352 (36%)] Loss: -192648.000000\n",
      "Train Epoch: 71 [6240/17352 (36%)] Loss: -187529.265625\n",
      "Train Epoch: 71 [6320/17352 (36%)] Loss: -180538.656250\n",
      "Train Epoch: 71 [6400/17352 (37%)] Loss: -193368.921875\n",
      "Train Epoch: 71 [6480/17352 (37%)] Loss: -202519.593750\n",
      "Train Epoch: 71 [6560/17352 (38%)] Loss: -181375.406250\n",
      "Train Epoch: 71 [6640/17352 (38%)] Loss: -177078.062500\n",
      "Train Epoch: 71 [6720/17352 (39%)] Loss: -180751.625000\n",
      "Train Epoch: 71 [6800/17352 (39%)] Loss: -178095.156250\n",
      "Train Epoch: 71 [6880/17352 (40%)] Loss: -186844.859375\n",
      "Train Epoch: 71 [6960/17352 (40%)] Loss: -196868.171875\n",
      "Train Epoch: 71 [7040/17352 (41%)] Loss: -191043.890625\n",
      "Train Epoch: 71 [7120/17352 (41%)] Loss: -223963.156250\n",
      "Train Epoch: 71 [7200/17352 (41%)] Loss: -193264.578125\n",
      "Train Epoch: 71 [7280/17352 (42%)] Loss: -181542.796875\n",
      "Train Epoch: 71 [7360/17352 (42%)] Loss: -200118.171875\n",
      "Train Epoch: 71 [7440/17352 (43%)] Loss: -176283.031250\n",
      "Train Epoch: 71 [7520/17352 (43%)] Loss: -193454.906250\n",
      "Train Epoch: 71 [7600/17352 (44%)] Loss: -174941.812500\n",
      "Train Epoch: 71 [7680/17352 (44%)] Loss: -215417.296875\n",
      "Train Epoch: 71 [7760/17352 (45%)] Loss: -190244.109375\n",
      "Train Epoch: 71 [7840/17352 (45%)] Loss: -196450.812500\n",
      "Train Epoch: 71 [7920/17352 (46%)] Loss: -172235.671875\n",
      "Train Epoch: 71 [8000/17352 (46%)] Loss: -187714.406250\n",
      "Train Epoch: 71 [8080/17352 (47%)] Loss: -191683.406250\n",
      "Train Epoch: 71 [8160/17352 (47%)] Loss: -156611.109375\n",
      "Train Epoch: 71 [8240/17352 (47%)] Loss: -179386.453125\n",
      "Train Epoch: 71 [8320/17352 (48%)] Loss: -214962.218750\n",
      "Train Epoch: 71 [8400/17352 (48%)] Loss: -210275.921875\n",
      "Train Epoch: 71 [8480/17352 (49%)] Loss: -197571.906250\n",
      "Train Epoch: 71 [8560/17352 (49%)] Loss: -175404.765625\n",
      "Train Epoch: 71 [8640/17352 (50%)] Loss: -177732.218750\n",
      "Train Epoch: 71 [8720/17352 (50%)] Loss: -191311.187500\n",
      "Train Epoch: 71 [8800/17352 (51%)] Loss: -185924.593750\n",
      "Train Epoch: 71 [8880/17352 (51%)] Loss: -173007.156250\n",
      "Train Epoch: 71 [8960/17352 (52%)] Loss: -185991.671875\n",
      "Train Epoch: 71 [9040/17352 (52%)] Loss: -184985.562500\n",
      "Train Epoch: 71 [9120/17352 (53%)] Loss: -174034.218750\n",
      "Train Epoch: 71 [9200/17352 (53%)] Loss: -197440.171875\n",
      "Train Epoch: 71 [9280/17352 (53%)] Loss: -205512.921875\n",
      "Train Epoch: 71 [9360/17352 (54%)] Loss: -142618.375000\n",
      "Train Epoch: 71 [9440/17352 (54%)] Loss: -181670.750000\n",
      "Train Epoch: 71 [9520/17352 (55%)] Loss: -191723.296875\n",
      "Train Epoch: 71 [9600/17352 (55%)] Loss: -199892.703125\n",
      "Train Epoch: 71 [9680/17352 (56%)] Loss: -208023.468750\n",
      "Train Epoch: 71 [9760/17352 (56%)] Loss: -193053.531250\n",
      "Train Epoch: 71 [9840/17352 (57%)] Loss: -220013.843750\n",
      "Train Epoch: 71 [9920/17352 (57%)] Loss: -200631.703125\n",
      "Train Epoch: 71 [10000/17352 (58%)] Loss: -196566.859375\n",
      "Train Epoch: 71 [10080/17352 (58%)] Loss: -167806.781250\n",
      "Train Epoch: 71 [10160/17352 (59%)] Loss: -173044.468750\n",
      "Train Epoch: 71 [10240/17352 (59%)] Loss: -198703.937500\n",
      "Train Epoch: 71 [10320/17352 (59%)] Loss: -178871.187500\n",
      "Train Epoch: 71 [10400/17352 (60%)] Loss: -153889.265625\n",
      "Train Epoch: 71 [10480/17352 (60%)] Loss: -192791.875000\n",
      "Train Epoch: 71 [10560/17352 (61%)] Loss: -175690.937500\n",
      "Train Epoch: 71 [10640/17352 (61%)] Loss: -205723.062500\n",
      "Train Epoch: 71 [10720/17352 (62%)] Loss: -159312.437500\n",
      "Train Epoch: 71 [10800/17352 (62%)] Loss: -178667.406250\n",
      "Train Epoch: 71 [10880/17352 (63%)] Loss: -191061.265625\n",
      "Train Epoch: 71 [10960/17352 (63%)] Loss: -171902.140625\n",
      "Train Epoch: 71 [11040/17352 (64%)] Loss: -159751.250000\n",
      "Train Epoch: 71 [11120/17352 (64%)] Loss: -168965.406250\n",
      "Train Epoch: 71 [11200/17352 (65%)] Loss: -203147.843750\n",
      "Train Epoch: 71 [11280/17352 (65%)] Loss: -151505.843750\n",
      "Train Epoch: 71 [11360/17352 (65%)] Loss: -189262.953125\n",
      "Train Epoch: 71 [11440/17352 (66%)] Loss: -184023.156250\n",
      "Train Epoch: 71 [11520/17352 (66%)] Loss: -179746.640625\n",
      "Train Epoch: 71 [11600/17352 (67%)] Loss: -174984.453125\n",
      "Train Epoch: 71 [11680/17352 (67%)] Loss: -200197.562500\n",
      "Train Epoch: 71 [11760/17352 (68%)] Loss: -206929.109375\n",
      "Train Epoch: 71 [11840/17352 (68%)] Loss: -138337.015625\n",
      "Train Epoch: 71 [11920/17352 (69%)] Loss: -200877.046875\n",
      "Train Epoch: 71 [12000/17352 (69%)] Loss: -177093.984375\n",
      "Train Epoch: 71 [12080/17352 (70%)] Loss: -188811.921875\n",
      "Train Epoch: 71 [12160/17352 (70%)] Loss: -172552.109375\n",
      "Train Epoch: 71 [12240/17352 (71%)] Loss: -214641.703125\n",
      "Train Epoch: 71 [12320/17352 (71%)] Loss: -196698.140625\n",
      "Train Epoch: 71 [12400/17352 (71%)] Loss: -210156.937500\n",
      "Train Epoch: 71 [12480/17352 (72%)] Loss: -178321.593750\n",
      "Train Epoch: 71 [12560/17352 (72%)] Loss: -192231.421875\n",
      "Train Epoch: 71 [12640/17352 (73%)] Loss: -196121.328125\n",
      "Train Epoch: 71 [12720/17352 (73%)] Loss: -203741.953125\n",
      "Train Epoch: 71 [12800/17352 (74%)] Loss: -187457.500000\n",
      "Train Epoch: 71 [12880/17352 (74%)] Loss: -212614.781250\n",
      "Train Epoch: 71 [12960/17352 (75%)] Loss: -196734.781250\n",
      "Train Epoch: 71 [13040/17352 (75%)] Loss: -151219.406250\n",
      "Train Epoch: 71 [13120/17352 (76%)] Loss: -192392.437500\n",
      "Train Epoch: 71 [13200/17352 (76%)] Loss: -192245.140625\n",
      "Train Epoch: 71 [13280/17352 (77%)] Loss: -188866.265625\n",
      "Train Epoch: 71 [13360/17352 (77%)] Loss: -197596.031250\n",
      "Train Epoch: 71 [13440/17352 (77%)] Loss: -181727.000000\n",
      "Train Epoch: 71 [13520/17352 (78%)] Loss: -209420.765625\n",
      "Train Epoch: 71 [13600/17352 (78%)] Loss: -177148.359375\n",
      "Train Epoch: 71 [13680/17352 (79%)] Loss: -184755.687500\n",
      "Train Epoch: 71 [13760/17352 (79%)] Loss: -177307.781250\n",
      "Train Epoch: 71 [13840/17352 (80%)] Loss: -162563.500000\n",
      "Train Epoch: 71 [13920/17352 (80%)] Loss: -182531.859375\n",
      "Train Epoch: 71 [14000/17352 (81%)] Loss: -183228.140625\n",
      "Train Epoch: 71 [14080/17352 (81%)] Loss: -204698.531250\n",
      "Train Epoch: 71 [14160/17352 (82%)] Loss: -178600.515625\n",
      "Train Epoch: 71 [14240/17352 (82%)] Loss: -179313.406250\n",
      "Train Epoch: 71 [14320/17352 (83%)] Loss: -181248.218750\n",
      "Train Epoch: 71 [14400/17352 (83%)] Loss: -148444.078125\n",
      "Train Epoch: 71 [14480/17352 (83%)] Loss: -187265.171875\n",
      "Train Epoch: 71 [14560/17352 (84%)] Loss: -176491.375000\n",
      "Train Epoch: 71 [14640/17352 (84%)] Loss: -200278.890625\n",
      "Train Epoch: 71 [14720/17352 (85%)] Loss: -196127.937500\n",
      "Train Epoch: 71 [14800/17352 (85%)] Loss: -175412.906250\n",
      "Train Epoch: 71 [14880/17352 (86%)] Loss: -152740.578125\n",
      "Train Epoch: 71 [14960/17352 (86%)] Loss: -175421.906250\n",
      "Train Epoch: 71 [15040/17352 (87%)] Loss: -173886.375000\n",
      "Train Epoch: 71 [15120/17352 (87%)] Loss: -211090.750000\n",
      "Train Epoch: 71 [15200/17352 (88%)] Loss: -165682.156250\n",
      "Train Epoch: 71 [15280/17352 (88%)] Loss: -181619.000000\n",
      "Train Epoch: 71 [15360/17352 (89%)] Loss: -182742.328125\n",
      "Train Epoch: 71 [15440/17352 (89%)] Loss: -201522.406250\n",
      "Train Epoch: 71 [15520/17352 (89%)] Loss: -184604.796875\n",
      "Train Epoch: 71 [15600/17352 (90%)] Loss: -184852.421875\n",
      "Train Epoch: 71 [15680/17352 (90%)] Loss: -198552.953125\n",
      "Train Epoch: 71 [15760/17352 (91%)] Loss: -188565.828125\n",
      "Train Epoch: 71 [15840/17352 (91%)] Loss: -181753.781250\n",
      "Train Epoch: 71 [15920/17352 (92%)] Loss: -201366.171875\n",
      "Train Epoch: 71 [16000/17352 (92%)] Loss: -177489.937500\n",
      "Train Epoch: 71 [16080/17352 (93%)] Loss: -179668.187500\n",
      "Train Epoch: 71 [16160/17352 (93%)] Loss: -163962.765625\n",
      "Train Epoch: 71 [16240/17352 (94%)] Loss: -173581.265625\n",
      "Train Epoch: 71 [16320/17352 (94%)] Loss: -179012.750000\n",
      "Train Epoch: 71 [16400/17352 (95%)] Loss: -192747.937500\n",
      "Train Epoch: 71 [16480/17352 (95%)] Loss: -202581.125000\n",
      "Train Epoch: 71 [16560/17352 (95%)] Loss: -198018.187500\n",
      "Train Epoch: 71 [16640/17352 (96%)] Loss: -216392.828125\n",
      "Train Epoch: 71 [16720/17352 (96%)] Loss: -181922.046875\n",
      "Train Epoch: 71 [16800/17352 (97%)] Loss: -194997.468750\n",
      "Train Epoch: 71 [16880/17352 (97%)] Loss: -196934.765625\n",
      "Train Epoch: 71 [16960/17352 (98%)] Loss: -187648.968750\n",
      "Train Epoch: 71 [17040/17352 (98%)] Loss: -178196.875000\n",
      "Train Epoch: 71 [17120/17352 (99%)] Loss: -183607.484375\n",
      "Train Epoch: 71 [17200/17352 (99%)] Loss: -173665.531250\n",
      "Train Epoch: 71 [17280/17352 (100%)] Loss: -187617.968750\n",
      "Train Epoch: 71 [17360/17352 (100%)] Loss: -142339.765625\n",
      "    epoch          : 71\n",
      "    loss           : -189095.03803761507\n",
      "    val_loss       : -23716.186525944813\n",
      "Train Epoch: 72 [0/17352 (0%)] Loss: -216214.906250\n",
      "Train Epoch: 72 [80/17352 (0%)] Loss: -186071.937500\n",
      "Train Epoch: 72 [160/17352 (1%)] Loss: -224355.312500\n",
      "Train Epoch: 72 [240/17352 (1%)] Loss: -199808.468750\n",
      "Train Epoch: 72 [320/17352 (2%)] Loss: -212660.406250\n",
      "Train Epoch: 72 [400/17352 (2%)] Loss: -241901.765625\n",
      "Train Epoch: 72 [480/17352 (3%)] Loss: -188750.906250\n",
      "Train Epoch: 72 [560/17352 (3%)] Loss: -204711.171875\n",
      "Train Epoch: 72 [640/17352 (4%)] Loss: -199535.281250\n",
      "Train Epoch: 72 [720/17352 (4%)] Loss: -196443.890625\n",
      "Train Epoch: 72 [800/17352 (5%)] Loss: -230189.656250\n",
      "Train Epoch: 72 [880/17352 (5%)] Loss: -212697.218750\n",
      "Train Epoch: 72 [960/17352 (6%)] Loss: -219205.703125\n",
      "Train Epoch: 72 [1040/17352 (6%)] Loss: -214412.250000\n",
      "Train Epoch: 72 [1120/17352 (6%)] Loss: -214516.390625\n",
      "Train Epoch: 72 [1200/17352 (7%)] Loss: -215094.093750\n",
      "Train Epoch: 72 [1280/17352 (7%)] Loss: -196425.328125\n",
      "Train Epoch: 72 [1360/17352 (8%)] Loss: -213324.156250\n",
      "Train Epoch: 72 [1440/17352 (8%)] Loss: -229961.687500\n",
      "Train Epoch: 72 [1520/17352 (9%)] Loss: -228899.046875\n",
      "Train Epoch: 72 [1600/17352 (9%)] Loss: -215487.625000\n",
      "Train Epoch: 72 [1680/17352 (10%)] Loss: -216098.906250\n",
      "Train Epoch: 72 [1760/17352 (10%)] Loss: -193711.406250\n",
      "Train Epoch: 72 [1840/17352 (11%)] Loss: -193020.750000\n",
      "Train Epoch: 72 [1920/17352 (11%)] Loss: -217626.390625\n",
      "Train Epoch: 72 [2000/17352 (12%)] Loss: -230408.750000\n",
      "Train Epoch: 72 [2080/17352 (12%)] Loss: -209552.390625\n",
      "Train Epoch: 72 [2160/17352 (12%)] Loss: -204731.765625\n",
      "Train Epoch: 72 [2240/17352 (13%)] Loss: -183289.281250\n",
      "Train Epoch: 72 [2320/17352 (13%)] Loss: -172554.421875\n",
      "Train Epoch: 72 [2400/17352 (14%)] Loss: -196706.984375\n",
      "Train Epoch: 72 [2480/17352 (14%)] Loss: -164506.875000\n",
      "Train Epoch: 72 [2560/17352 (15%)] Loss: -206464.625000\n",
      "Train Epoch: 72 [2640/17352 (15%)] Loss: -183610.750000\n",
      "Train Epoch: 72 [2720/17352 (16%)] Loss: -185169.906250\n",
      "Train Epoch: 72 [2800/17352 (16%)] Loss: -156481.140625\n",
      "Train Epoch: 72 [2880/17352 (17%)] Loss: -186430.000000\n",
      "Train Epoch: 72 [2960/17352 (17%)] Loss: -163111.406250\n",
      "Train Epoch: 72 [3040/17352 (18%)] Loss: -196133.312500\n",
      "Train Epoch: 72 [3120/17352 (18%)] Loss: -207128.531250\n",
      "Train Epoch: 72 [3200/17352 (18%)] Loss: -179675.078125\n",
      "Train Epoch: 72 [3280/17352 (19%)] Loss: -203269.093750\n",
      "Train Epoch: 72 [3360/17352 (19%)] Loss: -186191.953125\n",
      "Train Epoch: 72 [3440/17352 (20%)] Loss: -191808.140625\n",
      "Train Epoch: 72 [3520/17352 (20%)] Loss: -152746.312500\n",
      "Train Epoch: 72 [3600/17352 (21%)] Loss: -183726.093750\n",
      "Train Epoch: 72 [3680/17352 (21%)] Loss: -158746.640625\n",
      "Train Epoch: 72 [3760/17352 (22%)] Loss: -178433.921875\n",
      "Train Epoch: 72 [3840/17352 (22%)] Loss: -197538.859375\n",
      "Train Epoch: 72 [3920/17352 (23%)] Loss: -180971.843750\n",
      "Train Epoch: 72 [4000/17352 (23%)] Loss: -175673.343750\n",
      "Train Epoch: 72 [4080/17352 (24%)] Loss: -190501.015625\n",
      "Train Epoch: 72 [4160/17352 (24%)] Loss: -180758.312500\n",
      "Train Epoch: 72 [4240/17352 (24%)] Loss: -174645.390625\n",
      "Train Epoch: 72 [4320/17352 (25%)] Loss: -189573.500000\n",
      "Train Epoch: 72 [4400/17352 (25%)] Loss: -171840.234375\n",
      "Train Epoch: 72 [4480/17352 (26%)] Loss: -189481.437500\n",
      "Train Epoch: 72 [4560/17352 (26%)] Loss: -202243.343750\n",
      "Train Epoch: 72 [4640/17352 (27%)] Loss: -207867.000000\n",
      "Train Epoch: 72 [4720/17352 (27%)] Loss: -191226.562500\n",
      "Train Epoch: 72 [4800/17352 (28%)] Loss: -208756.656250\n",
      "Train Epoch: 72 [4880/17352 (28%)] Loss: -195648.890625\n",
      "Train Epoch: 72 [4960/17352 (29%)] Loss: -203512.062500\n",
      "Train Epoch: 72 [5040/17352 (29%)] Loss: -194075.203125\n",
      "Train Epoch: 72 [5120/17352 (30%)] Loss: -170358.546875\n",
      "Train Epoch: 72 [5200/17352 (30%)] Loss: -195831.671875\n",
      "Train Epoch: 72 [5280/17352 (30%)] Loss: -177081.890625\n",
      "Train Epoch: 72 [5360/17352 (31%)] Loss: -185546.109375\n",
      "Train Epoch: 72 [5440/17352 (31%)] Loss: -179742.609375\n",
      "Train Epoch: 72 [5520/17352 (32%)] Loss: -169166.203125\n",
      "Train Epoch: 72 [5600/17352 (32%)] Loss: -182397.953125\n",
      "Train Epoch: 72 [5680/17352 (33%)] Loss: -167238.125000\n",
      "Train Epoch: 72 [5760/17352 (33%)] Loss: -167007.937500\n",
      "Train Epoch: 72 [5840/17352 (34%)] Loss: -185577.875000\n",
      "Train Epoch: 72 [5920/17352 (34%)] Loss: -227896.390625\n",
      "Train Epoch: 72 [6000/17352 (35%)] Loss: -165804.859375\n",
      "Train Epoch: 72 [6080/17352 (35%)] Loss: -208013.562500\n",
      "Train Epoch: 72 [6160/17352 (36%)] Loss: -204950.062500\n",
      "Train Epoch: 72 [6240/17352 (36%)] Loss: -199520.765625\n",
      "Train Epoch: 72 [6320/17352 (36%)] Loss: -181911.531250\n",
      "Train Epoch: 72 [6400/17352 (37%)] Loss: -178199.593750\n",
      "Train Epoch: 72 [6480/17352 (37%)] Loss: -134539.296875\n",
      "Train Epoch: 72 [6560/17352 (38%)] Loss: -204687.750000\n",
      "Train Epoch: 72 [6640/17352 (38%)] Loss: -202584.156250\n",
      "Train Epoch: 72 [6720/17352 (39%)] Loss: -203748.718750\n",
      "Train Epoch: 72 [6800/17352 (39%)] Loss: -185333.140625\n",
      "Train Epoch: 72 [6880/17352 (40%)] Loss: -148402.218750\n",
      "Train Epoch: 72 [6960/17352 (40%)] Loss: -202021.125000\n",
      "Train Epoch: 72 [7040/17352 (41%)] Loss: -165732.296875\n",
      "Train Epoch: 72 [7120/17352 (41%)] Loss: -208157.890625\n",
      "Train Epoch: 72 [7200/17352 (41%)] Loss: -203881.437500\n",
      "Train Epoch: 72 [7280/17352 (42%)] Loss: -182771.625000\n",
      "Train Epoch: 72 [7360/17352 (42%)] Loss: -164881.625000\n",
      "Train Epoch: 72 [7440/17352 (43%)] Loss: -219920.875000\n",
      "Train Epoch: 72 [7520/17352 (43%)] Loss: -184456.796875\n",
      "Train Epoch: 72 [7600/17352 (44%)] Loss: -170110.859375\n",
      "Train Epoch: 72 [7680/17352 (44%)] Loss: -201517.265625\n",
      "Train Epoch: 72 [7760/17352 (45%)] Loss: -187521.156250\n",
      "Train Epoch: 72 [7840/17352 (45%)] Loss: -188438.656250\n",
      "Train Epoch: 72 [7920/17352 (46%)] Loss: -186948.546875\n",
      "Train Epoch: 72 [8000/17352 (46%)] Loss: -184819.687500\n",
      "Train Epoch: 72 [8080/17352 (47%)] Loss: -187305.781250\n",
      "Train Epoch: 72 [8160/17352 (47%)] Loss: -202980.906250\n",
      "Train Epoch: 72 [8240/17352 (47%)] Loss: -182742.984375\n",
      "Train Epoch: 72 [8320/17352 (48%)] Loss: -164684.828125\n",
      "Train Epoch: 72 [8400/17352 (48%)] Loss: -188564.234375\n",
      "Train Epoch: 72 [8480/17352 (49%)] Loss: -175509.437500\n",
      "Train Epoch: 72 [8560/17352 (49%)] Loss: -183971.156250\n",
      "Train Epoch: 72 [8640/17352 (50%)] Loss: -168965.015625\n",
      "Train Epoch: 72 [8720/17352 (50%)] Loss: -190989.593750\n",
      "Train Epoch: 72 [8800/17352 (51%)] Loss: -167188.765625\n",
      "Train Epoch: 72 [8880/17352 (51%)] Loss: -173950.687500\n",
      "Train Epoch: 72 [8960/17352 (52%)] Loss: -181960.218750\n",
      "Train Epoch: 72 [9040/17352 (52%)] Loss: -184951.265625\n",
      "Train Epoch: 72 [9120/17352 (53%)] Loss: -212903.703125\n",
      "Train Epoch: 72 [9200/17352 (53%)] Loss: -190993.562500\n",
      "Train Epoch: 72 [9280/17352 (53%)] Loss: -181161.281250\n",
      "Train Epoch: 72 [9360/17352 (54%)] Loss: -201263.890625\n",
      "Train Epoch: 72 [9440/17352 (54%)] Loss: -193000.125000\n",
      "Train Epoch: 72 [9520/17352 (55%)] Loss: -212617.671875\n",
      "Train Epoch: 72 [9600/17352 (55%)] Loss: -148161.656250\n",
      "Train Epoch: 72 [9680/17352 (56%)] Loss: -175367.562500\n",
      "Train Epoch: 72 [9760/17352 (56%)] Loss: -206228.296875\n",
      "Train Epoch: 72 [9840/17352 (57%)] Loss: -176159.437500\n",
      "Train Epoch: 72 [9920/17352 (57%)] Loss: -216323.125000\n",
      "Train Epoch: 72 [10000/17352 (58%)] Loss: -187407.218750\n",
      "Train Epoch: 72 [10080/17352 (58%)] Loss: -159310.734375\n",
      "Train Epoch: 72 [10160/17352 (59%)] Loss: -179446.390625\n",
      "Train Epoch: 72 [10240/17352 (59%)] Loss: -179008.687500\n",
      "Train Epoch: 72 [10320/17352 (59%)] Loss: -163087.609375\n",
      "Train Epoch: 72 [10400/17352 (60%)] Loss: -160049.468750\n",
      "Train Epoch: 72 [10480/17352 (60%)] Loss: -193512.578125\n",
      "Train Epoch: 72 [10560/17352 (61%)] Loss: -181337.531250\n",
      "Train Epoch: 72 [10640/17352 (61%)] Loss: -196124.890625\n",
      "Train Epoch: 72 [10720/17352 (62%)] Loss: -210558.843750\n",
      "Train Epoch: 72 [10800/17352 (62%)] Loss: -195300.796875\n",
      "Train Epoch: 72 [10880/17352 (63%)] Loss: -202081.718750\n",
      "Train Epoch: 72 [10960/17352 (63%)] Loss: -206563.843750\n",
      "Train Epoch: 72 [11040/17352 (64%)] Loss: -204332.859375\n",
      "Train Epoch: 72 [11120/17352 (64%)] Loss: -166410.406250\n",
      "Train Epoch: 72 [11200/17352 (65%)] Loss: -163762.968750\n",
      "Train Epoch: 72 [11280/17352 (65%)] Loss: -190791.281250\n",
      "Train Epoch: 72 [11360/17352 (65%)] Loss: -172892.640625\n",
      "Train Epoch: 72 [11440/17352 (66%)] Loss: -158609.343750\n",
      "Train Epoch: 72 [11520/17352 (66%)] Loss: -170535.171875\n",
      "Train Epoch: 72 [11600/17352 (67%)] Loss: -177621.312500\n",
      "Train Epoch: 72 [11680/17352 (67%)] Loss: -181069.578125\n",
      "Train Epoch: 72 [11760/17352 (68%)] Loss: -176591.828125\n",
      "Train Epoch: 72 [11840/17352 (68%)] Loss: -188808.609375\n",
      "Train Epoch: 72 [11920/17352 (69%)] Loss: -151738.953125\n",
      "Train Epoch: 72 [12000/17352 (69%)] Loss: -181376.437500\n",
      "Train Epoch: 72 [12080/17352 (70%)] Loss: -178808.625000\n",
      "Train Epoch: 72 [12160/17352 (70%)] Loss: -195788.671875\n",
      "Train Epoch: 72 [12240/17352 (71%)] Loss: -187645.984375\n",
      "Train Epoch: 72 [12320/17352 (71%)] Loss: -160149.140625\n",
      "Train Epoch: 72 [12400/17352 (71%)] Loss: -170677.187500\n",
      "Train Epoch: 72 [12480/17352 (72%)] Loss: -192790.546875\n",
      "Train Epoch: 72 [12560/17352 (72%)] Loss: -170238.296875\n",
      "Train Epoch: 72 [12640/17352 (73%)] Loss: -175544.437500\n",
      "Train Epoch: 72 [12720/17352 (73%)] Loss: -190581.125000\n",
      "Train Epoch: 72 [12800/17352 (74%)] Loss: -176705.640625\n",
      "Train Epoch: 72 [12880/17352 (74%)] Loss: -176922.234375\n",
      "Train Epoch: 72 [12960/17352 (75%)] Loss: -187596.718750\n",
      "Train Epoch: 72 [13040/17352 (75%)] Loss: -160099.984375\n",
      "Train Epoch: 72 [13120/17352 (76%)] Loss: -187713.859375\n",
      "Train Epoch: 72 [13200/17352 (76%)] Loss: -185506.593750\n",
      "Train Epoch: 72 [13280/17352 (77%)] Loss: -200205.031250\n",
      "Train Epoch: 72 [13360/17352 (77%)] Loss: -201391.156250\n",
      "Train Epoch: 72 [13440/17352 (77%)] Loss: -199417.468750\n",
      "Train Epoch: 72 [13520/17352 (78%)] Loss: -193196.890625\n",
      "Train Epoch: 72 [13600/17352 (78%)] Loss: -164079.593750\n",
      "Train Epoch: 72 [13680/17352 (79%)] Loss: -213402.156250\n",
      "Train Epoch: 72 [13760/17352 (79%)] Loss: -193355.328125\n",
      "Train Epoch: 72 [13840/17352 (80%)] Loss: -183753.984375\n",
      "Train Epoch: 72 [13920/17352 (80%)] Loss: -182097.187500\n",
      "Train Epoch: 72 [14000/17352 (81%)] Loss: -198546.031250\n",
      "Train Epoch: 72 [14080/17352 (81%)] Loss: -148445.296875\n",
      "Train Epoch: 72 [14160/17352 (82%)] Loss: -181611.593750\n",
      "Train Epoch: 72 [14240/17352 (82%)] Loss: -197380.921875\n",
      "Train Epoch: 72 [14320/17352 (83%)] Loss: -177303.109375\n",
      "Train Epoch: 72 [14400/17352 (83%)] Loss: -202518.093750\n",
      "Train Epoch: 72 [14480/17352 (83%)] Loss: -180696.171875\n",
      "Train Epoch: 72 [14560/17352 (84%)] Loss: -208345.093750\n",
      "Train Epoch: 72 [14640/17352 (84%)] Loss: -151509.437500\n",
      "Train Epoch: 72 [14720/17352 (85%)] Loss: -172180.171875\n",
      "Train Epoch: 72 [14800/17352 (85%)] Loss: -167296.515625\n",
      "Train Epoch: 72 [14880/17352 (86%)] Loss: -199780.062500\n",
      "Train Epoch: 72 [14960/17352 (86%)] Loss: -192247.343750\n",
      "Train Epoch: 72 [15040/17352 (87%)] Loss: -214962.281250\n",
      "Train Epoch: 72 [15120/17352 (87%)] Loss: -173126.687500\n",
      "Train Epoch: 72 [15200/17352 (88%)] Loss: -193496.171875\n",
      "Train Epoch: 72 [15280/17352 (88%)] Loss: -183083.921875\n",
      "Train Epoch: 72 [15360/17352 (89%)] Loss: -183872.796875\n",
      "Train Epoch: 72 [15440/17352 (89%)] Loss: -188092.531250\n",
      "Train Epoch: 72 [15520/17352 (89%)] Loss: -176585.406250\n",
      "Train Epoch: 72 [15600/17352 (90%)] Loss: -188966.109375\n",
      "Train Epoch: 72 [15680/17352 (90%)] Loss: -201381.015625\n",
      "Train Epoch: 72 [15760/17352 (91%)] Loss: -207093.218750\n",
      "Train Epoch: 72 [15840/17352 (91%)] Loss: -187252.187500\n",
      "Train Epoch: 72 [15920/17352 (92%)] Loss: -199177.078125\n",
      "Train Epoch: 72 [16000/17352 (92%)] Loss: -196197.937500\n",
      "Train Epoch: 72 [16080/17352 (93%)] Loss: -203848.281250\n",
      "Train Epoch: 72 [16160/17352 (93%)] Loss: -169747.562500\n",
      "Train Epoch: 72 [16240/17352 (94%)] Loss: -225471.031250\n",
      "Train Epoch: 72 [16320/17352 (94%)] Loss: -198015.531250\n",
      "Train Epoch: 72 [16400/17352 (95%)] Loss: -174451.125000\n",
      "Train Epoch: 72 [16480/17352 (95%)] Loss: -185296.656250\n",
      "Train Epoch: 72 [16560/17352 (95%)] Loss: -185371.765625\n",
      "Train Epoch: 72 [16640/17352 (96%)] Loss: -170034.921875\n",
      "Train Epoch: 72 [16720/17352 (96%)] Loss: -196044.593750\n",
      "Train Epoch: 72 [16800/17352 (97%)] Loss: -168254.484375\n",
      "Train Epoch: 72 [16880/17352 (97%)] Loss: -177776.796875\n",
      "Train Epoch: 72 [16960/17352 (98%)] Loss: -194936.968750\n",
      "Train Epoch: 72 [17040/17352 (98%)] Loss: -149030.609375\n",
      "Train Epoch: 72 [17120/17352 (99%)] Loss: -199072.703125\n",
      "Train Epoch: 72 [17200/17352 (99%)] Loss: -210920.937500\n",
      "Train Epoch: 72 [17280/17352 (100%)] Loss: -187791.109375\n",
      "Train Epoch: 72 [17360/17352 (100%)] Loss: -181337.687500\n",
      "    epoch          : 72\n",
      "    loss           : -189169.60323468066\n",
      "    val_loss       : -23716.180240899743\n",
      "Train Epoch: 73 [0/17352 (0%)] Loss: -212370.406250\n",
      "Train Epoch: 73 [80/17352 (0%)] Loss: -210634.671875\n",
      "Train Epoch: 73 [160/17352 (1%)] Loss: -236630.593750\n",
      "Train Epoch: 73 [240/17352 (1%)] Loss: -209557.734375\n",
      "Train Epoch: 73 [320/17352 (2%)] Loss: -210203.734375\n",
      "Train Epoch: 73 [400/17352 (2%)] Loss: -185158.031250\n",
      "Train Epoch: 73 [480/17352 (3%)] Loss: -206566.640625\n",
      "Train Epoch: 73 [560/17352 (3%)] Loss: -219203.187500\n",
      "Train Epoch: 73 [640/17352 (4%)] Loss: -215833.000000\n",
      "Train Epoch: 73 [720/17352 (4%)] Loss: -204363.343750\n",
      "Train Epoch: 73 [800/17352 (5%)] Loss: -199103.125000\n",
      "Train Epoch: 73 [880/17352 (5%)] Loss: -215484.609375\n",
      "Train Epoch: 73 [960/17352 (6%)] Loss: -219665.062500\n",
      "Train Epoch: 73 [1040/17352 (6%)] Loss: -210529.812500\n",
      "Train Epoch: 73 [1120/17352 (6%)] Loss: -206652.328125\n",
      "Train Epoch: 73 [1200/17352 (7%)] Loss: -212703.937500\n",
      "Train Epoch: 73 [1280/17352 (7%)] Loss: -214337.859375\n",
      "Train Epoch: 73 [1360/17352 (8%)] Loss: -196444.640625\n",
      "Train Epoch: 73 [1440/17352 (8%)] Loss: -205201.375000\n",
      "Train Epoch: 73 [1520/17352 (9%)] Loss: -213840.765625\n",
      "Train Epoch: 73 [1600/17352 (9%)] Loss: -215108.687500\n",
      "Train Epoch: 73 [1680/17352 (10%)] Loss: -228901.312500\n",
      "Train Epoch: 73 [1760/17352 (10%)] Loss: -198772.906250\n",
      "Train Epoch: 73 [1840/17352 (11%)] Loss: -204400.609375\n",
      "Train Epoch: 73 [1920/17352 (11%)] Loss: -205078.156250\n",
      "Train Epoch: 73 [2000/17352 (12%)] Loss: -188754.156250\n",
      "Train Epoch: 73 [2080/17352 (12%)] Loss: -211901.859375\n",
      "Train Epoch: 73 [2160/17352 (12%)] Loss: -194295.859375\n",
      "Train Epoch: 73 [2240/17352 (13%)] Loss: -192887.390625\n",
      "Train Epoch: 73 [2320/17352 (13%)] Loss: -183617.625000\n",
      "Train Epoch: 73 [2400/17352 (14%)] Loss: -177250.562500\n",
      "Train Epoch: 73 [2480/17352 (14%)] Loss: -206225.109375\n",
      "Train Epoch: 73 [2560/17352 (15%)] Loss: -179466.921875\n",
      "Train Epoch: 73 [2640/17352 (15%)] Loss: -189015.218750\n",
      "Train Epoch: 73 [2720/17352 (16%)] Loss: -172197.171875\n",
      "Train Epoch: 73 [2800/17352 (16%)] Loss: -191837.312500\n",
      "Train Epoch: 73 [2880/17352 (17%)] Loss: -181735.562500\n",
      "Train Epoch: 73 [2960/17352 (17%)] Loss: -171720.390625\n",
      "Train Epoch: 73 [3040/17352 (18%)] Loss: -189176.640625\n",
      "Train Epoch: 73 [3120/17352 (18%)] Loss: -153326.375000\n",
      "Train Epoch: 73 [3200/17352 (18%)] Loss: -179009.343750\n",
      "Train Epoch: 73 [3280/17352 (19%)] Loss: -167217.281250\n",
      "Train Epoch: 73 [3360/17352 (19%)] Loss: -200404.093750\n",
      "Train Epoch: 73 [3440/17352 (20%)] Loss: -171585.625000\n",
      "Train Epoch: 73 [3520/17352 (20%)] Loss: -197106.093750\n",
      "Train Epoch: 73 [3600/17352 (21%)] Loss: -187717.843750\n",
      "Train Epoch: 73 [3680/17352 (21%)] Loss: -213752.984375\n",
      "Train Epoch: 73 [3760/17352 (22%)] Loss: -171320.750000\n",
      "Train Epoch: 73 [3840/17352 (22%)] Loss: -184755.859375\n",
      "Train Epoch: 73 [3920/17352 (23%)] Loss: -203460.125000\n",
      "Train Epoch: 73 [4000/17352 (23%)] Loss: -164504.875000\n",
      "Train Epoch: 73 [4080/17352 (24%)] Loss: -201368.921875\n",
      "Train Epoch: 73 [4160/17352 (24%)] Loss: -193920.609375\n",
      "Train Epoch: 73 [4240/17352 (24%)] Loss: -192639.531250\n",
      "Train Epoch: 73 [4320/17352 (25%)] Loss: -203509.281250\n",
      "Train Epoch: 73 [4400/17352 (25%)] Loss: -192381.953125\n",
      "Train Epoch: 73 [4480/17352 (26%)] Loss: -200874.421875\n",
      "Train Epoch: 73 [4560/17352 (26%)] Loss: -177076.687500\n",
      "Train Epoch: 73 [4640/17352 (27%)] Loss: -205505.296875\n",
      "Train Epoch: 73 [4720/17352 (27%)] Loss: -202574.500000\n",
      "Train Epoch: 73 [4800/17352 (28%)] Loss: -161958.875000\n",
      "Train Epoch: 73 [4880/17352 (28%)] Loss: -191008.359375\n",
      "Train Epoch: 73 [4960/17352 (29%)] Loss: -191596.937500\n",
      "Train Epoch: 73 [5040/17352 (29%)] Loss: -187222.703125\n",
      "Train Epoch: 73 [5120/17352 (30%)] Loss: -184991.750000\n",
      "Train Epoch: 73 [5200/17352 (30%)] Loss: -201263.609375\n",
      "Train Epoch: 73 [5280/17352 (30%)] Loss: -205393.156250\n",
      "Train Epoch: 73 [5360/17352 (31%)] Loss: -189604.875000\n",
      "Train Epoch: 73 [5440/17352 (31%)] Loss: -181621.093750\n",
      "Train Epoch: 73 [5520/17352 (32%)] Loss: -177235.593750\n",
      "Train Epoch: 73 [5600/17352 (32%)] Loss: -193006.265625\n",
      "Train Epoch: 73 [5680/17352 (33%)] Loss: -215459.578125\n",
      "Train Epoch: 73 [5760/17352 (33%)] Loss: -174726.781250\n",
      "Train Epoch: 73 [5840/17352 (34%)] Loss: -195065.421875\n",
      "Train Epoch: 73 [5920/17352 (34%)] Loss: -177096.359375\n",
      "Train Epoch: 73 [6000/17352 (35%)] Loss: -149032.531250\n",
      "Train Epoch: 73 [6080/17352 (35%)] Loss: -201955.109375\n",
      "Train Epoch: 73 [6160/17352 (36%)] Loss: -172897.265625\n",
      "Train Epoch: 73 [6240/17352 (36%)] Loss: -206245.406250\n",
      "Train Epoch: 73 [6320/17352 (36%)] Loss: -188269.062500\n",
      "Train Epoch: 73 [6400/17352 (37%)] Loss: -199783.078125\n",
      "Train Epoch: 73 [6480/17352 (37%)] Loss: -206931.312500\n",
      "Train Epoch: 73 [6560/17352 (38%)] Loss: -198018.359375\n",
      "Train Epoch: 73 [6640/17352 (38%)] Loss: -191056.625000\n",
      "Train Epoch: 73 [6720/17352 (39%)] Loss: -191805.437500\n",
      "Train Epoch: 73 [6800/17352 (39%)] Loss: -173844.984375\n",
      "Train Epoch: 73 [6880/17352 (40%)] Loss: -185245.484375\n",
      "Train Epoch: 73 [6960/17352 (40%)] Loss: -151737.156250\n",
      "Train Epoch: 73 [7040/17352 (41%)] Loss: -176291.968750\n",
      "Train Epoch: 73 [7120/17352 (41%)] Loss: -171307.531250\n",
      "Train Epoch: 73 [7200/17352 (41%)] Loss: -180308.593750\n",
      "Train Epoch: 73 [7280/17352 (42%)] Loss: -187713.750000\n",
      "Train Epoch: 73 [7360/17352 (42%)] Loss: -189483.781250\n",
      "Train Epoch: 73 [7440/17352 (43%)] Loss: -167958.531250\n",
      "Train Epoch: 73 [7520/17352 (43%)] Loss: -191040.656250\n",
      "Train Epoch: 73 [7600/17352 (44%)] Loss: -209902.312500\n",
      "Train Epoch: 73 [7680/17352 (44%)] Loss: -164138.281250\n",
      "Train Epoch: 73 [7760/17352 (45%)] Loss: -165365.375000\n",
      "Train Epoch: 73 [7840/17352 (45%)] Loss: -185004.125000\n",
      "Train Epoch: 73 [7920/17352 (46%)] Loss: -177312.531250\n",
      "Train Epoch: 73 [8000/17352 (46%)] Loss: -187887.359375\n",
      "Train Epoch: 73 [8080/17352 (47%)] Loss: -208013.671875\n",
      "Train Epoch: 73 [8160/17352 (47%)] Loss: -188054.875000\n",
      "Train Epoch: 73 [8240/17352 (47%)] Loss: -177605.984375\n",
      "Train Epoch: 73 [8320/17352 (48%)] Loss: -188870.078125\n",
      "Train Epoch: 73 [8400/17352 (48%)] Loss: -208430.500000\n",
      "Train Epoch: 73 [8480/17352 (49%)] Loss: -195830.843750\n",
      "Train Epoch: 73 [8560/17352 (49%)] Loss: -175364.343750\n",
      "Train Epoch: 73 [8640/17352 (50%)] Loss: -172966.812500\n",
      "Train Epoch: 73 [8720/17352 (50%)] Loss: -215631.906250\n",
      "Train Epoch: 73 [8800/17352 (51%)] Loss: -178877.687500\n",
      "Train Epoch: 73 [8880/17352 (51%)] Loss: -192266.781250\n",
      "Train Epoch: 73 [8960/17352 (52%)] Loss: -167805.937500\n",
      "Train Epoch: 73 [9040/17352 (52%)] Loss: -217620.875000\n",
      "Train Epoch: 73 [9120/17352 (53%)] Loss: -196126.140625\n",
      "Train Epoch: 73 [9200/17352 (53%)] Loss: -200201.156250\n",
      "Train Epoch: 73 [9280/17352 (53%)] Loss: -221252.546875\n",
      "Train Epoch: 73 [9360/17352 (54%)] Loss: -197522.187500\n",
      "Train Epoch: 73 [9440/17352 (54%)] Loss: -188218.093750\n",
      "Train Epoch: 73 [9520/17352 (55%)] Loss: -185539.625000\n",
      "Train Epoch: 73 [9600/17352 (55%)] Loss: -167081.375000\n",
      "Train Epoch: 73 [9680/17352 (56%)] Loss: -175597.875000\n",
      "Train Epoch: 73 [9760/17352 (56%)] Loss: -187247.578125\n",
      "Train Epoch: 73 [9840/17352 (57%)] Loss: -189269.593750\n",
      "Train Epoch: 73 [9920/17352 (57%)] Loss: -166029.453125\n",
      "Train Epoch: 73 [10000/17352 (58%)] Loss: -174943.656250\n",
      "Train Epoch: 73 [10080/17352 (58%)] Loss: -188256.484375\n",
      "Train Epoch: 73 [10160/17352 (59%)] Loss: -167733.562500\n",
      "Train Epoch: 73 [10240/17352 (59%)] Loss: -195299.781250\n",
      "Train Epoch: 73 [10320/17352 (59%)] Loss: -171844.859375\n",
      "Train Epoch: 73 [10400/17352 (60%)] Loss: -181339.015625\n",
      "Train Epoch: 73 [10480/17352 (60%)] Loss: -205021.375000\n",
      "Train Epoch: 73 [10560/17352 (61%)] Loss: -157587.500000\n",
      "Train Epoch: 73 [10640/17352 (61%)] Loss: -189723.093750\n",
      "Train Epoch: 73 [10720/17352 (62%)] Loss: -179684.734375\n",
      "Train Epoch: 73 [10800/17352 (62%)] Loss: -180262.562500\n",
      "Train Epoch: 73 [10880/17352 (63%)] Loss: -196198.218750\n",
      "Train Epoch: 73 [10960/17352 (63%)] Loss: -183718.031250\n",
      "Train Epoch: 73 [11040/17352 (64%)] Loss: -180249.000000\n",
      "Train Epoch: 73 [11120/17352 (64%)] Loss: -206692.453125\n",
      "Train Epoch: 73 [11200/17352 (65%)] Loss: -175068.296875\n",
      "Train Epoch: 73 [11280/17352 (65%)] Loss: -204330.953125\n",
      "Train Epoch: 73 [11360/17352 (65%)] Loss: -208123.265625\n",
      "Train Epoch: 73 [11440/17352 (66%)] Loss: -212132.140625\n",
      "Train Epoch: 73 [11520/17352 (66%)] Loss: -196940.390625\n",
      "Train Epoch: 73 [11600/17352 (67%)] Loss: -208721.468750\n",
      "Train Epoch: 73 [11680/17352 (67%)] Loss: -162557.546875\n",
      "Train Epoch: 73 [11760/17352 (68%)] Loss: -193051.218750\n",
      "Train Epoch: 73 [11840/17352 (68%)] Loss: -208900.328125\n",
      "Train Epoch: 73 [11920/17352 (69%)] Loss: -191806.875000\n",
      "Train Epoch: 73 [12000/17352 (69%)] Loss: -136429.656250\n",
      "Train Epoch: 73 [12080/17352 (70%)] Loss: -173664.046875\n",
      "Train Epoch: 73 [12160/17352 (70%)] Loss: -192287.593750\n",
      "Train Epoch: 73 [12240/17352 (71%)] Loss: -171732.843750\n",
      "Train Epoch: 73 [12320/17352 (71%)] Loss: -201388.109375\n",
      "Train Epoch: 73 [12400/17352 (71%)] Loss: -190987.000000\n",
      "Train Epoch: 73 [12480/17352 (72%)] Loss: -174625.187500\n",
      "Train Epoch: 73 [12560/17352 (72%)] Loss: -161511.093750\n",
      "Train Epoch: 73 [12640/17352 (73%)] Loss: -185996.687500\n",
      "Train Epoch: 73 [12720/17352 (73%)] Loss: -182746.500000\n",
      "Train Epoch: 73 [12800/17352 (74%)] Loss: -193800.187500\n",
      "Train Epoch: 73 [12880/17352 (74%)] Loss: -159670.687500\n",
      "Train Epoch: 73 [12960/17352 (75%)] Loss: -199778.406250\n",
      "Train Epoch: 73 [13040/17352 (75%)] Loss: -203847.156250\n",
      "Train Epoch: 73 [13120/17352 (76%)] Loss: -188565.609375\n",
      "Train Epoch: 73 [13200/17352 (76%)] Loss: -168255.875000\n",
      "Train Epoch: 73 [13280/17352 (77%)] Loss: -164688.359375\n",
      "Train Epoch: 73 [13360/17352 (77%)] Loss: -192124.421875\n",
      "Train Epoch: 73 [13440/17352 (77%)] Loss: -191513.656250\n",
      "Train Epoch: 73 [13520/17352 (78%)] Loss: -183802.125000\n",
      "Train Epoch: 73 [13600/17352 (78%)] Loss: -198803.140625\n",
      "Train Epoch: 73 [13680/17352 (79%)] Loss: -183727.593750\n",
      "Train Epoch: 73 [13760/17352 (79%)] Loss: -148823.609375\n",
      "Train Epoch: 73 [13840/17352 (80%)] Loss: -189570.437500\n",
      "Train Epoch: 73 [13920/17352 (80%)] Loss: -170535.421875\n",
      "Train Epoch: 73 [14000/17352 (81%)] Loss: -203261.312500\n",
      "Train Epoch: 73 [14080/17352 (81%)] Loss: -153891.734375\n",
      "Train Epoch: 73 [14160/17352 (82%)] Loss: -183973.375000\n",
      "Train Epoch: 73 [14240/17352 (82%)] Loss: -192234.328125\n",
      "Train Epoch: 73 [14320/17352 (83%)] Loss: -185313.078125\n",
      "Train Epoch: 73 [14400/17352 (83%)] Loss: -201116.203125\n",
      "Train Epoch: 73 [14480/17352 (83%)] Loss: -168193.531250\n",
      "Train Epoch: 73 [14560/17352 (84%)] Loss: -173127.203125\n",
      "Train Epoch: 73 [14640/17352 (84%)] Loss: -163496.781250\n",
      "Train Epoch: 73 [14720/17352 (85%)] Loss: -220975.515625\n",
      "Train Epoch: 73 [14800/17352 (85%)] Loss: -224867.718750\n",
      "Train Epoch: 73 [14880/17352 (86%)] Loss: -192957.000000\n",
      "Train Epoch: 73 [14960/17352 (86%)] Loss: -152900.000000\n",
      "Train Epoch: 73 [15040/17352 (87%)] Loss: -191232.765625\n",
      "Train Epoch: 73 [15120/17352 (87%)] Loss: -196198.546875\n",
      "Train Epoch: 73 [15200/17352 (88%)] Loss: -178601.093750\n",
      "Train Epoch: 73 [15280/17352 (88%)] Loss: -194952.265625\n",
      "Train Epoch: 73 [15360/17352 (89%)] Loss: -182095.890625\n",
      "Train Epoch: 73 [15440/17352 (89%)] Loss: -202196.796875\n",
      "Train Epoch: 73 [15520/17352 (89%)] Loss: -203877.968750\n",
      "Train Epoch: 73 [15600/17352 (90%)] Loss: -193512.515625\n",
      "Train Epoch: 73 [15680/17352 (90%)] Loss: -190216.765625\n",
      "Train Epoch: 73 [15760/17352 (91%)] Loss: -152740.453125\n",
      "Train Epoch: 73 [15840/17352 (91%)] Loss: -191557.265625\n",
      "Train Epoch: 73 [15920/17352 (92%)] Loss: -173002.546875\n",
      "Train Epoch: 73 [16000/17352 (92%)] Loss: -190919.937500\n",
      "Train Epoch: 73 [16080/17352 (93%)] Loss: -199894.062500\n",
      "Train Epoch: 73 [16160/17352 (93%)] Loss: -193049.062500\n",
      "Train Epoch: 73 [16240/17352 (94%)] Loss: -179485.296875\n",
      "Train Epoch: 73 [16320/17352 (94%)] Loss: -200296.390625\n",
      "Train Epoch: 73 [16400/17352 (95%)] Loss: -176962.406250\n",
      "Train Epoch: 73 [16480/17352 (95%)] Loss: -200169.062500\n",
      "Train Epoch: 73 [16560/17352 (95%)] Loss: -178727.765625\n",
      "Train Epoch: 73 [16640/17352 (96%)] Loss: -167039.812500\n",
      "Train Epoch: 73 [16720/17352 (96%)] Loss: -194228.125000\n",
      "Train Epoch: 73 [16800/17352 (97%)] Loss: -192958.015625\n",
      "Train Epoch: 73 [16880/17352 (97%)] Loss: -192374.453125\n",
      "Train Epoch: 73 [16960/17352 (98%)] Loss: -176705.906250\n",
      "Train Epoch: 73 [17040/17352 (98%)] Loss: -175411.109375\n",
      "Train Epoch: 73 [17120/17352 (99%)] Loss: -213405.078125\n",
      "Train Epoch: 73 [17200/17352 (99%)] Loss: -178383.484375\n",
      "Train Epoch: 73 [17280/17352 (100%)] Loss: -187127.890625\n",
      "Train Epoch: 73 [17360/17352 (100%)] Loss: -186778.656250\n",
      "    epoch          : 73\n",
      "    loss           : -189451.1848568757\n",
      "    val_loss       : -23716.184191421722\n",
      "Train Epoch: 74 [0/17352 (0%)] Loss: -210755.859375\n",
      "Train Epoch: 74 [80/17352 (0%)] Loss: -224252.906250\n",
      "Train Epoch: 74 [160/17352 (1%)] Loss: -217628.796875\n",
      "Train Epoch: 74 [240/17352 (1%)] Loss: -228014.375000\n",
      "Train Epoch: 74 [320/17352 (2%)] Loss: -193029.703125\n",
      "Train Epoch: 74 [400/17352 (2%)] Loss: -226106.390625\n",
      "Train Epoch: 74 [480/17352 (3%)] Loss: -214523.796875\n",
      "Train Epoch: 74 [560/17352 (3%)] Loss: -217941.125000\n",
      "Train Epoch: 74 [640/17352 (4%)] Loss: -230183.156250\n",
      "Train Epoch: 74 [720/17352 (4%)] Loss: -205213.437500\n",
      "Train Epoch: 74 [800/17352 (5%)] Loss: -230409.046875\n",
      "Train Epoch: 74 [880/17352 (5%)] Loss: -209786.562500\n",
      "Train Epoch: 74 [960/17352 (6%)] Loss: -218567.062500\n",
      "Train Epoch: 74 [1040/17352 (6%)] Loss: -214519.765625\n",
      "Train Epoch: 74 [1120/17352 (6%)] Loss: -206784.453125\n",
      "Train Epoch: 74 [1200/17352 (7%)] Loss: -224254.687500\n",
      "Train Epoch: 74 [1280/17352 (7%)] Loss: -229239.140625\n",
      "Train Epoch: 74 [1360/17352 (8%)] Loss: -193705.296875\n",
      "Train Epoch: 74 [1440/17352 (8%)] Loss: -212704.031250\n",
      "Train Epoch: 74 [1520/17352 (9%)] Loss: -210206.437500\n",
      "Train Epoch: 74 [1600/17352 (9%)] Loss: -204734.500000\n",
      "Train Epoch: 74 [1680/17352 (10%)] Loss: -206651.796875\n",
      "Train Epoch: 74 [1760/17352 (10%)] Loss: -211897.140625\n",
      "Train Epoch: 74 [1840/17352 (11%)] Loss: -199926.890625\n",
      "Train Epoch: 74 [1920/17352 (11%)] Loss: -191881.546875\n",
      "Train Epoch: 74 [2000/17352 (12%)] Loss: -209642.015625\n",
      "Train Epoch: 74 [2080/17352 (12%)] Loss: -236510.687500\n",
      "Train Epoch: 74 [2160/17352 (12%)] Loss: -219257.171875\n",
      "Train Epoch: 74 [2240/17352 (13%)] Loss: -180512.328125\n",
      "Train Epoch: 74 [2320/17352 (13%)] Loss: -186607.593750\n",
      "Train Epoch: 74 [2400/17352 (14%)] Loss: -148922.937500\n",
      "Train Epoch: 74 [2480/17352 (14%)] Loss: -204947.968750\n",
      "Train Epoch: 74 [2560/17352 (15%)] Loss: -196044.437500\n",
      "Train Epoch: 74 [2640/17352 (15%)] Loss: -174190.031250\n",
      "Train Epoch: 74 [2720/17352 (16%)] Loss: -199146.984375\n",
      "Train Epoch: 74 [2800/17352 (16%)] Loss: -203138.843750\n",
      "Train Epoch: 74 [2880/17352 (17%)] Loss: -192639.484375\n",
      "Train Epoch: 74 [2960/17352 (17%)] Loss: -225481.468750\n",
      "Train Epoch: 74 [3040/17352 (18%)] Loss: -178875.593750\n",
      "Train Epoch: 74 [3120/17352 (18%)] Loss: -178138.140625\n",
      "Train Epoch: 74 [3200/17352 (18%)] Loss: -186041.484375\n",
      "Train Epoch: 74 [3280/17352 (19%)] Loss: -177974.234375\n",
      "Train Epoch: 74 [3360/17352 (19%)] Loss: -200414.890625\n",
      "Train Epoch: 74 [3440/17352 (20%)] Loss: -177601.937500\n",
      "Train Epoch: 74 [3520/17352 (20%)] Loss: -164507.859375\n",
      "Train Epoch: 74 [3600/17352 (21%)] Loss: -192271.109375\n",
      "Train Epoch: 74 [3680/17352 (21%)] Loss: -156996.640625\n",
      "Train Epoch: 74 [3760/17352 (22%)] Loss: -177784.859375\n",
      "Train Epoch: 74 [3840/17352 (22%)] Loss: -184957.562500\n",
      "Train Epoch: 74 [3920/17352 (23%)] Loss: -176483.562500\n",
      "Train Epoch: 74 [4000/17352 (23%)] Loss: -178328.218750\n",
      "Train Epoch: 74 [4080/17352 (24%)] Loss: -188970.781250\n",
      "Train Epoch: 74 [4160/17352 (24%)] Loss: -199415.953125\n",
      "Train Epoch: 74 [4240/17352 (24%)] Loss: -204333.125000\n",
      "Train Epoch: 74 [4320/17352 (25%)] Loss: -206602.156250\n",
      "Train Epoch: 74 [4400/17352 (25%)] Loss: -201097.812500\n",
      "Train Epoch: 74 [4480/17352 (26%)] Loss: -200170.953125\n",
      "Train Epoch: 74 [4560/17352 (26%)] Loss: -185233.156250\n",
      "Train Epoch: 74 [4640/17352 (27%)] Loss: -185400.109375\n",
      "Train Epoch: 74 [4720/17352 (27%)] Loss: -167207.500000\n",
      "Train Epoch: 74 [4800/17352 (28%)] Loss: -190499.359375\n",
      "Train Epoch: 74 [4880/17352 (28%)] Loss: -182102.187500\n",
      "Train Epoch: 74 [4960/17352 (29%)] Loss: -191231.062500\n",
      "Train Epoch: 74 [5040/17352 (29%)] Loss: -151508.703125\n",
      "Train Epoch: 74 [5120/17352 (30%)] Loss: -184277.468750\n",
      "Train Epoch: 74 [5200/17352 (30%)] Loss: -180642.031250\n",
      "Train Epoch: 74 [5280/17352 (30%)] Loss: -200301.875000\n",
      "Train Epoch: 74 [5360/17352 (31%)] Loss: -188014.406250\n",
      "Train Epoch: 74 [5440/17352 (31%)] Loss: -200836.562500\n",
      "Train Epoch: 74 [5520/17352 (32%)] Loss: -183753.390625\n",
      "Train Epoch: 74 [5600/17352 (32%)] Loss: -193127.984375\n",
      "Train Epoch: 74 [5680/17352 (33%)] Loss: -193496.625000\n",
      "Train Epoch: 74 [5760/17352 (33%)] Loss: -203842.125000\n",
      "Train Epoch: 74 [5840/17352 (34%)] Loss: -205689.203125\n",
      "Train Epoch: 74 [5920/17352 (34%)] Loss: -199446.406250\n",
      "Train Epoch: 74 [6000/17352 (35%)] Loss: -177310.500000\n",
      "Train Epoch: 74 [6080/17352 (35%)] Loss: -213185.562500\n",
      "Train Epoch: 74 [6160/17352 (36%)] Loss: -196819.875000\n",
      "Train Epoch: 74 [6240/17352 (36%)] Loss: -180992.437500\n",
      "Train Epoch: 74 [6320/17352 (36%)] Loss: -180060.656250\n",
      "Train Epoch: 74 [6400/17352 (37%)] Loss: -182526.156250\n",
      "Train Epoch: 74 [6480/17352 (37%)] Loss: -191337.500000\n",
      "Train Epoch: 74 [6560/17352 (38%)] Loss: -178570.718750\n",
      "Train Epoch: 74 [6640/17352 (38%)] Loss: -184991.375000\n",
      "Train Epoch: 74 [6720/17352 (39%)] Loss: -228259.656250\n",
      "Train Epoch: 74 [6800/17352 (39%)] Loss: -166551.562500\n",
      "Train Epoch: 74 [6880/17352 (40%)] Loss: -163551.703125\n",
      "Train Epoch: 74 [6960/17352 (40%)] Loss: -195001.796875\n",
      "Train Epoch: 74 [7040/17352 (41%)] Loss: -181339.906250\n",
      "Train Epoch: 74 [7120/17352 (41%)] Loss: -198698.750000\n",
      "Train Epoch: 74 [7200/17352 (41%)] Loss: -185596.703125\n",
      "Train Epoch: 74 [7280/17352 (42%)] Loss: -183284.484375\n",
      "Train Epoch: 74 [7360/17352 (42%)] Loss: -181426.921875\n",
      "Train Epoch: 74 [7440/17352 (43%)] Loss: -188503.187500\n",
      "Train Epoch: 74 [7520/17352 (43%)] Loss: -156483.140625\n",
      "Train Epoch: 74 [7600/17352 (44%)] Loss: -176903.062500\n",
      "Train Epoch: 74 [7680/17352 (44%)] Loss: -208041.312500\n",
      "Train Epoch: 74 [7760/17352 (45%)] Loss: -207861.218750\n",
      "Train Epoch: 74 [7840/17352 (45%)] Loss: -207828.656250\n",
      "Train Epoch: 74 [7920/17352 (46%)] Loss: -186681.484375\n",
      "Train Epoch: 74 [8000/17352 (46%)] Loss: -181892.531250\n",
      "Train Epoch: 74 [8080/17352 (47%)] Loss: -180293.906250\n",
      "Train Epoch: 74 [8160/17352 (47%)] Loss: -180695.218750\n",
      "Train Epoch: 74 [8240/17352 (47%)] Loss: -197308.765625\n",
      "Train Epoch: 74 [8320/17352 (48%)] Loss: -174544.140625\n",
      "Train Epoch: 74 [8400/17352 (48%)] Loss: -187251.500000\n",
      "Train Epoch: 74 [8480/17352 (49%)] Loss: -173307.515625\n",
      "Train Epoch: 74 [8560/17352 (49%)] Loss: -193102.296875\n",
      "Train Epoch: 74 [8640/17352 (50%)] Loss: -186190.281250\n",
      "Train Epoch: 74 [8720/17352 (50%)] Loss: -200481.750000\n",
      "Train Epoch: 74 [8800/17352 (51%)] Loss: -174989.546875\n",
      "Train Epoch: 74 [8880/17352 (51%)] Loss: -179480.921875\n",
      "Train Epoch: 74 [8960/17352 (52%)] Loss: -199725.109375\n",
      "Train Epoch: 74 [9040/17352 (52%)] Loss: -206367.562500\n",
      "Train Epoch: 74 [9120/17352 (53%)] Loss: -184825.703125\n",
      "Train Epoch: 74 [9200/17352 (53%)] Loss: -204692.484375\n",
      "Train Epoch: 74 [9280/17352 (53%)] Loss: -189724.562500\n",
      "Train Epoch: 74 [9360/17352 (54%)] Loss: -196278.000000\n",
      "Train Epoch: 74 [9440/17352 (54%)] Loss: -179301.531250\n",
      "Train Epoch: 74 [9520/17352 (55%)] Loss: -184456.546875\n",
      "Train Epoch: 74 [9600/17352 (55%)] Loss: -178870.968750\n",
      "Train Epoch: 74 [9680/17352 (56%)] Loss: -179312.078125\n",
      "Train Epoch: 74 [9760/17352 (56%)] Loss: -185798.562500\n",
      "Train Epoch: 74 [9840/17352 (57%)] Loss: -212139.015625\n",
      "Train Epoch: 74 [9920/17352 (57%)] Loss: -210917.765625\n",
      "Train Epoch: 74 [10000/17352 (58%)] Loss: -192748.640625\n",
      "Train Epoch: 74 [10080/17352 (58%)] Loss: -170244.875000\n",
      "Train Epoch: 74 [10160/17352 (59%)] Loss: -204417.343750\n",
      "Train Epoch: 74 [10240/17352 (59%)] Loss: -176591.109375\n",
      "Train Epoch: 74 [10320/17352 (59%)] Loss: -192888.421875\n",
      "Train Epoch: 74 [10400/17352 (60%)] Loss: -202313.125000\n",
      "Train Epoch: 74 [10480/17352 (60%)] Loss: -192393.171875\n",
      "Train Epoch: 74 [10560/17352 (61%)] Loss: -188182.515625\n",
      "Train Epoch: 74 [10640/17352 (61%)] Loss: -207125.578125\n",
      "Train Epoch: 74 [10720/17352 (62%)] Loss: -194070.984375\n",
      "Train Epoch: 74 [10800/17352 (62%)] Loss: -183087.703125\n",
      "Train Epoch: 74 [10880/17352 (63%)] Loss: -179172.250000\n",
      "Train Epoch: 74 [10960/17352 (63%)] Loss: -149444.156250\n",
      "Train Epoch: 74 [11040/17352 (64%)] Loss: -214688.343750\n",
      "Train Epoch: 74 [11120/17352 (64%)] Loss: -171907.781250\n",
      "Train Epoch: 74 [11200/17352 (65%)] Loss: -199520.296875\n",
      "Train Epoch: 74 [11280/17352 (65%)] Loss: -191001.468750\n",
      "Train Epoch: 74 [11360/17352 (65%)] Loss: -182405.234375\n",
      "Train Epoch: 74 [11440/17352 (66%)] Loss: -196195.468750\n",
      "Train Epoch: 74 [11520/17352 (66%)] Loss: -198014.218750\n",
      "Train Epoch: 74 [11600/17352 (67%)] Loss: -206471.281250\n",
      "Train Epoch: 74 [11680/17352 (67%)] Loss: -164075.312500\n",
      "Train Epoch: 74 [11760/17352 (68%)] Loss: -168510.062500\n",
      "Train Epoch: 74 [11840/17352 (68%)] Loss: -185788.843750\n",
      "Train Epoch: 74 [11920/17352 (69%)] Loss: -210785.890625\n",
      "Train Epoch: 74 [12000/17352 (69%)] Loss: -170777.890625\n",
      "Train Epoch: 74 [12080/17352 (70%)] Loss: -189796.218750\n",
      "Train Epoch: 74 [12160/17352 (70%)] Loss: -140590.390625\n",
      "Train Epoch: 74 [12240/17352 (71%)] Loss: -187648.171875\n",
      "Train Epoch: 74 [12320/17352 (71%)] Loss: -157595.781250\n",
      "Train Epoch: 74 [12400/17352 (71%)] Loss: -201936.046875\n",
      "Train Epoch: 74 [12480/17352 (72%)] Loss: -163774.765625\n",
      "Train Epoch: 74 [12560/17352 (72%)] Loss: -205509.687500\n",
      "Train Epoch: 74 [12640/17352 (73%)] Loss: -201958.390625\n",
      "Train Epoch: 74 [12720/17352 (73%)] Loss: -172894.281250\n",
      "Train Epoch: 74 [12800/17352 (74%)] Loss: -184844.968750\n",
      "Train Epoch: 74 [12880/17352 (74%)] Loss: -180118.390625\n",
      "Train Epoch: 74 [12960/17352 (75%)] Loss: -177768.656250\n",
      "Train Epoch: 74 [13040/17352 (75%)] Loss: -163349.953125\n",
      "Train Epoch: 74 [13120/17352 (76%)] Loss: -170531.984375\n",
      "Train Epoch: 74 [13200/17352 (76%)] Loss: -188753.171875\n",
      "Train Epoch: 74 [13280/17352 (77%)] Loss: -185044.015625\n",
      "Train Epoch: 74 [13360/17352 (77%)] Loss: -184255.609375\n",
      "Train Epoch: 74 [13440/17352 (77%)] Loss: -170110.984375\n",
      "Train Epoch: 74 [13520/17352 (78%)] Loss: -195055.390625\n",
      "Train Epoch: 74 [13600/17352 (78%)] Loss: -209592.140625\n",
      "Train Epoch: 74 [13680/17352 (79%)] Loss: -162559.390625\n",
      "Train Epoch: 74 [13760/17352 (79%)] Loss: -173448.609375\n",
      "Train Epoch: 74 [13840/17352 (80%)] Loss: -177623.000000\n",
      "Train Epoch: 74 [13920/17352 (80%)] Loss: -191160.625000\n",
      "Train Epoch: 74 [14000/17352 (81%)] Loss: -193263.750000\n",
      "Train Epoch: 74 [14080/17352 (81%)] Loss: -176165.078125\n",
      "Train Epoch: 74 [14160/17352 (82%)] Loss: -228147.187500\n",
      "Train Epoch: 74 [14240/17352 (82%)] Loss: -159734.796875\n",
      "Train Epoch: 74 [14320/17352 (83%)] Loss: -209281.296875\n",
      "Train Epoch: 74 [14400/17352 (83%)] Loss: -168078.906250\n",
      "Train Epoch: 74 [14480/17352 (83%)] Loss: -163248.656250\n",
      "Train Epoch: 74 [14560/17352 (84%)] Loss: -173002.921875\n",
      "Train Epoch: 74 [14640/17352 (84%)] Loss: -197593.359375\n",
      "Train Epoch: 74 [14720/17352 (85%)] Loss: -199806.656250\n",
      "Train Epoch: 74 [14800/17352 (85%)] Loss: -164990.046875\n",
      "Train Epoch: 74 [14880/17352 (86%)] Loss: -201376.656250\n",
      "Train Epoch: 74 [14960/17352 (86%)] Loss: -183611.812500\n",
      "Train Epoch: 74 [15040/17352 (87%)] Loss: -206927.328125\n",
      "Train Epoch: 74 [15120/17352 (87%)] Loss: -195290.125000\n",
      "Train Epoch: 74 [15200/17352 (88%)] Loss: -197347.421875\n",
      "Train Epoch: 74 [15280/17352 (88%)] Loss: -210395.062500\n",
      "Train Epoch: 74 [15360/17352 (89%)] Loss: -205642.109375\n",
      "Train Epoch: 74 [15440/17352 (89%)] Loss: -148445.437500\n",
      "Train Epoch: 74 [15520/17352 (89%)] Loss: -199893.000000\n",
      "Train Epoch: 74 [15600/17352 (90%)] Loss: -187602.593750\n",
      "Train Epoch: 74 [15680/17352 (90%)] Loss: -168056.890625\n",
      "Train Epoch: 74 [15760/17352 (91%)] Loss: -152745.375000\n",
      "Train Epoch: 74 [15840/17352 (91%)] Loss: -184950.265625\n",
      "Train Epoch: 74 [15920/17352 (92%)] Loss: -167798.937500\n",
      "Train Epoch: 74 [16000/17352 (92%)] Loss: -185440.203125\n",
      "Train Epoch: 74 [16080/17352 (93%)] Loss: -216326.375000\n",
      "Train Epoch: 74 [16160/17352 (93%)] Loss: -180838.843750\n",
      "Train Epoch: 74 [16240/17352 (94%)] Loss: -203271.390625\n",
      "Train Epoch: 74 [16320/17352 (94%)] Loss: -200278.312500\n",
      "Train Epoch: 74 [16400/17352 (95%)] Loss: -167734.125000\n",
      "Train Epoch: 74 [16480/17352 (95%)] Loss: -196451.546875\n",
      "Train Epoch: 74 [16560/17352 (95%)] Loss: -195383.171875\n",
      "Train Epoch: 74 [16640/17352 (96%)] Loss: -179009.125000\n",
      "Train Epoch: 74 [16720/17352 (96%)] Loss: -212611.359375\n",
      "Train Epoch: 74 [16800/17352 (97%)] Loss: -177308.312500\n",
      "Train Epoch: 74 [16880/17352 (97%)] Loss: -174986.984375\n",
      "Train Epoch: 74 [16960/17352 (98%)] Loss: -200868.250000\n",
      "Train Epoch: 74 [17040/17352 (98%)] Loss: -175410.062500\n",
      "Train Epoch: 74 [17120/17352 (99%)] Loss: -171712.796875\n",
      "Train Epoch: 74 [17200/17352 (99%)] Loss: -208761.640625\n",
      "Train Epoch: 74 [17280/17352 (100%)] Loss: -159746.093750\n",
      "Train Epoch: 74 [17360/17352 (100%)] Loss: -161682.562500\n",
      "    epoch          : 74\n",
      "    loss           : -189640.26095008632\n",
      "    val_loss       : -23716.35148957302\n",
      "Train Epoch: 75 [0/17352 (0%)] Loss: -213327.484375\n",
      "Train Epoch: 75 [80/17352 (0%)] Loss: -229959.296875\n",
      "Train Epoch: 75 [160/17352 (1%)] Loss: -204538.343750\n",
      "Train Epoch: 75 [240/17352 (1%)] Loss: -218564.546875\n",
      "Train Epoch: 75 [320/17352 (2%)] Loss: -230411.625000\n",
      "Train Epoch: 75 [400/17352 (2%)] Loss: -191882.968750\n",
      "Train Epoch: 75 [480/17352 (3%)] Loss: -193416.484375\n",
      "Train Epoch: 75 [560/17352 (3%)] Loss: -211898.921875\n",
      "Train Epoch: 75 [640/17352 (4%)] Loss: -204735.781250\n",
      "Train Epoch: 75 [720/17352 (4%)] Loss: -206149.828125\n",
      "Train Epoch: 75 [800/17352 (5%)] Loss: -196420.765625\n",
      "Train Epoch: 75 [880/17352 (5%)] Loss: -203747.140625\n",
      "Train Epoch: 75 [960/17352 (6%)] Loss: -233737.812500\n",
      "Train Epoch: 75 [1040/17352 (6%)] Loss: -224351.656250\n",
      "Train Epoch: 75 [1120/17352 (6%)] Loss: -196928.718750\n",
      "Train Epoch: 75 [1200/17352 (7%)] Loss: -214525.203125\n",
      "Train Epoch: 75 [1280/17352 (7%)] Loss: -214457.562500\n",
      "Train Epoch: 75 [1360/17352 (8%)] Loss: -215487.843750\n",
      "Train Epoch: 75 [1440/17352 (8%)] Loss: -214341.656250\n",
      "Train Epoch: 75 [1520/17352 (9%)] Loss: -222513.515625\n",
      "Train Epoch: 75 [1600/17352 (9%)] Loss: -226094.125000\n",
      "Train Epoch: 75 [1680/17352 (10%)] Loss: -201668.687500\n",
      "Train Epoch: 75 [1760/17352 (10%)] Loss: -213828.968750\n",
      "Train Epoch: 75 [1840/17352 (11%)] Loss: -205560.265625\n",
      "Train Epoch: 75 [1920/17352 (11%)] Loss: -196442.203125\n",
      "Train Epoch: 75 [2000/17352 (12%)] Loss: -204399.250000\n",
      "Train Epoch: 75 [2080/17352 (12%)] Loss: -216084.421875\n",
      "Train Epoch: 75 [2160/17352 (12%)] Loss: -221762.250000\n",
      "Train Epoch: 75 [2240/17352 (13%)] Loss: -174984.328125\n",
      "Train Epoch: 75 [2320/17352 (13%)] Loss: -155865.312500\n",
      "Train Epoch: 75 [2400/17352 (14%)] Loss: -196125.562500\n",
      "Train Epoch: 75 [2480/17352 (14%)] Loss: -173663.828125\n",
      "Train Epoch: 75 [2560/17352 (15%)] Loss: -194932.015625\n",
      "Train Epoch: 75 [2640/17352 (15%)] Loss: -189021.125000\n",
      "Train Epoch: 75 [2720/17352 (16%)] Loss: -192257.140625\n",
      "Train Epoch: 75 [2800/17352 (16%)] Loss: -177466.265625\n",
      "Train Epoch: 75 [2880/17352 (17%)] Loss: -177607.609375\n",
      "Train Epoch: 75 [2960/17352 (17%)] Loss: -169164.812500\n",
      "Train Epoch: 75 [3040/17352 (18%)] Loss: -168965.515625\n",
      "Train Epoch: 75 [3120/17352 (18%)] Loss: -194601.656250\n",
      "Train Epoch: 75 [3200/17352 (18%)] Loss: -166675.671875\n",
      "Train Epoch: 75 [3280/17352 (19%)] Loss: -165765.015625\n",
      "Train Epoch: 75 [3360/17352 (19%)] Loss: -192694.312500\n",
      "Train Epoch: 75 [3440/17352 (20%)] Loss: -218518.687500\n",
      "Train Epoch: 75 [3520/17352 (20%)] Loss: -196819.500000\n",
      "Train Epoch: 75 [3600/17352 (21%)] Loss: -182401.203125\n",
      "Train Epoch: 75 [3680/17352 (21%)] Loss: -175363.968750\n",
      "Train Epoch: 75 [3760/17352 (22%)] Loss: -178600.656250\n",
      "Train Epoch: 75 [3840/17352 (22%)] Loss: -217609.468750\n",
      "Train Epoch: 75 [3920/17352 (23%)] Loss: -142336.546875\n",
      "Train Epoch: 75 [4000/17352 (23%)] Loss: -193201.968750\n",
      "Train Epoch: 75 [4080/17352 (24%)] Loss: -193511.187500\n",
      "Train Epoch: 75 [4160/17352 (24%)] Loss: -192379.328125\n",
      "Train Epoch: 75 [4240/17352 (24%)] Loss: -201971.281250\n",
      "Train Epoch: 75 [4320/17352 (25%)] Loss: -175678.593750\n",
      "Train Epoch: 75 [4400/17352 (25%)] Loss: -196935.000000\n",
      "Train Epoch: 75 [4480/17352 (26%)] Loss: -168505.734375\n",
      "Train Epoch: 75 [4560/17352 (26%)] Loss: -183612.828125\n",
      "Train Epoch: 75 [4640/17352 (27%)] Loss: -196697.109375\n",
      "Train Epoch: 75 [4720/17352 (27%)] Loss: -214753.234375\n",
      "Train Epoch: 75 [4800/17352 (28%)] Loss: -138339.578125\n",
      "Train Epoch: 75 [4880/17352 (28%)] Loss: -175685.453125\n",
      "Train Epoch: 75 [4960/17352 (29%)] Loss: -153321.078125\n",
      "Train Epoch: 75 [5040/17352 (29%)] Loss: -187777.375000\n",
      "Train Epoch: 75 [5120/17352 (30%)] Loss: -202483.187500\n",
      "Train Epoch: 75 [5200/17352 (30%)] Loss: -208758.859375\n",
      "Train Epoch: 75 [5280/17352 (30%)] Loss: -201373.562500\n",
      "Train Epoch: 75 [5360/17352 (31%)] Loss: -183168.656250\n",
      "Train Epoch: 75 [5440/17352 (31%)] Loss: -191963.109375\n",
      "Train Epoch: 75 [5520/17352 (32%)] Loss: -183465.593750\n",
      "Train Epoch: 75 [5600/17352 (32%)] Loss: -205687.328125\n",
      "Train Epoch: 75 [5680/17352 (33%)] Loss: -175543.375000\n",
      "Train Epoch: 75 [5760/17352 (33%)] Loss: -198800.531250\n",
      "Train Epoch: 75 [5840/17352 (34%)] Loss: -171440.781250\n",
      "Train Epoch: 75 [5920/17352 (34%)] Loss: -203520.546875\n",
      "Train Epoch: 75 [6000/17352 (35%)] Loss: -228149.234375\n",
      "Train Epoch: 75 [6080/17352 (35%)] Loss: -187953.937500\n",
      "Train Epoch: 75 [6160/17352 (36%)] Loss: -188970.781250\n",
      "Train Epoch: 75 [6240/17352 (36%)] Loss: -200832.781250\n",
      "Train Epoch: 75 [6320/17352 (36%)] Loss: -197519.359375\n",
      "Train Epoch: 75 [6400/17352 (37%)] Loss: -200482.515625\n",
      "Train Epoch: 75 [6480/17352 (37%)] Loss: -170533.640625\n",
      "Train Epoch: 75 [6560/17352 (38%)] Loss: -224860.890625\n",
      "Train Epoch: 75 [6640/17352 (38%)] Loss: -178573.171875\n",
      "Train Epoch: 75 [6720/17352 (39%)] Loss: -178607.234375\n",
      "Train Epoch: 75 [6800/17352 (39%)] Loss: -218748.640625\n",
      "Train Epoch: 75 [6880/17352 (40%)] Loss: -210259.468750\n",
      "Train Epoch: 75 [6960/17352 (40%)] Loss: -176707.484375\n",
      "Train Epoch: 75 [7040/17352 (41%)] Loss: -173890.546875\n",
      "Train Epoch: 75 [7120/17352 (41%)] Loss: -177487.125000\n",
      "Train Epoch: 75 [7200/17352 (41%)] Loss: -167087.109375\n",
      "Train Epoch: 75 [7280/17352 (42%)] Loss: -164990.718750\n",
      "Train Epoch: 75 [7360/17352 (42%)] Loss: -179484.078125\n",
      "Train Epoch: 75 [7440/17352 (43%)] Loss: -180170.718750\n",
      "Train Epoch: 75 [7520/17352 (43%)] Loss: -183286.453125\n",
      "Train Epoch: 75 [7600/17352 (44%)] Loss: -184951.187500\n",
      "Train Epoch: 75 [7680/17352 (44%)] Loss: -182745.468750\n",
      "Train Epoch: 75 [7760/17352 (45%)] Loss: -215649.750000\n",
      "Train Epoch: 75 [7840/17352 (45%)] Loss: -175751.484375\n",
      "Train Epoch: 75 [7920/17352 (46%)] Loss: -170781.171875\n",
      "Train Epoch: 75 [8000/17352 (46%)] Loss: -180893.015625\n",
      "Train Epoch: 75 [8080/17352 (47%)] Loss: -198313.640625\n",
      "Train Epoch: 75 [8160/17352 (47%)] Loss: -184478.734375\n",
      "Train Epoch: 75 [8240/17352 (47%)] Loss: -176161.515625\n",
      "Train Epoch: 75 [8320/17352 (48%)] Loss: -163766.468750\n",
      "Train Epoch: 75 [8400/17352 (48%)] Loss: -185576.125000\n",
      "Train Epoch: 75 [8480/17352 (49%)] Loss: -183633.546875\n",
      "Train Epoch: 75 [8560/17352 (49%)] Loss: -193490.171875\n",
      "Train Epoch: 75 [8640/17352 (50%)] Loss: -195062.687500\n",
      "Train Epoch: 75 [8720/17352 (50%)] Loss: -174616.609375\n",
      "Train Epoch: 75 [8800/17352 (51%)] Loss: -210558.343750\n",
      "Train Epoch: 75 [8880/17352 (51%)] Loss: -179743.156250\n",
      "Train Epoch: 75 [8960/17352 (52%)] Loss: -175410.765625\n",
      "Train Epoch: 75 [9040/17352 (52%)] Loss: -204497.031250\n",
      "Train Epoch: 75 [9120/17352 (53%)] Loss: -192114.750000\n",
      "Train Epoch: 75 [9200/17352 (53%)] Loss: -178326.468750\n",
      "Train Epoch: 75 [9280/17352 (53%)] Loss: -149445.234375\n",
      "Train Epoch: 75 [9360/17352 (54%)] Loss: -165866.765625\n",
      "Train Epoch: 75 [9440/17352 (54%)] Loss: -191051.421875\n",
      "Train Epoch: 75 [9520/17352 (55%)] Loss: -180906.687500\n",
      "Train Epoch: 75 [9600/17352 (55%)] Loss: -223692.750000\n",
      "Train Epoch: 75 [9680/17352 (56%)] Loss: -165390.187500\n",
      "Train Epoch: 75 [9760/17352 (56%)] Loss: -176536.718750\n",
      "Train Epoch: 75 [9840/17352 (57%)] Loss: -179675.984375\n",
      "Train Epoch: 75 [9920/17352 (57%)] Loss: -171311.218750\n",
      "Train Epoch: 75 [10000/17352 (58%)] Loss: -200071.609375\n",
      "Train Epoch: 75 [10080/17352 (58%)] Loss: -181694.750000\n",
      "Train Epoch: 75 [10160/17352 (59%)] Loss: -149033.375000\n",
      "Train Epoch: 75 [10240/17352 (59%)] Loss: -188146.625000\n",
      "Train Epoch: 75 [10320/17352 (59%)] Loss: -167148.328125\n",
      "Train Epoch: 75 [10400/17352 (60%)] Loss: -177097.359375\n",
      "Train Epoch: 75 [10480/17352 (60%)] Loss: -170230.750000\n",
      "Train Epoch: 75 [10560/17352 (61%)] Loss: -199173.656250\n",
      "Train Epoch: 75 [10640/17352 (61%)] Loss: -182742.328125\n",
      "Train Epoch: 75 [10720/17352 (62%)] Loss: -198025.390625\n",
      "Train Epoch: 75 [10800/17352 (62%)] Loss: -170311.609375\n",
      "Train Epoch: 75 [10880/17352 (63%)] Loss: -178376.609375\n",
      "Train Epoch: 75 [10960/17352 (63%)] Loss: -187132.718750\n",
      "Train Epoch: 75 [11040/17352 (64%)] Loss: -173448.203125\n",
      "Train Epoch: 75 [11120/17352 (64%)] Loss: -218839.250000\n",
      "Train Epoch: 75 [11200/17352 (65%)] Loss: -172616.296875\n",
      "Train Epoch: 75 [11280/17352 (65%)] Loss: -164877.250000\n",
      "Train Epoch: 75 [11360/17352 (65%)] Loss: -206092.281250\n",
      "Train Epoch: 75 [11440/17352 (66%)] Loss: -143624.625000\n",
      "Train Epoch: 75 [11520/17352 (66%)] Loss: -209187.453125\n",
      "Train Epoch: 75 [11600/17352 (67%)] Loss: -183724.859375\n",
      "Train Epoch: 75 [11680/17352 (67%)] Loss: -196727.718750\n",
      "Train Epoch: 75 [11760/17352 (68%)] Loss: -193132.171875\n",
      "Train Epoch: 75 [11840/17352 (68%)] Loss: -193918.437500\n",
      "Train Epoch: 75 [11920/17352 (69%)] Loss: -185061.593750\n",
      "Train Epoch: 75 [12000/17352 (69%)] Loss: -178871.296875\n",
      "Train Epoch: 75 [12080/17352 (70%)] Loss: -198550.531250\n",
      "Train Epoch: 75 [12160/17352 (70%)] Loss: -200204.031250\n",
      "Train Epoch: 75 [12240/17352 (71%)] Loss: -167481.265625\n",
      "Train Epoch: 75 [12320/17352 (71%)] Loss: -184949.953125\n",
      "Train Epoch: 75 [12400/17352 (71%)] Loss: -177195.000000\n",
      "Train Epoch: 75 [12480/17352 (72%)] Loss: -208157.250000\n",
      "Train Epoch: 75 [12560/17352 (72%)] Loss: -184761.421875\n",
      "Train Epoch: 75 [12640/17352 (73%)] Loss: -175663.781250\n",
      "Train Epoch: 75 [12720/17352 (73%)] Loss: -148399.656250\n",
      "Train Epoch: 75 [12800/17352 (74%)] Loss: -222862.625000\n",
      "Train Epoch: 75 [12880/17352 (74%)] Loss: -183589.640625\n",
      "Train Epoch: 75 [12960/17352 (75%)] Loss: -189219.546875\n",
      "Train Epoch: 75 [13040/17352 (75%)] Loss: -187524.234375\n",
      "Train Epoch: 75 [13120/17352 (76%)] Loss: -193531.031250\n",
      "Train Epoch: 75 [13200/17352 (76%)] Loss: -196043.140625\n",
      "Train Epoch: 75 [13280/17352 (77%)] Loss: -214640.171875\n",
      "Train Epoch: 75 [13360/17352 (77%)] Loss: -179018.593750\n",
      "Train Epoch: 75 [13440/17352 (77%)] Loss: -149334.218750\n",
      "Train Epoch: 75 [13520/17352 (78%)] Loss: -191811.609375\n",
      "Train Epoch: 75 [13600/17352 (78%)] Loss: -196568.750000\n",
      "Train Epoch: 75 [13680/17352 (79%)] Loss: -183868.531250\n",
      "Train Epoch: 75 [13760/17352 (79%)] Loss: -191559.453125\n",
      "Train Epoch: 75 [13840/17352 (80%)] Loss: -176915.562500\n",
      "Train Epoch: 75 [13920/17352 (80%)] Loss: -171324.609375\n",
      "Train Epoch: 75 [14000/17352 (81%)] Loss: -171225.593750\n",
      "Train Epoch: 75 [14080/17352 (81%)] Loss: -177194.484375\n",
      "Train Epoch: 75 [14160/17352 (82%)] Loss: -209901.734375\n",
      "Train Epoch: 75 [14240/17352 (82%)] Loss: -205813.765625\n",
      "Train Epoch: 75 [14320/17352 (83%)] Loss: -208302.859375\n",
      "Train Epoch: 75 [14400/17352 (83%)] Loss: -201322.171875\n",
      "Train Epoch: 75 [14480/17352 (83%)] Loss: -191889.265625\n",
      "Train Epoch: 75 [14560/17352 (84%)] Loss: -201955.984375\n",
      "Train Epoch: 75 [14640/17352 (84%)] Loss: -201038.546875\n",
      "Train Epoch: 75 [14720/17352 (85%)] Loss: -191592.609375\n",
      "Train Epoch: 75 [14800/17352 (85%)] Loss: -159739.921875\n",
      "Train Epoch: 75 [14880/17352 (86%)] Loss: -170356.109375\n",
      "Train Epoch: 75 [14960/17352 (86%)] Loss: -156608.046875\n",
      "Train Epoch: 75 [15040/17352 (87%)] Loss: -190626.421875\n",
      "Train Epoch: 75 [15120/17352 (87%)] Loss: -181259.218750\n",
      "Train Epoch: 75 [15200/17352 (88%)] Loss: -186684.625000\n",
      "Train Epoch: 75 [15280/17352 (88%)] Loss: -164807.046875\n",
      "Train Epoch: 75 [15360/17352 (89%)] Loss: -215647.875000\n",
      "Train Epoch: 75 [15440/17352 (89%)] Loss: -201385.312500\n",
      "Train Epoch: 75 [15520/17352 (89%)] Loss: -206247.437500\n",
      "Train Epoch: 75 [15600/17352 (90%)] Loss: -189797.140625\n",
      "Train Epoch: 75 [15680/17352 (90%)] Loss: -177308.750000\n",
      "Train Epoch: 75 [15760/17352 (91%)] Loss: -219929.421875\n",
      "Train Epoch: 75 [15840/17352 (91%)] Loss: -193098.750000\n",
      "Train Epoch: 75 [15920/17352 (92%)] Loss: -193358.546875\n",
      "Train Epoch: 75 [16000/17352 (92%)] Loss: -177595.515625\n",
      "Train Epoch: 75 [16080/17352 (93%)] Loss: -163108.078125\n",
      "Train Epoch: 75 [16160/17352 (93%)] Loss: -208719.296875\n",
      "Train Epoch: 75 [16240/17352 (94%)] Loss: -184607.781250\n",
      "Train Epoch: 75 [16320/17352 (94%)] Loss: -180152.796875\n",
      "Train Epoch: 75 [16400/17352 (95%)] Loss: -168082.718750\n",
      "Train Epoch: 75 [16480/17352 (95%)] Loss: -166031.734375\n",
      "Train Epoch: 75 [16560/17352 (95%)] Loss: -195109.640625\n",
      "Train Epoch: 75 [16640/17352 (96%)] Loss: -177774.734375\n",
      "Train Epoch: 75 [16720/17352 (96%)] Loss: -194065.906250\n",
      "Train Epoch: 75 [16800/17352 (97%)] Loss: -203875.703125\n",
      "Train Epoch: 75 [16880/17352 (97%)] Loss: -213396.578125\n",
      "Train Epoch: 75 [16960/17352 (98%)] Loss: -160050.750000\n",
      "Train Epoch: 75 [17040/17352 (98%)] Loss: -183070.531250\n",
      "Train Epoch: 75 [17120/17352 (99%)] Loss: -186035.828125\n",
      "Train Epoch: 75 [17200/17352 (99%)] Loss: -187507.609375\n",
      "Train Epoch: 75 [17280/17352 (100%)] Loss: -187719.765625\n",
      "Train Epoch: 75 [17360/17352 (100%)] Loss: -188430.078125\n",
      "    epoch          : 75\n",
      "    loss           : -189290.13402617953\n",
      "    val_loss       : -23716.09289901805\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch75.pth ...\n",
      "Train Epoch: 76 [0/17352 (0%)] Loss: -205108.421875\n",
      "Train Epoch: 76 [80/17352 (0%)] Loss: -205555.890625\n",
      "Train Epoch: 76 [160/17352 (1%)] Loss: -210352.093750\n",
      "Train Epoch: 76 [240/17352 (1%)] Loss: -214521.406250\n",
      "Train Epoch: 76 [320/17352 (2%)] Loss: -193024.718750\n",
      "Train Epoch: 76 [400/17352 (2%)] Loss: -199537.359375\n",
      "Train Epoch: 76 [480/17352 (3%)] Loss: -215485.453125\n",
      "Train Epoch: 76 [560/17352 (3%)] Loss: -236831.734375\n",
      "Train Epoch: 76 [640/17352 (4%)] Loss: -204358.171875\n",
      "Train Epoch: 76 [720/17352 (4%)] Loss: -214463.421875\n",
      "Train Epoch: 76 [800/17352 (5%)] Loss: -193584.937500\n",
      "Train Epoch: 76 [880/17352 (5%)] Loss: -212182.093750\n",
      "Train Epoch: 76 [960/17352 (6%)] Loss: -205202.875000\n",
      "Train Epoch: 76 [1040/17352 (6%)] Loss: -206561.703125\n",
      "Train Epoch: 76 [1120/17352 (6%)] Loss: -211109.250000\n",
      "Train Epoch: 76 [1200/17352 (7%)] Loss: -203747.796875\n",
      "Train Epoch: 76 [1280/17352 (7%)] Loss: -200602.546875\n",
      "Train Epoch: 76 [1360/17352 (8%)] Loss: -204735.140625\n",
      "Train Epoch: 76 [1440/17352 (8%)] Loss: -208536.000000\n",
      "Train Epoch: 76 [1520/17352 (9%)] Loss: -213332.765625\n",
      "Train Epoch: 76 [1600/17352 (9%)] Loss: -196446.046875\n",
      "Train Epoch: 76 [1680/17352 (10%)] Loss: -204709.062500\n",
      "Train Epoch: 76 [1760/17352 (10%)] Loss: -213323.890625\n",
      "Train Epoch: 76 [1840/17352 (11%)] Loss: -196928.953125\n",
      "Train Epoch: 76 [1920/17352 (11%)] Loss: -214710.250000\n",
      "Train Epoch: 76 [2000/17352 (12%)] Loss: -199111.343750\n",
      "Train Epoch: 76 [2080/17352 (12%)] Loss: -209556.171875\n",
      "Train Epoch: 76 [2160/17352 (12%)] Loss: -228017.484375\n",
      "Train Epoch: 76 [2240/17352 (13%)] Loss: -178665.125000\n",
      "Train Epoch: 76 [2320/17352 (13%)] Loss: -173450.281250\n",
      "Train Epoch: 76 [2400/17352 (14%)] Loss: -192283.750000\n",
      "Train Epoch: 76 [2480/17352 (14%)] Loss: -164682.296875\n",
      "Train Epoch: 76 [2560/17352 (15%)] Loss: -206552.437500\n",
      "Train Epoch: 76 [2640/17352 (15%)] Loss: -189269.015625\n",
      "Train Epoch: 76 [2720/17352 (16%)] Loss: -179445.687500\n",
      "Train Epoch: 76 [2800/17352 (16%)] Loss: -163958.125000\n",
      "Train Epoch: 76 [2880/17352 (17%)] Loss: -191800.640625\n",
      "Train Epoch: 76 [2960/17352 (17%)] Loss: -177595.531250\n",
      "Train Epoch: 76 [3040/17352 (18%)] Loss: -200981.984375\n",
      "Train Epoch: 76 [3120/17352 (18%)] Loss: -175310.796875\n",
      "Train Epoch: 76 [3200/17352 (18%)] Loss: -172553.890625\n",
      "Train Epoch: 76 [3280/17352 (19%)] Loss: -177625.703125\n",
      "Train Epoch: 76 [3360/17352 (19%)] Loss: -193801.359375\n",
      "Train Epoch: 76 [3440/17352 (20%)] Loss: -187319.125000\n",
      "Train Epoch: 76 [3520/17352 (20%)] Loss: -206165.250000\n",
      "Train Epoch: 76 [3600/17352 (21%)] Loss: -172185.578125\n",
      "Train Epoch: 76 [3680/17352 (21%)] Loss: -202850.984375\n",
      "Train Epoch: 76 [3760/17352 (22%)] Loss: -190814.171875\n",
      "Train Epoch: 76 [3840/17352 (22%)] Loss: -196569.750000\n",
      "Train Epoch: 76 [3920/17352 (23%)] Loss: -208045.546875\n",
      "Train Epoch: 76 [4000/17352 (23%)] Loss: -183614.718750\n",
      "Train Epoch: 76 [4080/17352 (24%)] Loss: -179019.906250\n",
      "Train Epoch: 76 [4160/17352 (24%)] Loss: -143617.609375\n",
      "Train Epoch: 76 [4240/17352 (24%)] Loss: -191636.031250\n",
      "Train Epoch: 76 [4320/17352 (25%)] Loss: -169506.265625\n",
      "Train Epoch: 76 [4400/17352 (25%)] Loss: -188813.953125\n",
      "Train Epoch: 76 [4480/17352 (26%)] Loss: -179968.671875\n",
      "Train Epoch: 76 [4560/17352 (26%)] Loss: -175012.703125\n",
      "Train Epoch: 76 [4640/17352 (27%)] Loss: -201004.078125\n",
      "Train Epoch: 76 [4720/17352 (27%)] Loss: -219925.125000\n",
      "Train Epoch: 76 [4800/17352 (28%)] Loss: -202240.171875\n",
      "Train Epoch: 76 [4880/17352 (28%)] Loss: -177731.312500\n",
      "Train Epoch: 76 [4960/17352 (29%)] Loss: -186782.546875\n",
      "Train Epoch: 76 [5040/17352 (29%)] Loss: -167148.031250\n",
      "Train Epoch: 76 [5120/17352 (30%)] Loss: -185177.359375\n",
      "Train Epoch: 76 [5200/17352 (30%)] Loss: -174641.937500\n",
      "Train Epoch: 76 [5280/17352 (30%)] Loss: -178563.453125\n",
      "Train Epoch: 76 [5360/17352 (31%)] Loss: -208314.125000\n",
      "Train Epoch: 76 [5440/17352 (31%)] Loss: -151738.015625\n",
      "Train Epoch: 76 [5520/17352 (32%)] Loss: -177308.125000\n",
      "Train Epoch: 76 [5600/17352 (32%)] Loss: -202475.906250\n",
      "Train Epoch: 76 [5680/17352 (33%)] Loss: -181425.765625\n",
      "Train Epoch: 76 [5760/17352 (33%)] Loss: -176588.656250\n",
      "Train Epoch: 76 [5840/17352 (34%)] Loss: -177238.687500\n",
      "Train Epoch: 76 [5920/17352 (34%)] Loss: -182685.593750\n",
      "Train Epoch: 76 [6000/17352 (35%)] Loss: -190794.250000\n",
      "Train Epoch: 76 [6080/17352 (35%)] Loss: -184752.406250\n",
      "Train Epoch: 76 [6160/17352 (36%)] Loss: -175408.859375\n",
      "Train Epoch: 76 [6240/17352 (36%)] Loss: -185575.500000\n",
      "Train Epoch: 76 [6320/17352 (36%)] Loss: -163770.812500\n",
      "Train Epoch: 76 [6400/17352 (37%)] Loss: -192895.015625\n",
      "Train Epoch: 76 [6480/17352 (37%)] Loss: -180883.140625\n",
      "Train Epoch: 76 [6560/17352 (38%)] Loss: -174519.812500\n",
      "Train Epoch: 76 [6640/17352 (38%)] Loss: -180512.265625\n",
      "Train Epoch: 76 [6720/17352 (39%)] Loss: -200172.593750\n",
      "Train Epoch: 76 [6800/17352 (39%)] Loss: -195061.812500\n",
      "Train Epoch: 76 [6880/17352 (40%)] Loss: -201938.250000\n",
      "Train Epoch: 76 [6960/17352 (40%)] Loss: -197377.421875\n",
      "Train Epoch: 76 [7040/17352 (41%)] Loss: -189603.250000\n",
      "Train Epoch: 76 [7120/17352 (41%)] Loss: -180152.328125\n",
      "Train Epoch: 76 [7200/17352 (41%)] Loss: -203144.421875\n",
      "Train Epoch: 76 [7280/17352 (42%)] Loss: -193369.250000\n",
      "Train Epoch: 76 [7360/17352 (42%)] Loss: -203852.765625\n",
      "Train Epoch: 76 [7440/17352 (43%)] Loss: -165733.125000\n",
      "Train Epoch: 76 [7520/17352 (43%)] Loss: -192795.562500\n",
      "Train Epoch: 76 [7600/17352 (44%)] Loss: -204608.921875\n",
      "Train Epoch: 76 [7680/17352 (44%)] Loss: -191338.562500\n",
      "Train Epoch: 76 [7760/17352 (45%)] Loss: -177984.062500\n",
      "Train Epoch: 76 [7840/17352 (45%)] Loss: -208761.328125\n",
      "Train Epoch: 76 [7920/17352 (46%)] Loss: -203268.031250\n",
      "Train Epoch: 76 [8000/17352 (46%)] Loss: -193349.906250\n",
      "Train Epoch: 76 [8080/17352 (47%)] Loss: -159675.953125\n",
      "Train Epoch: 76 [8160/17352 (47%)] Loss: -177097.187500\n",
      "Train Epoch: 76 [8240/17352 (47%)] Loss: -175668.203125\n",
      "Train Epoch: 76 [8320/17352 (48%)] Loss: -192984.703125\n",
      "Train Epoch: 76 [8400/17352 (48%)] Loss: -215186.703125\n",
      "Train Epoch: 76 [8480/17352 (49%)] Loss: -167212.031250\n",
      "Train Epoch: 76 [8560/17352 (49%)] Loss: -228150.453125\n",
      "Train Epoch: 76 [8640/17352 (50%)] Loss: -216323.531250\n",
      "Train Epoch: 76 [8720/17352 (50%)] Loss: -194955.921875\n",
      "Train Epoch: 76 [8800/17352 (51%)] Loss: -188092.750000\n",
      "Train Epoch: 76 [8880/17352 (51%)] Loss: -188183.375000\n",
      "Train Epoch: 76 [8960/17352 (52%)] Loss: -174946.296875\n",
      "Train Epoch: 76 [9040/17352 (52%)] Loss: -203815.781250\n",
      "Train Epoch: 76 [9120/17352 (53%)] Loss: -209589.671875\n",
      "Train Epoch: 76 [9200/17352 (53%)] Loss: -200169.593750\n",
      "Train Epoch: 76 [9280/17352 (53%)] Loss: -196200.906250\n",
      "Train Epoch: 76 [9360/17352 (54%)] Loss: -188508.718750\n",
      "Train Epoch: 76 [9440/17352 (54%)] Loss: -201089.156250\n",
      "Train Epoch: 76 [9520/17352 (55%)] Loss: -156611.000000\n",
      "Train Epoch: 76 [9600/17352 (55%)] Loss: -225315.062500\n",
      "Train Epoch: 76 [9680/17352 (56%)] Loss: -212978.000000\n",
      "Train Epoch: 76 [9760/17352 (56%)] Loss: -197084.203125\n",
      "Train Epoch: 76 [9840/17352 (57%)] Loss: -187786.734375\n",
      "Train Epoch: 76 [9920/17352 (57%)] Loss: -214964.250000\n",
      "Train Epoch: 76 [10000/17352 (58%)] Loss: -160144.984375\n",
      "Train Epoch: 76 [10080/17352 (58%)] Loss: -199718.437500\n",
      "Train Epoch: 76 [10160/17352 (59%)] Loss: -180289.906250\n",
      "Train Epoch: 76 [10240/17352 (59%)] Loss: -192173.031250\n",
      "Train Epoch: 76 [10320/17352 (59%)] Loss: -188900.718750\n",
      "Train Epoch: 76 [10400/17352 (60%)] Loss: -200846.265625\n",
      "Train Epoch: 76 [10480/17352 (60%)] Loss: -192639.703125\n",
      "Train Epoch: 76 [10560/17352 (61%)] Loss: -193167.484375\n",
      "Train Epoch: 76 [10640/17352 (61%)] Loss: -208717.375000\n",
      "Train Epoch: 76 [10720/17352 (62%)] Loss: -179896.078125\n",
      "Train Epoch: 76 [10800/17352 (62%)] Loss: -192121.093750\n",
      "Train Epoch: 76 [10880/17352 (63%)] Loss: -164510.734375\n",
      "Train Epoch: 76 [10960/17352 (63%)] Loss: -189725.296875\n",
      "Train Epoch: 76 [11040/17352 (64%)] Loss: -154607.312500\n",
      "Train Epoch: 76 [11120/17352 (64%)] Loss: -180915.984375\n",
      "Train Epoch: 76 [11200/17352 (65%)] Loss: -171547.296875\n",
      "Train Epoch: 76 [11280/17352 (65%)] Loss: -177303.078125\n",
      "Train Epoch: 76 [11360/17352 (65%)] Loss: -205412.500000\n",
      "Train Epoch: 76 [11440/17352 (66%)] Loss: -212661.859375\n",
      "Train Epoch: 76 [11520/17352 (66%)] Loss: -171849.796875\n",
      "Train Epoch: 76 [11600/17352 (67%)] Loss: -182528.140625\n",
      "Train Epoch: 76 [11680/17352 (67%)] Loss: -185363.796875\n",
      "Train Epoch: 76 [11760/17352 (68%)] Loss: -178800.781250\n",
      "Train Epoch: 76 [11840/17352 (68%)] Loss: -203885.468750\n",
      "Train Epoch: 76 [11920/17352 (69%)] Loss: -210557.843750\n",
      "Train Epoch: 76 [12000/17352 (69%)] Loss: -228094.375000\n",
      "Train Epoch: 76 [12080/17352 (70%)] Loss: -199791.484375\n",
      "Train Epoch: 76 [12160/17352 (70%)] Loss: -201522.531250\n",
      "Train Epoch: 76 [12240/17352 (71%)] Loss: -220015.078125\n",
      "Train Epoch: 76 [12320/17352 (71%)] Loss: -152743.156250\n",
      "Train Epoch: 76 [12400/17352 (71%)] Loss: -195716.843750\n",
      "Train Epoch: 76 [12480/17352 (72%)] Loss: -183163.406250\n",
      "Train Epoch: 76 [12560/17352 (72%)] Loss: -214684.375000\n",
      "Train Epoch: 76 [12640/17352 (73%)] Loss: -194604.296875\n",
      "Train Epoch: 76 [12720/17352 (73%)] Loss: -149442.640625\n",
      "Train Epoch: 76 [12800/17352 (74%)] Loss: -177172.421875\n",
      "Train Epoch: 76 [12880/17352 (74%)] Loss: -184967.421875\n",
      "Train Epoch: 76 [12960/17352 (75%)] Loss: -171227.078125\n",
      "Train Epoch: 76 [13040/17352 (75%)] Loss: -179449.515625\n",
      "Train Epoch: 76 [13120/17352 (76%)] Loss: -187652.468750\n",
      "Train Epoch: 76 [13200/17352 (76%)] Loss: -180698.218750\n",
      "Train Epoch: 76 [13280/17352 (77%)] Loss: -164079.625000\n",
      "Train Epoch: 76 [13360/17352 (77%)] Loss: -166004.234375\n",
      "Train Epoch: 76 [13440/17352 (77%)] Loss: -177202.265625\n",
      "Train Epoch: 76 [13520/17352 (78%)] Loss: -173842.078125\n",
      "Train Epoch: 76 [13600/17352 (78%)] Loss: -199892.078125\n",
      "Train Epoch: 76 [13680/17352 (79%)] Loss: -215973.890625\n",
      "Train Epoch: 76 [13760/17352 (79%)] Loss: -210393.734375\n",
      "Train Epoch: 76 [13840/17352 (80%)] Loss: -200408.859375\n",
      "Train Epoch: 76 [13920/17352 (80%)] Loss: -208725.531250\n",
      "Train Epoch: 76 [14000/17352 (81%)] Loss: -189486.656250\n",
      "Train Epoch: 76 [14080/17352 (81%)] Loss: -170039.046875\n",
      "Train Epoch: 76 [14160/17352 (82%)] Loss: -180255.875000\n",
      "Train Epoch: 76 [14240/17352 (82%)] Loss: -185398.765625\n",
      "Train Epoch: 76 [14320/17352 (83%)] Loss: -177788.156250\n",
      "Train Epoch: 76 [14400/17352 (83%)] Loss: -167734.218750\n",
      "Train Epoch: 76 [14480/17352 (83%)] Loss: -208424.078125\n",
      "Train Epoch: 76 [14560/17352 (84%)] Loss: -166789.031250\n",
      "Train Epoch: 76 [14640/17352 (84%)] Loss: -170780.187500\n",
      "Train Epoch: 76 [14720/17352 (85%)] Loss: -188497.890625\n",
      "Train Epoch: 76 [14800/17352 (85%)] Loss: -181956.921875\n",
      "Train Epoch: 76 [14880/17352 (86%)] Loss: -179464.828125\n",
      "Train Epoch: 76 [14960/17352 (86%)] Loss: -199418.125000\n",
      "Train Epoch: 76 [15040/17352 (87%)] Loss: -215464.125000\n",
      "Train Epoch: 76 [15120/17352 (87%)] Loss: -214753.375000\n",
      "Train Epoch: 76 [15200/17352 (88%)] Loss: -183780.890625\n",
      "Train Epoch: 76 [15280/17352 (88%)] Loss: -183060.562500\n",
      "Train Epoch: 76 [15360/17352 (89%)] Loss: -153889.046875\n",
      "Train Epoch: 76 [15440/17352 (89%)] Loss: -166650.718750\n",
      "Train Epoch: 76 [15520/17352 (89%)] Loss: -183921.703125\n",
      "Train Epoch: 76 [15600/17352 (90%)] Loss: -163248.031250\n",
      "Train Epoch: 76 [15680/17352 (90%)] Loss: -176080.968750\n",
      "Train Epoch: 76 [15760/17352 (91%)] Loss: -198554.265625\n",
      "Train Epoch: 76 [15840/17352 (91%)] Loss: -157485.484375\n",
      "Train Epoch: 76 [15920/17352 (92%)] Loss: -196251.171875\n",
      "Train Epoch: 76 [16000/17352 (92%)] Loss: -192316.750000\n",
      "Train Epoch: 76 [16080/17352 (93%)] Loss: -208023.562500\n",
      "Train Epoch: 76 [16160/17352 (93%)] Loss: -131043.031250\n",
      "Train Epoch: 76 [16240/17352 (94%)] Loss: -158255.531250\n",
      "Train Epoch: 76 [16320/17352 (94%)] Loss: -187716.156250\n",
      "Train Epoch: 76 [16400/17352 (95%)] Loss: -218754.750000\n",
      "Train Epoch: 76 [16480/17352 (95%)] Loss: -189511.625000\n",
      "Train Epoch: 76 [16560/17352 (95%)] Loss: -196945.609375\n",
      "Train Epoch: 76 [16640/17352 (96%)] Loss: -185834.328125\n",
      "Train Epoch: 76 [16720/17352 (96%)] Loss: -174188.625000\n",
      "Train Epoch: 76 [16800/17352 (97%)] Loss: -205168.281250\n",
      "Train Epoch: 76 [16880/17352 (97%)] Loss: -151218.734375\n",
      "Train Epoch: 76 [16960/17352 (98%)] Loss: -178211.750000\n",
      "Train Epoch: 76 [17040/17352 (98%)] Loss: -200640.281250\n",
      "Train Epoch: 76 [17120/17352 (99%)] Loss: -204618.296875\n",
      "Train Epoch: 76 [17200/17352 (99%)] Loss: -165872.312500\n",
      "Train Epoch: 76 [17280/17352 (100%)] Loss: -176488.921875\n",
      "Train Epoch: 76 [17360/17352 (100%)] Loss: -169757.750000\n",
      "    epoch          : 76\n",
      "    loss           : -189317.9347130322\n",
      "    val_loss       : -23716.1406255731\n",
      "Train Epoch: 77 [0/17352 (0%)] Loss: -212694.984375\n",
      "Train Epoch: 77 [80/17352 (0%)] Loss: -196447.421875\n",
      "Train Epoch: 77 [160/17352 (1%)] Loss: -210205.390625\n",
      "Train Epoch: 77 [240/17352 (1%)] Loss: -233736.593750\n",
      "Train Epoch: 77 [320/17352 (2%)] Loss: -219262.781250\n",
      "Train Epoch: 77 [400/17352 (2%)] Loss: -205192.562500\n",
      "Train Epoch: 77 [480/17352 (3%)] Loss: -215098.078125\n",
      "Train Epoch: 77 [560/17352 (3%)] Loss: -214338.593750\n",
      "Train Epoch: 77 [640/17352 (4%)] Loss: -221761.906250\n",
      "Train Epoch: 77 [720/17352 (4%)] Loss: -207166.671875\n",
      "Train Epoch: 77 [800/17352 (5%)] Loss: -209780.984375\n",
      "Train Epoch: 77 [880/17352 (5%)] Loss: -216089.718750\n",
      "Train Epoch: 77 [960/17352 (6%)] Loss: -215491.156250\n",
      "Train Epoch: 77 [1040/17352 (6%)] Loss: -215829.640625\n",
      "Train Epoch: 77 [1120/17352 (6%)] Loss: -199809.781250\n",
      "Train Epoch: 77 [1200/17352 (7%)] Loss: -205111.609375\n",
      "Train Epoch: 77 [1280/17352 (7%)] Loss: -206785.687500\n",
      "Train Epoch: 77 [1360/17352 (8%)] Loss: -210754.718750\n",
      "Train Epoch: 77 [1440/17352 (8%)] Loss: -228020.578125\n",
      "Train Epoch: 77 [1520/17352 (9%)] Loss: -229958.921875\n",
      "Train Epoch: 77 [1600/17352 (9%)] Loss: -193716.421875\n",
      "Train Epoch: 77 [1680/17352 (10%)] Loss: -199537.453125\n",
      "Train Epoch: 77 [1760/17352 (10%)] Loss: -194494.484375\n",
      "Train Epoch: 77 [1840/17352 (11%)] Loss: -205929.093750\n",
      "Train Epoch: 77 [1920/17352 (11%)] Loss: -229237.734375\n",
      "Train Epoch: 77 [2000/17352 (12%)] Loss: -241905.625000\n",
      "Train Epoch: 77 [2080/17352 (12%)] Loss: -228905.218750\n",
      "Train Epoch: 77 [2160/17352 (12%)] Loss: -205085.500000\n",
      "Train Epoch: 77 [2240/17352 (13%)] Loss: -163248.718750\n",
      "Train Epoch: 77 [2320/17352 (13%)] Loss: -180998.515625\n",
      "Train Epoch: 77 [2400/17352 (14%)] Loss: -188568.484375\n",
      "Train Epoch: 77 [2480/17352 (14%)] Loss: -209197.031250\n",
      "Train Epoch: 77 [2560/17352 (15%)] Loss: -159313.156250\n",
      "Train Epoch: 77 [2640/17352 (15%)] Loss: -193497.484375\n",
      "Train Epoch: 77 [2720/17352 (16%)] Loss: -206095.593750\n",
      "Train Epoch: 77 [2800/17352 (16%)] Loss: -201307.234375\n",
      "Train Epoch: 77 [2880/17352 (17%)] Loss: -179970.531250\n",
      "Train Epoch: 77 [2960/17352 (17%)] Loss: -167245.218750\n",
      "Train Epoch: 77 [3040/17352 (18%)] Loss: -191641.140625\n",
      "Train Epoch: 77 [3120/17352 (18%)] Loss: -153890.375000\n",
      "Train Epoch: 77 [3200/17352 (18%)] Loss: -227894.109375\n",
      "Train Epoch: 77 [3280/17352 (19%)] Loss: -218519.593750\n",
      "Train Epoch: 77 [3360/17352 (19%)] Loss: -203460.125000\n",
      "Train Epoch: 77 [3440/17352 (20%)] Loss: -203888.843750\n",
      "Train Epoch: 77 [3520/17352 (20%)] Loss: -208312.312500\n",
      "Train Epoch: 77 [3600/17352 (21%)] Loss: -209511.078125\n",
      "Train Epoch: 77 [3680/17352 (21%)] Loss: -190504.718750\n",
      "Train Epoch: 77 [3760/17352 (22%)] Loss: -159753.734375\n",
      "Train Epoch: 77 [3840/17352 (22%)] Loss: -193368.437500\n",
      "Train Epoch: 77 [3920/17352 (23%)] Loss: -197994.296875\n",
      "Train Epoch: 77 [4000/17352 (23%)] Loss: -201094.062500\n",
      "Train Epoch: 77 [4080/17352 (24%)] Loss: -183065.671875\n",
      "Train Epoch: 77 [4160/17352 (24%)] Loss: -192384.578125\n",
      "Train Epoch: 77 [4240/17352 (24%)] Loss: -181923.093750\n",
      "Train Epoch: 77 [4320/17352 (25%)] Loss: -175665.796875\n",
      "Train Epoch: 77 [4400/17352 (25%)] Loss: -175669.093750\n",
      "Train Epoch: 77 [4480/17352 (26%)] Loss: -166456.765625\n",
      "Train Epoch: 77 [4560/17352 (26%)] Loss: -143618.968750\n",
      "Train Epoch: 77 [4640/17352 (27%)] Loss: -195377.531250\n",
      "Train Epoch: 77 [4720/17352 (27%)] Loss: -164137.546875\n",
      "Train Epoch: 77 [4800/17352 (28%)] Loss: -184755.687500\n",
      "Train Epoch: 77 [4880/17352 (28%)] Loss: -183922.046875\n",
      "Train Epoch: 77 [4960/17352 (29%)] Loss: -213902.265625\n",
      "Train Epoch: 77 [5040/17352 (29%)] Loss: -142336.984375\n",
      "Train Epoch: 77 [5120/17352 (30%)] Loss: -165862.484375\n",
      "Train Epoch: 77 [5200/17352 (30%)] Loss: -177474.859375\n",
      "Train Epoch: 77 [5280/17352 (30%)] Loss: -207869.625000\n",
      "Train Epoch: 77 [5360/17352 (31%)] Loss: -167486.031250\n",
      "Train Epoch: 77 [5440/17352 (31%)] Loss: -193008.015625\n",
      "Train Epoch: 77 [5520/17352 (32%)] Loss: -188006.718750\n",
      "Train Epoch: 77 [5600/17352 (32%)] Loss: -191511.500000\n",
      "Train Epoch: 77 [5680/17352 (33%)] Loss: -186609.062500\n",
      "Train Epoch: 77 [5760/17352 (33%)] Loss: -211168.765625\n",
      "Train Epoch: 77 [5840/17352 (34%)] Loss: -148157.781250\n",
      "Train Epoch: 77 [5920/17352 (34%)] Loss: -184070.625000\n",
      "Train Epoch: 77 [6000/17352 (35%)] Loss: -190236.296875\n",
      "Train Epoch: 77 [6080/17352 (35%)] Loss: -157592.781250\n",
      "Train Epoch: 77 [6160/17352 (36%)] Loss: -178824.875000\n",
      "Train Epoch: 77 [6240/17352 (36%)] Loss: -177251.125000\n",
      "Train Epoch: 77 [6320/17352 (36%)] Loss: -200839.828125\n",
      "Train Epoch: 77 [6400/17352 (37%)] Loss: -193098.390625\n",
      "Train Epoch: 77 [6480/17352 (37%)] Loss: -177101.640625\n",
      "Train Epoch: 77 [6560/17352 (38%)] Loss: -173844.921875\n",
      "Train Epoch: 77 [6640/17352 (38%)] Loss: -211721.781250\n",
      "Train Epoch: 77 [6720/17352 (39%)] Loss: -162562.703125\n",
      "Train Epoch: 77 [6800/17352 (39%)] Loss: -200635.578125\n",
      "Train Epoch: 77 [6880/17352 (40%)] Loss: -195835.375000\n",
      "Train Epoch: 77 [6960/17352 (40%)] Loss: -136424.546875\n",
      "Train Epoch: 77 [7040/17352 (41%)] Loss: -191957.968750\n",
      "Train Epoch: 77 [7120/17352 (41%)] Loss: -166656.109375\n",
      "Train Epoch: 77 [7200/17352 (41%)] Loss: -168969.359375\n",
      "Train Epoch: 77 [7280/17352 (42%)] Loss: -178328.828125\n",
      "Train Epoch: 77 [7360/17352 (42%)] Loss: -182745.453125\n",
      "Train Epoch: 77 [7440/17352 (43%)] Loss: -183727.359375\n",
      "Train Epoch: 77 [7520/17352 (43%)] Loss: -188182.000000\n",
      "Train Epoch: 77 [7600/17352 (44%)] Loss: -192245.843750\n",
      "Train Epoch: 77 [7680/17352 (44%)] Loss: -170352.843750\n",
      "Train Epoch: 77 [7760/17352 (45%)] Loss: -180542.234375\n",
      "Train Epoch: 77 [7840/17352 (45%)] Loss: -193132.218750\n",
      "Train Epoch: 77 [7920/17352 (46%)] Loss: -210794.640625\n",
      "Train Epoch: 77 [8000/17352 (46%)] Loss: -174030.015625\n",
      "Train Epoch: 77 [8080/17352 (47%)] Loss: -197541.781250\n",
      "Train Epoch: 77 [8160/17352 (47%)] Loss: -181673.250000\n",
      "Train Epoch: 77 [8240/17352 (47%)] Loss: -225323.390625\n",
      "Train Epoch: 77 [8320/17352 (48%)] Loss: -201935.515625\n",
      "Train Epoch: 77 [8400/17352 (48%)] Loss: -205170.750000\n",
      "Train Epoch: 77 [8480/17352 (49%)] Loss: -188862.062500\n",
      "Train Epoch: 77 [8560/17352 (49%)] Loss: -167871.796875\n",
      "Train Epoch: 77 [8640/17352 (50%)] Loss: -202870.875000\n",
      "Train Epoch: 77 [8720/17352 (50%)] Loss: -164687.484375\n",
      "Train Epoch: 77 [8800/17352 (51%)] Loss: -197522.203125\n",
      "Train Epoch: 77 [8880/17352 (51%)] Loss: -171710.468750\n",
      "Train Epoch: 77 [8960/17352 (52%)] Loss: -228253.531250\n",
      "Train Epoch: 77 [9040/17352 (52%)] Loss: -167799.968750\n",
      "Train Epoch: 77 [9120/17352 (53%)] Loss: -206243.453125\n",
      "Train Epoch: 77 [9200/17352 (53%)] Loss: -196944.406250\n",
      "Train Epoch: 77 [9280/17352 (53%)] Loss: -179414.359375\n",
      "Train Epoch: 77 [9360/17352 (54%)] Loss: -187323.453125\n",
      "Train Epoch: 77 [9440/17352 (54%)] Loss: -146854.203125\n",
      "Train Epoch: 77 [9520/17352 (55%)] Loss: -214753.687500\n",
      "Train Epoch: 77 [9600/17352 (55%)] Loss: -196504.156250\n",
      "Train Epoch: 77 [9680/17352 (56%)] Loss: -202309.218750\n",
      "Train Epoch: 77 [9760/17352 (56%)] Loss: -161095.437500\n",
      "Train Epoch: 77 [9840/17352 (57%)] Loss: -173364.937500\n",
      "Train Epoch: 77 [9920/17352 (57%)] Loss: -203442.375000\n",
      "Train Epoch: 77 [10000/17352 (58%)] Loss: -148929.406250\n",
      "Train Epoch: 77 [10080/17352 (58%)] Loss: -167214.062500\n",
      "Train Epoch: 77 [10160/17352 (59%)] Loss: -201378.140625\n",
      "Train Epoch: 77 [10240/17352 (59%)] Loss: -159672.671875\n",
      "Train Epoch: 77 [10320/17352 (59%)] Loss: -175507.906250\n",
      "Train Epoch: 77 [10400/17352 (60%)] Loss: -178310.796875\n",
      "Train Epoch: 77 [10480/17352 (60%)] Loss: -167248.140625\n",
      "Train Epoch: 77 [10560/17352 (61%)] Loss: -183590.250000\n",
      "Train Epoch: 77 [10640/17352 (61%)] Loss: -187772.281250\n",
      "Train Epoch: 77 [10720/17352 (62%)] Loss: -184971.406250\n",
      "Train Epoch: 77 [10800/17352 (62%)] Loss: -185268.906250\n",
      "Train Epoch: 77 [10880/17352 (63%)] Loss: -175759.562500\n",
      "Train Epoch: 77 [10960/17352 (63%)] Loss: -188678.968750\n",
      "Train Epoch: 77 [11040/17352 (64%)] Loss: -209265.437500\n",
      "Train Epoch: 77 [11120/17352 (64%)] Loss: -205691.390625\n",
      "Train Epoch: 77 [11200/17352 (65%)] Loss: -149442.875000\n",
      "Train Epoch: 77 [11280/17352 (65%)] Loss: -156610.328125\n",
      "Train Epoch: 77 [11360/17352 (65%)] Loss: -186512.671875\n",
      "Train Epoch: 77 [11440/17352 (66%)] Loss: -183082.937500\n",
      "Train Epoch: 77 [11520/17352 (66%)] Loss: -174910.953125\n",
      "Train Epoch: 77 [11600/17352 (67%)] Loss: -174187.921875\n",
      "Train Epoch: 77 [11680/17352 (67%)] Loss: -170232.578125\n",
      "Train Epoch: 77 [11760/17352 (68%)] Loss: -200642.359375\n",
      "Train Epoch: 77 [11840/17352 (68%)] Loss: -213750.734375\n",
      "Train Epoch: 77 [11920/17352 (69%)] Loss: -185836.671875\n",
      "Train Epoch: 77 [12000/17352 (69%)] Loss: -196295.406250\n",
      "Train Epoch: 77 [12080/17352 (70%)] Loss: -179497.812500\n",
      "Train Epoch: 77 [12160/17352 (70%)] Loss: -167093.031250\n",
      "Train Epoch: 77 [12240/17352 (71%)] Loss: -164373.640625\n",
      "Train Epoch: 77 [12320/17352 (71%)] Loss: -174994.812500\n",
      "Train Epoch: 77 [12400/17352 (71%)] Loss: -168051.203125\n",
      "Train Epoch: 77 [12480/17352 (72%)] Loss: -169166.281250\n",
      "Train Epoch: 77 [12560/17352 (72%)] Loss: -165807.125000\n",
      "Train Epoch: 77 [12640/17352 (73%)] Loss: -184985.921875\n",
      "Train Epoch: 77 [12720/17352 (73%)] Loss: -188056.750000\n",
      "Train Epoch: 77 [12800/17352 (74%)] Loss: -186501.937500\n",
      "Train Epoch: 77 [12880/17352 (74%)] Loss: -173304.218750\n",
      "Train Epoch: 77 [12960/17352 (75%)] Loss: -185784.187500\n",
      "Train Epoch: 77 [13040/17352 (75%)] Loss: -205520.937500\n",
      "Train Epoch: 77 [13120/17352 (76%)] Loss: -191153.937500\n",
      "Train Epoch: 77 [13200/17352 (76%)] Loss: -175013.937500\n",
      "Train Epoch: 77 [13280/17352 (77%)] Loss: -205644.218750\n",
      "Train Epoch: 77 [13360/17352 (77%)] Loss: -196561.984375\n",
      "Train Epoch: 77 [13440/17352 (77%)] Loss: -156470.109375\n",
      "Train Epoch: 77 [13520/17352 (78%)] Loss: -178216.593750\n",
      "Train Epoch: 77 [13600/17352 (78%)] Loss: -198831.687500\n",
      "Train Epoch: 77 [13680/17352 (79%)] Loss: -180258.187500\n",
      "Train Epoch: 77 [13760/17352 (79%)] Loss: -203482.312500\n",
      "Train Epoch: 77 [13840/17352 (80%)] Loss: -171308.437500\n",
      "Train Epoch: 77 [13920/17352 (80%)] Loss: -148397.406250\n",
      "Train Epoch: 77 [14000/17352 (81%)] Loss: -223964.625000\n",
      "Train Epoch: 77 [14080/17352 (81%)] Loss: -172554.468750\n",
      "Train Epoch: 77 [14160/17352 (82%)] Loss: -163204.640625\n",
      "Train Epoch: 77 [14240/17352 (82%)] Loss: -189406.109375\n",
      "Train Epoch: 77 [14320/17352 (83%)] Loss: -185922.718750\n",
      "Train Epoch: 77 [14400/17352 (83%)] Loss: -208431.250000\n",
      "Train Epoch: 77 [14480/17352 (83%)] Loss: -168677.500000\n",
      "Train Epoch: 77 [14560/17352 (84%)] Loss: -187129.453125\n",
      "Train Epoch: 77 [14640/17352 (84%)] Loss: -201035.359375\n",
      "Train Epoch: 77 [14720/17352 (85%)] Loss: -212620.375000\n",
      "Train Epoch: 77 [14800/17352 (85%)] Loss: -207785.156250\n",
      "Train Epoch: 77 [14880/17352 (86%)] Loss: -198263.312500\n",
      "Train Epoch: 77 [14960/17352 (86%)] Loss: -180509.375000\n",
      "Train Epoch: 77 [15040/17352 (87%)] Loss: -147415.453125\n",
      "Train Epoch: 77 [15120/17352 (87%)] Loss: -218468.281250\n",
      "Train Epoch: 77 [15200/17352 (88%)] Loss: -183168.875000\n",
      "Train Epoch: 77 [15280/17352 (88%)] Loss: -195839.859375\n",
      "Train Epoch: 77 [15360/17352 (89%)] Loss: -175603.234375\n",
      "Train Epoch: 77 [15440/17352 (89%)] Loss: -203874.468750\n",
      "Train Epoch: 77 [15520/17352 (89%)] Loss: -151733.140625\n",
      "Train Epoch: 77 [15600/17352 (90%)] Loss: -183381.750000\n",
      "Train Epoch: 77 [15680/17352 (90%)] Loss: -179005.937500\n",
      "Train Epoch: 77 [15760/17352 (91%)] Loss: -219925.765625\n",
      "Train Epoch: 77 [15840/17352 (91%)] Loss: -187400.312500\n",
      "Train Epoch: 77 [15920/17352 (92%)] Loss: -214965.421875\n",
      "Train Epoch: 77 [16000/17352 (92%)] Loss: -187540.187500\n",
      "Train Epoch: 77 [16080/17352 (93%)] Loss: -177486.125000\n",
      "Train Epoch: 77 [16160/17352 (93%)] Loss: -192690.937500\n",
      "Train Epoch: 77 [16240/17352 (94%)] Loss: -202792.718750\n",
      "Train Epoch: 77 [16320/17352 (94%)] Loss: -189797.265625\n",
      "Train Epoch: 77 [16400/17352 (95%)] Loss: -187219.250000\n",
      "Train Epoch: 77 [16480/17352 (95%)] Loss: -165802.250000\n",
      "Train Epoch: 77 [16560/17352 (95%)] Loss: -207857.234375\n",
      "Train Epoch: 77 [16640/17352 (96%)] Loss: -185435.750000\n",
      "Train Epoch: 77 [16720/17352 (96%)] Loss: -172189.156250\n",
      "Train Epoch: 77 [16800/17352 (97%)] Loss: -129698.539062\n",
      "Train Epoch: 77 [16880/17352 (97%)] Loss: -177600.062500\n",
      "Train Epoch: 77 [16960/17352 (98%)] Loss: -170034.578125\n",
      "Train Epoch: 77 [17040/17352 (98%)] Loss: -196402.921875\n",
      "Train Epoch: 77 [17120/17352 (99%)] Loss: -205221.593750\n",
      "Train Epoch: 77 [17200/17352 (99%)] Loss: -209188.187500\n",
      "Train Epoch: 77 [17280/17352 (100%)] Loss: -201374.890625\n",
      "Train Epoch: 77 [17360/17352 (100%)] Loss: -197082.156250\n",
      "    epoch          : 77\n",
      "    loss           : -189490.13500611336\n",
      "    val_loss       : -23716.1278066859\n",
      "Train Epoch: 78 [0/17352 (0%)] Loss: -228019.218750\n",
      "Train Epoch: 78 [80/17352 (0%)] Loss: -204407.000000\n",
      "Train Epoch: 78 [160/17352 (1%)] Loss: -205560.000000\n",
      "Train Epoch: 78 [240/17352 (1%)] Loss: -208381.250000\n",
      "Train Epoch: 78 [320/17352 (2%)] Loss: -215096.015625\n",
      "Train Epoch: 78 [400/17352 (2%)] Loss: -217937.531250\n",
      "Train Epoch: 78 [480/17352 (3%)] Loss: -218557.171875\n",
      "Train Epoch: 78 [560/17352 (3%)] Loss: -202321.906250\n",
      "Train Epoch: 78 [640/17352 (4%)] Loss: -205215.031250\n",
      "Train Epoch: 78 [720/17352 (4%)] Loss: -233734.437500\n",
      "Train Epoch: 78 [800/17352 (5%)] Loss: -213325.125000\n",
      "Train Epoch: 78 [880/17352 (5%)] Loss: -236505.734375\n",
      "Train Epoch: 78 [960/17352 (6%)] Loss: -194294.687500\n",
      "Train Epoch: 78 [1040/17352 (6%)] Loss: -196929.203125\n",
      "Train Epoch: 78 [1120/17352 (6%)] Loss: -210209.000000\n",
      "Train Epoch: 78 [1200/17352 (7%)] Loss: -209637.031250\n",
      "Train Epoch: 78 [1280/17352 (7%)] Loss: -224251.890625\n",
      "Train Epoch: 78 [1360/17352 (8%)] Loss: -207169.812500\n",
      "Train Epoch: 78 [1440/17352 (8%)] Loss: -230410.937500\n",
      "Train Epoch: 78 [1520/17352 (9%)] Loss: -206150.156250\n",
      "Train Epoch: 78 [1600/17352 (9%)] Loss: -211108.250000\n",
      "Train Epoch: 78 [1680/17352 (10%)] Loss: -236639.125000\n",
      "Train Epoch: 78 [1760/17352 (10%)] Loss: -186067.843750\n",
      "Train Epoch: 78 [1840/17352 (11%)] Loss: -206654.296875\n",
      "Train Epoch: 78 [1920/17352 (11%)] Loss: -230191.109375\n",
      "Train Epoch: 78 [2000/17352 (12%)] Loss: -199805.906250\n",
      "Train Epoch: 78 [2080/17352 (12%)] Loss: -231328.390625\n",
      "Train Epoch: 78 [2160/17352 (12%)] Loss: -217629.937500\n",
      "Train Epoch: 78 [2240/17352 (13%)] Loss: -192176.859375\n",
      "Train Epoch: 78 [2320/17352 (13%)] Loss: -179463.828125\n",
      "Train Epoch: 78 [2400/17352 (14%)] Loss: -176890.625000\n",
      "Train Epoch: 78 [2480/17352 (14%)] Loss: -168056.921875\n",
      "Train Epoch: 78 [2560/17352 (15%)] Loss: -183283.453125\n",
      "Train Epoch: 78 [2640/17352 (15%)] Loss: -153890.921875\n",
      "Train Epoch: 78 [2720/17352 (16%)] Loss: -206225.765625\n",
      "Train Epoch: 78 [2800/17352 (16%)] Loss: -188181.937500\n",
      "Train Epoch: 78 [2880/17352 (17%)] Loss: -209421.265625\n",
      "Train Epoch: 78 [2960/17352 (17%)] Loss: -199602.437500\n",
      "Train Epoch: 78 [3040/17352 (18%)] Loss: -136431.906250\n",
      "Train Epoch: 78 [3120/17352 (18%)] Loss: -198694.359375\n",
      "Train Epoch: 78 [3200/17352 (18%)] Loss: -194064.171875\n",
      "Train Epoch: 78 [3280/17352 (19%)] Loss: -202986.687500\n",
      "Train Epoch: 78 [3360/17352 (19%)] Loss: -193129.968750\n",
      "Train Epoch: 78 [3440/17352 (20%)] Loss: -183610.656250\n",
      "Train Epoch: 78 [3520/17352 (20%)] Loss: -167253.500000\n",
      "Train Epoch: 78 [3600/17352 (21%)] Loss: -192748.515625\n",
      "Train Epoch: 78 [3680/17352 (21%)] Loss: -191956.265625\n",
      "Train Epoch: 78 [3760/17352 (22%)] Loss: -175508.078125\n",
      "Train Epoch: 78 [3840/17352 (22%)] Loss: -202520.765625\n",
      "Train Epoch: 78 [3920/17352 (23%)] Loss: -185046.109375\n",
      "Train Epoch: 78 [4000/17352 (23%)] Loss: -178733.906250\n",
      "Train Epoch: 78 [4080/17352 (24%)] Loss: -184920.359375\n",
      "Train Epoch: 78 [4160/17352 (24%)] Loss: -148447.937500\n",
      "Train Epoch: 78 [4240/17352 (24%)] Loss: -163249.750000\n",
      "Train Epoch: 78 [4320/17352 (25%)] Loss: -186189.578125\n",
      "Train Epoch: 78 [4400/17352 (25%)] Loss: -143624.687500\n",
      "Train Epoch: 78 [4480/17352 (26%)] Loss: -177148.781250\n",
      "Train Epoch: 78 [4560/17352 (26%)] Loss: -197303.312500\n",
      "Train Epoch: 78 [4640/17352 (27%)] Loss: -167300.937500\n",
      "Train Epoch: 78 [4720/17352 (27%)] Loss: -193958.890625\n",
      "Train Epoch: 78 [4800/17352 (28%)] Loss: -177977.734375\n",
      "Train Epoch: 78 [4880/17352 (28%)] Loss: -183763.875000\n",
      "Train Epoch: 78 [4960/17352 (29%)] Loss: -173370.328125\n",
      "Train Epoch: 78 [5040/17352 (29%)] Loss: -208802.546875\n",
      "Train Epoch: 78 [5120/17352 (30%)] Loss: -201824.875000\n",
      "Train Epoch: 78 [5200/17352 (30%)] Loss: -178318.250000\n",
      "Train Epoch: 78 [5280/17352 (30%)] Loss: -179314.171875\n",
      "Train Epoch: 78 [5360/17352 (31%)] Loss: -184826.125000\n",
      "Train Epoch: 78 [5440/17352 (31%)] Loss: -180260.359375\n",
      "Train Epoch: 78 [5520/17352 (32%)] Loss: -188494.140625\n",
      "Train Epoch: 78 [5600/17352 (32%)] Loss: -228093.140625\n",
      "Train Epoch: 78 [5680/17352 (33%)] Loss: -173942.437500\n",
      "Train Epoch: 78 [5760/17352 (33%)] Loss: -192016.031250\n",
      "Train Epoch: 78 [5840/17352 (34%)] Loss: -166459.031250\n",
      "Train Epoch: 78 [5920/17352 (34%)] Loss: -179924.937500\n",
      "Train Epoch: 78 [6000/17352 (35%)] Loss: -184174.593750\n",
      "Train Epoch: 78 [6080/17352 (35%)] Loss: -191807.203125\n",
      "Train Epoch: 78 [6160/17352 (36%)] Loss: -149334.734375\n",
      "Train Epoch: 78 [6240/17352 (36%)] Loss: -186498.468750\n",
      "Train Epoch: 78 [6320/17352 (36%)] Loss: -168084.015625\n",
      "Train Epoch: 78 [6400/17352 (37%)] Loss: -183720.796875\n",
      "Train Epoch: 78 [6480/17352 (37%)] Loss: -188003.437500\n",
      "Train Epoch: 78 [6560/17352 (38%)] Loss: -174719.468750\n",
      "Train Epoch: 78 [6640/17352 (38%)] Loss: -188272.593750\n",
      "Train Epoch: 78 [6720/17352 (39%)] Loss: -191808.328125\n",
      "Train Epoch: 78 [6800/17352 (39%)] Loss: -180241.875000\n",
      "Train Epoch: 78 [6880/17352 (40%)] Loss: -173584.500000\n",
      "Train Epoch: 78 [6960/17352 (40%)] Loss: -206243.234375\n",
      "Train Epoch: 78 [7040/17352 (41%)] Loss: -201310.875000\n",
      "Train Epoch: 78 [7120/17352 (41%)] Loss: -180910.250000\n",
      "Train Epoch: 78 [7200/17352 (41%)] Loss: -208156.812500\n",
      "Train Epoch: 78 [7280/17352 (42%)] Loss: -172893.890625\n",
      "Train Epoch: 78 [7360/17352 (42%)] Loss: -192958.796875\n",
      "Train Epoch: 78 [7440/17352 (43%)] Loss: -190941.265625\n",
      "Train Epoch: 78 [7520/17352 (43%)] Loss: -173127.968750\n",
      "Train Epoch: 78 [7600/17352 (44%)] Loss: -185550.515625\n",
      "Train Epoch: 78 [7680/17352 (44%)] Loss: -183613.765625\n",
      "Train Epoch: 78 [7760/17352 (45%)] Loss: -180550.921875\n",
      "Train Epoch: 78 [7840/17352 (45%)] Loss: -196501.375000\n",
      "Train Epoch: 78 [7920/17352 (46%)] Loss: -215412.468750\n",
      "Train Epoch: 78 [8000/17352 (46%)] Loss: -174915.421875\n",
      "Train Epoch: 78 [8080/17352 (47%)] Loss: -195059.828125\n",
      "Train Epoch: 78 [8160/17352 (47%)] Loss: -163093.281250\n",
      "Train Epoch: 78 [8240/17352 (47%)] Loss: -203844.031250\n",
      "Train Epoch: 78 [8320/17352 (48%)] Loss: -157773.062500\n",
      "Train Epoch: 78 [8400/17352 (48%)] Loss: -201112.953125\n",
      "Train Epoch: 78 [8480/17352 (49%)] Loss: -190583.828125\n",
      "Train Epoch: 78 [8560/17352 (49%)] Loss: -184833.468750\n",
      "Train Epoch: 78 [8640/17352 (50%)] Loss: -181738.250000\n",
      "Train Epoch: 78 [8720/17352 (50%)] Loss: -179733.734375\n",
      "Train Epoch: 78 [8800/17352 (51%)] Loss: -196199.046875\n",
      "Train Epoch: 78 [8880/17352 (51%)] Loss: -201377.437500\n",
      "Train Epoch: 78 [8960/17352 (52%)] Loss: -151738.843750\n",
      "Train Epoch: 78 [9040/17352 (52%)] Loss: -205688.640625\n",
      "Train Epoch: 78 [9120/17352 (53%)] Loss: -189490.093750\n",
      "Train Epoch: 78 [9200/17352 (53%)] Loss: -193053.015625\n",
      "Train Epoch: 78 [9280/17352 (53%)] Loss: -188435.406250\n",
      "Train Epoch: 78 [9360/17352 (54%)] Loss: -167044.703125\n",
      "Train Epoch: 78 [9440/17352 (54%)] Loss: -183923.218750\n",
      "Train Epoch: 78 [9520/17352 (55%)] Loss: -200204.953125\n",
      "Train Epoch: 78 [9600/17352 (55%)] Loss: -204414.875000\n",
      "Train Epoch: 78 [9680/17352 (56%)] Loss: -193795.718750\n",
      "Train Epoch: 78 [9760/17352 (56%)] Loss: -174942.031250\n",
      "Train Epoch: 78 [9840/17352 (57%)] Loss: -153316.281250\n",
      "Train Epoch: 78 [9920/17352 (57%)] Loss: -185829.421875\n",
      "Train Epoch: 78 [10000/17352 (58%)] Loss: -167146.250000\n",
      "Train Epoch: 78 [10080/17352 (58%)] Loss: -179894.390625\n",
      "Train Epoch: 78 [10160/17352 (59%)] Loss: -204343.453125\n",
      "Train Epoch: 78 [10240/17352 (59%)] Loss: -190919.234375\n",
      "Train Epoch: 78 [10320/17352 (59%)] Loss: -192790.640625\n",
      "Train Epoch: 78 [10400/17352 (60%)] Loss: -188867.250000\n",
      "Train Epoch: 78 [10480/17352 (60%)] Loss: -191156.281250\n",
      "Train Epoch: 78 [10560/17352 (61%)] Loss: -185290.859375\n",
      "Train Epoch: 78 [10640/17352 (61%)] Loss: -170535.031250\n",
      "Train Epoch: 78 [10720/17352 (62%)] Loss: -193519.718750\n",
      "Train Epoch: 78 [10800/17352 (62%)] Loss: -191594.546875\n",
      "Train Epoch: 78 [10880/17352 (63%)] Loss: -183789.750000\n",
      "Train Epoch: 78 [10960/17352 (63%)] Loss: -174484.906250\n",
      "Train Epoch: 78 [11040/17352 (64%)] Loss: -181720.109375\n",
      "Train Epoch: 78 [11120/17352 (64%)] Loss: -207089.359375\n",
      "Train Epoch: 78 [11200/17352 (65%)] Loss: -162559.281250\n",
      "Train Epoch: 78 [11280/17352 (65%)] Loss: -187773.765625\n",
      "Train Epoch: 78 [11360/17352 (65%)] Loss: -195837.750000\n",
      "Train Epoch: 78 [11440/17352 (66%)] Loss: -179167.031250\n",
      "Train Epoch: 78 [11520/17352 (66%)] Loss: -197597.468750\n",
      "Train Epoch: 78 [11600/17352 (67%)] Loss: -192368.265625\n",
      "Train Epoch: 78 [11680/17352 (67%)] Loss: -187528.062500\n",
      "Train Epoch: 78 [11760/17352 (68%)] Loss: -177200.125000\n",
      "Train Epoch: 78 [11840/17352 (68%)] Loss: -190475.453125\n",
      "Train Epoch: 78 [11920/17352 (69%)] Loss: -178133.062500\n",
      "Train Epoch: 78 [12000/17352 (69%)] Loss: -208429.406250\n",
      "Train Epoch: 78 [12080/17352 (70%)] Loss: -181758.656250\n",
      "Train Epoch: 78 [12160/17352 (70%)] Loss: -183223.093750\n",
      "Train Epoch: 78 [12240/17352 (71%)] Loss: -178874.890625\n",
      "Train Epoch: 78 [12320/17352 (71%)] Loss: -188745.000000\n",
      "Train Epoch: 78 [12400/17352 (71%)] Loss: -184996.468750\n",
      "Train Epoch: 78 [12480/17352 (72%)] Loss: -209598.812500\n",
      "Train Epoch: 78 [12560/17352 (72%)] Loss: -146854.453125\n",
      "Train Epoch: 78 [12640/17352 (73%)] Loss: -189265.718750\n",
      "Train Epoch: 78 [12720/17352 (73%)] Loss: -168763.531250\n",
      "Train Epoch: 78 [12800/17352 (74%)] Loss: -163755.468750\n",
      "Train Epoch: 78 [12880/17352 (74%)] Loss: -203514.015625\n",
      "Train Epoch: 78 [12960/17352 (75%)] Loss: -176542.859375\n",
      "Train Epoch: 78 [13040/17352 (75%)] Loss: -191563.312500\n",
      "Train Epoch: 78 [13120/17352 (76%)] Loss: -201323.531250\n",
      "Train Epoch: 78 [13200/17352 (76%)] Loss: -190232.390625\n",
      "Train Epoch: 78 [13280/17352 (77%)] Loss: -187361.062500\n",
      "Train Epoch: 78 [13360/17352 (77%)] Loss: -196559.296875\n",
      "Train Epoch: 78 [13440/17352 (77%)] Loss: -170783.796875\n",
      "Train Epoch: 78 [13520/17352 (78%)] Loss: -160149.984375\n",
      "Train Epoch: 78 [13600/17352 (78%)] Loss: -177767.593750\n",
      "Train Epoch: 78 [13680/17352 (79%)] Loss: -196032.859375\n",
      "Train Epoch: 78 [13760/17352 (79%)] Loss: -204608.656250\n",
      "Train Epoch: 78 [13840/17352 (80%)] Loss: -174187.718750\n",
      "Train Epoch: 78 [13920/17352 (80%)] Loss: -203487.031250\n",
      "Train Epoch: 78 [14000/17352 (81%)] Loss: -187786.937500\n",
      "Train Epoch: 78 [14080/17352 (81%)] Loss: -212981.765625\n",
      "Train Epoch: 78 [14160/17352 (82%)] Loss: -204662.078125\n",
      "Train Epoch: 78 [14240/17352 (82%)] Loss: -187222.578125\n",
      "Train Epoch: 78 [14320/17352 (83%)] Loss: -202018.390625\n",
      "Train Epoch: 78 [14400/17352 (83%)] Loss: -176594.750000\n",
      "Train Epoch: 78 [14480/17352 (83%)] Loss: -188809.703125\n",
      "Train Epoch: 78 [14560/17352 (84%)] Loss: -187951.562500\n",
      "Train Epoch: 78 [14640/17352 (84%)] Loss: -216323.328125\n",
      "Train Epoch: 78 [14720/17352 (85%)] Loss: -194602.796875\n",
      "Train Epoch: 78 [14800/17352 (85%)] Loss: -210266.093750\n",
      "Train Epoch: 78 [14880/17352 (86%)] Loss: -177470.843750\n",
      "Train Epoch: 78 [14960/17352 (86%)] Loss: -205003.890625\n",
      "Train Epoch: 78 [15040/17352 (87%)] Loss: -185232.156250\n",
      "Train Epoch: 78 [15120/17352 (87%)] Loss: -188680.125000\n",
      "Train Epoch: 78 [15200/17352 (88%)] Loss: -173511.140625\n",
      "Train Epoch: 78 [15280/17352 (88%)] Loss: -188149.468750\n",
      "Train Epoch: 78 [15360/17352 (89%)] Loss: -174143.265625\n",
      "Train Epoch: 78 [15440/17352 (89%)] Loss: -218756.312500\n",
      "Train Epoch: 78 [15520/17352 (89%)] Loss: -177624.156250\n",
      "Train Epoch: 78 [15600/17352 (90%)] Loss: -197952.671875\n",
      "Train Epoch: 78 [15680/17352 (90%)] Loss: -202991.125000\n",
      "Train Epoch: 78 [15760/17352 (91%)] Loss: -197107.406250\n",
      "Train Epoch: 78 [15840/17352 (91%)] Loss: -185062.109375\n",
      "Train Epoch: 78 [15920/17352 (92%)] Loss: -180108.843750\n",
      "Train Epoch: 78 [16000/17352 (92%)] Loss: -181984.281250\n",
      "Train Epoch: 78 [16080/17352 (93%)] Loss: -146009.593750\n",
      "Train Epoch: 78 [16160/17352 (93%)] Loss: -173927.125000\n",
      "Train Epoch: 78 [16240/17352 (94%)] Loss: -213179.828125\n",
      "Train Epoch: 78 [16320/17352 (94%)] Loss: -196701.656250\n",
      "Train Epoch: 78 [16400/17352 (95%)] Loss: -177781.843750\n",
      "Train Epoch: 78 [16480/17352 (95%)] Loss: -184735.468750\n",
      "Train Epoch: 78 [16560/17352 (95%)] Loss: -183087.062500\n",
      "Train Epoch: 78 [16640/17352 (96%)] Loss: -203808.328125\n",
      "Train Epoch: 78 [16720/17352 (96%)] Loss: -185826.875000\n",
      "Train Epoch: 78 [16800/17352 (97%)] Loss: -201264.015625\n",
      "Train Epoch: 78 [16880/17352 (97%)] Loss: -178202.187500\n",
      "Train Epoch: 78 [16960/17352 (98%)] Loss: -183465.390625\n",
      "Train Epoch: 78 [17040/17352 (98%)] Loss: -176913.609375\n",
      "Train Epoch: 78 [17120/17352 (99%)] Loss: -170036.890625\n",
      "Train Epoch: 78 [17200/17352 (99%)] Loss: -200865.531250\n",
      "Train Epoch: 78 [17280/17352 (100%)] Loss: -202879.812500\n",
      "Train Epoch: 78 [17360/17352 (100%)] Loss: -177305.562500\n",
      "    epoch          : 78\n",
      "    loss           : -189161.91638197642\n",
      "    val_loss       : -23716.116405576606\n",
      "Train Epoch: 79 [0/17352 (0%)] Loss: -199541.296875\n",
      "Train Epoch: 79 [80/17352 (0%)] Loss: -208535.578125\n",
      "Train Epoch: 79 [160/17352 (1%)] Loss: -213337.578125\n",
      "Train Epoch: 79 [240/17352 (1%)] Loss: -193712.796875\n",
      "Train Epoch: 79 [320/17352 (2%)] Loss: -213324.531250\n",
      "Train Epoch: 79 [400/17352 (2%)] Loss: -185165.203125\n",
      "Train Epoch: 79 [480/17352 (3%)] Loss: -209552.937500\n",
      "Train Epoch: 79 [560/17352 (3%)] Loss: -217941.000000\n",
      "Train Epoch: 79 [640/17352 (4%)] Loss: -224247.218750\n",
      "Train Epoch: 79 [720/17352 (4%)] Loss: -219261.546875\n",
      "Train Epoch: 79 [800/17352 (5%)] Loss: -226097.500000\n",
      "Train Epoch: 79 [880/17352 (5%)] Loss: -222513.546875\n",
      "Train Epoch: 79 [960/17352 (6%)] Loss: -212656.609375\n",
      "Train Epoch: 79 [1040/17352 (6%)] Loss: -210756.625000\n",
      "Train Epoch: 79 [1120/17352 (6%)] Loss: -206566.531250\n",
      "Train Epoch: 79 [1200/17352 (7%)] Loss: -215487.734375\n",
      "Train Epoch: 79 [1280/17352 (7%)] Loss: -224250.734375\n",
      "Train Epoch: 79 [1360/17352 (8%)] Loss: -202235.750000\n",
      "Train Epoch: 79 [1440/17352 (8%)] Loss: -214713.562500\n",
      "Train Epoch: 79 [1520/17352 (9%)] Loss: -182778.312500\n",
      "Train Epoch: 79 [1600/17352 (9%)] Loss: -199904.609375\n",
      "Train Epoch: 79 [1680/17352 (10%)] Loss: -213833.265625\n",
      "Train Epoch: 79 [1760/17352 (10%)] Loss: -235593.859375\n",
      "Train Epoch: 79 [1840/17352 (11%)] Loss: -207168.187500\n",
      "Train Epoch: 79 [1920/17352 (11%)] Loss: -186077.859375\n",
      "Train Epoch: 79 [2000/17352 (12%)] Loss: -228912.687500\n",
      "Train Epoch: 79 [2080/17352 (12%)] Loss: -229239.250000\n",
      "Train Epoch: 79 [2160/17352 (12%)] Loss: -210213.187500\n",
      "Train Epoch: 79 [2240/17352 (13%)] Loss: -203476.000000\n",
      "Train Epoch: 79 [2320/17352 (13%)] Loss: -187354.015625\n",
      "Train Epoch: 79 [2400/17352 (14%)] Loss: -184949.296875\n",
      "Train Epoch: 79 [2480/17352 (14%)] Loss: -210487.968750\n",
      "Train Epoch: 79 [2560/17352 (15%)] Loss: -214638.250000\n",
      "Train Epoch: 79 [2640/17352 (15%)] Loss: -185503.109375\n",
      "Train Epoch: 79 [2720/17352 (16%)] Loss: -192959.875000\n",
      "Train Epoch: 79 [2800/17352 (16%)] Loss: -204495.250000\n",
      "Train Epoch: 79 [2880/17352 (17%)] Loss: -180510.687500\n",
      "Train Epoch: 79 [2960/17352 (17%)] Loss: -205516.375000\n",
      "Train Epoch: 79 [3040/17352 (18%)] Loss: -169194.296875\n",
      "Train Epoch: 79 [3120/17352 (18%)] Loss: -159312.484375\n",
      "Train Epoch: 79 [3200/17352 (18%)] Loss: -186505.859375\n",
      "Train Epoch: 79 [3280/17352 (19%)] Loss: -181890.468750\n",
      "Train Epoch: 79 [3360/17352 (19%)] Loss: -213402.328125\n",
      "Train Epoch: 79 [3440/17352 (20%)] Loss: -192683.500000\n",
      "Train Epoch: 79 [3520/17352 (20%)] Loss: -196816.328125\n",
      "Train Epoch: 79 [3600/17352 (21%)] Loss: -209276.531250\n",
      "Train Epoch: 79 [3680/17352 (21%)] Loss: -201028.000000\n",
      "Train Epoch: 79 [3760/17352 (22%)] Loss: -183166.343750\n",
      "Train Epoch: 79 [3840/17352 (22%)] Loss: -195785.062500\n",
      "Train Epoch: 79 [3920/17352 (23%)] Loss: -170248.109375\n",
      "Train Epoch: 79 [4000/17352 (23%)] Loss: -192129.437500\n",
      "Train Epoch: 79 [4080/17352 (24%)] Loss: -168079.968750\n",
      "Train Epoch: 79 [4160/17352 (24%)] Loss: -178832.328125\n",
      "Train Epoch: 79 [4240/17352 (24%)] Loss: -170681.671875\n",
      "Train Epoch: 79 [4320/17352 (25%)] Loss: -187721.656250\n",
      "Train Epoch: 79 [4400/17352 (25%)] Loss: -208306.750000\n",
      "Train Epoch: 79 [4480/17352 (26%)] Loss: -163249.718750\n",
      "Train Epoch: 79 [4560/17352 (26%)] Loss: -185173.421875\n",
      "Train Epoch: 79 [4640/17352 (27%)] Loss: -202238.062500\n",
      "Train Epoch: 79 [4720/17352 (27%)] Loss: -178885.671875\n",
      "Train Epoch: 79 [4800/17352 (28%)] Loss: -164145.828125\n",
      "Train Epoch: 79 [4880/17352 (28%)] Loss: -175552.406250\n",
      "Train Epoch: 79 [4960/17352 (29%)] Loss: -205639.281250\n",
      "Train Epoch: 79 [5040/17352 (29%)] Loss: -200480.250000\n",
      "Train Epoch: 79 [5120/17352 (30%)] Loss: -178805.312500\n",
      "Train Epoch: 79 [5200/17352 (30%)] Loss: -174448.546875\n",
      "Train Epoch: 79 [5280/17352 (30%)] Loss: -201525.609375\n",
      "Train Epoch: 79 [5360/17352 (31%)] Loss: -149331.562500\n",
      "Train Epoch: 79 [5440/17352 (31%)] Loss: -177098.031250\n",
      "Train Epoch: 79 [5520/17352 (32%)] Loss: -196506.312500\n",
      "Train Epoch: 79 [5600/17352 (32%)] Loss: -197076.281250\n",
      "Train Epoch: 79 [5680/17352 (33%)] Loss: -193371.593750\n",
      "Train Epoch: 79 [5760/17352 (33%)] Loss: -177201.375000\n",
      "Train Epoch: 79 [5840/17352 (34%)] Loss: -193453.187500\n",
      "Train Epoch: 79 [5920/17352 (34%)] Loss: -180800.015625\n",
      "Train Epoch: 79 [6000/17352 (35%)] Loss: -189568.406250\n",
      "Train Epoch: 79 [6080/17352 (35%)] Loss: -181918.578125\n",
      "Train Epoch: 79 [6160/17352 (36%)] Loss: -193535.609375\n",
      "Train Epoch: 79 [6240/17352 (36%)] Loss: -185360.343750\n",
      "Train Epoch: 79 [6320/17352 (36%)] Loss: -177085.750000\n",
      "Train Epoch: 79 [6400/17352 (37%)] Loss: -197443.828125\n",
      "Train Epoch: 79 [6480/17352 (37%)] Loss: -192272.281250\n",
      "Train Epoch: 79 [6560/17352 (38%)] Loss: -195719.656250\n",
      "Train Epoch: 79 [6640/17352 (38%)] Loss: -188053.921875\n",
      "Train Epoch: 79 [6720/17352 (39%)] Loss: -159669.093750\n",
      "Train Epoch: 79 [6800/17352 (39%)] Loss: -148158.406250\n",
      "Train Epoch: 79 [6880/17352 (40%)] Loss: -148394.296875\n",
      "Train Epoch: 79 [6960/17352 (40%)] Loss: -177779.046875\n",
      "Train Epoch: 79 [7040/17352 (41%)] Loss: -195380.031250\n",
      "Train Epoch: 79 [7120/17352 (41%)] Loss: -151739.828125\n",
      "Train Epoch: 79 [7200/17352 (41%)] Loss: -180111.640625\n",
      "Train Epoch: 79 [7280/17352 (42%)] Loss: -202518.500000\n",
      "Train Epoch: 79 [7360/17352 (42%)] Loss: -188491.812500\n",
      "Train Epoch: 79 [7440/17352 (43%)] Loss: -204613.546875\n",
      "Train Epoch: 79 [7520/17352 (43%)] Loss: -211099.609375\n",
      "Train Epoch: 79 [7600/17352 (44%)] Loss: -203679.140625\n",
      "Train Epoch: 79 [7680/17352 (44%)] Loss: -202200.109375\n",
      "Train Epoch: 79 [7760/17352 (45%)] Loss: -144991.031250\n",
      "Train Epoch: 79 [7840/17352 (45%)] Loss: -193053.906250\n",
      "Train Epoch: 79 [7920/17352 (46%)] Loss: -192373.578125\n",
      "Train Epoch: 79 [8000/17352 (46%)] Loss: -196040.359375\n",
      "Train Epoch: 79 [8080/17352 (47%)] Loss: -176276.921875\n",
      "Train Epoch: 79 [8160/17352 (47%)] Loss: -198703.546875\n",
      "Train Epoch: 79 [8240/17352 (47%)] Loss: -191234.796875\n",
      "Train Epoch: 79 [8320/17352 (48%)] Loss: -188675.906250\n",
      "Train Epoch: 79 [8400/17352 (48%)] Loss: -188966.968750\n",
      "Train Epoch: 79 [8480/17352 (49%)] Loss: -136432.859375\n",
      "Train Epoch: 79 [8560/17352 (49%)] Loss: -183508.687500\n",
      "Train Epoch: 79 [8640/17352 (50%)] Loss: -204689.875000\n",
      "Train Epoch: 79 [8720/17352 (50%)] Loss: -163756.328125\n",
      "Train Epoch: 79 [8800/17352 (51%)] Loss: -189734.718750\n",
      "Train Epoch: 79 [8880/17352 (51%)] Loss: -193199.984375\n",
      "Train Epoch: 79 [8960/17352 (52%)] Loss: -186944.187500\n",
      "Train Epoch: 79 [9040/17352 (52%)] Loss: -195061.484375\n",
      "Train Epoch: 79 [9120/17352 (53%)] Loss: -176536.578125\n",
      "Train Epoch: 79 [9200/17352 (53%)] Loss: -206242.437500\n",
      "Train Epoch: 79 [9280/17352 (53%)] Loss: -201096.718750\n",
      "Train Epoch: 79 [9360/17352 (54%)] Loss: -179440.406250\n",
      "Train Epoch: 79 [9440/17352 (54%)] Loss: -188092.000000\n",
      "Train Epoch: 79 [9520/17352 (55%)] Loss: -221256.484375\n",
      "Train Epoch: 79 [9600/17352 (55%)] Loss: -199788.000000\n",
      "Train Epoch: 79 [9680/17352 (56%)] Loss: -182328.734375\n",
      "Train Epoch: 79 [9760/17352 (56%)] Loss: -202178.390625\n",
      "Train Epoch: 79 [9840/17352 (57%)] Loss: -186845.734375\n",
      "Train Epoch: 79 [9920/17352 (57%)] Loss: -183391.484375\n",
      "Train Epoch: 79 [10000/17352 (58%)] Loss: -202942.781250\n",
      "Train Epoch: 79 [10080/17352 (58%)] Loss: -192987.656250\n",
      "Train Epoch: 79 [10160/17352 (59%)] Loss: -183785.578125\n",
      "Train Epoch: 79 [10240/17352 (59%)] Loss: -210160.062500\n",
      "Train Epoch: 79 [10320/17352 (59%)] Loss: -193262.687500\n",
      "Train Epoch: 79 [10400/17352 (60%)] Loss: -196283.750000\n",
      "Train Epoch: 79 [10480/17352 (60%)] Loss: -200401.796875\n",
      "Train Epoch: 79 [10560/17352 (61%)] Loss: -175417.921875\n",
      "Train Epoch: 79 [10640/17352 (61%)] Loss: -193051.171875\n",
      "Train Epoch: 79 [10720/17352 (62%)] Loss: -164747.968750\n",
      "Train Epoch: 79 [10800/17352 (62%)] Loss: -180910.890625\n",
      "Train Epoch: 79 [10880/17352 (63%)] Loss: -188437.140625\n",
      "Train Epoch: 79 [10960/17352 (63%)] Loss: -182531.687500\n",
      "Train Epoch: 79 [11040/17352 (64%)] Loss: -203268.875000\n",
      "Train Epoch: 79 [11120/17352 (64%)] Loss: -195881.296875\n",
      "Train Epoch: 79 [11200/17352 (65%)] Loss: -165796.296875\n",
      "Train Epoch: 79 [11280/17352 (65%)] Loss: -190229.640625\n",
      "Train Epoch: 79 [11360/17352 (65%)] Loss: -220977.968750\n",
      "Train Epoch: 79 [11440/17352 (66%)] Loss: -215183.109375\n",
      "Train Epoch: 79 [11520/17352 (66%)] Loss: -180748.640625\n",
      "Train Epoch: 79 [11600/17352 (67%)] Loss: -181015.437500\n",
      "Train Epoch: 79 [11680/17352 (67%)] Loss: -178596.218750\n",
      "Train Epoch: 79 [11760/17352 (68%)] Loss: -183408.796875\n",
      "Train Epoch: 79 [11840/17352 (68%)] Loss: -177597.921875\n",
      "Train Epoch: 79 [11920/17352 (69%)] Loss: -180995.843750\n",
      "Train Epoch: 79 [12000/17352 (69%)] Loss: -223688.000000\n",
      "Train Epoch: 79 [12080/17352 (70%)] Loss: -205806.171875\n",
      "Train Epoch: 79 [12160/17352 (70%)] Loss: -188562.343750\n",
      "Train Epoch: 79 [12240/17352 (71%)] Loss: -153322.921875\n",
      "Train Epoch: 79 [12320/17352 (71%)] Loss: -193348.078125\n",
      "Train Epoch: 79 [12400/17352 (71%)] Loss: -207094.000000\n",
      "Train Epoch: 79 [12480/17352 (72%)] Loss: -184485.921875\n",
      "Train Epoch: 79 [12560/17352 (72%)] Loss: -190944.125000\n",
      "Train Epoch: 79 [12640/17352 (73%)] Loss: -176900.531250\n",
      "Train Epoch: 79 [12720/17352 (73%)] Loss: -206224.265625\n",
      "Train Epoch: 79 [12800/17352 (74%)] Loss: -162721.312500\n",
      "Train Epoch: 79 [12880/17352 (74%)] Loss: -193358.046875\n",
      "Train Epoch: 79 [12960/17352 (75%)] Loss: -201970.890625\n",
      "Train Epoch: 79 [13040/17352 (75%)] Loss: -209592.828125\n",
      "Train Epoch: 79 [13120/17352 (76%)] Loss: -151509.093750\n",
      "Train Epoch: 79 [13200/17352 (76%)] Loss: -188902.140625\n",
      "Train Epoch: 79 [13280/17352 (77%)] Loss: -171424.609375\n",
      "Train Epoch: 79 [13360/17352 (77%)] Loss: -158606.109375\n",
      "Train Epoch: 79 [13440/17352 (77%)] Loss: -191568.718750\n",
      "Train Epoch: 79 [13520/17352 (78%)] Loss: -169972.015625\n",
      "Train Epoch: 79 [13600/17352 (78%)] Loss: -180693.078125\n",
      "Train Epoch: 79 [13680/17352 (79%)] Loss: -164877.296875\n",
      "Train Epoch: 79 [13760/17352 (79%)] Loss: -179451.531250\n",
      "Train Epoch: 79 [13840/17352 (80%)] Loss: -209201.468750\n",
      "Train Epoch: 79 [13920/17352 (80%)] Loss: -177251.437500\n",
      "Train Epoch: 79 [14000/17352 (81%)] Loss: -180291.015625\n",
      "Train Epoch: 79 [14080/17352 (81%)] Loss: -162559.812500\n",
      "Train Epoch: 79 [14160/17352 (82%)] Loss: -187529.312500\n",
      "Train Epoch: 79 [14240/17352 (82%)] Loss: -217625.453125\n",
      "Train Epoch: 79 [14320/17352 (83%)] Loss: -180970.125000\n",
      "Train Epoch: 79 [14400/17352 (83%)] Loss: -168767.359375\n",
      "Train Epoch: 79 [14480/17352 (83%)] Loss: -208040.859375\n",
      "Train Epoch: 79 [14560/17352 (84%)] Loss: -209414.109375\n",
      "Train Epoch: 79 [14640/17352 (84%)] Loss: -198008.015625\n",
      "Train Epoch: 79 [14720/17352 (85%)] Loss: -200331.250000\n",
      "Train Epoch: 79 [14800/17352 (85%)] Loss: -187622.906250\n",
      "Train Epoch: 79 [14880/17352 (86%)] Loss: -178571.453125\n",
      "Train Epoch: 79 [14960/17352 (86%)] Loss: -185828.984375\n",
      "Train Epoch: 79 [15040/17352 (87%)] Loss: -163347.578125\n",
      "Train Epoch: 79 [15120/17352 (87%)] Loss: -174548.296875\n",
      "Train Epoch: 79 [15200/17352 (88%)] Loss: -179172.812500\n",
      "Train Epoch: 79 [15280/17352 (88%)] Loss: -215639.171875\n",
      "Train Epoch: 79 [15360/17352 (89%)] Loss: -175013.375000\n",
      "Train Epoch: 79 [15440/17352 (89%)] Loss: -192016.046875\n",
      "Train Epoch: 79 [15520/17352 (89%)] Loss: -179894.546875\n",
      "Train Epoch: 79 [15600/17352 (90%)] Loss: -179311.031250\n",
      "Train Epoch: 79 [15680/17352 (90%)] Loss: -196130.718750\n",
      "Train Epoch: 79 [15760/17352 (91%)] Loss: -205169.437500\n",
      "Train Epoch: 79 [15840/17352 (91%)] Loss: -192795.093750\n",
      "Train Epoch: 79 [15920/17352 (92%)] Loss: -175362.468750\n",
      "Train Epoch: 79 [16000/17352 (92%)] Loss: -178209.812500\n",
      "Train Epoch: 79 [16080/17352 (93%)] Loss: -200302.562500\n",
      "Train Epoch: 79 [16160/17352 (93%)] Loss: -190912.671875\n",
      "Train Epoch: 79 [16240/17352 (94%)] Loss: -201112.843750\n",
      "Train Epoch: 79 [16320/17352 (94%)] Loss: -169010.593750\n",
      "Train Epoch: 79 [16400/17352 (95%)] Loss: -201392.312500\n",
      "Train Epoch: 79 [16480/17352 (95%)] Loss: -164506.578125\n",
      "Train Epoch: 79 [16560/17352 (95%)] Loss: -201952.375000\n",
      "Train Epoch: 79 [16640/17352 (96%)] Loss: -194226.296875\n",
      "Train Epoch: 79 [16720/17352 (96%)] Loss: -175072.406250\n",
      "Train Epoch: 79 [16800/17352 (97%)] Loss: -182399.343750\n",
      "Train Epoch: 79 [16880/17352 (97%)] Loss: -171733.093750\n",
      "Train Epoch: 79 [16960/17352 (98%)] Loss: -185055.703125\n",
      "Train Epoch: 79 [17040/17352 (98%)] Loss: -175315.046875\n",
      "Train Epoch: 79 [17120/17352 (99%)] Loss: -200615.843750\n",
      "Train Epoch: 79 [17200/17352 (99%)] Loss: -231041.156250\n",
      "Train Epoch: 79 [17280/17352 (100%)] Loss: -180541.859375\n",
      "Train Epoch: 79 [17360/17352 (100%)] Loss: -214960.000000\n",
      "    epoch          : 79\n",
      "    loss           : -189287.65454185847\n",
      "    val_loss       : -23716.19309238201\n",
      "Train Epoch: 80 [0/17352 (0%)] Loss: -214420.171875\n",
      "Train Epoch: 80 [80/17352 (0%)] Loss: -207161.312500\n",
      "Train Epoch: 80 [160/17352 (1%)] Loss: -215834.078125\n",
      "Train Epoch: 80 [240/17352 (1%)] Loss: -214708.968750\n",
      "Train Epoch: 80 [320/17352 (2%)] Loss: -215488.390625\n",
      "Train Epoch: 80 [400/17352 (2%)] Loss: -208385.015625\n",
      "Train Epoch: 80 [480/17352 (3%)] Loss: -210635.281250\n",
      "Train Epoch: 80 [560/17352 (3%)] Loss: -219257.656250\n",
      "Train Epoch: 80 [640/17352 (4%)] Loss: -221474.921875\n",
      "Train Epoch: 80 [720/17352 (4%)] Loss: -208539.203125\n",
      "Train Epoch: 80 [800/17352 (5%)] Loss: -210208.437500\n",
      "Train Epoch: 80 [880/17352 (5%)] Loss: -206785.031250\n",
      "Train Epoch: 80 [960/17352 (6%)] Loss: -217629.406250\n",
      "Train Epoch: 80 [1040/17352 (6%)] Loss: -213322.890625\n",
      "Train Epoch: 80 [1120/17352 (6%)] Loss: -217936.000000\n",
      "Train Epoch: 80 [1200/17352 (7%)] Loss: -219668.921875\n",
      "Train Epoch: 80 [1280/17352 (7%)] Loss: -235590.937500\n",
      "Train Epoch: 80 [1360/17352 (8%)] Loss: -194295.875000\n",
      "Train Epoch: 80 [1440/17352 (8%)] Loss: -229957.125000\n",
      "Train Epoch: 80 [1520/17352 (9%)] Loss: -185283.078125\n",
      "Train Epoch: 80 [1600/17352 (9%)] Loss: -209775.062500\n",
      "Train Epoch: 80 [1680/17352 (10%)] Loss: -216103.531250\n",
      "Train Epoch: 80 [1760/17352 (10%)] Loss: -213340.500000\n",
      "Train Epoch: 80 [1840/17352 (11%)] Loss: -212395.437500\n",
      "Train Epoch: 80 [1920/17352 (11%)] Loss: -196444.203125\n",
      "Train Epoch: 80 [2000/17352 (12%)] Loss: -215102.343750\n",
      "Train Epoch: 80 [2080/17352 (12%)] Loss: -193577.531250\n",
      "Train Epoch: 80 [2160/17352 (12%)] Loss: -194495.562500\n",
      "Train Epoch: 80 [2240/17352 (13%)] Loss: -182740.968750\n",
      "Train Epoch: 80 [2320/17352 (13%)] Loss: -205212.781250\n",
      "Train Epoch: 80 [2400/17352 (14%)] Loss: -170352.734375\n",
      "Train Epoch: 80 [2480/17352 (14%)] Loss: -190479.921875\n",
      "Train Epoch: 80 [2560/17352 (15%)] Loss: -184030.937500\n",
      "Train Epoch: 80 [2640/17352 (15%)] Loss: -188566.250000\n",
      "Train Epoch: 80 [2720/17352 (16%)] Loss: -168076.875000\n",
      "Train Epoch: 80 [2800/17352 (16%)] Loss: -193493.390625\n",
      "Train Epoch: 80 [2880/17352 (17%)] Loss: -180698.250000\n",
      "Train Epoch: 80 [2960/17352 (17%)] Loss: -174509.453125\n",
      "Train Epoch: 80 [3040/17352 (18%)] Loss: -197594.625000\n",
      "Train Epoch: 80 [3120/17352 (18%)] Loss: -189795.203125\n",
      "Train Epoch: 80 [3200/17352 (18%)] Loss: -204606.593750\n",
      "Train Epoch: 80 [3280/17352 (19%)] Loss: -197087.843750\n",
      "Train Epoch: 80 [3360/17352 (19%)] Loss: -193801.859375\n",
      "Train Epoch: 80 [3440/17352 (20%)] Loss: -202194.187500\n",
      "Train Epoch: 80 [3520/17352 (20%)] Loss: -170786.312500\n",
      "Train Epoch: 80 [3600/17352 (21%)] Loss: -203845.437500\n",
      "Train Epoch: 80 [3680/17352 (21%)] Loss: -178212.171875\n",
      "Train Epoch: 80 [3760/17352 (22%)] Loss: -193127.687500\n",
      "Train Epoch: 80 [3840/17352 (22%)] Loss: -176591.000000\n",
      "Train Epoch: 80 [3920/17352 (23%)] Loss: -175363.296875\n",
      "Train Epoch: 80 [4000/17352 (23%)] Loss: -193047.000000\n",
      "Train Epoch: 80 [4080/17352 (24%)] Loss: -202235.140625\n",
      "Train Epoch: 80 [4160/17352 (24%)] Loss: -212132.500000\n",
      "Train Epoch: 80 [4240/17352 (24%)] Loss: -167728.640625\n",
      "Train Epoch: 80 [4320/17352 (25%)] Loss: -228150.453125\n",
      "Train Epoch: 80 [4400/17352 (25%)] Loss: -206602.375000\n",
      "Train Epoch: 80 [4480/17352 (26%)] Loss: -192171.656250\n",
      "Train Epoch: 80 [4560/17352 (26%)] Loss: -196035.062500\n",
      "Train Epoch: 80 [4640/17352 (27%)] Loss: -188748.828125\n",
      "Train Epoch: 80 [4720/17352 (27%)] Loss: -169442.312500\n",
      "Train Epoch: 80 [4800/17352 (28%)] Loss: -180512.687500\n",
      "Train Epoch: 80 [4880/17352 (28%)] Loss: -185267.843750\n",
      "Train Epoch: 80 [4960/17352 (29%)] Loss: -156607.265625\n",
      "Train Epoch: 80 [5040/17352 (29%)] Loss: -203146.625000\n",
      "Train Epoch: 80 [5120/17352 (30%)] Loss: -212980.875000\n",
      "Train Epoch: 80 [5200/17352 (30%)] Loss: -202513.656250\n",
      "Train Epoch: 80 [5280/17352 (30%)] Loss: -167192.203125\n",
      "Train Epoch: 80 [5360/17352 (31%)] Loss: -202996.062500\n",
      "Train Epoch: 80 [5440/17352 (31%)] Loss: -207129.765625\n",
      "Train Epoch: 80 [5520/17352 (32%)] Loss: -168764.906250\n",
      "Train Epoch: 80 [5600/17352 (32%)] Loss: -182743.343750\n",
      "Train Epoch: 80 [5680/17352 (33%)] Loss: -208036.531250\n",
      "Train Epoch: 80 [5760/17352 (33%)] Loss: -185059.453125\n",
      "Train Epoch: 80 [5840/17352 (34%)] Loss: -204209.078125\n",
      "Train Epoch: 80 [5920/17352 (34%)] Loss: -186433.515625\n",
      "Train Epoch: 80 [6000/17352 (35%)] Loss: -209203.453125\n",
      "Train Epoch: 80 [6080/17352 (35%)] Loss: -185321.234375\n",
      "Train Epoch: 80 [6160/17352 (36%)] Loss: -214642.859375\n",
      "Train Epoch: 80 [6240/17352 (36%)] Loss: -183921.609375\n",
      "Train Epoch: 80 [6320/17352 (36%)] Loss: -182778.687500\n",
      "Train Epoch: 80 [6400/17352 (37%)] Loss: -206092.203125\n",
      "Train Epoch: 80 [6480/17352 (37%)] Loss: -181071.125000\n",
      "Train Epoch: 80 [6560/17352 (38%)] Loss: -185000.937500\n",
      "Train Epoch: 80 [6640/17352 (38%)] Loss: -156469.515625\n",
      "Train Epoch: 80 [6720/17352 (39%)] Loss: -173509.656250\n",
      "Train Epoch: 80 [6800/17352 (39%)] Loss: -212661.218750\n",
      "Train Epoch: 80 [6880/17352 (40%)] Loss: -196399.015625\n",
      "Train Epoch: 80 [6960/17352 (40%)] Loss: -179385.812500\n",
      "Train Epoch: 80 [7040/17352 (41%)] Loss: -202174.843750\n",
      "Train Epoch: 80 [7120/17352 (41%)] Loss: -220972.984375\n",
      "Train Epoch: 80 [7200/17352 (41%)] Loss: -192953.250000\n",
      "Train Epoch: 80 [7280/17352 (42%)] Loss: -193372.984375\n",
      "Train Epoch: 80 [7360/17352 (42%)] Loss: -183080.890625\n",
      "Train Epoch: 80 [7440/17352 (43%)] Loss: -181014.328125\n",
      "Train Epoch: 80 [7520/17352 (43%)] Loss: -176700.546875\n",
      "Train Epoch: 80 [7600/17352 (44%)] Loss: -183058.453125\n",
      "Train Epoch: 80 [7680/17352 (44%)] Loss: -164147.531250\n",
      "Train Epoch: 80 [7760/17352 (45%)] Loss: -172960.046875\n",
      "Train Epoch: 80 [7840/17352 (45%)] Loss: -204328.359375\n",
      "Train Epoch: 80 [7920/17352 (46%)] Loss: -180256.343750\n",
      "Train Epoch: 80 [8000/17352 (46%)] Loss: -159753.953125\n",
      "Train Epoch: 80 [8080/17352 (47%)] Loss: -176700.640625\n",
      "Train Epoch: 80 [8160/17352 (47%)] Loss: -205727.203125\n",
      "Train Epoch: 80 [8240/17352 (47%)] Loss: -192121.234375\n",
      "Train Epoch: 80 [8320/17352 (48%)] Loss: -199721.531250\n",
      "Train Epoch: 80 [8400/17352 (48%)] Loss: -173000.953125\n",
      "Train Epoch: 80 [8480/17352 (49%)] Loss: -199780.781250\n",
      "Train Epoch: 80 [8560/17352 (49%)] Loss: -178633.390625\n",
      "Train Epoch: 80 [8640/17352 (50%)] Loss: -195516.437500\n",
      "Train Epoch: 80 [8720/17352 (50%)] Loss: -176039.640625\n",
      "Train Epoch: 80 [8800/17352 (51%)] Loss: -184259.531250\n",
      "Train Epoch: 80 [8880/17352 (51%)] Loss: -176488.468750\n",
      "Train Epoch: 80 [8960/17352 (52%)] Loss: -191593.062500\n",
      "Train Epoch: 80 [9040/17352 (52%)] Loss: -207860.000000\n",
      "Train Epoch: 80 [9120/17352 (53%)] Loss: -171588.265625\n",
      "Train Epoch: 80 [9200/17352 (53%)] Loss: -177463.859375\n",
      "Train Epoch: 80 [9280/17352 (53%)] Loss: -185927.125000\n",
      "Train Epoch: 80 [9360/17352 (54%)] Loss: -217605.718750\n",
      "Train Epoch: 80 [9440/17352 (54%)] Loss: -201960.437500\n",
      "Train Epoch: 80 [9520/17352 (55%)] Loss: -211633.718750\n",
      "Train Epoch: 80 [9600/17352 (55%)] Loss: -165362.328125\n",
      "Train Epoch: 80 [9680/17352 (56%)] Loss: -165863.812500\n",
      "Train Epoch: 80 [9760/17352 (56%)] Loss: -173307.312500\n",
      "Train Epoch: 80 [9840/17352 (57%)] Loss: -169500.640625\n",
      "Train Epoch: 80 [9920/17352 (57%)] Loss: -174482.578125\n",
      "Train Epoch: 80 [10000/17352 (58%)] Loss: -180052.218750\n",
      "Train Epoch: 80 [10080/17352 (58%)] Loss: -183263.890625\n",
      "Train Epoch: 80 [10160/17352 (59%)] Loss: -202477.671875\n",
      "Train Epoch: 80 [10240/17352 (59%)] Loss: -202856.968750\n",
      "Train Epoch: 80 [10320/17352 (59%)] Loss: -193193.843750\n",
      "Train Epoch: 80 [10400/17352 (60%)] Loss: -185371.453125\n",
      "Train Epoch: 80 [10480/17352 (60%)] Loss: -186680.359375\n",
      "Train Epoch: 80 [10560/17352 (61%)] Loss: -199454.406250\n",
      "Train Epoch: 80 [10640/17352 (61%)] Loss: -188186.875000\n",
      "Train Epoch: 80 [10720/17352 (62%)] Loss: -188898.859375\n",
      "Train Epoch: 80 [10800/17352 (62%)] Loss: -231039.609375\n",
      "Train Epoch: 80 [10880/17352 (63%)] Loss: -177305.296875\n",
      "Train Epoch: 80 [10960/17352 (63%)] Loss: -176540.828125\n",
      "Train Epoch: 80 [11040/17352 (64%)] Loss: -203461.437500\n",
      "Train Epoch: 80 [11120/17352 (64%)] Loss: -159675.062500\n",
      "Train Epoch: 80 [11200/17352 (65%)] Loss: -159097.062500\n",
      "Train Epoch: 80 [11280/17352 (65%)] Loss: -166002.171875\n",
      "Train Epoch: 80 [11360/17352 (65%)] Loss: -217619.843750\n",
      "Train Epoch: 80 [11440/17352 (66%)] Loss: -200635.562500\n",
      "Train Epoch: 80 [11520/17352 (66%)] Loss: -206156.234375\n",
      "Train Epoch: 80 [11600/17352 (67%)] Loss: -178884.656250\n",
      "Train Epoch: 80 [11680/17352 (67%)] Loss: -195887.250000\n",
      "Train Epoch: 80 [11760/17352 (68%)] Loss: -225325.265625\n",
      "Train Epoch: 80 [11840/17352 (68%)] Loss: -174546.578125\n",
      "Train Epoch: 80 [11920/17352 (69%)] Loss: -185798.171875\n",
      "Train Epoch: 80 [12000/17352 (69%)] Loss: -215182.812500\n",
      "Train Epoch: 80 [12080/17352 (70%)] Loss: -200863.625000\n",
      "Train Epoch: 80 [12160/17352 (70%)] Loss: -192268.890625\n",
      "Train Epoch: 80 [12240/17352 (71%)] Loss: -192883.359375\n",
      "Train Epoch: 80 [12320/17352 (71%)] Loss: -189222.625000\n",
      "Train Epoch: 80 [12400/17352 (71%)] Loss: -181890.265625\n",
      "Train Epoch: 80 [12480/17352 (72%)] Loss: -173587.968750\n",
      "Train Epoch: 80 [12560/17352 (72%)] Loss: -171732.796875\n",
      "Train Epoch: 80 [12640/17352 (73%)] Loss: -142336.875000\n",
      "Train Epoch: 80 [12720/17352 (73%)] Loss: -182329.625000\n",
      "Train Epoch: 80 [12800/17352 (74%)] Loss: -168676.328125\n",
      "Train Epoch: 80 [12880/17352 (74%)] Loss: -187220.281250\n",
      "Train Epoch: 80 [12960/17352 (75%)] Loss: -187314.250000\n",
      "Train Epoch: 80 [13040/17352 (75%)] Loss: -173039.015625\n",
      "Train Epoch: 80 [13120/17352 (76%)] Loss: -179318.656250\n",
      "Train Epoch: 80 [13200/17352 (76%)] Loss: -197953.218750\n",
      "Train Epoch: 80 [13280/17352 (77%)] Loss: -197573.093750\n",
      "Train Epoch: 80 [13360/17352 (77%)] Loss: -187621.531250\n",
      "Train Epoch: 80 [13440/17352 (77%)] Loss: -157777.390625\n",
      "Train Epoch: 80 [13520/17352 (78%)] Loss: -166666.875000\n",
      "Train Epoch: 80 [13600/17352 (78%)] Loss: -181615.531250\n",
      "Train Epoch: 80 [13680/17352 (79%)] Loss: -185237.687500\n",
      "Train Epoch: 80 [13760/17352 (79%)] Loss: -179976.453125\n",
      "Train Epoch: 80 [13840/17352 (80%)] Loss: -164991.390625\n",
      "Train Epoch: 80 [13920/17352 (80%)] Loss: -187647.671875\n",
      "Train Epoch: 80 [14000/17352 (81%)] Loss: -136427.343750\n",
      "Train Epoch: 80 [14080/17352 (81%)] Loss: -193054.859375\n",
      "Train Epoch: 80 [14160/17352 (82%)] Loss: -202087.687500\n",
      "Train Epoch: 80 [14240/17352 (82%)] Loss: -205406.218750\n",
      "Train Epoch: 80 [14320/17352 (83%)] Loss: -200616.781250\n",
      "Train Epoch: 80 [14400/17352 (83%)] Loss: -176974.062500\n",
      "Train Epoch: 80 [14480/17352 (83%)] Loss: -191335.437500\n",
      "Train Epoch: 80 [14560/17352 (84%)] Loss: -171320.500000\n",
      "Train Epoch: 80 [14640/17352 (84%)] Loss: -198830.312500\n",
      "Train Epoch: 80 [14720/17352 (85%)] Loss: -200485.234375\n",
      "Train Epoch: 80 [14800/17352 (85%)] Loss: -192375.531250\n",
      "Train Epoch: 80 [14880/17352 (86%)] Loss: -191556.734375\n",
      "Train Epoch: 80 [14960/17352 (86%)] Loss: -186503.890625\n",
      "Train Epoch: 80 [15040/17352 (87%)] Loss: -177780.328125\n",
      "Train Epoch: 80 [15120/17352 (87%)] Loss: -204414.765625\n",
      "Train Epoch: 80 [15200/17352 (88%)] Loss: -169953.187500\n",
      "Train Epoch: 80 [15280/17352 (88%)] Loss: -228252.062500\n",
      "Train Epoch: 80 [15360/17352 (89%)] Loss: -199178.125000\n",
      "Train Epoch: 80 [15440/17352 (89%)] Loss: -148447.296875\n",
      "Train Epoch: 80 [15520/17352 (89%)] Loss: -201371.468750\n",
      "Train Epoch: 80 [15600/17352 (90%)] Loss: -192288.703125\n",
      "Train Epoch: 80 [15680/17352 (90%)] Loss: -187357.687500\n",
      "Train Epoch: 80 [15760/17352 (91%)] Loss: -181759.218750\n",
      "Train Epoch: 80 [15840/17352 (91%)] Loss: -195003.921875\n",
      "Train Epoch: 80 [15920/17352 (92%)] Loss: -218409.718750\n",
      "Train Epoch: 80 [16000/17352 (92%)] Loss: -185331.890625\n",
      "Train Epoch: 80 [16080/17352 (93%)] Loss: -183503.859375\n",
      "Train Epoch: 80 [16160/17352 (93%)] Loss: -154608.078125\n",
      "Train Epoch: 80 [16240/17352 (94%)] Loss: -223960.234375\n",
      "Train Epoch: 80 [16320/17352 (94%)] Loss: -197536.812500\n",
      "Train Epoch: 80 [16400/17352 (95%)] Loss: -172183.531250\n",
      "Train Epoch: 80 [16480/17352 (95%)] Loss: -211165.546875\n",
      "Train Epoch: 80 [16560/17352 (95%)] Loss: -182563.906250\n",
      "Train Epoch: 80 [16640/17352 (96%)] Loss: -192284.218750\n",
      "Train Epoch: 80 [16720/17352 (96%)] Loss: -181342.953125\n",
      "Train Epoch: 80 [16800/17352 (97%)] Loss: -185597.187500\n",
      "Train Epoch: 80 [16880/17352 (97%)] Loss: -179006.828125\n",
      "Train Epoch: 80 [16960/17352 (98%)] Loss: -193184.937500\n",
      "Train Epoch: 80 [17040/17352 (98%)] Loss: -169195.906250\n",
      "Train Epoch: 80 [17120/17352 (99%)] Loss: -163095.031250\n",
      "Train Epoch: 80 [17200/17352 (99%)] Loss: -158749.265625\n",
      "Train Epoch: 80 [17280/17352 (100%)] Loss: -185546.078125\n",
      "Train Epoch: 80 [17360/17352 (100%)] Loss: -173838.921875\n",
      "    epoch          : 80\n",
      "    loss           : -189379.26153445052\n",
      "    val_loss       : -23716.289284289724\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch80.pth ...\n",
      "Train Epoch: 81 [0/17352 (0%)] Loss: -212181.921875\n",
      "Train Epoch: 81 [80/17352 (0%)] Loss: -219203.906250\n",
      "Train Epoch: 81 [160/17352 (1%)] Loss: -205923.656250\n",
      "Train Epoch: 81 [240/17352 (1%)] Loss: -198767.062500\n",
      "Train Epoch: 81 [320/17352 (2%)] Loss: -205087.578125\n",
      "Train Epoch: 81 [400/17352 (2%)] Loss: -202265.750000\n",
      "Train Epoch: 81 [480/17352 (3%)] Loss: -194492.718750\n",
      "Train Epoch: 81 [560/17352 (3%)] Loss: -202328.234375\n",
      "Train Epoch: 81 [640/17352 (4%)] Loss: -214719.390625\n",
      "Train Epoch: 81 [720/17352 (4%)] Loss: -188755.156250\n",
      "Train Epoch: 81 [800/17352 (5%)] Loss: -202231.500000\n",
      "Train Epoch: 81 [880/17352 (5%)] Loss: -214459.750000\n",
      "Train Epoch: 81 [960/17352 (6%)] Loss: -202038.140625\n",
      "Train Epoch: 81 [1040/17352 (6%)] Loss: -210629.531250\n",
      "Train Epoch: 81 [1120/17352 (6%)] Loss: -228020.328125\n",
      "Train Epoch: 81 [1200/17352 (7%)] Loss: -206787.015625\n",
      "Train Epoch: 81 [1280/17352 (7%)] Loss: -236508.671875\n",
      "Train Epoch: 81 [1360/17352 (8%)] Loss: -241902.265625\n",
      "Train Epoch: 81 [1440/17352 (8%)] Loss: -204403.828125\n",
      "Train Epoch: 81 [1520/17352 (9%)] Loss: -205556.421875\n",
      "Train Epoch: 81 [1600/17352 (9%)] Loss: -211899.109375\n",
      "Train Epoch: 81 [1680/17352 (10%)] Loss: -204035.578125\n",
      "Train Epoch: 81 [1760/17352 (10%)] Loss: -229232.484375\n",
      "Train Epoch: 81 [1840/17352 (11%)] Loss: -204537.453125\n",
      "Train Epoch: 81 [1920/17352 (11%)] Loss: -214521.687500\n",
      "Train Epoch: 81 [2000/17352 (12%)] Loss: -185153.203125\n",
      "Train Epoch: 81 [2080/17352 (12%)] Loss: -191873.531250\n",
      "Train Epoch: 81 [2160/17352 (12%)] Loss: -205194.359375\n",
      "Train Epoch: 81 [2240/17352 (13%)] Loss: -204341.796875\n",
      "Train Epoch: 81 [2320/17352 (13%)] Loss: -95258.765625\n",
      "Train Epoch: 81 [2400/17352 (14%)] Loss: -167243.468750\n",
      "Train Epoch: 81 [2480/17352 (14%)] Loss: -228154.000000\n",
      "Train Epoch: 81 [2560/17352 (15%)] Loss: -188156.718750\n",
      "Train Epoch: 81 [2640/17352 (15%)] Loss: -166003.312500\n",
      "Train Epoch: 81 [2720/17352 (16%)] Loss: -174516.015625\n",
      "Train Epoch: 81 [2800/17352 (16%)] Loss: -202939.750000\n",
      "Train Epoch: 81 [2880/17352 (17%)] Loss: -192679.218750\n",
      "Train Epoch: 81 [2960/17352 (17%)] Loss: -194071.265625\n",
      "Train Epoch: 81 [3040/17352 (18%)] Loss: -173925.781250\n",
      "Train Epoch: 81 [3120/17352 (18%)] Loss: -176042.046875\n",
      "Train Epoch: 81 [3200/17352 (18%)] Loss: -180150.796875\n",
      "Train Epoch: 81 [3280/17352 (19%)] Loss: -175413.578125\n",
      "Train Epoch: 81 [3360/17352 (19%)] Loss: -177979.703125\n",
      "Train Epoch: 81 [3440/17352 (20%)] Loss: -174948.625000\n",
      "Train Epoch: 81 [3520/17352 (20%)] Loss: -186428.140625\n",
      "Train Epoch: 81 [3600/17352 (21%)] Loss: -166459.187500\n",
      "Train Epoch: 81 [3680/17352 (21%)] Loss: -170350.890625\n",
      "Train Epoch: 81 [3760/17352 (22%)] Loss: -215644.203125\n",
      "Train Epoch: 81 [3840/17352 (22%)] Loss: -210159.609375\n",
      "Train Epoch: 81 [3920/17352 (23%)] Loss: -197343.312500\n",
      "Train Epoch: 81 [4000/17352 (23%)] Loss: -225472.031250\n",
      "Train Epoch: 81 [4080/17352 (24%)] Loss: -190225.187500\n",
      "Train Epoch: 81 [4160/17352 (24%)] Loss: -167486.906250\n",
      "Train Epoch: 81 [4240/17352 (24%)] Loss: -165733.609375\n",
      "Train Epoch: 81 [4320/17352 (25%)] Loss: -175319.312500\n",
      "Train Epoch: 81 [4400/17352 (25%)] Loss: -191048.406250\n",
      "Train Epoch: 81 [4480/17352 (26%)] Loss: -176154.218750\n",
      "Train Epoch: 81 [4560/17352 (26%)] Loss: -192010.640625\n",
      "Train Epoch: 81 [4640/17352 (27%)] Loss: -182101.437500\n",
      "Train Epoch: 81 [4720/17352 (27%)] Loss: -214640.765625\n",
      "Train Epoch: 81 [4800/17352 (28%)] Loss: -203893.093750\n",
      "Train Epoch: 81 [4880/17352 (28%)] Loss: -205495.531250\n",
      "Train Epoch: 81 [4960/17352 (29%)] Loss: -183467.468750\n",
      "Train Epoch: 81 [5040/17352 (29%)] Loss: -178874.203125\n",
      "Train Epoch: 81 [5120/17352 (30%)] Loss: -200864.578125\n",
      "Train Epoch: 81 [5200/17352 (30%)] Loss: -208906.187500\n",
      "Train Epoch: 81 [5280/17352 (30%)] Loss: -207789.203125\n",
      "Train Epoch: 81 [5360/17352 (31%)] Loss: -205693.390625\n",
      "Train Epoch: 81 [5440/17352 (31%)] Loss: -188569.843750\n",
      "Train Epoch: 81 [5520/17352 (32%)] Loss: -200633.984375\n",
      "Train Epoch: 81 [5600/17352 (32%)] Loss: -176902.921875\n",
      "Train Epoch: 81 [5680/17352 (33%)] Loss: -187524.500000\n",
      "Train Epoch: 81 [5760/17352 (33%)] Loss: -183058.406250\n",
      "Train Epoch: 81 [5840/17352 (34%)] Loss: -181890.218750\n",
      "Train Epoch: 81 [5920/17352 (34%)] Loss: -178830.343750\n",
      "Train Epoch: 81 [6000/17352 (35%)] Loss: -192750.875000\n",
      "Train Epoch: 81 [6080/17352 (35%)] Loss: -205409.656250\n",
      "Train Epoch: 81 [6160/17352 (36%)] Loss: -189511.265625\n",
      "Train Epoch: 81 [6240/17352 (36%)] Loss: -185044.703125\n",
      "Train Epoch: 81 [6320/17352 (36%)] Loss: -138340.296875\n",
      "Train Epoch: 81 [6400/17352 (37%)] Loss: -213231.875000\n",
      "Train Epoch: 81 [6480/17352 (37%)] Loss: -202087.093750\n",
      "Train Epoch: 81 [6560/17352 (38%)] Loss: -188810.953125\n",
      "Train Epoch: 81 [6640/17352 (38%)] Loss: -194230.312500\n",
      "Train Epoch: 81 [6720/17352 (39%)] Loss: -180969.328125\n",
      "Train Epoch: 81 [6800/17352 (39%)] Loss: -179928.015625\n",
      "Train Epoch: 81 [6880/17352 (40%)] Loss: -200482.781250\n",
      "Train Epoch: 81 [6960/17352 (40%)] Loss: -217626.812500\n",
      "Train Epoch: 81 [7040/17352 (41%)] Loss: -179676.484375\n",
      "Train Epoch: 81 [7120/17352 (41%)] Loss: -178601.125000\n",
      "Train Epoch: 81 [7200/17352 (41%)] Loss: -176536.312500\n",
      "Train Epoch: 81 [7280/17352 (42%)] Loss: -171713.031250\n",
      "Train Epoch: 81 [7360/17352 (42%)] Loss: -177278.125000\n",
      "Train Epoch: 81 [7440/17352 (43%)] Loss: -159754.218750\n",
      "Train Epoch: 81 [7520/17352 (43%)] Loss: -202238.390625\n",
      "Train Epoch: 81 [7600/17352 (44%)] Loss: -228264.640625\n",
      "Train Epoch: 81 [7680/17352 (44%)] Loss: -159096.359375\n",
      "Train Epoch: 81 [7760/17352 (45%)] Loss: -151506.000000\n",
      "Train Epoch: 81 [7840/17352 (45%)] Loss: -209595.718750\n",
      "Train Epoch: 81 [7920/17352 (46%)] Loss: -192392.125000\n",
      "Train Epoch: 81 [8000/17352 (46%)] Loss: -163343.703125\n",
      "Train Epoch: 81 [8080/17352 (47%)] Loss: -177177.359375\n",
      "Train Epoch: 81 [8160/17352 (47%)] Loss: -181010.921875\n",
      "Train Epoch: 81 [8240/17352 (47%)] Loss: -134540.000000\n",
      "Train Epoch: 81 [8320/17352 (48%)] Loss: -183406.906250\n",
      "Train Epoch: 81 [8400/17352 (48%)] Loss: -189800.062500\n",
      "Train Epoch: 81 [8480/17352 (49%)] Loss: -177737.187500\n",
      "Train Epoch: 81 [8560/17352 (49%)] Loss: -165764.765625\n",
      "Train Epoch: 81 [8640/17352 (50%)] Loss: -176054.781250\n",
      "Train Epoch: 81 [8720/17352 (50%)] Loss: -185548.796875\n",
      "Train Epoch: 81 [8800/17352 (51%)] Loss: -171590.437500\n",
      "Train Epoch: 81 [8880/17352 (51%)] Loss: -183506.812500\n",
      "Train Epoch: 81 [8960/17352 (52%)] Loss: -166408.765625\n",
      "Train Epoch: 81 [9040/17352 (52%)] Loss: -179013.156250\n",
      "Train Epoch: 81 [9120/17352 (53%)] Loss: -201937.937500\n",
      "Train Epoch: 81 [9200/17352 (53%)] Loss: -163093.468750\n",
      "Train Epoch: 81 [9280/17352 (53%)] Loss: -207829.140625\n",
      "Train Epoch: 81 [9360/17352 (54%)] Loss: -201826.625000\n",
      "Train Epoch: 81 [9440/17352 (54%)] Loss: -181752.890625\n",
      "Train Epoch: 81 [9520/17352 (55%)] Loss: -175670.406250\n",
      "Train Epoch: 81 [9600/17352 (55%)] Loss: -199721.421875\n",
      "Train Epoch: 81 [9680/17352 (56%)] Loss: -197383.265625\n",
      "Train Epoch: 81 [9760/17352 (56%)] Loss: -208156.265625\n",
      "Train Epoch: 81 [9840/17352 (57%)] Loss: -167876.328125\n",
      "Train Epoch: 81 [9920/17352 (57%)] Loss: -169749.781250\n",
      "Train Epoch: 81 [10000/17352 (58%)] Loss: -208754.937500\n",
      "Train Epoch: 81 [10080/17352 (58%)] Loss: -173662.625000\n",
      "Train Epoch: 81 [10160/17352 (59%)] Loss: -198552.578125\n",
      "Train Epoch: 81 [10240/17352 (59%)] Loss: -223685.218750\n",
      "Train Epoch: 81 [10320/17352 (59%)] Loss: -200421.890625\n",
      "Train Epoch: 81 [10400/17352 (60%)] Loss: -201971.031250\n",
      "Train Epoch: 81 [10480/17352 (60%)] Loss: -202983.562500\n",
      "Train Epoch: 81 [10560/17352 (61%)] Loss: -171726.453125\n",
      "Train Epoch: 81 [10640/17352 (61%)] Loss: -211090.390625\n",
      "Train Epoch: 81 [10720/17352 (62%)] Loss: -169507.406250\n",
      "Train Epoch: 81 [10800/17352 (62%)] Loss: -220974.937500\n",
      "Train Epoch: 81 [10880/17352 (63%)] Loss: -161092.437500\n",
      "Train Epoch: 81 [10960/17352 (63%)] Loss: -181164.046875\n",
      "Train Epoch: 81 [11040/17352 (64%)] Loss: -180906.265625\n",
      "Train Epoch: 81 [11120/17352 (64%)] Loss: -146005.437500\n",
      "Train Epoch: 81 [11200/17352 (65%)] Loss: -201387.265625\n",
      "Train Epoch: 81 [11280/17352 (65%)] Loss: -187219.218750\n",
      "Train Epoch: 81 [11360/17352 (65%)] Loss: -190471.843750\n",
      "Train Epoch: 81 [11440/17352 (66%)] Loss: -192952.781250\n",
      "Train Epoch: 81 [11520/17352 (66%)] Loss: -185800.093750\n",
      "Train Epoch: 81 [11600/17352 (67%)] Loss: -169169.656250\n",
      "Train Epoch: 81 [11680/17352 (67%)] Loss: -174880.828125\n",
      "Train Epoch: 81 [11760/17352 (68%)] Loss: -180053.765625\n",
      "Train Epoch: 81 [11840/17352 (68%)] Loss: -206602.546875\n",
      "Train Epoch: 81 [11920/17352 (69%)] Loss: -199452.750000\n",
      "Train Epoch: 81 [12000/17352 (69%)] Loss: -157774.640625\n",
      "Train Epoch: 81 [12080/17352 (70%)] Loss: -170107.734375\n",
      "Train Epoch: 81 [12160/17352 (70%)] Loss: -196814.890625\n",
      "Train Epoch: 81 [12240/17352 (71%)] Loss: -199017.703125\n",
      "Train Epoch: 81 [12320/17352 (71%)] Loss: -176585.078125\n",
      "Train Epoch: 81 [12400/17352 (71%)] Loss: -164750.218750\n",
      "Train Epoch: 81 [12480/17352 (72%)] Loss: -200976.921875\n",
      "Train Epoch: 81 [12560/17352 (72%)] Loss: -187353.125000\n",
      "Train Epoch: 81 [12640/17352 (73%)] Loss: -218467.453125\n",
      "Train Epoch: 81 [12720/17352 (73%)] Loss: -200071.921875\n",
      "Train Epoch: 81 [12800/17352 (74%)] Loss: -181986.000000\n",
      "Train Epoch: 81 [12880/17352 (74%)] Loss: -177249.156250\n",
      "Train Epoch: 81 [12960/17352 (75%)] Loss: -154606.609375\n",
      "Train Epoch: 81 [13040/17352 (75%)] Loss: -187317.265625\n",
      "Train Epoch: 81 [13120/17352 (76%)] Loss: -212137.796875\n",
      "Train Epoch: 81 [13200/17352 (76%)] Loss: -206475.578125\n",
      "Train Epoch: 81 [13280/17352 (77%)] Loss: -169616.375000\n",
      "Train Epoch: 81 [13360/17352 (77%)] Loss: -177077.593750\n",
      "Train Epoch: 81 [13440/17352 (77%)] Loss: -190817.062500\n",
      "Train Epoch: 81 [13520/17352 (78%)] Loss: -174645.828125\n",
      "Train Epoch: 81 [13600/17352 (78%)] Loss: -206095.859375\n",
      "Train Epoch: 81 [13680/17352 (79%)] Loss: -152740.500000\n",
      "Train Epoch: 81 [13760/17352 (79%)] Loss: -228100.359375\n",
      "Train Epoch: 81 [13840/17352 (80%)] Loss: -210788.078125\n",
      "Train Epoch: 81 [13920/17352 (80%)] Loss: -193263.281250\n",
      "Train Epoch: 81 [14000/17352 (81%)] Loss: -178878.781250\n",
      "Train Epoch: 81 [14080/17352 (81%)] Loss: -188674.187500\n",
      "Train Epoch: 81 [14160/17352 (82%)] Loss: -183375.625000\n",
      "Train Epoch: 81 [14240/17352 (82%)] Loss: -164829.015625\n",
      "Train Epoch: 81 [14320/17352 (83%)] Loss: -175409.171875\n",
      "Train Epoch: 81 [14400/17352 (83%)] Loss: -185363.406250\n",
      "Train Epoch: 81 [14480/17352 (83%)] Loss: -185063.656250\n",
      "Train Epoch: 81 [14560/17352 (84%)] Loss: -183393.250000\n",
      "Train Epoch: 81 [14640/17352 (84%)] Loss: -176593.031250\n",
      "Train Epoch: 81 [14720/17352 (85%)] Loss: -168072.937500\n",
      "Train Epoch: 81 [14800/17352 (85%)] Loss: -181372.281250\n",
      "Train Epoch: 81 [14880/17352 (86%)] Loss: -204495.875000\n",
      "Train Epoch: 81 [14960/17352 (86%)] Loss: -209503.828125\n",
      "Train Epoch: 81 [15040/17352 (87%)] Loss: -191004.406250\n",
      "Train Epoch: 81 [15120/17352 (87%)] Loss: -164146.171875\n",
      "Train Epoch: 81 [15200/17352 (88%)] Loss: -196734.125000\n",
      "Train Epoch: 81 [15280/17352 (88%)] Loss: -183764.328125\n",
      "Train Epoch: 81 [15360/17352 (89%)] Loss: -197949.812500\n",
      "Train Epoch: 81 [15440/17352 (89%)] Loss: -170774.500000\n",
      "Train Epoch: 81 [15520/17352 (89%)] Loss: -191805.875000\n",
      "Train Epoch: 81 [15600/17352 (90%)] Loss: -166994.453125\n",
      "Train Epoch: 81 [15680/17352 (90%)] Loss: -182779.484375\n",
      "Train Epoch: 81 [15760/17352 (91%)] Loss: -149445.109375\n",
      "Train Epoch: 81 [15840/17352 (91%)] Loss: -174146.156250\n",
      "Train Epoch: 81 [15920/17352 (92%)] Loss: -215412.968750\n",
      "Train Epoch: 81 [16000/17352 (92%)] Loss: -210394.765625\n",
      "Train Epoch: 81 [16080/17352 (93%)] Loss: -180292.046875\n",
      "Train Epoch: 81 [16160/17352 (93%)] Loss: -202021.046875\n",
      "Train Epoch: 81 [16240/17352 (94%)] Loss: -180839.546875\n",
      "Train Epoch: 81 [16320/17352 (94%)] Loss: -208726.328125\n",
      "Train Epoch: 81 [16400/17352 (95%)] Loss: -177775.515625\n",
      "Train Epoch: 81 [16480/17352 (95%)] Loss: -183795.593750\n",
      "Train Epoch: 81 [16560/17352 (95%)] Loss: -168195.703125\n",
      "Train Epoch: 81 [16640/17352 (96%)] Loss: -180308.671875\n",
      "Train Epoch: 81 [16720/17352 (96%)] Loss: -186776.000000\n",
      "Train Epoch: 81 [16800/17352 (97%)] Loss: -180512.484375\n",
      "Train Epoch: 81 [16880/17352 (97%)] Loss: -164953.750000\n",
      "Train Epoch: 81 [16960/17352 (98%)] Loss: -165679.609375\n",
      "Train Epoch: 81 [17040/17352 (98%)] Loss: -174186.203125\n",
      "Train Epoch: 81 [17120/17352 (99%)] Loss: -174513.156250\n",
      "Train Epoch: 81 [17200/17352 (99%)] Loss: -179443.343750\n",
      "Train Epoch: 81 [17280/17352 (100%)] Loss: -192957.796875\n",
      "Train Epoch: 81 [17360/17352 (100%)] Loss: -185241.421875\n",
      "    epoch          : 81\n",
      "    loss           : -189223.89760140967\n",
      "    val_loss       : -23716.309649257033\n",
      "Train Epoch: 82 [0/17352 (0%)] Loss: -206784.046875\n",
      "Train Epoch: 82 [80/17352 (0%)] Loss: -216217.875000\n",
      "Train Epoch: 82 [160/17352 (1%)] Loss: -204735.656250\n",
      "Train Epoch: 82 [240/17352 (1%)] Loss: -210353.750000\n",
      "Train Epoch: 82 [320/17352 (2%)] Loss: -202321.640625\n",
      "Train Epoch: 82 [400/17352 (2%)] Loss: -205196.109375\n",
      "Train Epoch: 82 [480/17352 (3%)] Loss: -230188.125000\n",
      "Train Epoch: 82 [560/17352 (3%)] Loss: -213321.484375\n",
      "Train Epoch: 82 [640/17352 (4%)] Loss: -196928.593750\n",
      "Train Epoch: 82 [720/17352 (4%)] Loss: -199930.593750\n",
      "Train Epoch: 82 [800/17352 (5%)] Loss: -231335.046875\n",
      "Train Epoch: 82 [880/17352 (5%)] Loss: -210528.765625\n",
      "Train Epoch: 82 [960/17352 (6%)] Loss: -209779.968750\n",
      "Train Epoch: 82 [1040/17352 (6%)] Loss: -217599.968750\n",
      "Train Epoch: 82 [1120/17352 (6%)] Loss: -228018.765625\n",
      "Train Epoch: 82 [1200/17352 (7%)] Loss: -208377.906250\n",
      "Train Epoch: 82 [1280/17352 (7%)] Loss: -214418.250000\n",
      "Train Epoch: 82 [1360/17352 (8%)] Loss: -202235.453125\n",
      "Train Epoch: 82 [1440/17352 (8%)] Loss: -199106.343750\n",
      "Train Epoch: 82 [1520/17352 (9%)] Loss: -205929.937500\n",
      "Train Epoch: 82 [1600/17352 (9%)] Loss: -193412.796875\n",
      "Train Epoch: 82 [1680/17352 (10%)] Loss: -215096.937500\n",
      "Train Epoch: 82 [1760/17352 (10%)] Loss: -203268.718750\n",
      "Train Epoch: 82 [1840/17352 (11%)] Loss: -215827.015625\n",
      "Train Epoch: 82 [1920/17352 (11%)] Loss: -204529.765625\n",
      "Train Epoch: 82 [2000/17352 (12%)] Loss: -212386.296875\n",
      "Train Epoch: 82 [2080/17352 (12%)] Loss: -217940.531250\n",
      "Train Epoch: 82 [2160/17352 (12%)] Loss: -206574.265625\n",
      "Train Epoch: 82 [2240/17352 (13%)] Loss: -164076.125000\n",
      "Train Epoch: 82 [2320/17352 (13%)] Loss: -202597.812500\n",
      "Train Epoch: 82 [2400/17352 (14%)] Loss: -176878.203125\n",
      "Train Epoch: 82 [2480/17352 (14%)] Loss: -168760.234375\n",
      "Train Epoch: 82 [2560/17352 (15%)] Loss: -171422.765625\n",
      "Train Epoch: 82 [2640/17352 (15%)] Loss: -164504.796875\n",
      "Train Epoch: 82 [2720/17352 (16%)] Loss: -212977.156250\n",
      "Train Epoch: 82 [2800/17352 (16%)] Loss: -184845.078125\n",
      "Train Epoch: 82 [2880/17352 (17%)] Loss: -192316.718750\n",
      "Train Epoch: 82 [2960/17352 (17%)] Loss: -194054.265625\n",
      "Train Epoch: 82 [3040/17352 (18%)] Loss: -184950.906250\n",
      "Train Epoch: 82 [3120/17352 (18%)] Loss: -156612.546875\n",
      "Train Epoch: 82 [3200/17352 (18%)] Loss: -165732.687500\n",
      "Train Epoch: 82 [3280/17352 (19%)] Loss: -197387.921875\n",
      "Train Epoch: 82 [3360/17352 (19%)] Loss: -165680.890625\n",
      "Train Epoch: 82 [3440/17352 (20%)] Loss: -143619.593750\n",
      "Train Epoch: 82 [3520/17352 (20%)] Loss: -185291.312500\n",
      "Train Epoch: 82 [3600/17352 (21%)] Loss: -204423.671875\n",
      "Train Epoch: 82 [3680/17352 (21%)] Loss: -180165.046875\n",
      "Train Epoch: 82 [3760/17352 (22%)] Loss: -192690.359375\n",
      "Train Epoch: 82 [3840/17352 (22%)] Loss: -201004.843750\n",
      "Train Epoch: 82 [3920/17352 (23%)] Loss: -188052.234375\n",
      "Train Epoch: 82 [4000/17352 (23%)] Loss: -163254.437500\n",
      "Train Epoch: 82 [4080/17352 (24%)] Loss: -203147.234375\n",
      "Train Epoch: 82 [4160/17352 (24%)] Loss: -176538.125000\n",
      "Train Epoch: 82 [4240/17352 (24%)] Loss: -197543.515625\n",
      "Train Epoch: 82 [4320/17352 (25%)] Loss: -167191.906250\n",
      "Train Epoch: 82 [4400/17352 (25%)] Loss: -187217.281250\n",
      "Train Epoch: 82 [4480/17352 (26%)] Loss: -192889.750000\n",
      "Train Epoch: 82 [4560/17352 (26%)] Loss: -178876.468750\n",
      "Train Epoch: 82 [4640/17352 (27%)] Loss: -152738.375000\n",
      "Train Epoch: 82 [4720/17352 (27%)] Loss: -200169.500000\n",
      "Train Epoch: 82 [4800/17352 (28%)] Loss: -197073.625000\n",
      "Train Epoch: 82 [4880/17352 (28%)] Loss: -178805.218750\n",
      "Train Epoch: 82 [4960/17352 (29%)] Loss: -194602.500000\n",
      "Train Epoch: 82 [5040/17352 (29%)] Loss: -179417.421875\n",
      "Train Epoch: 82 [5120/17352 (30%)] Loss: -195000.984375\n",
      "Train Epoch: 82 [5200/17352 (30%)] Loss: -178600.531250\n",
      "Train Epoch: 82 [5280/17352 (30%)] Loss: -193056.234375\n",
      "Train Epoch: 82 [5360/17352 (31%)] Loss: -172553.453125\n",
      "Train Epoch: 82 [5440/17352 (31%)] Loss: -200267.609375\n",
      "Train Epoch: 82 [5520/17352 (32%)] Loss: -183726.781250\n",
      "Train Epoch: 82 [5600/17352 (32%)] Loss: -181958.640625\n",
      "Train Epoch: 82 [5680/17352 (33%)] Loss: -208024.812500\n",
      "Train Epoch: 82 [5760/17352 (33%)] Loss: -187246.734375\n",
      "Train Epoch: 82 [5840/17352 (34%)] Loss: -189305.390625\n",
      "Train Epoch: 82 [5920/17352 (34%)] Loss: -178667.406250\n",
      "Train Epoch: 82 [6000/17352 (35%)] Loss: -188568.718750\n",
      "Train Epoch: 82 [6080/17352 (35%)] Loss: -195386.421875\n",
      "Train Epoch: 82 [6160/17352 (36%)] Loss: -185936.734375\n",
      "Train Epoch: 82 [6240/17352 (36%)] Loss: -199722.640625\n",
      "Train Epoch: 82 [6320/17352 (36%)] Loss: -200634.203125\n",
      "Train Epoch: 82 [6400/17352 (37%)] Loss: -176037.812500\n",
      "Train Epoch: 82 [6480/17352 (37%)] Loss: -179453.296875\n",
      "Train Epoch: 82 [6560/17352 (38%)] Loss: -186043.265625\n",
      "Train Epoch: 82 [6640/17352 (38%)] Loss: -177732.109375\n",
      "Train Epoch: 82 [6720/17352 (39%)] Loss: -164993.406250\n",
      "Train Epoch: 82 [6800/17352 (39%)] Loss: -187645.093750\n",
      "Train Epoch: 82 [6880/17352 (40%)] Loss: -206930.687500\n",
      "Train Epoch: 82 [6960/17352 (40%)] Loss: -197320.125000\n",
      "Train Epoch: 82 [7040/17352 (41%)] Loss: -187525.375000\n",
      "Train Epoch: 82 [7120/17352 (41%)] Loss: -211092.000000\n",
      "Train Epoch: 82 [7200/17352 (41%)] Loss: -178825.078125\n",
      "Train Epoch: 82 [7280/17352 (42%)] Loss: -186614.390625\n",
      "Train Epoch: 82 [7360/17352 (42%)] Loss: -161967.765625\n",
      "Train Epoch: 82 [7440/17352 (43%)] Loss: -203438.515625\n",
      "Train Epoch: 82 [7520/17352 (43%)] Loss: -192176.171875\n",
      "Train Epoch: 82 [7600/17352 (44%)] Loss: -181730.562500\n",
      "Train Epoch: 82 [7680/17352 (44%)] Loss: -184922.171875\n",
      "Train Epoch: 82 [7760/17352 (45%)] Loss: -156994.250000\n",
      "Train Epoch: 82 [7840/17352 (45%)] Loss: -206201.843750\n",
      "Train Epoch: 82 [7920/17352 (46%)] Loss: -182096.765625\n",
      "Train Epoch: 82 [8000/17352 (46%)] Loss: -203269.968750\n",
      "Train Epoch: 82 [8080/17352 (47%)] Loss: -180307.984375\n",
      "Train Epoch: 82 [8160/17352 (47%)] Loss: -197518.750000\n",
      "Train Epoch: 82 [8240/17352 (47%)] Loss: -163502.609375\n",
      "Train Epoch: 82 [8320/17352 (48%)] Loss: -185045.796875\n",
      "Train Epoch: 82 [8400/17352 (48%)] Loss: -193174.375000\n",
      "Train Epoch: 82 [8480/17352 (49%)] Loss: -179385.796875\n",
      "Train Epoch: 82 [8560/17352 (49%)] Loss: -166520.500000\n",
      "Train Epoch: 82 [8640/17352 (50%)] Loss: -206094.984375\n",
      "Train Epoch: 82 [8720/17352 (50%)] Loss: -196934.968750\n",
      "Train Epoch: 82 [8800/17352 (51%)] Loss: -208725.875000\n",
      "Train Epoch: 82 [8880/17352 (51%)] Loss: -184176.062500\n",
      "Train Epoch: 82 [8960/17352 (52%)] Loss: -192124.828125\n",
      "Train Epoch: 82 [9040/17352 (52%)] Loss: -196565.343750\n",
      "Train Epoch: 82 [9120/17352 (53%)] Loss: -214682.968750\n",
      "Train Epoch: 82 [9200/17352 (53%)] Loss: -187268.078125\n",
      "Train Epoch: 82 [9280/17352 (53%)] Loss: -187453.812500\n",
      "Train Epoch: 82 [9360/17352 (54%)] Loss: -204350.234375\n",
      "Train Epoch: 82 [9440/17352 (54%)] Loss: -173657.796875\n",
      "Train Epoch: 82 [9520/17352 (55%)] Loss: -174544.984375\n",
      "Train Epoch: 82 [9600/17352 (55%)] Loss: -183759.546875\n",
      "Train Epoch: 82 [9680/17352 (56%)] Loss: -187320.796875\n",
      "Train Epoch: 82 [9760/17352 (56%)] Loss: -159667.984375\n",
      "Train Epoch: 82 [9840/17352 (57%)] Loss: -187592.500000\n",
      "Train Epoch: 82 [9920/17352 (57%)] Loss: -197600.140625\n",
      "Train Epoch: 82 [10000/17352 (58%)] Loss: -198262.359375\n",
      "Train Epoch: 82 [10080/17352 (58%)] Loss: -198294.859375\n",
      "Train Epoch: 82 [10160/17352 (59%)] Loss: -180524.437500\n",
      "Train Epoch: 82 [10240/17352 (59%)] Loss: -178201.250000\n",
      "Train Epoch: 82 [10320/17352 (59%)] Loss: -218522.671875\n",
      "Train Epoch: 82 [10400/17352 (60%)] Loss: -179893.671875\n",
      "Train Epoch: 82 [10480/17352 (60%)] Loss: -173446.828125\n",
      "Train Epoch: 82 [10560/17352 (61%)] Loss: -170787.125000\n",
      "Train Epoch: 82 [10640/17352 (61%)] Loss: -200463.500000\n",
      "Train Epoch: 82 [10720/17352 (62%)] Loss: -218751.296875\n",
      "Train Epoch: 82 [10800/17352 (62%)] Loss: -158257.609375\n",
      "Train Epoch: 82 [10880/17352 (63%)] Loss: -183068.625000\n",
      "Train Epoch: 82 [10960/17352 (63%)] Loss: -182778.593750\n",
      "Train Epoch: 82 [11040/17352 (64%)] Loss: -191000.875000\n",
      "Train Epoch: 82 [11120/17352 (64%)] Loss: -208343.203125\n",
      "Train Epoch: 82 [11200/17352 (65%)] Loss: -200299.703125\n",
      "Train Epoch: 82 [11280/17352 (65%)] Loss: -170038.046875\n",
      "Train Epoch: 82 [11360/17352 (65%)] Loss: -181011.656250\n",
      "Train Epoch: 82 [11440/17352 (66%)] Loss: -180145.484375\n",
      "Train Epoch: 82 [11520/17352 (66%)] Loss: -198000.359375\n",
      "Train Epoch: 82 [11600/17352 (67%)] Loss: -193448.234375\n",
      "Train Epoch: 82 [11680/17352 (67%)] Loss: -182745.843750\n",
      "Train Epoch: 82 [11760/17352 (68%)] Loss: -168076.750000\n",
      "Train Epoch: 82 [11840/17352 (68%)] Loss: -181670.609375\n",
      "Train Epoch: 82 [11920/17352 (69%)] Loss: -173002.343750\n",
      "Train Epoch: 82 [12000/17352 (69%)] Loss: -192791.921875\n",
      "Train Epoch: 82 [12080/17352 (70%)] Loss: -186782.593750\n",
      "Train Epoch: 82 [12160/17352 (70%)] Loss: -180908.875000\n",
      "Train Epoch: 82 [12240/17352 (71%)] Loss: -188211.625000\n",
      "Train Epoch: 82 [12320/17352 (71%)] Loss: -210263.359375\n",
      "Train Epoch: 82 [12400/17352 (71%)] Loss: -199417.796875\n",
      "Train Epoch: 82 [12480/17352 (72%)] Loss: -200170.859375\n",
      "Train Epoch: 82 [12560/17352 (72%)] Loss: -190915.546875\n",
      "Train Epoch: 82 [12640/17352 (73%)] Loss: -159695.796875\n",
      "Train Epoch: 82 [12720/17352 (73%)] Loss: -200221.671875\n",
      "Train Epoch: 82 [12800/17352 (74%)] Loss: -209422.578125\n",
      "Train Epoch: 82 [12880/17352 (74%)] Loss: -171714.062500\n",
      "Train Epoch: 82 [12960/17352 (75%)] Loss: -191591.843750\n",
      "Train Epoch: 82 [13040/17352 (75%)] Loss: -148397.812500\n",
      "Train Epoch: 82 [13120/17352 (76%)] Loss: -206227.718750\n",
      "Train Epoch: 82 [13200/17352 (76%)] Loss: -199787.453125\n",
      "Train Epoch: 82 [13280/17352 (77%)] Loss: -200479.546875\n",
      "Train Epoch: 82 [13360/17352 (77%)] Loss: -191158.781250\n",
      "Train Epoch: 82 [13440/17352 (77%)] Loss: -208429.921875\n",
      "Train Epoch: 82 [13520/17352 (78%)] Loss: -136429.906250\n",
      "Train Epoch: 82 [13600/17352 (78%)] Loss: -195657.078125\n",
      "Train Epoch: 82 [13680/17352 (79%)] Loss: -153893.234375\n",
      "Train Epoch: 82 [13760/17352 (79%)] Loss: -191681.593750\n",
      "Train Epoch: 82 [13840/17352 (80%)] Loss: -184954.109375\n",
      "Train Epoch: 82 [13920/17352 (80%)] Loss: -182690.062500\n",
      "Train Epoch: 82 [14000/17352 (81%)] Loss: -181919.218750\n",
      "Train Epoch: 82 [14080/17352 (81%)] Loss: -171193.390625\n",
      "Train Epoch: 82 [14160/17352 (82%)] Loss: -214753.406250\n",
      "Train Epoch: 82 [14240/17352 (82%)] Loss: -170311.812500\n",
      "Train Epoch: 82 [14320/17352 (83%)] Loss: -168084.687500\n",
      "Train Epoch: 82 [14400/17352 (83%)] Loss: -179674.812500\n",
      "Train Epoch: 82 [14480/17352 (83%)] Loss: -178097.453125\n",
      "Train Epoch: 82 [14560/17352 (84%)] Loss: -186557.578125\n",
      "Train Epoch: 82 [14640/17352 (84%)] Loss: -179741.906250\n",
      "Train Epoch: 82 [14720/17352 (85%)] Loss: -176680.500000\n",
      "Train Epoch: 82 [14800/17352 (85%)] Loss: -205006.531250\n",
      "Train Epoch: 82 [14880/17352 (86%)] Loss: -188086.734375\n",
      "Train Epoch: 82 [14960/17352 (86%)] Loss: -196405.500000\n",
      "Train Epoch: 82 [15040/17352 (87%)] Loss: -206474.468750\n",
      "Train Epoch: 82 [15120/17352 (87%)] Loss: -189487.109375\n",
      "Train Epoch: 82 [15200/17352 (88%)] Loss: -177601.718750\n",
      "Train Epoch: 82 [15280/17352 (88%)] Loss: -187724.703125\n",
      "Train Epoch: 82 [15360/17352 (89%)] Loss: -174729.562500\n",
      "Train Epoch: 82 [15440/17352 (89%)] Loss: -180874.375000\n",
      "Train Epoch: 82 [15520/17352 (89%)] Loss: -191836.328125\n",
      "Train Epoch: 82 [15600/17352 (90%)] Loss: -224865.453125\n",
      "Train Epoch: 82 [15680/17352 (90%)] Loss: -181750.875000\n",
      "Train Epoch: 82 [15760/17352 (91%)] Loss: -202242.687500\n",
      "Train Epoch: 82 [15840/17352 (91%)] Loss: -183262.906250\n",
      "Train Epoch: 82 [15920/17352 (92%)] Loss: -181977.781250\n",
      "Train Epoch: 82 [16000/17352 (92%)] Loss: -167803.843750\n",
      "Train Epoch: 82 [16080/17352 (93%)] Loss: -213236.640625\n",
      "Train Epoch: 82 [16160/17352 (93%)] Loss: -165730.203125\n",
      "Train Epoch: 82 [16240/17352 (94%)] Loss: -158747.109375\n",
      "Train Epoch: 82 [16320/17352 (94%)] Loss: -190475.593750\n",
      "Train Epoch: 82 [16400/17352 (95%)] Loss: -170537.781250\n",
      "Train Epoch: 82 [16480/17352 (95%)] Loss: -185175.015625\n",
      "Train Epoch: 82 [16560/17352 (95%)] Loss: -187206.578125\n",
      "Train Epoch: 82 [16640/17352 (96%)] Loss: -183505.281250\n",
      "Train Epoch: 82 [16720/17352 (96%)] Loss: -213180.062500\n",
      "Train Epoch: 82 [16800/17352 (97%)] Loss: -192013.140625\n",
      "Train Epoch: 82 [16880/17352 (97%)] Loss: -190945.343750\n",
      "Train Epoch: 82 [16960/17352 (98%)] Loss: -151222.484375\n",
      "Train Epoch: 82 [17040/17352 (98%)] Loss: -161514.593750\n",
      "Train Epoch: 82 [17120/17352 (99%)] Loss: -183870.578125\n",
      "Train Epoch: 82 [17200/17352 (99%)] Loss: -192012.625000\n",
      "Train Epoch: 82 [17280/17352 (100%)] Loss: -207092.687500\n",
      "Train Epoch: 82 [17360/17352 (100%)] Loss: -188259.109375\n",
      "    epoch          : 82\n",
      "    loss           : -189203.60618347238\n",
      "    val_loss       : -23716.28243087267\n",
      "Train Epoch: 83 [0/17352 (0%)] Loss: -199922.609375\n",
      "Train Epoch: 83 [80/17352 (0%)] Loss: -236834.234375\n",
      "Train Epoch: 83 [160/17352 (1%)] Loss: -204732.656250\n",
      "Train Epoch: 83 [240/17352 (1%)] Loss: -196416.937500\n",
      "Train Epoch: 83 [320/17352 (2%)] Loss: -187716.187500\n",
      "Train Epoch: 83 [400/17352 (2%)] Loss: -204028.640625\n",
      "Train Epoch: 83 [480/17352 (3%)] Loss: -203267.500000\n",
      "Train Epoch: 83 [560/17352 (3%)] Loss: -206788.156250\n",
      "Train Epoch: 83 [640/17352 (4%)] Loss: -213323.015625\n",
      "Train Epoch: 83 [720/17352 (4%)] Loss: -211897.406250\n",
      "Train Epoch: 83 [800/17352 (5%)] Loss: -205213.484375\n",
      "Train Epoch: 83 [880/17352 (5%)] Loss: -194494.812500\n",
      "Train Epoch: 83 [960/17352 (6%)] Loss: -214526.062500\n",
      "Train Epoch: 83 [1040/17352 (6%)] Loss: -199107.750000\n",
      "Train Epoch: 83 [1120/17352 (6%)] Loss: -208534.125000\n",
      "Train Epoch: 83 [1200/17352 (7%)] Loss: -212654.281250\n",
      "Train Epoch: 83 [1280/17352 (7%)] Loss: -219206.468750\n",
      "Train Epoch: 83 [1360/17352 (8%)] Loss: -208382.656250\n",
      "Train Epoch: 83 [1440/17352 (8%)] Loss: -203739.500000\n",
      "Train Epoch: 83 [1520/17352 (9%)] Loss: -185289.750000\n",
      "Train Epoch: 83 [1600/17352 (9%)] Loss: -214458.906250\n",
      "Train Epoch: 83 [1680/17352 (10%)] Loss: -200605.187500\n",
      "Train Epoch: 83 [1760/17352 (10%)] Loss: -193575.531250\n",
      "Train Epoch: 83 [1840/17352 (11%)] Loss: -202311.578125\n",
      "Train Epoch: 83 [1920/17352 (11%)] Loss: -199905.718750\n",
      "Train Epoch: 83 [2000/17352 (12%)] Loss: -205559.625000\n",
      "Train Epoch: 83 [2080/17352 (12%)] Loss: -230413.906250\n",
      "Train Epoch: 83 [2160/17352 (12%)] Loss: -214333.312500\n",
      "Train Epoch: 83 [2240/17352 (13%)] Loss: -192237.640625\n",
      "Train Epoch: 83 [2320/17352 (13%)] Loss: -217604.968750\n",
      "Train Epoch: 83 [2400/17352 (14%)] Loss: -197328.359375\n",
      "Train Epoch: 83 [2480/17352 (14%)] Loss: -172962.187500\n",
      "Train Epoch: 83 [2560/17352 (15%)] Loss: -181339.968750\n",
      "Train Epoch: 83 [2640/17352 (15%)] Loss: -185800.578125\n",
      "Train Epoch: 83 [2720/17352 (16%)] Loss: -205536.156250\n",
      "Train Epoch: 83 [2800/17352 (16%)] Loss: -196440.500000\n",
      "Train Epoch: 83 [2880/17352 (17%)] Loss: -184844.484375\n",
      "Train Epoch: 83 [2960/17352 (17%)] Loss: -199008.062500\n",
      "Train Epoch: 83 [3040/17352 (18%)] Loss: -225473.937500\n",
      "Train Epoch: 83 [3120/17352 (18%)] Loss: -203815.765625\n",
      "Train Epoch: 83 [3200/17352 (18%)] Loss: -177239.250000\n",
      "Train Epoch: 83 [3280/17352 (19%)] Loss: -205023.640625\n",
      "Train Epoch: 83 [3360/17352 (19%)] Loss: -180056.156250\n",
      "Train Epoch: 83 [3440/17352 (20%)] Loss: -183797.937500\n",
      "Train Epoch: 83 [3520/17352 (20%)] Loss: -215964.984375\n",
      "Train Epoch: 83 [3600/17352 (21%)] Loss: -163343.578125\n",
      "Train Epoch: 83 [3680/17352 (21%)] Loss: -215414.812500\n",
      "Train Epoch: 83 [3760/17352 (22%)] Loss: -181618.500000\n",
      "Train Epoch: 83 [3840/17352 (22%)] Loss: -180797.359375\n",
      "Train Epoch: 83 [3920/17352 (23%)] Loss: -199796.265625\n",
      "Train Epoch: 83 [4000/17352 (23%)] Loss: -179968.375000\n",
      "Train Epoch: 83 [4080/17352 (24%)] Loss: -207125.656250\n",
      "Train Epoch: 83 [4160/17352 (24%)] Loss: -221258.000000\n",
      "Train Epoch: 83 [4240/17352 (24%)] Loss: -193131.828125\n",
      "Train Epoch: 83 [4320/17352 (25%)] Loss: -140589.875000\n",
      "Train Epoch: 83 [4400/17352 (25%)] Loss: -177080.656250\n",
      "Train Epoch: 83 [4480/17352 (26%)] Loss: -183605.953125\n",
      "Train Epoch: 83 [4560/17352 (26%)] Loss: -216400.125000\n",
      "Train Epoch: 83 [4640/17352 (27%)] Loss: -174935.796875\n",
      "Train Epoch: 83 [4720/17352 (27%)] Loss: -198553.421875\n",
      "Train Epoch: 83 [4800/17352 (28%)] Loss: -203676.796875\n",
      "Train Epoch: 83 [4880/17352 (28%)] Loss: -186161.687500\n",
      "Train Epoch: 83 [4960/17352 (29%)] Loss: -201310.781250\n",
      "Train Epoch: 83 [5040/17352 (29%)] Loss: -185051.687500\n",
      "Train Epoch: 83 [5120/17352 (30%)] Loss: -186493.750000\n",
      "Train Epoch: 83 [5200/17352 (30%)] Loss: -188801.593750\n",
      "Train Epoch: 83 [5280/17352 (30%)] Loss: -159613.859375\n",
      "Train Epoch: 83 [5360/17352 (31%)] Loss: -212128.984375\n",
      "Train Epoch: 83 [5440/17352 (31%)] Loss: -195375.453125\n",
      "Train Epoch: 83 [5520/17352 (32%)] Loss: -183964.218750\n",
      "Train Epoch: 83 [5600/17352 (32%)] Loss: -208037.062500\n",
      "Train Epoch: 83 [5680/17352 (33%)] Loss: -196870.343750\n",
      "Train Epoch: 83 [5760/17352 (33%)] Loss: -178378.843750\n",
      "Train Epoch: 83 [5840/17352 (34%)] Loss: -178600.625000\n",
      "Train Epoch: 83 [5920/17352 (34%)] Loss: -183628.484375\n",
      "Train Epoch: 83 [6000/17352 (35%)] Loss: -192953.546875\n",
      "Train Epoch: 83 [6080/17352 (35%)] Loss: -207788.250000\n",
      "Train Epoch: 83 [6160/17352 (36%)] Loss: -146006.656250\n",
      "Train Epoch: 83 [6240/17352 (36%)] Loss: -166405.000000\n",
      "Train Epoch: 83 [6320/17352 (36%)] Loss: -171850.500000\n",
      "Train Epoch: 83 [6400/17352 (37%)] Loss: -178306.390625\n",
      "Train Epoch: 83 [6480/17352 (37%)] Loss: -199599.468750\n",
      "Train Epoch: 83 [6560/17352 (38%)] Loss: -176896.968750\n",
      "Train Epoch: 83 [6640/17352 (38%)] Loss: -203880.796875\n",
      "Train Epoch: 83 [6720/17352 (39%)] Loss: -178731.625000\n",
      "Train Epoch: 83 [6800/17352 (39%)] Loss: -156477.375000\n",
      "Train Epoch: 83 [6880/17352 (40%)] Loss: -208127.453125\n",
      "Train Epoch: 83 [6960/17352 (40%)] Loss: -198264.906250\n",
      "Train Epoch: 83 [7040/17352 (41%)] Loss: -224865.375000\n",
      "Train Epoch: 83 [7120/17352 (41%)] Loss: -190503.328125\n",
      "Train Epoch: 83 [7200/17352 (41%)] Loss: -187726.125000\n",
      "Train Epoch: 83 [7280/17352 (42%)] Loss: -174546.031250\n",
      "Train Epoch: 83 [7360/17352 (42%)] Loss: -188679.687500\n",
      "Train Epoch: 83 [7440/17352 (43%)] Loss: -183393.234375\n",
      "Train Epoch: 83 [7520/17352 (43%)] Loss: -212978.078125\n",
      "Train Epoch: 83 [7600/17352 (44%)] Loss: -183225.250000\n",
      "Train Epoch: 83 [7680/17352 (44%)] Loss: -205513.312500\n",
      "Train Epoch: 83 [7760/17352 (45%)] Loss: -160148.437500\n",
      "Train Epoch: 83 [7840/17352 (45%)] Loss: -196817.500000\n",
      "Train Epoch: 83 [7920/17352 (46%)] Loss: -189268.156250\n",
      "Train Epoch: 83 [8000/17352 (46%)] Loss: -203433.484375\n",
      "Train Epoch: 83 [8080/17352 (47%)] Loss: -167491.812500\n",
      "Train Epoch: 83 [8160/17352 (47%)] Loss: -198549.859375\n",
      "Train Epoch: 83 [8240/17352 (47%)] Loss: -175360.828125\n",
      "Train Epoch: 83 [8320/17352 (48%)] Loss: -192127.671875\n",
      "Train Epoch: 83 [8400/17352 (48%)] Loss: -192371.843750\n",
      "Train Epoch: 83 [8480/17352 (49%)] Loss: -183720.468750\n",
      "Train Epoch: 83 [8560/17352 (49%)] Loss: -165681.234375\n",
      "Train Epoch: 83 [8640/17352 (50%)] Loss: -179014.656250\n",
      "Train Epoch: 83 [8720/17352 (50%)] Loss: -168504.765625\n",
      "Train Epoch: 83 [8800/17352 (51%)] Loss: -181728.640625\n",
      "Train Epoch: 83 [8880/17352 (51%)] Loss: -185230.718750\n",
      "Train Epoch: 83 [8960/17352 (52%)] Loss: -204348.593750\n",
      "Train Epoch: 83 [9040/17352 (52%)] Loss: -177982.187500\n",
      "Train Epoch: 83 [9120/17352 (53%)] Loss: -208426.500000\n",
      "Train Epoch: 83 [9200/17352 (53%)] Loss: -189214.015625\n",
      "Train Epoch: 83 [9280/17352 (53%)] Loss: -181540.406250\n",
      "Train Epoch: 83 [9360/17352 (54%)] Loss: -215650.796875\n",
      "Train Epoch: 83 [9440/17352 (54%)] Loss: -142337.125000\n",
      "Train Epoch: 83 [9520/17352 (55%)] Loss: -167141.937500\n",
      "Train Epoch: 83 [9600/17352 (55%)] Loss: -183922.906250\n",
      "Train Epoch: 83 [9680/17352 (56%)] Loss: -184757.265625\n",
      "Train Epoch: 83 [9760/17352 (56%)] Loss: -205811.718750\n",
      "Train Epoch: 83 [9840/17352 (57%)] Loss: -186515.437500\n",
      "Train Epoch: 83 [9920/17352 (57%)] Loss: -177463.125000\n",
      "Train Epoch: 83 [10000/17352 (58%)] Loss: -177605.937500\n",
      "Train Epoch: 83 [10080/17352 (58%)] Loss: -171421.296875\n",
      "Train Epoch: 83 [10160/17352 (59%)] Loss: -189482.937500\n",
      "Train Epoch: 83 [10240/17352 (59%)] Loss: -176590.125000\n",
      "Train Epoch: 83 [10320/17352 (59%)] Loss: -184034.015625\n",
      "Train Epoch: 83 [10400/17352 (60%)] Loss: -182524.078125\n",
      "Train Epoch: 83 [10480/17352 (60%)] Loss: -164799.953125\n",
      "Train Epoch: 83 [10560/17352 (61%)] Loss: -202854.859375\n",
      "Train Epoch: 83 [10640/17352 (61%)] Loss: -151220.328125\n",
      "Train Epoch: 83 [10720/17352 (62%)] Loss: -185337.531250\n",
      "Train Epoch: 83 [10800/17352 (62%)] Loss: -204615.687500\n",
      "Train Epoch: 83 [10880/17352 (63%)] Loss: -185315.968750\n",
      "Train Epoch: 83 [10960/17352 (63%)] Loss: -177487.703125\n",
      "Train Epoch: 83 [11040/17352 (64%)] Loss: -162720.562500\n",
      "Train Epoch: 83 [11120/17352 (64%)] Loss: -180114.343750\n",
      "Train Epoch: 83 [11200/17352 (65%)] Loss: -202234.750000\n",
      "Train Epoch: 83 [11280/17352 (65%)] Loss: -192649.375000\n",
      "Train Epoch: 83 [11360/17352 (65%)] Loss: -161680.312500\n",
      "Train Epoch: 83 [11440/17352 (66%)] Loss: -180147.015625\n",
      "Train Epoch: 83 [11520/17352 (66%)] Loss: -192688.140625\n",
      "Train Epoch: 83 [11600/17352 (67%)] Loss: -155870.609375\n",
      "Train Epoch: 83 [11680/17352 (67%)] Loss: -210159.687500\n",
      "Train Epoch: 83 [11760/17352 (68%)] Loss: -187325.156250\n",
      "Train Epoch: 83 [11840/17352 (68%)] Loss: -179676.546875\n",
      "Train Epoch: 83 [11920/17352 (69%)] Loss: -176706.296875\n",
      "Train Epoch: 83 [12000/17352 (69%)] Loss: -196409.984375\n",
      "Train Epoch: 83 [12080/17352 (70%)] Loss: -179444.750000\n",
      "Train Epoch: 83 [12160/17352 (70%)] Loss: -205733.953125\n",
      "Train Epoch: 83 [12240/17352 (71%)] Loss: -200334.984375\n",
      "Train Epoch: 83 [12320/17352 (71%)] Loss: -199714.046875\n",
      "Train Epoch: 83 [12400/17352 (71%)] Loss: -165607.312500\n",
      "Train Epoch: 83 [12480/17352 (72%)] Loss: -206231.734375\n",
      "Train Epoch: 83 [12560/17352 (72%)] Loss: -191806.687500\n",
      "Train Epoch: 83 [12640/17352 (73%)] Loss: -195061.484375\n",
      "Train Epoch: 83 [12720/17352 (73%)] Loss: -148822.750000\n",
      "Train Epoch: 83 [12800/17352 (74%)] Loss: -163499.875000\n",
      "Train Epoch: 83 [12880/17352 (74%)] Loss: -188509.328125\n",
      "Train Epoch: 83 [12960/17352 (75%)] Loss: -180055.421875\n",
      "Train Epoch: 83 [13040/17352 (75%)] Loss: -191001.515625\n",
      "Train Epoch: 83 [13120/17352 (76%)] Loss: -187246.656250\n",
      "Train Epoch: 83 [13200/17352 (76%)] Loss: -159734.093750\n",
      "Train Epoch: 83 [13280/17352 (77%)] Loss: -167803.609375\n",
      "Train Epoch: 83 [13360/17352 (77%)] Loss: -180692.718750\n",
      "Train Epoch: 83 [13440/17352 (77%)] Loss: -163961.250000\n",
      "Train Epoch: 83 [13520/17352 (78%)] Loss: -167215.765625\n",
      "Train Epoch: 83 [13600/17352 (78%)] Loss: -164877.734375\n",
      "Train Epoch: 83 [13680/17352 (79%)] Loss: -178604.968750\n",
      "Train Epoch: 83 [13760/17352 (79%)] Loss: -192286.218750\n",
      "Train Epoch: 83 [13840/17352 (80%)] Loss: -152909.718750\n",
      "Train Epoch: 83 [13920/17352 (80%)] Loss: -195004.781250\n",
      "Train Epoch: 83 [14000/17352 (81%)] Loss: -185544.546875\n",
      "Train Epoch: 83 [14080/17352 (81%)] Loss: -166029.046875\n",
      "Train Epoch: 83 [14160/17352 (82%)] Loss: -183727.500000\n",
      "Train Epoch: 83 [14240/17352 (82%)] Loss: -158748.062500\n",
      "Train Epoch: 83 [14320/17352 (83%)] Loss: -184950.000000\n",
      "Train Epoch: 83 [14400/17352 (83%)] Loss: -196280.750000\n",
      "Train Epoch: 83 [14480/17352 (83%)] Loss: -210553.078125\n",
      "Train Epoch: 83 [14560/17352 (84%)] Loss: -201936.640625\n",
      "Train Epoch: 83 [14640/17352 (84%)] Loss: -182924.609375\n",
      "Train Epoch: 83 [14720/17352 (85%)] Loss: -159091.109375\n",
      "Train Epoch: 83 [14800/17352 (85%)] Loss: -180514.656250\n",
      "Train Epoch: 83 [14880/17352 (86%)] Loss: -189564.812500\n",
      "Train Epoch: 83 [14960/17352 (86%)] Loss: -171189.453125\n",
      "Train Epoch: 83 [15040/17352 (87%)] Loss: -193509.078125\n",
      "Train Epoch: 83 [15120/17352 (87%)] Loss: -199892.609375\n",
      "Train Epoch: 83 [15200/17352 (88%)] Loss: -172557.218750\n",
      "Train Epoch: 83 [15280/17352 (88%)] Loss: -164368.250000\n",
      "Train Epoch: 83 [15360/17352 (89%)] Loss: -201261.921875\n",
      "Train Epoch: 83 [15440/17352 (89%)] Loss: -206473.031250\n",
      "Train Epoch: 83 [15520/17352 (89%)] Loss: -188971.234375\n",
      "Train Epoch: 83 [15600/17352 (90%)] Loss: -202993.453125\n",
      "Train Epoch: 83 [15680/17352 (90%)] Loss: -194952.781250\n",
      "Train Epoch: 83 [15760/17352 (91%)] Loss: -205692.859375\n",
      "Train Epoch: 83 [15840/17352 (91%)] Loss: -218745.437500\n",
      "Train Epoch: 83 [15920/17352 (92%)] Loss: -187515.609375\n",
      "Train Epoch: 83 [16000/17352 (92%)] Loss: -163771.000000\n",
      "Train Epoch: 83 [16080/17352 (93%)] Loss: -188007.171875\n",
      "Train Epoch: 83 [16160/17352 (93%)] Loss: -228098.468750\n",
      "Train Epoch: 83 [16240/17352 (94%)] Loss: -172617.718750\n",
      "Train Epoch: 83 [16320/17352 (94%)] Loss: -169612.546875\n",
      "Train Epoch: 83 [16400/17352 (95%)] Loss: -185791.140625\n",
      "Train Epoch: 83 [16480/17352 (95%)] Loss: -205213.953125\n",
      "Train Epoch: 83 [16560/17352 (95%)] Loss: -190938.218750\n",
      "Train Epoch: 83 [16640/17352 (96%)] Loss: -179308.125000\n",
      "Train Epoch: 83 [16720/17352 (96%)] Loss: -192791.906250\n",
      "Train Epoch: 83 [16800/17352 (97%)] Loss: -204490.640625\n",
      "Train Epoch: 83 [16880/17352 (97%)] Loss: -187952.531250\n",
      "Train Epoch: 83 [16960/17352 (98%)] Loss: -166786.812500\n",
      "Train Epoch: 83 [17040/17352 (98%)] Loss: -170234.343750\n",
      "Train Epoch: 83 [17120/17352 (99%)] Loss: -190478.765625\n",
      "Train Epoch: 83 [17200/17352 (99%)] Loss: -179172.296875\n",
      "Train Epoch: 83 [17280/17352 (100%)] Loss: -192121.375000\n",
      "Train Epoch: 83 [17360/17352 (100%)] Loss: -167731.609375\n",
      "    epoch          : 83\n",
      "    loss           : -189392.22778516973\n",
      "    val_loss       : -23716.289521194958\n",
      "Train Epoch: 84 [0/17352 (0%)] Loss: -185153.734375\n",
      "Train Epoch: 84 [80/17352 (0%)] Loss: -229958.718750\n",
      "Train Epoch: 84 [160/17352 (1%)] Loss: -219201.468750\n",
      "Train Epoch: 84 [240/17352 (1%)] Loss: -199908.843750\n",
      "Train Epoch: 84 [320/17352 (2%)] Loss: -213345.281250\n",
      "Train Epoch: 84 [400/17352 (2%)] Loss: -203746.937500\n",
      "Train Epoch: 84 [480/17352 (3%)] Loss: -214419.390625\n",
      "Train Epoch: 84 [560/17352 (3%)] Loss: -215486.515625\n",
      "Train Epoch: 84 [640/17352 (4%)] Loss: -203266.781250\n",
      "Train Epoch: 84 [720/17352 (4%)] Loss: -212372.750000\n",
      "Train Epoch: 84 [800/17352 (5%)] Loss: -205212.750000\n",
      "Train Epoch: 84 [880/17352 (5%)] Loss: -193716.500000\n",
      "Train Epoch: 84 [960/17352 (6%)] Loss: -182779.140625\n",
      "Train Epoch: 84 [1040/17352 (6%)] Loss: -202034.656250\n",
      "Train Epoch: 84 [1120/17352 (6%)] Loss: -206148.859375\n",
      "Train Epoch: 84 [1200/17352 (7%)] Loss: -230189.078125\n",
      "Train Epoch: 84 [1280/17352 (7%)] Loss: -204534.859375\n",
      "Train Epoch: 84 [1360/17352 (8%)] Loss: -193028.093750\n",
      "Train Epoch: 84 [1440/17352 (8%)] Loss: -231324.296875\n",
      "Train Epoch: 84 [1520/17352 (9%)] Loss: -206751.437500\n",
      "Train Epoch: 84 [1600/17352 (9%)] Loss: -210752.953125\n",
      "Train Epoch: 84 [1680/17352 (10%)] Loss: -210631.437500\n",
      "Train Epoch: 84 [1760/17352 (10%)] Loss: -216090.265625\n",
      "Train Epoch: 84 [1840/17352 (11%)] Loss: -236833.125000\n",
      "Train Epoch: 84 [1920/17352 (11%)] Loss: -212701.812500\n",
      "Train Epoch: 84 [2000/17352 (12%)] Loss: -205565.140625\n",
      "Train Epoch: 84 [2080/17352 (12%)] Loss: -228016.156250\n",
      "Train Epoch: 84 [2160/17352 (12%)] Loss: -212394.484375\n",
      "Train Epoch: 84 [2240/17352 (13%)] Loss: -192245.140625\n",
      "Train Epoch: 84 [2320/17352 (13%)] Loss: -167144.000000\n",
      "Train Epoch: 84 [2400/17352 (14%)] Loss: -183503.109375\n",
      "Train Epoch: 84 [2480/17352 (14%)] Loss: -172960.812500\n",
      "Train Epoch: 84 [2560/17352 (15%)] Loss: -175546.015625\n",
      "Train Epoch: 84 [2640/17352 (15%)] Loss: -183388.578125\n",
      "Train Epoch: 84 [2720/17352 (16%)] Loss: -186945.890625\n",
      "Train Epoch: 84 [2800/17352 (16%)] Loss: -193181.500000\n",
      "Train Epoch: 84 [2880/17352 (17%)] Loss: -201941.281250\n",
      "Train Epoch: 84 [2960/17352 (17%)] Loss: -187219.031250\n",
      "Train Epoch: 84 [3040/17352 (18%)] Loss: -204662.343750\n",
      "Train Epoch: 84 [3120/17352 (18%)] Loss: -201120.718750\n",
      "Train Epoch: 84 [3200/17352 (18%)] Loss: -195004.703125\n",
      "Train Epoch: 84 [3280/17352 (19%)] Loss: -200866.875000\n",
      "Train Epoch: 84 [3360/17352 (19%)] Loss: -199417.375000\n",
      "Train Epoch: 84 [3440/17352 (20%)] Loss: -197543.765625\n",
      "Train Epoch: 84 [3520/17352 (20%)] Loss: -186041.812500\n",
      "Train Epoch: 84 [3600/17352 (21%)] Loss: -187529.828125\n",
      "Train Epoch: 84 [3680/17352 (21%)] Loss: -176060.640625\n",
      "Train Epoch: 84 [3760/17352 (22%)] Loss: -187325.375000\n",
      "Train Epoch: 84 [3840/17352 (22%)] Loss: -191506.859375\n",
      "Train Epoch: 84 [3920/17352 (23%)] Loss: -169950.687500\n",
      "Train Epoch: 84 [4000/17352 (23%)] Loss: -208124.625000\n",
      "Train Epoch: 84 [4080/17352 (24%)] Loss: -176085.250000\n",
      "Train Epoch: 84 [4160/17352 (24%)] Loss: -162968.453125\n",
      "Train Epoch: 84 [4240/17352 (24%)] Loss: -185928.343750\n",
      "Train Epoch: 84 [4320/17352 (25%)] Loss: -176896.406250\n",
      "Train Epoch: 84 [4400/17352 (25%)] Loss: -180750.734375\n",
      "Train Epoch: 84 [4480/17352 (26%)] Loss: -166675.406250\n",
      "Train Epoch: 84 [4560/17352 (26%)] Loss: -169451.593750\n",
      "Train Epoch: 84 [4640/17352 (27%)] Loss: -200170.015625\n",
      "Train Epoch: 84 [4720/17352 (27%)] Loss: -195373.218750\n",
      "Train Epoch: 84 [4800/17352 (28%)] Loss: -161678.125000\n",
      "Train Epoch: 84 [4880/17352 (28%)] Loss: -174946.515625\n",
      "Train Epoch: 84 [4960/17352 (29%)] Loss: -169975.453125\n",
      "Train Epoch: 84 [5040/17352 (29%)] Loss: -203882.453125\n",
      "Train Epoch: 84 [5120/17352 (30%)] Loss: -178635.812500\n",
      "Train Epoch: 84 [5200/17352 (30%)] Loss: -176541.390625\n",
      "Train Epoch: 84 [5280/17352 (30%)] Loss: -172199.640625\n",
      "Train Epoch: 84 [5360/17352 (31%)] Loss: -190986.218750\n",
      "Train Epoch: 84 [5440/17352 (31%)] Loss: -184063.640625\n",
      "Train Epoch: 84 [5520/17352 (32%)] Loss: -186724.031250\n",
      "Train Epoch: 84 [5600/17352 (32%)] Loss: -161962.453125\n",
      "Train Epoch: 84 [5680/17352 (33%)] Loss: -197653.703125\n",
      "Train Epoch: 84 [5760/17352 (33%)] Loss: -184496.500000\n",
      "Train Epoch: 84 [5840/17352 (34%)] Loss: -180158.000000\n",
      "Train Epoch: 84 [5920/17352 (34%)] Loss: -197322.250000\n",
      "Train Epoch: 84 [6000/17352 (35%)] Loss: -171726.343750\n",
      "Train Epoch: 84 [6080/17352 (35%)] Loss: -203143.562500\n",
      "Train Epoch: 84 [6160/17352 (36%)] Loss: -208424.515625\n",
      "Train Epoch: 84 [6240/17352 (36%)] Loss: -203513.718750\n",
      "Train Epoch: 84 [6320/17352 (36%)] Loss: -180886.921875\n",
      "Train Epoch: 84 [6400/17352 (37%)] Loss: -184743.328125\n",
      "Train Epoch: 84 [6480/17352 (37%)] Loss: -174628.125000\n",
      "Train Epoch: 84 [6560/17352 (38%)] Loss: -180905.187500\n",
      "Train Epoch: 84 [6640/17352 (38%)] Loss: -168509.640625\n",
      "Train Epoch: 84 [6720/17352 (39%)] Loss: -200636.640625\n",
      "Train Epoch: 84 [6800/17352 (39%)] Loss: -193919.093750\n",
      "Train Epoch: 84 [6880/17352 (40%)] Loss: -143625.656250\n",
      "Train Epoch: 84 [6960/17352 (40%)] Loss: -192885.687500\n",
      "Train Epoch: 84 [7040/17352 (41%)] Loss: -184984.859375\n",
      "Train Epoch: 84 [7120/17352 (41%)] Loss: -159313.062500\n",
      "Train Epoch: 84 [7200/17352 (41%)] Loss: -195838.937500\n",
      "Train Epoch: 84 [7280/17352 (42%)] Loss: -191883.968750\n",
      "Train Epoch: 84 [7360/17352 (42%)] Loss: -210795.156250\n",
      "Train Epoch: 84 [7440/17352 (43%)] Loss: -191044.203125\n",
      "Train Epoch: 84 [7520/17352 (43%)] Loss: -170769.859375\n",
      "Train Epoch: 84 [7600/17352 (44%)] Loss: -186499.687500\n",
      "Train Epoch: 84 [7680/17352 (44%)] Loss: -177476.562500\n",
      "Train Epoch: 84 [7760/17352 (45%)] Loss: -178430.953125\n",
      "Train Epoch: 84 [7840/17352 (45%)] Loss: -205405.640625\n",
      "Train Epoch: 84 [7920/17352 (46%)] Loss: -203678.875000\n",
      "Train Epoch: 84 [8000/17352 (46%)] Loss: -191809.468750\n",
      "Train Epoch: 84 [8080/17352 (47%)] Loss: -172552.562500\n",
      "Train Epoch: 84 [8160/17352 (47%)] Loss: -190480.062500\n",
      "Train Epoch: 84 [8240/17352 (47%)] Loss: -203885.265625\n",
      "Train Epoch: 84 [8320/17352 (48%)] Loss: -187322.703125\n",
      "Train Epoch: 84 [8400/17352 (48%)] Loss: -180645.984375\n",
      "Train Epoch: 84 [8480/17352 (49%)] Loss: -201096.703125\n",
      "Train Epoch: 84 [8560/17352 (49%)] Loss: -148401.296875\n",
      "Train Epoch: 84 [8640/17352 (50%)] Loss: -144991.843750\n",
      "Train Epoch: 84 [8720/17352 (50%)] Loss: -204616.187500\n",
      "Train Epoch: 84 [8800/17352 (51%)] Loss: -179973.687500\n",
      "Train Epoch: 84 [8880/17352 (51%)] Loss: -188572.437500\n",
      "Train Epoch: 84 [8960/17352 (52%)] Loss: -188152.812500\n",
      "Train Epoch: 84 [9040/17352 (52%)] Loss: -152907.734375\n",
      "Train Epoch: 84 [9120/17352 (53%)] Loss: -185394.656250\n",
      "Train Epoch: 84 [9200/17352 (53%)] Loss: -180695.375000\n",
      "Train Epoch: 84 [9280/17352 (53%)] Loss: -202993.312500\n",
      "Train Epoch: 84 [9360/17352 (54%)] Loss: -178213.000000\n",
      "Train Epoch: 84 [9440/17352 (54%)] Loss: -180838.843750\n",
      "Train Epoch: 84 [9520/17352 (55%)] Loss: -178661.515625\n",
      "Train Epoch: 84 [9600/17352 (55%)] Loss: -163554.000000\n",
      "Train Epoch: 84 [9680/17352 (56%)] Loss: -188817.046875\n",
      "Train Epoch: 84 [9760/17352 (56%)] Loss: -183405.296875\n",
      "Train Epoch: 84 [9840/17352 (57%)] Loss: -173304.328125\n",
      "Train Epoch: 84 [9920/17352 (57%)] Loss: -198826.515625\n",
      "Train Epoch: 84 [10000/17352 (58%)] Loss: -191970.375000\n",
      "Train Epoch: 84 [10080/17352 (58%)] Loss: -183609.296875\n",
      "Train Epoch: 84 [10160/17352 (59%)] Loss: -163966.546875\n",
      "Train Epoch: 84 [10240/17352 (59%)] Loss: -202978.843750\n",
      "Train Epoch: 84 [10320/17352 (59%)] Loss: -181014.406250\n",
      "Train Epoch: 84 [10400/17352 (60%)] Loss: -178604.531250\n",
      "Train Epoch: 84 [10480/17352 (60%)] Loss: -164076.531250\n",
      "Train Epoch: 84 [10560/17352 (61%)] Loss: -201384.031250\n",
      "Train Epoch: 84 [10640/17352 (61%)] Loss: -166794.343750\n",
      "Train Epoch: 84 [10720/17352 (62%)] Loss: -181544.375000\n",
      "Train Epoch: 84 [10800/17352 (62%)] Loss: -206564.546875\n",
      "Train Epoch: 84 [10880/17352 (63%)] Loss: -176881.546875\n",
      "Train Epoch: 84 [10960/17352 (63%)] Loss: -193946.421875\n",
      "Train Epoch: 84 [11040/17352 (64%)] Loss: -185006.421875\n",
      "Train Epoch: 84 [11120/17352 (64%)] Loss: -177729.031250\n",
      "Train Epoch: 84 [11200/17352 (65%)] Loss: -224870.390625\n",
      "Train Epoch: 84 [11280/17352 (65%)] Loss: -202238.140625\n",
      "Train Epoch: 84 [11360/17352 (65%)] Loss: -178134.781250\n",
      "Train Epoch: 84 [11440/17352 (66%)] Loss: -206601.078125\n",
      "Train Epoch: 84 [11520/17352 (66%)] Loss: -196813.953125\n",
      "Train Epoch: 84 [11600/17352 (67%)] Loss: -189798.750000\n",
      "Train Epoch: 84 [11680/17352 (67%)] Loss: -192237.671875\n",
      "Train Epoch: 84 [11760/17352 (68%)] Loss: -195792.140625\n",
      "Train Epoch: 84 [11840/17352 (68%)] Loss: -156475.468750\n",
      "Train Epoch: 84 [11920/17352 (69%)] Loss: -189217.343750\n",
      "Train Epoch: 84 [12000/17352 (69%)] Loss: -182399.171875\n",
      "Train Epoch: 84 [12080/17352 (70%)] Loss: -189607.625000\n",
      "Train Epoch: 84 [12160/17352 (70%)] Loss: -204346.546875\n",
      "Train Epoch: 84 [12240/17352 (71%)] Loss: -201375.796875\n",
      "Train Epoch: 84 [12320/17352 (71%)] Loss: -193798.093750\n",
      "Train Epoch: 84 [12400/17352 (71%)] Loss: -153889.312500\n",
      "Train Epoch: 84 [12480/17352 (72%)] Loss: -183625.718750\n",
      "Train Epoch: 84 [12560/17352 (72%)] Loss: -171324.093750\n",
      "Train Epoch: 84 [12640/17352 (73%)] Loss: -177583.140625\n",
      "Train Epoch: 84 [12720/17352 (73%)] Loss: -227895.031250\n",
      "Train Epoch: 84 [12800/17352 (74%)] Loss: -188440.109375\n",
      "Train Epoch: 84 [12880/17352 (74%)] Loss: -202941.062500\n",
      "Train Epoch: 84 [12960/17352 (75%)] Loss: -149333.531250\n",
      "Train Epoch: 84 [13040/17352 (75%)] Loss: -164368.140625\n",
      "Train Epoch: 84 [13120/17352 (76%)] Loss: -167884.281250\n",
      "Train Epoch: 84 [13200/17352 (76%)] Loss: -183080.062500\n",
      "Train Epoch: 84 [13280/17352 (77%)] Loss: -207089.031250\n",
      "Train Epoch: 84 [13360/17352 (77%)] Loss: -193266.906250\n",
      "Train Epoch: 84 [13440/17352 (77%)] Loss: -231044.109375\n",
      "Train Epoch: 84 [13520/17352 (78%)] Loss: -204342.718750\n",
      "Train Epoch: 84 [13600/17352 (78%)] Loss: -185794.218750\n",
      "Train Epoch: 84 [13680/17352 (79%)] Loss: -196701.437500\n",
      "Train Epoch: 84 [13760/17352 (79%)] Loss: -168192.734375\n",
      "Train Epoch: 84 [13840/17352 (80%)] Loss: -187957.906250\n",
      "Train Epoch: 84 [13920/17352 (80%)] Loss: -196029.078125\n",
      "Train Epoch: 84 [14000/17352 (81%)] Loss: -177470.515625\n",
      "Train Epoch: 84 [14080/17352 (81%)] Loss: -179388.875000\n",
      "Train Epoch: 84 [14160/17352 (82%)] Loss: -196136.406250\n",
      "Train Epoch: 84 [14240/17352 (82%)] Loss: -180293.531250\n",
      "Train Epoch: 84 [14320/17352 (83%)] Loss: -174550.953125\n",
      "Train Epoch: 84 [14400/17352 (83%)] Loss: -158254.046875\n",
      "Train Epoch: 84 [14480/17352 (83%)] Loss: -188501.203125\n",
      "Train Epoch: 84 [14560/17352 (84%)] Loss: -171836.656250\n",
      "Train Epoch: 84 [14640/17352 (84%)] Loss: -193098.000000\n",
      "Train Epoch: 84 [14720/17352 (85%)] Loss: -188092.234375\n",
      "Train Epoch: 84 [14800/17352 (85%)] Loss: -191314.750000\n",
      "Train Epoch: 84 [14880/17352 (86%)] Loss: -201036.656250\n",
      "Train Epoch: 84 [14960/17352 (86%)] Loss: -175023.515625\n",
      "Train Epoch: 84 [15040/17352 (87%)] Loss: -178596.812500\n",
      "Train Epoch: 84 [15120/17352 (87%)] Loss: -199071.437500\n",
      "Train Epoch: 84 [15200/17352 (88%)] Loss: -189510.406250\n",
      "Train Epoch: 84 [15280/17352 (88%)] Loss: -187320.562500\n",
      "Train Epoch: 84 [15360/17352 (89%)] Loss: -183870.546875\n",
      "Train Epoch: 84 [15440/17352 (89%)] Loss: -181674.140625\n",
      "Train Epoch: 84 [15520/17352 (89%)] Loss: -196445.140625\n",
      "Train Epoch: 84 [15600/17352 (90%)] Loss: -181887.890625\n",
      "Train Epoch: 84 [15680/17352 (90%)] Loss: -183224.140625\n",
      "Train Epoch: 84 [15760/17352 (91%)] Loss: -202190.390625\n",
      "Train Epoch: 84 [15840/17352 (91%)] Loss: -193004.937500\n",
      "Train Epoch: 84 [15920/17352 (92%)] Loss: -181914.265625\n",
      "Train Epoch: 84 [16000/17352 (92%)] Loss: -192899.828125\n",
      "Train Epoch: 84 [16080/17352 (93%)] Loss: -193447.859375\n",
      "Train Epoch: 84 [16160/17352 (93%)] Loss: -203275.328125\n",
      "Train Epoch: 84 [16240/17352 (94%)] Loss: -170108.406250\n",
      "Train Epoch: 84 [16320/17352 (94%)] Loss: -195837.000000\n",
      "Train Epoch: 84 [16400/17352 (95%)] Loss: -162566.265625\n",
      "Train Epoch: 84 [16480/17352 (95%)] Loss: -176973.390625\n",
      "Train Epoch: 84 [16560/17352 (95%)] Loss: -184280.406250\n",
      "Train Epoch: 84 [16640/17352 (96%)] Loss: -177306.812500\n",
      "Train Epoch: 84 [16720/17352 (96%)] Loss: -204211.609375\n",
      "Train Epoch: 84 [16800/17352 (97%)] Loss: -194587.937500\n",
      "Train Epoch: 84 [16880/17352 (97%)] Loss: -205722.156250\n",
      "Train Epoch: 84 [16960/17352 (98%)] Loss: -168074.203125\n",
      "Train Epoch: 84 [17040/17352 (98%)] Loss: -180703.343750\n",
      "Train Epoch: 84 [17120/17352 (99%)] Loss: -197518.281250\n",
      "Train Epoch: 84 [17200/17352 (99%)] Loss: -192121.375000\n",
      "Train Epoch: 84 [17280/17352 (100%)] Loss: -187774.609375\n",
      "Train Epoch: 84 [17360/17352 (100%)] Loss: -200203.562500\n",
      "    epoch          : 84\n",
      "    loss           : -189286.57389959725\n",
      "    val_loss       : -23716.236163215457\n",
      "Train Epoch: 85 [0/17352 (0%)] Loss: -236638.781250\n",
      "Train Epoch: 85 [80/17352 (0%)] Loss: -200600.218750\n",
      "Train Epoch: 85 [160/17352 (1%)] Loss: -230194.531250\n",
      "Train Epoch: 85 [240/17352 (1%)] Loss: -211097.843750\n",
      "Train Epoch: 85 [320/17352 (2%)] Loss: -203267.328125\n",
      "Train Epoch: 85 [400/17352 (2%)] Loss: -202266.203125\n",
      "Train Epoch: 85 [480/17352 (3%)] Loss: -210627.687500\n",
      "Train Epoch: 85 [560/17352 (3%)] Loss: -218568.625000\n",
      "Train Epoch: 85 [640/17352 (4%)] Loss: -205109.656250\n",
      "Train Epoch: 85 [720/17352 (4%)] Loss: -199103.921875\n",
      "Train Epoch: 85 [800/17352 (5%)] Loss: -210207.906250\n",
      "Train Epoch: 85 [880/17352 (5%)] Loss: -224242.078125\n",
      "Train Epoch: 85 [960/17352 (6%)] Loss: -205195.984375\n",
      "Train Epoch: 85 [1040/17352 (6%)] Loss: -208382.328125\n",
      "Train Epoch: 85 [1120/17352 (6%)] Loss: -208541.968750\n",
      "Train Epoch: 85 [1200/17352 (7%)] Loss: -187721.250000\n",
      "Train Epoch: 85 [1280/17352 (7%)] Loss: -182781.453125\n",
      "Train Epoch: 85 [1360/17352 (8%)] Loss: -204034.500000\n",
      "Train Epoch: 85 [1440/17352 (8%)] Loss: -241901.265625\n",
      "Train Epoch: 85 [1520/17352 (9%)] Loss: -229243.406250\n",
      "Train Epoch: 85 [1600/17352 (9%)] Loss: -218533.343750\n",
      "Train Epoch: 85 [1680/17352 (10%)] Loss: -210525.546875\n",
      "Train Epoch: 85 [1760/17352 (10%)] Loss: -214524.500000\n",
      "Train Epoch: 85 [1840/17352 (11%)] Loss: -213348.031250\n",
      "Train Epoch: 85 [1920/17352 (11%)] Loss: -213321.312500\n",
      "Train Epoch: 85 [2000/17352 (12%)] Loss: -231329.531250\n",
      "Train Epoch: 85 [2080/17352 (12%)] Loss: -214461.562500\n",
      "Train Epoch: 85 [2160/17352 (12%)] Loss: -185289.390625\n",
      "Train Epoch: 85 [2240/17352 (13%)] Loss: -205530.656250\n",
      "Train Epoch: 85 [2320/17352 (13%)] Loss: -173661.359375\n",
      "Train Epoch: 85 [2400/17352 (14%)] Loss: -203871.515625\n",
      "Train Epoch: 85 [2480/17352 (14%)] Loss: -191558.468750\n",
      "Train Epoch: 85 [2560/17352 (15%)] Loss: -184924.359375\n",
      "Train Epoch: 85 [2640/17352 (15%)] Loss: -148512.765625\n",
      "Train Epoch: 85 [2720/17352 (16%)] Loss: -151509.015625\n",
      "Train Epoch: 85 [2800/17352 (16%)] Loss: -231033.265625\n",
      "Train Epoch: 85 [2880/17352 (17%)] Loss: -210493.828125\n",
      "Train Epoch: 85 [2960/17352 (17%)] Loss: -196301.921875\n",
      "Train Epoch: 85 [3040/17352 (18%)] Loss: -186192.593750\n",
      "Train Epoch: 85 [3120/17352 (18%)] Loss: -201976.796875\n",
      "Train Epoch: 85 [3200/17352 (18%)] Loss: -190217.953125\n",
      "Train Epoch: 85 [3280/17352 (19%)] Loss: -189505.828125\n",
      "Train Epoch: 85 [3360/17352 (19%)] Loss: -189803.562500\n",
      "Train Epoch: 85 [3440/17352 (20%)] Loss: -181016.328125\n",
      "Train Epoch: 85 [3520/17352 (20%)] Loss: -185041.609375\n",
      "Train Epoch: 85 [3600/17352 (21%)] Loss: -204696.984375\n",
      "Train Epoch: 85 [3680/17352 (21%)] Loss: -181962.312500\n",
      "Train Epoch: 85 [3760/17352 (22%)] Loss: -176058.125000\n",
      "Train Epoch: 85 [3840/17352 (22%)] Loss: -187258.390625\n",
      "Train Epoch: 85 [3920/17352 (23%)] Loss: -179894.968750\n",
      "Train Epoch: 85 [4000/17352 (23%)] Loss: -192642.812500\n",
      "Train Epoch: 85 [4080/17352 (24%)] Loss: -197567.968750\n",
      "Train Epoch: 85 [4160/17352 (24%)] Loss: -166435.109375\n",
      "Train Epoch: 85 [4240/17352 (24%)] Loss: -138339.062500\n",
      "Train Epoch: 85 [4320/17352 (25%)] Loss: -186495.640625\n",
      "Train Epoch: 85 [4400/17352 (25%)] Loss: -186685.031250\n",
      "Train Epoch: 85 [4480/17352 (26%)] Loss: -174875.937500\n",
      "Train Epoch: 85 [4560/17352 (26%)] Loss: -183630.906250\n",
      "Train Epoch: 85 [4640/17352 (27%)] Loss: -179967.234375\n",
      "Train Epoch: 85 [4720/17352 (27%)] Loss: -180991.421875\n",
      "Train Epoch: 85 [4800/17352 (28%)] Loss: -201098.593750\n",
      "Train Epoch: 85 [4880/17352 (28%)] Loss: -197603.640625\n",
      "Train Epoch: 85 [4960/17352 (29%)] Loss: -164955.046875\n",
      "Train Epoch: 85 [5040/17352 (29%)] Loss: -193362.921875\n",
      "Train Epoch: 85 [5120/17352 (30%)] Loss: -184456.937500\n",
      "Train Epoch: 85 [5200/17352 (30%)] Loss: -200128.031250\n",
      "Train Epoch: 85 [5280/17352 (30%)] Loss: -205643.921875\n",
      "Train Epoch: 85 [5360/17352 (31%)] Loss: -164878.468750\n",
      "Train Epoch: 85 [5440/17352 (31%)] Loss: -192318.656250\n",
      "Train Epoch: 85 [5520/17352 (32%)] Loss: -196128.218750\n",
      "Train Epoch: 85 [5600/17352 (32%)] Loss: -181696.156250\n",
      "Train Epoch: 85 [5680/17352 (33%)] Loss: -188677.328125\n",
      "Train Epoch: 85 [5760/17352 (33%)] Loss: -163768.265625\n",
      "Train Epoch: 85 [5840/17352 (34%)] Loss: -198015.625000\n",
      "Train Epoch: 85 [5920/17352 (34%)] Loss: -203851.046875\n",
      "Train Epoch: 85 [6000/17352 (35%)] Loss: -190478.953125\n",
      "Train Epoch: 85 [6080/17352 (35%)] Loss: -210638.859375\n",
      "Train Epoch: 85 [6160/17352 (36%)] Loss: -218848.953125\n",
      "Train Epoch: 85 [6240/17352 (36%)] Loss: -189613.765625\n",
      "Train Epoch: 85 [6320/17352 (36%)] Loss: -200423.968750\n",
      "Train Epoch: 85 [6400/17352 (37%)] Loss: -200271.015625\n",
      "Train Epoch: 85 [6480/17352 (37%)] Loss: -176972.531250\n",
      "Train Epoch: 85 [6560/17352 (38%)] Loss: -203432.250000\n",
      "Train Epoch: 85 [6640/17352 (38%)] Loss: -167484.375000\n",
      "Train Epoch: 85 [6720/17352 (39%)] Loss: -187308.531250\n",
      "Train Epoch: 85 [6800/17352 (39%)] Loss: -181974.515625\n",
      "Train Epoch: 85 [6880/17352 (40%)] Loss: -155862.921875\n",
      "Train Epoch: 85 [6960/17352 (40%)] Loss: -192016.078125\n",
      "Train Epoch: 85 [7040/17352 (41%)] Loss: -205021.406250\n",
      "Train Epoch: 85 [7120/17352 (41%)] Loss: -189736.375000\n",
      "Train Epoch: 85 [7200/17352 (41%)] Loss: -195060.546875\n",
      "Train Epoch: 85 [7280/17352 (42%)] Loss: -192789.796875\n",
      "Train Epoch: 85 [7360/17352 (42%)] Loss: -185177.687500\n",
      "Train Epoch: 85 [7440/17352 (43%)] Loss: -192378.500000\n",
      "Train Epoch: 85 [7520/17352 (43%)] Loss: -208425.125000\n",
      "Train Epoch: 85 [7600/17352 (44%)] Loss: -185317.203125\n",
      "Train Epoch: 85 [7680/17352 (44%)] Loss: -170033.796875\n",
      "Train Epoch: 85 [7760/17352 (45%)] Loss: -179420.531250\n",
      "Train Epoch: 85 [7840/17352 (45%)] Loss: -189493.312500\n",
      "Train Epoch: 85 [7920/17352 (46%)] Loss: -181676.343750\n",
      "Train Epoch: 85 [8000/17352 (46%)] Loss: -171717.437500\n",
      "Train Epoch: 85 [8080/17352 (47%)] Loss: -174543.531250\n",
      "Train Epoch: 85 [8160/17352 (47%)] Loss: -206927.453125\n",
      "Train Epoch: 85 [8240/17352 (47%)] Loss: -184256.125000\n",
      "Train Epoch: 85 [8320/17352 (48%)] Loss: -195381.578125\n",
      "Train Epoch: 85 [8400/17352 (48%)] Loss: -192395.000000\n",
      "Train Epoch: 85 [8480/17352 (49%)] Loss: -213228.750000\n",
      "Train Epoch: 85 [8560/17352 (49%)] Loss: -154604.656250\n",
      "Train Epoch: 85 [8640/17352 (50%)] Loss: -193353.875000\n",
      "Train Epoch: 85 [8720/17352 (50%)] Loss: -152902.500000\n",
      "Train Epoch: 85 [8800/17352 (51%)] Loss: -200979.031250\n",
      "Train Epoch: 85 [8880/17352 (51%)] Loss: -168199.953125\n",
      "Train Epoch: 85 [8960/17352 (52%)] Loss: -209827.312500\n",
      "Train Epoch: 85 [9040/17352 (52%)] Loss: -202986.015625\n",
      "Train Epoch: 85 [9120/17352 (53%)] Loss: -196037.421875\n",
      "Train Epoch: 85 [9200/17352 (53%)] Loss: -191813.421875\n",
      "Train Epoch: 85 [9280/17352 (53%)] Loss: -180917.468750\n",
      "Train Epoch: 85 [9360/17352 (54%)] Loss: -202314.078125\n",
      "Train Epoch: 85 [9440/17352 (54%)] Loss: -193369.000000\n",
      "Train Epoch: 85 [9520/17352 (55%)] Loss: -203675.687500\n",
      "Train Epoch: 85 [9600/17352 (55%)] Loss: -210551.343750\n",
      "Train Epoch: 85 [9680/17352 (56%)] Loss: -169170.328125\n",
      "Train Epoch: 85 [9760/17352 (56%)] Loss: -207130.843750\n",
      "Train Epoch: 85 [9840/17352 (57%)] Loss: -204422.359375\n",
      "Train Epoch: 85 [9920/17352 (57%)] Loss: -187324.000000\n",
      "Train Epoch: 85 [10000/17352 (58%)] Loss: -168254.765625\n",
      "Train Epoch: 85 [10080/17352 (58%)] Loss: -193446.656250\n",
      "Train Epoch: 85 [10160/17352 (59%)] Loss: -177732.968750\n",
      "Train Epoch: 85 [10240/17352 (59%)] Loss: -179307.562500\n",
      "Train Epoch: 85 [10320/17352 (59%)] Loss: -192954.546875\n",
      "Train Epoch: 85 [10400/17352 (60%)] Loss: -175399.203125\n",
      "Train Epoch: 85 [10480/17352 (60%)] Loss: -166257.078125\n",
      "Train Epoch: 85 [10560/17352 (61%)] Loss: -178660.859375\n",
      "Train Epoch: 85 [10640/17352 (61%)] Loss: -210790.031250\n",
      "Train Epoch: 85 [10720/17352 (62%)] Loss: -180255.812500\n",
      "Train Epoch: 85 [10800/17352 (62%)] Loss: -191312.906250\n",
      "Train Epoch: 85 [10880/17352 (63%)] Loss: -156475.359375\n",
      "Train Epoch: 85 [10960/17352 (63%)] Loss: -199781.718750\n",
      "Train Epoch: 85 [11040/17352 (64%)] Loss: -216328.843750\n",
      "Train Epoch: 85 [11120/17352 (64%)] Loss: -184991.218750\n",
      "Train Epoch: 85 [11200/17352 (65%)] Loss: -183405.468750\n",
      "Train Epoch: 85 [11280/17352 (65%)] Loss: -213403.375000\n",
      "Train Epoch: 85 [11360/17352 (65%)] Loss: -196938.671875\n",
      "Train Epoch: 85 [11440/17352 (66%)] Loss: -199068.171875\n",
      "Train Epoch: 85 [11520/17352 (66%)] Loss: -182742.265625\n",
      "Train Epoch: 85 [11600/17352 (67%)] Loss: -206167.796875\n",
      "Train Epoch: 85 [11680/17352 (67%)] Loss: -178603.093750\n",
      "Train Epoch: 85 [11760/17352 (68%)] Loss: -187950.781250\n",
      "Train Epoch: 85 [11840/17352 (68%)] Loss: -197440.531250\n",
      "Train Epoch: 85 [11920/17352 (69%)] Loss: -200222.656250\n",
      "Train Epoch: 85 [12000/17352 (69%)] Loss: -188802.593750\n",
      "Train Epoch: 85 [12080/17352 (70%)] Loss: -218463.625000\n",
      "Train Epoch: 85 [12160/17352 (70%)] Loss: -168760.656250\n",
      "Train Epoch: 85 [12240/17352 (71%)] Loss: -175365.781250\n",
      "Train Epoch: 85 [12320/17352 (71%)] Loss: -167191.265625\n",
      "Train Epoch: 85 [12400/17352 (71%)] Loss: -191042.312500\n",
      "Train Epoch: 85 [12480/17352 (72%)] Loss: -199012.531250\n",
      "Train Epoch: 85 [12560/17352 (72%)] Loss: -180143.343750\n",
      "Train Epoch: 85 [12640/17352 (73%)] Loss: -149028.953125\n",
      "Train Epoch: 85 [12720/17352 (73%)] Loss: -178433.687500\n",
      "Train Epoch: 85 [12800/17352 (74%)] Loss: -171732.546875\n",
      "Train Epoch: 85 [12880/17352 (74%)] Loss: -165738.203125\n",
      "Train Epoch: 85 [12960/17352 (75%)] Loss: -188013.031250\n",
      "Train Epoch: 85 [13040/17352 (75%)] Loss: -158748.937500\n",
      "Train Epoch: 85 [13120/17352 (76%)] Loss: -193001.859375\n",
      "Train Epoch: 85 [13200/17352 (76%)] Loss: -208041.296875\n",
      "Train Epoch: 85 [13280/17352 (77%)] Loss: -194230.750000\n",
      "Train Epoch: 85 [13360/17352 (77%)] Loss: -172546.968750\n",
      "Train Epoch: 85 [13440/17352 (77%)] Loss: -169507.328125\n",
      "Train Epoch: 85 [13520/17352 (78%)] Loss: -202083.640625\n",
      "Train Epoch: 85 [13600/17352 (78%)] Loss: -202573.765625\n",
      "Train Epoch: 85 [13680/17352 (79%)] Loss: -169193.203125\n",
      "Train Epoch: 85 [13760/17352 (79%)] Loss: -204330.359375\n",
      "Train Epoch: 85 [13840/17352 (80%)] Loss: -177475.656250\n",
      "Train Epoch: 85 [13920/17352 (80%)] Loss: -190791.875000\n",
      "Train Epoch: 85 [14000/17352 (81%)] Loss: -179974.765625\n",
      "Train Epoch: 85 [14080/17352 (81%)] Loss: -210392.843750\n",
      "Train Epoch: 85 [14160/17352 (82%)] Loss: -216396.093750\n",
      "Train Epoch: 85 [14240/17352 (82%)] Loss: -175215.421875\n",
      "Train Epoch: 85 [14320/17352 (83%)] Loss: -162560.359375\n",
      "Train Epoch: 85 [14400/17352 (83%)] Loss: -186039.218750\n",
      "Train Epoch: 85 [14480/17352 (83%)] Loss: -136435.250000\n",
      "Train Epoch: 85 [14560/17352 (84%)] Loss: -177583.906250\n",
      "Train Epoch: 85 [14640/17352 (84%)] Loss: -182102.359375\n",
      "Train Epoch: 85 [14720/17352 (85%)] Loss: -192010.218750\n",
      "Train Epoch: 85 [14800/17352 (85%)] Loss: -191816.046875\n",
      "Train Epoch: 85 [14880/17352 (86%)] Loss: -161096.890625\n",
      "Train Epoch: 85 [14960/17352 (86%)] Loss: -188451.343750\n",
      "Train Epoch: 85 [15040/17352 (87%)] Loss: -174984.937500\n",
      "Train Epoch: 85 [15120/17352 (87%)] Loss: -223962.781250\n",
      "Train Epoch: 85 [15200/17352 (88%)] Loss: -183590.593750\n",
      "Train Epoch: 85 [15280/17352 (88%)] Loss: -183084.281250\n",
      "Train Epoch: 85 [15360/17352 (89%)] Loss: -182406.703125\n",
      "Train Epoch: 85 [15440/17352 (89%)] Loss: -170537.234375\n",
      "Train Epoch: 85 [15520/17352 (89%)] Loss: -190088.171875\n",
      "Train Epoch: 85 [15600/17352 (90%)] Loss: -177198.843750\n",
      "Train Epoch: 85 [15680/17352 (90%)] Loss: -178596.968750\n",
      "Train Epoch: 85 [15760/17352 (91%)] Loss: -177600.703125\n",
      "Train Epoch: 85 [15840/17352 (91%)] Loss: -175509.281250\n",
      "Train Epoch: 85 [15920/17352 (92%)] Loss: -181722.984375\n",
      "Train Epoch: 85 [16000/17352 (92%)] Loss: -212136.828125\n",
      "Train Epoch: 85 [16080/17352 (93%)] Loss: -193492.734375\n",
      "Train Epoch: 85 [16160/17352 (93%)] Loss: -168087.062500\n",
      "Train Epoch: 85 [16240/17352 (94%)] Loss: -196815.984375\n",
      "Train Epoch: 85 [16320/17352 (94%)] Loss: -179676.890625\n",
      "Train Epoch: 85 [16400/17352 (95%)] Loss: -190808.125000\n",
      "Train Epoch: 85 [16480/17352 (95%)] Loss: -200076.562500\n",
      "Train Epoch: 85 [16560/17352 (95%)] Loss: -156611.140625\n",
      "Train Epoch: 85 [16640/17352 (96%)] Loss: -190384.796875\n",
      "Train Epoch: 85 [16720/17352 (96%)] Loss: -184493.359375\n",
      "Train Epoch: 85 [16800/17352 (97%)] Loss: -205492.984375\n",
      "Train Epoch: 85 [16880/17352 (97%)] Loss: -186946.250000\n",
      "Train Epoch: 85 [16960/17352 (98%)] Loss: -210262.500000\n",
      "Train Epoch: 85 [17040/17352 (98%)] Loss: -189174.312500\n",
      "Train Epoch: 85 [17120/17352 (99%)] Loss: -167249.640625\n",
      "Train Epoch: 85 [17200/17352 (99%)] Loss: -179005.359375\n",
      "Train Epoch: 85 [17280/17352 (100%)] Loss: -183786.328125\n",
      "Train Epoch: 85 [17360/17352 (100%)] Loss: -159737.609375\n",
      "    epoch          : 85\n",
      "    loss           : -189162.7419897152\n",
      "    val_loss       : -23716.295212006906\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch85.pth ...\n",
      "Train Epoch: 86 [0/17352 (0%)] Loss: -203744.828125\n",
      "Train Epoch: 86 [80/17352 (0%)] Loss: -187722.328125\n",
      "Train Epoch: 86 [160/17352 (1%)] Loss: -204406.078125\n",
      "Train Epoch: 86 [240/17352 (1%)] Loss: -196926.625000\n",
      "Train Epoch: 86 [320/17352 (2%)] Loss: -208385.437500\n",
      "Train Epoch: 86 [400/17352 (2%)] Loss: -235585.328125\n",
      "Train Epoch: 86 [480/17352 (3%)] Loss: -209555.437500\n",
      "Train Epoch: 86 [560/17352 (3%)] Loss: -209637.187500\n",
      "Train Epoch: 86 [640/17352 (4%)] Loss: -205562.062500\n",
      "Train Epoch: 86 [720/17352 (4%)] Loss: -228907.718750\n",
      "Train Epoch: 86 [800/17352 (5%)] Loss: -208539.187500\n",
      "Train Epoch: 86 [880/17352 (5%)] Loss: -213326.234375\n",
      "Train Epoch: 86 [960/17352 (6%)] Loss: -191885.171875\n",
      "Train Epoch: 86 [1040/17352 (6%)] Loss: -236636.187500\n",
      "Train Epoch: 86 [1120/17352 (6%)] Loss: -217632.953125\n",
      "Train Epoch: 86 [1200/17352 (7%)] Loss: -210530.625000\n",
      "Train Epoch: 86 [1280/17352 (7%)] Loss: -193417.843750\n",
      "Train Epoch: 86 [1360/17352 (8%)] Loss: -226100.953125\n",
      "Train Epoch: 86 [1440/17352 (8%)] Loss: -229236.703125\n",
      "Train Epoch: 86 [1520/17352 (9%)] Loss: -200606.625000\n",
      "Train Epoch: 86 [1600/17352 (9%)] Loss: -214413.578125\n",
      "Train Epoch: 86 [1680/17352 (10%)] Loss: -204359.562500\n",
      "Train Epoch: 86 [1760/17352 (10%)] Loss: -210354.531250\n",
      "Train Epoch: 86 [1840/17352 (11%)] Loss: -212660.921875\n",
      "Train Epoch: 86 [1920/17352 (11%)] Loss: -205083.000000\n",
      "Train Epoch: 86 [2000/17352 (12%)] Loss: -196450.843750\n",
      "Train Epoch: 86 [2080/17352 (12%)] Loss: -186072.421875\n",
      "Train Epoch: 86 [2160/17352 (12%)] Loss: -206791.281250\n",
      "Train Epoch: 86 [2240/17352 (13%)] Loss: -194955.437500\n",
      "Train Epoch: 86 [2320/17352 (13%)] Loss: -192270.890625\n",
      "Train Epoch: 86 [2400/17352 (14%)] Loss: -165599.609375\n",
      "Train Epoch: 86 [2480/17352 (14%)] Loss: -165733.203125\n",
      "Train Epoch: 86 [2560/17352 (15%)] Loss: -216331.078125\n",
      "Train Epoch: 86 [2640/17352 (15%)] Loss: -196247.921875\n",
      "Train Epoch: 86 [2720/17352 (16%)] Loss: -185058.890625\n",
      "Train Epoch: 86 [2800/17352 (16%)] Loss: -170308.140625\n",
      "Train Epoch: 86 [2880/17352 (17%)] Loss: -164508.640625\n",
      "Train Epoch: 86 [2960/17352 (17%)] Loss: -200176.359375\n",
      "Train Epoch: 86 [3040/17352 (18%)] Loss: -199075.062500\n",
      "Train Epoch: 86 [3120/17352 (18%)] Loss: -196401.125000\n",
      "Train Epoch: 86 [3200/17352 (18%)] Loss: -190382.656250\n",
      "Train Epoch: 86 [3280/17352 (19%)] Loss: -186432.671875\n",
      "Train Epoch: 86 [3360/17352 (19%)] Loss: -163258.453125\n",
      "Train Epoch: 86 [3440/17352 (20%)] Loss: -188901.953125\n",
      "Train Epoch: 86 [3520/17352 (20%)] Loss: -191961.234375\n",
      "Train Epoch: 86 [3600/17352 (21%)] Loss: -196200.109375\n",
      "Train Epoch: 86 [3680/17352 (21%)] Loss: -213397.843750\n",
      "Train Epoch: 86 [3760/17352 (22%)] Loss: -193363.750000\n",
      "Train Epoch: 86 [3840/17352 (22%)] Loss: -197954.937500\n",
      "Train Epoch: 86 [3920/17352 (23%)] Loss: -173006.796875\n",
      "Train Epoch: 86 [4000/17352 (23%)] Loss: -171315.406250\n",
      "Train Epoch: 86 [4080/17352 (24%)] Loss: -195378.375000\n",
      "Train Epoch: 86 [4160/17352 (24%)] Loss: -186001.203125\n",
      "Train Epoch: 86 [4240/17352 (24%)] Loss: -163757.218750\n",
      "Train Epoch: 86 [4320/17352 (25%)] Loss: -196728.390625\n",
      "Train Epoch: 86 [4400/17352 (25%)] Loss: -204215.187500\n",
      "Train Epoch: 86 [4480/17352 (26%)] Loss: -200404.031250\n",
      "Train Epoch: 86 [4560/17352 (26%)] Loss: -193495.250000\n",
      "Train Epoch: 86 [4640/17352 (27%)] Loss: -183609.031250\n",
      "Train Epoch: 86 [4720/17352 (27%)] Loss: -162562.187500\n",
      "Train Epoch: 86 [4800/17352 (28%)] Loss: -177095.093750\n",
      "Train Epoch: 86 [4880/17352 (28%)] Loss: -166651.140625\n",
      "Train Epoch: 86 [4960/17352 (29%)] Loss: -184739.812500\n",
      "Train Epoch: 86 [5040/17352 (29%)] Loss: -192956.640625\n",
      "Train Epoch: 86 [5120/17352 (30%)] Loss: -168510.546875\n",
      "Train Epoch: 86 [5200/17352 (30%)] Loss: -179977.187500\n",
      "Train Epoch: 86 [5280/17352 (30%)] Loss: -183169.625000\n",
      "Train Epoch: 86 [5360/17352 (31%)] Loss: -205212.343750\n",
      "Train Epoch: 86 [5440/17352 (31%)] Loss: -176874.296875\n",
      "Train Epoch: 86 [5520/17352 (32%)] Loss: -206692.312500\n",
      "Train Epoch: 86 [5600/17352 (32%)] Loss: -188965.000000\n",
      "Train Epoch: 86 [5680/17352 (33%)] Loss: -191159.640625\n",
      "Train Epoch: 86 [5760/17352 (33%)] Loss: -228147.468750\n",
      "Train Epoch: 86 [5840/17352 (34%)] Loss: -193792.187500\n",
      "Train Epoch: 86 [5920/17352 (34%)] Loss: -176288.046875\n",
      "Train Epoch: 86 [6000/17352 (35%)] Loss: -186951.718750\n",
      "Train Epoch: 86 [6080/17352 (35%)] Loss: -212986.218750\n",
      "Train Epoch: 86 [6160/17352 (36%)] Loss: -192387.656250\n",
      "Train Epoch: 86 [6240/17352 (36%)] Loss: -180513.578125\n",
      "Train Epoch: 86 [6320/17352 (36%)] Loss: -148511.781250\n",
      "Train Epoch: 86 [6400/17352 (37%)] Loss: -185834.203125\n",
      "Train Epoch: 86 [6480/17352 (37%)] Loss: -187512.093750\n",
      "Train Epoch: 86 [6560/17352 (38%)] Loss: -188258.968750\n",
      "Train Epoch: 86 [6640/17352 (38%)] Loss: -201321.406250\n",
      "Train Epoch: 86 [6720/17352 (39%)] Loss: -187773.484375\n",
      "Train Epoch: 86 [6800/17352 (39%)] Loss: -165729.000000\n",
      "Train Epoch: 86 [6880/17352 (40%)] Loss: -192688.453125\n",
      "Train Epoch: 86 [6960/17352 (40%)] Loss: -173669.625000\n",
      "Train Epoch: 86 [7040/17352 (41%)] Loss: -190234.656250\n",
      "Train Epoch: 86 [7120/17352 (41%)] Loss: -195296.515625\n",
      "Train Epoch: 86 [7200/17352 (41%)] Loss: -181016.187500\n",
      "Train Epoch: 86 [7280/17352 (42%)] Loss: -180237.921875\n",
      "Train Epoch: 86 [7360/17352 (42%)] Loss: -177146.187500\n",
      "Train Epoch: 86 [7440/17352 (43%)] Loss: -178889.843750\n",
      "Train Epoch: 86 [7520/17352 (43%)] Loss: -186681.593750\n",
      "Train Epoch: 86 [7600/17352 (44%)] Loss: -185578.125000\n",
      "Train Epoch: 86 [7680/17352 (44%)] Loss: -186046.687500\n",
      "Train Epoch: 86 [7760/17352 (45%)] Loss: -218406.125000\n",
      "Train Epoch: 86 [7840/17352 (45%)] Loss: -195839.359375\n",
      "Train Epoch: 86 [7920/17352 (46%)] Loss: -175416.750000\n",
      "Train Epoch: 86 [8000/17352 (46%)] Loss: -205001.343750\n",
      "Train Epoch: 86 [8080/17352 (47%)] Loss: -220014.156250\n",
      "Train Epoch: 86 [8160/17352 (47%)] Loss: -193912.812500\n",
      "Train Epoch: 86 [8240/17352 (47%)] Loss: -180259.156250\n",
      "Train Epoch: 86 [8320/17352 (48%)] Loss: -152742.687500\n",
      "Train Epoch: 86 [8400/17352 (48%)] Loss: -199788.687500\n",
      "Train Epoch: 86 [8480/17352 (49%)] Loss: -192988.015625\n",
      "Train Epoch: 86 [8560/17352 (49%)] Loss: -183624.296875\n",
      "Train Epoch: 86 [8640/17352 (50%)] Loss: -188504.203125\n",
      "Train Epoch: 86 [8720/17352 (50%)] Loss: -191679.015625\n",
      "Train Epoch: 86 [8800/17352 (51%)] Loss: -143617.906250\n",
      "Train Epoch: 86 [8880/17352 (51%)] Loss: -164374.796875\n",
      "Train Epoch: 86 [8960/17352 (52%)] Loss: -190082.968750\n",
      "Train Epoch: 86 [9040/17352 (52%)] Loss: -203673.593750\n",
      "Train Epoch: 86 [9120/17352 (53%)] Loss: -165386.390625\n",
      "Train Epoch: 86 [9200/17352 (53%)] Loss: -167000.343750\n",
      "Train Epoch: 86 [9280/17352 (53%)] Loss: -185047.125000\n",
      "Train Epoch: 86 [9360/17352 (54%)] Loss: -172890.421875\n",
      "Train Epoch: 86 [9440/17352 (54%)] Loss: -200637.031250\n",
      "Train Epoch: 86 [9520/17352 (55%)] Loss: -179742.062500\n",
      "Train Epoch: 86 [9600/17352 (55%)] Loss: -227894.046875\n",
      "Train Epoch: 86 [9680/17352 (56%)] Loss: -175076.515625\n",
      "Train Epoch: 86 [9760/17352 (56%)] Loss: -178575.062500\n",
      "Train Epoch: 86 [9840/17352 (57%)] Loss: -180920.015625\n",
      "Train Epoch: 86 [9920/17352 (57%)] Loss: -191804.593750\n",
      "Train Epoch: 86 [10000/17352 (58%)] Loss: -199176.171875\n",
      "Train Epoch: 86 [10080/17352 (58%)] Loss: -169950.375000\n",
      "Train Epoch: 86 [10160/17352 (59%)] Loss: -171732.546875\n",
      "Train Epoch: 86 [10240/17352 (59%)] Loss: -151514.218750\n",
      "Train Epoch: 86 [10320/17352 (59%)] Loss: -205168.875000\n",
      "Train Epoch: 86 [10400/17352 (60%)] Loss: -159612.062500\n",
      "Train Epoch: 86 [10480/17352 (60%)] Loss: -156605.156250\n",
      "Train Epoch: 86 [10560/17352 (61%)] Loss: -187223.359375\n",
      "Train Epoch: 86 [10640/17352 (61%)] Loss: -178312.859375\n",
      "Train Epoch: 86 [10720/17352 (62%)] Loss: -157001.609375\n",
      "Train Epoch: 86 [10800/17352 (62%)] Loss: -209895.828125\n",
      "Train Epoch: 86 [10880/17352 (63%)] Loss: -192395.109375\n",
      "Train Epoch: 86 [10960/17352 (63%)] Loss: -202021.015625\n",
      "Train Epoch: 86 [11040/17352 (64%)] Loss: -185791.375000\n",
      "Train Epoch: 86 [11120/17352 (64%)] Loss: -161098.156250\n",
      "Train Epoch: 86 [11200/17352 (65%)] Loss: -203886.984375\n",
      "Train Epoch: 86 [11280/17352 (65%)] Loss: -191055.171875\n",
      "Train Epoch: 86 [11360/17352 (65%)] Loss: -190006.578125\n",
      "Train Epoch: 86 [11440/17352 (66%)] Loss: -215462.015625\n",
      "Train Epoch: 86 [11520/17352 (66%)] Loss: -180054.906250\n",
      "Train Epoch: 86 [11600/17352 (67%)] Loss: -164955.453125\n",
      "Train Epoch: 86 [11680/17352 (67%)] Loss: -191234.500000\n",
      "Train Epoch: 86 [11760/17352 (68%)] Loss: -186158.812500\n",
      "Train Epoch: 86 [11840/17352 (68%)] Loss: -204349.000000\n",
      "Train Epoch: 86 [11920/17352 (69%)] Loss: -174515.750000\n",
      "Train Epoch: 86 [12000/17352 (69%)] Loss: -207127.078125\n",
      "Train Epoch: 86 [12080/17352 (70%)] Loss: -167804.843750\n",
      "Train Epoch: 86 [12160/17352 (70%)] Loss: -174143.093750\n",
      "Train Epoch: 86 [12240/17352 (71%)] Loss: -201002.093750\n",
      "Train Epoch: 86 [12320/17352 (71%)] Loss: -164080.578125\n",
      "Train Epoch: 86 [12400/17352 (71%)] Loss: -190811.265625\n",
      "Train Epoch: 86 [12480/17352 (72%)] Loss: -194069.250000\n",
      "Train Epoch: 86 [12560/17352 (72%)] Loss: -191312.562500\n",
      "Train Epoch: 86 [12640/17352 (73%)] Loss: -193049.890625\n",
      "Train Epoch: 86 [12720/17352 (73%)] Loss: -196132.781250\n",
      "Train Epoch: 86 [12800/17352 (74%)] Loss: -180258.906250\n",
      "Train Epoch: 86 [12880/17352 (74%)] Loss: -159090.656250\n",
      "Train Epoch: 86 [12960/17352 (75%)] Loss: -184600.375000\n",
      "Train Epoch: 86 [13040/17352 (75%)] Loss: -187639.421875\n",
      "Train Epoch: 86 [13120/17352 (76%)] Loss: -156477.234375\n",
      "Train Epoch: 86 [13200/17352 (76%)] Loss: -174990.718750\n",
      "Train Epoch: 86 [13280/17352 (77%)] Loss: -196447.265625\n",
      "Train Epoch: 86 [13360/17352 (77%)] Loss: -197592.750000\n",
      "Train Epoch: 86 [13440/17352 (77%)] Loss: -161517.000000\n",
      "Train Epoch: 86 [13520/17352 (78%)] Loss: -187949.281250\n",
      "Train Epoch: 86 [13600/17352 (78%)] Loss: -190237.625000\n",
      "Train Epoch: 86 [13680/17352 (79%)] Loss: -205529.312500\n",
      "Train Epoch: 86 [13760/17352 (79%)] Loss: -180146.015625\n",
      "Train Epoch: 86 [13840/17352 (80%)] Loss: -193530.484375\n",
      "Train Epoch: 86 [13920/17352 (80%)] Loss: -180644.453125\n",
      "Train Epoch: 86 [14000/17352 (81%)] Loss: -180159.750000\n",
      "Train Epoch: 86 [14080/17352 (81%)] Loss: -192013.968750\n",
      "Train Epoch: 86 [14160/17352 (82%)] Loss: -193168.718750\n",
      "Train Epoch: 86 [14240/17352 (82%)] Loss: -166521.062500\n",
      "Train Epoch: 86 [14320/17352 (83%)] Loss: -176593.984375\n",
      "Train Epoch: 86 [14400/17352 (83%)] Loss: -202235.500000\n",
      "Train Epoch: 86 [14480/17352 (83%)] Loss: -190211.781250\n",
      "Train Epoch: 86 [14560/17352 (84%)] Loss: -208429.421875\n",
      "Train Epoch: 86 [14640/17352 (84%)] Loss: -167186.765625\n",
      "Train Epoch: 86 [14720/17352 (85%)] Loss: -189213.343750\n",
      "Train Epoch: 86 [14800/17352 (85%)] Loss: -207095.484375\n",
      "Train Epoch: 86 [14880/17352 (86%)] Loss: -158257.750000\n",
      "Train Epoch: 86 [14960/17352 (86%)] Loss: -176700.593750\n",
      "Train Epoch: 86 [15040/17352 (87%)] Loss: -187272.843750\n",
      "Train Epoch: 86 [15120/17352 (87%)] Loss: -170536.125000\n",
      "Train Epoch: 86 [15200/17352 (88%)] Loss: -190997.296875\n",
      "Train Epoch: 86 [15280/17352 (88%)] Loss: -196448.406250\n",
      "Train Epoch: 86 [15360/17352 (89%)] Loss: -176682.265625\n",
      "Train Epoch: 86 [15440/17352 (89%)] Loss: -199453.781250\n",
      "Train Epoch: 86 [15520/17352 (89%)] Loss: -167086.953125\n",
      "Train Epoch: 86 [15600/17352 (90%)] Loss: -183762.000000\n",
      "Train Epoch: 86 [15680/17352 (90%)] Loss: -185366.640625\n",
      "Train Epoch: 86 [15760/17352 (91%)] Loss: -200171.937500\n",
      "Train Epoch: 86 [15840/17352 (91%)] Loss: -186724.062500\n",
      "Train Epoch: 86 [15920/17352 (92%)] Loss: -192749.937500\n",
      "Train Epoch: 86 [16000/17352 (92%)] Loss: -191957.484375\n",
      "Train Epoch: 86 [16080/17352 (93%)] Loss: -129698.320312\n",
      "Train Epoch: 86 [16160/17352 (93%)] Loss: -205643.562500\n",
      "Train Epoch: 86 [16240/17352 (94%)] Loss: -190917.406250\n",
      "Train Epoch: 86 [16320/17352 (94%)] Loss: -183080.906250\n",
      "Train Epoch: 86 [16400/17352 (95%)] Loss: -176040.140625\n",
      "Train Epoch: 86 [16480/17352 (95%)] Loss: -179387.843750\n",
      "Train Epoch: 86 [16560/17352 (95%)] Loss: -181156.468750\n",
      "Train Epoch: 86 [16640/17352 (96%)] Loss: -166550.515625\n",
      "Train Epoch: 86 [16720/17352 (96%)] Loss: -142620.781250\n",
      "Train Epoch: 86 [16800/17352 (97%)] Loss: -158746.453125\n",
      "Train Epoch: 86 [16880/17352 (97%)] Loss: -168085.375000\n",
      "Train Epoch: 86 [16960/17352 (98%)] Loss: -159318.640625\n",
      "Train Epoch: 86 [17040/17352 (98%)] Loss: -192791.156250\n",
      "Train Epoch: 86 [17120/17352 (99%)] Loss: -199891.093750\n",
      "Train Epoch: 86 [17200/17352 (99%)] Loss: -202524.328125\n",
      "Train Epoch: 86 [17280/17352 (100%)] Loss: -159755.375000\n",
      "Train Epoch: 86 [17360/17352 (100%)] Loss: -209419.640625\n",
      "    epoch          : 86\n",
      "    loss           : -189301.70798870828\n",
      "    val_loss       : -23716.3244624608\n",
      "Train Epoch: 87 [0/17352 (0%)] Loss: -206646.484375\n",
      "Train Epoch: 87 [80/17352 (0%)] Loss: -212660.640625\n",
      "Train Epoch: 87 [160/17352 (1%)] Loss: -212373.531250\n",
      "Train Epoch: 87 [240/17352 (1%)] Loss: -233738.031250\n",
      "Train Epoch: 87 [320/17352 (2%)] Loss: -204407.781250\n",
      "Train Epoch: 87 [400/17352 (2%)] Loss: -206786.531250\n",
      "Train Epoch: 87 [480/17352 (3%)] Loss: -228021.375000\n",
      "Train Epoch: 87 [560/17352 (3%)] Loss: -214342.937500\n",
      "Train Epoch: 87 [640/17352 (4%)] Loss: -205219.406250\n",
      "Train Epoch: 87 [720/17352 (4%)] Loss: -226097.468750\n",
      "Train Epoch: 87 [800/17352 (5%)] Loss: -213341.968750\n",
      "Train Epoch: 87 [880/17352 (5%)] Loss: -228906.312500\n",
      "Train Epoch: 87 [960/17352 (6%)] Loss: -212185.187500\n",
      "Train Epoch: 87 [1040/17352 (6%)] Loss: -214456.375000\n",
      "Train Epoch: 87 [1120/17352 (6%)] Loss: -213327.015625\n",
      "Train Epoch: 87 [1200/17352 (7%)] Loss: -217589.843750\n",
      "Train Epoch: 87 [1280/17352 (7%)] Loss: -224257.515625\n",
      "Train Epoch: 87 [1360/17352 (8%)] Loss: -198767.062500\n",
      "Train Epoch: 87 [1440/17352 (8%)] Loss: -191887.265625\n",
      "Train Epoch: 87 [1520/17352 (9%)] Loss: -210350.046875\n",
      "Train Epoch: 87 [1600/17352 (9%)] Loss: -215490.812500\n",
      "Train Epoch: 87 [1680/17352 (10%)] Loss: -201668.656250\n",
      "Train Epoch: 87 [1760/17352 (10%)] Loss: -204708.781250\n",
      "Train Epoch: 87 [1840/17352 (11%)] Loss: -187718.343750\n",
      "Train Epoch: 87 [1920/17352 (11%)] Loss: -214527.437500\n",
      "Train Epoch: 87 [2000/17352 (12%)] Loss: -185157.703125\n",
      "Train Epoch: 87 [2080/17352 (12%)] Loss: -188748.000000\n",
      "Train Epoch: 87 [2160/17352 (12%)] Loss: -216089.328125\n",
      "Train Epoch: 87 [2240/17352 (13%)] Loss: -195107.109375\n",
      "Train Epoch: 87 [2320/17352 (13%)] Loss: -163351.890625\n",
      "Train Epoch: 87 [2400/17352 (14%)] Loss: -165808.890625\n",
      "Train Epoch: 87 [2480/17352 (14%)] Loss: -160052.718750\n",
      "Train Epoch: 87 [2560/17352 (15%)] Loss: -162562.656250\n",
      "Train Epoch: 87 [2640/17352 (15%)] Loss: -191727.140625\n",
      "Train Epoch: 87 [2720/17352 (16%)] Loss: -183921.390625\n",
      "Train Epoch: 87 [2800/17352 (16%)] Loss: -164831.843750\n",
      "Train Epoch: 87 [2880/17352 (17%)] Loss: -174505.593750\n",
      "Train Epoch: 87 [2960/17352 (17%)] Loss: -203742.796875\n",
      "Train Epoch: 87 [3040/17352 (18%)] Loss: -175412.828125\n",
      "Train Epoch: 87 [3120/17352 (18%)] Loss: -149332.234375\n",
      "Train Epoch: 87 [3200/17352 (18%)] Loss: -188274.656250\n",
      "Train Epoch: 87 [3280/17352 (19%)] Loss: -180027.765625\n",
      "Train Epoch: 87 [3360/17352 (19%)] Loss: -216316.421875\n",
      "Train Epoch: 87 [3440/17352 (20%)] Loss: -212137.734375\n",
      "Train Epoch: 87 [3520/17352 (20%)] Loss: -218468.234375\n",
      "Train Epoch: 87 [3600/17352 (21%)] Loss: -188508.546875\n",
      "Train Epoch: 87 [3680/17352 (21%)] Loss: -177199.109375\n",
      "Train Epoch: 87 [3760/17352 (22%)] Loss: -197345.187500\n",
      "Train Epoch: 87 [3840/17352 (22%)] Loss: -171551.484375\n",
      "Train Epoch: 87 [3920/17352 (23%)] Loss: -225323.250000\n",
      "Train Epoch: 87 [4000/17352 (23%)] Loss: -164994.078125\n",
      "Train Epoch: 87 [4080/17352 (24%)] Loss: -183588.203125\n",
      "Train Epoch: 87 [4160/17352 (24%)] Loss: -204616.000000\n",
      "Train Epoch: 87 [4240/17352 (24%)] Loss: -176154.656250\n",
      "Train Epoch: 87 [4320/17352 (25%)] Loss: -174641.906250\n",
      "Train Epoch: 87 [4400/17352 (25%)] Loss: -192902.343750\n",
      "Train Epoch: 87 [4480/17352 (26%)] Loss: -181976.484375\n",
      "Train Epoch: 87 [4560/17352 (26%)] Loss: -179969.000000\n",
      "Train Epoch: 87 [4640/17352 (27%)] Loss: -206092.281250\n",
      "Train Epoch: 87 [4720/17352 (27%)] Loss: -175596.687500\n",
      "Train Epoch: 87 [4800/17352 (28%)] Loss: -205494.796875\n",
      "Train Epoch: 87 [4880/17352 (28%)] Loss: -188451.125000\n",
      "Train Epoch: 87 [4960/17352 (29%)] Loss: -164077.843750\n",
      "Train Epoch: 87 [5040/17352 (29%)] Loss: -193198.546875\n",
      "Train Epoch: 87 [5120/17352 (30%)] Loss: -196506.062500\n",
      "Train Epoch: 87 [5200/17352 (30%)] Loss: -171188.671875\n",
      "Train Epoch: 87 [5280/17352 (30%)] Loss: -166790.484375\n",
      "Train Epoch: 87 [5360/17352 (31%)] Loss: -176089.109375\n",
      "Train Epoch: 87 [5440/17352 (31%)] Loss: -206928.156250\n",
      "Train Epoch: 87 [5520/17352 (32%)] Loss: -201386.187500\n",
      "Train Epoch: 87 [5600/17352 (32%)] Loss: -206564.609375\n",
      "Train Epoch: 87 [5680/17352 (33%)] Loss: -200223.890625\n",
      "Train Epoch: 87 [5760/17352 (33%)] Loss: -214684.531250\n",
      "Train Epoch: 87 [5840/17352 (34%)] Loss: -185832.187500\n",
      "Train Epoch: 87 [5920/17352 (34%)] Loss: -210394.765625\n",
      "Train Epoch: 87 [6000/17352 (35%)] Loss: -185545.031250\n",
      "Train Epoch: 87 [6080/17352 (35%)] Loss: -147418.937500\n",
      "Train Epoch: 87 [6160/17352 (36%)] Loss: -189485.828125\n",
      "Train Epoch: 87 [6240/17352 (36%)] Loss: -191057.203125\n",
      "Train Epoch: 87 [6320/17352 (36%)] Loss: -180110.140625\n",
      "Train Epoch: 87 [6400/17352 (37%)] Loss: -152744.250000\n",
      "Train Epoch: 87 [6480/17352 (37%)] Loss: -194957.250000\n",
      "Train Epoch: 87 [6560/17352 (38%)] Loss: -179412.343750\n",
      "Train Epoch: 87 [6640/17352 (38%)] Loss: -171305.468750\n",
      "Train Epoch: 87 [6720/17352 (39%)] Loss: -187325.546875\n",
      "Train Epoch: 87 [6800/17352 (39%)] Loss: -193057.500000\n",
      "Train Epoch: 87 [6880/17352 (40%)] Loss: -190381.609375\n",
      "Train Epoch: 87 [6960/17352 (40%)] Loss: -204947.687500\n",
      "Train Epoch: 87 [7040/17352 (41%)] Loss: -215464.859375\n",
      "Train Epoch: 87 [7120/17352 (41%)] Loss: -187623.921875\n",
      "Train Epoch: 87 [7200/17352 (41%)] Loss: -129701.593750\n",
      "Train Epoch: 87 [7280/17352 (42%)] Loss: -208422.031250\n",
      "Train Epoch: 87 [7360/17352 (42%)] Loss: -177774.546875\n",
      "Train Epoch: 87 [7440/17352 (43%)] Loss: -169190.875000\n",
      "Train Epoch: 87 [7520/17352 (43%)] Loss: -196131.859375\n",
      "Train Epoch: 87 [7600/17352 (44%)] Loss: -205533.125000\n",
      "Train Epoch: 87 [7680/17352 (44%)] Loss: -193951.031250\n",
      "Train Epoch: 87 [7760/17352 (45%)] Loss: -174724.656250\n",
      "Train Epoch: 87 [7840/17352 (45%)] Loss: -95258.554688\n",
      "Train Epoch: 87 [7920/17352 (46%)] Loss: -192956.390625\n",
      "Train Epoch: 87 [8000/17352 (46%)] Loss: -178596.062500\n",
      "Train Epoch: 87 [8080/17352 (47%)] Loss: -178318.312500\n",
      "Train Epoch: 87 [8160/17352 (47%)] Loss: -195380.656250\n",
      "Train Epoch: 87 [8240/17352 (47%)] Loss: -170248.750000\n",
      "Train Epoch: 87 [8320/17352 (48%)] Loss: -191840.968750\n",
      "Train Epoch: 87 [8400/17352 (48%)] Loss: -192270.500000\n",
      "Train Epoch: 87 [8480/17352 (49%)] Loss: -177969.031250\n",
      "Train Epoch: 87 [8560/17352 (49%)] Loss: -171846.187500\n",
      "Train Epoch: 87 [8640/17352 (50%)] Loss: -201034.234375\n",
      "Train Epoch: 87 [8720/17352 (50%)] Loss: -203884.468750\n",
      "Train Epoch: 87 [8800/17352 (51%)] Loss: -180877.640625\n",
      "Train Epoch: 87 [8880/17352 (51%)] Loss: -206471.234375\n",
      "Train Epoch: 87 [8960/17352 (52%)] Loss: -149031.906250\n",
      "Train Epoch: 87 [9040/17352 (52%)] Loss: -204349.343750\n",
      "Train Epoch: 87 [9120/17352 (53%)] Loss: -181075.437500\n",
      "Train Epoch: 87 [9200/17352 (53%)] Loss: -196200.031250\n",
      "Train Epoch: 87 [9280/17352 (53%)] Loss: -168083.625000\n",
      "Train Epoch: 87 [9360/17352 (54%)] Loss: -193359.546875\n",
      "Train Epoch: 87 [9440/17352 (54%)] Loss: -179502.718750\n",
      "Train Epoch: 87 [9520/17352 (55%)] Loss: -174627.515625\n",
      "Train Epoch: 87 [9600/17352 (55%)] Loss: -194600.734375\n",
      "Train Epoch: 87 [9680/17352 (56%)] Loss: -201980.015625\n",
      "Train Epoch: 87 [9760/17352 (56%)] Loss: -195649.828125\n",
      "Train Epoch: 87 [9840/17352 (57%)] Loss: -217610.843750\n",
      "Train Epoch: 87 [9920/17352 (57%)] Loss: -180753.187500\n",
      "Train Epoch: 87 [10000/17352 (58%)] Loss: -196044.640625\n",
      "Train Epoch: 87 [10080/17352 (58%)] Loss: -175362.968750\n",
      "Train Epoch: 87 [10160/17352 (59%)] Loss: -196450.921875\n",
      "Train Epoch: 87 [10240/17352 (59%)] Loss: -187534.109375\n",
      "Train Epoch: 87 [10320/17352 (59%)] Loss: -181617.281250\n",
      "Train Epoch: 87 [10400/17352 (60%)] Loss: -177082.187500\n",
      "Train Epoch: 87 [10480/17352 (60%)] Loss: -163549.406250\n",
      "Train Epoch: 87 [10560/17352 (61%)] Loss: -161960.921875\n",
      "Train Epoch: 87 [10640/17352 (61%)] Loss: -180517.906250\n",
      "Train Epoch: 87 [10720/17352 (62%)] Loss: -191316.968750\n",
      "Train Epoch: 87 [10800/17352 (62%)] Loss: -177150.546875\n",
      "Train Epoch: 87 [10880/17352 (63%)] Loss: -187250.484375\n",
      "Train Epoch: 87 [10960/17352 (63%)] Loss: -158748.609375\n",
      "Train Epoch: 87 [11040/17352 (64%)] Loss: -167962.125000\n",
      "Train Epoch: 87 [11120/17352 (64%)] Loss: -215635.375000\n",
      "Train Epoch: 87 [11200/17352 (65%)] Loss: -173005.453125\n",
      "Train Epoch: 87 [11280/17352 (65%)] Loss: -205807.859375\n",
      "Train Epoch: 87 [11360/17352 (65%)] Loss: -202790.390625\n",
      "Train Epoch: 87 [11440/17352 (66%)] Loss: -186435.406250\n",
      "Train Epoch: 87 [11520/17352 (66%)] Loss: -178205.984375\n",
      "Train Epoch: 87 [11600/17352 (67%)] Loss: -165767.484375\n",
      "Train Epoch: 87 [11680/17352 (67%)] Loss: -204661.062500\n",
      "Train Epoch: 87 [11760/17352 (68%)] Loss: -208729.312500\n",
      "Train Epoch: 87 [11840/17352 (68%)] Loss: -187716.218750\n",
      "Train Epoch: 87 [11920/17352 (69%)] Loss: -181009.250000\n",
      "Train Epoch: 87 [12000/17352 (69%)] Loss: -156475.734375\n",
      "Train Epoch: 87 [12080/17352 (70%)] Loss: -202853.906250\n",
      "Train Epoch: 87 [12160/17352 (70%)] Loss: -203440.687500\n",
      "Train Epoch: 87 [12240/17352 (71%)] Loss: -171422.500000\n",
      "Train Epoch: 87 [12320/17352 (71%)] Loss: -183071.156250\n",
      "Train Epoch: 87 [12400/17352 (71%)] Loss: -178806.687500\n",
      "Train Epoch: 87 [12480/17352 (72%)] Loss: -148829.218750\n",
      "Train Epoch: 87 [12560/17352 (72%)] Loss: -195783.390625\n",
      "Train Epoch: 87 [12640/17352 (73%)] Loss: -192864.562500\n",
      "Train Epoch: 87 [12720/17352 (73%)] Loss: -175751.890625\n",
      "Train Epoch: 87 [12800/17352 (74%)] Loss: -185512.093750\n",
      "Train Epoch: 87 [12880/17352 (74%)] Loss: -183061.390625\n",
      "Train Epoch: 87 [12960/17352 (75%)] Loss: -167800.140625\n",
      "Train Epoch: 87 [13040/17352 (75%)] Loss: -181915.031250\n",
      "Train Epoch: 87 [13120/17352 (76%)] Loss: -200405.015625\n",
      "Train Epoch: 87 [13200/17352 (76%)] Loss: -222854.421875\n",
      "Train Epoch: 87 [13280/17352 (77%)] Loss: -191592.265625\n",
      "Train Epoch: 87 [13360/17352 (77%)] Loss: -169951.531250\n",
      "Train Epoch: 87 [13440/17352 (77%)] Loss: -154609.281250\n",
      "Train Epoch: 87 [13520/17352 (78%)] Loss: -177174.796875\n",
      "Train Epoch: 87 [13600/17352 (78%)] Loss: -190940.265625\n",
      "Train Epoch: 87 [13680/17352 (79%)] Loss: -164077.296875\n",
      "Train Epoch: 87 [13760/17352 (79%)] Loss: -176704.531250\n",
      "Train Epoch: 87 [13840/17352 (80%)] Loss: -231045.546875\n",
      "Train Epoch: 87 [13920/17352 (80%)] Loss: -200867.125000\n",
      "Train Epoch: 87 [14000/17352 (81%)] Loss: -180695.046875\n",
      "Train Epoch: 87 [14080/17352 (81%)] Loss: -174546.843750\n",
      "Train Epoch: 87 [14160/17352 (82%)] Loss: -204209.140625\n",
      "Train Epoch: 87 [14240/17352 (82%)] Loss: -202317.140625\n",
      "Train Epoch: 87 [14320/17352 (83%)] Loss: -173664.890625\n",
      "Train Epoch: 87 [14400/17352 (83%)] Loss: -181960.125000\n",
      "Train Epoch: 87 [14480/17352 (83%)] Loss: -164368.593750\n",
      "Train Epoch: 87 [14560/17352 (84%)] Loss: -177275.140625\n",
      "Train Epoch: 87 [14640/17352 (84%)] Loss: -177312.125000\n",
      "Train Epoch: 87 [14720/17352 (85%)] Loss: -186724.750000\n",
      "Train Epoch: 87 [14800/17352 (85%)] Loss: -178828.671875\n",
      "Train Epoch: 87 [14880/17352 (86%)] Loss: -190217.484375\n",
      "Train Epoch: 87 [14960/17352 (86%)] Loss: -174992.234375\n",
      "Train Epoch: 87 [15040/17352 (87%)] Loss: -179460.296875\n",
      "Train Epoch: 87 [15120/17352 (87%)] Loss: -190244.093750\n",
      "Train Epoch: 87 [15200/17352 (88%)] Loss: -209269.906250\n",
      "Train Epoch: 87 [15280/17352 (88%)] Loss: -165738.406250\n",
      "Train Epoch: 87 [15360/17352 (89%)] Loss: -203273.000000\n",
      "Train Epoch: 87 [15440/17352 (89%)] Loss: -197999.515625\n",
      "Train Epoch: 87 [15520/17352 (89%)] Loss: -171898.093750\n",
      "Train Epoch: 87 [15600/17352 (90%)] Loss: -195057.281250\n",
      "Train Epoch: 87 [15680/17352 (90%)] Loss: -178430.531250\n",
      "Train Epoch: 87 [15760/17352 (91%)] Loss: -198550.218750\n",
      "Train Epoch: 87 [15840/17352 (91%)] Loss: -213906.078125\n",
      "Train Epoch: 87 [15920/17352 (92%)] Loss: -167089.343750\n",
      "Train Epoch: 87 [16000/17352 (92%)] Loss: -198264.734375\n",
      "Train Epoch: 87 [16080/17352 (93%)] Loss: -191686.578125\n",
      "Train Epoch: 87 [16160/17352 (93%)] Loss: -161686.593750\n",
      "Train Epoch: 87 [16240/17352 (94%)] Loss: -185787.046875\n",
      "Train Epoch: 87 [16320/17352 (94%)] Loss: -174185.531250\n",
      "Train Epoch: 87 [16400/17352 (95%)] Loss: -186043.812500\n",
      "Train Epoch: 87 [16480/17352 (95%)] Loss: -206163.843750\n",
      "Train Epoch: 87 [16560/17352 (95%)] Loss: -205409.937500\n",
      "Train Epoch: 87 [16640/17352 (96%)] Loss: -176061.109375\n",
      "Train Epoch: 87 [16720/17352 (96%)] Loss: -170309.203125\n",
      "Train Epoch: 87 [16800/17352 (97%)] Loss: -196444.640625\n",
      "Train Epoch: 87 [16880/17352 (97%)] Loss: -180920.578125\n",
      "Train Epoch: 87 [16960/17352 (98%)] Loss: -178310.734375\n",
      "Train Epoch: 87 [17040/17352 (98%)] Loss: -193369.078125\n",
      "Train Epoch: 87 [17120/17352 (99%)] Loss: -203846.656250\n",
      "Train Epoch: 87 [17200/17352 (99%)] Loss: -168999.046875\n",
      "Train Epoch: 87 [17280/17352 (100%)] Loss: -177487.531250\n",
      "Train Epoch: 87 [17360/17352 (100%)] Loss: -169444.937500\n",
      "    epoch          : 87\n",
      "    loss           : -189337.1799841772\n",
      "    val_loss       : -23716.216198128714\n",
      "Train Epoch: 88 [0/17352 (0%)] Loss: -198108.296875\n",
      "Train Epoch: 88 [80/17352 (0%)] Loss: -224352.281250\n",
      "Train Epoch: 88 [160/17352 (1%)] Loss: -230412.921875\n",
      "Train Epoch: 88 [240/17352 (1%)] Loss: -210526.281250\n",
      "Train Epoch: 88 [320/17352 (2%)] Loss: -202232.031250\n",
      "Train Epoch: 88 [400/17352 (2%)] Loss: -204030.734375\n",
      "Train Epoch: 88 [480/17352 (3%)] Loss: -213323.828125\n",
      "Train Epoch: 88 [560/17352 (3%)] Loss: -236834.921875\n",
      "Train Epoch: 88 [640/17352 (4%)] Loss: -203748.609375\n",
      "Train Epoch: 88 [720/17352 (4%)] Loss: -205086.093750\n",
      "Train Epoch: 88 [800/17352 (5%)] Loss: -210353.281250\n",
      "Train Epoch: 88 [880/17352 (5%)] Loss: -209785.843750\n",
      "Train Epoch: 88 [960/17352 (6%)] Loss: -196448.906250\n",
      "Train Epoch: 88 [1040/17352 (6%)] Loss: -204712.718750\n",
      "Train Epoch: 88 [1120/17352 (6%)] Loss: -233741.046875\n",
      "Train Epoch: 88 [1200/17352 (7%)] Loss: -210206.765625\n",
      "Train Epoch: 88 [1280/17352 (7%)] Loss: -193580.921875\n",
      "Train Epoch: 88 [1360/17352 (8%)] Loss: -205556.703125\n",
      "Train Epoch: 88 [1440/17352 (8%)] Loss: -205925.156250\n",
      "Train Epoch: 88 [1520/17352 (9%)] Loss: -196422.687500\n",
      "Train Epoch: 88 [1600/17352 (9%)] Loss: -212702.328125\n",
      "Train Epoch: 88 [1680/17352 (10%)] Loss: -219259.140625\n",
      "Train Epoch: 88 [1760/17352 (10%)] Loss: -208531.515625\n",
      "Train Epoch: 88 [1840/17352 (11%)] Loss: -214712.718750\n",
      "Train Epoch: 88 [1920/17352 (11%)] Loss: -212399.171875\n",
      "Train Epoch: 88 [2000/17352 (12%)] Loss: -202326.781250\n",
      "Train Epoch: 88 [2080/17352 (12%)] Loss: -182781.796875\n",
      "Train Epoch: 88 [2160/17352 (12%)] Loss: -216105.062500\n",
      "Train Epoch: 88 [2240/17352 (13%)] Loss: -177241.093750\n",
      "Train Epoch: 88 [2320/17352 (13%)] Loss: -205404.000000\n",
      "Train Epoch: 88 [2400/17352 (14%)] Loss: -187648.078125\n",
      "Train Epoch: 88 [2480/17352 (14%)] Loss: -189510.796875\n",
      "Train Epoch: 88 [2560/17352 (15%)] Loss: -168967.093750\n",
      "Train Epoch: 88 [2640/17352 (15%)] Loss: -175419.937500\n",
      "Train Epoch: 88 [2720/17352 (16%)] Loss: -188151.921875\n",
      "Train Epoch: 88 [2800/17352 (16%)] Loss: -195374.531250\n",
      "Train Epoch: 88 [2880/17352 (17%)] Loss: -159604.421875\n",
      "Train Epoch: 88 [2960/17352 (17%)] Loss: -213180.343750\n",
      "Train Epoch: 88 [3040/17352 (18%)] Loss: -179930.500000\n",
      "Train Epoch: 88 [3120/17352 (18%)] Loss: -176702.953125\n",
      "Train Epoch: 88 [3200/17352 (18%)] Loss: -206208.953125\n",
      "Train Epoch: 88 [3280/17352 (19%)] Loss: -192795.718750\n",
      "Train Epoch: 88 [3360/17352 (19%)] Loss: -198264.390625\n",
      "Train Epoch: 88 [3440/17352 (20%)] Loss: -184610.312500\n",
      "Train Epoch: 88 [3520/17352 (20%)] Loss: -187251.562500\n",
      "Train Epoch: 88 [3600/17352 (21%)] Loss: -209590.890625\n",
      "Train Epoch: 88 [3680/17352 (21%)] Loss: -177203.156250\n",
      "Train Epoch: 88 [3760/17352 (22%)] Loss: -204368.921875\n",
      "Train Epoch: 88 [3840/17352 (22%)] Loss: -188092.125000\n",
      "Train Epoch: 88 [3920/17352 (23%)] Loss: -187271.421875\n",
      "Train Epoch: 88 [4000/17352 (23%)] Loss: -163555.031250\n",
      "Train Epoch: 88 [4080/17352 (24%)] Loss: -149334.078125\n",
      "Train Epoch: 88 [4160/17352 (24%)] Loss: -223961.406250\n",
      "Train Epoch: 88 [4240/17352 (24%)] Loss: -178639.453125\n",
      "Train Epoch: 88 [4320/17352 (25%)] Loss: -210490.421875\n",
      "Train Epoch: 88 [4400/17352 (25%)] Loss: -221255.656250\n",
      "Train Epoch: 88 [4480/17352 (26%)] Loss: -176058.375000\n",
      "Train Epoch: 88 [4560/17352 (26%)] Loss: -187885.296875\n",
      "Train Epoch: 88 [4640/17352 (27%)] Loss: -180053.671875\n",
      "Train Epoch: 88 [4720/17352 (27%)] Loss: -196857.875000\n",
      "Train Epoch: 88 [4800/17352 (28%)] Loss: -219925.000000\n",
      "Train Epoch: 88 [4880/17352 (28%)] Loss: -192752.109375\n",
      "Train Epoch: 88 [4960/17352 (29%)] Loss: -180797.296875\n",
      "Train Epoch: 88 [5040/17352 (29%)] Loss: -170107.953125\n",
      "Train Epoch: 88 [5120/17352 (30%)] Loss: -193199.781250\n",
      "Train Epoch: 88 [5200/17352 (30%)] Loss: -202238.968750\n",
      "Train Epoch: 88 [5280/17352 (30%)] Loss: -206093.406250\n",
      "Train Epoch: 88 [5360/17352 (31%)] Loss: -197567.109375\n",
      "Train Epoch: 88 [5440/17352 (31%)] Loss: -209182.078125\n",
      "Train Epoch: 88 [5520/17352 (32%)] Loss: -167247.937500\n",
      "Train Epoch: 88 [5600/17352 (32%)] Loss: -178321.187500\n",
      "Train Epoch: 88 [5680/17352 (33%)] Loss: -199721.156250\n",
      "Train Epoch: 88 [5760/17352 (33%)] Loss: -189299.703125\n",
      "Train Epoch: 88 [5840/17352 (34%)] Loss: -189402.906250\n",
      "Train Epoch: 88 [5920/17352 (34%)] Loss: -170238.500000\n",
      "Train Epoch: 88 [6000/17352 (35%)] Loss: -167034.828125\n",
      "Train Epoch: 88 [6080/17352 (35%)] Loss: -167088.265625\n",
      "Train Epoch: 88 [6160/17352 (36%)] Loss: -197596.609375\n",
      "Train Epoch: 88 [6240/17352 (36%)] Loss: -203881.734375\n",
      "Train Epoch: 88 [6320/17352 (36%)] Loss: -186188.953125\n",
      "Train Epoch: 88 [6400/17352 (37%)] Loss: -200484.203125\n",
      "Train Epoch: 88 [6480/17352 (37%)] Loss: -174550.031250\n",
      "Train Epoch: 88 [6560/17352 (38%)] Loss: -174984.515625\n",
      "Train Epoch: 88 [6640/17352 (38%)] Loss: -201380.484375\n",
      "Train Epoch: 88 [6720/17352 (39%)] Loss: -190385.000000\n",
      "Train Epoch: 88 [6800/17352 (39%)] Loss: -208432.109375\n",
      "Train Epoch: 88 [6880/17352 (40%)] Loss: -189219.703125\n",
      "Train Epoch: 88 [6960/17352 (40%)] Loss: -177092.781250\n",
      "Train Epoch: 88 [7040/17352 (41%)] Loss: -198300.843750\n",
      "Train Epoch: 88 [7120/17352 (41%)] Loss: -200980.750000\n",
      "Train Epoch: 88 [7200/17352 (41%)] Loss: -152742.015625\n",
      "Train Epoch: 88 [7280/17352 (42%)] Loss: -209411.750000\n",
      "Train Epoch: 88 [7360/17352 (42%)] Loss: -178219.687500\n",
      "Train Epoch: 88 [7440/17352 (43%)] Loss: -185598.718750\n",
      "Train Epoch: 88 [7520/17352 (43%)] Loss: -138336.343750\n",
      "Train Epoch: 88 [7600/17352 (44%)] Loss: -185056.484375\n",
      "Train Epoch: 88 [7680/17352 (44%)] Loss: -169971.843750\n",
      "Train Epoch: 88 [7760/17352 (45%)] Loss: -160150.328125\n",
      "Train Epoch: 88 [7840/17352 (45%)] Loss: -178308.171875\n",
      "Train Epoch: 88 [7920/17352 (46%)] Loss: -193006.515625\n",
      "Train Epoch: 88 [8000/17352 (46%)] Loss: -151736.265625\n",
      "Train Epoch: 88 [8080/17352 (47%)] Loss: -197383.312500\n",
      "Train Epoch: 88 [8160/17352 (47%)] Loss: -204694.703125\n",
      "Train Epoch: 88 [8240/17352 (47%)] Loss: -181010.937500\n",
      "Train Epoch: 88 [8320/17352 (48%)] Loss: -204501.421875\n",
      "Train Epoch: 88 [8400/17352 (48%)] Loss: -197652.187500\n",
      "Train Epoch: 88 [8480/17352 (49%)] Loss: -178331.046875\n",
      "Train Epoch: 88 [8560/17352 (49%)] Loss: -149444.562500\n",
      "Train Epoch: 88 [8640/17352 (50%)] Loss: -190505.953125\n",
      "Train Epoch: 88 [8720/17352 (50%)] Loss: -183260.718750\n",
      "Train Epoch: 88 [8800/17352 (51%)] Loss: -196563.734375\n",
      "Train Epoch: 88 [8880/17352 (51%)] Loss: -192380.875000\n",
      "Train Epoch: 88 [8960/17352 (52%)] Loss: -185543.531250\n",
      "Train Epoch: 88 [9040/17352 (52%)] Loss: -171721.546875\n",
      "Train Epoch: 88 [9120/17352 (53%)] Loss: -180306.531250\n",
      "Train Epoch: 88 [9200/17352 (53%)] Loss: -182926.500000\n",
      "Train Epoch: 88 [9280/17352 (53%)] Loss: -164082.453125\n",
      "Train Epoch: 88 [9360/17352 (54%)] Loss: -181338.531250\n",
      "Train Epoch: 88 [9440/17352 (54%)] Loss: -191596.046875\n",
      "Train Epoch: 88 [9520/17352 (55%)] Loss: -179020.062500\n",
      "Train Epoch: 88 [9600/17352 (55%)] Loss: -190481.609375\n",
      "Train Epoch: 88 [9680/17352 (56%)] Loss: -180964.687500\n",
      "Train Epoch: 88 [9760/17352 (56%)] Loss: -174725.250000\n",
      "Train Epoch: 88 [9840/17352 (57%)] Loss: -183788.687500\n",
      "Train Epoch: 88 [9920/17352 (57%)] Loss: -152904.078125\n",
      "Train Epoch: 88 [10000/17352 (58%)] Loss: -189729.937500\n",
      "Train Epoch: 88 [10080/17352 (58%)] Loss: -174878.156250\n",
      "Train Epoch: 88 [10160/17352 (59%)] Loss: -197343.687500\n",
      "Train Epoch: 88 [10240/17352 (59%)] Loss: -202856.859375\n",
      "Train Epoch: 88 [10320/17352 (59%)] Loss: -180032.734375\n",
      "Train Epoch: 88 [10400/17352 (60%)] Loss: -183623.921875\n",
      "Train Epoch: 88 [10480/17352 (60%)] Loss: -189602.593750\n",
      "Train Epoch: 88 [10560/17352 (61%)] Loss: -192018.500000\n",
      "Train Epoch: 88 [10640/17352 (61%)] Loss: -183081.531250\n",
      "Train Epoch: 88 [10720/17352 (62%)] Loss: -172194.031250\n",
      "Train Epoch: 88 [10800/17352 (62%)] Loss: -185266.546875\n",
      "Train Epoch: 88 [10880/17352 (63%)] Loss: -161686.203125\n",
      "Train Epoch: 88 [10960/17352 (63%)] Loss: -131044.453125\n",
      "Train Epoch: 88 [11040/17352 (64%)] Loss: -196695.156250\n",
      "Train Epoch: 88 [11120/17352 (64%)] Loss: -193498.062500\n",
      "Train Epoch: 88 [11200/17352 (65%)] Loss: -178664.281250\n",
      "Train Epoch: 88 [11280/17352 (65%)] Loss: -218847.937500\n",
      "Train Epoch: 88 [11360/17352 (65%)] Loss: -181898.265625\n",
      "Train Epoch: 88 [11440/17352 (66%)] Loss: -166411.093750\n",
      "Train Epoch: 88 [11520/17352 (66%)] Loss: -179972.609375\n",
      "Train Epoch: 88 [11600/17352 (67%)] Loss: -148447.593750\n",
      "Train Epoch: 88 [11680/17352 (67%)] Loss: -175318.671875\n",
      "Train Epoch: 88 [11760/17352 (68%)] Loss: -214642.812500\n",
      "Train Epoch: 88 [11840/17352 (68%)] Loss: -178598.359375\n",
      "Train Epoch: 88 [11920/17352 (69%)] Loss: -170042.281250\n",
      "Train Epoch: 88 [12000/17352 (69%)] Loss: -201374.093750\n",
      "Train Epoch: 88 [12080/17352 (70%)] Loss: -196816.843750\n",
      "Train Epoch: 88 [12160/17352 (70%)] Loss: -178832.828125\n",
      "Train Epoch: 88 [12240/17352 (71%)] Loss: -179169.531250\n",
      "Train Epoch: 88 [12320/17352 (71%)] Loss: -200246.562500\n",
      "Train Epoch: 88 [12400/17352 (71%)] Loss: -184848.750000\n",
      "Train Epoch: 88 [12480/17352 (72%)] Loss: -194951.078125\n",
      "Train Epoch: 88 [12560/17352 (72%)] Loss: -214964.203125\n",
      "Train Epoch: 88 [12640/17352 (73%)] Loss: -186685.187500\n",
      "Train Epoch: 88 [12720/17352 (73%)] Loss: -177472.671875\n",
      "Train Epoch: 88 [12800/17352 (74%)] Loss: -165732.515625\n",
      "Train Epoch: 88 [12880/17352 (74%)] Loss: -217621.859375\n",
      "Train Epoch: 88 [12960/17352 (75%)] Loss: -206601.750000\n",
      "Train Epoch: 88 [13040/17352 (75%)] Loss: -200333.312500\n",
      "Train Epoch: 88 [13120/17352 (76%)] Loss: -202605.171875\n",
      "Train Epoch: 88 [13200/17352 (76%)] Loss: -170231.187500\n",
      "Train Epoch: 88 [13280/17352 (77%)] Loss: -212620.406250\n",
      "Train Epoch: 88 [13360/17352 (77%)] Loss: -186515.187500\n",
      "Train Epoch: 88 [13440/17352 (77%)] Loss: -171545.781250\n",
      "Train Epoch: 88 [13520/17352 (78%)] Loss: -202237.812500\n",
      "Train Epoch: 88 [13600/17352 (78%)] Loss: -167186.781250\n",
      "Train Epoch: 88 [13680/17352 (79%)] Loss: -223692.937500\n",
      "Train Epoch: 88 [13760/17352 (79%)] Loss: -157485.484375\n",
      "Train Epoch: 88 [13840/17352 (80%)] Loss: -173008.156250\n",
      "Train Epoch: 88 [13920/17352 (80%)] Loss: -180259.250000\n",
      "Train Epoch: 88 [14000/17352 (81%)] Loss: -173927.500000\n",
      "Train Epoch: 88 [14080/17352 (81%)] Loss: -179456.578125\n",
      "Train Epoch: 88 [14160/17352 (82%)] Loss: -214682.109375\n",
      "Train Epoch: 88 [14240/17352 (82%)] Loss: -183790.625000\n",
      "Train Epoch: 88 [14320/17352 (83%)] Loss: -158252.796875\n",
      "Train Epoch: 88 [14400/17352 (83%)] Loss: -183058.109375\n",
      "Train Epoch: 88 [14480/17352 (83%)] Loss: -163755.781250\n",
      "Train Epoch: 88 [14560/17352 (84%)] Loss: -190810.000000\n",
      "Train Epoch: 88 [14640/17352 (84%)] Loss: -201974.359375\n",
      "Train Epoch: 88 [14720/17352 (85%)] Loss: -177312.515625\n",
      "Train Epoch: 88 [14800/17352 (85%)] Loss: -177782.984375\n",
      "Train Epoch: 88 [14880/17352 (86%)] Loss: -192991.921875\n",
      "Train Epoch: 88 [14960/17352 (86%)] Loss: -193452.890625\n",
      "Train Epoch: 88 [15040/17352 (87%)] Loss: -177306.718750\n",
      "Train Epoch: 88 [15120/17352 (87%)] Loss: -186163.156250\n",
      "Train Epoch: 88 [15200/17352 (88%)] Loss: -191232.015625\n",
      "Train Epoch: 88 [15280/17352 (88%)] Loss: -176884.421875\n",
      "Train Epoch: 88 [15360/17352 (89%)] Loss: -183613.656250\n",
      "Train Epoch: 88 [15440/17352 (89%)] Loss: -201114.796875\n",
      "Train Epoch: 88 [15520/17352 (89%)] Loss: -203277.265625\n",
      "Train Epoch: 88 [15600/17352 (90%)] Loss: -184953.203125\n",
      "Train Epoch: 88 [15680/17352 (90%)] Loss: -185370.078125\n",
      "Train Epoch: 88 [15760/17352 (91%)] Loss: -201936.750000\n",
      "Train Epoch: 88 [15840/17352 (91%)] Loss: -185801.656250\n",
      "Train Epoch: 88 [15920/17352 (92%)] Loss: -173664.578125\n",
      "Train Epoch: 88 [16000/17352 (92%)] Loss: -191362.859375\n",
      "Train Epoch: 88 [16080/17352 (93%)] Loss: -183504.781250\n",
      "Train Epoch: 88 [16160/17352 (93%)] Loss: -210394.921875\n",
      "Train Epoch: 88 [16240/17352 (94%)] Loss: -177980.046875\n",
      "Train Epoch: 88 [16320/17352 (94%)] Loss: -191891.093750\n",
      "Train Epoch: 88 [16400/17352 (95%)] Loss: -204350.953125\n",
      "Train Epoch: 88 [16480/17352 (95%)] Loss: -190586.000000\n",
      "Train Epoch: 88 [16560/17352 (95%)] Loss: -161966.062500\n",
      "Train Epoch: 88 [16640/17352 (96%)] Loss: -203679.796875\n",
      "Train Epoch: 88 [16720/17352 (96%)] Loss: -181613.703125\n",
      "Train Epoch: 88 [16800/17352 (97%)] Loss: -196507.031250\n",
      "Train Epoch: 88 [16880/17352 (97%)] Loss: -214757.250000\n",
      "Train Epoch: 88 [16960/17352 (98%)] Loss: -186805.046875\n",
      "Train Epoch: 88 [17040/17352 (98%)] Loss: -177252.078125\n",
      "Train Epoch: 88 [17120/17352 (99%)] Loss: -180116.406250\n",
      "Train Epoch: 88 [17200/17352 (99%)] Loss: -176971.531250\n",
      "Train Epoch: 88 [17280/17352 (100%)] Loss: -204948.156250\n",
      "Train Epoch: 88 [17360/17352 (100%)] Loss: -203846.406250\n",
      "    epoch          : 88\n",
      "    loss           : -188951.18153049482\n",
      "    val_loss       : -23716.16370760779\n",
      "Train Epoch: 89 [0/17352 (0%)] Loss: -217636.484375\n",
      "Train Epoch: 89 [80/17352 (0%)] Loss: -213332.109375\n",
      "Train Epoch: 89 [160/17352 (1%)] Loss: -203265.671875\n",
      "Train Epoch: 89 [240/17352 (1%)] Loss: -213337.796875\n",
      "Train Epoch: 89 [320/17352 (2%)] Loss: -193027.062500\n",
      "Train Epoch: 89 [400/17352 (2%)] Loss: -205108.281250\n",
      "Train Epoch: 89 [480/17352 (3%)] Loss: -210529.953125\n",
      "Train Epoch: 89 [560/17352 (3%)] Loss: -213320.062500\n",
      "Train Epoch: 89 [640/17352 (4%)] Loss: -229232.296875\n",
      "Train Epoch: 89 [720/17352 (4%)] Loss: -205936.468750\n",
      "Train Epoch: 89 [800/17352 (5%)] Loss: -188747.843750\n",
      "Train Epoch: 89 [880/17352 (5%)] Loss: -199812.593750\n",
      "Train Epoch: 89 [960/17352 (6%)] Loss: -241906.718750\n",
      "Train Epoch: 89 [1040/17352 (6%)] Loss: -224249.687500\n",
      "Train Epoch: 89 [1120/17352 (6%)] Loss: -219254.375000\n",
      "Train Epoch: 89 [1200/17352 (7%)] Loss: -223002.390625\n",
      "Train Epoch: 89 [1280/17352 (7%)] Loss: -229965.203125\n",
      "Train Epoch: 89 [1360/17352 (8%)] Loss: -212697.281250\n",
      "Train Epoch: 89 [1440/17352 (8%)] Loss: -236516.421875\n",
      "Train Epoch: 89 [1520/17352 (9%)] Loss: -204401.109375\n",
      "Train Epoch: 89 [1600/17352 (9%)] Loss: -212654.156250\n",
      "Train Epoch: 89 [1680/17352 (10%)] Loss: -199114.546875\n",
      "Train Epoch: 89 [1760/17352 (10%)] Loss: -182766.390625\n",
      "Train Epoch: 89 [1840/17352 (11%)] Loss: -194302.000000\n",
      "Train Epoch: 89 [1920/17352 (11%)] Loss: -204737.640625\n",
      "Train Epoch: 89 [2000/17352 (12%)] Loss: -217931.265625\n",
      "Train Epoch: 89 [2080/17352 (12%)] Loss: -206753.781250\n",
      "Train Epoch: 89 [2160/17352 (12%)] Loss: -214340.812500\n",
      "Train Epoch: 89 [2240/17352 (13%)] Loss: -186800.968750\n",
      "Train Epoch: 89 [2320/17352 (13%)] Loss: -173844.734375\n",
      "Train Epoch: 89 [2400/17352 (14%)] Loss: -195057.531250\n",
      "Train Epoch: 89 [2480/17352 (14%)] Loss: -223686.984375\n",
      "Train Epoch: 89 [2560/17352 (15%)] Loss: -191833.000000\n",
      "Train Epoch: 89 [2640/17352 (15%)] Loss: -212653.968750\n",
      "Train Epoch: 89 [2720/17352 (16%)] Loss: -203849.375000\n",
      "Train Epoch: 89 [2800/17352 (16%)] Loss: -193178.671875\n",
      "Train Epoch: 89 [2880/17352 (17%)] Loss: -188909.562500\n",
      "Train Epoch: 89 [2960/17352 (17%)] Loss: -170785.171875\n",
      "Train Epoch: 89 [3040/17352 (18%)] Loss: -191562.359375\n",
      "Train Epoch: 89 [3120/17352 (18%)] Loss: -170686.015625\n",
      "Train Epoch: 89 [3200/17352 (18%)] Loss: -193003.000000\n",
      "Train Epoch: 89 [3280/17352 (19%)] Loss: -164802.593750\n",
      "Train Epoch: 89 [3360/17352 (19%)] Loss: -174513.296875\n",
      "Train Epoch: 89 [3440/17352 (20%)] Loss: -179171.015625\n",
      "Train Epoch: 89 [3520/17352 (20%)] Loss: -179017.687500\n",
      "Train Epoch: 89 [3600/17352 (21%)] Loss: -182742.781250\n",
      "Train Epoch: 89 [3680/17352 (21%)] Loss: -205000.062500\n",
      "Train Epoch: 89 [3760/17352 (22%)] Loss: -205216.265625\n",
      "Train Epoch: 89 [3840/17352 (22%)] Loss: -175428.203125\n",
      "Train Epoch: 89 [3920/17352 (23%)] Loss: -198005.421875\n",
      "Train Epoch: 89 [4000/17352 (23%)] Loss: -176275.890625\n",
      "Train Epoch: 89 [4080/17352 (24%)] Loss: -199790.937500\n",
      "Train Epoch: 89 [4160/17352 (24%)] Loss: -180793.359375\n",
      "Train Epoch: 89 [4240/17352 (24%)] Loss: -171833.328125\n",
      "Train Epoch: 89 [4320/17352 (25%)] Loss: -167241.578125\n",
      "Train Epoch: 89 [4400/17352 (25%)] Loss: -181428.187500\n",
      "Train Epoch: 89 [4480/17352 (26%)] Loss: -206922.437500\n",
      "Train Epoch: 89 [4560/17352 (26%)] Loss: -189601.875000\n",
      "Train Epoch: 89 [4640/17352 (27%)] Loss: -192791.671875\n",
      "Train Epoch: 89 [4720/17352 (27%)] Loss: -205493.109375\n",
      "Train Epoch: 89 [4800/17352 (28%)] Loss: -192018.734375\n",
      "Train Epoch: 89 [4880/17352 (28%)] Loss: -197080.984375\n",
      "Train Epoch: 89 [4960/17352 (29%)] Loss: -149333.750000\n",
      "Train Epoch: 89 [5040/17352 (29%)] Loss: -203270.187500\n",
      "Train Epoch: 89 [5120/17352 (30%)] Loss: -228154.703125\n",
      "Train Epoch: 89 [5200/17352 (30%)] Loss: -181371.984375\n",
      "Train Epoch: 89 [5280/17352 (30%)] Loss: -177172.093750\n",
      "Train Epoch: 89 [5360/17352 (31%)] Loss: -196299.015625\n",
      "Train Epoch: 89 [5440/17352 (31%)] Loss: -228098.937500\n",
      "Train Epoch: 89 [5520/17352 (32%)] Loss: -175410.812500\n",
      "Train Epoch: 89 [5600/17352 (32%)] Loss: -183388.171875\n",
      "Train Epoch: 89 [5680/17352 (33%)] Loss: -198262.562500\n",
      "Train Epoch: 89 [5760/17352 (33%)] Loss: -210486.203125\n",
      "Train Epoch: 89 [5840/17352 (34%)] Loss: -170234.843750\n",
      "Train Epoch: 89 [5920/17352 (34%)] Loss: -201389.609375\n",
      "Train Epoch: 89 [6000/17352 (35%)] Loss: -223963.265625\n",
      "Train Epoch: 89 [6080/17352 (35%)] Loss: -174452.531250\n",
      "Train Epoch: 89 [6160/17352 (36%)] Loss: -159750.015625\n",
      "Train Epoch: 89 [6240/17352 (36%)] Loss: -176492.531250\n",
      "Train Epoch: 89 [6320/17352 (36%)] Loss: -187352.406250\n",
      "Train Epoch: 89 [6400/17352 (37%)] Loss: -196562.968750\n",
      "Train Epoch: 89 [6480/17352 (37%)] Loss: -176971.843750\n",
      "Train Epoch: 89 [6560/17352 (38%)] Loss: -187322.125000\n",
      "Train Epoch: 89 [6640/17352 (38%)] Loss: -193372.375000\n",
      "Train Epoch: 89 [6720/17352 (39%)] Loss: -194588.484375\n",
      "Train Epoch: 89 [6800/17352 (39%)] Loss: -175017.000000\n",
      "Train Epoch: 89 [6880/17352 (40%)] Loss: -195056.765625\n",
      "Train Epoch: 89 [6960/17352 (40%)] Loss: -181892.218750\n",
      "Train Epoch: 89 [7040/17352 (41%)] Loss: -195883.453125\n",
      "Train Epoch: 89 [7120/17352 (41%)] Loss: -189537.718750\n",
      "Train Epoch: 89 [7200/17352 (41%)] Loss: -188008.656250\n",
      "Train Epoch: 89 [7280/17352 (42%)] Loss: -164750.031250\n",
      "Train Epoch: 89 [7360/17352 (42%)] Loss: -202088.218750\n",
      "Train Epoch: 89 [7440/17352 (43%)] Loss: -175688.062500\n",
      "Train Epoch: 89 [7520/17352 (43%)] Loss: -177309.593750\n",
      "Train Epoch: 89 [7600/17352 (44%)] Loss: -181671.421875\n",
      "Train Epoch: 89 [7680/17352 (44%)] Loss: -178567.796875\n",
      "Train Epoch: 89 [7760/17352 (45%)] Loss: -181919.562500\n",
      "Train Epoch: 89 [7840/17352 (45%)] Loss: -187523.968750\n",
      "Train Epoch: 89 [7920/17352 (46%)] Loss: -206474.546875\n",
      "Train Epoch: 89 [8000/17352 (46%)] Loss: -215636.625000\n",
      "Train Epoch: 89 [8080/17352 (47%)] Loss: -198025.187500\n",
      "Train Epoch: 89 [8160/17352 (47%)] Loss: -171588.875000\n",
      "Train Epoch: 89 [8240/17352 (47%)] Loss: -197106.625000\n",
      "Train Epoch: 89 [8320/17352 (48%)] Loss: -184486.781250\n",
      "Train Epoch: 89 [8400/17352 (48%)] Loss: -211087.906250\n",
      "Train Epoch: 89 [8480/17352 (49%)] Loss: -206688.484375\n",
      "Train Epoch: 89 [8560/17352 (49%)] Loss: -202520.875000\n",
      "Train Epoch: 89 [8640/17352 (50%)] Loss: -185447.437500\n",
      "Train Epoch: 89 [8720/17352 (50%)] Loss: -207860.640625\n",
      "Train Epoch: 89 [8800/17352 (51%)] Loss: -200828.125000\n",
      "Train Epoch: 89 [8880/17352 (51%)] Loss: -185546.437500\n",
      "Train Epoch: 89 [8960/17352 (52%)] Loss: -166667.812500\n",
      "Train Epoch: 89 [9040/17352 (52%)] Loss: -184844.453125\n",
      "Train Epoch: 89 [9120/17352 (53%)] Loss: -187245.078125\n",
      "Train Epoch: 89 [9200/17352 (53%)] Loss: -183722.187500\n",
      "Train Epoch: 89 [9280/17352 (53%)] Loss: -169617.781250\n",
      "Train Epoch: 89 [9360/17352 (54%)] Loss: -190503.390625\n",
      "Train Epoch: 89 [9440/17352 (54%)] Loss: -188680.359375\n",
      "Train Epoch: 89 [9520/17352 (55%)] Loss: -176586.546875\n",
      "Train Epoch: 89 [9600/17352 (55%)] Loss: -186192.578125\n",
      "Train Epoch: 89 [9680/17352 (56%)] Loss: -205642.687500\n",
      "Train Epoch: 89 [9760/17352 (56%)] Loss: -187885.281250\n",
      "Train Epoch: 89 [9840/17352 (57%)] Loss: -185831.031250\n",
      "Train Epoch: 89 [9920/17352 (57%)] Loss: -199146.250000\n",
      "Train Epoch: 89 [10000/17352 (58%)] Loss: -190805.203125\n",
      "Train Epoch: 89 [10080/17352 (58%)] Loss: -178317.265625\n",
      "Train Epoch: 89 [10160/17352 (59%)] Loss: -179311.734375\n",
      "Train Epoch: 89 [10240/17352 (59%)] Loss: -180256.484375\n",
      "Train Epoch: 89 [10320/17352 (59%)] Loss: -186038.687500\n",
      "Train Epoch: 89 [10400/17352 (60%)] Loss: -189483.437500\n",
      "Train Epoch: 89 [10480/17352 (60%)] Loss: -164080.140625\n",
      "Train Epoch: 89 [10560/17352 (61%)] Loss: -187407.437500\n",
      "Train Epoch: 89 [10640/17352 (61%)] Loss: -193169.687500\n",
      "Train Epoch: 89 [10720/17352 (62%)] Loss: -191338.203125\n",
      "Train Epoch: 89 [10800/17352 (62%)] Loss: -210270.765625\n",
      "Train Epoch: 89 [10880/17352 (63%)] Loss: -147416.359375\n",
      "Train Epoch: 89 [10960/17352 (63%)] Loss: -188184.000000\n",
      "Train Epoch: 89 [11040/17352 (64%)] Loss: -201306.671875\n",
      "Train Epoch: 89 [11120/17352 (64%)] Loss: -166655.546875\n",
      "Train Epoch: 89 [11200/17352 (65%)] Loss: -215179.453125\n",
      "Train Epoch: 89 [11280/17352 (65%)] Loss: -165732.468750\n",
      "Train Epoch: 89 [11360/17352 (65%)] Loss: -197521.218750\n",
      "Train Epoch: 89 [11440/17352 (66%)] Loss: -207785.421875\n",
      "Train Epoch: 89 [11520/17352 (66%)] Loss: -184252.937500\n",
      "Train Epoch: 89 [11600/17352 (67%)] Loss: -163097.421875\n",
      "Train Epoch: 89 [11680/17352 (67%)] Loss: -188757.734375\n",
      "Train Epoch: 89 [11760/17352 (68%)] Loss: -183404.312500\n",
      "Train Epoch: 89 [11840/17352 (68%)] Loss: -163258.828125\n",
      "Train Epoch: 89 [11920/17352 (69%)] Loss: -186051.328125\n",
      "Train Epoch: 89 [12000/17352 (69%)] Loss: -189794.515625\n",
      "Train Epoch: 89 [12080/17352 (70%)] Loss: -200979.671875\n",
      "Train Epoch: 89 [12160/17352 (70%)] Loss: -181621.750000\n",
      "Train Epoch: 89 [12240/17352 (71%)] Loss: -177489.531250\n",
      "Train Epoch: 89 [12320/17352 (71%)] Loss: -177735.578125\n",
      "Train Epoch: 89 [12400/17352 (71%)] Loss: -204945.484375\n",
      "Train Epoch: 89 [12480/17352 (72%)] Loss: -213403.796875\n",
      "Train Epoch: 89 [12560/17352 (72%)] Loss: -172239.406250\n",
      "Train Epoch: 89 [12640/17352 (73%)] Loss: -206597.312500\n",
      "Train Epoch: 89 [12720/17352 (73%)] Loss: -175669.140625\n",
      "Train Epoch: 89 [12800/17352 (74%)] Loss: -171322.828125\n",
      "Train Epoch: 89 [12880/17352 (74%)] Loss: -173893.906250\n",
      "Train Epoch: 89 [12960/17352 (75%)] Loss: -176542.375000\n",
      "Train Epoch: 89 [13040/17352 (75%)] Loss: -177776.156250\n",
      "Train Epoch: 89 [13120/17352 (76%)] Loss: -151218.484375\n",
      "Train Epoch: 89 [13200/17352 (76%)] Loss: -160146.750000\n",
      "Train Epoch: 89 [13280/17352 (77%)] Loss: -187318.281250\n",
      "Train Epoch: 89 [13360/17352 (77%)] Loss: -189266.843750\n",
      "Train Epoch: 89 [13440/17352 (77%)] Loss: -178200.671875\n",
      "Train Epoch: 89 [13520/17352 (78%)] Loss: -196949.796875\n",
      "Train Epoch: 89 [13600/17352 (78%)] Loss: -204345.468750\n",
      "Train Epoch: 89 [13680/17352 (79%)] Loss: -181756.765625\n",
      "Train Epoch: 89 [13760/17352 (79%)] Loss: -185342.468750\n",
      "Train Epoch: 89 [13840/17352 (80%)] Loss: -168089.593750\n",
      "Train Epoch: 89 [13920/17352 (80%)] Loss: -197440.843750\n",
      "Train Epoch: 89 [14000/17352 (81%)] Loss: -183971.296875\n",
      "Train Epoch: 89 [14080/17352 (81%)] Loss: -159312.656250\n",
      "Train Epoch: 89 [14160/17352 (82%)] Loss: -204662.109375\n",
      "Train Epoch: 89 [14240/17352 (82%)] Loss: -187267.234375\n",
      "Train Epoch: 89 [14320/17352 (83%)] Loss: -191590.718750\n",
      "Train Epoch: 89 [14400/17352 (83%)] Loss: -164830.875000\n",
      "Train Epoch: 89 [14480/17352 (83%)] Loss: -201936.875000\n",
      "Train Epoch: 89 [14560/17352 (84%)] Loss: -185369.656250\n",
      "Train Epoch: 89 [14640/17352 (84%)] Loss: -228250.421875\n",
      "Train Epoch: 89 [14720/17352 (85%)] Loss: -187716.265625\n",
      "Train Epoch: 89 [14800/17352 (85%)] Loss: -172622.343750\n",
      "Train Epoch: 89 [14880/17352 (86%)] Loss: -183611.859375\n",
      "Train Epoch: 89 [14960/17352 (86%)] Loss: -211169.093750\n",
      "Train Epoch: 89 [15040/17352 (87%)] Loss: -182400.375000\n",
      "Train Epoch: 89 [15120/17352 (87%)] Loss: -184951.484375\n",
      "Train Epoch: 89 [15200/17352 (88%)] Loss: -209899.218750\n",
      "Train Epoch: 89 [15280/17352 (88%)] Loss: -207865.218750\n",
      "Train Epoch: 89 [15360/17352 (89%)] Loss: -183791.609375\n",
      "Train Epoch: 89 [15440/17352 (89%)] Loss: -176149.843750\n",
      "Train Epoch: 89 [15520/17352 (89%)] Loss: -186953.937500\n",
      "Train Epoch: 89 [15600/17352 (90%)] Loss: -171227.203125\n",
      "Train Epoch: 89 [15680/17352 (90%)] Loss: -191678.750000\n",
      "Train Epoch: 89 [15760/17352 (91%)] Loss: -187223.578125\n",
      "Train Epoch: 89 [15840/17352 (91%)] Loss: -175745.828125\n",
      "Train Epoch: 89 [15920/17352 (92%)] Loss: -198310.859375\n",
      "Train Epoch: 89 [16000/17352 (92%)] Loss: -157491.281250\n",
      "Train Epoch: 89 [16080/17352 (93%)] Loss: -201377.281250\n",
      "Train Epoch: 89 [16160/17352 (93%)] Loss: -213747.562500\n",
      "Train Epoch: 89 [16240/17352 (94%)] Loss: -208016.390625\n",
      "Train Epoch: 89 [16320/17352 (94%)] Loss: -209194.218750\n",
      "Train Epoch: 89 [16400/17352 (95%)] Loss: -197322.796875\n",
      "Train Epoch: 89 [16480/17352 (95%)] Loss: -199603.625000\n",
      "Train Epoch: 89 [16560/17352 (95%)] Loss: -174939.437500\n",
      "Train Epoch: 89 [16640/17352 (96%)] Loss: -185998.875000\n",
      "Train Epoch: 89 [16720/17352 (96%)] Loss: -167001.656250\n",
      "Train Epoch: 89 [16800/17352 (97%)] Loss: -180053.265625\n",
      "Train Epoch: 89 [16880/17352 (97%)] Loss: -180903.390625\n",
      "Train Epoch: 89 [16960/17352 (98%)] Loss: -169746.734375\n",
      "Train Epoch: 89 [17040/17352 (98%)] Loss: -191234.546875\n",
      "Train Epoch: 89 [17120/17352 (99%)] Loss: -208724.375000\n",
      "Train Epoch: 89 [17200/17352 (99%)] Loss: -197654.578125\n",
      "Train Epoch: 89 [17280/17352 (100%)] Loss: -184962.578125\n",
      "Train Epoch: 89 [17360/17352 (100%)] Loss: -149028.437500\n",
      "    epoch          : 89\n",
      "    loss           : -188993.35934802933\n",
      "    val_loss       : -23716.20283042657\n",
      "Train Epoch: 90 [0/17352 (0%)] Loss: -205190.281250\n",
      "Train Epoch: 90 [80/17352 (0%)] Loss: -202321.671875\n",
      "Train Epoch: 90 [160/17352 (1%)] Loss: -228906.921875\n",
      "Train Epoch: 90 [240/17352 (1%)] Loss: -230187.000000\n",
      "Train Epoch: 90 [320/17352 (2%)] Loss: -216218.468750\n",
      "Train Epoch: 90 [400/17352 (2%)] Loss: -202273.765625\n",
      "Train Epoch: 90 [480/17352 (3%)] Loss: -214416.968750\n",
      "Train Epoch: 90 [560/17352 (3%)] Loss: -205111.921875\n",
      "Train Epoch: 90 [640/17352 (4%)] Loss: -219254.625000\n",
      "Train Epoch: 90 [720/17352 (4%)] Loss: -212191.078125\n",
      "Train Epoch: 90 [800/17352 (5%)] Loss: -186084.671875\n",
      "Train Epoch: 90 [880/17352 (5%)] Loss: -215832.968750\n",
      "Train Epoch: 90 [960/17352 (6%)] Loss: -221764.031250\n",
      "Train Epoch: 90 [1040/17352 (6%)] Loss: -212659.250000\n",
      "Train Epoch: 90 [1120/17352 (6%)] Loss: -196450.656250\n",
      "Train Epoch: 90 [1200/17352 (7%)] Loss: -219666.843750\n",
      "Train Epoch: 90 [1280/17352 (7%)] Loss: -204735.562500\n",
      "Train Epoch: 90 [1360/17352 (8%)] Loss: -228024.468750\n",
      "Train Epoch: 90 [1440/17352 (8%)] Loss: -200605.968750\n",
      "Train Epoch: 90 [1520/17352 (9%)] Loss: -221479.125000\n",
      "Train Epoch: 90 [1600/17352 (9%)] Loss: -204533.281250\n",
      "Train Epoch: 90 [1680/17352 (10%)] Loss: -212399.843750\n",
      "Train Epoch: 90 [1760/17352 (10%)] Loss: -236835.046875\n",
      "Train Epoch: 90 [1840/17352 (11%)] Loss: -214531.359375\n",
      "Train Epoch: 90 [1920/17352 (11%)] Loss: -222518.109375\n",
      "Train Epoch: 90 [2000/17352 (12%)] Loss: -214463.218750\n",
      "Train Epoch: 90 [2080/17352 (12%)] Loss: -185154.406250\n",
      "Train Epoch: 90 [2160/17352 (12%)] Loss: -188750.046875\n",
      "Train Epoch: 90 [2240/17352 (13%)] Loss: -182564.328125\n",
      "Train Epoch: 90 [2320/17352 (13%)] Loss: -179932.312500\n",
      "Train Epoch: 90 [2400/17352 (14%)] Loss: -198002.390625\n",
      "Train Epoch: 90 [2480/17352 (14%)] Loss: -188905.906250\n",
      "Train Epoch: 90 [2560/17352 (15%)] Loss: -173927.406250\n",
      "Train Epoch: 90 [2640/17352 (15%)] Loss: -180909.437500\n",
      "Train Epoch: 90 [2720/17352 (16%)] Loss: -205729.218750\n",
      "Train Epoch: 90 [2800/17352 (16%)] Loss: -205639.250000\n",
      "Train Epoch: 90 [2880/17352 (17%)] Loss: -177733.437500\n",
      "Train Epoch: 90 [2960/17352 (17%)] Loss: -191837.312500\n",
      "Train Epoch: 90 [3040/17352 (18%)] Loss: -169452.046875\n",
      "Train Epoch: 90 [3120/17352 (18%)] Loss: -169165.562500\n",
      "Train Epoch: 90 [3200/17352 (18%)] Loss: -190812.531250\n",
      "Train Epoch: 90 [3280/17352 (19%)] Loss: -189537.281250\n",
      "Train Epoch: 90 [3360/17352 (19%)] Loss: -201370.609375\n",
      "Train Epoch: 90 [3440/17352 (20%)] Loss: -165802.453125\n",
      "Train Epoch: 90 [3520/17352 (20%)] Loss: -167802.953125\n",
      "Train Epoch: 90 [3600/17352 (21%)] Loss: -178314.093750\n",
      "Train Epoch: 90 [3680/17352 (21%)] Loss: -191597.312500\n",
      "Train Epoch: 90 [3760/17352 (22%)] Loss: -184757.171875\n",
      "Train Epoch: 90 [3840/17352 (22%)] Loss: -160055.125000\n",
      "Train Epoch: 90 [3920/17352 (23%)] Loss: -200407.312500\n",
      "Train Epoch: 90 [4000/17352 (23%)] Loss: -194586.406250\n",
      "Train Epoch: 90 [4080/17352 (24%)] Loss: -203511.218750\n",
      "Train Epoch: 90 [4160/17352 (24%)] Loss: -164073.890625\n",
      "Train Epoch: 90 [4240/17352 (24%)] Loss: -179741.046875\n",
      "Train Epoch: 90 [4320/17352 (25%)] Loss: -190477.593750\n",
      "Train Epoch: 90 [4400/17352 (25%)] Loss: -186160.812500\n",
      "Train Epoch: 90 [4480/17352 (26%)] Loss: -183924.953125\n",
      "Train Epoch: 90 [4560/17352 (26%)] Loss: -193515.796875\n",
      "Train Epoch: 90 [4640/17352 (27%)] Loss: -182922.765625\n",
      "Train Epoch: 90 [4720/17352 (27%)] Loss: -160104.296875\n",
      "Train Epoch: 90 [4800/17352 (28%)] Loss: -180510.296875\n",
      "Train Epoch: 90 [4880/17352 (28%)] Loss: -192122.828125\n",
      "Train Epoch: 90 [4960/17352 (29%)] Loss: -188084.625000\n",
      "Train Epoch: 90 [5040/17352 (29%)] Loss: -143619.750000\n",
      "Train Epoch: 90 [5120/17352 (30%)] Loss: -177593.203125\n",
      "Train Epoch: 90 [5200/17352 (30%)] Loss: -164146.187500\n",
      "Train Epoch: 90 [5280/17352 (30%)] Loss: -151228.875000\n",
      "Train Epoch: 90 [5360/17352 (31%)] Loss: -146854.500000\n",
      "Train Epoch: 90 [5440/17352 (31%)] Loss: -208309.671875\n",
      "Train Epoch: 90 [5520/17352 (32%)] Loss: -179008.187500\n",
      "Train Epoch: 90 [5600/17352 (32%)] Loss: -184031.812500\n",
      "Train Epoch: 90 [5680/17352 (33%)] Loss: -211096.328125\n",
      "Train Epoch: 90 [5760/17352 (33%)] Loss: -185006.062500\n",
      "Train Epoch: 90 [5840/17352 (34%)] Loss: -194071.343750\n",
      "Train Epoch: 90 [5920/17352 (34%)] Loss: -208157.953125\n",
      "Train Epoch: 90 [6000/17352 (35%)] Loss: -194053.453125\n",
      "Train Epoch: 90 [6080/17352 (35%)] Loss: -200169.390625\n",
      "Train Epoch: 90 [6160/17352 (36%)] Loss: -195069.343750\n",
      "Train Epoch: 90 [6240/17352 (36%)] Loss: -190916.125000\n",
      "Train Epoch: 90 [6320/17352 (36%)] Loss: -205809.171875\n",
      "Train Epoch: 90 [6400/17352 (37%)] Loss: -187722.781250\n",
      "Train Epoch: 90 [6480/17352 (37%)] Loss: -181742.468750\n",
      "Train Epoch: 90 [6560/17352 (38%)] Loss: -192394.406250\n",
      "Train Epoch: 90 [6640/17352 (38%)] Loss: -165999.640625\n",
      "Train Epoch: 90 [6720/17352 (39%)] Loss: -200620.875000\n",
      "Train Epoch: 90 [6800/17352 (39%)] Loss: -192238.328125\n",
      "Train Epoch: 90 [6880/17352 (40%)] Loss: -173663.046875\n",
      "Train Epoch: 90 [6960/17352 (40%)] Loss: -148822.406250\n",
      "Train Epoch: 90 [7040/17352 (41%)] Loss: -166554.171875\n",
      "Train Epoch: 90 [7120/17352 (41%)] Loss: -212659.375000\n",
      "Train Epoch: 90 [7200/17352 (41%)] Loss: -142623.625000\n",
      "Train Epoch: 90 [7280/17352 (42%)] Loss: -192993.562500\n",
      "Train Epoch: 90 [7360/17352 (42%)] Loss: -199723.718750\n",
      "Train Epoch: 90 [7440/17352 (43%)] Loss: -181336.781250\n",
      "Train Epoch: 90 [7520/17352 (43%)] Loss: -185795.187500\n",
      "Train Epoch: 90 [7600/17352 (44%)] Loss: -185171.359375\n",
      "Train Epoch: 90 [7680/17352 (44%)] Loss: -207125.640625\n",
      "Train Epoch: 90 [7760/17352 (45%)] Loss: -170683.875000\n",
      "Train Epoch: 90 [7840/17352 (45%)] Loss: -196700.421875\n",
      "Train Epoch: 90 [7920/17352 (46%)] Loss: -221254.546875\n",
      "Train Epoch: 90 [8000/17352 (46%)] Loss: -204495.281250\n",
      "Train Epoch: 90 [8080/17352 (47%)] Loss: -195716.875000\n",
      "Train Epoch: 90 [8160/17352 (47%)] Loss: -203438.265625\n",
      "Train Epoch: 90 [8240/17352 (47%)] Loss: -198707.718750\n",
      "Train Epoch: 90 [8320/17352 (48%)] Loss: -175600.203125\n",
      "Train Epoch: 90 [8400/17352 (48%)] Loss: -187216.984375\n",
      "Train Epoch: 90 [8480/17352 (49%)] Loss: -188751.562500\n",
      "Train Epoch: 90 [8560/17352 (49%)] Loss: -194608.421875\n",
      "Train Epoch: 90 [8640/17352 (50%)] Loss: -180242.078125\n",
      "Train Epoch: 90 [8720/17352 (50%)] Loss: -201519.640625\n",
      "Train Epoch: 90 [8800/17352 (51%)] Loss: -193267.265625\n",
      "Train Epoch: 90 [8880/17352 (51%)] Loss: -196454.687500\n",
      "Train Epoch: 90 [8960/17352 (52%)] Loss: -177199.718750\n",
      "Train Epoch: 90 [9040/17352 (52%)] Loss: -162725.890625\n",
      "Train Epoch: 90 [9120/17352 (53%)] Loss: -185576.890625\n",
      "Train Epoch: 90 [9200/17352 (53%)] Loss: -178867.515625\n",
      "Train Epoch: 90 [9280/17352 (53%)] Loss: -186049.765625\n",
      "Train Epoch: 90 [9360/17352 (54%)] Loss: -170245.000000\n",
      "Train Epoch: 90 [9440/17352 (54%)] Loss: -218748.109375\n",
      "Train Epoch: 90 [9520/17352 (55%)] Loss: -185512.656250\n",
      "Train Epoch: 90 [9600/17352 (55%)] Loss: -179019.281250\n",
      "Train Epoch: 90 [9680/17352 (56%)] Loss: -148161.968750\n",
      "Train Epoch: 90 [9760/17352 (56%)] Loss: -187542.609375\n",
      "Train Epoch: 90 [9840/17352 (57%)] Loss: -204621.593750\n",
      "Train Epoch: 90 [9920/17352 (57%)] Loss: -181756.468750\n",
      "Train Epoch: 90 [10000/17352 (58%)] Loss: -177081.875000\n",
      "Train Epoch: 90 [10080/17352 (58%)] Loss: -199414.312500\n",
      "Train Epoch: 90 [10160/17352 (59%)] Loss: -228259.250000\n",
      "Train Epoch: 90 [10240/17352 (59%)] Loss: -185241.968750\n",
      "Train Epoch: 90 [10320/17352 (59%)] Loss: -192641.187500\n",
      "Train Epoch: 90 [10400/17352 (60%)] Loss: -200268.875000\n",
      "Train Epoch: 90 [10480/17352 (60%)] Loss: -196044.484375\n",
      "Train Epoch: 90 [10560/17352 (61%)] Loss: -210485.578125\n",
      "Train Epoch: 90 [10640/17352 (61%)] Loss: -181624.250000\n",
      "Train Epoch: 90 [10720/17352 (62%)] Loss: -189026.406250\n",
      "Train Epoch: 90 [10800/17352 (62%)] Loss: -169191.046875\n",
      "Train Epoch: 90 [10880/17352 (63%)] Loss: -178096.750000\n",
      "Train Epoch: 90 [10960/17352 (63%)] Loss: -189300.171875\n",
      "Train Epoch: 90 [11040/17352 (64%)] Loss: -176059.640625\n",
      "Train Epoch: 90 [11120/17352 (64%)] Loss: -170776.437500\n",
      "Train Epoch: 90 [11200/17352 (65%)] Loss: -174935.812500\n",
      "Train Epoch: 90 [11280/17352 (65%)] Loss: -208426.281250\n",
      "Train Epoch: 90 [11360/17352 (65%)] Loss: -195381.328125\n",
      "Train Epoch: 90 [11440/17352 (66%)] Loss: -167731.578125\n",
      "Train Epoch: 90 [11520/17352 (66%)] Loss: -192009.484375\n",
      "Train Epoch: 90 [11600/17352 (67%)] Loss: -185835.546875\n",
      "Train Epoch: 90 [11680/17352 (67%)] Loss: -192896.796875\n",
      "Train Epoch: 90 [11760/17352 (68%)] Loss: -201953.718750\n",
      "Train Epoch: 90 [11840/17352 (68%)] Loss: -220971.843750\n",
      "Train Epoch: 90 [11920/17352 (69%)] Loss: -178136.984375\n",
      "Train Epoch: 90 [12000/17352 (69%)] Loss: -131046.898438\n",
      "Train Epoch: 90 [12080/17352 (70%)] Loss: -165731.296875\n",
      "Train Epoch: 90 [12160/17352 (70%)] Loss: -148400.859375\n",
      "Train Epoch: 90 [12240/17352 (71%)] Loss: -158606.187500\n",
      "Train Epoch: 90 [12320/17352 (71%)] Loss: -179896.671875\n",
      "Train Epoch: 90 [12400/17352 (71%)] Loss: -192385.125000\n",
      "Train Epoch: 90 [12480/17352 (72%)] Loss: -208040.671875\n",
      "Train Epoch: 90 [12560/17352 (72%)] Loss: -192279.843750\n",
      "Train Epoch: 90 [12640/17352 (73%)] Loss: -170035.296875\n",
      "Train Epoch: 90 [12720/17352 (73%)] Loss: -196406.984375\n",
      "Train Epoch: 90 [12800/17352 (74%)] Loss: -192317.046875\n",
      "Train Epoch: 90 [12880/17352 (74%)] Loss: -175546.390625\n",
      "Train Epoch: 90 [12960/17352 (75%)] Loss: -192957.703125\n",
      "Train Epoch: 90 [13040/17352 (75%)] Loss: -190797.000000\n",
      "Train Epoch: 90 [13120/17352 (76%)] Loss: -171837.843750\n",
      "Train Epoch: 90 [13200/17352 (76%)] Loss: -192887.656250\n",
      "Train Epoch: 90 [13280/17352 (77%)] Loss: -140591.937500\n",
      "Train Epoch: 90 [13360/17352 (77%)] Loss: -198803.625000\n",
      "Train Epoch: 90 [13440/17352 (77%)] Loss: -199792.187500\n",
      "Train Epoch: 90 [13520/17352 (78%)] Loss: -205404.000000\n",
      "Train Epoch: 90 [13600/17352 (78%)] Loss: -165603.437500\n",
      "Train Epoch: 90 [13680/17352 (79%)] Loss: -169976.484375\n",
      "Train Epoch: 90 [13760/17352 (79%)] Loss: -213187.062500\n",
      "Train Epoch: 90 [13840/17352 (80%)] Loss: -166653.781250\n",
      "Train Epoch: 90 [13920/17352 (80%)] Loss: -193802.062500\n",
      "Train Epoch: 90 [14000/17352 (81%)] Loss: -205167.156250\n",
      "Train Epoch: 90 [14080/17352 (81%)] Loss: -203816.187500\n",
      "Train Epoch: 90 [14160/17352 (82%)] Loss: -188509.765625\n",
      "Train Epoch: 90 [14240/17352 (82%)] Loss: -181017.484375\n",
      "Train Epoch: 90 [14320/17352 (83%)] Loss: -178216.531250\n",
      "Train Epoch: 90 [14400/17352 (83%)] Loss: -191808.312500\n",
      "Train Epoch: 90 [14480/17352 (83%)] Loss: -186512.328125\n",
      "Train Epoch: 90 [14560/17352 (84%)] Loss: -210157.750000\n",
      "Train Epoch: 90 [14640/17352 (84%)] Loss: -189726.265625\n",
      "Train Epoch: 90 [14720/17352 (85%)] Loss: -191628.859375\n",
      "Train Epoch: 90 [14800/17352 (85%)] Loss: -212128.781250\n",
      "Train Epoch: 90 [14880/17352 (86%)] Loss: -192247.531250\n",
      "Train Epoch: 90 [14960/17352 (86%)] Loss: -187526.703125\n",
      "Train Epoch: 90 [15040/17352 (87%)] Loss: -179482.078125\n",
      "Train Epoch: 90 [15120/17352 (87%)] Loss: -179172.515625\n",
      "Train Epoch: 90 [15200/17352 (88%)] Loss: -188449.218750\n",
      "Train Epoch: 90 [15280/17352 (88%)] Loss: -167488.437500\n",
      "Train Epoch: 90 [15360/17352 (89%)] Loss: -215653.046875\n",
      "Train Epoch: 90 [15440/17352 (89%)] Loss: -187791.500000\n",
      "Train Epoch: 90 [15520/17352 (89%)] Loss: -173664.421875\n",
      "Train Epoch: 90 [15600/17352 (90%)] Loss: -193049.421875\n",
      "Train Epoch: 90 [15680/17352 (90%)] Loss: -177787.984375\n",
      "Train Epoch: 90 [15760/17352 (91%)] Loss: -202308.343750\n",
      "Train Epoch: 90 [15840/17352 (91%)] Loss: -165390.687500\n",
      "Train Epoch: 90 [15920/17352 (92%)] Loss: -172552.859375\n",
      "Train Epoch: 90 [16000/17352 (92%)] Loss: -163257.031250\n",
      "Train Epoch: 90 [16080/17352 (93%)] Loss: -214686.921875\n",
      "Train Epoch: 90 [16160/17352 (93%)] Loss: -181377.828125\n",
      "Train Epoch: 90 [16240/17352 (94%)] Loss: -215178.468750\n",
      "Train Epoch: 90 [16320/17352 (94%)] Loss: -197595.328125\n",
      "Train Epoch: 90 [16400/17352 (95%)] Loss: -209186.453125\n",
      "Train Epoch: 90 [16480/17352 (95%)] Loss: -172231.140625\n",
      "Train Epoch: 90 [16560/17352 (95%)] Loss: -178580.109375\n",
      "Train Epoch: 90 [16640/17352 (96%)] Loss: -183507.125000\n",
      "Train Epoch: 90 [16720/17352 (96%)] Loss: -169949.156250\n",
      "Train Epoch: 90 [16800/17352 (97%)] Loss: -167874.875000\n",
      "Train Epoch: 90 [16880/17352 (97%)] Loss: -203274.171875\n",
      "Train Epoch: 90 [16960/17352 (98%)] Loss: -183974.859375\n",
      "Train Epoch: 90 [17040/17352 (98%)] Loss: -200083.046875\n",
      "Train Epoch: 90 [17120/17352 (99%)] Loss: -164756.609375\n",
      "Train Epoch: 90 [17200/17352 (99%)] Loss: -225472.375000\n",
      "Train Epoch: 90 [17280/17352 (100%)] Loss: -196304.296875\n",
      "Train Epoch: 90 [17360/17352 (100%)] Loss: -164959.031250\n",
      "    epoch          : 90\n",
      "    loss           : -189225.83581163693\n",
      "    val_loss       : -23716.316901623362\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch90.pth ...\n",
      "Train Epoch: 91 [0/17352 (0%)] Loss: -212656.218750\n",
      "Train Epoch: 91 [80/17352 (0%)] Loss: -224347.421875\n",
      "Train Epoch: 91 [160/17352 (1%)] Loss: -213317.828125\n",
      "Train Epoch: 91 [240/17352 (1%)] Loss: -196929.734375\n",
      "Train Epoch: 91 [320/17352 (2%)] Loss: -217937.062500\n",
      "Train Epoch: 91 [400/17352 (2%)] Loss: -194303.156250\n",
      "Train Epoch: 91 [480/17352 (3%)] Loss: -205214.437500\n",
      "Train Epoch: 91 [560/17352 (3%)] Loss: -210530.843750\n",
      "Train Epoch: 91 [640/17352 (4%)] Loss: -210204.640625\n",
      "Train Epoch: 91 [720/17352 (4%)] Loss: -223004.828125\n",
      "Train Epoch: 91 [800/17352 (5%)] Loss: -213333.281250\n",
      "Train Epoch: 91 [880/17352 (5%)] Loss: -235584.546875\n",
      "Train Epoch: 91 [960/17352 (6%)] Loss: -205195.812500\n",
      "Train Epoch: 91 [1040/17352 (6%)] Loss: -203268.031250\n",
      "Train Epoch: 91 [1120/17352 (6%)] Loss: -204709.187500\n",
      "Train Epoch: 91 [1200/17352 (7%)] Loss: -199806.187500\n",
      "Train Epoch: 91 [1280/17352 (7%)] Loss: -217628.640625\n",
      "Train Epoch: 91 [1360/17352 (8%)] Loss: -221473.859375\n",
      "Train Epoch: 91 [1440/17352 (8%)] Loss: -198777.031250\n",
      "Train Epoch: 91 [1520/17352 (9%)] Loss: -215829.734375\n",
      "Train Epoch: 91 [1600/17352 (9%)] Loss: -205558.421875\n",
      "Train Epoch: 91 [1680/17352 (10%)] Loss: -193413.031250\n",
      "Train Epoch: 91 [1760/17352 (10%)] Loss: -215498.812500\n",
      "Train Epoch: 91 [1840/17352 (11%)] Loss: -204534.703125\n",
      "Train Epoch: 91 [1920/17352 (11%)] Loss: -228897.687500\n",
      "Train Epoch: 91 [2000/17352 (12%)] Loss: -209547.812500\n",
      "Train Epoch: 91 [2080/17352 (12%)] Loss: -199105.703125\n",
      "Train Epoch: 91 [2160/17352 (12%)] Loss: -198122.406250\n",
      "Train Epoch: 91 [2240/17352 (13%)] Loss: -166252.890625\n",
      "Train Epoch: 91 [2320/17352 (13%)] Loss: -204701.609375\n",
      "Train Epoch: 91 [2400/17352 (14%)] Loss: -182776.687500\n",
      "Train Epoch: 91 [2480/17352 (14%)] Loss: -210265.109375\n",
      "Train Epoch: 91 [2560/17352 (15%)] Loss: -159091.968750\n",
      "Train Epoch: 91 [2640/17352 (15%)] Loss: -177144.187500\n",
      "Train Epoch: 91 [2720/17352 (16%)] Loss: -185007.109375\n",
      "Train Epoch: 91 [2800/17352 (16%)] Loss: -191636.203125\n",
      "Train Epoch: 91 [2880/17352 (17%)] Loss: -183792.609375\n",
      "Train Epoch: 91 [2960/17352 (17%)] Loss: -173037.890625\n",
      "Train Epoch: 91 [3040/17352 (18%)] Loss: -165396.312500\n",
      "Train Epoch: 91 [3120/17352 (18%)] Loss: -173306.859375\n",
      "Train Epoch: 91 [3200/17352 (18%)] Loss: -179466.250000\n",
      "Train Epoch: 91 [3280/17352 (19%)] Loss: -190624.343750\n",
      "Train Epoch: 91 [3360/17352 (19%)] Loss: -205515.203125\n",
      "Train Epoch: 91 [3440/17352 (20%)] Loss: -191892.296875\n",
      "Train Epoch: 91 [3520/17352 (20%)] Loss: -176683.359375\n",
      "Train Epoch: 91 [3600/17352 (21%)] Loss: -218847.671875\n",
      "Train Epoch: 91 [3680/17352 (21%)] Loss: -196158.500000\n",
      "Train Epoch: 91 [3760/17352 (22%)] Loss: -187647.765625\n",
      "Train Epoch: 91 [3840/17352 (22%)] Loss: -173663.593750\n",
      "Train Epoch: 91 [3920/17352 (23%)] Loss: -192011.828125\n",
      "Train Epoch: 91 [4000/17352 (23%)] Loss: -190807.265625\n",
      "Train Epoch: 91 [4080/17352 (24%)] Loss: -193176.640625\n",
      "Train Epoch: 91 [4160/17352 (24%)] Loss: -206568.546875\n",
      "Train Epoch: 91 [4240/17352 (24%)] Loss: -199791.375000\n",
      "Train Epoch: 91 [4320/17352 (25%)] Loss: -170353.734375\n",
      "Train Epoch: 91 [4400/17352 (25%)] Loss: -182330.140625\n",
      "Train Epoch: 91 [4480/17352 (26%)] Loss: -178869.781250\n",
      "Train Epoch: 91 [4560/17352 (26%)] Loss: -176537.140625\n",
      "Train Epoch: 91 [4640/17352 (27%)] Loss: -165608.968750\n",
      "Train Epoch: 91 [4720/17352 (27%)] Loss: -191006.593750\n",
      "Train Epoch: 91 [4800/17352 (28%)] Loss: -212899.203125\n",
      "Train Epoch: 91 [4880/17352 (28%)] Loss: -209197.250000\n",
      "Train Epoch: 91 [4960/17352 (29%)] Loss: -155862.265625\n",
      "Train Epoch: 91 [5040/17352 (29%)] Loss: -183784.093750\n",
      "Train Epoch: 91 [5120/17352 (30%)] Loss: -175672.218750\n",
      "Train Epoch: 91 [5200/17352 (30%)] Loss: -192010.312500\n",
      "Train Epoch: 91 [5280/17352 (30%)] Loss: -208725.031250\n",
      "Train Epoch: 91 [5360/17352 (31%)] Loss: -198830.562500\n",
      "Train Epoch: 91 [5440/17352 (31%)] Loss: -209591.937500\n",
      "Train Epoch: 91 [5520/17352 (32%)] Loss: -173661.781250\n",
      "Train Epoch: 91 [5600/17352 (32%)] Loss: -168674.796875\n",
      "Train Epoch: 91 [5680/17352 (33%)] Loss: -178218.546875\n",
      "Train Epoch: 91 [5760/17352 (33%)] Loss: -202477.828125\n",
      "Train Epoch: 91 [5840/17352 (34%)] Loss: -185366.484375\n",
      "Train Epoch: 91 [5920/17352 (34%)] Loss: -210639.687500\n",
      "Train Epoch: 91 [6000/17352 (35%)] Loss: -199801.656250\n",
      "Train Epoch: 91 [6080/17352 (35%)] Loss: -187597.062500\n",
      "Train Epoch: 91 [6160/17352 (36%)] Loss: -206214.531250\n",
      "Train Epoch: 91 [6240/17352 (36%)] Loss: -202877.359375\n",
      "Train Epoch: 91 [6320/17352 (36%)] Loss: -177981.031250\n",
      "Train Epoch: 91 [6400/17352 (37%)] Loss: -198698.156250\n",
      "Train Epoch: 91 [6480/17352 (37%)] Loss: -201264.687500\n",
      "Train Epoch: 91 [6560/17352 (38%)] Loss: -177473.703125\n",
      "Train Epoch: 91 [6640/17352 (38%)] Loss: -215970.484375\n",
      "Train Epoch: 91 [6720/17352 (39%)] Loss: -187400.578125\n",
      "Train Epoch: 91 [6800/17352 (39%)] Loss: -184759.906250\n",
      "Train Epoch: 91 [6880/17352 (40%)] Loss: -188441.109375\n",
      "Train Epoch: 91 [6960/17352 (40%)] Loss: -200272.453125\n",
      "Train Epoch: 91 [7040/17352 (41%)] Loss: -176274.875000\n",
      "Train Epoch: 91 [7120/17352 (41%)] Loss: -188972.921875\n",
      "Train Epoch: 91 [7200/17352 (41%)] Loss: -192372.390625\n",
      "Train Epoch: 91 [7280/17352 (42%)] Loss: -194935.046875\n",
      "Train Epoch: 91 [7360/17352 (42%)] Loss: -197602.609375\n",
      "Train Epoch: 91 [7440/17352 (43%)] Loss: -173585.812500\n",
      "Train Epoch: 91 [7520/17352 (43%)] Loss: -196255.093750\n",
      "Train Epoch: 91 [7600/17352 (44%)] Loss: -203885.875000\n",
      "Train Epoch: 91 [7680/17352 (44%)] Loss: -179680.125000\n",
      "Train Epoch: 91 [7760/17352 (45%)] Loss: -193052.468750\n",
      "Train Epoch: 91 [7840/17352 (45%)] Loss: -175319.171875\n",
      "Train Epoch: 91 [7920/17352 (46%)] Loss: -193366.046875\n",
      "Train Epoch: 91 [8000/17352 (46%)] Loss: -129699.328125\n",
      "Train Epoch: 91 [8080/17352 (47%)] Loss: -206360.750000\n",
      "Train Epoch: 91 [8160/17352 (47%)] Loss: -176054.703125\n",
      "Train Epoch: 91 [8240/17352 (47%)] Loss: -192884.140625\n",
      "Train Epoch: 91 [8320/17352 (48%)] Loss: -165867.953125\n",
      "Train Epoch: 91 [8400/17352 (48%)] Loss: -165736.531250\n",
      "Train Epoch: 91 [8480/17352 (49%)] Loss: -207856.265625\n",
      "Train Epoch: 91 [8560/17352 (49%)] Loss: -205020.812500\n",
      "Train Epoch: 91 [8640/17352 (50%)] Loss: -189270.828125\n",
      "Train Epoch: 91 [8720/17352 (50%)] Loss: -159739.171875\n",
      "Train Epoch: 91 [8800/17352 (51%)] Loss: -190213.875000\n",
      "Train Epoch: 91 [8880/17352 (51%)] Loss: -208157.687500\n",
      "Train Epoch: 91 [8960/17352 (52%)] Loss: -177304.812500\n",
      "Train Epoch: 91 [9040/17352 (52%)] Loss: -180255.828125\n",
      "Train Epoch: 91 [9120/17352 (53%)] Loss: -186520.921875\n",
      "Train Epoch: 91 [9200/17352 (53%)] Loss: -174489.015625\n",
      "Train Epoch: 91 [9280/17352 (53%)] Loss: -189601.593750\n",
      "Train Epoch: 91 [9360/17352 (54%)] Loss: -224862.859375\n",
      "Train Epoch: 91 [9440/17352 (54%)] Loss: -187529.312500\n",
      "Train Epoch: 91 [9520/17352 (55%)] Loss: -174524.078125\n",
      "Train Epoch: 91 [9600/17352 (55%)] Loss: -136430.000000\n",
      "Train Epoch: 91 [9680/17352 (56%)] Loss: -231037.375000\n",
      "Train Epoch: 91 [9760/17352 (56%)] Loss: -187358.078125\n",
      "Train Epoch: 91 [9840/17352 (57%)] Loss: -197649.375000\n",
      "Train Epoch: 91 [9920/17352 (57%)] Loss: -183223.187500\n",
      "Train Epoch: 91 [10000/17352 (58%)] Loss: -185240.031250\n",
      "Train Epoch: 91 [10080/17352 (58%)] Loss: -211725.328125\n",
      "Train Epoch: 91 [10160/17352 (59%)] Loss: -176161.656250\n",
      "Train Epoch: 91 [10240/17352 (59%)] Loss: -149033.390625\n",
      "Train Epoch: 91 [10320/17352 (59%)] Loss: -192791.265625\n",
      "Train Epoch: 91 [10400/17352 (60%)] Loss: -187550.703125\n",
      "Train Epoch: 91 [10480/17352 (60%)] Loss: -176588.359375\n",
      "Train Epoch: 91 [10560/17352 (61%)] Loss: -196731.578125\n",
      "Train Epoch: 91 [10640/17352 (61%)] Loss: -191810.265625\n",
      "Train Epoch: 91 [10720/17352 (62%)] Loss: -193495.000000\n",
      "Train Epoch: 91 [10800/17352 (62%)] Loss: -168079.859375\n",
      "Train Epoch: 91 [10880/17352 (63%)] Loss: -167186.750000\n",
      "Train Epoch: 91 [10960/17352 (63%)] Loss: -178662.562500\n",
      "Train Epoch: 91 [11040/17352 (64%)] Loss: -159752.734375\n",
      "Train Epoch: 91 [11120/17352 (64%)] Loss: -164142.093750\n",
      "Train Epoch: 91 [11200/17352 (65%)] Loss: -192957.984375\n",
      "Train Epoch: 91 [11280/17352 (65%)] Loss: -190084.812500\n",
      "Train Epoch: 91 [11360/17352 (65%)] Loss: -200122.468750\n",
      "Train Epoch: 91 [11440/17352 (66%)] Loss: -157489.546875\n",
      "Train Epoch: 91 [11520/17352 (66%)] Loss: -187128.718750\n",
      "Train Epoch: 91 [11600/17352 (67%)] Loss: -177302.484375\n",
      "Train Epoch: 91 [11680/17352 (67%)] Loss: -222860.828125\n",
      "Train Epoch: 91 [11760/17352 (68%)] Loss: -190236.140625\n",
      "Train Epoch: 91 [11840/17352 (68%)] Loss: -182743.093750\n",
      "Train Epoch: 91 [11920/17352 (69%)] Loss: -192172.765625\n",
      "Train Epoch: 91 [12000/17352 (69%)] Loss: -185807.500000\n",
      "Train Epoch: 91 [12080/17352 (70%)] Loss: -215654.750000\n",
      "Train Epoch: 91 [12160/17352 (70%)] Loss: -191333.968750\n",
      "Train Epoch: 91 [12240/17352 (71%)] Loss: -185787.171875\n",
      "Train Epoch: 91 [12320/17352 (71%)] Loss: -131050.453125\n",
      "Train Epoch: 91 [12400/17352 (71%)] Loss: -199412.000000\n",
      "Train Epoch: 91 [12480/17352 (72%)] Loss: -200838.546875\n",
      "Train Epoch: 91 [12560/17352 (72%)] Loss: -188008.484375\n",
      "Train Epoch: 91 [12640/17352 (73%)] Loss: -192959.984375\n",
      "Train Epoch: 91 [12720/17352 (73%)] Loss: -195647.781250\n",
      "Train Epoch: 91 [12800/17352 (74%)] Loss: -223690.640625\n",
      "Train Epoch: 91 [12880/17352 (74%)] Loss: -176967.375000\n",
      "Train Epoch: 91 [12960/17352 (75%)] Loss: -186848.437500\n",
      "Train Epoch: 91 [13040/17352 (75%)] Loss: -176922.187500\n",
      "Train Epoch: 91 [13120/17352 (76%)] Loss: -183926.750000\n",
      "Train Epoch: 91 [13200/17352 (76%)] Loss: -187723.500000\n",
      "Train Epoch: 91 [13280/17352 (77%)] Loss: -180312.890625\n",
      "Train Epoch: 91 [13360/17352 (77%)] Loss: -170681.750000\n",
      "Train Epoch: 91 [13440/17352 (77%)] Loss: -209507.125000\n",
      "Train Epoch: 91 [13520/17352 (78%)] Loss: -171443.125000\n",
      "Train Epoch: 91 [13600/17352 (78%)] Loss: -189567.781250\n",
      "Train Epoch: 91 [13680/17352 (79%)] Loss: -184756.687500\n",
      "Train Epoch: 91 [13760/17352 (79%)] Loss: -183764.765625\n",
      "Train Epoch: 91 [13840/17352 (80%)] Loss: -175740.703125\n",
      "Train Epoch: 91 [13920/17352 (80%)] Loss: -206465.953125\n",
      "Train Epoch: 91 [14000/17352 (81%)] Loss: -188504.312500\n",
      "Train Epoch: 91 [14080/17352 (81%)] Loss: -164951.875000\n",
      "Train Epoch: 91 [14160/17352 (82%)] Loss: -177198.265625\n",
      "Train Epoch: 91 [14240/17352 (82%)] Loss: -189604.437500\n",
      "Train Epoch: 91 [14320/17352 (83%)] Loss: -180145.703125\n",
      "Train Epoch: 91 [14400/17352 (83%)] Loss: -184456.421875\n",
      "Train Epoch: 91 [14480/17352 (83%)] Loss: -204347.078125\n",
      "Train Epoch: 91 [14560/17352 (84%)] Loss: -189810.484375\n",
      "Train Epoch: 91 [14640/17352 (84%)] Loss: -186727.234375\n",
      "Train Epoch: 91 [14720/17352 (85%)] Loss: -184947.765625\n",
      "Train Epoch: 91 [14800/17352 (85%)] Loss: -183259.062500\n",
      "Train Epoch: 91 [14880/17352 (86%)] Loss: -193492.437500\n",
      "Train Epoch: 91 [14960/17352 (86%)] Loss: -196452.218750\n",
      "Train Epoch: 91 [15040/17352 (87%)] Loss: -204664.703125\n",
      "Train Epoch: 91 [15120/17352 (87%)] Loss: -213185.359375\n",
      "Train Epoch: 91 [15200/17352 (88%)] Loss: -185935.515625\n",
      "Train Epoch: 91 [15280/17352 (88%)] Loss: -215466.953125\n",
      "Train Epoch: 91 [15360/17352 (89%)] Loss: -199178.718750\n",
      "Train Epoch: 91 [15440/17352 (89%)] Loss: -203813.375000\n",
      "Train Epoch: 91 [15520/17352 (89%)] Loss: -192231.015625\n",
      "Train Epoch: 91 [15600/17352 (90%)] Loss: -194236.984375\n",
      "Train Epoch: 91 [15680/17352 (90%)] Loss: -192268.984375\n",
      "Train Epoch: 91 [15760/17352 (91%)] Loss: -191312.343750\n",
      "Train Epoch: 91 [15840/17352 (91%)] Loss: -177172.890625\n",
      "Train Epoch: 91 [15920/17352 (92%)] Loss: -188907.718750\n",
      "Train Epoch: 91 [16000/17352 (92%)] Loss: -149446.078125\n",
      "Train Epoch: 91 [16080/17352 (93%)] Loss: -170785.890625\n",
      "Train Epoch: 91 [16160/17352 (93%)] Loss: -197523.312500\n",
      "Train Epoch: 91 [16240/17352 (94%)] Loss: -173454.578125\n",
      "Train Epoch: 91 [16320/17352 (94%)] Loss: -196200.453125\n",
      "Train Epoch: 91 [16400/17352 (95%)] Loss: -196286.468750\n",
      "Train Epoch: 91 [16480/17352 (95%)] Loss: -202856.562500\n",
      "Train Epoch: 91 [16560/17352 (95%)] Loss: -196039.187500\n",
      "Train Epoch: 91 [16640/17352 (96%)] Loss: -218516.484375\n",
      "Train Epoch: 91 [16720/17352 (96%)] Loss: -179309.125000\n",
      "Train Epoch: 91 [16800/17352 (97%)] Loss: -192987.531250\n",
      "Train Epoch: 91 [16880/17352 (97%)] Loss: -196118.500000\n",
      "Train Epoch: 91 [16960/17352 (98%)] Loss: -184843.078125\n",
      "Train Epoch: 91 [17040/17352 (98%)] Loss: -202242.687500\n",
      "Train Epoch: 91 [17120/17352 (99%)] Loss: -177245.140625\n",
      "Train Epoch: 91 [17200/17352 (99%)] Loss: -177200.734375\n",
      "Train Epoch: 91 [17280/17352 (100%)] Loss: -200201.109375\n",
      "Train Epoch: 91 [17360/17352 (100%)] Loss: -202194.750000\n",
      "    epoch          : 91\n",
      "    loss           : -189363.75342527332\n",
      "    val_loss       : -23716.33978371777\n",
      "Train Epoch: 92 [0/17352 (0%)] Loss: -210527.765625\n",
      "Train Epoch: 92 [80/17352 (0%)] Loss: -205112.421875\n",
      "Train Epoch: 92 [160/17352 (1%)] Loss: -199105.671875\n",
      "Train Epoch: 92 [240/17352 (1%)] Loss: -212399.578125\n",
      "Train Epoch: 92 [320/17352 (2%)] Loss: -205082.484375\n",
      "Train Epoch: 92 [400/17352 (2%)] Loss: -210756.562500\n",
      "Train Epoch: 92 [480/17352 (3%)] Loss: -209555.687500\n",
      "Train Epoch: 92 [560/17352 (3%)] Loss: -231330.328125\n",
      "Train Epoch: 92 [640/17352 (4%)] Loss: -214338.484375\n",
      "Train Epoch: 92 [720/17352 (4%)] Loss: -198113.687500\n",
      "Train Epoch: 92 [800/17352 (5%)] Loss: -215832.328125\n",
      "Train Epoch: 92 [880/17352 (5%)] Loss: -213322.984375\n",
      "Train Epoch: 92 [960/17352 (6%)] Loss: -205197.031250\n",
      "Train Epoch: 92 [1040/17352 (6%)] Loss: -205933.859375\n",
      "Train Epoch: 92 [1120/17352 (6%)] Loss: -182778.718750\n",
      "Train Epoch: 92 [1200/17352 (7%)] Loss: -214511.843750\n",
      "Train Epoch: 92 [1280/17352 (7%)] Loss: -193707.156250\n",
      "Train Epoch: 92 [1360/17352 (8%)] Loss: -207169.187500\n",
      "Train Epoch: 92 [1440/17352 (8%)] Loss: -219203.531250\n",
      "Train Epoch: 92 [1520/17352 (9%)] Loss: -219668.484375\n",
      "Train Epoch: 92 [1600/17352 (9%)] Loss: -216106.875000\n",
      "Train Epoch: 92 [1680/17352 (10%)] Loss: -202323.843750\n",
      "Train Epoch: 92 [1760/17352 (10%)] Loss: -196923.843750\n",
      "Train Epoch: 92 [1840/17352 (11%)] Loss: -236632.750000\n",
      "Train Epoch: 92 [1920/17352 (11%)] Loss: -221475.781250\n",
      "Train Epoch: 92 [2000/17352 (12%)] Loss: -226096.015625\n",
      "Train Epoch: 92 [2080/17352 (12%)] Loss: -208382.968750\n",
      "Train Epoch: 92 [2160/17352 (12%)] Loss: -219267.093750\n",
      "Train Epoch: 92 [2240/17352 (13%)] Loss: -187529.500000\n",
      "Train Epoch: 92 [2320/17352 (13%)] Loss: -183613.468750\n",
      "Train Epoch: 92 [2400/17352 (14%)] Loss: -175505.687500\n",
      "Train Epoch: 92 [2480/17352 (14%)] Loss: -180542.718750\n",
      "Train Epoch: 92 [2560/17352 (15%)] Loss: -193133.484375\n",
      "Train Epoch: 92 [2640/17352 (15%)] Loss: -218524.765625\n",
      "Train Epoch: 92 [2720/17352 (16%)] Loss: -185049.609375\n",
      "Train Epoch: 92 [2800/17352 (16%)] Loss: -185595.343750\n",
      "Train Epoch: 92 [2880/17352 (17%)] Loss: -165864.718750\n",
      "Train Epoch: 92 [2960/17352 (17%)] Loss: -192128.109375\n",
      "Train Epoch: 92 [3040/17352 (18%)] Loss: -187258.968750\n",
      "Train Epoch: 92 [3120/17352 (18%)] Loss: -191559.546875\n",
      "Train Epoch: 92 [3200/17352 (18%)] Loss: -177607.281250\n",
      "Train Epoch: 92 [3280/17352 (19%)] Loss: -179416.000000\n",
      "Train Epoch: 92 [3360/17352 (19%)] Loss: -177240.484375\n",
      "Train Epoch: 92 [3440/17352 (20%)] Loss: -192268.312500\n",
      "Train Epoch: 92 [3520/17352 (20%)] Loss: -167252.671875\n",
      "Train Epoch: 92 [3600/17352 (21%)] Loss: -207839.578125\n",
      "Train Epoch: 92 [3680/17352 (21%)] Loss: -199722.453125\n",
      "Train Epoch: 92 [3760/17352 (22%)] Loss: -163107.359375\n",
      "Train Epoch: 92 [3840/17352 (22%)] Loss: -181164.750000\n",
      "Train Epoch: 92 [3920/17352 (23%)] Loss: -170039.750000\n",
      "Train Epoch: 92 [4000/17352 (23%)] Loss: -228250.546875\n",
      "Train Epoch: 92 [4080/17352 (24%)] Loss: -173509.062500\n",
      "Train Epoch: 92 [4160/17352 (24%)] Loss: -159317.625000\n",
      "Train Epoch: 92 [4240/17352 (24%)] Loss: -177629.281250\n",
      "Train Epoch: 92 [4320/17352 (25%)] Loss: -204607.171875\n",
      "Train Epoch: 92 [4400/17352 (25%)] Loss: -200174.671875\n",
      "Train Epoch: 92 [4480/17352 (26%)] Loss: -200168.343750\n",
      "Train Epoch: 92 [4560/17352 (26%)] Loss: -192228.406250\n",
      "Train Epoch: 92 [4640/17352 (27%)] Loss: -228150.218750\n",
      "Train Epoch: 92 [4720/17352 (27%)] Loss: -180035.484375\n",
      "Train Epoch: 92 [4800/17352 (28%)] Loss: -189600.250000\n",
      "Train Epoch: 92 [4880/17352 (28%)] Loss: -164083.328125\n",
      "Train Epoch: 92 [4960/17352 (29%)] Loss: -203813.421875\n",
      "Train Epoch: 92 [5040/17352 (29%)] Loss: -172971.718750\n",
      "Train Epoch: 92 [5120/17352 (30%)] Loss: -175014.000000\n",
      "Train Epoch: 92 [5200/17352 (30%)] Loss: -186685.953125\n",
      "Train Epoch: 92 [5280/17352 (30%)] Loss: -177148.187500\n",
      "Train Epoch: 92 [5360/17352 (31%)] Loss: -167298.906250\n",
      "Train Epoch: 92 [5440/17352 (31%)] Loss: -157595.890625\n",
      "Train Epoch: 92 [5520/17352 (32%)] Loss: -202941.890625\n",
      "Train Epoch: 92 [5600/17352 (32%)] Loss: -178824.578125\n",
      "Train Epoch: 92 [5680/17352 (33%)] Loss: -220977.250000\n",
      "Train Epoch: 92 [5760/17352 (33%)] Loss: -181431.734375\n",
      "Train Epoch: 92 [5840/17352 (34%)] Loss: -197306.203125\n",
      "Train Epoch: 92 [5920/17352 (34%)] Loss: -170539.921875\n",
      "Train Epoch: 92 [6000/17352 (35%)] Loss: -161962.265625\n",
      "Train Epoch: 92 [6080/17352 (35%)] Loss: -173367.968750\n",
      "Train Epoch: 92 [6160/17352 (36%)] Loss: -196931.843750\n",
      "Train Epoch: 92 [6240/17352 (36%)] Loss: -186046.406250\n",
      "Train Epoch: 92 [6320/17352 (36%)] Loss: -171225.828125\n",
      "Train Epoch: 92 [6400/17352 (37%)] Loss: -175748.187500\n",
      "Train Epoch: 92 [6480/17352 (37%)] Loss: -175073.750000\n",
      "Train Epoch: 92 [6560/17352 (38%)] Loss: -196570.875000\n",
      "Train Epoch: 92 [6640/17352 (38%)] Loss: -184921.625000\n",
      "Train Epoch: 92 [6720/17352 (39%)] Loss: -202991.625000\n",
      "Train Epoch: 92 [6800/17352 (39%)] Loss: -174916.906250\n",
      "Train Epoch: 92 [6880/17352 (40%)] Loss: -190940.093750\n",
      "Train Epoch: 92 [6960/17352 (40%)] Loss: -194235.406250\n",
      "Train Epoch: 92 [7040/17352 (41%)] Loss: -167211.484375\n",
      "Train Epoch: 92 [7120/17352 (41%)] Loss: -177195.953125\n",
      "Train Epoch: 92 [7200/17352 (41%)] Loss: -204213.093750\n",
      "Train Epoch: 92 [7280/17352 (42%)] Loss: -196289.640625\n",
      "Train Epoch: 92 [7360/17352 (42%)] Loss: -193923.515625\n",
      "Train Epoch: 92 [7440/17352 (43%)] Loss: -196198.031250\n",
      "Train Epoch: 92 [7520/17352 (43%)] Loss: -148397.640625\n",
      "Train Epoch: 92 [7600/17352 (44%)] Loss: -192886.593750\n",
      "Train Epoch: 92 [7680/17352 (44%)] Loss: -148162.515625\n",
      "Train Epoch: 92 [7760/17352 (45%)] Loss: -167247.234375\n",
      "Train Epoch: 92 [7840/17352 (45%)] Loss: -176681.250000\n",
      "Train Epoch: 92 [7920/17352 (46%)] Loss: -190004.312500\n",
      "Train Epoch: 92 [8000/17352 (46%)] Loss: -147418.296875\n",
      "Train Epoch: 92 [8080/17352 (47%)] Loss: -205167.843750\n",
      "Train Epoch: 92 [8160/17352 (47%)] Loss: -196040.765625\n",
      "Train Epoch: 92 [8240/17352 (47%)] Loss: -179738.890625\n",
      "Train Epoch: 92 [8320/17352 (48%)] Loss: -183394.328125\n",
      "Train Epoch: 92 [8400/17352 (48%)] Loss: -177601.812500\n",
      "Train Epoch: 92 [8480/17352 (49%)] Loss: -176699.187500\n",
      "Train Epoch: 92 [8560/17352 (49%)] Loss: -171417.531250\n",
      "Train Epoch: 92 [8640/17352 (50%)] Loss: -171441.062500\n",
      "Train Epoch: 92 [8720/17352 (50%)] Loss: -188507.359375\n",
      "Train Epoch: 92 [8800/17352 (51%)] Loss: -180910.921875\n",
      "Train Epoch: 92 [8880/17352 (51%)] Loss: -211720.765625\n",
      "Train Epoch: 92 [8960/17352 (52%)] Loss: -192176.375000\n",
      "Train Epoch: 92 [9040/17352 (52%)] Loss: -183227.671875\n",
      "Train Epoch: 92 [9120/17352 (53%)] Loss: -187953.812500\n",
      "Train Epoch: 92 [9200/17352 (53%)] Loss: -184737.796875\n",
      "Train Epoch: 92 [9280/17352 (53%)] Loss: -175691.062500\n",
      "Train Epoch: 92 [9360/17352 (54%)] Loss: -209894.781250\n",
      "Train Epoch: 92 [9440/17352 (54%)] Loss: -184753.187500\n",
      "Train Epoch: 92 [9520/17352 (55%)] Loss: -163559.140625\n",
      "Train Epoch: 92 [9600/17352 (55%)] Loss: -182530.843750\n",
      "Train Epoch: 92 [9680/17352 (56%)] Loss: -195887.828125\n",
      "Train Epoch: 92 [9760/17352 (56%)] Loss: -188436.265625\n",
      "Train Epoch: 92 [9840/17352 (57%)] Loss: -164681.390625\n",
      "Train Epoch: 92 [9920/17352 (57%)] Loss: -179441.468750\n",
      "Train Epoch: 92 [10000/17352 (58%)] Loss: -212663.484375\n",
      "Train Epoch: 92 [10080/17352 (58%)] Loss: -178215.859375\n",
      "Train Epoch: 92 [10160/17352 (59%)] Loss: -199897.562500\n",
      "Train Epoch: 92 [10240/17352 (59%)] Loss: -163246.875000\n",
      "Train Epoch: 92 [10320/17352 (59%)] Loss: -197089.078125\n",
      "Train Epoch: 92 [10400/17352 (60%)] Loss: -183787.921875\n",
      "Train Epoch: 92 [10480/17352 (60%)] Loss: -210257.546875\n",
      "Train Epoch: 92 [10560/17352 (61%)] Loss: -178671.296875\n",
      "Train Epoch: 92 [10640/17352 (61%)] Loss: -193005.328125\n",
      "Train Epoch: 92 [10720/17352 (62%)] Loss: -159672.812500\n",
      "Train Epoch: 92 [10800/17352 (62%)] Loss: -181260.328125\n",
      "Train Epoch: 92 [10880/17352 (63%)] Loss: -184493.812500\n",
      "Train Epoch: 92 [10960/17352 (63%)] Loss: -201036.593750\n",
      "Train Epoch: 92 [11040/17352 (64%)] Loss: -193950.312500\n",
      "Train Epoch: 92 [11120/17352 (64%)] Loss: -162559.843750\n",
      "Train Epoch: 92 [11200/17352 (65%)] Loss: -183726.109375\n",
      "Train Epoch: 92 [11280/17352 (65%)] Loss: -191056.562500\n",
      "Train Epoch: 92 [11360/17352 (65%)] Loss: -178319.359375\n",
      "Train Epoch: 92 [11440/17352 (66%)] Loss: -203149.296875\n",
      "Train Epoch: 92 [11520/17352 (66%)] Loss: -184027.515625\n",
      "Train Epoch: 92 [11600/17352 (67%)] Loss: -201319.484375\n",
      "Train Epoch: 92 [11680/17352 (67%)] Loss: -192118.375000\n",
      "Train Epoch: 92 [11760/17352 (68%)] Loss: -180262.406250\n",
      "Train Epoch: 92 [11840/17352 (68%)] Loss: -196163.421875\n",
      "Train Epoch: 92 [11920/17352 (69%)] Loss: -155862.515625\n",
      "Train Epoch: 92 [12000/17352 (69%)] Loss: -205727.593750\n",
      "Train Epoch: 92 [12080/17352 (70%)] Loss: -199416.015625\n",
      "Train Epoch: 92 [12160/17352 (70%)] Loss: -186857.171875\n",
      "Train Epoch: 92 [12240/17352 (71%)] Loss: -208013.781250\n",
      "Train Epoch: 92 [12320/17352 (71%)] Loss: -199598.125000\n",
      "Train Epoch: 92 [12400/17352 (71%)] Loss: -191321.421875\n",
      "Train Epoch: 92 [12480/17352 (72%)] Loss: -202238.578125\n",
      "Train Epoch: 92 [12560/17352 (72%)] Loss: -203514.734375\n",
      "Train Epoch: 92 [12640/17352 (73%)] Loss: -215637.562500\n",
      "Train Epoch: 92 [12720/17352 (73%)] Loss: -204367.187500\n",
      "Train Epoch: 92 [12800/17352 (74%)] Loss: -184171.187500\n",
      "Train Epoch: 92 [12880/17352 (74%)] Loss: -191365.500000\n",
      "Train Epoch: 92 [12960/17352 (75%)] Loss: -195512.015625\n",
      "Train Epoch: 92 [13040/17352 (75%)] Loss: -153895.640625\n",
      "Train Epoch: 92 [13120/17352 (76%)] Loss: -171191.750000\n",
      "Train Epoch: 92 [13200/17352 (76%)] Loss: -200999.312500\n",
      "Train Epoch: 92 [13280/17352 (77%)] Loss: -185830.562500\n",
      "Train Epoch: 92 [13360/17352 (77%)] Loss: -160102.812500\n",
      "Train Epoch: 92 [13440/17352 (77%)] Loss: -165733.484375\n",
      "Train Epoch: 92 [13520/17352 (78%)] Loss: -180238.125000\n",
      "Train Epoch: 92 [13600/17352 (78%)] Loss: -194950.218750\n",
      "Train Epoch: 92 [13680/17352 (79%)] Loss: -231044.140625\n",
      "Train Epoch: 92 [13760/17352 (79%)] Loss: -192398.828125\n",
      "Train Epoch: 92 [13840/17352 (80%)] Loss: -201940.031250\n",
      "Train Epoch: 92 [13920/17352 (80%)] Loss: -178829.765625\n",
      "Train Epoch: 92 [14000/17352 (81%)] Loss: -198019.406250\n",
      "Train Epoch: 92 [14080/17352 (81%)] Loss: -205635.437500\n",
      "Train Epoch: 92 [14160/17352 (82%)] Loss: -196116.984375\n",
      "Train Epoch: 92 [14240/17352 (82%)] Loss: -188749.578125\n",
      "Train Epoch: 92 [14320/17352 (83%)] Loss: -165735.625000\n",
      "Train Epoch: 92 [14400/17352 (83%)] Loss: -164504.218750\n",
      "Train Epoch: 92 [14480/17352 (83%)] Loss: -199804.515625\n",
      "Train Epoch: 92 [14560/17352 (84%)] Loss: -167800.875000\n",
      "Train Epoch: 92 [14640/17352 (84%)] Loss: -177981.578125\n",
      "Train Epoch: 92 [14720/17352 (85%)] Loss: -162721.609375\n",
      "Train Epoch: 92 [14800/17352 (85%)] Loss: -158748.000000\n",
      "Train Epoch: 92 [14880/17352 (86%)] Loss: -183628.500000\n",
      "Train Epoch: 92 [14960/17352 (86%)] Loss: -165766.171875\n",
      "Train Epoch: 92 [15040/17352 (87%)] Loss: -196459.765625\n",
      "Train Epoch: 92 [15120/17352 (87%)] Loss: -172555.609375\n",
      "Train Epoch: 92 [15200/17352 (88%)] Loss: -184483.281250\n",
      "Train Epoch: 92 [15280/17352 (88%)] Loss: -208428.625000\n",
      "Train Epoch: 92 [15360/17352 (89%)] Loss: -177176.140625\n",
      "Train Epoch: 92 [15440/17352 (89%)] Loss: -168080.359375\n",
      "Train Epoch: 92 [15520/17352 (89%)] Loss: -186435.937500\n",
      "Train Epoch: 92 [15600/17352 (90%)] Loss: -158609.609375\n",
      "Train Epoch: 92 [15680/17352 (90%)] Loss: -196818.812500\n",
      "Train Epoch: 92 [15760/17352 (91%)] Loss: -183505.671875\n",
      "Train Epoch: 92 [15840/17352 (91%)] Loss: -192643.187500\n",
      "Train Epoch: 92 [15920/17352 (92%)] Loss: -185396.656250\n",
      "Train Epoch: 92 [16000/17352 (92%)] Loss: -181753.625000\n",
      "Train Epoch: 92 [16080/17352 (93%)] Loss: -165599.078125\n",
      "Train Epoch: 92 [16160/17352 (93%)] Loss: -172559.328125\n",
      "Train Epoch: 92 [16240/17352 (94%)] Loss: -225323.593750\n",
      "Train Epoch: 92 [16320/17352 (94%)] Loss: -205023.359375\n",
      "Train Epoch: 92 [16400/17352 (95%)] Loss: -186045.062500\n",
      "Train Epoch: 92 [16480/17352 (95%)] Loss: -182742.421875\n",
      "Train Epoch: 92 [16560/17352 (95%)] Loss: -159681.390625\n",
      "Train Epoch: 92 [16640/17352 (96%)] Loss: -201956.562500\n",
      "Train Epoch: 92 [16720/17352 (96%)] Loss: -188447.437500\n",
      "Train Epoch: 92 [16800/17352 (97%)] Loss: -134538.656250\n",
      "Train Epoch: 92 [16880/17352 (97%)] Loss: -199791.406250\n",
      "Train Epoch: 92 [16960/17352 (98%)] Loss: -195000.031250\n",
      "Train Epoch: 92 [17040/17352 (98%)] Loss: -183728.781250\n",
      "Train Epoch: 92 [17120/17352 (99%)] Loss: -188676.312500\n",
      "Train Epoch: 92 [17200/17352 (99%)] Loss: -196206.062500\n",
      "Train Epoch: 92 [17280/17352 (100%)] Loss: -183585.968750\n",
      "Train Epoch: 92 [17360/17352 (100%)] Loss: -198552.968750\n",
      "    epoch          : 92\n",
      "    loss           : -189272.2526880754\n",
      "    val_loss       : -23716.446726409482\n",
      "Train Epoch: 93 [0/17352 (0%)] Loss: -201666.953125\n",
      "Train Epoch: 93 [80/17352 (0%)] Loss: -211908.593750\n",
      "Train Epoch: 93 [160/17352 (1%)] Loss: -236639.359375\n",
      "Train Epoch: 93 [240/17352 (1%)] Loss: -241903.625000\n",
      "Train Epoch: 93 [320/17352 (2%)] Loss: -202263.343750\n",
      "Train Epoch: 93 [400/17352 (2%)] Loss: -204401.906250\n",
      "Train Epoch: 93 [480/17352 (3%)] Loss: -199532.781250\n",
      "Train Epoch: 93 [560/17352 (3%)] Loss: -204033.015625\n",
      "Train Epoch: 93 [640/17352 (4%)] Loss: -207170.406250\n",
      "Train Epoch: 93 [720/17352 (4%)] Loss: -186070.171875\n",
      "Train Epoch: 93 [800/17352 (5%)] Loss: -205195.812500\n",
      "Train Epoch: 93 [880/17352 (5%)] Loss: -214423.156250\n",
      "Train Epoch: 93 [960/17352 (6%)] Loss: -203275.062500\n",
      "Train Epoch: 93 [1040/17352 (6%)] Loss: -210642.046875\n",
      "Train Epoch: 93 [1120/17352 (6%)] Loss: -202035.843750\n",
      "Train Epoch: 93 [1200/17352 (7%)] Loss: -213323.906250\n",
      "Train Epoch: 93 [1280/17352 (7%)] Loss: -199108.000000\n",
      "Train Epoch: 93 [1360/17352 (8%)] Loss: -199928.718750\n",
      "Train Epoch: 93 [1440/17352 (8%)] Loss: -206791.796875\n",
      "Train Epoch: 93 [1520/17352 (9%)] Loss: -193713.890625\n",
      "Train Epoch: 93 [1600/17352 (9%)] Loss: -206643.796875\n",
      "Train Epoch: 93 [1680/17352 (10%)] Loss: -210348.171875\n",
      "Train Epoch: 93 [1760/17352 (10%)] Loss: -228908.296875\n",
      "Train Epoch: 93 [1840/17352 (11%)] Loss: -215101.609375\n",
      "Train Epoch: 93 [1920/17352 (11%)] Loss: -224254.234375\n",
      "Train Epoch: 93 [2000/17352 (12%)] Loss: -230408.656250\n",
      "Train Epoch: 93 [2080/17352 (12%)] Loss: -212255.531250\n",
      "Train Epoch: 93 [2160/17352 (12%)] Loss: -205558.859375\n",
      "Train Epoch: 93 [2240/17352 (13%)] Loss: -174031.765625\n",
      "Train Epoch: 93 [2320/17352 (13%)] Loss: -191685.343750\n",
      "Train Epoch: 93 [2400/17352 (14%)] Loss: -190477.140625\n",
      "Train Epoch: 93 [2480/17352 (14%)] Loss: -184026.234375\n",
      "Train Epoch: 93 [2560/17352 (15%)] Loss: -142334.625000\n",
      "Train Epoch: 93 [2640/17352 (15%)] Loss: -191059.390625\n",
      "Train Epoch: 93 [2720/17352 (16%)] Loss: -185232.328125\n",
      "Train Epoch: 93 [2800/17352 (16%)] Loss: -171839.156250\n",
      "Train Epoch: 93 [2880/17352 (17%)] Loss: -189176.968750\n",
      "Train Epoch: 93 [2960/17352 (17%)] Loss: -186779.234375\n",
      "Train Epoch: 93 [3040/17352 (18%)] Loss: -148502.812500\n",
      "Train Epoch: 93 [3120/17352 (18%)] Loss: -179965.125000\n",
      "Train Epoch: 93 [3200/17352 (18%)] Loss: -188964.578125\n",
      "Train Epoch: 93 [3280/17352 (19%)] Loss: -192750.906250\n",
      "Train Epoch: 93 [3360/17352 (19%)] Loss: -179469.968750\n",
      "Train Epoch: 93 [3440/17352 (20%)] Loss: -181169.937500\n",
      "Train Epoch: 93 [3520/17352 (20%)] Loss: -160102.468750\n",
      "Train Epoch: 93 [3600/17352 (21%)] Loss: -218405.328125\n",
      "Train Epoch: 93 [3680/17352 (21%)] Loss: -180525.953125\n",
      "Train Epoch: 93 [3760/17352 (22%)] Loss: -206693.531250\n",
      "Train Epoch: 93 [3840/17352 (22%)] Loss: -200120.656250\n",
      "Train Epoch: 93 [3920/17352 (23%)] Loss: -176702.750000\n",
      "Train Epoch: 93 [4000/17352 (23%)] Loss: -181015.125000\n",
      "Train Epoch: 93 [4080/17352 (24%)] Loss: -165805.281250\n",
      "Train Epoch: 93 [4160/17352 (24%)] Loss: -206209.203125\n",
      "Train Epoch: 93 [4240/17352 (24%)] Loss: -187712.093750\n",
      "Train Epoch: 93 [4320/17352 (25%)] Loss: -183871.875000\n",
      "Train Epoch: 93 [4400/17352 (25%)] Loss: -203483.109375\n",
      "Train Epoch: 93 [4480/17352 (26%)] Loss: -221254.125000\n",
      "Train Epoch: 93 [4560/17352 (26%)] Loss: -186434.703125\n",
      "Train Epoch: 93 [4640/17352 (27%)] Loss: -174514.687500\n",
      "Train Epoch: 93 [4720/17352 (27%)] Loss: -187516.156250\n",
      "Train Epoch: 93 [4800/17352 (28%)] Loss: -183783.468750\n",
      "Train Epoch: 93 [4880/17352 (28%)] Loss: -228151.687500\n",
      "Train Epoch: 93 [4960/17352 (29%)] Loss: -195110.796875\n",
      "Train Epoch: 93 [5040/17352 (29%)] Loss: -181078.953125\n",
      "Train Epoch: 93 [5120/17352 (30%)] Loss: -196158.359375\n",
      "Train Epoch: 93 [5200/17352 (30%)] Loss: -181925.875000\n",
      "Train Epoch: 93 [5280/17352 (30%)] Loss: -172541.843750\n",
      "Train Epoch: 93 [5360/17352 (31%)] Loss: -181723.859375\n",
      "Train Epoch: 93 [5440/17352 (31%)] Loss: -197596.734375\n",
      "Train Epoch: 93 [5520/17352 (32%)] Loss: -204366.531250\n",
      "Train Epoch: 93 [5600/17352 (32%)] Loss: -185173.062500\n",
      "Train Epoch: 93 [5680/17352 (33%)] Loss: -187450.781250\n",
      "Train Epoch: 93 [5760/17352 (33%)] Loss: -211163.375000\n",
      "Train Epoch: 93 [5840/17352 (34%)] Loss: -154607.328125\n",
      "Train Epoch: 93 [5920/17352 (34%)] Loss: -166444.921875\n",
      "Train Epoch: 93 [6000/17352 (35%)] Loss: -175073.437500\n",
      "Train Epoch: 93 [6080/17352 (35%)] Loss: -199420.125000\n",
      "Train Epoch: 93 [6160/17352 (36%)] Loss: -180258.390625\n",
      "Train Epoch: 93 [6240/17352 (36%)] Loss: -203273.593750\n",
      "Train Epoch: 93 [6320/17352 (36%)] Loss: -191964.328125\n",
      "Train Epoch: 93 [6400/17352 (37%)] Loss: -166516.140625\n",
      "Train Epoch: 93 [6480/17352 (37%)] Loss: -151739.203125\n",
      "Train Epoch: 93 [6560/17352 (38%)] Loss: -185547.312500\n",
      "Train Epoch: 93 [6640/17352 (38%)] Loss: -191313.718750\n",
      "Train Epoch: 93 [6720/17352 (39%)] Loss: -167000.031250\n",
      "Train Epoch: 93 [6800/17352 (39%)] Loss: -207128.718750\n",
      "Train Epoch: 93 [6880/17352 (40%)] Loss: -194957.546875\n",
      "Train Epoch: 93 [6960/17352 (40%)] Loss: -187885.671875\n",
      "Train Epoch: 93 [7040/17352 (41%)] Loss: -190792.953125\n",
      "Train Epoch: 93 [7120/17352 (41%)] Loss: -208024.078125\n",
      "Train Epoch: 93 [7200/17352 (41%)] Loss: -192988.093750\n",
      "Train Epoch: 93 [7280/17352 (42%)] Loss: -177182.250000\n",
      "Train Epoch: 93 [7360/17352 (42%)] Loss: -209204.437500\n",
      "Train Epoch: 93 [7440/17352 (43%)] Loss: -176054.859375\n",
      "Train Epoch: 93 [7520/17352 (43%)] Loss: -160053.703125\n",
      "Train Epoch: 93 [7600/17352 (44%)] Loss: -169616.843750\n",
      "Train Epoch: 93 [7680/17352 (44%)] Loss: -194058.859375\n",
      "Train Epoch: 93 [7760/17352 (45%)] Loss: -213908.109375\n",
      "Train Epoch: 93 [7840/17352 (45%)] Loss: -177311.875000\n",
      "Train Epoch: 93 [7920/17352 (46%)] Loss: -188258.437500\n",
      "Train Epoch: 93 [8000/17352 (46%)] Loss: -222863.671875\n",
      "Train Epoch: 93 [8080/17352 (47%)] Loss: -180053.062500\n",
      "Train Epoch: 93 [8160/17352 (47%)] Loss: -183286.328125\n",
      "Train Epoch: 93 [8240/17352 (47%)] Loss: -180545.453125\n",
      "Train Epoch: 93 [8320/17352 (48%)] Loss: -166655.593750\n",
      "Train Epoch: 93 [8400/17352 (48%)] Loss: -205405.875000\n",
      "Train Epoch: 93 [8480/17352 (49%)] Loss: -180157.843750\n",
      "Train Epoch: 93 [8560/17352 (49%)] Loss: -178100.703125\n",
      "Train Epoch: 93 [8640/17352 (50%)] Loss: -144992.281250\n",
      "Train Epoch: 93 [8720/17352 (50%)] Loss: -194071.656250\n",
      "Train Epoch: 93 [8800/17352 (51%)] Loss: -196701.875000\n",
      "Train Epoch: 93 [8880/17352 (51%)] Loss: -149333.734375\n",
      "Train Epoch: 93 [8960/17352 (52%)] Loss: -217606.968750\n",
      "Train Epoch: 93 [9040/17352 (52%)] Loss: -169002.843750\n",
      "Train Epoch: 93 [9120/17352 (53%)] Loss: -178731.468750\n",
      "Train Epoch: 93 [9200/17352 (53%)] Loss: -185573.093750\n",
      "Train Epoch: 93 [9280/17352 (53%)] Loss: -178666.343750\n",
      "Train Epoch: 93 [9360/17352 (54%)] Loss: -179448.375000\n",
      "Train Epoch: 93 [9440/17352 (54%)] Loss: -196446.312500\n",
      "Train Epoch: 93 [9520/17352 (55%)] Loss: -192232.062500\n",
      "Train Epoch: 93 [9600/17352 (55%)] Loss: -181342.921875\n",
      "Train Epoch: 93 [9680/17352 (56%)] Loss: -200405.406250\n",
      "Train Epoch: 93 [9760/17352 (56%)] Loss: -176900.984375\n",
      "Train Epoch: 93 [9840/17352 (57%)] Loss: -181982.640625\n",
      "Train Epoch: 93 [9920/17352 (57%)] Loss: -185044.640625\n",
      "Train Epoch: 93 [10000/17352 (58%)] Loss: -177205.343750\n",
      "Train Epoch: 93 [10080/17352 (58%)] Loss: -184745.453125\n",
      "Train Epoch: 93 [10160/17352 (59%)] Loss: -191363.125000\n",
      "Train Epoch: 93 [10240/17352 (59%)] Loss: -184953.140625\n",
      "Train Epoch: 93 [10320/17352 (59%)] Loss: -178822.578125\n",
      "Train Epoch: 93 [10400/17352 (60%)] Loss: -165996.390625\n",
      "Train Epoch: 93 [10480/17352 (60%)] Loss: -181737.718750\n",
      "Train Epoch: 93 [10560/17352 (61%)] Loss: -187251.671875\n",
      "Train Epoch: 93 [10640/17352 (61%)] Loss: -193534.109375\n",
      "Train Epoch: 93 [10720/17352 (62%)] Loss: -212660.781250\n",
      "Train Epoch: 93 [10800/17352 (62%)] Loss: -179388.453125\n",
      "Train Epoch: 93 [10880/17352 (63%)] Loss: -175689.265625\n",
      "Train Epoch: 93 [10960/17352 (63%)] Loss: -180260.312500\n",
      "Train Epoch: 93 [11040/17352 (64%)] Loss: -186497.484375\n",
      "Train Epoch: 93 [11120/17352 (64%)] Loss: -195832.203125\n",
      "Train Epoch: 93 [11200/17352 (65%)] Loss: -168084.812500\n",
      "Train Epoch: 93 [11280/17352 (65%)] Loss: -205215.812500\n",
      "Train Epoch: 93 [11360/17352 (65%)] Loss: -187776.265625\n",
      "Train Epoch: 93 [11440/17352 (66%)] Loss: -180147.437500\n",
      "Train Epoch: 93 [11520/17352 (66%)] Loss: -201034.437500\n",
      "Train Epoch: 93 [11600/17352 (67%)] Loss: -183917.468750\n",
      "Train Epoch: 93 [11680/17352 (67%)] Loss: -191343.140625\n",
      "Train Epoch: 93 [11760/17352 (68%)] Loss: -187267.500000\n",
      "Train Epoch: 93 [11840/17352 (68%)] Loss: -181892.281250\n",
      "Train Epoch: 93 [11920/17352 (69%)] Loss: -187321.484375\n",
      "Train Epoch: 93 [12000/17352 (69%)] Loss: -202197.125000\n",
      "Train Epoch: 93 [12080/17352 (70%)] Loss: -174190.515625\n",
      "Train Epoch: 93 [12160/17352 (70%)] Loss: -190509.812500\n",
      "Train Epoch: 93 [12240/17352 (71%)] Loss: -165732.781250\n",
      "Train Epoch: 93 [12320/17352 (71%)] Loss: -181374.390625\n",
      "Train Epoch: 93 [12400/17352 (71%)] Loss: -196290.953125\n",
      "Train Epoch: 93 [12480/17352 (72%)] Loss: -175751.390625\n",
      "Train Epoch: 93 [12560/17352 (72%)] Loss: -212983.625000\n",
      "Train Epoch: 93 [12640/17352 (73%)] Loss: -178602.890625\n",
      "Train Epoch: 93 [12720/17352 (73%)] Loss: -196130.281250\n",
      "Train Epoch: 93 [12800/17352 (74%)] Loss: -176286.640625\n",
      "Train Epoch: 93 [12880/17352 (74%)] Loss: -189734.625000\n",
      "Train Epoch: 93 [12960/17352 (75%)] Loss: -180910.906250\n",
      "Train Epoch: 93 [13040/17352 (75%)] Loss: -188493.937500\n",
      "Train Epoch: 93 [13120/17352 (76%)] Loss: -168260.562500\n",
      "Train Epoch: 93 [13200/17352 (76%)] Loss: -176148.593750\n",
      "Train Epoch: 93 [13280/17352 (77%)] Loss: -172198.343750\n",
      "Train Epoch: 93 [13360/17352 (77%)] Loss: -179017.515625\n",
      "Train Epoch: 93 [13440/17352 (77%)] Loss: -206567.484375\n",
      "Train Epoch: 93 [13520/17352 (78%)] Loss: -192956.906250\n",
      "Train Epoch: 93 [13600/17352 (78%)] Loss: -185239.812500\n",
      "Train Epoch: 93 [13680/17352 (79%)] Loss: -168072.515625\n",
      "Train Epoch: 93 [13760/17352 (79%)] Loss: -173366.625000\n",
      "Train Epoch: 93 [13840/17352 (80%)] Loss: -168672.562500\n",
      "Train Epoch: 93 [13920/17352 (80%)] Loss: -187350.609375\n",
      "Train Epoch: 93 [14000/17352 (81%)] Loss: -193100.125000\n",
      "Train Epoch: 93 [14080/17352 (81%)] Loss: -209416.937500\n",
      "Train Epoch: 93 [14160/17352 (82%)] Loss: -169951.562500\n",
      "Train Epoch: 93 [14240/17352 (82%)] Loss: -164741.359375\n",
      "Train Epoch: 93 [14320/17352 (83%)] Loss: -193514.421875\n",
      "Train Epoch: 93 [14400/17352 (83%)] Loss: -169443.140625\n",
      "Train Epoch: 93 [14480/17352 (83%)] Loss: -206364.828125\n",
      "Train Epoch: 93 [14560/17352 (84%)] Loss: -193131.718750\n",
      "Train Epoch: 93 [14640/17352 (84%)] Loss: -170769.546875\n",
      "Train Epoch: 93 [14720/17352 (85%)] Loss: -196935.281250\n",
      "Train Epoch: 93 [14800/17352 (85%)] Loss: -192951.343750\n",
      "Train Epoch: 93 [14880/17352 (86%)] Loss: -165390.515625\n",
      "Train Epoch: 93 [14960/17352 (86%)] Loss: -182686.812500\n",
      "Train Epoch: 93 [15040/17352 (87%)] Loss: -189267.625000\n",
      "Train Epoch: 93 [15120/17352 (87%)] Loss: -164882.062500\n",
      "Train Epoch: 93 [15200/17352 (88%)] Loss: -129702.195312\n",
      "Train Epoch: 93 [15280/17352 (88%)] Loss: -184758.625000\n",
      "Train Epoch: 93 [15360/17352 (89%)] Loss: -210161.468750\n",
      "Train Epoch: 93 [15440/17352 (89%)] Loss: -184959.500000\n",
      "Train Epoch: 93 [15520/17352 (89%)] Loss: -180695.828125\n",
      "Train Epoch: 93 [15600/17352 (90%)] Loss: -162968.671875\n",
      "Train Epoch: 93 [15680/17352 (90%)] Loss: -138342.078125\n",
      "Train Epoch: 93 [15760/17352 (91%)] Loss: -231043.890625\n",
      "Train Epoch: 93 [15840/17352 (91%)] Loss: -190582.562500\n",
      "Train Epoch: 93 [15920/17352 (92%)] Loss: -169192.765625\n",
      "Train Epoch: 93 [16000/17352 (92%)] Loss: -178426.328125\n",
      "Train Epoch: 93 [16080/17352 (93%)] Loss: -201958.343750\n",
      "Train Epoch: 93 [16160/17352 (93%)] Loss: -199781.140625\n",
      "Train Epoch: 93 [16240/17352 (94%)] Loss: -164806.375000\n",
      "Train Epoch: 93 [16320/17352 (94%)] Loss: -208011.281250\n",
      "Train Epoch: 93 [16400/17352 (95%)] Loss: -181544.125000\n",
      "Train Epoch: 93 [16480/17352 (95%)] Loss: -165802.187500\n",
      "Train Epoch: 93 [16560/17352 (95%)] Loss: -185266.265625\n",
      "Train Epoch: 93 [16640/17352 (96%)] Loss: -174550.109375\n",
      "Train Epoch: 93 [16720/17352 (96%)] Loss: -163774.984375\n",
      "Train Epoch: 93 [16800/17352 (97%)] Loss: -196029.515625\n",
      "Train Epoch: 93 [16880/17352 (97%)] Loss: -169506.953125\n",
      "Train Epoch: 93 [16960/17352 (98%)] Loss: -200979.250000\n",
      "Train Epoch: 93 [17040/17352 (98%)] Loss: -173128.609375\n",
      "Train Epoch: 93 [17120/17352 (99%)] Loss: -178315.859375\n",
      "Train Epoch: 93 [17200/17352 (99%)] Loss: -140591.125000\n",
      "Train Epoch: 93 [17280/17352 (100%)] Loss: -177235.562500\n",
      "Train Epoch: 93 [17360/17352 (100%)] Loss: -203462.937500\n",
      "    epoch          : 93\n",
      "    loss           : -189296.22311924625\n",
      "    val_loss       : -23716.339041553194\n",
      "Train Epoch: 94 [0/17352 (0%)] Loss: -205206.937500\n",
      "Train Epoch: 94 [80/17352 (0%)] Loss: -193416.062500\n",
      "Train Epoch: 94 [160/17352 (1%)] Loss: -209790.453125\n",
      "Train Epoch: 94 [240/17352 (1%)] Loss: -226104.375000\n",
      "Train Epoch: 94 [320/17352 (2%)] Loss: -193585.500000\n",
      "Train Epoch: 94 [400/17352 (2%)] Loss: -205201.687500\n",
      "Train Epoch: 94 [480/17352 (3%)] Loss: -185296.968750\n",
      "Train Epoch: 94 [560/17352 (3%)] Loss: -210349.562500\n",
      "Train Epoch: 94 [640/17352 (4%)] Loss: -191879.515625\n",
      "Train Epoch: 94 [720/17352 (4%)] Loss: -186082.281250\n",
      "Train Epoch: 94 [800/17352 (5%)] Loss: -211900.843750\n",
      "Train Epoch: 94 [880/17352 (5%)] Loss: -214422.250000\n",
      "Train Epoch: 94 [960/17352 (6%)] Loss: -212184.000000\n",
      "Train Epoch: 94 [1040/17352 (6%)] Loss: -213829.968750\n",
      "Train Epoch: 94 [1120/17352 (6%)] Loss: -203739.234375\n",
      "Train Epoch: 94 [1200/17352 (7%)] Loss: -223005.578125\n",
      "Train Epoch: 94 [1280/17352 (7%)] Loss: -212377.359375\n",
      "Train Epoch: 94 [1360/17352 (8%)] Loss: -221475.437500\n",
      "Train Epoch: 94 [1440/17352 (8%)] Loss: -218535.421875\n",
      "Train Epoch: 94 [1520/17352 (9%)] Loss: -228905.703125\n",
      "Train Epoch: 94 [1600/17352 (9%)] Loss: -221758.171875\n",
      "Train Epoch: 94 [1680/17352 (10%)] Loss: -209555.703125\n",
      "Train Epoch: 94 [1760/17352 (10%)] Loss: -207163.234375\n",
      "Train Epoch: 94 [1840/17352 (11%)] Loss: -214524.187500\n",
      "Train Epoch: 94 [1920/17352 (11%)] Loss: -231328.750000\n",
      "Train Epoch: 94 [2000/17352 (12%)] Loss: -213325.718750\n",
      "Train Epoch: 94 [2080/17352 (12%)] Loss: -212700.937500\n",
      "Train Epoch: 94 [2160/17352 (12%)] Loss: -206565.281250\n",
      "Train Epoch: 94 [2240/17352 (13%)] Loss: -193136.343750\n",
      "Train Epoch: 94 [2320/17352 (13%)] Loss: -193014.546875\n",
      "Train Epoch: 94 [2400/17352 (14%)] Loss: -186605.828125\n",
      "Train Epoch: 94 [2480/17352 (14%)] Loss: -206605.234375\n",
      "Train Epoch: 94 [2560/17352 (15%)] Loss: -168084.781250\n",
      "Train Epoch: 94 [2640/17352 (15%)] Loss: -196451.531250\n",
      "Train Epoch: 94 [2720/17352 (16%)] Loss: -168260.015625\n",
      "Train Epoch: 94 [2800/17352 (16%)] Loss: -196163.531250\n",
      "Train Epoch: 94 [2880/17352 (17%)] Loss: -202485.000000\n",
      "Train Epoch: 94 [2960/17352 (17%)] Loss: -164148.328125\n",
      "Train Epoch: 94 [3040/17352 (18%)] Loss: -183784.921875\n",
      "Train Epoch: 94 [3120/17352 (18%)] Loss: -158252.515625\n",
      "Train Epoch: 94 [3200/17352 (18%)] Loss: -202790.437500\n",
      "Train Epoch: 94 [3280/17352 (19%)] Loss: -192107.171875\n",
      "Train Epoch: 94 [3360/17352 (19%)] Loss: -214636.265625\n",
      "Train Epoch: 94 [3440/17352 (20%)] Loss: -158611.640625\n",
      "Train Epoch: 94 [3520/17352 (20%)] Loss: -200079.609375\n",
      "Train Epoch: 94 [3600/17352 (21%)] Loss: -152905.531250\n",
      "Train Epoch: 94 [3680/17352 (21%)] Loss: -200976.734375\n",
      "Train Epoch: 94 [3760/17352 (22%)] Loss: -180905.937500\n",
      "Train Epoch: 94 [3840/17352 (22%)] Loss: -180240.296875\n",
      "Train Epoch: 94 [3920/17352 (23%)] Loss: -187223.187500\n",
      "Train Epoch: 94 [4000/17352 (23%)] Loss: -160051.031250\n",
      "Train Epoch: 94 [4080/17352 (24%)] Loss: -186727.625000\n",
      "Train Epoch: 94 [4160/17352 (24%)] Loss: -164369.671875\n",
      "Train Epoch: 94 [4240/17352 (24%)] Loss: -194951.234375\n",
      "Train Epoch: 94 [4320/17352 (25%)] Loss: -190944.140625\n",
      "Train Epoch: 94 [4400/17352 (25%)] Loss: -172237.390625\n",
      "Train Epoch: 94 [4480/17352 (26%)] Loss: -193353.843750\n",
      "Train Epoch: 94 [4560/17352 (26%)] Loss: -188252.765625\n",
      "Train Epoch: 94 [4640/17352 (27%)] Loss: -159753.375000\n",
      "Train Epoch: 94 [4720/17352 (27%)] Loss: -196118.640625\n",
      "Train Epoch: 94 [4800/17352 (28%)] Loss: -188005.406250\n",
      "Train Epoch: 94 [4880/17352 (28%)] Loss: -177099.687500\n",
      "Train Epoch: 94 [4960/17352 (29%)] Loss: -205511.875000\n",
      "Train Epoch: 94 [5040/17352 (29%)] Loss: -189491.671875\n",
      "Train Epoch: 94 [5120/17352 (30%)] Loss: -179311.250000\n",
      "Train Epoch: 94 [5200/17352 (30%)] Loss: -181894.218750\n",
      "Train Epoch: 94 [5280/17352 (30%)] Loss: -197544.171875\n",
      "Train Epoch: 94 [5360/17352 (31%)] Loss: -186160.031250\n",
      "Train Epoch: 94 [5440/17352 (31%)] Loss: -192270.343750\n",
      "Train Epoch: 94 [5520/17352 (32%)] Loss: -175017.015625\n",
      "Train Epoch: 94 [5600/17352 (32%)] Loss: -162722.953125\n",
      "Train Epoch: 94 [5680/17352 (33%)] Loss: -166411.484375\n",
      "Train Epoch: 94 [5760/17352 (33%)] Loss: -218471.359375\n",
      "Train Epoch: 94 [5840/17352 (34%)] Loss: -212983.531250\n",
      "Train Epoch: 94 [5920/17352 (34%)] Loss: -177082.031250\n",
      "Train Epoch: 94 [6000/17352 (35%)] Loss: -175424.421875\n",
      "Train Epoch: 94 [6080/17352 (35%)] Loss: -171837.109375\n",
      "Train Epoch: 94 [6160/17352 (36%)] Loss: -205692.906250\n",
      "Train Epoch: 94 [6240/17352 (36%)] Loss: -208313.328125\n",
      "Train Epoch: 94 [6320/17352 (36%)] Loss: -204374.734375\n",
      "Train Epoch: 94 [6400/17352 (37%)] Loss: -223965.156250\n",
      "Train Epoch: 94 [6480/17352 (37%)] Loss: -161095.812500\n",
      "Train Epoch: 94 [6560/17352 (38%)] Loss: -189514.125000\n",
      "Train Epoch: 94 [6640/17352 (38%)] Loss: -200301.750000\n",
      "Train Epoch: 94 [6720/17352 (39%)] Loss: -171193.781250\n",
      "Train Epoch: 94 [6800/17352 (39%)] Loss: -149443.250000\n",
      "Train Epoch: 94 [6880/17352 (40%)] Loss: -197597.718750\n",
      "Train Epoch: 94 [6960/17352 (40%)] Loss: -210489.968750\n",
      "Train Epoch: 94 [7040/17352 (41%)] Loss: -163966.046875\n",
      "Train Epoch: 94 [7120/17352 (41%)] Loss: -207833.187500\n",
      "Train Epoch: 94 [7200/17352 (41%)] Loss: -192991.531250\n",
      "Train Epoch: 94 [7280/17352 (42%)] Loss: -187529.625000\n",
      "Train Epoch: 94 [7360/17352 (42%)] Loss: -192792.109375\n",
      "Train Epoch: 94 [7440/17352 (43%)] Loss: -188904.796875\n",
      "Train Epoch: 94 [7520/17352 (43%)] Loss: -196206.906250\n",
      "Train Epoch: 94 [7600/17352 (44%)] Loss: -181165.578125\n",
      "Train Epoch: 94 [7680/17352 (44%)] Loss: -181012.828125\n",
      "Train Epoch: 94 [7760/17352 (45%)] Loss: -178568.453125\n",
      "Train Epoch: 94 [7840/17352 (45%)] Loss: -200469.781250\n",
      "Train Epoch: 94 [7920/17352 (46%)] Loss: -183794.437500\n",
      "Train Epoch: 94 [8000/17352 (46%)] Loss: -184460.390625\n",
      "Train Epoch: 94 [8080/17352 (47%)] Loss: -188153.500000\n",
      "Train Epoch: 94 [8160/17352 (47%)] Loss: -191008.546875\n",
      "Train Epoch: 94 [8240/17352 (47%)] Loss: -197952.203125\n",
      "Train Epoch: 94 [8320/17352 (48%)] Loss: -170105.921875\n",
      "Train Epoch: 94 [8400/17352 (48%)] Loss: -167807.187500\n",
      "Train Epoch: 94 [8480/17352 (49%)] Loss: -192012.718750\n",
      "Train Epoch: 94 [8560/17352 (49%)] Loss: -136426.296875\n",
      "Train Epoch: 94 [8640/17352 (50%)] Loss: -166518.734375\n",
      "Train Epoch: 94 [8720/17352 (50%)] Loss: -206097.500000\n",
      "Train Epoch: 94 [8800/17352 (51%)] Loss: -175077.843750\n",
      "Train Epoch: 94 [8880/17352 (51%)] Loss: -167878.343750\n",
      "Train Epoch: 94 [8960/17352 (52%)] Loss: -210262.015625\n",
      "Train Epoch: 94 [9040/17352 (52%)] Loss: -153890.750000\n",
      "Train Epoch: 94 [9120/17352 (53%)] Loss: -196563.421875\n",
      "Train Epoch: 94 [9200/17352 (53%)] Loss: -197342.921875\n",
      "Train Epoch: 94 [9280/17352 (53%)] Loss: -195513.328125\n",
      "Train Epoch: 94 [9360/17352 (54%)] Loss: -178215.906250\n",
      "Train Epoch: 94 [9440/17352 (54%)] Loss: -218842.421875\n",
      "Train Epoch: 94 [9520/17352 (55%)] Loss: -192390.250000\n",
      "Train Epoch: 94 [9600/17352 (55%)] Loss: -187644.125000\n",
      "Train Epoch: 94 [9680/17352 (56%)] Loss: -202185.796875\n",
      "Train Epoch: 94 [9760/17352 (56%)] Loss: -176044.968750\n",
      "Train Epoch: 94 [9840/17352 (57%)] Loss: -193517.437500\n",
      "Train Epoch: 94 [9920/17352 (57%)] Loss: -165392.578125\n",
      "Train Epoch: 94 [10000/17352 (58%)] Loss: -194936.468750\n",
      "Train Epoch: 94 [10080/17352 (58%)] Loss: -188504.671875\n",
      "Train Epoch: 94 [10160/17352 (59%)] Loss: -177306.468750\n",
      "Train Epoch: 94 [10240/17352 (59%)] Loss: -196028.484375\n",
      "Train Epoch: 94 [10320/17352 (59%)] Loss: -185368.265625\n",
      "Train Epoch: 94 [10400/17352 (60%)] Loss: -182407.937500\n",
      "Train Epoch: 94 [10480/17352 (60%)] Loss: -196513.546875\n",
      "Train Epoch: 94 [10560/17352 (61%)] Loss: -154606.453125\n",
      "Train Epoch: 94 [10640/17352 (61%)] Loss: -176590.640625\n",
      "Train Epoch: 94 [10720/17352 (62%)] Loss: -196451.156250\n",
      "Train Epoch: 94 [10800/17352 (62%)] Loss: -173127.656250\n",
      "Train Epoch: 94 [10880/17352 (63%)] Loss: -151219.171875\n",
      "Train Epoch: 94 [10960/17352 (63%)] Loss: -180647.515625\n",
      "Train Epoch: 94 [11040/17352 (64%)] Loss: -208043.859375\n",
      "Train Epoch: 94 [11120/17352 (64%)] Loss: -188090.656250\n",
      "Train Epoch: 94 [11200/17352 (65%)] Loss: -175759.312500\n",
      "Train Epoch: 94 [11280/17352 (65%)] Loss: -193367.343750\n",
      "Train Epoch: 94 [11360/17352 (65%)] Loss: -175411.687500\n",
      "Train Epoch: 94 [11440/17352 (66%)] Loss: -199455.421875\n",
      "Train Epoch: 94 [11520/17352 (66%)] Loss: -214755.140625\n",
      "Train Epoch: 94 [11600/17352 (67%)] Loss: -187513.078125\n",
      "Train Epoch: 94 [11680/17352 (67%)] Loss: -183167.546875\n",
      "Train Epoch: 94 [11760/17352 (68%)] Loss: -169002.750000\n",
      "Train Epoch: 94 [11840/17352 (68%)] Loss: -217607.828125\n",
      "Train Epoch: 94 [11920/17352 (69%)] Loss: -180309.734375\n",
      "Train Epoch: 94 [12000/17352 (69%)] Loss: -205404.859375\n",
      "Train Epoch: 94 [12080/17352 (70%)] Loss: -182685.234375\n",
      "Train Epoch: 94 [12160/17352 (70%)] Loss: -183225.328125\n",
      "Train Epoch: 94 [12240/17352 (71%)] Loss: -179745.296875\n",
      "Train Epoch: 94 [12320/17352 (71%)] Loss: -185578.437500\n",
      "Train Epoch: 94 [12400/17352 (71%)] Loss: -156993.656250\n",
      "Train Epoch: 94 [12480/17352 (72%)] Loss: -184027.562500\n",
      "Train Epoch: 94 [12560/17352 (72%)] Loss: -168679.062500\n",
      "Train Epoch: 94 [12640/17352 (73%)] Loss: -189601.171875\n",
      "Train Epoch: 94 [12720/17352 (73%)] Loss: -198018.937500\n",
      "Train Epoch: 94 [12800/17352 (74%)] Loss: -134539.875000\n",
      "Train Epoch: 94 [12880/17352 (74%)] Loss: -220969.781250\n",
      "Train Epoch: 94 [12960/17352 (75%)] Loss: -201517.953125\n",
      "Train Epoch: 94 [13040/17352 (75%)] Loss: -138336.437500\n",
      "Train Epoch: 94 [13120/17352 (76%)] Loss: -204494.703125\n",
      "Train Epoch: 94 [13200/17352 (76%)] Loss: -174643.875000\n",
      "Train Epoch: 94 [13280/17352 (77%)] Loss: -196251.796875\n",
      "Train Epoch: 94 [13360/17352 (77%)] Loss: -187267.765625\n",
      "Train Epoch: 94 [13440/17352 (77%)] Loss: -192955.296875\n",
      "Train Epoch: 94 [13520/17352 (78%)] Loss: -196033.453125\n",
      "Train Epoch: 94 [13600/17352 (78%)] Loss: -165356.234375\n",
      "Train Epoch: 94 [13680/17352 (79%)] Loss: -200480.343750\n",
      "Train Epoch: 94 [13760/17352 (79%)] Loss: -173585.375000\n",
      "Train Epoch: 94 [13840/17352 (80%)] Loss: -190003.046875\n",
      "Train Epoch: 94 [13920/17352 (80%)] Loss: -200123.203125\n",
      "Train Epoch: 94 [14000/17352 (81%)] Loss: -160102.437500\n",
      "Train Epoch: 94 [14080/17352 (81%)] Loss: -184487.468750\n",
      "Train Epoch: 94 [14160/17352 (82%)] Loss: -203436.546875\n",
      "Train Epoch: 94 [14240/17352 (82%)] Loss: -148403.734375\n",
      "Train Epoch: 94 [14320/17352 (83%)] Loss: -174036.296875\n",
      "Train Epoch: 94 [14400/17352 (83%)] Loss: -165737.484375\n",
      "Train Epoch: 94 [14480/17352 (83%)] Loss: -183282.906250\n",
      "Train Epoch: 94 [14560/17352 (84%)] Loss: -183072.156250\n",
      "Train Epoch: 94 [14640/17352 (84%)] Loss: -200225.296875\n",
      "Train Epoch: 94 [14720/17352 (85%)] Loss: -183372.656250\n",
      "Train Epoch: 94 [14800/17352 (85%)] Loss: -198827.656250\n",
      "Train Epoch: 94 [14880/17352 (86%)] Loss: -197655.343750\n",
      "Train Epoch: 94 [14960/17352 (86%)] Loss: -184493.203125\n",
      "Train Epoch: 94 [15040/17352 (87%)] Loss: -183606.921875\n",
      "Train Epoch: 94 [15120/17352 (87%)] Loss: -203891.187500\n",
      "Train Epoch: 94 [15200/17352 (88%)] Loss: -192854.515625\n",
      "Train Epoch: 94 [15280/17352 (88%)] Loss: -165804.109375\n",
      "Train Epoch: 94 [15360/17352 (89%)] Loss: -208802.562500\n",
      "Train Epoch: 94 [15440/17352 (89%)] Loss: -202577.984375\n",
      "Train Epoch: 94 [15520/17352 (89%)] Loss: -195839.156250\n",
      "Train Epoch: 94 [15600/17352 (90%)] Loss: -193507.843750\n",
      "Train Epoch: 94 [15680/17352 (90%)] Loss: -190381.609375\n",
      "Train Epoch: 94 [15760/17352 (91%)] Loss: -180545.296875\n",
      "Train Epoch: 94 [15840/17352 (91%)] Loss: -170785.500000\n",
      "Train Epoch: 94 [15920/17352 (92%)] Loss: -215178.484375\n",
      "Train Epoch: 94 [16000/17352 (92%)] Loss: -95258.414062\n",
      "Train Epoch: 94 [16080/17352 (93%)] Loss: -189173.156250\n",
      "Train Epoch: 94 [16160/17352 (93%)] Loss: -173441.625000\n",
      "Train Epoch: 94 [16240/17352 (94%)] Loss: -168060.265625\n",
      "Train Epoch: 94 [16320/17352 (94%)] Loss: -207857.484375\n",
      "Train Epoch: 94 [16400/17352 (95%)] Loss: -166442.593750\n",
      "Train Epoch: 94 [16480/17352 (95%)] Loss: -204352.218750\n",
      "Train Epoch: 94 [16560/17352 (95%)] Loss: -195887.812500\n",
      "Train Epoch: 94 [16640/17352 (96%)] Loss: -177277.906250\n",
      "Train Epoch: 94 [16720/17352 (96%)] Loss: -174146.250000\n",
      "Train Epoch: 94 [16800/17352 (97%)] Loss: -201973.765625\n",
      "Train Epoch: 94 [16880/17352 (97%)] Loss: -197523.390625\n",
      "Train Epoch: 94 [16960/17352 (98%)] Loss: -143619.390625\n",
      "Train Epoch: 94 [17040/17352 (98%)] Loss: -205494.890625\n",
      "Train Epoch: 94 [17120/17352 (99%)] Loss: -205212.265625\n",
      "Train Epoch: 94 [17200/17352 (99%)] Loss: -179500.093750\n",
      "Train Epoch: 94 [17280/17352 (100%)] Loss: -210262.656250\n",
      "Train Epoch: 94 [17360/17352 (100%)] Loss: -170247.109375\n",
      "    epoch          : 94\n",
      "    loss           : -189114.8260122986\n",
      "    val_loss       : -23716.370653609156\n",
      "Train Epoch: 95 [0/17352 (0%)] Loss: -218560.078125\n",
      "Train Epoch: 95 [80/17352 (0%)] Loss: -186073.859375\n",
      "Train Epoch: 95 [160/17352 (1%)] Loss: -199109.406250\n",
      "Train Epoch: 95 [240/17352 (1%)] Loss: -199546.093750\n",
      "Train Epoch: 95 [320/17352 (2%)] Loss: -206751.750000\n",
      "Train Epoch: 95 [400/17352 (2%)] Loss: -210354.734375\n",
      "Train Epoch: 95 [480/17352 (3%)] Loss: -196928.937500\n",
      "Train Epoch: 95 [560/17352 (3%)] Loss: -209558.906250\n",
      "Train Epoch: 95 [640/17352 (4%)] Loss: -194299.687500\n",
      "Train Epoch: 95 [720/17352 (4%)] Loss: -219661.781250\n",
      "Train Epoch: 95 [800/17352 (5%)] Loss: -196421.187500\n",
      "Train Epoch: 95 [880/17352 (5%)] Loss: -221479.468750\n",
      "Train Epoch: 95 [960/17352 (6%)] Loss: -212395.296875\n",
      "Train Epoch: 95 [1040/17352 (6%)] Loss: -202225.328125\n",
      "Train Epoch: 95 [1120/17352 (6%)] Loss: -217933.515625\n",
      "Train Epoch: 95 [1200/17352 (7%)] Loss: -218536.156250\n",
      "Train Epoch: 95 [1280/17352 (7%)] Loss: -214518.875000\n",
      "Train Epoch: 95 [1360/17352 (8%)] Loss: -206652.000000\n",
      "Train Epoch: 95 [1440/17352 (8%)] Loss: -214462.578125\n",
      "Train Epoch: 95 [1520/17352 (9%)] Loss: -216217.859375\n",
      "Train Epoch: 95 [1600/17352 (9%)] Loss: -204700.734375\n",
      "Train Epoch: 95 [1680/17352 (10%)] Loss: -193411.859375\n",
      "Train Epoch: 95 [1760/17352 (10%)] Loss: -236637.421875\n",
      "Train Epoch: 95 [1840/17352 (11%)] Loss: -206571.625000\n",
      "Train Epoch: 95 [1920/17352 (11%)] Loss: -208385.625000\n",
      "Train Epoch: 95 [2000/17352 (12%)] Loss: -204403.453125\n",
      "Train Epoch: 95 [2080/17352 (12%)] Loss: -214524.156250\n",
      "Train Epoch: 95 [2160/17352 (12%)] Loss: -222508.468750\n",
      "Train Epoch: 95 [2240/17352 (13%)] Loss: -192180.671875\n",
      "Train Epoch: 95 [2320/17352 (13%)] Loss: -169441.312500\n",
      "Train Epoch: 95 [2400/17352 (14%)] Loss: -189509.796875\n",
      "Train Epoch: 95 [2480/17352 (14%)] Loss: -167299.406250\n",
      "Train Epoch: 95 [2560/17352 (15%)] Loss: -206245.546875\n",
      "Train Epoch: 95 [2640/17352 (15%)] Loss: -171322.187500\n",
      "Train Epoch: 95 [2720/17352 (16%)] Loss: -170244.375000\n",
      "Train Epoch: 95 [2800/17352 (16%)] Loss: -215179.937500\n",
      "Train Epoch: 95 [2880/17352 (17%)] Loss: -203879.062500\n",
      "Train Epoch: 95 [2960/17352 (17%)] Loss: -164369.031250\n",
      "Train Epoch: 95 [3040/17352 (18%)] Loss: -142337.453125\n",
      "Train Epoch: 95 [3120/17352 (18%)] Loss: -184763.171875\n",
      "Train Epoch: 95 [3200/17352 (18%)] Loss: -187317.250000\n",
      "Train Epoch: 95 [3280/17352 (19%)] Loss: -188094.843750\n",
      "Train Epoch: 95 [3360/17352 (19%)] Loss: -158258.921875\n",
      "Train Epoch: 95 [3440/17352 (20%)] Loss: -176969.046875\n",
      "Train Epoch: 95 [3520/17352 (20%)] Loss: -165357.390625\n",
      "Train Epoch: 95 [3600/17352 (21%)] Loss: -187885.953125\n",
      "Train Epoch: 95 [3680/17352 (21%)] Loss: -204416.671875\n",
      "Train Epoch: 95 [3760/17352 (22%)] Loss: -168076.343750\n",
      "Train Epoch: 95 [3840/17352 (22%)] Loss: -207124.437500\n",
      "Train Epoch: 95 [3920/17352 (23%)] Loss: -191342.000000\n",
      "Train Epoch: 95 [4000/17352 (23%)] Loss: -179467.640625\n",
      "Train Epoch: 95 [4080/17352 (24%)] Loss: -184925.484375\n",
      "Train Epoch: 95 [4160/17352 (24%)] Loss: -193376.687500\n",
      "Train Epoch: 95 [4240/17352 (24%)] Loss: -181256.406250\n",
      "Train Epoch: 95 [4320/17352 (25%)] Loss: -201310.843750\n",
      "Train Epoch: 95 [4400/17352 (25%)] Loss: -191163.500000\n",
      "Train Epoch: 95 [4480/17352 (26%)] Loss: -188210.234375\n",
      "Train Epoch: 95 [4560/17352 (26%)] Loss: -167809.609375\n",
      "Train Epoch: 95 [4640/17352 (27%)] Loss: -188566.609375\n",
      "Train Epoch: 95 [4720/17352 (27%)] Loss: -184953.187500\n",
      "Train Epoch: 95 [4800/17352 (28%)] Loss: -159095.968750\n",
      "Train Epoch: 95 [4880/17352 (28%)] Loss: -201955.156250\n",
      "Train Epoch: 95 [4960/17352 (29%)] Loss: -196451.328125\n",
      "Train Epoch: 95 [5040/17352 (29%)] Loss: -193499.468750\n",
      "Train Epoch: 95 [5120/17352 (30%)] Loss: -174946.453125\n",
      "Train Epoch: 95 [5200/17352 (30%)] Loss: -197546.953125\n",
      "Train Epoch: 95 [5280/17352 (30%)] Loss: -213401.781250\n",
      "Train Epoch: 95 [5360/17352 (31%)] Loss: -209270.015625\n",
      "Train Epoch: 95 [5440/17352 (31%)] Loss: -191963.953125\n",
      "Train Epoch: 95 [5520/17352 (32%)] Loss: -180162.375000\n",
      "Train Epoch: 95 [5600/17352 (32%)] Loss: -177282.687500\n",
      "Train Epoch: 95 [5680/17352 (33%)] Loss: -196302.250000\n",
      "Train Epoch: 95 [5760/17352 (33%)] Loss: -176060.265625\n",
      "Train Epoch: 95 [5840/17352 (34%)] Loss: -182922.312500\n",
      "Train Epoch: 95 [5920/17352 (34%)] Loss: -189612.406250\n",
      "Train Epoch: 95 [6000/17352 (35%)] Loss: -204949.781250\n",
      "Train Epoch: 95 [6080/17352 (35%)] Loss: -167143.296875\n",
      "Train Epoch: 95 [6160/17352 (36%)] Loss: -200073.906250\n",
      "Train Epoch: 95 [6240/17352 (36%)] Loss: -174037.703125\n",
      "Train Epoch: 95 [6320/17352 (36%)] Loss: -216328.531250\n",
      "Train Epoch: 95 [6400/17352 (37%)] Loss: -206469.265625\n",
      "Train Epoch: 95 [6480/17352 (37%)] Loss: -167250.875000\n",
      "Train Epoch: 95 [6560/17352 (38%)] Loss: -180881.703125\n",
      "Train Epoch: 95 [6640/17352 (38%)] Loss: -193355.328125\n",
      "Train Epoch: 95 [6720/17352 (39%)] Loss: -196506.812500\n",
      "Train Epoch: 95 [6800/17352 (39%)] Loss: -215468.093750\n",
      "Train Epoch: 95 [6880/17352 (40%)] Loss: -199786.609375\n",
      "Train Epoch: 95 [6960/17352 (40%)] Loss: -184753.015625\n",
      "Train Epoch: 95 [7040/17352 (41%)] Loss: -191837.687500\n",
      "Train Epoch: 95 [7120/17352 (41%)] Loss: -204342.484375\n",
      "Train Epoch: 95 [7200/17352 (41%)] Loss: -202082.750000\n",
      "Train Epoch: 95 [7280/17352 (42%)] Loss: -199147.609375\n",
      "Train Epoch: 95 [7360/17352 (42%)] Loss: -183286.093750\n",
      "Train Epoch: 95 [7440/17352 (43%)] Loss: -175510.625000\n",
      "Train Epoch: 95 [7520/17352 (43%)] Loss: -171849.625000\n",
      "Train Epoch: 95 [7600/17352 (44%)] Loss: -172199.531250\n",
      "Train Epoch: 95 [7680/17352 (44%)] Loss: -206207.343750\n",
      "Train Epoch: 95 [7760/17352 (45%)] Loss: -190215.250000\n",
      "Train Epoch: 95 [7840/17352 (45%)] Loss: -183080.593750\n",
      "Train Epoch: 95 [7920/17352 (46%)] Loss: -191809.046875\n",
      "Train Epoch: 95 [8000/17352 (46%)] Loss: -149445.281250\n",
      "Train Epoch: 95 [8080/17352 (47%)] Loss: -202235.703125\n",
      "Train Epoch: 95 [8160/17352 (47%)] Loss: -211088.765625\n",
      "Train Epoch: 95 [8240/17352 (47%)] Loss: -187538.828125\n",
      "Train Epoch: 95 [8320/17352 (48%)] Loss: -199176.828125\n",
      "Train Epoch: 95 [8400/17352 (48%)] Loss: -208038.515625\n",
      "Train Epoch: 95 [8480/17352 (49%)] Loss: -188674.578125\n",
      "Train Epoch: 95 [8560/17352 (49%)] Loss: -187312.062500\n",
      "Train Epoch: 95 [8640/17352 (50%)] Loss: -193167.640625\n",
      "Train Epoch: 95 [8720/17352 (50%)] Loss: -205211.015625\n",
      "Train Epoch: 95 [8800/17352 (51%)] Loss: -169616.281250\n",
      "Train Epoch: 95 [8880/17352 (51%)] Loss: -182563.828125\n",
      "Train Epoch: 95 [8960/17352 (52%)] Loss: -172621.296875\n",
      "Train Epoch: 95 [9040/17352 (52%)] Loss: -205690.359375\n",
      "Train Epoch: 95 [9120/17352 (53%)] Loss: -213910.656250\n",
      "Train Epoch: 95 [9200/17352 (53%)] Loss: -170236.875000\n",
      "Train Epoch: 95 [9280/17352 (53%)] Loss: -195001.781250\n",
      "Train Epoch: 95 [9360/17352 (54%)] Loss: -202605.093750\n",
      "Train Epoch: 95 [9440/17352 (54%)] Loss: -175319.781250\n",
      "Train Epoch: 95 [9520/17352 (55%)] Loss: -199069.781250\n",
      "Train Epoch: 95 [9600/17352 (55%)] Loss: -228252.062500\n",
      "Train Epoch: 95 [9680/17352 (56%)] Loss: -197108.234375\n",
      "Train Epoch: 95 [9760/17352 (56%)] Loss: -185934.296875\n",
      "Train Epoch: 95 [9840/17352 (57%)] Loss: -168965.156250\n",
      "Train Epoch: 95 [9920/17352 (57%)] Loss: -190802.000000\n",
      "Train Epoch: 95 [10000/17352 (58%)] Loss: -171188.390625\n",
      "Train Epoch: 95 [10080/17352 (58%)] Loss: -166012.968750\n",
      "Train Epoch: 95 [10160/17352 (59%)] Loss: -220972.218750\n",
      "Train Epoch: 95 [10240/17352 (59%)] Loss: -202939.296875\n",
      "Train Epoch: 95 [10320/17352 (59%)] Loss: -182401.171875\n",
      "Train Epoch: 95 [10400/17352 (60%)] Loss: -193948.875000\n",
      "Train Epoch: 95 [10480/17352 (60%)] Loss: -199807.031250\n",
      "Train Epoch: 95 [10560/17352 (61%)] Loss: -191234.468750\n",
      "Train Epoch: 95 [10640/17352 (61%)] Loss: -168257.468750\n",
      "Train Epoch: 95 [10720/17352 (62%)] Loss: -187775.359375\n",
      "Train Epoch: 95 [10800/17352 (62%)] Loss: -174143.734375\n",
      "Train Epoch: 95 [10880/17352 (63%)] Loss: -189215.796875\n",
      "Train Epoch: 95 [10960/17352 (63%)] Loss: -159675.500000\n",
      "Train Epoch: 95 [11040/17352 (64%)] Loss: -191808.812500\n",
      "Train Epoch: 95 [11120/17352 (64%)] Loss: -169505.671875\n",
      "Train Epoch: 95 [11200/17352 (65%)] Loss: -154602.546875\n",
      "Train Epoch: 95 [11280/17352 (65%)] Loss: -174912.812500\n",
      "Train Epoch: 95 [11360/17352 (65%)] Loss: -193011.859375\n",
      "Train Epoch: 95 [11440/17352 (66%)] Loss: -166464.031250\n",
      "Train Epoch: 95 [11520/17352 (66%)] Loss: -197570.500000\n",
      "Train Epoch: 95 [11600/17352 (67%)] Loss: -167952.937500\n",
      "Train Epoch: 95 [11680/17352 (67%)] Loss: -197656.031250\n",
      "Train Epoch: 95 [11760/17352 (68%)] Loss: -179966.031250\n",
      "Train Epoch: 95 [11840/17352 (68%)] Loss: -173131.921875\n",
      "Train Epoch: 95 [11920/17352 (69%)] Loss: -129698.148438\n",
      "Train Epoch: 95 [12000/17352 (69%)] Loss: -180119.015625\n",
      "Train Epoch: 95 [12080/17352 (70%)] Loss: -131050.515625\n",
      "Train Epoch: 95 [12160/17352 (70%)] Loss: -200626.531250\n",
      "Train Epoch: 95 [12240/17352 (71%)] Loss: -95266.312500\n",
      "Train Epoch: 95 [12320/17352 (71%)] Loss: -201326.953125\n",
      "Train Epoch: 95 [12400/17352 (71%)] Loss: -196287.781250\n",
      "Train Epoch: 95 [12480/17352 (72%)] Loss: -173840.187500\n",
      "Train Epoch: 95 [12560/17352 (72%)] Loss: -180053.671875\n",
      "Train Epoch: 95 [12640/17352 (73%)] Loss: -178606.171875\n",
      "Train Epoch: 95 [12720/17352 (73%)] Loss: -193454.062500\n",
      "Train Epoch: 95 [12800/17352 (74%)] Loss: -203467.078125\n",
      "Train Epoch: 95 [12880/17352 (74%)] Loss: -181752.343750\n",
      "Train Epoch: 95 [12960/17352 (75%)] Loss: -171548.421875\n",
      "Train Epoch: 95 [13040/17352 (75%)] Loss: -192235.937500\n",
      "Train Epoch: 95 [13120/17352 (76%)] Loss: -172240.593750\n",
      "Train Epoch: 95 [13200/17352 (76%)] Loss: -187715.500000\n",
      "Train Epoch: 95 [13280/17352 (77%)] Loss: -202195.265625\n",
      "Train Epoch: 95 [13360/17352 (77%)] Loss: -178381.312500\n",
      "Train Epoch: 95 [13440/17352 (77%)] Loss: -176150.390625\n",
      "Train Epoch: 95 [13520/17352 (78%)] Loss: -209280.250000\n",
      "Train Epoch: 95 [13600/17352 (78%)] Loss: -186516.421875\n",
      "Train Epoch: 95 [13680/17352 (79%)] Loss: -167212.515625\n",
      "Train Epoch: 95 [13760/17352 (79%)] Loss: -181017.671875\n",
      "Train Epoch: 95 [13840/17352 (80%)] Loss: -215657.406250\n",
      "Train Epoch: 95 [13920/17352 (80%)] Loss: -185002.718750\n",
      "Train Epoch: 95 [14000/17352 (81%)] Loss: -205031.875000\n",
      "Train Epoch: 95 [14080/17352 (81%)] Loss: -166519.609375\n",
      "Train Epoch: 95 [14160/17352 (82%)] Loss: -182102.109375\n",
      "Train Epoch: 95 [14240/17352 (82%)] Loss: -200638.796875\n",
      "Train Epoch: 95 [14320/17352 (83%)] Loss: -173590.453125\n",
      "Train Epoch: 95 [14400/17352 (83%)] Loss: -173660.109375\n",
      "Train Epoch: 95 [14480/17352 (83%)] Loss: -192958.750000\n",
      "Train Epoch: 95 [14560/17352 (84%)] Loss: -190936.750000\n",
      "Train Epoch: 95 [14640/17352 (84%)] Loss: -195835.953125\n",
      "Train Epoch: 95 [14720/17352 (85%)] Loss: -192014.968750\n",
      "Train Epoch: 95 [14800/17352 (85%)] Loss: -180699.218750\n",
      "Train Epoch: 95 [14880/17352 (86%)] Loss: -198831.640625\n",
      "Train Epoch: 95 [14960/17352 (86%)] Loss: -201266.843750\n",
      "Train Epoch: 95 [15040/17352 (87%)] Loss: -157489.453125\n",
      "Train Epoch: 95 [15120/17352 (87%)] Loss: -199524.421875\n",
      "Train Epoch: 95 [15200/17352 (88%)] Loss: -210793.765625\n",
      "Train Epoch: 95 [15280/17352 (88%)] Loss: -196563.937500\n",
      "Train Epoch: 95 [15360/17352 (89%)] Loss: -186046.359375\n",
      "Train Epoch: 95 [15440/17352 (89%)] Loss: -210490.656250\n",
      "Train Epoch: 95 [15520/17352 (89%)] Loss: -180055.750000\n",
      "Train Epoch: 95 [15600/17352 (90%)] Loss: -167868.031250\n",
      "Train Epoch: 95 [15680/17352 (90%)] Loss: -177304.875000\n",
      "Train Epoch: 95 [15760/17352 (91%)] Loss: -200833.796875\n",
      "Train Epoch: 95 [15840/17352 (91%)] Loss: -184480.812500\n",
      "Train Epoch: 95 [15920/17352 (92%)] Loss: -186157.250000\n",
      "Train Epoch: 95 [16000/17352 (92%)] Loss: -183406.187500\n",
      "Train Epoch: 95 [16080/17352 (93%)] Loss: -187786.468750\n",
      "Train Epoch: 95 [16160/17352 (93%)] Loss: -209822.656250\n",
      "Train Epoch: 95 [16240/17352 (94%)] Loss: -173443.250000\n",
      "Train Epoch: 95 [16320/17352 (94%)] Loss: -189407.484375\n",
      "Train Epoch: 95 [16400/17352 (95%)] Loss: -174873.640625\n",
      "Train Epoch: 95 [16480/17352 (95%)] Loss: -163093.312500\n",
      "Train Epoch: 95 [16560/17352 (95%)] Loss: -183068.359375\n",
      "Train Epoch: 95 [16640/17352 (96%)] Loss: -174989.421875\n",
      "Train Epoch: 95 [16720/17352 (96%)] Loss: -167087.093750\n",
      "Train Epoch: 95 [16800/17352 (97%)] Loss: -179926.296875\n",
      "Train Epoch: 95 [16880/17352 (97%)] Loss: -166996.921875\n",
      "Train Epoch: 95 [16960/17352 (98%)] Loss: -198265.718750\n",
      "Train Epoch: 95 [17040/17352 (98%)] Loss: -202522.078125\n",
      "Train Epoch: 95 [17120/17352 (99%)] Loss: -165730.296875\n",
      "Train Epoch: 95 [17200/17352 (99%)] Loss: -167730.531250\n",
      "Train Epoch: 95 [17280/17352 (100%)] Loss: -202174.187500\n",
      "Train Epoch: 95 [17360/17352 (100%)] Loss: -195719.437500\n",
      "    epoch          : 95\n",
      "    loss           : -189481.43197101553\n",
      "    val_loss       : -23716.345272511942\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch95.pth ...\n",
      "Train Epoch: 96 [0/17352 (0%)] Loss: -236643.812500\n",
      "Train Epoch: 96 [80/17352 (0%)] Loss: -241907.203125\n",
      "Train Epoch: 96 [160/17352 (1%)] Loss: -229958.218750\n",
      "Train Epoch: 96 [240/17352 (1%)] Loss: -205083.796875\n",
      "Train Epoch: 96 [320/17352 (2%)] Loss: -204729.796875\n",
      "Train Epoch: 96 [400/17352 (2%)] Loss: -209785.921875\n",
      "Train Epoch: 96 [480/17352 (3%)] Loss: -217943.156250\n",
      "Train Epoch: 96 [560/17352 (3%)] Loss: -199111.812500\n",
      "Train Epoch: 96 [640/17352 (4%)] Loss: -215101.515625\n",
      "Train Epoch: 96 [720/17352 (4%)] Loss: -210752.859375\n",
      "Train Epoch: 96 [800/17352 (5%)] Loss: -233742.218750\n",
      "Train Epoch: 96 [880/17352 (5%)] Loss: -230410.203125\n",
      "Train Epoch: 96 [960/17352 (6%)] Loss: -212655.359375\n",
      "Train Epoch: 96 [1040/17352 (6%)] Loss: -206646.812500\n",
      "Train Epoch: 96 [1120/17352 (6%)] Loss: -186078.031250\n",
      "Train Epoch: 96 [1200/17352 (7%)] Loss: -214334.375000\n",
      "Train Epoch: 96 [1280/17352 (7%)] Loss: -202277.234375\n",
      "Train Epoch: 96 [1360/17352 (8%)] Loss: -235590.156250\n",
      "Train Epoch: 96 [1440/17352 (8%)] Loss: -214464.890625\n",
      "Train Epoch: 96 [1520/17352 (9%)] Loss: -206751.859375\n",
      "Train Epoch: 96 [1600/17352 (9%)] Loss: -204403.968750\n",
      "Train Epoch: 96 [1680/17352 (10%)] Loss: -204707.140625\n",
      "Train Epoch: 96 [1760/17352 (10%)] Loss: -209643.968750\n",
      "Train Epoch: 96 [1840/17352 (11%)] Loss: -185294.859375\n",
      "Train Epoch: 96 [1920/17352 (11%)] Loss: -224250.125000\n",
      "Train Epoch: 96 [2000/17352 (12%)] Loss: -214711.390625\n",
      "Train Epoch: 96 [2080/17352 (12%)] Loss: -214414.750000\n",
      "Train Epoch: 96 [2160/17352 (12%)] Loss: -198116.281250\n",
      "Train Epoch: 96 [2240/17352 (13%)] Loss: -221255.671875\n",
      "Train Epoch: 96 [2320/17352 (13%)] Loss: -210559.875000\n",
      "Train Epoch: 96 [2400/17352 (14%)] Loss: -200834.921875\n",
      "Train Epoch: 96 [2480/17352 (14%)] Loss: -160104.718750\n",
      "Train Epoch: 96 [2560/17352 (15%)] Loss: -179419.750000\n",
      "Train Epoch: 96 [2640/17352 (15%)] Loss: -192009.671875\n",
      "Train Epoch: 96 [2720/17352 (16%)] Loss: -201037.781250\n",
      "Train Epoch: 96 [2800/17352 (16%)] Loss: -162564.109375\n",
      "Train Epoch: 96 [2880/17352 (17%)] Loss: -175078.031250\n",
      "Train Epoch: 96 [2960/17352 (17%)] Loss: -195785.250000\n",
      "Train Epoch: 96 [3040/17352 (18%)] Loss: -218841.546875\n",
      "Train Epoch: 96 [3120/17352 (18%)] Loss: -208031.062500\n",
      "Train Epoch: 96 [3200/17352 (18%)] Loss: -189804.421875\n",
      "Train Epoch: 96 [3280/17352 (19%)] Loss: -192107.687500\n",
      "Train Epoch: 96 [3360/17352 (19%)] Loss: -180879.906250\n",
      "Train Epoch: 96 [3440/17352 (20%)] Loss: -190088.156250\n",
      "Train Epoch: 96 [3520/17352 (20%)] Loss: -196813.796875\n",
      "Train Epoch: 96 [3600/17352 (21%)] Loss: -174455.062500\n",
      "Train Epoch: 96 [3680/17352 (21%)] Loss: -163557.593750\n",
      "Train Epoch: 96 [3760/17352 (22%)] Loss: -189270.890625\n",
      "Train Epoch: 96 [3840/17352 (22%)] Loss: -149448.453125\n",
      "Train Epoch: 96 [3920/17352 (23%)] Loss: -185171.062500\n",
      "Train Epoch: 96 [4000/17352 (23%)] Loss: -165733.921875\n",
      "Train Epoch: 96 [4080/17352 (24%)] Loss: -156992.921875\n",
      "Train Epoch: 96 [4160/17352 (24%)] Loss: -140591.968750\n",
      "Train Epoch: 96 [4240/17352 (24%)] Loss: -160149.453125\n",
      "Train Epoch: 96 [4320/17352 (25%)] Loss: -215970.312500\n",
      "Train Epoch: 96 [4400/17352 (25%)] Loss: -183758.843750\n",
      "Train Epoch: 96 [4480/17352 (26%)] Loss: -179442.421875\n",
      "Train Epoch: 96 [4560/17352 (26%)] Loss: -199599.015625\n",
      "Train Epoch: 96 [4640/17352 (27%)] Loss: -188506.281250\n",
      "Train Epoch: 96 [4720/17352 (27%)] Loss: -173581.203125\n",
      "Train Epoch: 96 [4800/17352 (28%)] Loss: -174517.937500\n",
      "Train Epoch: 96 [4880/17352 (28%)] Loss: -169618.578125\n",
      "Train Epoch: 96 [4960/17352 (29%)] Loss: -193488.984375\n",
      "Train Epoch: 96 [5040/17352 (29%)] Loss: -177776.640625\n",
      "Train Epoch: 96 [5120/17352 (30%)] Loss: -204327.125000\n",
      "Train Epoch: 96 [5200/17352 (30%)] Loss: -176587.468750\n",
      "Train Epoch: 96 [5280/17352 (30%)] Loss: -177176.656250\n",
      "Train Epoch: 96 [5360/17352 (31%)] Loss: -195379.953125\n",
      "Train Epoch: 96 [5440/17352 (31%)] Loss: -197079.171875\n",
      "Train Epoch: 96 [5520/17352 (32%)] Loss: -180840.906250\n",
      "Train Epoch: 96 [5600/17352 (32%)] Loss: -179315.078125\n",
      "Train Epoch: 96 [5680/17352 (33%)] Loss: -204662.156250\n",
      "Train Epoch: 96 [5760/17352 (33%)] Loss: -180523.500000\n",
      "Train Epoch: 96 [5840/17352 (34%)] Loss: -190235.343750\n",
      "Train Epoch: 96 [5920/17352 (34%)] Loss: -218748.156250\n",
      "Train Epoch: 96 [6000/17352 (35%)] Loss: -196938.234375\n",
      "Train Epoch: 96 [6080/17352 (35%)] Loss: -203808.937500\n",
      "Train Epoch: 96 [6160/17352 (36%)] Loss: -181917.218750\n",
      "Train Epoch: 96 [6240/17352 (36%)] Loss: -196449.562500\n",
      "Train Epoch: 96 [6320/17352 (36%)] Loss: -185239.343750\n",
      "Train Epoch: 96 [6400/17352 (37%)] Loss: -203676.562500\n",
      "Train Epoch: 96 [6480/17352 (37%)] Loss: -182923.609375\n",
      "Train Epoch: 96 [6560/17352 (38%)] Loss: -185997.953125\n",
      "Train Epoch: 96 [6640/17352 (38%)] Loss: -197543.031250\n",
      "Train Epoch: 96 [6720/17352 (39%)] Loss: -186162.937500\n",
      "Train Epoch: 96 [6800/17352 (39%)] Loss: -163350.281250\n",
      "Train Epoch: 96 [6880/17352 (40%)] Loss: -190580.234375\n",
      "Train Epoch: 96 [6960/17352 (40%)] Loss: -191511.625000\n",
      "Train Epoch: 96 [7040/17352 (41%)] Loss: -190386.421875\n",
      "Train Epoch: 96 [7120/17352 (41%)] Loss: -166249.312500\n",
      "Train Epoch: 96 [7200/17352 (41%)] Loss: -175407.625000\n",
      "Train Epoch: 96 [7280/17352 (42%)] Loss: -185369.968750\n",
      "Train Epoch: 96 [7360/17352 (42%)] Loss: -171850.406250\n",
      "Train Epoch: 96 [7440/17352 (43%)] Loss: -179932.187500\n",
      "Train Epoch: 96 [7520/17352 (43%)] Loss: -209195.796875\n",
      "Train Epoch: 96 [7600/17352 (44%)] Loss: -180309.875000\n",
      "Train Epoch: 96 [7680/17352 (44%)] Loss: -194073.359375\n",
      "Train Epoch: 96 [7760/17352 (45%)] Loss: -175365.093750\n",
      "Train Epoch: 96 [7840/17352 (45%)] Loss: -181547.640625\n",
      "Train Epoch: 96 [7920/17352 (46%)] Loss: -181899.312500\n",
      "Train Epoch: 96 [8000/17352 (46%)] Loss: -199894.375000\n",
      "Train Epoch: 96 [8080/17352 (47%)] Loss: -188094.593750\n",
      "Train Epoch: 96 [8160/17352 (47%)] Loss: -199183.156250\n",
      "Train Epoch: 96 [8240/17352 (47%)] Loss: -181736.031250\n",
      "Train Epoch: 96 [8320/17352 (48%)] Loss: -187775.203125\n",
      "Train Epoch: 96 [8400/17352 (48%)] Loss: -191061.375000\n",
      "Train Epoch: 96 [8480/17352 (49%)] Loss: -191636.328125\n",
      "Train Epoch: 96 [8560/17352 (49%)] Loss: -196506.656250\n",
      "Train Epoch: 96 [8640/17352 (50%)] Loss: -173043.687500\n",
      "Train Epoch: 96 [8720/17352 (50%)] Loss: -209506.437500\n",
      "Train Epoch: 96 [8800/17352 (51%)] Loss: -178311.734375\n",
      "Train Epoch: 96 [8880/17352 (51%)] Loss: -164993.640625\n",
      "Train Epoch: 96 [8960/17352 (52%)] Loss: -156475.015625\n",
      "Train Epoch: 96 [9040/17352 (52%)] Loss: -188495.515625\n",
      "Train Epoch: 96 [9120/17352 (53%)] Loss: -159094.625000\n",
      "Train Epoch: 96 [9200/17352 (53%)] Loss: -191561.328125\n",
      "Train Epoch: 96 [9280/17352 (53%)] Loss: -191972.250000\n",
      "Train Epoch: 96 [9360/17352 (54%)] Loss: -189563.578125\n",
      "Train Epoch: 96 [9440/17352 (54%)] Loss: -167802.828125\n",
      "Train Epoch: 96 [9520/17352 (55%)] Loss: -177252.828125\n",
      "Train Epoch: 96 [9600/17352 (55%)] Loss: -167486.000000\n",
      "Train Epoch: 96 [9680/17352 (56%)] Loss: -142337.921875\n",
      "Train Epoch: 96 [9760/17352 (56%)] Loss: -197309.640625\n",
      "Train Epoch: 96 [9840/17352 (57%)] Loss: -172618.953125\n",
      "Train Epoch: 96 [9920/17352 (57%)] Loss: -183508.359375\n",
      "Train Epoch: 96 [10000/17352 (58%)] Loss: -190627.390625\n",
      "Train Epoch: 96 [10080/17352 (58%)] Loss: -201524.312500\n",
      "Train Epoch: 96 [10160/17352 (59%)] Loss: -161095.796875\n",
      "Train Epoch: 96 [10240/17352 (59%)] Loss: -156611.500000\n",
      "Train Epoch: 96 [10320/17352 (59%)] Loss: -153889.703125\n",
      "Train Epoch: 96 [10400/17352 (60%)] Loss: -167089.875000\n",
      "Train Epoch: 96 [10480/17352 (60%)] Loss: -171733.125000\n",
      "Train Epoch: 96 [10560/17352 (61%)] Loss: -170311.968750\n",
      "Train Epoch: 96 [10640/17352 (61%)] Loss: -183726.984375\n",
      "Train Epoch: 96 [10720/17352 (62%)] Loss: -191230.031250\n",
      "Train Epoch: 96 [10800/17352 (62%)] Loss: -178729.421875\n",
      "Train Epoch: 96 [10880/17352 (63%)] Loss: -190012.125000\n",
      "Train Epoch: 96 [10960/17352 (63%)] Loss: -208724.828125\n",
      "Train Epoch: 96 [11040/17352 (64%)] Loss: -167873.265625\n",
      "Train Epoch: 96 [11120/17352 (64%)] Loss: -187952.093750\n",
      "Train Epoch: 96 [11200/17352 (65%)] Loss: -166458.796875\n",
      "Train Epoch: 96 [11280/17352 (65%)] Loss: -206931.812500\n",
      "Train Epoch: 96 [11360/17352 (65%)] Loss: -151739.843750\n",
      "Train Epoch: 96 [11440/17352 (66%)] Loss: -211089.500000\n",
      "Train Epoch: 96 [11520/17352 (66%)] Loss: -179736.156250\n",
      "Train Epoch: 96 [11600/17352 (67%)] Loss: -206090.468750\n",
      "Train Epoch: 96 [11680/17352 (67%)] Loss: -189173.968750\n",
      "Train Epoch: 96 [11760/17352 (68%)] Loss: -201838.578125\n",
      "Train Epoch: 96 [11840/17352 (68%)] Loss: -193264.750000\n",
      "Train Epoch: 96 [11920/17352 (69%)] Loss: -183803.546875\n",
      "Train Epoch: 96 [12000/17352 (69%)] Loss: -188185.359375\n",
      "Train Epoch: 96 [12080/17352 (70%)] Loss: -203873.875000\n",
      "Train Epoch: 96 [12160/17352 (70%)] Loss: -166996.546875\n",
      "Train Epoch: 96 [12240/17352 (71%)] Loss: -206363.375000\n",
      "Train Epoch: 96 [12320/17352 (71%)] Loss: -195721.640625\n",
      "Train Epoch: 96 [12400/17352 (71%)] Loss: -207094.406250\n",
      "Train Epoch: 96 [12480/17352 (72%)] Loss: -180254.203125\n",
      "Train Epoch: 96 [12560/17352 (72%)] Loss: -180912.312500\n",
      "Train Epoch: 96 [12640/17352 (73%)] Loss: -195832.562500\n",
      "Train Epoch: 96 [12720/17352 (73%)] Loss: -196405.984375\n",
      "Train Epoch: 96 [12800/17352 (74%)] Loss: -191813.328125\n",
      "Train Epoch: 96 [12880/17352 (74%)] Loss: -178435.375000\n",
      "Train Epoch: 96 [12960/17352 (75%)] Loss: -193917.671875\n",
      "Train Epoch: 96 [13040/17352 (75%)] Loss: -174724.250000\n",
      "Train Epoch: 96 [13120/17352 (76%)] Loss: -197955.953125\n",
      "Train Epoch: 96 [13200/17352 (76%)] Loss: -179450.468750\n",
      "Train Epoch: 96 [13280/17352 (77%)] Loss: -199452.734375\n",
      "Train Epoch: 96 [13360/17352 (77%)] Loss: -161685.671875\n",
      "Train Epoch: 96 [13440/17352 (77%)] Loss: -182101.218750\n",
      "Train Epoch: 96 [13520/17352 (78%)] Loss: -188566.843750\n",
      "Train Epoch: 96 [13600/17352 (78%)] Loss: -188257.734375\n",
      "Train Epoch: 96 [13680/17352 (79%)] Loss: -216331.296875\n",
      "Train Epoch: 96 [13760/17352 (79%)] Loss: -185598.234375\n",
      "Train Epoch: 96 [13840/17352 (80%)] Loss: -228149.062500\n",
      "Train Epoch: 96 [13920/17352 (80%)] Loss: -210493.781250\n",
      "Train Epoch: 96 [14000/17352 (81%)] Loss: -172967.859375\n",
      "Train Epoch: 96 [14080/17352 (81%)] Loss: -204493.218750\n",
      "Train Epoch: 96 [14160/17352 (82%)] Loss: -202578.125000\n",
      "Train Epoch: 96 [14240/17352 (82%)] Loss: -178327.875000\n",
      "Train Epoch: 96 [14320/17352 (83%)] Loss: -215470.578125\n",
      "Train Epoch: 96 [14400/17352 (83%)] Loss: -148516.312500\n",
      "Train Epoch: 96 [14480/17352 (83%)] Loss: -206162.109375\n",
      "Train Epoch: 96 [14560/17352 (84%)] Loss: -183611.234375\n",
      "Train Epoch: 96 [14640/17352 (84%)] Loss: -173370.890625\n",
      "Train Epoch: 96 [14720/17352 (85%)] Loss: -165686.375000\n",
      "Train Epoch: 96 [14800/17352 (85%)] Loss: -175752.625000\n",
      "Train Epoch: 96 [14880/17352 (86%)] Loss: -205512.640625\n",
      "Train Epoch: 96 [14960/17352 (86%)] Loss: -175423.000000\n",
      "Train Epoch: 96 [15040/17352 (87%)] Loss: -200170.281250\n",
      "Train Epoch: 96 [15120/17352 (87%)] Loss: -197343.562500\n",
      "Train Epoch: 96 [15200/17352 (88%)] Loss: -163246.921875\n",
      "Train Epoch: 96 [15280/17352 (88%)] Loss: -197603.062500\n",
      "Train Epoch: 96 [15360/17352 (89%)] Loss: -186954.750000\n",
      "Train Epoch: 96 [15440/17352 (89%)] Loss: -196030.093750\n",
      "Train Epoch: 96 [15520/17352 (89%)] Loss: -177728.671875\n",
      "Train Epoch: 96 [15600/17352 (90%)] Loss: -228087.796875\n",
      "Train Epoch: 96 [15680/17352 (90%)] Loss: -148162.453125\n",
      "Train Epoch: 96 [15760/17352 (91%)] Loss: -169439.765625\n",
      "Train Epoch: 96 [15840/17352 (91%)] Loss: -183786.171875\n",
      "Train Epoch: 96 [15920/17352 (92%)] Loss: -191313.234375\n",
      "Train Epoch: 96 [16000/17352 (92%)] Loss: -191892.656250\n",
      "Train Epoch: 96 [16080/17352 (93%)] Loss: -159610.375000\n",
      "Train Epoch: 96 [16160/17352 (93%)] Loss: -210638.781250\n",
      "Train Epoch: 96 [16240/17352 (94%)] Loss: -213747.937500\n",
      "Train Epoch: 96 [16320/17352 (94%)] Loss: -192319.750000\n",
      "Train Epoch: 96 [16400/17352 (95%)] Loss: -149332.359375\n",
      "Train Epoch: 96 [16480/17352 (95%)] Loss: -175668.234375\n",
      "Train Epoch: 96 [16560/17352 (95%)] Loss: -199420.546875\n",
      "Train Epoch: 96 [16640/17352 (96%)] Loss: -192995.125000\n",
      "Train Epoch: 96 [16720/17352 (96%)] Loss: -177278.531250\n",
      "Train Epoch: 96 [16800/17352 (97%)] Loss: -189605.515625\n",
      "Train Epoch: 96 [16880/17352 (97%)] Loss: -187508.890625\n",
      "Train Epoch: 96 [16960/17352 (98%)] Loss: -147417.843750\n",
      "Train Epoch: 96 [17040/17352 (98%)] Loss: -165391.093750\n",
      "Train Epoch: 96 [17120/17352 (99%)] Loss: -209415.609375\n",
      "Train Epoch: 96 [17200/17352 (99%)] Loss: -148824.421875\n",
      "Train Epoch: 96 [17280/17352 (100%)] Loss: -184755.359375\n",
      "Train Epoch: 96 [17360/17352 (100%)] Loss: -187271.890625\n",
      "    epoch          : 96\n",
      "    loss           : -189542.26883450805\n",
      "    val_loss       : -23716.41534137278\n",
      "Train Epoch: 97 [0/17352 (0%)] Loss: -203743.968750\n",
      "Train Epoch: 97 [80/17352 (0%)] Loss: -212371.046875\n",
      "Train Epoch: 97 [160/17352 (1%)] Loss: -196446.281250\n",
      "Train Epoch: 97 [240/17352 (1%)] Loss: -236636.484375\n",
      "Train Epoch: 97 [320/17352 (2%)] Loss: -204407.765625\n",
      "Train Epoch: 97 [400/17352 (2%)] Loss: -228907.140625\n",
      "Train Epoch: 97 [480/17352 (3%)] Loss: -229237.093750\n",
      "Train Epoch: 97 [560/17352 (3%)] Loss: -218562.750000\n",
      "Train Epoch: 97 [640/17352 (4%)] Loss: -215102.734375\n",
      "Train Epoch: 97 [720/17352 (4%)] Loss: -204734.859375\n",
      "Train Epoch: 97 [800/17352 (5%)] Loss: -218545.000000\n",
      "Train Epoch: 97 [880/17352 (5%)] Loss: -210631.625000\n",
      "Train Epoch: 97 [960/17352 (6%)] Loss: -193582.734375\n",
      "Train Epoch: 97 [1040/17352 (6%)] Loss: -241904.406250\n",
      "Train Epoch: 97 [1120/17352 (6%)] Loss: -206644.625000\n",
      "Train Epoch: 97 [1200/17352 (7%)] Loss: -204533.343750\n",
      "Train Epoch: 97 [1280/17352 (7%)] Loss: -199541.546875\n",
      "Train Epoch: 97 [1360/17352 (8%)] Loss: -217939.250000\n",
      "Train Epoch: 97 [1440/17352 (8%)] Loss: -209779.562500\n",
      "Train Epoch: 97 [1520/17352 (9%)] Loss: -230408.562500\n",
      "Train Epoch: 97 [1600/17352 (9%)] Loss: -202227.953125\n",
      "Train Epoch: 97 [1680/17352 (10%)] Loss: -217632.234375\n",
      "Train Epoch: 97 [1760/17352 (10%)] Loss: -214517.687500\n",
      "Train Epoch: 97 [1840/17352 (11%)] Loss: -202273.671875\n",
      "Train Epoch: 97 [1920/17352 (11%)] Loss: -206751.437500\n",
      "Train Epoch: 97 [2000/17352 (12%)] Loss: -226098.812500\n",
      "Train Epoch: 97 [2080/17352 (12%)] Loss: -210203.000000\n",
      "Train Epoch: 97 [2160/17352 (12%)] Loss: -214341.250000\n",
      "Train Epoch: 97 [2240/17352 (13%)] Loss: -183785.078125\n",
      "Train Epoch: 97 [2320/17352 (13%)] Loss: -179484.687500\n",
      "Train Epoch: 97 [2400/17352 (14%)] Loss: -188809.968750\n",
      "Train Epoch: 97 [2480/17352 (14%)] Loss: -180116.625000\n",
      "Train Epoch: 97 [2560/17352 (15%)] Loss: -205009.000000\n",
      "Train Epoch: 97 [2640/17352 (15%)] Loss: -187407.500000\n",
      "Train Epoch: 97 [2720/17352 (16%)] Loss: -180062.546875\n",
      "Train Epoch: 97 [2800/17352 (16%)] Loss: -218747.968750\n",
      "Train Epoch: 97 [2880/17352 (17%)] Loss: -214683.343750\n",
      "Train Epoch: 97 [2960/17352 (17%)] Loss: -191563.687500\n",
      "Train Epoch: 97 [3040/17352 (18%)] Loss: -187269.703125\n",
      "Train Epoch: 97 [3120/17352 (18%)] Loss: -180259.890625\n",
      "Train Epoch: 97 [3200/17352 (18%)] Loss: -201364.906250\n",
      "Train Epoch: 97 [3280/17352 (19%)] Loss: -180806.640625\n",
      "Train Epoch: 97 [3360/17352 (19%)] Loss: -208753.734375\n",
      "Train Epoch: 97 [3440/17352 (20%)] Loss: -178602.062500\n",
      "Train Epoch: 97 [3520/17352 (20%)] Loss: -192287.453125\n",
      "Train Epoch: 97 [3600/17352 (21%)] Loss: -207861.171875\n",
      "Train Epoch: 97 [3680/17352 (21%)] Loss: -171546.343750\n",
      "Train Epoch: 97 [3760/17352 (22%)] Loss: -179501.250000\n",
      "Train Epoch: 97 [3840/17352 (22%)] Loss: -207090.750000\n",
      "Train Epoch: 97 [3920/17352 (23%)] Loss: -208307.531250\n",
      "Train Epoch: 97 [4000/17352 (23%)] Loss: -182923.265625\n",
      "Train Epoch: 97 [4080/17352 (24%)] Loss: -199792.765625\n",
      "Train Epoch: 97 [4160/17352 (24%)] Loss: -181895.109375\n",
      "Train Epoch: 97 [4240/17352 (24%)] Loss: -163496.968750\n",
      "Train Epoch: 97 [4320/17352 (25%)] Loss: -179970.750000\n",
      "Train Epoch: 97 [4400/17352 (25%)] Loss: -170536.828125\n",
      "Train Epoch: 97 [4480/17352 (26%)] Loss: -207788.984375\n",
      "Train Epoch: 97 [4560/17352 (26%)] Loss: -167189.343750\n",
      "Train Epoch: 97 [4640/17352 (27%)] Loss: -201036.578125\n",
      "Train Epoch: 97 [4720/17352 (27%)] Loss: -188260.671875\n",
      "Train Epoch: 97 [4800/17352 (28%)] Loss: -131048.570312\n",
      "Train Epoch: 97 [4880/17352 (28%)] Loss: -180909.968750\n",
      "Train Epoch: 97 [4960/17352 (29%)] Loss: -178828.312500\n",
      "Train Epoch: 97 [5040/17352 (29%)] Loss: -166655.906250\n",
      "Train Epoch: 97 [5120/17352 (30%)] Loss: -187322.890625\n",
      "Train Epoch: 97 [5200/17352 (30%)] Loss: -167297.968750\n",
      "Train Epoch: 97 [5280/17352 (30%)] Loss: -174729.218750\n",
      "Train Epoch: 97 [5360/17352 (31%)] Loss: -177603.437500\n",
      "Train Epoch: 97 [5440/17352 (31%)] Loss: -196701.484375\n",
      "Train Epoch: 97 [5520/17352 (32%)] Loss: -167874.578125\n",
      "Train Epoch: 97 [5600/17352 (32%)] Loss: -174485.093750\n",
      "Train Epoch: 97 [5680/17352 (33%)] Loss: -176485.125000\n",
      "Train Epoch: 97 [5760/17352 (33%)] Loss: -159611.671875\n",
      "Train Epoch: 97 [5840/17352 (34%)] Loss: -188684.750000\n",
      "Train Epoch: 97 [5920/17352 (34%)] Loss: -151508.828125\n",
      "Train Epoch: 97 [6000/17352 (35%)] Loss: -202243.531250\n",
      "Train Epoch: 97 [6080/17352 (35%)] Loss: -200465.562500\n",
      "Train Epoch: 97 [6160/17352 (36%)] Loss: -184071.890625\n",
      "Train Epoch: 97 [6240/17352 (36%)] Loss: -161515.937500\n",
      "Train Epoch: 97 [6320/17352 (36%)] Loss: -220016.343750\n",
      "Train Epoch: 97 [6400/17352 (37%)] Loss: -165598.125000\n",
      "Train Epoch: 97 [6480/17352 (37%)] Loss: -194605.468750\n",
      "Train Epoch: 97 [6560/17352 (38%)] Loss: -166554.265625\n",
      "Train Epoch: 97 [6640/17352 (38%)] Loss: -209824.218750\n",
      "Train Epoch: 97 [6720/17352 (39%)] Loss: -167734.500000\n",
      "Train Epoch: 97 [6800/17352 (39%)] Loss: -170242.078125\n",
      "Train Epoch: 97 [6880/17352 (40%)] Loss: -185369.640625\n",
      "Train Epoch: 97 [6960/17352 (40%)] Loss: -215418.890625\n",
      "Train Epoch: 97 [7040/17352 (41%)] Loss: -181338.750000\n",
      "Train Epoch: 97 [7120/17352 (41%)] Loss: -193186.421875\n",
      "Train Epoch: 97 [7200/17352 (41%)] Loss: -179008.609375\n",
      "Train Epoch: 97 [7280/17352 (42%)] Loss: -217608.921875\n",
      "Train Epoch: 97 [7360/17352 (42%)] Loss: -184923.218750\n",
      "Train Epoch: 97 [7440/17352 (43%)] Loss: -180995.406250\n",
      "Train Epoch: 97 [7520/17352 (43%)] Loss: -196514.984375\n",
      "Train Epoch: 97 [7600/17352 (44%)] Loss: -183386.250000\n",
      "Train Epoch: 97 [7680/17352 (44%)] Loss: -204418.343750\n",
      "Train Epoch: 97 [7760/17352 (45%)] Loss: -194053.671875\n",
      "Train Epoch: 97 [7840/17352 (45%)] Loss: -148163.859375\n",
      "Train Epoch: 97 [7920/17352 (46%)] Loss: -181173.671875\n",
      "Train Epoch: 97 [8000/17352 (46%)] Loss: -136432.140625\n",
      "Train Epoch: 97 [8080/17352 (47%)] Loss: -204212.734375\n",
      "Train Epoch: 97 [8160/17352 (47%)] Loss: -179453.500000\n",
      "Train Epoch: 97 [8240/17352 (47%)] Loss: -170035.875000\n",
      "Train Epoch: 97 [8320/17352 (48%)] Loss: -168968.031250\n",
      "Train Epoch: 97 [8400/17352 (48%)] Loss: -175672.578125\n",
      "Train Epoch: 97 [8480/17352 (49%)] Loss: -184762.250000\n",
      "Train Epoch: 97 [8560/17352 (49%)] Loss: -195650.500000\n",
      "Train Epoch: 97 [8640/17352 (50%)] Loss: -180148.937500\n",
      "Train Epoch: 97 [8720/17352 (50%)] Loss: -196044.031250\n",
      "Train Epoch: 97 [8800/17352 (51%)] Loss: -174992.125000\n",
      "Train Epoch: 97 [8880/17352 (51%)] Loss: -163109.406250\n",
      "Train Epoch: 97 [8960/17352 (52%)] Loss: -200975.515625\n",
      "Train Epoch: 97 [9040/17352 (52%)] Loss: -142339.109375\n",
      "Train Epoch: 97 [9120/17352 (53%)] Loss: -185547.921875\n",
      "Train Epoch: 97 [9200/17352 (53%)] Loss: -204333.015625\n",
      "Train Epoch: 97 [9280/17352 (53%)] Loss: -170354.546875\n",
      "Train Epoch: 97 [9360/17352 (54%)] Loss: -203875.218750\n",
      "Train Epoch: 97 [9440/17352 (54%)] Loss: -187595.812500\n",
      "Train Epoch: 97 [9520/17352 (55%)] Loss: -208129.437500\n",
      "Train Epoch: 97 [9600/17352 (55%)] Loss: -174881.453125\n",
      "Train Epoch: 97 [9680/17352 (56%)] Loss: -188862.750000\n",
      "Train Epoch: 97 [9760/17352 (56%)] Loss: -193366.937500\n",
      "Train Epoch: 97 [9840/17352 (57%)] Loss: -173660.140625\n",
      "Train Epoch: 97 [9920/17352 (57%)] Loss: -159679.187500\n",
      "Train Epoch: 97 [10000/17352 (58%)] Loss: -170680.750000\n",
      "Train Epoch: 97 [10080/17352 (58%)] Loss: -212905.437500\n",
      "Train Epoch: 97 [10160/17352 (59%)] Loss: -213402.500000\n",
      "Train Epoch: 97 [10240/17352 (59%)] Loss: -204350.328125\n",
      "Train Epoch: 97 [10320/17352 (59%)] Loss: -183503.562500\n",
      "Train Epoch: 97 [10400/17352 (60%)] Loss: -180255.625000\n",
      "Train Epoch: 97 [10480/17352 (60%)] Loss: -170786.062500\n",
      "Train Epoch: 97 [10560/17352 (61%)] Loss: -174645.343750\n",
      "Train Epoch: 97 [10640/17352 (61%)] Loss: -161686.109375\n",
      "Train Epoch: 97 [10720/17352 (62%)] Loss: -207127.812500\n",
      "Train Epoch: 97 [10800/17352 (62%)] Loss: -196035.078125\n",
      "Train Epoch: 97 [10880/17352 (63%)] Loss: -167254.531250\n",
      "Train Epoch: 97 [10960/17352 (63%)] Loss: -148448.406250\n",
      "Train Epoch: 97 [11040/17352 (64%)] Loss: -192255.703125\n",
      "Train Epoch: 97 [11120/17352 (64%)] Loss: -183375.062500\n",
      "Train Epoch: 97 [11200/17352 (65%)] Loss: -181077.281250\n",
      "Train Epoch: 97 [11280/17352 (65%)] Loss: -186782.359375\n",
      "Train Epoch: 97 [11360/17352 (65%)] Loss: -205214.187500\n",
      "Train Epoch: 97 [11440/17352 (66%)] Loss: -183288.625000\n",
      "Train Epoch: 97 [11520/17352 (66%)] Loss: -180290.921875\n",
      "Train Epoch: 97 [11600/17352 (67%)] Loss: -184758.250000\n",
      "Train Epoch: 97 [11680/17352 (67%)] Loss: -183977.921875\n",
      "Train Epoch: 97 [11760/17352 (68%)] Loss: -183064.500000\n",
      "Train Epoch: 97 [11840/17352 (68%)] Loss: -202083.546875\n",
      "Train Epoch: 97 [11920/17352 (69%)] Loss: -143623.468750\n",
      "Train Epoch: 97 [12000/17352 (69%)] Loss: -184493.921875\n",
      "Train Epoch: 97 [12080/17352 (70%)] Loss: -174517.468750\n",
      "Train Epoch: 97 [12160/17352 (70%)] Loss: -200203.843750\n",
      "Train Epoch: 97 [12240/17352 (71%)] Loss: -177313.046875\n",
      "Train Epoch: 97 [12320/17352 (71%)] Loss: -170312.578125\n",
      "Train Epoch: 97 [12400/17352 (71%)] Loss: -171730.890625\n",
      "Train Epoch: 97 [12480/17352 (72%)] Loss: -205021.546875\n",
      "Train Epoch: 97 [12560/17352 (72%)] Loss: -144999.078125\n",
      "Train Epoch: 97 [12640/17352 (73%)] Loss: -188566.390625\n",
      "Train Epoch: 97 [12720/17352 (73%)] Loss: -188051.812500\n",
      "Train Epoch: 97 [12800/17352 (74%)] Loss: -140589.359375\n",
      "Train Epoch: 97 [12880/17352 (74%)] Loss: -175749.468750\n",
      "Train Epoch: 97 [12960/17352 (75%)] Loss: -186555.921875\n",
      "Train Epoch: 97 [13040/17352 (75%)] Loss: -168053.968750\n",
      "Train Epoch: 97 [13120/17352 (76%)] Loss: -210635.468750\n",
      "Train Epoch: 97 [13200/17352 (76%)] Loss: -185059.640625\n",
      "Train Epoch: 97 [13280/17352 (77%)] Loss: -191892.437500\n",
      "Train Epoch: 97 [13360/17352 (77%)] Loss: -196286.750000\n",
      "Train Epoch: 97 [13440/17352 (77%)] Loss: -198552.187500\n",
      "Train Epoch: 97 [13520/17352 (78%)] Loss: -160054.375000\n",
      "Train Epoch: 97 [13600/17352 (78%)] Loss: -187128.078125\n",
      "Train Epoch: 97 [13680/17352 (79%)] Loss: -216320.968750\n",
      "Train Epoch: 97 [13760/17352 (79%)] Loss: -184843.265625\n",
      "Train Epoch: 97 [13840/17352 (80%)] Loss: -180754.156250\n",
      "Train Epoch: 97 [13920/17352 (80%)] Loss: -189491.656250\n",
      "Train Epoch: 97 [14000/17352 (81%)] Loss: -191048.640625\n",
      "Train Epoch: 97 [14080/17352 (81%)] Loss: -196567.140625\n",
      "Train Epoch: 97 [14160/17352 (82%)] Loss: -225476.843750\n",
      "Train Epoch: 97 [14240/17352 (82%)] Loss: -192121.312500\n",
      "Train Epoch: 97 [14320/17352 (83%)] Loss: -175691.281250\n",
      "Train Epoch: 97 [14400/17352 (83%)] Loss: -211636.531250\n",
      "Train Epoch: 97 [14480/17352 (83%)] Loss: -203677.625000\n",
      "Train Epoch: 97 [14560/17352 (84%)] Loss: -180696.625000\n",
      "Train Epoch: 97 [14640/17352 (84%)] Loss: -202176.218750\n",
      "Train Epoch: 97 [14720/17352 (85%)] Loss: -181728.546875\n",
      "Train Epoch: 97 [14800/17352 (85%)] Loss: -156608.609375\n",
      "Train Epoch: 97 [14880/17352 (86%)] Loss: -188428.171875\n",
      "Train Epoch: 97 [14960/17352 (86%)] Loss: -215657.796875\n",
      "Train Epoch: 97 [15040/17352 (87%)] Loss: -180166.343750\n",
      "Train Epoch: 97 [15120/17352 (87%)] Loss: -172184.875000\n",
      "Train Epoch: 97 [15200/17352 (88%)] Loss: -173443.515625\n",
      "Train Epoch: 97 [15280/17352 (88%)] Loss: -214638.203125\n",
      "Train Epoch: 97 [15360/17352 (89%)] Loss: -184035.718750\n",
      "Train Epoch: 97 [15440/17352 (89%)] Loss: -185786.437500\n",
      "Train Epoch: 97 [15520/17352 (89%)] Loss: -200170.156250\n",
      "Train Epoch: 97 [15600/17352 (90%)] Loss: -192959.468750\n",
      "Train Epoch: 97 [15680/17352 (90%)] Loss: -158747.500000\n",
      "Train Epoch: 97 [15760/17352 (91%)] Loss: -187248.656250\n",
      "Train Epoch: 97 [15840/17352 (91%)] Loss: -189512.515625\n",
      "Train Epoch: 97 [15920/17352 (92%)] Loss: -203484.046875\n",
      "Train Epoch: 97 [16000/17352 (92%)] Loss: -195827.718750\n",
      "Train Epoch: 97 [16080/17352 (93%)] Loss: -174144.906250\n",
      "Train Epoch: 97 [16160/17352 (93%)] Loss: -206093.281250\n",
      "Train Epoch: 97 [16240/17352 (94%)] Loss: -177982.843750\n",
      "Train Epoch: 97 [16320/17352 (94%)] Loss: -171419.406250\n",
      "Train Epoch: 97 [16400/17352 (95%)] Loss: -191335.578125\n",
      "Train Epoch: 97 [16480/17352 (95%)] Loss: -189218.296875\n",
      "Train Epoch: 97 [16560/17352 (95%)] Loss: -164075.906250\n",
      "Train Epoch: 97 [16640/17352 (96%)] Loss: -186951.093750\n",
      "Train Epoch: 97 [16720/17352 (96%)] Loss: -184482.312500\n",
      "Train Epoch: 97 [16800/17352 (97%)] Loss: -173044.656250\n",
      "Train Epoch: 97 [16880/17352 (97%)] Loss: -167958.218750\n",
      "Train Epoch: 97 [16960/17352 (98%)] Loss: -206599.406250\n",
      "Train Epoch: 97 [17040/17352 (98%)] Loss: -214752.625000\n",
      "Train Epoch: 97 [17120/17352 (99%)] Loss: -177248.046875\n",
      "Train Epoch: 97 [17200/17352 (99%)] Loss: -172233.250000\n",
      "Train Epoch: 97 [17280/17352 (100%)] Loss: -221261.218750\n",
      "Train Epoch: 97 [17360/17352 (100%)] Loss: -167870.234375\n",
      "    epoch          : 97\n",
      "    loss           : -189233.06396540563\n",
      "    val_loss       : -23716.38212814689\n",
      "Train Epoch: 98 [0/17352 (0%)] Loss: -211899.421875\n",
      "Train Epoch: 98 [80/17352 (0%)] Loss: -218537.296875\n",
      "Train Epoch: 98 [160/17352 (1%)] Loss: -219208.375000\n",
      "Train Epoch: 98 [240/17352 (1%)] Loss: -198770.421875\n",
      "Train Epoch: 98 [320/17352 (2%)] Loss: -212394.281250\n",
      "Train Epoch: 98 [400/17352 (2%)] Loss: -222516.781250\n",
      "Train Epoch: 98 [480/17352 (3%)] Loss: -223003.765625\n",
      "Train Epoch: 98 [560/17352 (3%)] Loss: -216104.812500\n",
      "Train Epoch: 98 [640/17352 (4%)] Loss: -219265.125000\n",
      "Train Epoch: 98 [720/17352 (4%)] Loss: -193708.875000\n",
      "Train Epoch: 98 [800/17352 (5%)] Loss: -191881.406250\n",
      "Train Epoch: 98 [880/17352 (5%)] Loss: -208533.546875\n",
      "Train Epoch: 98 [960/17352 (6%)] Loss: -205197.062500\n",
      "Train Epoch: 98 [1040/17352 (6%)] Loss: -204703.656250\n",
      "Train Epoch: 98 [1120/17352 (6%)] Loss: -212707.437500\n",
      "Train Epoch: 98 [1200/17352 (7%)] Loss: -210630.421875\n",
      "Train Epoch: 98 [1280/17352 (7%)] Loss: -193582.109375\n",
      "Train Epoch: 98 [1360/17352 (8%)] Loss: -206650.968750\n",
      "Train Epoch: 98 [1440/17352 (8%)] Loss: -182777.328125\n",
      "Train Epoch: 98 [1520/17352 (9%)] Loss: -224354.750000\n",
      "Train Epoch: 98 [1600/17352 (9%)] Loss: -241909.000000\n",
      "Train Epoch: 98 [1680/17352 (10%)] Loss: -205090.000000\n",
      "Train Epoch: 98 [1760/17352 (10%)] Loss: -196444.578125\n",
      "Train Epoch: 98 [1840/17352 (11%)] Loss: -217632.750000\n",
      "Train Epoch: 98 [1920/17352 (11%)] Loss: -194296.031250\n",
      "Train Epoch: 98 [2000/17352 (12%)] Loss: -229962.281250\n",
      "Train Epoch: 98 [2080/17352 (12%)] Loss: -209639.437500\n",
      "Train Epoch: 98 [2160/17352 (12%)] Loss: -204536.375000\n",
      "Train Epoch: 98 [2240/17352 (13%)] Loss: -187266.140625\n",
      "Train Epoch: 98 [2320/17352 (13%)] Loss: -167954.421875\n",
      "Train Epoch: 98 [2400/17352 (14%)] Loss: -211638.171875\n",
      "Train Epoch: 98 [2480/17352 (14%)] Loss: -188094.093750\n",
      "Train Epoch: 98 [2560/17352 (15%)] Loss: -202478.765625\n",
      "Train Epoch: 98 [2640/17352 (15%)] Loss: -204498.593750\n",
      "Train Epoch: 98 [2720/17352 (16%)] Loss: -159315.125000\n",
      "Train Epoch: 98 [2800/17352 (16%)] Loss: -192010.203125\n",
      "Train Epoch: 98 [2880/17352 (17%)] Loss: -177148.328125\n",
      "Train Epoch: 98 [2960/17352 (17%)] Loss: -168075.390625\n",
      "Train Epoch: 98 [3040/17352 (18%)] Loss: -225474.546875\n",
      "Train Epoch: 98 [3120/17352 (18%)] Loss: -193446.062500\n",
      "Train Epoch: 98 [3200/17352 (18%)] Loss: -180513.406250\n",
      "Train Epoch: 98 [3280/17352 (19%)] Loss: -177196.000000\n",
      "Train Epoch: 98 [3360/17352 (19%)] Loss: -182777.750000\n",
      "Train Epoch: 98 [3440/17352 (20%)] Loss: -171325.984375\n",
      "Train Epoch: 98 [3520/17352 (20%)] Loss: -218749.515625\n",
      "Train Epoch: 98 [3600/17352 (21%)] Loss: -191007.656250\n",
      "Train Epoch: 98 [3680/17352 (21%)] Loss: -167036.703125\n",
      "Train Epoch: 98 [3760/17352 (22%)] Loss: -204946.062500\n",
      "Train Epoch: 98 [3840/17352 (22%)] Loss: -178429.062500\n",
      "Train Epoch: 98 [3920/17352 (23%)] Loss: -196446.375000\n",
      "Train Epoch: 98 [4000/17352 (23%)] Loss: -164744.656250\n",
      "Train Epoch: 98 [4080/17352 (24%)] Loss: -164991.796875\n",
      "Train Epoch: 98 [4160/17352 (24%)] Loss: -199520.875000\n",
      "Train Epoch: 98 [4240/17352 (24%)] Loss: -166670.125000\n",
      "Train Epoch: 98 [4320/17352 (25%)] Loss: -231037.281250\n",
      "Train Epoch: 98 [4400/17352 (25%)] Loss: -202990.968750\n",
      "Train Epoch: 98 [4480/17352 (26%)] Loss: -204610.796875\n",
      "Train Epoch: 98 [4560/17352 (26%)] Loss: -163554.578125\n",
      "Train Epoch: 98 [4640/17352 (27%)] Loss: -190385.750000\n",
      "Train Epoch: 98 [4720/17352 (27%)] Loss: -134539.312500\n",
      "Train Epoch: 98 [4800/17352 (28%)] Loss: -197114.093750\n",
      "Train Epoch: 98 [4880/17352 (28%)] Loss: -153319.156250\n",
      "Train Epoch: 98 [4960/17352 (29%)] Loss: -197597.671875\n",
      "Train Epoch: 98 [5040/17352 (29%)] Loss: -178806.140625\n",
      "Train Epoch: 98 [5120/17352 (30%)] Loss: -173364.375000\n",
      "Train Epoch: 98 [5200/17352 (30%)] Loss: -174510.796875\n",
      "Train Epoch: 98 [5280/17352 (30%)] Loss: -187727.906250\n",
      "Train Epoch: 98 [5360/17352 (31%)] Loss: -196446.812500\n",
      "Train Epoch: 98 [5440/17352 (31%)] Loss: -187888.718750\n",
      "Train Epoch: 98 [5520/17352 (32%)] Loss: -173511.546875\n",
      "Train Epoch: 98 [5600/17352 (32%)] Loss: -151508.578125\n",
      "Train Epoch: 98 [5680/17352 (33%)] Loss: -215461.687500\n",
      "Train Epoch: 98 [5760/17352 (33%)] Loss: -192962.031250\n",
      "Train Epoch: 98 [5840/17352 (34%)] Loss: -178327.187500\n",
      "Train Epoch: 98 [5920/17352 (34%)] Loss: -138342.546875\n",
      "Train Epoch: 98 [6000/17352 (35%)] Loss: -176884.578125\n",
      "Train Epoch: 98 [6080/17352 (35%)] Loss: -188676.031250\n",
      "Train Epoch: 98 [6160/17352 (36%)] Loss: -198311.968750\n",
      "Train Epoch: 98 [6240/17352 (36%)] Loss: -171230.671875\n",
      "Train Epoch: 98 [6320/17352 (36%)] Loss: -169954.468750\n",
      "Train Epoch: 98 [6400/17352 (37%)] Loss: -187274.781250\n",
      "Train Epoch: 98 [6480/17352 (37%)] Loss: -191954.312500\n",
      "Train Epoch: 98 [6560/17352 (38%)] Loss: -178601.500000\n",
      "Train Epoch: 98 [6640/17352 (38%)] Loss: -171306.781250\n",
      "Train Epoch: 98 [6720/17352 (39%)] Loss: -195830.281250\n",
      "Train Epoch: 98 [6800/17352 (39%)] Loss: -172182.484375\n",
      "Train Epoch: 98 [6880/17352 (40%)] Loss: -202316.250000\n",
      "Train Epoch: 98 [6960/17352 (40%)] Loss: -192120.734375\n",
      "Train Epoch: 98 [7040/17352 (41%)] Loss: -166654.031250\n",
      "Train Epoch: 98 [7120/17352 (41%)] Loss: -170231.437500\n",
      "Train Epoch: 98 [7200/17352 (41%)] Loss: -167140.250000\n",
      "Train Epoch: 98 [7280/17352 (42%)] Loss: -187254.203125\n",
      "Train Epoch: 98 [7360/17352 (42%)] Loss: -159752.250000\n",
      "Train Epoch: 98 [7440/17352 (43%)] Loss: -191831.765625\n",
      "Train Epoch: 98 [7520/17352 (43%)] Loss: -209186.968750\n",
      "Train Epoch: 98 [7600/17352 (44%)] Loss: -167304.640625\n",
      "Train Epoch: 98 [7680/17352 (44%)] Loss: -146004.218750\n",
      "Train Epoch: 98 [7760/17352 (45%)] Loss: -164510.296875\n",
      "Train Epoch: 98 [7840/17352 (45%)] Loss: -168258.562500\n",
      "Train Epoch: 98 [7920/17352 (46%)] Loss: -202242.515625\n",
      "Train Epoch: 98 [8000/17352 (46%)] Loss: -176154.359375\n",
      "Train Epoch: 98 [8080/17352 (47%)] Loss: -196506.359375\n",
      "Train Epoch: 98 [8160/17352 (47%)] Loss: -190811.000000\n",
      "Train Epoch: 98 [8240/17352 (47%)] Loss: -199790.156250\n",
      "Train Epoch: 98 [8320/17352 (48%)] Loss: -183800.265625\n",
      "Train Epoch: 98 [8400/17352 (48%)] Loss: -204614.531250\n",
      "Train Epoch: 98 [8480/17352 (49%)] Loss: -182096.625000\n",
      "Train Epoch: 98 [8560/17352 (49%)] Loss: -208904.984375\n",
      "Train Epoch: 98 [8640/17352 (50%)] Loss: -171833.078125\n",
      "Train Epoch: 98 [8720/17352 (50%)] Loss: -187542.906250\n",
      "Train Epoch: 98 [8800/17352 (51%)] Loss: -212657.703125\n",
      "Train Epoch: 98 [8880/17352 (51%)] Loss: -186040.812500\n",
      "Train Epoch: 98 [8960/17352 (52%)] Loss: -192646.671875\n",
      "Train Epoch: 98 [9040/17352 (52%)] Loss: -175320.031250\n",
      "Train Epoch: 98 [9120/17352 (53%)] Loss: -169752.671875\n",
      "Train Epoch: 98 [9200/17352 (53%)] Loss: -185439.937500\n",
      "Train Epoch: 98 [9280/17352 (53%)] Loss: -197566.781250\n",
      "Train Epoch: 98 [9360/17352 (54%)] Loss: -185508.906250\n",
      "Train Epoch: 98 [9440/17352 (54%)] Loss: -201269.734375\n",
      "Train Epoch: 98 [9520/17352 (55%)] Loss: -193195.453125\n",
      "Train Epoch: 98 [9600/17352 (55%)] Loss: -184821.531250\n",
      "Train Epoch: 98 [9680/17352 (56%)] Loss: -177780.734375\n",
      "Train Epoch: 98 [9760/17352 (56%)] Loss: -184760.593750\n",
      "Train Epoch: 98 [9840/17352 (57%)] Loss: -181261.171875\n",
      "Train Epoch: 98 [9920/17352 (57%)] Loss: -209274.000000\n",
      "Train Epoch: 98 [10000/17352 (58%)] Loss: -163969.781250\n",
      "Train Epoch: 98 [10080/17352 (58%)] Loss: -195106.218750\n",
      "Train Epoch: 98 [10160/17352 (59%)] Loss: -182742.406250\n",
      "Train Epoch: 98 [10240/17352 (59%)] Loss: -170111.000000\n",
      "Train Epoch: 98 [10320/17352 (59%)] Loss: -220976.093750\n",
      "Train Epoch: 98 [10400/17352 (60%)] Loss: -184758.859375\n",
      "Train Epoch: 98 [10480/17352 (60%)] Loss: -192322.500000\n",
      "Train Epoch: 98 [10560/17352 (61%)] Loss: -198699.359375\n",
      "Train Epoch: 98 [10640/17352 (61%)] Loss: -177467.843750\n",
      "Train Epoch: 98 [10720/17352 (62%)] Loss: -193369.375000\n",
      "Train Epoch: 98 [10800/17352 (62%)] Loss: -161679.640625\n",
      "Train Epoch: 98 [10880/17352 (63%)] Loss: -208763.500000\n",
      "Train Epoch: 98 [10960/17352 (63%)] Loss: -189488.187500\n",
      "Train Epoch: 98 [11040/17352 (64%)] Loss: -209201.531250\n",
      "Train Epoch: 98 [11120/17352 (64%)] Loss: -194054.000000\n",
      "Train Epoch: 98 [11200/17352 (65%)] Loss: -192386.828125\n",
      "Train Epoch: 98 [11280/17352 (65%)] Loss: -202181.203125\n",
      "Train Epoch: 98 [11360/17352 (65%)] Loss: -200076.234375\n",
      "Train Epoch: 98 [11440/17352 (66%)] Loss: -149436.828125\n",
      "Train Epoch: 98 [11520/17352 (66%)] Loss: -164810.609375\n",
      "Train Epoch: 98 [11600/17352 (67%)] Loss: -187594.656250\n",
      "Train Epoch: 98 [11680/17352 (67%)] Loss: -180164.078125\n",
      "Train Epoch: 98 [11760/17352 (68%)] Loss: -185231.406250\n",
      "Train Epoch: 98 [11840/17352 (68%)] Loss: -209272.031250\n",
      "Train Epoch: 98 [11920/17352 (69%)] Loss: -198300.875000\n",
      "Train Epoch: 98 [12000/17352 (69%)] Loss: -191889.750000\n",
      "Train Epoch: 98 [12080/17352 (70%)] Loss: -210160.921875\n",
      "Train Epoch: 98 [12160/17352 (70%)] Loss: -190583.750000\n",
      "Train Epoch: 98 [12240/17352 (71%)] Loss: -201307.968750\n",
      "Train Epoch: 98 [12320/17352 (71%)] Loss: -184030.250000\n",
      "Train Epoch: 98 [12400/17352 (71%)] Loss: -184482.453125\n",
      "Train Epoch: 98 [12480/17352 (72%)] Loss: -207785.312500\n",
      "Train Epoch: 98 [12560/17352 (72%)] Loss: -186684.187500\n",
      "Train Epoch: 98 [12640/17352 (73%)] Loss: -181958.640625\n",
      "Train Epoch: 98 [12720/17352 (73%)] Loss: -183920.250000\n",
      "Train Epoch: 98 [12800/17352 (74%)] Loss: -191235.265625\n",
      "Train Epoch: 98 [12880/17352 (74%)] Loss: -180910.250000\n",
      "Train Epoch: 98 [12960/17352 (75%)] Loss: -185998.656250\n",
      "Train Epoch: 98 [13040/17352 (75%)] Loss: -174457.578125\n",
      "Train Epoch: 98 [13120/17352 (76%)] Loss: -176589.031250\n",
      "Train Epoch: 98 [13200/17352 (76%)] Loss: -192888.343750\n",
      "Train Epoch: 98 [13280/17352 (77%)] Loss: -195376.375000\n",
      "Train Epoch: 98 [13360/17352 (77%)] Loss: -183633.421875\n",
      "Train Epoch: 98 [13440/17352 (77%)] Loss: -202986.046875\n",
      "Train Epoch: 98 [13520/17352 (78%)] Loss: -180964.937500\n",
      "Train Epoch: 98 [13600/17352 (78%)] Loss: -194605.125000\n",
      "Train Epoch: 98 [13680/17352 (79%)] Loss: -178732.562500\n",
      "Train Epoch: 98 [13760/17352 (79%)] Loss: -191555.796875\n",
      "Train Epoch: 98 [13840/17352 (80%)] Loss: -187319.546875\n",
      "Train Epoch: 98 [13920/17352 (80%)] Loss: -184989.015625\n",
      "Train Epoch: 98 [14000/17352 (81%)] Loss: -177305.578125\n",
      "Train Epoch: 98 [14080/17352 (81%)] Loss: -176973.468750\n",
      "Train Epoch: 98 [14160/17352 (82%)] Loss: -201526.531250\n",
      "Train Epoch: 98 [14240/17352 (82%)] Loss: -179383.656250\n",
      "Train Epoch: 98 [14320/17352 (83%)] Loss: -177278.437500\n",
      "Train Epoch: 98 [14400/17352 (83%)] Loss: -177606.234375\n",
      "Train Epoch: 98 [14480/17352 (83%)] Loss: -179012.796875\n",
      "Train Epoch: 98 [14560/17352 (84%)] Loss: -193167.703125\n",
      "Train Epoch: 98 [14640/17352 (84%)] Loss: -189172.062500\n",
      "Train Epoch: 98 [14720/17352 (85%)] Loss: -197309.890625\n",
      "Train Epoch: 98 [14800/17352 (85%)] Loss: -200842.734375\n",
      "Train Epoch: 98 [14880/17352 (86%)] Loss: -166258.250000\n",
      "Train Epoch: 98 [14960/17352 (86%)] Loss: -201089.500000\n",
      "Train Epoch: 98 [15040/17352 (87%)] Loss: -186517.406250\n",
      "Train Epoch: 98 [15120/17352 (87%)] Loss: -190229.421875\n",
      "Train Epoch: 98 [15200/17352 (88%)] Loss: -201387.609375\n",
      "Train Epoch: 98 [15280/17352 (88%)] Loss: -181379.312500\n",
      "Train Epoch: 98 [15360/17352 (89%)] Loss: -170243.265625\n",
      "Train Epoch: 98 [15440/17352 (89%)] Loss: -191804.187500\n",
      "Train Epoch: 98 [15520/17352 (89%)] Loss: -179307.546875\n",
      "Train Epoch: 98 [15600/17352 (90%)] Loss: -192233.562500\n",
      "Train Epoch: 98 [15680/17352 (90%)] Loss: -163219.250000\n",
      "Train Epoch: 98 [15760/17352 (91%)] Loss: -166550.796875\n",
      "Train Epoch: 98 [15840/17352 (91%)] Loss: -171734.093750\n",
      "Train Epoch: 98 [15920/17352 (92%)] Loss: -184838.953125\n",
      "Train Epoch: 98 [16000/17352 (92%)] Loss: -159674.968750\n",
      "Train Epoch: 98 [16080/17352 (93%)] Loss: -183759.031250\n",
      "Train Epoch: 98 [16160/17352 (93%)] Loss: -165764.218750\n",
      "Train Epoch: 98 [16240/17352 (94%)] Loss: -163109.234375\n",
      "Train Epoch: 98 [16320/17352 (94%)] Loss: -205638.000000\n",
      "Train Epoch: 98 [16400/17352 (95%)] Loss: -173447.687500\n",
      "Train Epoch: 98 [16480/17352 (95%)] Loss: -208342.875000\n",
      "Train Epoch: 98 [16560/17352 (95%)] Loss: -200863.546875\n",
      "Train Epoch: 98 [16640/17352 (96%)] Loss: -174937.484375\n",
      "Train Epoch: 98 [16720/17352 (96%)] Loss: -189607.890625\n",
      "Train Epoch: 98 [16800/17352 (97%)] Loss: -216324.671875\n",
      "Train Epoch: 98 [16880/17352 (97%)] Loss: -177254.765625\n",
      "Train Epoch: 98 [16960/17352 (98%)] Loss: -177470.390625\n",
      "Train Epoch: 98 [17040/17352 (98%)] Loss: -193098.046875\n",
      "Train Epoch: 98 [17120/17352 (99%)] Loss: -200636.343750\n",
      "Train Epoch: 98 [17200/17352 (99%)] Loss: -181699.234375\n",
      "Train Epoch: 98 [17280/17352 (100%)] Loss: -211165.625000\n",
      "Train Epoch: 98 [17360/17352 (100%)] Loss: -168673.359375\n",
      "    epoch          : 98\n",
      "    loss           : -189087.9394778481\n",
      "    val_loss       : -23716.2962909394\n",
      "Train Epoch: 99 [0/17352 (0%)] Loss: -228906.812500\n",
      "Train Epoch: 99 [80/17352 (0%)] Loss: -205935.375000\n",
      "Train Epoch: 99 [160/17352 (1%)] Loss: -204361.734375\n",
      "Train Epoch: 99 [240/17352 (1%)] Loss: -204035.671875\n",
      "Train Epoch: 99 [320/17352 (2%)] Loss: -210523.078125\n",
      "Train Epoch: 99 [400/17352 (2%)] Loss: -228019.234375\n",
      "Train Epoch: 99 [480/17352 (3%)] Loss: -214522.921875\n",
      "Train Epoch: 99 [560/17352 (3%)] Loss: -216106.640625\n",
      "Train Epoch: 99 [640/17352 (4%)] Loss: -214713.406250\n",
      "Train Epoch: 99 [720/17352 (4%)] Loss: -231326.953125\n",
      "Train Epoch: 99 [800/17352 (5%)] Loss: -219202.531250\n",
      "Train Epoch: 99 [880/17352 (5%)] Loss: -205084.515625\n",
      "Train Epoch: 99 [960/17352 (6%)] Loss: -212655.593750\n",
      "Train Epoch: 99 [1040/17352 (6%)] Loss: -216085.484375\n",
      "Train Epoch: 99 [1120/17352 (6%)] Loss: -214457.109375\n",
      "Train Epoch: 99 [1200/17352 (7%)] Loss: -198766.687500\n",
      "Train Epoch: 99 [1280/17352 (7%)] Loss: -233743.968750\n",
      "Train Epoch: 99 [1360/17352 (8%)] Loss: -212188.359375\n",
      "Train Epoch: 99 [1440/17352 (8%)] Loss: -182782.437500\n",
      "Train Epoch: 99 [1520/17352 (9%)] Loss: -230193.984375\n",
      "Train Epoch: 99 [1600/17352 (9%)] Loss: -209639.921875\n",
      "Train Epoch: 99 [1680/17352 (10%)] Loss: -214337.031250\n",
      "Train Epoch: 99 [1760/17352 (10%)] Loss: -196445.031250\n",
      "Train Epoch: 99 [1840/17352 (11%)] Loss: -211106.000000\n",
      "Train Epoch: 99 [1920/17352 (11%)] Loss: -198116.406250\n",
      "Train Epoch: 99 [2000/17352 (12%)] Loss: -205199.187500\n",
      "Train Epoch: 99 [2080/17352 (12%)] Loss: -202231.750000\n",
      "Train Epoch: 99 [2160/17352 (12%)] Loss: -236519.515625\n",
      "Train Epoch: 99 [2240/17352 (13%)] Loss: -178317.406250\n",
      "Train Epoch: 99 [2320/17352 (13%)] Loss: -170238.343750\n",
      "Train Epoch: 99 [2400/17352 (14%)] Loss: -167243.453125\n",
      "Train Epoch: 99 [2480/17352 (14%)] Loss: -195840.781250\n",
      "Train Epoch: 99 [2560/17352 (15%)] Loss: -169507.546875\n",
      "Train Epoch: 99 [2640/17352 (15%)] Loss: -181337.078125\n",
      "Train Epoch: 99 [2720/17352 (16%)] Loss: -189269.640625\n",
      "Train Epoch: 99 [2800/17352 (16%)] Loss: -171544.109375\n",
      "Train Epoch: 99 [2880/17352 (17%)] Loss: -179453.546875\n",
      "Train Epoch: 99 [2960/17352 (17%)] Loss: -178573.734375\n",
      "Train Epoch: 99 [3040/17352 (18%)] Loss: -187888.109375\n",
      "Train Epoch: 99 [3120/17352 (18%)] Loss: -134534.375000\n",
      "Train Epoch: 99 [3200/17352 (18%)] Loss: -201308.421875\n",
      "Train Epoch: 99 [3280/17352 (19%)] Loss: -182564.140625\n",
      "Train Epoch: 99 [3360/17352 (19%)] Loss: -192012.750000\n",
      "Train Epoch: 99 [3440/17352 (20%)] Loss: -183724.875000\n",
      "Train Epoch: 99 [3520/17352 (20%)] Loss: -171313.531250\n",
      "Train Epoch: 99 [3600/17352 (21%)] Loss: -189171.109375\n",
      "Train Epoch: 99 [3680/17352 (21%)] Loss: -174950.609375\n",
      "Train Epoch: 99 [3760/17352 (22%)] Loss: -183874.546875\n",
      "Train Epoch: 99 [3840/17352 (22%)] Loss: -205693.468750\n",
      "Train Epoch: 99 [3920/17352 (23%)] Loss: -201036.593750\n",
      "Train Epoch: 99 [4000/17352 (23%)] Loss: -180256.687500\n",
      "Train Epoch: 99 [4080/17352 (24%)] Loss: -161518.359375\n",
      "Train Epoch: 99 [4160/17352 (24%)] Loss: -195056.078125\n",
      "Train Epoch: 99 [4240/17352 (24%)] Loss: -182742.015625\n",
      "Train Epoch: 99 [4320/17352 (25%)] Loss: -200271.640625\n",
      "Train Epoch: 99 [4400/17352 (25%)] Loss: -185541.406250\n",
      "Train Epoch: 99 [4480/17352 (26%)] Loss: -182532.312500\n",
      "Train Epoch: 99 [4560/17352 (26%)] Loss: -204700.046875\n",
      "Train Epoch: 99 [4640/17352 (27%)] Loss: -175601.234375\n",
      "Train Epoch: 99 [4720/17352 (27%)] Loss: -195003.390625\n",
      "Train Epoch: 99 [4800/17352 (28%)] Loss: -215465.015625\n",
      "Train Epoch: 99 [4880/17352 (28%)] Loss: -180697.796875\n",
      "Train Epoch: 99 [4960/17352 (29%)] Loss: -164880.765625\n",
      "Train Epoch: 99 [5040/17352 (29%)] Loss: -164079.140625\n",
      "Train Epoch: 99 [5120/17352 (30%)] Loss: -224865.453125\n",
      "Train Epoch: 99 [5200/17352 (30%)] Loss: -167298.578125\n",
      "Train Epoch: 99 [5280/17352 (30%)] Loss: -201322.156250\n",
      "Train Epoch: 99 [5360/17352 (31%)] Loss: -191633.343750\n",
      "Train Epoch: 99 [5440/17352 (31%)] Loss: -163964.781250\n",
      "Train Epoch: 99 [5520/17352 (32%)] Loss: -173367.859375\n",
      "Train Epoch: 99 [5600/17352 (32%)] Loss: -169616.953125\n",
      "Train Epoch: 99 [5680/17352 (33%)] Loss: -184951.593750\n",
      "Train Epoch: 99 [5760/17352 (33%)] Loss: -159313.937500\n",
      "Train Epoch: 99 [5840/17352 (34%)] Loss: -185930.046875\n",
      "Train Epoch: 99 [5920/17352 (34%)] Loss: -158256.078125\n",
      "Train Epoch: 99 [6000/17352 (35%)] Loss: -170677.250000\n",
      "Train Epoch: 99 [6080/17352 (35%)] Loss: -166676.500000\n",
      "Train Epoch: 99 [6160/17352 (36%)] Loss: -177772.078125\n",
      "Train Epoch: 99 [6240/17352 (36%)] Loss: -188502.281250\n",
      "Train Epoch: 99 [6320/17352 (36%)] Loss: -159699.359375\n",
      "Train Epoch: 99 [6400/17352 (37%)] Loss: -206209.359375\n",
      "Train Epoch: 99 [6480/17352 (37%)] Loss: -189574.500000\n",
      "Train Epoch: 99 [6560/17352 (38%)] Loss: -151223.343750\n",
      "Train Epoch: 99 [6640/17352 (38%)] Loss: -188451.250000\n",
      "Train Epoch: 99 [6720/17352 (39%)] Loss: -173310.828125\n",
      "Train Epoch: 99 [6800/17352 (39%)] Loss: -169950.828125\n",
      "Train Epoch: 99 [6880/17352 (40%)] Loss: -173002.328125\n",
      "Train Epoch: 99 [6960/17352 (40%)] Loss: -195297.000000\n",
      "Train Epoch: 99 [7040/17352 (41%)] Loss: -179480.406250\n",
      "Train Epoch: 99 [7120/17352 (41%)] Loss: -196863.937500\n",
      "Train Epoch: 99 [7200/17352 (41%)] Loss: -192127.343750\n",
      "Train Epoch: 99 [7280/17352 (42%)] Loss: -202478.296875\n",
      "Train Epoch: 99 [7360/17352 (42%)] Loss: -165394.406250\n",
      "Train Epoch: 99 [7440/17352 (43%)] Loss: -183965.218750\n",
      "Train Epoch: 99 [7520/17352 (43%)] Loss: -172967.156250\n",
      "Train Epoch: 99 [7600/17352 (44%)] Loss: -206359.250000\n",
      "Train Epoch: 99 [7680/17352 (44%)] Loss: -202020.265625\n",
      "Train Epoch: 99 [7760/17352 (45%)] Loss: -182921.640625\n",
      "Train Epoch: 99 [7840/17352 (45%)] Loss: -161097.187500\n",
      "Train Epoch: 99 [7920/17352 (46%)] Loss: -165765.734375\n",
      "Train Epoch: 99 [8000/17352 (46%)] Loss: -185293.578125\n",
      "Train Epoch: 99 [8080/17352 (47%)] Loss: -165810.812500\n",
      "Train Epoch: 99 [8160/17352 (47%)] Loss: -192112.062500\n",
      "Train Epoch: 99 [8240/17352 (47%)] Loss: -206224.421875\n",
      "Train Epoch: 99 [8320/17352 (48%)] Loss: -201265.875000\n",
      "Train Epoch: 99 [8400/17352 (48%)] Loss: -181073.671875\n",
      "Train Epoch: 99 [8480/17352 (49%)] Loss: -175366.984375\n",
      "Train Epoch: 99 [8560/17352 (49%)] Loss: -192119.703125\n",
      "Train Epoch: 99 [8640/17352 (50%)] Loss: -156611.500000\n",
      "Train Epoch: 99 [8720/17352 (50%)] Loss: -228155.515625\n",
      "Train Epoch: 99 [8800/17352 (51%)] Loss: -179974.187500\n",
      "Train Epoch: 99 [8880/17352 (51%)] Loss: -166787.671875\n",
      "Train Epoch: 99 [8960/17352 (52%)] Loss: -197959.250000\n",
      "Train Epoch: 99 [9040/17352 (52%)] Loss: -196949.250000\n",
      "Train Epoch: 99 [9120/17352 (53%)] Loss: -197307.937500\n",
      "Train Epoch: 99 [9200/17352 (53%)] Loss: -179925.796875\n",
      "Train Epoch: 99 [9280/17352 (53%)] Loss: -154610.421875\n",
      "Train Epoch: 99 [9360/17352 (54%)] Loss: -165866.343750\n",
      "Train Epoch: 99 [9440/17352 (54%)] Loss: -205025.359375\n",
      "Train Epoch: 99 [9520/17352 (55%)] Loss: -179442.781250\n",
      "Train Epoch: 99 [9600/17352 (55%)] Loss: -193495.953125\n",
      "Train Epoch: 99 [9680/17352 (56%)] Loss: -180754.500000\n",
      "Train Epoch: 99 [9760/17352 (56%)] Loss: -178880.093750\n",
      "Train Epoch: 99 [9840/17352 (57%)] Loss: -194075.546875\n",
      "Train Epoch: 99 [9920/17352 (57%)] Loss: -181619.546875\n",
      "Train Epoch: 99 [10000/17352 (58%)] Loss: -174644.062500\n",
      "Train Epoch: 99 [10080/17352 (58%)] Loss: -223689.609375\n",
      "Train Epoch: 99 [10160/17352 (59%)] Loss: -185338.250000\n",
      "Train Epoch: 99 [10240/17352 (59%)] Loss: -180878.234375\n",
      "Train Epoch: 99 [10320/17352 (59%)] Loss: -180031.687500\n",
      "Train Epoch: 99 [10400/17352 (60%)] Loss: -212905.093750\n",
      "Train Epoch: 99 [10480/17352 (60%)] Loss: -192898.500000\n",
      "Train Epoch: 99 [10560/17352 (61%)] Loss: -192960.750000\n",
      "Train Epoch: 99 [10640/17352 (61%)] Loss: -156480.250000\n",
      "Train Epoch: 99 [10720/17352 (62%)] Loss: -168260.015625\n",
      "Train Epoch: 99 [10800/17352 (62%)] Loss: -215970.890625\n",
      "Train Epoch: 99 [10880/17352 (63%)] Loss: -176151.000000\n",
      "Train Epoch: 99 [10960/17352 (63%)] Loss: -151741.781250\n",
      "Train Epoch: 99 [11040/17352 (64%)] Loss: -203275.265625\n",
      "Train Epoch: 99 [11120/17352 (64%)] Loss: -177195.781250\n",
      "Train Epoch: 99 [11200/17352 (65%)] Loss: -183803.453125\n",
      "Train Epoch: 99 [11280/17352 (65%)] Loss: -201381.265625\n",
      "Train Epoch: 99 [11360/17352 (65%)] Loss: -172240.859375\n",
      "Train Epoch: 99 [11440/17352 (66%)] Loss: -200422.359375\n",
      "Train Epoch: 99 [11520/17352 (66%)] Loss: -187310.828125\n",
      "Train Epoch: 99 [11600/17352 (67%)] Loss: -185368.000000\n",
      "Train Epoch: 99 [11680/17352 (67%)] Loss: -174459.171875\n",
      "Train Epoch: 99 [11760/17352 (68%)] Loss: -198549.453125\n",
      "Train Epoch: 99 [11840/17352 (68%)] Loss: -175214.281250\n",
      "Train Epoch: 99 [11920/17352 (69%)] Loss: -188751.421875\n",
      "Train Epoch: 99 [12000/17352 (69%)] Loss: -175552.828125\n",
      "Train Epoch: 99 [12080/17352 (70%)] Loss: -189027.031250\n",
      "Train Epoch: 99 [12160/17352 (70%)] Loss: -187510.000000\n",
      "Train Epoch: 99 [12240/17352 (71%)] Loss: -220972.281250\n",
      "Train Epoch: 99 [12320/17352 (71%)] Loss: -178731.171875\n",
      "Train Epoch: 99 [12400/17352 (71%)] Loss: -185007.359375\n",
      "Train Epoch: 99 [12480/17352 (72%)] Loss: -176538.203125\n",
      "Train Epoch: 99 [12560/17352 (72%)] Loss: -190940.156250\n",
      "Train Epoch: 99 [12640/17352 (73%)] Loss: -196122.500000\n",
      "Train Epoch: 99 [12720/17352 (73%)] Loss: -193952.609375\n",
      "Train Epoch: 99 [12800/17352 (74%)] Loss: -187127.265625\n",
      "Train Epoch: 99 [12880/17352 (74%)] Loss: -211093.843750\n",
      "Train Epoch: 99 [12960/17352 (75%)] Loss: -157602.921875\n",
      "Train Epoch: 99 [13040/17352 (75%)] Loss: -202580.562500\n",
      "Train Epoch: 99 [13120/17352 (76%)] Loss: -180056.343750\n",
      "Train Epoch: 99 [13200/17352 (76%)] Loss: -184819.953125\n",
      "Train Epoch: 99 [13280/17352 (77%)] Loss: -196197.468750\n",
      "Train Epoch: 99 [13360/17352 (77%)] Loss: -180995.625000\n",
      "Train Epoch: 99 [13440/17352 (77%)] Loss: -192793.046875\n",
      "Train Epoch: 99 [13520/17352 (78%)] Loss: -175074.078125\n",
      "Train Epoch: 99 [13600/17352 (78%)] Loss: -173893.015625\n",
      "Train Epoch: 99 [13680/17352 (79%)] Loss: -164150.203125\n",
      "Train Epoch: 99 [13760/17352 (79%)] Loss: -182778.343750\n",
      "Train Epoch: 99 [13840/17352 (80%)] Loss: -181259.281250\n",
      "Train Epoch: 99 [13920/17352 (80%)] Loss: -218467.750000\n",
      "Train Epoch: 99 [14000/17352 (81%)] Loss: -142339.546875\n",
      "Train Epoch: 99 [14080/17352 (81%)] Loss: -178139.968750\n",
      "Train Epoch: 99 [14160/17352 (82%)] Loss: -162965.078125\n",
      "Train Epoch: 99 [14240/17352 (82%)] Loss: -196249.031250\n",
      "Train Epoch: 99 [14320/17352 (83%)] Loss: -181016.453125\n",
      "Train Epoch: 99 [14400/17352 (83%)] Loss: -231039.031250\n",
      "Train Epoch: 99 [14480/17352 (83%)] Loss: -208758.296875\n",
      "Train Epoch: 99 [14560/17352 (84%)] Loss: -175403.515625\n",
      "Train Epoch: 99 [14640/17352 (84%)] Loss: -192175.859375\n",
      "Train Epoch: 99 [14720/17352 (85%)] Loss: -202985.343750\n",
      "Train Epoch: 99 [14800/17352 (85%)] Loss: -176701.656250\n",
      "Train Epoch: 99 [14880/17352 (86%)] Loss: -201955.312500\n",
      "Train Epoch: 99 [14960/17352 (86%)] Loss: -178662.109375\n",
      "Train Epoch: 99 [15040/17352 (87%)] Loss: -191001.031250\n",
      "Train Epoch: 99 [15120/17352 (87%)] Loss: -171715.484375\n",
      "Train Epoch: 99 [15200/17352 (88%)] Loss: -187404.843750\n",
      "Train Epoch: 99 [15280/17352 (88%)] Loss: -184761.468750\n",
      "Train Epoch: 99 [15360/17352 (89%)] Loss: -209832.390625\n",
      "Train Epoch: 99 [15440/17352 (89%)] Loss: -197603.015625\n",
      "Train Epoch: 99 [15520/17352 (89%)] Loss: -194054.781250\n",
      "Train Epoch: 99 [15600/17352 (90%)] Loss: -195834.625000\n",
      "Train Epoch: 99 [15680/17352 (90%)] Loss: -191888.296875\n",
      "Train Epoch: 99 [15760/17352 (91%)] Loss: -169003.375000\n",
      "Train Epoch: 99 [15840/17352 (91%)] Loss: -148156.843750\n",
      "Train Epoch: 99 [15920/17352 (92%)] Loss: -210269.750000\n",
      "Train Epoch: 99 [16000/17352 (92%)] Loss: -181924.406250\n",
      "Train Epoch: 99 [16080/17352 (93%)] Loss: -164505.484375\n",
      "Train Epoch: 99 [16160/17352 (93%)] Loss: -208429.453125\n",
      "Train Epoch: 99 [16240/17352 (94%)] Loss: -209201.562500\n",
      "Train Epoch: 99 [16320/17352 (94%)] Loss: -173924.578125\n",
      "Train Epoch: 99 [16400/17352 (95%)] Loss: -208012.796875\n",
      "Train Epoch: 99 [16480/17352 (95%)] Loss: -217626.796875\n",
      "Train Epoch: 99 [16560/17352 (95%)] Loss: -208123.421875\n",
      "Train Epoch: 99 [16640/17352 (96%)] Loss: -179315.328125\n",
      "Train Epoch: 99 [16720/17352 (96%)] Loss: -195883.859375\n",
      "Train Epoch: 99 [16800/17352 (97%)] Loss: -196938.171875\n",
      "Train Epoch: 99 [16880/17352 (97%)] Loss: -196454.921875\n",
      "Train Epoch: 99 [16960/17352 (98%)] Loss: -179678.734375\n",
      "Train Epoch: 99 [17040/17352 (98%)] Loss: -177784.609375\n",
      "Train Epoch: 99 [17120/17352 (99%)] Loss: -202085.781250\n",
      "Train Epoch: 99 [17200/17352 (99%)] Loss: -191835.859375\n",
      "Train Epoch: 99 [17280/17352 (100%)] Loss: -197443.343750\n",
      "Train Epoch: 99 [17360/17352 (100%)] Loss: -177193.515625\n",
      "    epoch          : 99\n",
      "    loss           : -189017.7399309551\n",
      "    val_loss       : -23716.063217378\n",
      "Train Epoch: 100 [0/17352 (0%)] Loss: -229233.437500\n",
      "Train Epoch: 100 [80/17352 (0%)] Loss: -196428.734375\n",
      "Train Epoch: 100 [160/17352 (1%)] Loss: -202321.250000\n",
      "Train Epoch: 100 [240/17352 (1%)] Loss: -213340.703125\n",
      "Train Epoch: 100 [320/17352 (2%)] Loss: -236514.078125\n",
      "Train Epoch: 100 [400/17352 (2%)] Loss: -204358.203125\n",
      "Train Epoch: 100 [480/17352 (3%)] Loss: -205557.468750\n",
      "Train Epoch: 100 [560/17352 (3%)] Loss: -241910.359375\n",
      "Train Epoch: 100 [640/17352 (4%)] Loss: -217590.218750\n",
      "Train Epoch: 100 [720/17352 (4%)] Loss: -204741.250000\n",
      "Train Epoch: 100 [800/17352 (5%)] Loss: -204540.890625\n",
      "Train Epoch: 100 [880/17352 (5%)] Loss: -185152.406250\n",
      "Train Epoch: 100 [960/17352 (6%)] Loss: -199110.875000\n",
      "Train Epoch: 100 [1040/17352 (6%)] Loss: -236639.218750\n",
      "Train Epoch: 100 [1120/17352 (6%)] Loss: -193715.125000\n",
      "Train Epoch: 100 [1200/17352 (7%)] Loss: -229962.421875\n",
      "Train Epoch: 100 [1280/17352 (7%)] Loss: -214713.578125\n",
      "Train Epoch: 100 [1360/17352 (8%)] Loss: -206646.593750\n",
      "Train Epoch: 100 [1440/17352 (8%)] Loss: -202038.750000\n",
      "Train Epoch: 100 [1520/17352 (9%)] Loss: -186074.718750\n",
      "Train Epoch: 100 [1600/17352 (9%)] Loss: -209557.671875\n",
      "Train Epoch: 100 [1680/17352 (10%)] Loss: -221478.156250\n",
      "Train Epoch: 100 [1760/17352 (10%)] Loss: -206792.468750\n",
      "Train Epoch: 100 [1840/17352 (11%)] Loss: -188757.390625\n",
      "Train Epoch: 100 [1920/17352 (11%)] Loss: -202274.093750\n",
      "Train Epoch: 100 [2000/17352 (12%)] Loss: -210205.671875\n",
      "Train Epoch: 100 [2080/17352 (12%)] Loss: -199815.625000\n",
      "Train Epoch: 100 [2160/17352 (12%)] Loss: -222513.906250\n",
      "Train Epoch: 100 [2240/17352 (13%)] Loss: -163758.984375\n",
      "Train Epoch: 100 [2320/17352 (13%)] Loss: -179970.953125\n",
      "Train Epoch: 100 [2400/17352 (14%)] Loss: -144992.765625\n",
      "Train Epoch: 100 [2480/17352 (14%)] Loss: -174453.750000\n",
      "Train Epoch: 100 [2560/17352 (15%)] Loss: -180240.328125\n",
      "Train Epoch: 100 [2640/17352 (15%)] Loss: -176879.390625\n",
      "Train Epoch: 100 [2720/17352 (16%)] Loss: -148826.843750\n",
      "Train Epoch: 100 [2800/17352 (16%)] Loss: -203877.953125\n",
      "Train Epoch: 100 [2880/17352 (17%)] Loss: -156997.593750\n",
      "Train Epoch: 100 [2960/17352 (17%)] Loss: -183594.234375\n",
      "Train Epoch: 100 [3040/17352 (18%)] Loss: -168201.468750\n",
      "Train Epoch: 100 [3120/17352 (18%)] Loss: -193365.234375\n",
      "Train Epoch: 100 [3200/17352 (18%)] Loss: -217625.187500\n",
      "Train Epoch: 100 [3280/17352 (19%)] Loss: -195826.109375\n",
      "Train Epoch: 100 [3360/17352 (19%)] Loss: -161685.890625\n",
      "Train Epoch: 100 [3440/17352 (20%)] Loss: -142337.703125\n",
      "Train Epoch: 100 [3520/17352 (20%)] Loss: -165600.921875\n",
      "Train Epoch: 100 [3600/17352 (21%)] Loss: -159696.296875\n",
      "Train Epoch: 100 [3680/17352 (21%)] Loss: -196044.906250\n",
      "Train Epoch: 100 [3760/17352 (22%)] Loss: -168260.312500\n",
      "Train Epoch: 100 [3840/17352 (22%)] Loss: -184275.281250\n",
      "Train Epoch: 100 [3920/17352 (23%)] Loss: -190943.906250\n",
      "Train Epoch: 100 [4000/17352 (23%)] Loss: -165806.500000\n",
      "Train Epoch: 100 [4080/17352 (24%)] Loss: -180055.093750\n",
      "Train Epoch: 100 [4160/17352 (24%)] Loss: -191163.640625\n",
      "Train Epoch: 100 [4240/17352 (24%)] Loss: -188680.468750\n",
      "Train Epoch: 100 [4320/17352 (25%)] Loss: -173665.875000\n",
      "Train Epoch: 100 [4400/17352 (25%)] Loss: -165363.921875\n",
      "Train Epoch: 100 [4480/17352 (26%)] Loss: -192177.015625\n",
      "Train Epoch: 100 [4560/17352 (26%)] Loss: -180514.890625\n",
      "Train Epoch: 100 [4640/17352 (27%)] Loss: -192009.187500\n",
      "Train Epoch: 100 [4720/17352 (27%)] Loss: -191595.203125\n",
      "Train Epoch: 100 [4800/17352 (28%)] Loss: -208312.265625\n",
      "Train Epoch: 100 [4880/17352 (28%)] Loss: -182395.796875\n",
      "Train Epoch: 100 [4960/17352 (29%)] Loss: -170537.937500\n",
      "Train Epoch: 100 [5040/17352 (29%)] Loss: -158613.546875\n",
      "Train Epoch: 100 [5120/17352 (30%)] Loss: -174640.703125\n",
      "Train Epoch: 100 [5200/17352 (30%)] Loss: -180971.593750\n",
      "Train Epoch: 100 [5280/17352 (30%)] Loss: -169980.437500\n",
      "Train Epoch: 100 [5360/17352 (31%)] Loss: -196401.031250\n",
      "Train Epoch: 100 [5440/17352 (31%)] Loss: -203487.234375\n",
      "Train Epoch: 100 [5520/17352 (32%)] Loss: -187132.421875\n",
      "Train Epoch: 100 [5600/17352 (32%)] Loss: -207090.046875\n",
      "Train Epoch: 100 [5680/17352 (33%)] Loss: -187952.906250\n",
      "Train Epoch: 100 [5760/17352 (33%)] Loss: -184760.796875\n",
      "Train Epoch: 100 [5840/17352 (34%)] Loss: -202194.468750\n",
      "Train Epoch: 100 [5920/17352 (34%)] Loss: -169951.203125\n",
      "Train Epoch: 100 [6000/17352 (35%)] Loss: -223966.000000\n",
      "Train Epoch: 100 [6080/17352 (35%)] Loss: -176594.218750\n",
      "Train Epoch: 100 [6160/17352 (36%)] Loss: -213750.437500\n",
      "Train Epoch: 100 [6240/17352 (36%)] Loss: -201957.593750\n",
      "Train Epoch: 100 [6320/17352 (36%)] Loss: -195880.093750\n",
      "Train Epoch: 100 [6400/17352 (37%)] Loss: -166657.921875\n",
      "Train Epoch: 100 [6480/17352 (37%)] Loss: -192237.156250\n",
      "Train Epoch: 100 [6560/17352 (38%)] Loss: -175693.796875\n",
      "Train Epoch: 100 [6640/17352 (38%)] Loss: -182558.875000\n",
      "Train Epoch: 100 [6720/17352 (39%)] Loss: -208132.781250\n",
      "Train Epoch: 100 [6800/17352 (39%)] Loss: -196510.265625\n",
      "Train Epoch: 100 [6880/17352 (40%)] Loss: -218470.578125\n",
      "Train Epoch: 100 [6960/17352 (40%)] Loss: -186043.078125\n",
      "Train Epoch: 100 [7040/17352 (41%)] Loss: -174030.734375\n",
      "Train Epoch: 100 [7120/17352 (41%)] Loss: -193536.968750\n",
      "Train Epoch: 100 [7200/17352 (41%)] Loss: -201934.640625\n",
      "Train Epoch: 100 [7280/17352 (42%)] Loss: -184927.375000\n",
      "Train Epoch: 100 [7360/17352 (42%)] Loss: -205533.062500\n",
      "Train Epoch: 100 [7440/17352 (43%)] Loss: -188812.234375\n",
      "Train Epoch: 100 [7520/17352 (43%)] Loss: -149442.296875\n",
      "Train Epoch: 100 [7600/17352 (44%)] Loss: -178732.421875\n",
      "Train Epoch: 100 [7680/17352 (44%)] Loss: -180700.218750\n",
      "Train Epoch: 100 [7760/17352 (45%)] Loss: -196252.281250\n",
      "Train Epoch: 100 [7840/17352 (45%)] Loss: -171845.406250\n",
      "Train Epoch: 100 [7920/17352 (46%)] Loss: -168768.093750\n",
      "Train Epoch: 100 [8000/17352 (46%)] Loss: -190512.046875\n",
      "Train Epoch: 100 [8080/17352 (47%)] Loss: -207860.421875\n",
      "Train Epoch: 100 [8160/17352 (47%)] Loss: -199415.359375\n",
      "Train Epoch: 100 [8240/17352 (47%)] Loss: -218843.750000\n",
      "Train Epoch: 100 [8320/17352 (48%)] Loss: -192954.093750\n",
      "Train Epoch: 100 [8400/17352 (48%)] Loss: -159674.843750\n",
      "Train Epoch: 100 [8480/17352 (49%)] Loss: -189809.156250\n",
      "Train Epoch: 100 [8560/17352 (49%)] Loss: -190232.468750\n",
      "Train Epoch: 100 [8640/17352 (50%)] Loss: -185365.109375\n",
      "Train Epoch: 100 [8720/17352 (50%)] Loss: -149028.562500\n",
      "Train Epoch: 100 [8800/17352 (51%)] Loss: -185341.968750\n",
      "Train Epoch: 100 [8880/17352 (51%)] Loss: -138337.875000\n",
      "Train Epoch: 100 [8960/17352 (52%)] Loss: -202941.562500\n",
      "Train Epoch: 100 [9040/17352 (52%)] Loss: -204326.078125\n",
      "Train Epoch: 100 [9120/17352 (53%)] Loss: -209591.859375\n",
      "Train Epoch: 100 [9200/17352 (53%)] Loss: -187592.312500\n",
      "Train Epoch: 100 [9280/17352 (53%)] Loss: -179737.484375\n",
      "Train Epoch: 100 [9360/17352 (54%)] Loss: -205217.546875\n",
      "Train Epoch: 100 [9440/17352 (54%)] Loss: -186503.187500\n",
      "Train Epoch: 100 [9520/17352 (55%)] Loss: -208344.562500\n",
      "Train Epoch: 100 [9600/17352 (55%)] Loss: -205692.078125\n",
      "Train Epoch: 100 [9680/17352 (56%)] Loss: -211167.562500\n",
      "Train Epoch: 100 [9760/17352 (56%)] Loss: -183614.906250\n",
      "Train Epoch: 100 [9840/17352 (57%)] Loss: -191806.546875\n",
      "Train Epoch: 100 [9920/17352 (57%)] Loss: -163766.171875\n",
      "Train Epoch: 100 [10000/17352 (58%)] Loss: -183791.125000\n",
      "Train Epoch: 100 [10080/17352 (58%)] Loss: -197443.859375\n",
      "Train Epoch: 100 [10160/17352 (59%)] Loss: -193491.812500\n",
      "Train Epoch: 100 [10240/17352 (59%)] Loss: -204350.718750\n",
      "Train Epoch: 100 [10320/17352 (59%)] Loss: -181758.296875\n",
      "Train Epoch: 100 [10400/17352 (60%)] Loss: -206563.359375\n",
      "Train Epoch: 100 [10480/17352 (60%)] Loss: -167037.140625\n",
      "Train Epoch: 100 [10560/17352 (61%)] Loss: -183287.625000\n",
      "Train Epoch: 100 [10640/17352 (61%)] Loss: -204943.843750\n",
      "Train Epoch: 100 [10720/17352 (62%)] Loss: -195656.015625\n",
      "Train Epoch: 100 [10800/17352 (62%)] Loss: -187795.000000\n",
      "Train Epoch: 100 [10880/17352 (63%)] Loss: -208041.437500\n",
      "Train Epoch: 100 [10960/17352 (63%)] Loss: -203894.593750\n",
      "Train Epoch: 100 [11040/17352 (64%)] Loss: -181983.109375\n",
      "Train Epoch: 100 [11120/17352 (64%)] Loss: -203518.828125\n",
      "Train Epoch: 100 [11200/17352 (65%)] Loss: -206161.953125\n",
      "Train Epoch: 100 [11280/17352 (65%)] Loss: -164830.375000\n",
      "Train Epoch: 100 [11360/17352 (65%)] Loss: -176922.359375\n",
      "Train Epoch: 100 [11440/17352 (66%)] Loss: -201000.687500\n",
      "Train Epoch: 100 [11520/17352 (66%)] Loss: -187509.218750\n",
      "Train Epoch: 100 [11600/17352 (67%)] Loss: -186044.765625\n",
      "Train Epoch: 100 [11680/17352 (67%)] Loss: -191047.015625\n",
      "Train Epoch: 100 [11760/17352 (68%)] Loss: -198807.578125\n",
      "Train Epoch: 100 [11840/17352 (68%)] Loss: -188901.546875\n",
      "Train Epoch: 100 [11920/17352 (69%)] Loss: -199788.500000\n",
      "Train Epoch: 100 [12000/17352 (69%)] Loss: -173582.312500\n",
      "Train Epoch: 100 [12080/17352 (70%)] Loss: -194231.203125\n",
      "Train Epoch: 100 [12160/17352 (70%)] Loss: -187544.140625\n",
      "Train Epoch: 100 [12240/17352 (71%)] Loss: -202992.250000\n",
      "Train Epoch: 100 [12320/17352 (71%)] Loss: -199724.046875\n",
      "Train Epoch: 100 [12400/17352 (71%)] Loss: -199452.562500\n",
      "Train Epoch: 100 [12480/17352 (72%)] Loss: -183613.078125\n",
      "Train Epoch: 100 [12560/17352 (72%)] Loss: -151734.984375\n",
      "Train Epoch: 100 [12640/17352 (73%)] Loss: -180258.812500\n",
      "Train Epoch: 100 [12720/17352 (73%)] Loss: -200423.640625\n",
      "Train Epoch: 100 [12800/17352 (74%)] Loss: -196448.859375\n",
      "Train Epoch: 100 [12880/17352 (74%)] Loss: -191339.812500\n",
      "Train Epoch: 100 [12960/17352 (75%)] Loss: -163963.265625\n",
      "Train Epoch: 100 [13040/17352 (75%)] Loss: -171555.375000\n",
      "Train Epoch: 100 [13120/17352 (76%)] Loss: -231035.406250\n",
      "Train Epoch: 100 [13200/17352 (76%)] Loss: -189796.515625\n",
      "Train Epoch: 100 [13280/17352 (77%)] Loss: -164079.781250\n",
      "Train Epoch: 100 [13360/17352 (77%)] Loss: -178212.750000\n",
      "Train Epoch: 100 [13440/17352 (77%)] Loss: -228157.640625\n",
      "Train Epoch: 100 [13520/17352 (78%)] Loss: -183800.859375\n",
      "Train Epoch: 100 [13600/17352 (78%)] Loss: -165763.156250\n",
      "Train Epoch: 100 [13680/17352 (79%)] Loss: -200624.453125\n",
      "Train Epoch: 100 [13760/17352 (79%)] Loss: -173303.750000\n",
      "Train Epoch: 100 [13840/17352 (80%)] Loss: -166665.218750\n",
      "Train Epoch: 100 [13920/17352 (80%)] Loss: -176704.406250\n",
      "Train Epoch: 100 [14000/17352 (81%)] Loss: -171304.718750\n",
      "Train Epoch: 100 [14080/17352 (81%)] Loss: -183073.656250\n",
      "Train Epoch: 100 [14160/17352 (82%)] Loss: -188276.406250\n",
      "Train Epoch: 100 [14240/17352 (82%)] Loss: -175410.656250\n",
      "Train Epoch: 100 [14320/17352 (83%)] Loss: -197653.578125\n",
      "Train Epoch: 100 [14400/17352 (83%)] Loss: -173366.515625\n",
      "Train Epoch: 100 [14480/17352 (83%)] Loss: -187619.031250\n",
      "Train Epoch: 100 [14560/17352 (84%)] Loss: -203847.968750\n",
      "Train Epoch: 100 [14640/17352 (84%)] Loss: -185934.875000\n",
      "Train Epoch: 100 [14720/17352 (85%)] Loss: -202089.234375\n",
      "Train Epoch: 100 [14800/17352 (85%)] Loss: -190811.437500\n",
      "Train Epoch: 100 [14880/17352 (86%)] Loss: -200634.406250\n",
      "Train Epoch: 100 [14960/17352 (86%)] Loss: -212138.156250\n",
      "Train Epoch: 100 [15040/17352 (87%)] Loss: -187354.593750\n",
      "Train Epoch: 100 [15120/17352 (87%)] Loss: -170113.437500\n",
      "Train Epoch: 100 [15200/17352 (88%)] Loss: -171437.328125\n",
      "Train Epoch: 100 [15280/17352 (88%)] Loss: -192961.000000\n",
      "Train Epoch: 100 [15360/17352 (89%)] Loss: -172552.453125\n",
      "Train Epoch: 100 [15440/17352 (89%)] Loss: -186726.843750\n",
      "Train Epoch: 100 [15520/17352 (89%)] Loss: -187216.078125\n",
      "Train Epoch: 100 [15600/17352 (90%)] Loss: -205729.875000\n",
      "Train Epoch: 100 [15680/17352 (90%)] Loss: -176711.531250\n",
      "Train Epoch: 100 [15760/17352 (91%)] Loss: -193170.906250\n",
      "Train Epoch: 100 [15840/17352 (91%)] Loss: -200273.968750\n",
      "Train Epoch: 100 [15920/17352 (92%)] Loss: -195787.187500\n",
      "Train Epoch: 100 [16000/17352 (92%)] Loss: -175513.078125\n",
      "Train Epoch: 100 [16080/17352 (93%)] Loss: -201369.109375\n",
      "Train Epoch: 100 [16160/17352 (93%)] Loss: -188052.421875\n",
      "Train Epoch: 100 [16240/17352 (94%)] Loss: -178823.437500\n",
      "Train Epoch: 100 [16320/17352 (94%)] Loss: -197092.468750\n",
      "Train Epoch: 100 [16400/17352 (95%)] Loss: -179451.046875\n",
      "Train Epoch: 100 [16480/17352 (95%)] Loss: -177770.765625\n",
      "Train Epoch: 100 [16560/17352 (95%)] Loss: -185235.421875\n",
      "Train Epoch: 100 [16640/17352 (96%)] Loss: -180645.296875\n",
      "Train Epoch: 100 [16720/17352 (96%)] Loss: -204373.843750\n",
      "Train Epoch: 100 [16800/17352 (97%)] Loss: -210924.828125\n",
      "Train Epoch: 100 [16880/17352 (97%)] Loss: -202310.015625\n",
      "Train Epoch: 100 [16960/17352 (98%)] Loss: -193795.859375\n",
      "Train Epoch: 100 [17040/17352 (98%)] Loss: -180257.921875\n",
      "Train Epoch: 100 [17120/17352 (99%)] Loss: -173845.031250\n",
      "Train Epoch: 100 [17200/17352 (99%)] Loss: -197326.234375\n",
      "Train Epoch: 100 [17280/17352 (100%)] Loss: -181375.953125\n",
      "Train Epoch: 100 [17360/17352 (100%)] Loss: -180695.437500\n",
      "    epoch          : 100\n",
      "    loss           : -189089.16148230725\n",
      "    val_loss       : -23716.501159524694\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0426_184347/checkpoint-epoch100.pth ...\n",
      "Saving current best: model_best.pth ...\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:RoutingCategories] *",
   "language": "python",
   "name": "conda-env-RoutingCategories-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
