{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/categorical_bpl\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = collections.namedtuple('Args', 'config resume device')\n",
    "config = ConfigParser.from_args(Args(config='omniglot_config.json', resume=None, device=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = config.get_logger('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip to data/omniglot-py/images_background.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9664117a5a4e4114ad9d444d5a33b3e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9464212.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data/omniglot-py/images_background.zip to data/omniglot-py\n",
      "Downloading https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_evaluation.zip to data/omniglot-py/images_evaluation.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff397a5c45943f6b9ec95a929463779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6462886.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data/omniglot-py/images_evaluation.zip to data/omniglot-py\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = pyro.optim.ReduceLROnPlateau({\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'optim_args': {\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": 0,\n",
    "        \"amsgrad\": True\n",
    "    },\n",
    "    \"patience\": 50,\n",
    "    \"cooldown\": 25,\n",
    "    \"factor\": 0.1,\n",
    "    \"verbose\": True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, [], optimizer, config=config,\n",
    "                  data_loader=data_loader,\n",
    "                  valid_data_loader=valid_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [512/17352 (3%)] Loss: 1722.337158\n",
      "Train Epoch: 1 [10068/17352 (58%)] Loss: 1082.017423\n",
      "Train Epoch: 1 [16939/17352 (98%)] Loss: 973.377068\n",
      "    epoch          : 1\n",
      "    loss           : 1127.89618291453\n",
      "    val_loss       : 947.8297191672776\n",
      "    val_log_likelihood: -816.1482405239784\n",
      "    val_log_marginal: -893.9770626010408\n",
      "Train Epoch: 2 [512/17352 (3%)] Loss: 970.833618\n",
      "Train Epoch: 2 [10382/17352 (60%)] Loss: 938.529755\n",
      "Train Epoch: 2 [17263/17352 (99%)] Loss: 840.577303\n",
      "    epoch          : 2\n",
      "    loss           : 878.7033057891047\n",
      "    val_loss       : 834.993852410643\n",
      "    val_log_likelihood: -755.2571964150849\n",
      "    val_log_marginal: -798.0746582828151\n",
      "Train Epoch: 3 [512/17352 (3%)] Loss: 868.070679\n",
      "Train Epoch: 3 [10694/17352 (62%)] Loss: 777.743218\n",
      "Train Epoch: 3 [17153/17352 (99%)] Loss: 830.023239\n",
      "    epoch          : 3\n",
      "    loss           : 795.8705032507338\n",
      "    val_loss       : 768.0807685528231\n",
      "    val_log_likelihood: -720.1796183177313\n",
      "    val_log_marginal: -749.5755152858707\n",
      "Train Epoch: 4 [512/17352 (3%)] Loss: 760.022278\n",
      "Train Epoch: 4 [10007/17352 (58%)] Loss: 746.707415\n",
      "Train Epoch: 4 [17049/17352 (98%)] Loss: 762.099136\n",
      "    epoch          : 4\n",
      "    loss           : 753.196764494765\n",
      "    val_loss       : 810.5295439917409\n",
      "    val_log_likelihood: -702.7175579778879\n",
      "    val_log_marginal: -755.7684540345422\n",
      "Train Epoch: 5 [512/17352 (3%)] Loss: 757.423828\n",
      "Train Epoch: 5 [10769/17352 (62%)] Loss: 717.141009\n",
      "Train Epoch: 5 [17126/17352 (99%)] Loss: 700.870587\n",
      "    epoch          : 5\n",
      "    loss           : 724.1981415140814\n",
      "    val_loss       : 726.7423725513229\n",
      "    val_log_likelihood: -674.2403962857754\n",
      "    val_log_marginal: -700.8485534124325\n",
      "Train Epoch: 6 [512/17352 (3%)] Loss: 702.309387\n",
      "Train Epoch: 6 [10226/17352 (59%)] Loss: 687.732608\n",
      "Train Epoch: 6 [16887/17352 (97%)] Loss: 674.696224\n",
      "    epoch          : 6\n",
      "    loss           : 691.6599431685872\n",
      "    val_loss       : 709.5031258671403\n",
      "    val_log_likelihood: -655.3854261596576\n",
      "    val_log_marginal: -676.9768869591435\n",
      "Train Epoch: 7 [512/17352 (3%)] Loss: 674.910461\n",
      "Train Epoch: 7 [10715/17352 (62%)] Loss: 667.859073\n",
      "Train Epoch: 7 [17044/17352 (98%)] Loss: 659.577782\n",
      "    epoch          : 7\n",
      "    loss           : 664.794413064304\n",
      "    val_loss       : 660.100207826493\n",
      "    val_log_likelihood: -636.0010280850336\n",
      "    val_log_marginal: -652.0547306976597\n",
      "Train Epoch: 8 [512/17352 (3%)] Loss: 648.052002\n",
      "Train Epoch: 8 [10595/17352 (61%)] Loss: 641.228981\n",
      "Train Epoch: 8 [17263/17352 (99%)] Loss: 645.118571\n",
      "    epoch          : 8\n",
      "    loss           : 643.7213956272143\n",
      "    val_loss       : 681.8286711384909\n",
      "    val_log_likelihood: -618.5926898100636\n",
      "    val_log_marginal: -659.0512933352371\n",
      "Train Epoch: 9 [512/17352 (3%)] Loss: 638.114868\n",
      "Train Epoch: 9 [10243/17352 (59%)] Loss: 625.972914\n",
      "Train Epoch: 9 [16887/17352 (97%)] Loss: 637.552413\n",
      "    epoch          : 9\n",
      "    loss           : 633.9569343924669\n",
      "    val_loss       : 650.8713956268253\n",
      "    val_log_likelihood: -603.309981105915\n",
      "    val_log_marginal: -628.5161159586477\n",
      "Train Epoch: 10 [512/17352 (3%)] Loss: 620.323730\n",
      "Train Epoch: 10 [10504/17352 (61%)] Loss: 639.464405\n",
      "Train Epoch: 10 [16883/17352 (97%)] Loss: 616.433065\n",
      "    epoch          : 10\n",
      "    loss           : 624.9576775183722\n",
      "    val_loss       : 624.6078675557561\n",
      "    val_log_likelihood: -588.1045864315729\n",
      "    val_log_marginal: -609.8681821473923\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch10.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 11 [512/17352 (3%)] Loss: 602.563110\n",
      "Train Epoch: 11 [9856/17352 (57%)] Loss: 592.381556\n",
      "Train Epoch: 11 [17049/17352 (98%)] Loss: 576.092617\n",
      "    epoch          : 11\n",
      "    loss           : 591.3419521419796\n",
      "    val_loss       : 594.0670635392995\n",
      "    val_log_likelihood: -567.7213614963075\n",
      "    val_log_marginal: -584.215938909303\n",
      "Train Epoch: 12 [512/17352 (3%)] Loss: 580.641235\n",
      "Train Epoch: 12 [9838/17352 (57%)] Loss: 575.538229\n",
      "Train Epoch: 12 [17064/17352 (98%)] Loss: 570.096998\n",
      "    epoch          : 12\n",
      "    loss           : 573.2729013452648\n",
      "    val_loss       : 571.294028928328\n",
      "    val_log_likelihood: -551.5961516227045\n",
      "    val_log_marginal: -564.6066961067924\n",
      "Train Epoch: 13 [512/17352 (3%)] Loss: 561.723816\n",
      "Train Epoch: 13 [10313/17352 (59%)] Loss: 549.585898\n",
      "Train Epoch: 13 [17253/17352 (99%)] Loss: 552.959288\n",
      "    epoch          : 13\n",
      "    loss           : 560.5561040423244\n",
      "    val_loss       : 586.6810739795957\n",
      "    val_log_likelihood: -536.4348818643409\n",
      "    val_log_marginal: -556.4506017641723\n",
      "Train Epoch: 14 [512/17352 (3%)] Loss: 550.175415\n",
      "Train Epoch: 14 [10999/17352 (63%)] Loss: 535.122721\n",
      "Train Epoch: 14 [16992/17352 (98%)] Loss: 530.312972\n",
      "    epoch          : 14\n",
      "    loss           : 542.5864111937311\n",
      "    val_loss       : 539.3606617580876\n",
      "    val_log_likelihood: -519.1640008470343\n",
      "    val_log_marginal: -533.8825982980486\n",
      "Train Epoch: 15 [512/17352 (3%)] Loss: 528.489319\n",
      "Train Epoch: 15 [10563/17352 (61%)] Loss: 528.727083\n",
      "Train Epoch: 15 [17016/17352 (98%)] Loss: 509.958939\n",
      "    epoch          : 15\n",
      "    loss           : 523.7859746825891\n",
      "    val_loss       : 523.3006585943099\n",
      "    val_log_likelihood: -503.6988279615163\n",
      "    val_log_marginal: -518.9511517690989\n",
      "Train Epoch: 16 [512/17352 (3%)] Loss: 515.574219\n",
      "Train Epoch: 16 [10191/17352 (59%)] Loss: 513.618963\n",
      "Train Epoch: 16 [17090/17352 (98%)] Loss: 533.549306\n",
      "    epoch          : 16\n",
      "    loss           : 509.1799969656299\n",
      "    val_loss       : 541.1862527622849\n",
      "    val_log_likelihood: -488.1759249499078\n",
      "    val_log_marginal: -537.0086789481037\n",
      "Train Epoch: 17 [512/17352 (3%)] Loss: 532.557983\n",
      "Train Epoch: 17 [10427/17352 (60%)] Loss: 495.973001\n",
      "Train Epoch: 17 [16957/17352 (98%)] Loss: 510.358703\n",
      "    epoch          : 17\n",
      "    loss           : 498.9608133854118\n",
      "    val_loss       : 496.363919355396\n",
      "    val_log_likelihood: -471.3560347109812\n",
      "    val_log_marginal: -494.4548543644139\n",
      "Train Epoch: 18 [512/17352 (3%)] Loss: 492.630798\n",
      "Train Epoch: 18 [10135/17352 (58%)] Loss: 488.735272\n",
      "Train Epoch: 18 [17335/17352 (100%)] Loss: 482.746597\n",
      "    epoch          : 18\n",
      "    loss           : 476.90053192545747\n",
      "    val_loss       : 481.0312738746358\n",
      "    val_log_likelihood: -455.2986352944634\n",
      "    val_log_marginal: -472.53321917827\n",
      "Train Epoch: 19 [512/17352 (3%)] Loss: 467.311646\n",
      "Train Epoch: 19 [10251/17352 (59%)] Loss: 456.896298\n",
      "Train Epoch: 19 [16922/17352 (98%)] Loss: 480.631915\n",
      "    epoch          : 19\n",
      "    loss           : 460.5667627913102\n",
      "    val_loss       : 455.6881035546791\n",
      "    val_log_likelihood: -439.5221023948021\n",
      "    val_log_marginal: -450.6796714881916\n",
      "Train Epoch: 20 [512/17352 (3%)] Loss: 448.783630\n",
      "Train Epoch: 20 [10151/17352 (59%)] Loss: 442.544902\n",
      "Train Epoch: 20 [16872/17352 (97%)] Loss: 431.507059\n",
      "    epoch          : 20\n",
      "    loss           : 445.16363555804634\n",
      "    val_loss       : 440.23618973676923\n",
      "    val_log_likelihood: -421.6008604428832\n",
      "    val_log_marginal: -435.11132905999096\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch20.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 21 [512/17352 (3%)] Loss: 433.261688\n",
      "Train Epoch: 21 [10491/17352 (60%)] Loss: 414.616319\n",
      "Train Epoch: 21 [17126/17352 (99%)] Loss: 412.965257\n",
      "    epoch          : 21\n",
      "    loss           : 427.1931548548305\n",
      "    val_loss       : 424.6131358314043\n",
      "    val_log_likelihood: -405.263509544721\n",
      "    val_log_marginal: -420.92689851333586\n",
      "Train Epoch: 22 [512/17352 (3%)] Loss: 416.811981\n",
      "Train Epoch: 22 [9965/17352 (57%)] Loss: 396.508599\n",
      "Train Epoch: 22 [16878/17352 (97%)] Loss: 411.139152\n",
      "    epoch          : 22\n",
      "    loss           : 411.3413024877831\n",
      "    val_loss       : 405.11840189679697\n",
      "    val_log_likelihood: -388.98987620310896\n",
      "    val_log_marginal: -402.7516677323052\n",
      "Train Epoch: 23 [512/17352 (3%)] Loss: 398.527832\n",
      "Train Epoch: 23 [10405/17352 (60%)] Loss: 404.770036\n",
      "Train Epoch: 23 [17133/17352 (99%)] Loss: 382.813045\n",
      "    epoch          : 23\n",
      "    loss           : 393.45118877930935\n",
      "    val_loss       : 393.3041864557458\n",
      "    val_log_likelihood: -373.3795093396121\n",
      "    val_log_marginal: -389.48645640608373\n",
      "Train Epoch: 24 [512/17352 (3%)] Loss: 385.712708\n",
      "Train Epoch: 24 [9762/17352 (56%)] Loss: 390.649846\n",
      "Train Epoch: 24 [17106/17352 (99%)] Loss: 377.487078\n",
      "    epoch          : 24\n",
      "    loss           : 381.25282033483325\n",
      "    val_loss       : 392.4611566574325\n",
      "    val_log_likelihood: -360.10766654206986\n",
      "    val_log_marginal: -387.2175986526405\n",
      "Train Epoch: 25 [512/17352 (3%)] Loss: 382.590057\n",
      "Train Epoch: 25 [9896/17352 (57%)] Loss: 384.698340\n",
      "Train Epoch: 25 [16922/17352 (98%)] Loss: 348.736280\n",
      "    epoch          : 25\n",
      "    loss           : 368.3983326486816\n",
      "    val_loss       : 364.6805066609127\n",
      "    val_log_likelihood: -343.58451248731154\n",
      "    val_log_marginal: -360.7240486820126\n",
      "Train Epoch: 26 [512/17352 (3%)] Loss: 358.432648\n",
      "Train Epoch: 26 [10526/17352 (61%)] Loss: 350.704892\n",
      "Train Epoch: 26 [17101/17352 (99%)] Loss: 364.671950\n",
      "    epoch          : 26\n",
      "    loss           : 349.6566978123985\n",
      "    val_loss       : 343.36221149670143\n",
      "    val_log_likelihood: -325.1427439144546\n",
      "    val_log_marginal: -340.5677532043845\n",
      "Train Epoch: 27 [512/17352 (3%)] Loss: 338.205078\n",
      "Train Epoch: 27 [9710/17352 (56%)] Loss: 352.254564\n",
      "Train Epoch: 27 [17108/17352 (99%)] Loss: 343.184136\n",
      "    epoch          : 27\n",
      "    loss           : 333.30564101038345\n",
      "    val_loss       : 328.93557913827374\n",
      "    val_log_likelihood: -311.66059622490883\n",
      "    val_log_marginal: -325.9625768060606\n",
      "Train Epoch: 28 [512/17352 (3%)] Loss: 324.337769\n",
      "Train Epoch: 28 [9917/17352 (57%)] Loss: 330.672783\n",
      "Train Epoch: 28 [16958/17352 (98%)] Loss: 315.994212\n",
      "    epoch          : 28\n",
      "    loss           : 324.61928576373344\n",
      "    val_loss       : 335.28011916268053\n",
      "    val_log_likelihood: -297.60826334019544\n",
      "    val_log_marginal: -330.63173632760635\n",
      "Train Epoch: 29 [512/17352 (3%)] Loss: 328.068085\n",
      "Train Epoch: 29 [10190/17352 (59%)] Loss: 310.671894\n",
      "Train Epoch: 29 [16992/17352 (98%)] Loss: 293.890085\n",
      "    epoch          : 29\n",
      "    loss           : 317.6639244980688\n",
      "    val_loss       : 306.6652997639276\n",
      "    val_log_likelihood: -283.1956688583418\n",
      "    val_log_marginal: -301.3284049591517\n",
      "Train Epoch: 30 [512/17352 (3%)] Loss: 302.473999\n",
      "Train Epoch: 30 [10295/17352 (59%)] Loss: 321.673522\n",
      "Train Epoch: 30 [16992/17352 (98%)] Loss: 282.554352\n",
      "    epoch          : 30\n",
      "    loss           : 295.6290754760927\n",
      "    val_loss       : 289.7675971947381\n",
      "    val_log_likelihood: -269.0411448549226\n",
      "    val_log_marginal: -286.26652928658683\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch30.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 31 [512/17352 (3%)] Loss: 281.674652\n",
      "Train Epoch: 31 [10667/17352 (61%)] Loss: 273.013623\n",
      "Train Epoch: 31 [17044/17352 (98%)] Loss: 274.081362\n",
      "    epoch          : 31\n",
      "    loss           : 280.4733111841577\n",
      "    val_loss       : 278.49408461372894\n",
      "    val_log_likelihood: -254.67473549918765\n",
      "    val_log_marginal: -273.8776547625869\n",
      "Train Epoch: 32 [512/17352 (3%)] Loss: 271.169556\n",
      "Train Epoch: 32 [10581/17352 (61%)] Loss: 277.254043\n",
      "Train Epoch: 32 [16958/17352 (98%)] Loss: 235.378348\n",
      "    epoch          : 32\n",
      "    loss           : 266.66682347051324\n",
      "    val_loss       : 267.10291367410605\n",
      "    val_log_likelihood: -242.71541056739906\n",
      "    val_log_marginal: -264.07789416287403\n",
      "Train Epoch: 33 [512/17352 (3%)] Loss: 260.987030\n",
      "Train Epoch: 33 [10075/17352 (58%)] Loss: 228.836920\n",
      "Train Epoch: 33 [17126/17352 (99%)] Loss: 257.688216\n",
      "    epoch          : 33\n",
      "    loss           : 256.1732886454988\n",
      "    val_loss       : 257.795414533439\n",
      "    val_log_likelihood: -230.87290888712408\n",
      "    val_log_marginal: -254.51548919900898\n",
      "Train Epoch: 34 [512/17352 (3%)] Loss: 254.385010\n",
      "Train Epoch: 34 [10108/17352 (58%)] Loss: 228.933177\n",
      "Train Epoch: 34 [16883/17352 (97%)] Loss: 255.637952\n",
      "    epoch          : 34\n",
      "    loss           : 243.0142701649357\n",
      "    val_loss       : 241.03925467076618\n",
      "    val_log_likelihood: -216.02309457839192\n",
      "    val_log_marginal: -236.1750579310627\n",
      "Train Epoch: 35 [512/17352 (3%)] Loss: 229.447266\n",
      "Train Epoch: 35 [10108/17352 (58%)] Loss: 198.064860\n",
      "Train Epoch: 35 [17108/17352 (99%)] Loss: 229.150162\n",
      "    epoch          : 35\n",
      "    loss           : 230.67852482079158\n",
      "    val_loss       : 235.93209456090483\n",
      "    val_log_likelihood: -205.44821641139615\n",
      "    val_log_marginal: -231.39294378523581\n",
      "Train Epoch: 36 [512/17352 (3%)] Loss: 227.978790\n",
      "Train Epoch: 36 [10298/17352 (59%)] Loss: 217.020716\n",
      "Train Epoch: 36 [16957/17352 (98%)] Loss: 190.852277\n",
      "    epoch          : 36\n",
      "    loss           : 216.97495948061479\n",
      "    val_loss       : 216.98842937870924\n",
      "    val_log_likelihood: -189.8047317747777\n",
      "    val_log_marginal: -209.60011188706108\n",
      "Train Epoch: 37 [512/17352 (3%)] Loss: 206.496170\n",
      "Train Epoch: 37 [10429/17352 (60%)] Loss: 183.555798\n",
      "Train Epoch: 37 [17143/17352 (99%)] Loss: 172.493273\n",
      "    epoch          : 37\n",
      "    loss           : 205.0082456054097\n",
      "    val_loss       : 212.73984387198772\n",
      "    val_log_likelihood: -174.36195128839788\n",
      "    val_log_marginal: -204.2511281791726\n",
      "Train Epoch: 38 [512/17352 (3%)] Loss: 204.065552\n",
      "Train Epoch: 38 [10365/17352 (60%)] Loss: 219.817915\n",
      "Train Epoch: 38 [17133/17352 (99%)] Loss: 182.224818\n",
      "    epoch          : 38\n",
      "    loss           : 193.34864749525553\n",
      "    val_loss       : 189.8132135809343\n",
      "    val_log_likelihood: -157.7809358184218\n",
      "    val_log_marginal: -183.89739674741617\n",
      "Train Epoch: 39 [512/17352 (3%)] Loss: 183.963913\n",
      "Train Epoch: 39 [10420/17352 (60%)] Loss: 178.010769\n",
      "Train Epoch: 39 [16922/17352 (98%)] Loss: 201.885345\n",
      "    epoch          : 39\n",
      "    loss           : 184.66200570388517\n",
      "    val_loss       : 198.66083055327903\n",
      "    val_log_likelihood: -154.7630549061381\n",
      "    val_log_marginal: -191.9204201943393\n",
      "Train Epoch: 40 [512/17352 (3%)] Loss: 188.583679\n",
      "Train Epoch: 40 [10017/17352 (58%)] Loss: 178.128548\n",
      "Train Epoch: 40 [16992/17352 (98%)] Loss: 178.097817\n",
      "    epoch          : 40\n",
      "    loss           : 179.15326472938287\n",
      "    val_loss       : 171.17572968287\n",
      "    val_log_likelihood: -139.93068035550016\n",
      "    val_log_marginal: -165.5624914175457\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch40.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 41 [512/17352 (3%)] Loss: 157.143341\n",
      "Train Epoch: 41 [10705/17352 (62%)] Loss: 142.973883\n",
      "Train Epoch: 41 [16988/17352 (98%)] Loss: 178.302703\n",
      "    epoch          : 41\n",
      "    loss           : 161.02221259551814\n",
      "    val_loss       : 166.1647936865441\n",
      "    val_log_likelihood: -125.85676596303398\n",
      "    val_log_marginal: -158.48514993584112\n",
      "Train Epoch: 42 [512/17352 (3%)] Loss: 151.924545\n",
      "Train Epoch: 42 [10394/17352 (60%)] Loss: 157.151313\n",
      "Train Epoch: 42 [17049/17352 (98%)] Loss: 170.580270\n",
      "    epoch          : 42\n",
      "    loss           : 153.7566844829303\n",
      "    val_loss       : 150.96022291187893\n",
      "    val_log_likelihood: -116.61475689625432\n",
      "    val_log_marginal: -144.96125095637208\n",
      "Train Epoch: 43 [512/17352 (3%)] Loss: 137.334595\n",
      "Train Epoch: 43 [10404/17352 (60%)] Loss: 171.613749\n",
      "Train Epoch: 43 [17153/17352 (99%)] Loss: 134.592135\n",
      "    epoch          : 43\n",
      "    loss           : 145.8784735197658\n",
      "    val_loss       : 150.1781082561326\n",
      "    val_log_likelihood: -105.5814344406461\n",
      "    val_log_marginal: -145.09139718778079\n",
      "Train Epoch: 44 [512/17352 (3%)] Loss: 138.567032\n",
      "Train Epoch: 44 [10269/17352 (59%)] Loss: 158.056161\n",
      "Train Epoch: 44 [17335/17352 (100%)] Loss: 126.281293\n",
      "    epoch          : 44\n",
      "    loss           : 135.4738526317421\n",
      "    val_loss       : 142.6077159168812\n",
      "    val_log_likelihood: -99.13381159609357\n",
      "    val_log_marginal: -137.70233947247277\n",
      "Train Epoch: 45 [512/17352 (3%)] Loss: 130.132080\n",
      "Train Epoch: 45 [9592/17352 (55%)] Loss: 144.987780\n",
      "Train Epoch: 45 [17049/17352 (98%)] Loss: 117.121102\n",
      "    epoch          : 45\n",
      "    loss           : 123.81283782061674\n",
      "    val_loss       : 126.43522438451075\n",
      "    val_log_likelihood: -83.76345390645632\n",
      "    val_log_marginal: -120.27976566591386\n",
      "Train Epoch: 46 [512/17352 (3%)] Loss: 113.943428\n",
      "Train Epoch: 46 [10913/17352 (63%)] Loss: 101.506348\n",
      "Train Epoch: 46 [17277/17352 (100%)] Loss: 86.530681\n",
      "    epoch          : 46\n",
      "    loss           : 112.9468927024989\n",
      "    val_loss       : 123.84596456608742\n",
      "    val_log_likelihood: -74.26024347857205\n",
      "    val_log_marginal: -116.3484977832872\n",
      "Train Epoch: 47 [512/17352 (3%)] Loss: 111.579475\n",
      "Train Epoch: 47 [10264/17352 (59%)] Loss: 79.976538\n",
      "Train Epoch: 47 [17143/17352 (99%)] Loss: 97.941900\n",
      "    epoch          : 47\n",
      "    loss           : 104.46625646811773\n",
      "    val_loss       : 114.8388582253693\n",
      "    val_log_likelihood: -63.71898419265367\n",
      "    val_log_marginal: -110.20291686417166\n",
      "Train Epoch: 48 [512/17352 (3%)] Loss: 101.524040\n",
      "Train Epoch: 48 [10189/17352 (59%)] Loss: 73.392971\n",
      "Train Epoch: 48 [17253/17352 (99%)] Loss: 129.021725\n",
      "    epoch          : 48\n",
      "    loss           : 98.3279782080596\n",
      "    val_loss       : 108.74280498548873\n",
      "    val_log_likelihood: -57.50790090738812\n",
      "    val_log_marginal: -103.5327875728886\n",
      "Train Epoch: 49 [512/17352 (3%)] Loss: 98.045990\n",
      "Train Epoch: 49 [10375/17352 (60%)] Loss: 85.528705\n",
      "Train Epoch: 49 [17153/17352 (99%)] Loss: 101.620771\n",
      "    epoch          : 49\n",
      "    loss           : 90.81606231316427\n",
      "    val_loss       : 112.91422194815065\n",
      "    val_log_likelihood: -52.31235899688625\n",
      "    val_log_marginal: -105.75622994754175\n",
      "Train Epoch: 50 [512/17352 (3%)] Loss: 103.021103\n",
      "Train Epoch: 50 [10743/17352 (62%)] Loss: 31.773220\n",
      "Train Epoch: 50 [17049/17352 (98%)] Loss: 99.207281\n",
      "    epoch          : 50\n",
      "    loss           : 81.78775595598367\n",
      "    val_loss       : 81.15005928419585\n",
      "    val_log_likelihood: -35.70946079178286\n",
      "    val_log_marginal: -75.769092682153\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch50.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 51 [512/17352 (3%)] Loss: 71.166458\n",
      "Train Epoch: 51 [10471/17352 (60%)] Loss: 66.653192\n",
      "Train Epoch: 51 [17263/17352 (99%)] Loss: 65.105364\n",
      "    epoch          : 51\n",
      "    loss           : 74.57902383848878\n",
      "    val_loss       : 96.82638275216677\n",
      "    val_log_likelihood: -28.340263924755654\n",
      "    val_log_marginal: -90.04094440856882\n",
      "Train Epoch: 52 [512/17352 (3%)] Loss: 88.619179\n",
      "Train Epoch: 52 [10466/17352 (60%)] Loss: 54.318382\n",
      "Train Epoch: 52 [16922/17352 (98%)] Loss: 47.358887\n",
      "    epoch          : 52\n",
      "    loss           : 70.40034559576479\n",
      "    val_loss       : 61.703693105427895\n",
      "    val_log_likelihood: -20.48187081236185\n",
      "    val_log_marginal: -55.34090216900623\n",
      "Train Epoch: 53 [512/17352 (3%)] Loss: 52.740414\n",
      "Train Epoch: 53 [10416/17352 (60%)] Loss: 25.912134\n",
      "Train Epoch: 53 [17133/17352 (99%)] Loss: 39.933635\n",
      "    epoch          : 53\n",
      "    loss           : 54.55442760974878\n",
      "    val_loss       : 72.46309363640138\n",
      "    val_log_likelihood: -13.935089957795489\n",
      "    val_log_marginal: -64.49038295098443\n",
      "Train Epoch: 54 [512/17352 (3%)] Loss: 66.304321\n",
      "Train Epoch: 54 [9728/17352 (56%)] Loss: 102.589817\n",
      "Train Epoch: 54 [17016/17352 (98%)] Loss: 76.782080\n",
      "    epoch          : 54\n",
      "    loss           : 93.26316304716389\n",
      "    val_loss       : 91.91254276650723\n",
      "    val_log_likelihood: -33.28923580682177\n",
      "    val_log_marginal: -85.56486582461935\n",
      "Train Epoch: 55 [512/17352 (3%)] Loss: 76.716049\n",
      "Train Epoch: 55 [10093/17352 (58%)] Loss: 35.430830\n",
      "Train Epoch: 55 [17016/17352 (98%)] Loss: 68.232734\n",
      "    epoch          : 55\n",
      "    loss           : 67.09354228470643\n",
      "    val_loss       : 52.72367987870717\n",
      "    val_log_likelihood: -1.614070042024777\n",
      "    val_log_marginal: -45.93860646618891\n",
      "Train Epoch: 56 [512/17352 (3%)] Loss: 48.125336\n",
      "Train Epoch: 56 [10215/17352 (59%)] Loss: 59.246039\n",
      "Train Epoch: 56 [17064/17352 (98%)] Loss: 28.731519\n",
      "    epoch          : 56\n",
      "    loss           : 42.767933702949925\n",
      "    val_loss       : 47.43459975565296\n",
      "    val_log_likelihood: 8.384990278147418\n",
      "    val_log_marginal: -39.65190608583045\n",
      "Train Epoch: 57 [512/17352 (3%)] Loss: 32.121342\n",
      "Train Epoch: 57 [9851/17352 (57%)] Loss: 5.559149\n",
      "Train Epoch: 57 [17126/17352 (99%)] Loss: 28.363169\n",
      "    epoch          : 57\n",
      "    loss           : 33.030665389090466\n",
      "    val_loss       : 38.30974147314522\n",
      "    val_log_likelihood: 20.155717268676167\n",
      "    val_log_marginal: -31.023362751579917\n",
      "Train Epoch: 58 [512/17352 (3%)] Loss: 18.093872\n",
      "Train Epoch: 58 [10257/17352 (59%)] Loss: -4.623293\n",
      "Train Epoch: 58 [17126/17352 (99%)] Loss: 41.701300\n",
      "    epoch          : 58\n",
      "    loss           : 23.3622303771461\n",
      "    val_loss       : 26.07981477095771\n",
      "    val_log_likelihood: 29.100813000384008\n",
      "    val_log_marginal: -19.974833431119656\n",
      "Train Epoch: 59 [512/17352 (3%)] Loss: 8.258860\n",
      "Train Epoch: 59 [10426/17352 (60%)] Loss: -17.922339\n",
      "Train Epoch: 59 [16887/17352 (97%)] Loss: -17.089299\n",
      "    epoch          : 59\n",
      "    loss           : 16.022053188016184\n",
      "    val_loss       : 20.209899680507522\n",
      "    val_log_likelihood: 42.13016735655826\n",
      "    val_log_marginal: -13.224905815625805\n",
      "Train Epoch: 60 [512/17352 (3%)] Loss: 1.049951\n",
      "Train Epoch: 60 [10639/17352 (61%)] Loss: 72.809397\n",
      "Train Epoch: 60 [17106/17352 (99%)] Loss: 5.799704\n",
      "    epoch          : 60\n",
      "    loss           : 32.153448558430455\n",
      "    val_loss       : 216.90195582710538\n",
      "    val_log_likelihood: 42.904894350404064\n",
      "    val_log_marginal: -208.51690987986504\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch60.pth ...\n",
      "Train Epoch: 61 [512/17352 (3%)] Loss: 191.264435\n",
      "Train Epoch: 61 [9778/17352 (56%)] Loss: -2.997774\n",
      "Train Epoch: 61 [16923/17352 (98%)] Loss: 49.379309\n",
      "    epoch          : 61\n",
      "    loss           : 45.281460064599216\n",
      "    val_loss       : 23.227291552565777\n",
      "    val_log_likelihood: 37.136194014352434\n",
      "    val_log_marginal: -16.43405944032951\n",
      "Train Epoch: 62 [512/17352 (3%)] Loss: 5.239025\n",
      "Train Epoch: 62 [10783/17352 (62%)] Loss: 83.233115\n",
      "Train Epoch: 62 [16923/17352 (98%)] Loss: 89.236270\n",
      "    epoch          : 62\n",
      "    loss           : 10.438952379348578\n",
      "    val_loss       : 23.890003005229744\n",
      "    val_log_likelihood: 51.94473877844169\n",
      "    val_log_marginal: -14.118478350487845\n",
      "Train Epoch: 63 [512/17352 (3%)] Loss: 13.009732\n",
      "Train Epoch: 63 [10198/17352 (59%)] Loss: -18.381246\n",
      "Train Epoch: 63 [16957/17352 (98%)] Loss: 77.205225\n",
      "    epoch          : 63\n",
      "    loss           : 16.368067467046625\n",
      "    val_loss       : 15.625425414463116\n",
      "    val_log_likelihood: 59.55460540520373\n",
      "    val_log_marginal: -4.460902697877882\n",
      "Train Epoch: 64 [512/17352 (3%)] Loss: -0.402332\n",
      "Train Epoch: 64 [10478/17352 (60%)] Loss: -40.486619\n",
      "Train Epoch: 64 [16992/17352 (98%)] Loss: -13.506069\n",
      "    epoch          : 64\n",
      "    loss           : -1.3547586220989287\n",
      "    val_loss       : 1.9835175358810384\n",
      "    val_log_likelihood: 72.26966195122321\n",
      "    val_log_marginal: 7.083261570434634\n",
      "Train Epoch: 65 [512/17352 (3%)] Loss: -24.440342\n",
      "Train Epoch: 65 [10656/17352 (61%)] Loss: 11.540161\n",
      "Train Epoch: 65 [16882/17352 (97%)] Loss: -46.975036\n",
      "    epoch          : 65\n",
      "    loss           : -10.027140539576456\n",
      "    val_loss       : -3.1324334622199377\n",
      "    val_log_likelihood: 83.76242868123553\n",
      "    val_log_marginal: 12.476836677509004\n",
      "Train Epoch: 66 [512/17352 (3%)] Loss: -15.348538\n",
      "Train Epoch: 66 [10770/17352 (62%)] Loss: 17.505609\n",
      "Train Epoch: 66 [17106/17352 (99%)] Loss: -50.567115\n",
      "    epoch          : 66\n",
      "    loss           : -14.529931247319313\n",
      "    val_loss       : -5.941469238714152\n",
      "    val_log_likelihood: 90.84272385242569\n",
      "    val_log_marginal: 14.455972028559497\n",
      "Train Epoch: 67 [512/17352 (3%)] Loss: -30.129841\n",
      "Train Epoch: 67 [10488/17352 (60%)] Loss: 44.041375\n",
      "Train Epoch: 67 [17263/17352 (99%)] Loss: -39.630037\n",
      "    epoch          : 67\n",
      "    loss           : -22.848175420221946\n",
      "    val_loss       : -13.322580137643438\n",
      "    val_log_likelihood: 99.8755663846867\n",
      "    val_log_marginal: 21.706468253881607\n",
      "Train Epoch: 68 [512/17352 (3%)] Loss: -39.056961\n",
      "Train Epoch: 68 [10649/17352 (61%)] Loss: 34.998144\n",
      "Train Epoch: 68 [16922/17352 (98%)] Loss: -43.115690\n",
      "    epoch          : 68\n",
      "    loss           : -28.089582213901163\n",
      "    val_loss       : -24.844595550723497\n",
      "    val_log_likelihood: 108.8227647686421\n",
      "    val_log_marginal: 32.36052080968955\n",
      "Train Epoch: 69 [512/17352 (3%)] Loss: -41.823902\n",
      "Train Epoch: 69 [10359/17352 (60%)] Loss: -101.731215\n",
      "Train Epoch: 69 [17049/17352 (98%)] Loss: -106.268865\n",
      "    epoch          : 69\n",
      "    loss           : -33.11763986569026\n",
      "    val_loss       : -27.049335456497836\n",
      "    val_log_likelihood: 122.1827035993731\n",
      "    val_log_marginal: 35.12866937607319\n",
      "Train Epoch: 70 [512/17352 (3%)] Loss: -41.395821\n",
      "Train Epoch: 70 [10134/17352 (58%)] Loss: -74.477621\n",
      "Train Epoch: 70 [17126/17352 (99%)] Loss: -29.396313\n",
      "    epoch          : 70\n",
      "    loss           : -35.3839843918206\n",
      "    val_loss       : 6.822949530602964\n",
      "    val_log_likelihood: 125.07578664592116\n",
      "    val_log_marginal: 2.8683596985025916\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch70.pth ...\n",
      "Train Epoch: 71 [512/17352 (3%)] Loss: -5.730117\n",
      "Train Epoch: 71 [10138/17352 (58%)] Loss: -63.517456\n",
      "Train Epoch: 71 [16934/17352 (98%)] Loss: -29.491650\n",
      "    epoch          : 71\n",
      "    loss           : -37.069840386804515\n",
      "    val_loss       : -34.47182095833119\n",
      "    val_log_likelihood: 135.24891741202512\n",
      "    val_log_marginal: 44.27441396144252\n",
      "Train Epoch: 72 [512/17352 (3%)] Loss: -54.479980\n",
      "Train Epoch: 72 [10304/17352 (59%)] Loss: -87.103113\n",
      "Train Epoch: 72 [17335/17352 (100%)] Loss: 38.040961\n",
      "    epoch          : 72\n",
      "    loss           : -44.24594167524548\n",
      "    val_loss       : -18.607488402205682\n",
      "    val_log_likelihood: 142.08566115915937\n",
      "    val_log_marginal: 30.009171125179147\n",
      "Train Epoch: 73 [512/17352 (3%)] Loss: -44.145767\n",
      "Train Epoch: 73 [10020/17352 (58%)] Loss: -41.530055\n",
      "Train Epoch: 73 [17090/17352 (98%)] Loss: 14.305283\n",
      "    epoch          : 73\n",
      "    loss           : -37.40784844802625\n",
      "    val_loss       : -26.41796692446765\n",
      "    val_log_likelihood: 142.7984426690767\n",
      "    val_log_marginal: 36.88740110889417\n",
      "Train Epoch: 74 [512/17352 (3%)] Loss: 29.987354\n",
      "Train Epoch: 74 [10640/17352 (61%)] Loss: -10.708512\n",
      "Train Epoch: 74 [17016/17352 (98%)] Loss: 29.681199\n",
      "    epoch          : 74\n",
      "    loss           : -26.004682689738264\n",
      "    val_loss       : -15.22688743547765\n",
      "    val_log_likelihood: 135.40275098601685\n",
      "    val_log_marginal: 27.466622008502334\n",
      "Train Epoch: 75 [512/17352 (3%)] Loss: -33.106915\n",
      "Train Epoch: 75 [10363/17352 (60%)] Loss: -36.197417\n",
      "Train Epoch: 75 [17253/17352 (99%)] Loss: -138.064616\n",
      "    epoch          : 75\n",
      "    loss           : -40.10920742536542\n",
      "    val_loss       : -42.28499390081677\n",
      "    val_log_likelihood: 148.14151930286295\n",
      "    val_log_marginal: 53.643745263277125\n",
      "Train Epoch: 76 [512/17352 (3%)] Loss: -64.108971\n",
      "Train Epoch: 76 [9968/17352 (57%)] Loss: 7.812945\n",
      "Train Epoch: 76 [16887/17352 (97%)] Loss: -4.757469\n",
      "    epoch          : 76\n",
      "    loss           : -50.06054614218357\n",
      "    val_loss       : -49.38466927870369\n",
      "    val_log_likelihood: 153.18697603487257\n",
      "    val_log_marginal: 59.667079862728514\n",
      "Train Epoch: 77 [512/17352 (3%)] Loss: -64.616661\n",
      "Train Epoch: 77 [10567/17352 (61%)] Loss: -31.100299\n",
      "Train Epoch: 77 [16883/17352 (97%)] Loss: -93.252634\n",
      "    epoch          : 77\n",
      "    loss           : -66.03650029229406\n",
      "    val_loss       : -63.80415816608877\n",
      "    val_log_likelihood: 169.04677346909966\n",
      "    val_log_marginal: 73.80072548705449\n",
      "Train Epoch: 78 [512/17352 (3%)] Loss: -82.565346\n",
      "Train Epoch: 78 [11032/17352 (64%)] Loss: -87.455443\n",
      "Train Epoch: 78 [17090/17352 (98%)] Loss: -31.209066\n",
      "    epoch          : 78\n",
      "    loss           : -74.22970983716029\n",
      "    val_loss       : -66.39455511471566\n",
      "    val_log_likelihood: 183.57503332679855\n",
      "    val_log_marginal: 78.42067260077012\n",
      "Train Epoch: 79 [512/17352 (3%)] Loss: -82.371468\n",
      "Train Epoch: 79 [10526/17352 (61%)] Loss: -22.110738\n",
      "Train Epoch: 79 [17064/17352 (98%)] Loss: -113.977689\n",
      "    epoch          : 79\n",
      "    loss           : -75.76163989215652\n",
      "    val_loss       : -68.25827020096796\n",
      "    val_log_likelihood: 182.3493956166551\n",
      "    val_log_marginal: 79.16206526685812\n",
      "Train Epoch: 80 [512/17352 (3%)] Loss: -0.591435\n",
      "Train Epoch: 80 [10405/17352 (60%)] Loss: -97.647508\n",
      "Train Epoch: 80 [17044/17352 (98%)] Loss: -25.816461\n",
      "    epoch          : 80\n",
      "    loss           : -64.22746024182406\n",
      "    val_loss       : -49.055602618630765\n",
      "    val_log_likelihood: 182.88215948345922\n",
      "    val_log_marginal: 65.5007328763067\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch80.pth ...\n",
      "Train Epoch: 81 [512/17352 (3%)] Loss: -78.430862\n",
      "Train Epoch: 81 [10585/17352 (61%)] Loss: -65.059373\n",
      "Train Epoch: 81 [17143/17352 (99%)] Loss: -74.080509\n",
      "    epoch          : 81\n",
      "    loss           : -75.18919806012927\n",
      "    val_loss       : -57.6477548206547\n",
      "    val_log_likelihood: 189.4439917160509\n",
      "    val_log_marginal: 71.88433260427999\n",
      "Train Epoch: 82 [512/17352 (3%)] Loss: -96.320930\n",
      "Train Epoch: 82 [10051/17352 (58%)] Loss: -59.603451\n",
      "Train Epoch: 82 [16988/17352 (98%)] Loss: 23.325452\n",
      "    epoch          : 82\n",
      "    loss           : -39.821652619384\n",
      "    val_loss       : -35.7917689333626\n",
      "    val_log_likelihood: 152.7075647545212\n",
      "    val_log_marginal: 46.650964825115864\n",
      "Train Epoch: 83 [512/17352 (3%)] Loss: -65.037498\n",
      "Train Epoch: 83 [10043/17352 (58%)] Loss: -98.055080\n",
      "Train Epoch: 83 [16988/17352 (98%)] Loss: -15.734959\n",
      "    epoch          : 83\n",
      "    loss           : -58.05821490166586\n",
      "    val_loss       : -50.33910411001556\n",
      "    val_log_likelihood: 199.56309906315624\n",
      "    val_log_marginal: 64.3229440931191\n",
      "Train Epoch: 84 [512/17352 (3%)] Loss: -95.183891\n",
      "Train Epoch: 84 [10188/17352 (59%)] Loss: -57.060704\n",
      "Train Epoch: 84 [17277/17352 (100%)] Loss: -40.713867\n",
      "    epoch          : 84\n",
      "    loss           : -75.63780466411\n",
      "    val_loss       : -33.5106280806869\n",
      "    val_log_likelihood: 201.14560554943543\n",
      "    val_log_marginal: 47.58632150420378\n",
      "Train Epoch: 85 [512/17352 (3%)] Loss: -68.549118\n",
      "Train Epoch: 85 [10404/17352 (60%)] Loss: -93.153084\n",
      "Train Epoch: 85 [16958/17352 (98%)] Loss: -48.675024\n",
      "    epoch          : 85\n",
      "    loss           : -79.74988154569806\n",
      "    val_loss       : -78.7572424382581\n",
      "    val_log_likelihood: 217.4977274355185\n",
      "    val_log_marginal: 92.28216668348773\n",
      "Train Epoch: 86 [512/17352 (3%)] Loss: -97.544609\n",
      "Train Epoch: 86 [10360/17352 (60%)] Loss: -124.233511\n",
      "Train Epoch: 86 [16934/17352 (98%)] Loss: -41.552501\n",
      "    epoch          : 86\n",
      "    loss           : -88.32673129394234\n",
      "    val_loss       : -58.879269989878935\n",
      "    val_log_likelihood: 219.59008410298074\n",
      "    val_log_marginal: 71.79320621669487\n",
      "Train Epoch: 87 [512/17352 (3%)] Loss: -90.566422\n",
      "Train Epoch: 87 [10322/17352 (59%)] Loss: 17.769737\n",
      "Train Epoch: 87 [17335/17352 (100%)] Loss: -132.923104\n",
      "    epoch          : 87\n",
      "    loss           : -94.661995177063\n",
      "    val_loss       : -75.70670780926599\n",
      "    val_log_likelihood: 234.32337338779823\n",
      "    val_log_marginal: 91.32852519615206\n",
      "Train Epoch: 88 [512/17352 (3%)] Loss: -100.263794\n",
      "Train Epoch: 88 [9941/17352 (57%)] Loss: -73.757812\n",
      "Train Epoch: 88 [17253/17352 (99%)] Loss: -97.119568\n",
      "    epoch          : 88\n",
      "    loss           : -101.03708004286239\n",
      "    val_loss       : -79.54766409421669\n",
      "    val_log_likelihood: 240.79597524498303\n",
      "    val_log_marginal: 92.36607120309186\n",
      "Train Epoch: 89 [512/17352 (3%)] Loss: -111.376328\n",
      "Train Epoch: 89 [10528/17352 (61%)] Loss: -144.336414\n",
      "Train Epoch: 89 [17253/17352 (99%)] Loss: -147.999648\n",
      "    epoch          : 89\n",
      "    loss           : -108.86616243173522\n",
      "    val_loss       : -100.51854211178811\n",
      "    val_log_likelihood: 249.8464801585849\n",
      "    val_log_marginal: 115.87740522120355\n",
      "Train Epoch: 90 [512/17352 (3%)] Loss: -133.427658\n",
      "Train Epoch: 90 [10057/17352 (58%)] Loss: -73.173555\n",
      "Train Epoch: 90 [16988/17352 (98%)] Loss: -183.838870\n",
      "    epoch          : 90\n",
      "    loss           : -120.61625475911175\n",
      "    val_loss       : -107.74445324189588\n",
      "    val_log_likelihood: 267.4746021108517\n",
      "    val_log_marginal: 126.11012780098358\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch90.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 91 [512/17352 (3%)] Loss: -23.161694\n",
      "Train Epoch: 91 [10525/17352 (61%)] Loss: -21.743962\n",
      "Train Epoch: 91 [17133/17352 (99%)] Loss: -68.818778\n",
      "    epoch          : 91\n",
      "    loss           : -119.61338792289007\n",
      "    val_loss       : -113.74267199372547\n",
      "    val_log_likelihood: 273.0099453989537\n",
      "    val_log_marginal: 128.30475570802344\n",
      "Train Epoch: 92 [512/17352 (3%)] Loss: -11.407195\n",
      "Train Epoch: 92 [10194/17352 (59%)] Loss: -191.681954\n",
      "Train Epoch: 92 [16988/17352 (98%)] Loss: -150.746265\n",
      "    epoch          : 92\n",
      "    loss           : -131.69516016120738\n",
      "    val_loss       : -128.62575356451967\n",
      "    val_log_likelihood: 290.6930261299053\n",
      "    val_log_marginal: 141.5994757412356\n",
      "Train Epoch: 93 [512/17352 (3%)] Loss: -162.057770\n",
      "Train Epoch: 93 [10707/17352 (62%)] Loss: -89.550891\n",
      "Train Epoch: 93 [17277/17352 (100%)] Loss: -138.532844\n",
      "    epoch          : 93\n",
      "    loss           : -135.45314196048196\n",
      "    val_loss       : -111.32177061715838\n",
      "    val_log_likelihood: 286.6156755660574\n",
      "    val_log_marginal: 128.71961511430288\n",
      "Train Epoch: 94 [512/17352 (3%)] Loss: -142.470184\n",
      "Train Epoch: 94 [10263/17352 (59%)] Loss: -105.012658\n",
      "Train Epoch: 94 [17277/17352 (100%)] Loss: -97.281669\n",
      "    epoch          : 94\n",
      "    loss           : -126.86673777496178\n",
      "    val_loss       : -104.15803210348706\n",
      "    val_log_likelihood: 283.50562621658435\n",
      "    val_log_marginal: 126.81277150582632\n",
      "Train Epoch: 95 [512/17352 (3%)] Loss: -144.598206\n",
      "Train Epoch: 95 [10042/17352 (58%)] Loss: -129.792456\n",
      "Train Epoch: 95 [16923/17352 (98%)] Loss: -80.295239\n",
      "    epoch          : 95\n",
      "    loss           : -131.80150397325832\n",
      "    val_loss       : -119.90000471568786\n",
      "    val_log_likelihood: 293.0523990220938\n",
      "    val_log_marginal: 139.16800074863056\n",
      "Train Epoch: 96 [512/17352 (3%)] Loss: -169.813873\n",
      "Train Epoch: 96 [10819/17352 (62%)] Loss: -76.087844\n",
      "Train Epoch: 96 [17126/17352 (99%)] Loss: -202.195645\n",
      "    epoch          : 96\n",
      "    loss           : -122.71710609538714\n",
      "    val_loss       : -122.7918866540596\n",
      "    val_log_likelihood: 289.32973369979464\n",
      "    val_log_marginal: 137.4332445404127\n",
      "Train Epoch: 97 [512/17352 (3%)] Loss: -141.355530\n",
      "Train Epoch: 97 [9868/17352 (57%)] Loss: -94.260370\n",
      "Train Epoch: 97 [16957/17352 (98%)] Loss: -215.904595\n",
      "    epoch          : 97\n",
      "    loss           : -140.55973165246095\n",
      "    val_loss       : -145.21826401238204\n",
      "    val_log_likelihood: 313.3162820944699\n",
      "    val_log_marginal: 160.3723311459023\n",
      "Train Epoch: 98 [512/17352 (3%)] Loss: -160.942184\n",
      "Train Epoch: 98 [10510/17352 (61%)] Loss: -105.936140\n",
      "Train Epoch: 98 [16939/17352 (98%)] Loss: -166.269858\n",
      "    epoch          : 98\n",
      "    loss           : -143.6739423471147\n",
      "    val_loss       : -128.38457407892332\n",
      "    val_log_likelihood: 312.8035325068443\n",
      "    val_log_marginal: 154.48628111903554\n",
      "Train Epoch: 99 [512/17352 (3%)] Loss: -178.045563\n",
      "Train Epoch: 99 [10488/17352 (60%)] Loss: -196.982025\n",
      "Train Epoch: 99 [17090/17352 (98%)] Loss: -112.756836\n",
      "    epoch          : 99\n",
      "    loss           : -139.8328780124194\n",
      "    val_loss       : -106.12426280336327\n",
      "    val_log_likelihood: 311.0710173329726\n",
      "    val_log_marginal: 138.20957208473422\n",
      "Train Epoch: 100 [512/17352 (3%)] Loss: -111.230865\n",
      "Train Epoch: 100 [10541/17352 (61%)] Loss: -110.094640\n",
      "Train Epoch: 100 [16878/17352 (97%)] Loss: 77.395232\n",
      "    epoch          : 100\n",
      "    loss           : -124.31913824853115\n",
      "    val_loss       : 92.29247293219437\n",
      "    val_log_likelihood: 296.3892859974622\n",
      "    val_log_marginal: -73.3728863477268\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch100.pth ...\n",
      "Train Epoch: 101 [512/17352 (3%)] Loss: 55.381496\n",
      "Train Epoch: 101 [10051/17352 (58%)] Loss: -38.606775\n",
      "Train Epoch: 101 [17108/17352 (99%)] Loss: -158.088044\n",
      "    epoch          : 101\n",
      "    loss           : -109.9757833784243\n",
      "    val_loss       : -114.26357381002194\n",
      "    val_log_likelihood: 308.7143425942379\n",
      "    val_log_marginal: 143.33432928911324\n",
      "Train Epoch: 102 [512/17352 (3%)] Loss: -161.468933\n",
      "Train Epoch: 102 [10645/17352 (61%)] Loss: -121.860136\n",
      "Train Epoch: 102 [17335/17352 (100%)] Loss: -244.331000\n",
      "    epoch          : 102\n",
      "    loss           : -157.14925448348905\n",
      "    val_loss       : -152.5586263992932\n",
      "    val_log_likelihood: 330.65236620916494\n",
      "    val_log_marginal: 165.09847681871997\n",
      "Train Epoch: 103 [512/17352 (3%)] Loss: -185.539795\n",
      "Train Epoch: 103 [10548/17352 (61%)] Loss: -153.179091\n",
      "Train Epoch: 103 [17124/17352 (99%)] Loss: -194.340273\n",
      "    epoch          : 103\n",
      "    loss           : -176.4928893469544\n",
      "    val_loss       : -166.45673830623846\n",
      "    val_log_likelihood: 347.26527890776595\n",
      "    val_log_marginal: 182.5828632042716\n",
      "Train Epoch: 104 [512/17352 (3%)] Loss: -213.052979\n",
      "Train Epoch: 104 [10545/17352 (61%)] Loss: -251.477826\n",
      "Train Epoch: 104 [17016/17352 (98%)] Loss: -157.934659\n",
      "    epoch          : 104\n",
      "    loss           : -170.1486319730769\n",
      "    val_loss       : -156.08304873052447\n",
      "    val_log_likelihood: 345.91968409726394\n",
      "    val_log_marginal: 178.2065276742208\n",
      "Train Epoch: 105 [512/17352 (3%)] Loss: -172.006027\n",
      "Train Epoch: 105 [10745/17352 (62%)] Loss: -247.632437\n",
      "Train Epoch: 105 [16878/17352 (97%)] Loss: -214.218065\n",
      "    epoch          : 105\n",
      "    loss           : -183.49513402296262\n",
      "    val_loss       : -169.07933569265214\n",
      "    val_log_likelihood: 369.099242319771\n",
      "    val_log_marginal: 199.00203869136396\n",
      "Train Epoch: 106 [512/17352 (3%)] Loss: -202.103775\n",
      "Train Epoch: 106 [10049/17352 (58%)] Loss: -287.904207\n",
      "Train Epoch: 106 [17101/17352 (99%)] Loss: -176.163667\n",
      "    epoch          : 106\n",
      "    loss           : -192.2379728189457\n",
      "    val_loss       : -168.6063412485939\n",
      "    val_log_likelihood: 371.698321569844\n",
      "    val_log_marginal: 189.19945818673222\n",
      "Train Epoch: 107 [512/17352 (3%)] Loss: -166.223099\n",
      "Train Epoch: 107 [10503/17352 (61%)] Loss: -28.818385\n",
      "Train Epoch: 107 [16988/17352 (98%)] Loss: -147.334996\n",
      "    epoch          : 107\n",
      "    loss           : -173.84193603368666\n",
      "    val_loss       : -165.09488603159787\n",
      "    val_log_likelihood: 362.8974117063664\n",
      "    val_log_marginal: 192.19874877385908\n",
      "Train Epoch: 108 [512/17352 (3%)] Loss: -227.610474\n",
      "Train Epoch: 108 [9692/17352 (56%)] Loss: -224.510274\n",
      "Train Epoch: 108 [16883/17352 (97%)] Loss: -241.431566\n",
      "    epoch          : 108\n",
      "    loss           : -191.7905939881169\n",
      "    val_loss       : -182.2570686028823\n",
      "    val_log_likelihood: 378.10974908106266\n",
      "    val_log_marginal: 204.7438691657861\n",
      "Train Epoch: 109 [512/17352 (3%)] Loss: -237.977112\n",
      "Train Epoch: 109 [10711/17352 (62%)] Loss: -141.753687\n",
      "Train Epoch: 109 [16934/17352 (98%)] Loss: -160.411167\n",
      "    epoch          : 109\n",
      "    loss           : -209.80239890047827\n",
      "    val_loss       : -203.79347281326275\n",
      "    val_log_likelihood: 388.98334040505995\n",
      "    val_log_marginal: 217.18678278065204\n",
      "Train Epoch: 110 [512/17352 (3%)] Loss: -245.955826\n",
      "Train Epoch: 110 [9894/17352 (57%)] Loss: -202.766651\n",
      "Train Epoch: 110 [16878/17352 (97%)] Loss: 201.576544\n",
      "    epoch          : 110\n",
      "    loss           : -177.33843348167264\n",
      "    val_loss       : 111.57315137602131\n",
      "    val_log_likelihood: 344.03226032249233\n",
      "    val_log_marginal: -69.89780936999989\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch110.pth ...\n",
      "Train Epoch: 111 [512/17352 (3%)] Loss: 87.544357\n",
      "Train Epoch: 111 [10649/17352 (61%)] Loss: -141.147287\n",
      "Train Epoch: 111 [17064/17352 (98%)] Loss: -27.714027\n",
      "    epoch          : 111\n",
      "    loss           : -143.99886826531846\n",
      "    val_loss       : -158.09019813080116\n",
      "    val_log_likelihood: 381.8384611636207\n",
      "    val_log_marginal: 180.39662943001588\n",
      "Train Epoch: 112 [512/17352 (3%)] Loss: -186.782944\n",
      "Train Epoch: 112 [10345/17352 (60%)] Loss: -190.732805\n",
      "Train Epoch: 112 [16887/17352 (97%)] Loss: -259.850813\n",
      "    epoch          : 112\n",
      "    loss           : -207.09465805126646\n",
      "    val_loss       : -204.30918322942844\n",
      "    val_log_likelihood: 405.912218721614\n",
      "    val_log_marginal: 223.32394233972224\n",
      "Train Epoch: 113 [512/17352 (3%)] Loss: -247.240692\n",
      "Train Epoch: 113 [10609/17352 (61%)] Loss: -194.574661\n",
      "Train Epoch: 113 [17106/17352 (99%)] Loss: -309.301239\n",
      "    epoch          : 113\n",
      "    loss           : -222.30820897778432\n",
      "    val_loss       : -174.72629278365778\n",
      "    val_log_likelihood: 408.13304349824836\n",
      "    val_log_marginal: 190.14032596845914\n",
      "Train Epoch: 114 [512/17352 (3%)] Loss: -232.826202\n",
      "Train Epoch: 114 [9745/17352 (56%)] Loss: -211.210029\n",
      "Train Epoch: 114 [17044/17352 (98%)] Loss: -88.610509\n",
      "    epoch          : 114\n",
      "    loss           : -181.1714451636113\n",
      "    val_loss       : -145.59727730108273\n",
      "    val_log_likelihood: 371.00782313401663\n",
      "    val_log_marginal: 167.69015743622336\n",
      "Train Epoch: 115 [512/17352 (3%)] Loss: -197.792084\n",
      "Train Epoch: 115 [10369/17352 (60%)] Loss: -125.863328\n",
      "Train Epoch: 115 [16958/17352 (98%)] Loss: -236.295194\n",
      "    epoch          : 115\n",
      "    loss           : -198.945488913588\n",
      "    val_loss       : -201.91327379805114\n",
      "    val_log_likelihood: 404.95462246897625\n",
      "    val_log_marginal: 227.55846248436697\n",
      "Train Epoch: 116 [512/17352 (3%)] Loss: -266.607666\n",
      "Train Epoch: 116 [10351/17352 (60%)] Loss: -54.636118\n",
      "Train Epoch: 116 [17106/17352 (99%)] Loss: -257.768550\n",
      "    epoch          : 116\n",
      "    loss           : -234.13550921782542\n",
      "    val_loss       : -229.78444883179608\n",
      "    val_log_likelihood: 426.3290574042836\n",
      "    val_log_marginal: 247.0908513469526\n",
      "Train Epoch: 117 [512/17352 (3%)] Loss: -275.856476\n",
      "Train Epoch: 117 [10312/17352 (59%)] Loss: -279.467806\n",
      "Train Epoch: 117 [17153/17352 (99%)] Loss: -326.418038\n",
      "    epoch          : 117\n",
      "    loss           : -256.67108536009715\n",
      "    val_loss       : -215.3718566500262\n",
      "    val_log_likelihood: 444.02560398423896\n",
      "    val_log_marginal: 231.77917909300615\n",
      "Train Epoch: 118 [512/17352 (3%)] Loss: -273.007690\n",
      "Train Epoch: 118 [9978/17352 (58%)] Loss: -302.617407\n",
      "Train Epoch: 118 [17124/17352 (99%)] Loss: -317.606815\n",
      "    epoch          : 118\n",
      "    loss           : -250.88437858995286\n",
      "    val_loss       : -187.44563448659514\n",
      "    val_log_likelihood: 445.6933723450707\n",
      "    val_log_marginal: 210.7724980754074\n",
      "Train Epoch: 119 [512/17352 (3%)] Loss: -279.625732\n",
      "Train Epoch: 119 [10442/17352 (60%)] Loss: -146.852964\n",
      "Train Epoch: 119 [17090/17352 (98%)] Loss: -287.378059\n",
      "    epoch          : 119\n",
      "    loss           : -236.94637056912063\n",
      "    val_loss       : -198.3266372785138\n",
      "    val_log_likelihood: 411.05922679626656\n",
      "    val_log_marginal: 219.07696759129928\n",
      "Train Epoch: 120 [512/17352 (3%)] Loss: -267.724396\n",
      "Train Epoch: 120 [9988/17352 (58%)] Loss: -309.556705\n",
      "Train Epoch: 120 [17064/17352 (98%)] Loss: -164.057237\n",
      "    epoch          : 120\n",
      "    loss           : -244.60623125778804\n",
      "    val_loss       : -236.95291308719598\n",
      "    val_log_likelihood: 451.95044184093547\n",
      "    val_log_marginal: 263.2984271226951\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch120.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 121 [512/17352 (3%)] Loss: -272.407990\n",
      "Train Epoch: 121 [9931/17352 (57%)] Loss: -282.698129\n",
      "Train Epoch: 121 [16887/17352 (97%)] Loss: -287.041634\n",
      "    epoch          : 121\n",
      "    loss           : -258.82915421792944\n",
      "    val_loss       : -251.32322474001018\n",
      "    val_log_likelihood: 465.86568421609246\n",
      "    val_log_marginal: 275.9101660195449\n",
      "Train Epoch: 122 [512/17352 (3%)] Loss: -300.780396\n",
      "Train Epoch: 122 [10309/17352 (59%)] Loss: -317.087666\n",
      "Train Epoch: 122 [17049/17352 (98%)] Loss: -247.939571\n",
      "    epoch          : 122\n",
      "    loss           : -277.613450133382\n",
      "    val_loss       : -260.3323762922284\n",
      "    val_log_likelihood: 473.6557945332229\n",
      "    val_log_marginal: 280.24359355135874\n",
      "Train Epoch: 123 [512/17352 (3%)] Loss: -290.869537\n",
      "Train Epoch: 123 [10345/17352 (60%)] Loss: -253.128488\n",
      "Train Epoch: 123 [16934/17352 (98%)] Loss: -399.893457\n",
      "    epoch          : 123\n",
      "    loss           : -285.85372084157086\n",
      "    val_loss       : -273.78092435093515\n",
      "    val_log_likelihood: 482.58369826371484\n",
      "    val_log_marginal: 293.8094090250154\n",
      "Train Epoch: 124 [512/17352 (3%)] Loss: -336.568512\n",
      "Train Epoch: 124 [10580/17352 (61%)] Loss: -373.503391\n",
      "Train Epoch: 124 [17133/17352 (99%)] Loss: -250.285829\n",
      "    epoch          : 124\n",
      "    loss           : -292.84200479862693\n",
      "    val_loss       : -267.3598498857633\n",
      "    val_log_likelihood: 491.1290796604816\n",
      "    val_log_marginal: 284.3833881953483\n",
      "Train Epoch: 125 [512/17352 (3%)] Loss: -307.069336\n",
      "Train Epoch: 125 [10641/17352 (61%)] Loss: -275.461675\n",
      "Train Epoch: 125 [16883/17352 (97%)] Loss: -324.766788\n",
      "    epoch          : 125\n",
      "    loss           : -303.574517676661\n",
      "    val_loss       : -285.0965405898076\n",
      "    val_log_likelihood: 506.8000843283372\n",
      "    val_log_marginal: 304.93105196355253\n",
      "Train Epoch: 126 [512/17352 (3%)] Loss: -343.023834\n",
      "Train Epoch: 126 [10212/17352 (59%)] Loss: -389.858242\n",
      "Train Epoch: 126 [16934/17352 (98%)] Loss: -271.459071\n",
      "    epoch          : 126\n",
      "    loss           : -304.81850541409085\n",
      "    val_loss       : -274.6671219552083\n",
      "    val_log_likelihood: 506.6361335806715\n",
      "    val_log_marginal: 298.1718051760203\n",
      "Train Epoch: 127 [512/17352 (3%)] Loss: -330.343567\n",
      "Train Epoch: 127 [10629/17352 (61%)] Loss: -379.052017\n",
      "Train Epoch: 127 [16958/17352 (98%)] Loss: -218.883472\n",
      "    epoch          : 127\n",
      "    loss           : -296.75838935687017\n",
      "    val_loss       : -293.47656714851485\n",
      "    val_log_likelihood: 513.5430886750091\n",
      "    val_log_marginal: 316.62839705357595\n",
      "Train Epoch: 128 [512/17352 (3%)] Loss: -335.010193\n",
      "Train Epoch: 128 [10401/17352 (60%)] Loss: -366.051781\n",
      "Train Epoch: 128 [16957/17352 (98%)] Loss: -350.086230\n",
      "    epoch          : 128\n",
      "    loss           : -318.54968365410286\n",
      "    val_loss       : -300.16691467790827\n",
      "    val_log_likelihood: 523.3565787994672\n",
      "    val_log_marginal: 314.9481748990156\n",
      "Train Epoch: 129 [512/17352 (3%)] Loss: -326.822876\n",
      "Train Epoch: 129 [9867/17352 (57%)] Loss: -269.354407\n",
      "Train Epoch: 129 [17277/17352 (100%)] Loss: -275.942927\n",
      "    epoch          : 129\n",
      "    loss           : -319.29456465875984\n",
      "    val_loss       : -288.94751673813516\n",
      "    val_log_likelihood: 529.7497678956603\n",
      "    val_log_marginal: 303.61749896466483\n",
      "Train Epoch: 130 [512/17352 (3%)] Loss: -299.647095\n",
      "Train Epoch: 130 [10519/17352 (61%)] Loss: -203.746339\n",
      "Train Epoch: 130 [16957/17352 (98%)] Loss: -395.487905\n",
      "    epoch          : 130\n",
      "    loss           : -321.4227468070219\n",
      "    val_loss       : -303.5375567310778\n",
      "    val_log_likelihood: 536.7538392429723\n",
      "    val_log_marginal: 325.6401282284965\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch130.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 131 [512/17352 (3%)] Loss: -350.359802\n",
      "Train Epoch: 131 [10218/17352 (59%)] Loss: -385.234075\n",
      "Train Epoch: 131 [17126/17352 (99%)] Loss: -203.511288\n",
      "    epoch          : 131\n",
      "    loss           : -284.73857859298676\n",
      "    val_loss       : -255.82381335704196\n",
      "    val_log_likelihood: 515.0903428320654\n",
      "    val_log_marginal: 294.88759994795737\n",
      "Train Epoch: 132 [512/17352 (3%)] Loss: -332.880005\n",
      "Train Epoch: 132 [10511/17352 (61%)] Loss: -330.259057\n",
      "Train Epoch: 132 [16923/17352 (98%)] Loss: -296.506771\n",
      "    epoch          : 132\n",
      "    loss           : -303.10402368875754\n",
      "    val_loss       : -271.79479105891244\n",
      "    val_log_likelihood: 529.0788827188115\n",
      "    val_log_marginal: 292.16545543927367\n",
      "Train Epoch: 133 [512/17352 (3%)] Loss: -330.450989\n",
      "Train Epoch: 133 [10281/17352 (59%)] Loss: -199.279447\n",
      "Train Epoch: 133 [17090/17352 (98%)] Loss: -328.362760\n",
      "    epoch          : 133\n",
      "    loss           : -231.45380524396833\n",
      "    val_loss       : -252.25745980631424\n",
      "    val_log_likelihood: 494.2256423233566\n",
      "    val_log_marginal: 284.6289659147141\n",
      "Train Epoch: 134 [512/17352 (3%)] Loss: -330.360413\n",
      "Train Epoch: 134 [10198/17352 (59%)] Loss: -307.248794\n",
      "Train Epoch: 134 [17106/17352 (99%)] Loss: -232.334365\n",
      "    epoch          : 134\n",
      "    loss           : -282.96509209828434\n",
      "    val_loss       : -263.65810184804184\n",
      "    val_log_likelihood: 520.372711723953\n",
      "    val_log_marginal: 299.86738327901224\n",
      "Train Epoch: 135 [512/17352 (3%)] Loss: -335.587341\n",
      "Train Epoch: 135 [10224/17352 (59%)] Loss: -357.767981\n",
      "Train Epoch: 135 [17106/17352 (99%)] Loss: -430.145732\n",
      "    epoch          : 135\n",
      "    loss           : -315.7412842229878\n",
      "    val_loss       : -317.56918262553756\n",
      "    val_log_likelihood: 541.9989106425236\n",
      "    val_log_marginal: 343.2050137497992\n",
      "Train Epoch: 136 [512/17352 (3%)] Loss: -370.771393\n",
      "Train Epoch: 136 [10262/17352 (59%)] Loss: -181.507107\n",
      "Train Epoch: 136 [16882/17352 (97%)] Loss: -363.327734\n",
      "    epoch          : 136\n",
      "    loss           : -339.6746293891042\n",
      "    val_loss       : -315.0122149482606\n",
      "    val_log_likelihood: 557.5373134058245\n",
      "    val_log_marginal: 344.88847188173804\n",
      "Train Epoch: 137 [512/17352 (3%)] Loss: -380.581818\n",
      "Train Epoch: 137 [10186/17352 (59%)] Loss: -348.428368\n",
      "Train Epoch: 137 [16958/17352 (98%)] Loss: -400.546173\n",
      "    epoch          : 137\n",
      "    loss           : -315.9805730993872\n",
      "    val_loss       : -296.0566533346166\n",
      "    val_log_likelihood: 542.1866795385796\n",
      "    val_log_marginal: 328.9883308610361\n",
      "Train Epoch: 138 [512/17352 (3%)] Loss: -381.991943\n",
      "Train Epoch: 138 [10462/17352 (60%)] Loss: -374.711552\n",
      "Train Epoch: 138 [17126/17352 (99%)] Loss: -358.009960\n",
      "    epoch          : 138\n",
      "    loss           : -330.8391704369739\n",
      "    val_loss       : -316.78165793228857\n",
      "    val_log_likelihood: 556.6384427791387\n",
      "    val_log_marginal: 336.22379853998046\n",
      "Train Epoch: 139 [512/17352 (3%)] Loss: -393.903442\n",
      "Train Epoch: 139 [9945/17352 (57%)] Loss: -406.738237\n",
      "Train Epoch: 139 [17090/17352 (98%)] Loss: -432.566090\n",
      "    epoch          : 139\n",
      "    loss           : -351.5465711240402\n",
      "    val_loss       : -315.3327862367245\n",
      "    val_log_likelihood: 568.9669530174732\n",
      "    val_log_marginal: 337.86703732884797\n",
      "Train Epoch: 140 [512/17352 (3%)] Loss: -386.868561\n",
      "Train Epoch: 140 [10506/17352 (61%)] Loss: -378.000484\n",
      "Train Epoch: 140 [17124/17352 (99%)] Loss: -475.462782\n",
      "    epoch          : 140\n",
      "    loss           : -357.48615615941196\n",
      "    val_loss       : -338.2676766029387\n",
      "    val_log_likelihood: 580.0222158556953\n",
      "    val_log_marginal: 357.4690237847612\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch140.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 141 [512/17352 (3%)] Loss: -393.304382\n",
      "Train Epoch: 141 [9931/17352 (57%)] Loss: -456.945407\n",
      "Train Epoch: 141 [16878/17352 (97%)] Loss: -430.687134\n",
      "    epoch          : 141\n",
      "    loss           : -358.68400658124665\n",
      "    val_loss       : -338.80464375132306\n",
      "    val_log_likelihood: 584.7403545637824\n",
      "    val_log_marginal: 357.27311807051063\n",
      "Train Epoch: 142 [512/17352 (3%)] Loss: -383.349243\n",
      "Train Epoch: 142 [10641/17352 (61%)] Loss: -244.564332\n",
      "Train Epoch: 142 [16923/17352 (98%)] Loss: -485.888326\n",
      "    epoch          : 142\n",
      "    loss           : -376.93784736761233\n",
      "    val_loss       : -347.8733564099295\n",
      "    val_log_likelihood: 592.7689948177583\n",
      "    val_log_marginal: 374.9971401734141\n",
      "Train Epoch: 143 [512/17352 (3%)] Loss: -411.072815\n",
      "Train Epoch: 143 [10549/17352 (61%)] Loss: -364.996233\n",
      "Train Epoch: 143 [17253/17352 (99%)] Loss: -143.556957\n",
      "    epoch          : 143\n",
      "    loss           : -344.8946941832746\n",
      "    val_loss       : -249.05736527708757\n",
      "    val_log_likelihood: 581.6568091648381\n",
      "    val_log_marginal: 279.5543337515543\n",
      "Train Epoch: 144 [512/17352 (3%)] Loss: -311.606537\n",
      "Train Epoch: 144 [10288/17352 (59%)] Loss: -151.799643\n",
      "Train Epoch: 144 [16934/17352 (98%)] Loss: -408.891556\n",
      "    epoch          : 144\n",
      "    loss           : -287.7462722328957\n",
      "    val_loss       : -306.5404434197519\n",
      "    val_log_likelihood: 563.0587890985037\n",
      "    val_log_marginal: 331.01239881688934\n",
      "Train Epoch: 145 [512/17352 (3%)] Loss: -339.867676\n",
      "Train Epoch: 145 [10253/17352 (59%)] Loss: -451.122396\n",
      "Train Epoch: 145 [17153/17352 (99%)] Loss: -429.529548\n",
      "    epoch          : 145\n",
      "    loss           : -338.14863970792356\n",
      "    val_loss       : -291.63030841416304\n",
      "    val_log_likelihood: 582.1964375777878\n",
      "    val_log_marginal: 324.9189803853342\n",
      "Train Epoch: 146 [512/17352 (3%)] Loss: -150.460358\n",
      "Train Epoch: 146 [10403/17352 (60%)] Loss: -419.522493\n",
      "Train Epoch: 146 [16988/17352 (98%)] Loss: -463.426264\n",
      "    epoch          : 146\n",
      "    loss           : -346.1476497572377\n",
      "    val_loss       : -338.9466496317015\n",
      "    val_log_likelihood: 600.213078847125\n",
      "    val_log_marginal: 365.7424932345213\n",
      "Train Epoch: 147 [512/17352 (3%)] Loss: -415.696960\n",
      "Train Epoch: 147 [10194/17352 (59%)] Loss: -273.003532\n",
      "Train Epoch: 147 [17133/17352 (99%)] Loss: -412.231851\n",
      "    epoch          : 147\n",
      "    loss           : -373.0108929340739\n",
      "    val_loss       : -342.7098490472521\n",
      "    val_log_likelihood: 604.7934291425707\n",
      "    val_log_marginal: 371.88459279271945\n",
      "Train Epoch: 148 [512/17352 (3%)] Loss: -229.508514\n",
      "Train Epoch: 148 [10370/17352 (60%)] Loss: -501.039605\n",
      "Train Epoch: 148 [16923/17352 (98%)] Loss: -417.838351\n",
      "    epoch          : 148\n",
      "    loss           : -371.9256690229741\n",
      "    val_loss       : -348.45816836744274\n",
      "    val_log_likelihood: 593.0261038360786\n",
      "    val_log_marginal: 374.1376884994027\n",
      "Train Epoch: 149 [512/17352 (3%)] Loss: -407.489349\n",
      "Train Epoch: 149 [9731/17352 (56%)] Loss: -370.147752\n",
      "Train Epoch: 149 [16887/17352 (97%)] Loss: -421.368336\n",
      "    epoch          : 149\n",
      "    loss           : -399.00729776723006\n",
      "    val_loss       : -369.957268998014\n",
      "    val_log_likelihood: 622.6343196833925\n",
      "    val_log_marginal: 398.57109475328843\n",
      "Train Epoch: 150 [512/17352 (3%)] Loss: -439.193176\n",
      "Train Epoch: 150 [10430/17352 (60%)] Loss: -385.819997\n",
      "Train Epoch: 150 [16872/17352 (97%)] Loss: -449.664633\n",
      "    epoch          : 150\n",
      "    loss           : -402.2863354720111\n",
      "    val_loss       : -380.02607464479564\n",
      "    val_log_likelihood: 630.1216053320833\n",
      "    val_log_marginal: 402.2735644017439\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch150.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 151 [512/17352 (3%)] Loss: -444.366730\n",
      "Train Epoch: 151 [10140/17352 (58%)] Loss: -475.912104\n",
      "Train Epoch: 151 [16988/17352 (98%)] Loss: -420.103408\n",
      "    epoch          : 151\n",
      "    loss           : -405.28151032392026\n",
      "    val_loss       : -375.3840235760656\n",
      "    val_log_likelihood: 636.3735505787332\n",
      "    val_log_marginal: 396.75070930133097\n",
      "Train Epoch: 152 [512/17352 (3%)] Loss: -266.590973\n",
      "Train Epoch: 152 [10944/17352 (63%)] Loss: -479.759597\n",
      "Train Epoch: 152 [17126/17352 (99%)] Loss: -385.452876\n",
      "    epoch          : 152\n",
      "    loss           : -402.61676913342023\n",
      "    val_loss       : -311.00428811819626\n",
      "    val_log_likelihood: 634.7635832734231\n",
      "    val_log_marginal: 334.7194188583623\n",
      "Train Epoch: 153 [512/17352 (3%)] Loss: -407.018005\n",
      "Train Epoch: 153 [10534/17352 (61%)] Loss: -408.844143\n",
      "Train Epoch: 153 [16992/17352 (98%)] Loss: 3117.625000\n",
      "    epoch          : 153\n",
      "    loss           : -112.91112016919645\n",
      "    val_loss       : 671.251469398243\n",
      "    val_log_likelihood: 403.00023931817566\n",
      "    val_log_marginal: -500.60331160675076\n",
      "Train Epoch: 154 [512/17352 (3%)] Loss: 465.365356\n",
      "Train Epoch: 154 [10942/17352 (63%)] Loss: 102.165109\n",
      "Train Epoch: 154 [17263/17352 (99%)] Loss: -38.760401\n",
      "    epoch          : 154\n",
      "    loss           : -10.885550061514266\n",
      "    val_loss       : -214.0165417971351\n",
      "    val_log_likelihood: 484.45754199339314\n",
      "    val_log_marginal: 255.06743826713992\n",
      "Train Epoch: 155 [512/17352 (3%)] Loss: -41.406593\n",
      "Train Epoch: 155 [10890/17352 (63%)] Loss: -380.174414\n",
      "Train Epoch: 155 [17044/17352 (98%)] Loss: -321.308594\n",
      "    epoch          : 155\n",
      "    loss           : -322.39049219938397\n",
      "    val_loss       : -317.9422699967264\n",
      "    val_log_likelihood: 580.4874561630199\n",
      "    val_log_marginal: 343.38911216424543\n",
      "Train Epoch: 156 [512/17352 (3%)] Loss: -389.348938\n",
      "Train Epoch: 156 [10405/17352 (60%)] Loss: -431.631679\n",
      "Train Epoch: 156 [17044/17352 (98%)] Loss: -405.326231\n",
      "    epoch          : 156\n",
      "    loss           : -379.165010268115\n",
      "    val_loss       : -358.62628389550196\n",
      "    val_log_likelihood: 614.2565690116173\n",
      "    val_log_marginal: 380.76600760043954\n",
      "Train Epoch: 157 [512/17352 (3%)] Loss: -428.312469\n",
      "Train Epoch: 157 [10224/17352 (59%)] Loss: -449.808849\n",
      "Train Epoch: 157 [17263/17352 (99%)] Loss: -446.923673\n",
      "    epoch          : 157\n",
      "    loss           : -397.4249784807057\n",
      "    val_loss       : -362.30677819892463\n",
      "    val_log_likelihood: 628.7131295761047\n",
      "    val_log_marginal: 397.99039607234585\n",
      "Train Epoch: 158 [512/17352 (3%)] Loss: -447.107300\n",
      "Train Epoch: 158 [10198/17352 (59%)] Loss: -485.479866\n",
      "Train Epoch: 158 [16934/17352 (98%)] Loss: -420.204756\n",
      "    epoch          : 158\n",
      "    loss           : -412.57813465769163\n",
      "    val_loss       : -380.9451919004081\n",
      "    val_log_likelihood: 644.4419719854668\n",
      "    val_log_marginal: 408.4159806992968\n",
      "Train Epoch: 159 [512/17352 (3%)] Loss: -456.975372\n",
      "Train Epoch: 159 [10389/17352 (60%)] Loss: -448.512254\n",
      "Train Epoch: 159 [17090/17352 (98%)] Loss: -392.614909\n",
      "    epoch          : 159\n",
      "    loss           : -417.5264210769007\n",
      "    val_loss       : -385.615938469741\n",
      "    val_log_likelihood: 650.8203884854128\n",
      "    val_log_marginal: 409.78574398469965\n",
      "Train Epoch: 160 [512/17352 (3%)] Loss: -455.290527\n",
      "Train Epoch: 160 [10713/17352 (62%)] Loss: -499.384954\n",
      "Train Epoch: 160 [17335/17352 (100%)] Loss: -425.687407\n",
      "    epoch          : 160\n",
      "    loss           : -423.1883941256988\n",
      "    val_loss       : -359.64462316589606\n",
      "    val_log_likelihood: 641.7186034216644\n",
      "    val_log_marginal: 386.6431092519379\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch160.pth ...\n",
      "Train Epoch: 161 [512/17352 (3%)] Loss: -432.214355\n",
      "Train Epoch: 161 [10233/17352 (59%)] Loss: -315.537593\n",
      "Train Epoch: 161 [17106/17352 (99%)] Loss: -488.705959\n",
      "    epoch          : 161\n",
      "    loss           : -418.94493511211476\n",
      "    val_loss       : -389.3606226447666\n",
      "    val_log_likelihood: 654.1827625072019\n",
      "    val_log_marginal: 414.2846474459169\n",
      "Train Epoch: 162 [512/17352 (3%)] Loss: -472.968567\n",
      "Train Epoch: 162 [9927/17352 (57%)] Loss: -376.162044\n",
      "Train Epoch: 162 [16878/17352 (97%)] Loss: -489.250145\n",
      "    epoch          : 162\n",
      "    loss           : -430.3054190276105\n",
      "    val_loss       : -404.0752637685722\n",
      "    val_log_likelihood: 657.7323619085018\n",
      "    val_log_marginal: 423.50199893175403\n",
      "Train Epoch: 163 [512/17352 (3%)] Loss: -477.361023\n",
      "Train Epoch: 163 [10028/17352 (58%)] Loss: -507.075312\n",
      "Train Epoch: 163 [17106/17352 (99%)] Loss: -419.290810\n",
      "    epoch          : 163\n",
      "    loss           : -439.6692265513864\n",
      "    val_loss       : -402.92973350555525\n",
      "    val_log_likelihood: 672.1152381240182\n",
      "    val_log_marginal: 424.9863864698538\n",
      "Train Epoch: 164 [512/17352 (3%)] Loss: -477.126892\n",
      "Train Epoch: 164 [10314/17352 (59%)] Loss: -506.982041\n",
      "Train Epoch: 164 [16958/17352 (98%)] Loss: -465.829795\n",
      "    epoch          : 164\n",
      "    loss           : -435.51747062851507\n",
      "    val_loss       : -344.3412178167832\n",
      "    val_log_likelihood: 672.4723947904741\n",
      "    val_log_marginal: 367.59496231826745\n",
      "Train Epoch: 165 [512/17352 (3%)] Loss: -414.584656\n",
      "Train Epoch: 165 [10989/17352 (63%)] Loss: -258.946673\n",
      "Train Epoch: 165 [17253/17352 (99%)] Loss: -502.779059\n",
      "    epoch          : 165\n",
      "    loss           : -400.975590721048\n",
      "    val_loss       : -388.54633568024354\n",
      "    val_log_likelihood: 668.4853124606378\n",
      "    val_log_marginal: 408.38834222823385\n",
      "Train Epoch: 166 [512/17352 (3%)] Loss: -465.596985\n",
      "Train Epoch: 166 [10688/17352 (62%)] Loss: -297.923118\n",
      "Train Epoch: 166 [16992/17352 (98%)] Loss: -234.839021\n",
      "    epoch          : 166\n",
      "    loss           : -408.628419297886\n",
      "    val_loss       : -378.88993527025144\n",
      "    val_log_likelihood: 662.8933257951822\n",
      "    val_log_marginal: 418.10604054027266\n",
      "Train Epoch: 167 [512/17352 (3%)] Loss: -415.682800\n",
      "Train Epoch: 167 [10185/17352 (59%)] Loss: -372.350827\n",
      "Train Epoch: 167 [17108/17352 (99%)] Loss: -492.999501\n",
      "    epoch          : 167\n",
      "    loss           : -434.70381285134965\n",
      "    val_loss       : -412.2870274984289\n",
      "    val_log_likelihood: 677.3423778283241\n",
      "    val_log_marginal: 432.16500050775494\n",
      "Train Epoch: 168 [512/17352 (3%)] Loss: -443.508850\n",
      "Train Epoch: 168 [10009/17352 (58%)] Loss: -419.662077\n",
      "Train Epoch: 168 [16887/17352 (97%)] Loss: -538.164161\n",
      "    epoch          : 168\n",
      "    loss           : -455.47182187428814\n",
      "    val_loss       : -415.3795883269244\n",
      "    val_log_likelihood: 690.949407152004\n",
      "    val_log_marginal: 437.3872164130271\n",
      "Train Epoch: 169 [512/17352 (3%)] Loss: -479.125031\n",
      "Train Epoch: 169 [10294/17352 (59%)] Loss: -487.022299\n",
      "Train Epoch: 169 [17277/17352 (100%)] Loss: -432.126030\n",
      "    epoch          : 169\n",
      "    loss           : -457.5486927872585\n",
      "    val_loss       : -420.9312755677585\n",
      "    val_log_likelihood: 694.2198009175066\n",
      "    val_log_marginal: 434.5541776430918\n",
      "Train Epoch: 170 [512/17352 (3%)] Loss: -484.968201\n",
      "Train Epoch: 170 [9905/17352 (57%)] Loss: -454.307055\n",
      "Train Epoch: 170 [16883/17352 (97%)] Loss: -444.422286\n",
      "    epoch          : 170\n",
      "    loss           : -463.6207289072033\n",
      "    val_loss       : -431.42760747440343\n",
      "    val_log_likelihood: 704.1344498202659\n",
      "    val_log_marginal: 450.6443780922779\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch170.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 171 [512/17352 (3%)] Loss: -494.559448\n",
      "Train Epoch: 171 [10647/17352 (61%)] Loss: -513.601068\n",
      "Train Epoch: 171 [17335/17352 (100%)] Loss: -508.751183\n",
      "    epoch          : 171\n",
      "    loss           : -465.21081608267565\n",
      "    val_loss       : -419.90243568704443\n",
      "    val_log_likelihood: 705.1320128132843\n",
      "    val_log_marginal: 446.11992281292476\n",
      "Train Epoch: 172 [512/17352 (3%)] Loss: -499.606445\n",
      "Train Epoch: 172 [10221/17352 (59%)] Loss: -502.658532\n",
      "Train Epoch: 172 [17090/17352 (98%)] Loss: -448.643928\n",
      "    epoch          : 172\n",
      "    loss           : -469.0360225341602\n",
      "    val_loss       : -425.50383725795126\n",
      "    val_log_likelihood: 714.510946102201\n",
      "    val_log_marginal: 453.6639244865024\n",
      "Train Epoch: 173 [512/17352 (3%)] Loss: -480.190491\n",
      "Train Epoch: 173 [10704/17352 (62%)] Loss: -401.961498\n",
      "Train Epoch: 173 [16939/17352 (98%)] Loss: -366.536475\n",
      "    epoch          : 173\n",
      "    loss           : -451.29437820109683\n",
      "    val_loss       : -407.9650187463996\n",
      "    val_log_likelihood: 704.3977286406509\n",
      "    val_log_marginal: 436.31924910113605\n",
      "Train Epoch: 174 [512/17352 (3%)] Loss: -480.972137\n",
      "Train Epoch: 174 [10370/17352 (60%)] Loss: -381.585333\n",
      "Train Epoch: 174 [17044/17352 (98%)] Loss: -342.382649\n",
      "    epoch          : 174\n",
      "    loss           : -451.4709759131305\n",
      "    val_loss       : -418.64033229372234\n",
      "    val_log_likelihood: 709.2913657204463\n",
      "    val_log_marginal: 446.8441663782671\n",
      "Train Epoch: 175 [512/17352 (3%)] Loss: -481.571686\n",
      "Train Epoch: 175 [10177/17352 (59%)] Loss: -576.741265\n",
      "Train Epoch: 175 [17016/17352 (98%)] Loss: -325.742150\n",
      "    epoch          : 175\n",
      "    loss           : -461.24396748699513\n",
      "    val_loss       : -421.19486948675967\n",
      "    val_log_likelihood: 715.340149860701\n",
      "    val_log_marginal: 444.58343145038924\n",
      "Train Epoch: 176 [512/17352 (3%)] Loss: -475.508423\n",
      "Train Epoch: 176 [10501/17352 (61%)] Loss: -442.896998\n",
      "Train Epoch: 176 [17044/17352 (98%)] Loss: -408.954948\n",
      "    epoch          : 176\n",
      "    loss           : -460.760326695275\n",
      "    val_loss       : -425.375981389779\n",
      "    val_log_likelihood: 722.5808614375658\n",
      "    val_log_marginal: 454.1318012628191\n",
      "Train Epoch: 177 [512/17352 (3%)] Loss: -507.161011\n",
      "Train Epoch: 177 [10324/17352 (59%)] Loss: -431.144394\n",
      "Train Epoch: 177 [16878/17352 (97%)] Loss: -332.140371\n",
      "    epoch          : 177\n",
      "    loss           : -467.96782951412047\n",
      "    val_loss       : -424.13537410096376\n",
      "    val_log_likelihood: 721.2039487821309\n",
      "    val_log_marginal: 443.7219836482373\n",
      "Train Epoch: 178 [512/17352 (3%)] Loss: -493.810211\n",
      "Train Epoch: 178 [9552/17352 (55%)] Loss: -481.069706\n",
      "Train Epoch: 178 [17044/17352 (98%)] Loss: -449.271243\n",
      "    epoch          : 178\n",
      "    loss           : -457.81812149809736\n",
      "    val_loss       : -404.2624918768024\n",
      "    val_log_likelihood: 711.9656281809224\n",
      "    val_log_marginal: 439.8872073526585\n",
      "Train Epoch: 179 [512/17352 (3%)] Loss: -472.707336\n",
      "Train Epoch: 179 [9716/17352 (56%)] Loss: -284.864401\n",
      "Train Epoch: 179 [16923/17352 (98%)] Loss: -268.378427\n",
      "    epoch          : 179\n",
      "    loss           : -430.63188628621725\n",
      "    val_loss       : -414.25810525584507\n",
      "    val_log_likelihood: 715.1556414354956\n",
      "    val_log_marginal: 448.05684659225074\n",
      "Train Epoch: 180 [512/17352 (3%)] Loss: -512.400085\n",
      "Train Epoch: 180 [10323/17352 (59%)] Loss: -430.788845\n",
      "Train Epoch: 180 [16878/17352 (97%)] Loss: -439.852493\n",
      "    epoch          : 180\n",
      "    loss           : -472.0713769646993\n",
      "    val_loss       : -441.8488502280097\n",
      "    val_log_likelihood: 731.9643249001689\n",
      "    val_log_marginal: 463.7415131683044\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch180.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 181 [512/17352 (3%)] Loss: -521.402954\n",
      "Train Epoch: 181 [10979/17352 (63%)] Loss: -389.108189\n",
      "Train Epoch: 181 [17101/17352 (99%)] Loss: -534.312085\n",
      "    epoch          : 181\n",
      "    loss           : -491.5465310583048\n",
      "    val_loss       : -456.0140080016858\n",
      "    val_log_likelihood: 743.5398198927603\n",
      "    val_log_marginal: 477.9573625029025\n",
      "Train Epoch: 182 [512/17352 (3%)] Loss: -539.571167\n",
      "Train Epoch: 182 [10574/17352 (61%)] Loss: -385.933746\n",
      "Train Epoch: 182 [17064/17352 (98%)] Loss: -521.923649\n",
      "    epoch          : 182\n",
      "    loss           : -495.9809609665982\n",
      "    val_loss       : -445.22019357194694\n",
      "    val_log_likelihood: 742.341329092034\n",
      "    val_log_marginal: 469.79399045194685\n",
      "Train Epoch: 183 [512/17352 (3%)] Loss: -541.976807\n",
      "Train Epoch: 183 [10037/17352 (58%)] Loss: -560.461198\n",
      "Train Epoch: 183 [17016/17352 (98%)] Loss: -530.375944\n",
      "    epoch          : 183\n",
      "    loss           : -496.11189845135755\n",
      "    val_loss       : -459.6644727863964\n",
      "    val_log_likelihood: 749.7362536073024\n",
      "    val_log_marginal: 482.2740804925371\n",
      "Train Epoch: 184 [512/17352 (3%)] Loss: -559.344116\n",
      "Train Epoch: 184 [10887/17352 (63%)] Loss: -572.783537\n",
      "Train Epoch: 184 [16922/17352 (98%)] Loss: -583.545437\n",
      "    epoch          : 184\n",
      "    loss           : -491.0377998647619\n",
      "    val_loss       : -454.7657338176127\n",
      "    val_log_likelihood: 749.3935257647144\n",
      "    val_log_marginal: 475.0609402053861\n",
      "Train Epoch: 185 [512/17352 (3%)] Loss: -534.236938\n",
      "Train Epoch: 185 [10610/17352 (61%)] Loss: -587.428602\n",
      "Train Epoch: 185 [17049/17352 (98%)] Loss: -517.922809\n",
      "    epoch          : 185\n",
      "    loss           : -459.4271248261262\n",
      "    val_loss       : -393.4291121474552\n",
      "    val_log_likelihood: 731.6018513879825\n",
      "    val_log_marginal: 417.7843805047711\n",
      "Train Epoch: 186 [512/17352 (3%)] Loss: -474.172516\n",
      "Train Epoch: 186 [10702/17352 (62%)] Loss: -283.075874\n",
      "Train Epoch: 186 [17335/17352 (100%)] Loss: -545.422508\n",
      "    epoch          : 186\n",
      "    loss           : -449.04158811539963\n",
      "    val_loss       : -312.9142377489926\n",
      "    val_log_likelihood: 724.4193462132502\n",
      "    val_log_marginal: 342.56025365285694\n",
      "Train Epoch: 187 [512/17352 (3%)] Loss: -202.713837\n",
      "Train Epoch: 187 [10159/17352 (59%)] Loss: -372.309896\n",
      "Train Epoch: 187 [17090/17352 (98%)] Loss: -429.289854\n",
      "    epoch          : 187\n",
      "    loss           : -437.6401135054028\n",
      "    val_loss       : -425.5476027824895\n",
      "    val_log_likelihood: 744.6440657685732\n",
      "    val_log_marginal: 450.2287065484192\n",
      "Train Epoch: 188 [512/17352 (3%)] Loss: -505.300446\n",
      "Train Epoch: 188 [10272/17352 (59%)] Loss: -400.851594\n",
      "Train Epoch: 188 [17263/17352 (99%)] Loss: -277.793941\n",
      "    epoch          : 188\n",
      "    loss           : -394.3626658466183\n",
      "    val_loss       : -164.81758023634964\n",
      "    val_log_likelihood: 685.8517723784261\n",
      "    val_log_marginal: 229.5226740241155\n",
      "Train Epoch: 189 [512/17352 (3%)] Loss: -241.680023\n",
      "Train Epoch: 189 [9805/17352 (57%)] Loss: -190.007374\n",
      "Train Epoch: 189 [17090/17352 (98%)] Loss: -563.902088\n",
      "    epoch          : 189\n",
      "    loss           : -383.6565621231483\n",
      "    val_loss       : -310.52581784601637\n",
      "    val_log_likelihood: 688.1124034512407\n",
      "    val_log_marginal: 340.4537553649133\n",
      "Train Epoch: 190 [512/17352 (3%)] Loss: -369.162720\n",
      "Train Epoch: 190 [10576/17352 (61%)] Loss: -313.591772\n",
      "Train Epoch: 190 [17143/17352 (99%)] Loss: -284.916303\n",
      "    epoch          : 190\n",
      "    loss           : -374.1662081963792\n",
      "    val_loss       : -112.14139039411873\n",
      "    val_log_likelihood: 684.6475055197368\n",
      "    val_log_marginal: 167.5239948318957\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch190.pth ...\n",
      "Train Epoch: 191 [512/17352 (3%)] Loss: -120.013878\n",
      "Train Epoch: 191 [10501/17352 (61%)] Loss: -112.949548\n",
      "Train Epoch: 191 [16934/17352 (98%)] Loss: -468.726458\n",
      "    epoch          : 191\n",
      "    loss           : -293.69322393128806\n",
      "    val_loss       : -366.7105570910844\n",
      "    val_log_likelihood: 677.9635334018469\n",
      "    val_log_marginal: 401.4747030286711\n",
      "Train Epoch: 192 [512/17352 (3%)] Loss: -384.587280\n",
      "Train Epoch: 192 [10085/17352 (58%)] Loss: -521.237413\n",
      "Train Epoch: 192 [17101/17352 (99%)] Loss: -382.495050\n",
      "    epoch          : 192\n",
      "    loss           : -450.66788056097016\n",
      "    val_loss       : -433.3305447606128\n",
      "    val_log_likelihood: 734.3971149973563\n",
      "    val_log_marginal: 462.7891659312492\n",
      "Train Epoch: 193 [512/17352 (3%)] Loss: -502.453156\n",
      "Train Epoch: 193 [9797/17352 (56%)] Loss: -349.154133\n",
      "Train Epoch: 193 [17016/17352 (98%)] Loss: -460.135330\n",
      "    epoch          : 193\n",
      "    loss           : -497.5704342457715\n",
      "    val_loss       : -457.1040855441955\n",
      "    val_log_likelihood: 750.9311569271833\n",
      "    val_log_marginal: 480.48711232021094\n",
      "Train Epoch: 194 [512/17352 (3%)] Loss: -550.574646\n",
      "Train Epoch: 194 [10640/17352 (61%)] Loss: -450.606589\n",
      "Train Epoch: 194 [16958/17352 (98%)] Loss: -550.145650\n",
      "    epoch          : 194\n",
      "    loss           : -494.7476702439671\n",
      "    val_loss       : -462.449383757737\n",
      "    val_log_likelihood: 752.6090917102695\n",
      "    val_log_marginal: 487.42746619360184\n",
      "Train Epoch: 195 [512/17352 (3%)] Loss: -539.695251\n",
      "Train Epoch: 195 [10833/17352 (62%)] Loss: -471.515842\n",
      "Train Epoch: 195 [17064/17352 (98%)] Loss: -459.291073\n",
      "    epoch          : 195\n",
      "    loss           : -507.5788153937212\n",
      "    val_loss       : -461.5375431012905\n",
      "    val_log_likelihood: 759.9897992843194\n",
      "    val_log_marginal: 485.86359950952226\n",
      "Train Epoch: 196 [512/17352 (3%)] Loss: -558.799561\n",
      "Train Epoch: 196 [10700/17352 (62%)] Loss: -582.893718\n",
      "Train Epoch: 196 [16883/17352 (97%)] Loss: -441.419193\n",
      "    epoch          : 196\n",
      "    loss           : -519.2608313873693\n",
      "    val_loss       : -484.0165310474557\n",
      "    val_log_likelihood: 782.9144966319498\n",
      "    val_log_marginal: 507.20447931050353\n",
      "Train Epoch: 197 [512/17352 (3%)] Loss: -422.945190\n",
      "Train Epoch: 197 [10695/17352 (62%)] Loss: -600.027245\n",
      "Train Epoch: 197 [17044/17352 (98%)] Loss: -446.138980\n",
      "    epoch          : 197\n",
      "    loss           : -528.8654205136286\n",
      "    val_loss       : -487.7522564961413\n",
      "    val_log_likelihood: 779.6550876370899\n",
      "    val_log_marginal: 505.19959566664085\n",
      "Train Epoch: 198 [512/17352 (3%)] Loss: -559.042114\n",
      "Train Epoch: 198 [10544/17352 (61%)] Loss: -434.195731\n",
      "Train Epoch: 198 [17106/17352 (99%)] Loss: -551.019991\n",
      "    epoch          : 198\n",
      "    loss           : -536.2254734124135\n",
      "    val_loss       : -472.0632380718362\n",
      "    val_log_likelihood: 782.6352821626766\n",
      "    val_log_marginal: 499.30054356872523\n",
      "Train Epoch: 199 [512/17352 (3%)] Loss: -550.128540\n",
      "Train Epoch: 199 [10566/17352 (61%)] Loss: -605.575435\n",
      "Train Epoch: 199 [17153/17352 (99%)] Loss: -454.454471\n",
      "    epoch          : 199\n",
      "    loss           : -535.0483062415923\n",
      "    val_loss       : -475.71961850255065\n",
      "    val_log_likelihood: 781.105315942087\n",
      "    val_log_marginal: 499.51024192778766\n",
      "Train Epoch: 200 [512/17352 (3%)] Loss: -566.784851\n",
      "Train Epoch: 200 [10698/17352 (62%)] Loss: -381.596965\n",
      "Train Epoch: 200 [17143/17352 (99%)] Loss: -626.524771\n",
      "    epoch          : 200\n",
      "    loss           : -530.8425132428298\n",
      "    val_loss       : -487.2245603030468\n",
      "    val_log_likelihood: 796.6913911239955\n",
      "    val_log_marginal: 513.6357164512864\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch200.pth ...\n",
      "Train Epoch: 201 [512/17352 (3%)] Loss: -578.843689\n",
      "Train Epoch: 201 [9953/17352 (57%)] Loss: -565.735184\n",
      "Train Epoch: 201 [16958/17352 (98%)] Loss: -564.370052\n",
      "    epoch          : 201\n",
      "    loss           : -543.4447123020047\n",
      "    val_loss       : -490.18790950490614\n",
      "    val_log_likelihood: 794.8760860251806\n",
      "    val_log_marginal: 509.859922114909\n",
      "Train Epoch: 202 [512/17352 (3%)] Loss: -598.448425\n",
      "Train Epoch: 202 [10182/17352 (59%)] Loss: -450.329208\n",
      "Train Epoch: 202 [16988/17352 (98%)] Loss: -581.883158\n",
      "    epoch          : 202\n",
      "    loss           : -548.2006400161353\n",
      "    val_loss       : -503.0550972572773\n",
      "    val_log_likelihood: 796.4324463381281\n",
      "    val_log_marginal: 522.4622284070957\n",
      "Train Epoch: 203 [512/17352 (3%)] Loss: -600.035522\n",
      "Train Epoch: 203 [10119/17352 (58%)] Loss: -443.356642\n",
      "Train Epoch: 203 [16988/17352 (98%)] Loss: -582.485945\n",
      "    epoch          : 203\n",
      "    loss           : -548.4644019465334\n",
      "    val_loss       : -493.39528408455186\n",
      "    val_log_likelihood: 803.6066892582088\n",
      "    val_log_marginal: 519.4048845724777\n",
      "Train Epoch: 204 [512/17352 (3%)] Loss: -583.711365\n",
      "Train Epoch: 204 [10041/17352 (58%)] Loss: -503.557786\n",
      "Train Epoch: 204 [17049/17352 (98%)] Loss: -557.069466\n",
      "    epoch          : 204\n",
      "    loss           : -539.9556326321517\n",
      "    val_loss       : -430.9915304080213\n",
      "    val_log_likelihood: 794.8606951114303\n",
      "    val_log_marginal: 504.27457341642\n",
      "Train Epoch: 205 [512/17352 (3%)] Loss: -501.576111\n",
      "Train Epoch: 205 [10342/17352 (60%)] Loss: -610.624809\n",
      "Train Epoch: 205 [16922/17352 (98%)] Loss: -542.914779\n",
      "    epoch          : 205\n",
      "    loss           : -509.01357092895057\n",
      "    val_loss       : -470.51481672839793\n",
      "    val_log_likelihood: 801.3937047399097\n",
      "    val_log_marginal: 507.2715923371234\n",
      "Train Epoch: 206 [512/17352 (3%)] Loss: -588.775879\n",
      "Train Epoch: 206 [10225/17352 (59%)] Loss: -419.042131\n",
      "Train Epoch: 206 [16958/17352 (98%)] Loss: -616.427239\n",
      "    epoch          : 206\n",
      "    loss           : -521.5598760363522\n",
      "    val_loss       : -484.4348320728301\n",
      "    val_log_likelihood: 795.0489031043022\n",
      "    val_log_marginal: 509.9970506416764\n",
      "Train Epoch: 207 [512/17352 (3%)] Loss: -556.348022\n",
      "Train Epoch: 207 [10012/17352 (58%)] Loss: -442.719260\n",
      "Train Epoch: 207 [17133/17352 (99%)] Loss: -631.466755\n",
      "    epoch          : 207\n",
      "    loss           : -520.1188473038601\n",
      "    val_loss       : -486.93713482148615\n",
      "    val_log_likelihood: 799.3064425591142\n",
      "    val_log_marginal: 509.56735779410224\n",
      "Train Epoch: 208 [512/17352 (3%)] Loss: -583.734436\n",
      "Train Epoch: 208 [10414/17352 (60%)] Loss: -568.784363\n",
      "Train Epoch: 208 [16878/17352 (97%)] Loss: -519.939357\n",
      "    epoch          : 208\n",
      "    loss           : -538.3874411148374\n",
      "    val_loss       : -499.882358574088\n",
      "    val_log_likelihood: 815.7375138716438\n",
      "    val_log_marginal: 520.205658231435\n",
      "Train Epoch: 209 [512/17352 (3%)] Loss: -589.092102\n",
      "Train Epoch: 209 [10310/17352 (59%)] Loss: -494.489995\n",
      "Train Epoch: 209 [17277/17352 (100%)] Loss: -508.911198\n",
      "    epoch          : 209\n",
      "    loss           : -545.4682399085027\n",
      "    val_loss       : -451.6751481651483\n",
      "    val_log_likelihood: 806.9333999350307\n",
      "    val_log_marginal: 478.71875186421084\n",
      "Train Epoch: 210 [512/17352 (3%)] Loss: -529.697998\n",
      "Train Epoch: 210 [10299/17352 (59%)] Loss: -636.871189\n",
      "Train Epoch: 210 [16922/17352 (98%)] Loss: -476.350722\n",
      "    epoch          : 210\n",
      "    loss           : -524.4278754849746\n",
      "    val_loss       : -443.60890143791374\n",
      "    val_log_likelihood: 810.3477800017428\n",
      "    val_log_marginal: 465.6932225575488\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch210.pth ...\n",
      "Train Epoch: 211 [512/17352 (3%)] Loss: -531.278015\n",
      "Train Epoch: 211 [10545/17352 (61%)] Loss: -589.545606\n",
      "Train Epoch: 211 [17153/17352 (99%)] Loss: -617.299446\n",
      "    epoch          : 211\n",
      "    loss           : -523.6798285666067\n",
      "    val_loss       : -422.67414641009367\n",
      "    val_log_likelihood: 799.4974689407618\n",
      "    val_log_marginal: 447.7155115677473\n",
      "Train Epoch: 212 [512/17352 (3%)] Loss: -549.122864\n",
      "Train Epoch: 212 [10227/17352 (59%)] Loss: -589.856093\n",
      "Train Epoch: 212 [16958/17352 (98%)] Loss: -619.547135\n",
      "    epoch          : 212\n",
      "    loss           : -537.866348581749\n",
      "    val_loss       : -496.9529793656222\n",
      "    val_log_likelihood: 816.0017514873264\n",
      "    val_log_marginal: 525.2886241510683\n",
      "Train Epoch: 213 [512/17352 (3%)] Loss: -598.569153\n",
      "Train Epoch: 213 [10207/17352 (59%)] Loss: -516.959156\n",
      "Train Epoch: 213 [17016/17352 (98%)] Loss: -527.021772\n",
      "    epoch          : 213\n",
      "    loss           : -565.4441593355356\n",
      "    val_loss       : -494.2511932794956\n",
      "    val_log_likelihood: 824.9270061328752\n",
      "    val_log_marginal: 530.6206847641934\n",
      "Train Epoch: 214 [512/17352 (3%)] Loss: -607.157654\n",
      "Train Epoch: 214 [10357/17352 (60%)] Loss: -678.528863\n",
      "Train Epoch: 214 [17106/17352 (99%)] Loss: -455.749381\n",
      "    epoch          : 214\n",
      "    loss           : -567.863369726363\n",
      "    val_loss       : -502.164993405871\n",
      "    val_log_likelihood: 836.7799458657162\n",
      "    val_log_marginal: 528.0657005744538\n",
      "Train Epoch: 215 [512/17352 (3%)] Loss: -588.876892\n",
      "Train Epoch: 215 [10332/17352 (60%)] Loss: -610.228567\n",
      "Train Epoch: 215 [17153/17352 (99%)] Loss: -621.001458\n",
      "    epoch          : 215\n",
      "    loss           : -566.5653450955842\n",
      "    val_loss       : -463.02919031866395\n",
      "    val_log_likelihood: 830.2908991357167\n",
      "    val_log_marginal: 477.89625451887025\n",
      "Train Epoch: 216 [512/17352 (3%)] Loss: -533.641846\n",
      "Train Epoch: 216 [10384/17352 (60%)] Loss: -543.719108\n",
      "Train Epoch: 216 [17064/17352 (98%)] Loss: -292.742823\n",
      "    epoch          : 216\n",
      "    loss           : -418.16904378731647\n",
      "    val_loss       : -216.5816953242809\n",
      "    val_log_likelihood: 732.8539958553356\n",
      "    val_log_marginal: 249.29584933007007\n",
      "Train Epoch: 217 [512/17352 (3%)] Loss: -275.769470\n",
      "Train Epoch: 217 [10585/17352 (61%)] Loss: -182.983333\n",
      "Train Epoch: 217 [16934/17352 (98%)] Loss: -454.505123\n",
      "    epoch          : 217\n",
      "    loss           : -418.16109264673065\n",
      "    val_loss       : -400.02762181314716\n",
      "    val_log_likelihood: 761.4898485255225\n",
      "    val_log_marginal: 440.9600330806164\n",
      "Train Epoch: 218 [512/17352 (3%)] Loss: -517.708313\n",
      "Train Epoch: 218 [10658/17352 (61%)] Loss: -646.652996\n",
      "Train Epoch: 218 [17335/17352 (100%)] Loss: -604.707477\n",
      "    epoch          : 218\n",
      "    loss           : -527.3092079281512\n",
      "    val_loss       : -477.8374665278229\n",
      "    val_log_likelihood: 812.0313123752218\n",
      "    val_log_marginal: 505.82170940356093\n",
      "Train Epoch: 219 [512/17352 (3%)] Loss: -577.740601\n",
      "Train Epoch: 219 [10355/17352 (60%)] Loss: -634.844004\n",
      "Train Epoch: 219 [16957/17352 (98%)] Loss: -591.831720\n",
      "    epoch          : 219\n",
      "    loss           : -545.9160133845337\n",
      "    val_loss       : -458.38375607977906\n",
      "    val_log_likelihood: 806.9696927971567\n",
      "    val_log_marginal: 496.61750775477265\n",
      "Train Epoch: 220 [512/17352 (3%)] Loss: -348.246399\n",
      "Train Epoch: 220 [10353/17352 (60%)] Loss: -470.897578\n",
      "Train Epoch: 220 [16958/17352 (98%)] Loss: -369.583807\n",
      "    epoch          : 220\n",
      "    loss           : -531.7732282395972\n",
      "    val_loss       : -481.9444924359656\n",
      "    val_log_likelihood: 815.879761679976\n",
      "    val_log_marginal: 508.00481684999573\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch220.pth ...\n",
      "Train Epoch: 221 [512/17352 (3%)] Loss: -565.189941\n",
      "Train Epoch: 221 [10454/17352 (60%)] Loss: -542.628949\n",
      "Train Epoch: 221 [17277/17352 (100%)] Loss: -599.023095\n",
      "    epoch          : 221\n",
      "    loss           : -546.2166803862553\n",
      "    val_loss       : -461.0640637493051\n",
      "    val_log_likelihood: 802.5373775360891\n",
      "    val_log_marginal: 490.1107521679485\n",
      "Train Epoch: 222 [512/17352 (3%)] Loss: -593.975708\n",
      "Train Epoch: 222 [10246/17352 (59%)] Loss: -599.861190\n",
      "Train Epoch: 222 [17106/17352 (99%)] Loss: -463.171875\n",
      "    epoch          : 222\n",
      "    loss           : -564.413806248806\n",
      "    val_loss       : -516.9193976098741\n",
      "    val_log_likelihood: 842.9238248571987\n",
      "    val_log_marginal: 543.6135666450521\n",
      "Train Epoch: 223 [512/17352 (3%)] Loss: -628.743530\n",
      "Train Epoch: 223 [9996/17352 (58%)] Loss: -543.649974\n",
      "Train Epoch: 223 [17044/17352 (98%)] Loss: -549.543381\n",
      "    epoch          : 223\n",
      "    loss           : -584.8563366372799\n",
      "    val_loss       : -524.3161599025442\n",
      "    val_log_likelihood: 855.3234255009373\n",
      "    val_log_marginal: 551.5481264628532\n",
      "Train Epoch: 224 [512/17352 (3%)] Loss: -634.130554\n",
      "Train Epoch: 224 [10772/17352 (62%)] Loss: -709.410102\n",
      "Train Epoch: 224 [17153/17352 (99%)] Loss: -616.846792\n",
      "    epoch          : 224\n",
      "    loss           : -577.7703650580681\n",
      "    val_loss       : -499.95815739972926\n",
      "    val_log_likelihood: 842.6175523656119\n",
      "    val_log_marginal: 532.0560320351076\n",
      "Train Epoch: 225 [512/17352 (3%)] Loss: -611.124268\n",
      "Train Epoch: 225 [10393/17352 (60%)] Loss: -689.187954\n",
      "Train Epoch: 225 [16958/17352 (98%)] Loss: -622.867810\n",
      "    epoch          : 225\n",
      "    loss           : -560.3880138315566\n",
      "    val_loss       : -487.0199180638805\n",
      "    val_log_likelihood: 828.7741495911253\n",
      "    val_log_marginal: 516.0700319639099\n",
      "Train Epoch: 226 [512/17352 (3%)] Loss: -604.788147\n",
      "Train Epoch: 226 [10062/17352 (58%)] Loss: -500.859951\n",
      "Train Epoch: 226 [17126/17352 (99%)] Loss: -446.236160\n",
      "    epoch          : 226\n",
      "    loss           : -559.9682738984211\n",
      "    val_loss       : -485.9278797099529\n",
      "    val_log_likelihood: 844.1180684758011\n",
      "    val_log_marginal: 518.3949862126804\n",
      "Train Epoch: 227 [512/17352 (3%)] Loss: -586.248474\n",
      "Train Epoch: 227 [9957/17352 (57%)] Loss: -610.447384\n",
      "Train Epoch: 227 [16934/17352 (98%)] Loss: -554.503534\n",
      "    epoch          : 227\n",
      "    loss           : -565.5638126616252\n",
      "    val_loss       : -510.6902254704953\n",
      "    val_log_likelihood: 851.3292971445486\n",
      "    val_log_marginal: 539.4385769913355\n",
      "Train Epoch: 228 [512/17352 (3%)] Loss: -629.993835\n",
      "Train Epoch: 228 [9632/17352 (56%)] Loss: -523.937500\n",
      "Train Epoch: 228 [16957/17352 (98%)] Loss: -555.190170\n",
      "    epoch          : 228\n",
      "    loss           : -542.6682326484721\n",
      "    val_loss       : -473.3068989465941\n",
      "    val_log_likelihood: 840.482053243404\n",
      "    val_log_marginal: 519.2563869981352\n",
      "Train Epoch: 229 [512/17352 (3%)] Loss: -565.590698\n",
      "Train Epoch: 229 [10441/17352 (60%)] Loss: -589.967448\n",
      "Train Epoch: 229 [17101/17352 (99%)] Loss: -524.492252\n",
      "    epoch          : 229\n",
      "    loss           : -519.6397520199895\n",
      "    val_loss       : -389.3145503109119\n",
      "    val_log_likelihood: 813.0504132789974\n",
      "    val_log_marginal: 412.8237441736562\n",
      "Train Epoch: 230 [512/17352 (3%)] Loss: -414.202942\n",
      "Train Epoch: 230 [10330/17352 (60%)] Loss: -347.189977\n",
      "Train Epoch: 230 [17133/17352 (99%)] Loss: -442.214923\n",
      "    epoch          : 230\n",
      "    loss           : -367.9315499849774\n",
      "    val_loss       : -282.1713028832841\n",
      "    val_log_likelihood: 762.2881636463051\n",
      "    val_log_marginal: 333.59178879326157\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch230.pth ...\n",
      "Train Epoch: 231 [512/17352 (3%)] Loss: -416.148376\n",
      "Train Epoch: 231 [11012/17352 (63%)] Loss: -523.768631\n",
      "Train Epoch: 231 [17277/17352 (100%)] Loss: -508.350948\n",
      "    epoch          : 231\n",
      "    loss           : -398.19358040644005\n",
      "    val_loss       : -360.56151068274767\n",
      "    val_log_likelihood: 765.6233893799628\n",
      "    val_log_marginal: 395.21949700014494\n",
      "Train Epoch: 232 [512/17352 (3%)] Loss: -476.918152\n",
      "Train Epoch: 232 [10073/17352 (58%)] Loss: -407.558746\n",
      "Train Epoch: 232 [17253/17352 (99%)] Loss: -492.949219\n",
      "    epoch          : 232\n",
      "    loss           : -475.9867177123353\n",
      "    val_loss       : -435.9839278448168\n",
      "    val_log_likelihood: 806.4941245762473\n",
      "    val_log_marginal: 500.93796176998984\n",
      "Train Epoch: 233 [512/17352 (3%)] Loss: -567.761719\n",
      "Train Epoch: 233 [10884/17352 (63%)] Loss: -655.160638\n",
      "Train Epoch: 233 [16934/17352 (98%)] Loss: -649.005417\n",
      "    epoch          : 233\n",
      "    loss           : -551.6193052624351\n",
      "    val_loss       : -462.29200576049294\n",
      "    val_log_likelihood: 835.0210092873052\n",
      "    val_log_marginal: 531.1361438718742\n",
      "Train Epoch: 234 [512/17352 (3%)] Loss: -553.751282\n",
      "Train Epoch: 234 [10350/17352 (60%)] Loss: -562.315641\n",
      "Train Epoch: 234 [17126/17352 (99%)] Loss: -560.575820\n",
      "    epoch          : 234\n",
      "    loss           : -575.0247633205221\n",
      "    val_loss       : -514.7016371142006\n",
      "    val_log_likelihood: 852.2588222534309\n",
      "    val_log_marginal: 551.7648702816515\n",
      "Train Epoch: 235 [512/17352 (3%)] Loss: -640.092651\n",
      "Train Epoch: 235 [9620/17352 (55%)] Loss: -683.390117\n",
      "Train Epoch: 235 [17090/17352 (98%)] Loss: -446.929341\n",
      "    epoch          : 235\n",
      "    loss           : -589.5966918052596\n",
      "    val_loss       : -532.124699035355\n",
      "    val_log_likelihood: 865.957278128291\n",
      "    val_log_marginal: 561.2288346191265\n",
      "Train Epoch: 236 [512/17352 (3%)] Loss: -644.923340\n",
      "Train Epoch: 236 [10607/17352 (61%)] Loss: -456.359845\n",
      "Train Epoch: 236 [17133/17352 (99%)] Loss: -557.553400\n",
      "    epoch          : 236\n",
      "    loss           : -595.3575676476202\n",
      "    val_loss       : -531.3184545012318\n",
      "    val_log_likelihood: 866.2990786464617\n",
      "    val_log_marginal: 557.0384617453929\n",
      "Train Epoch: 237 [512/17352 (3%)] Loss: -636.873047\n",
      "Train Epoch: 237 [10445/17352 (60%)] Loss: -652.004138\n",
      "Train Epoch: 237 [16939/17352 (98%)] Loss: -685.887068\n",
      "    epoch          : 237\n",
      "    loss           : -603.9241773603625\n",
      "    val_loss       : -544.535133498081\n",
      "    val_log_likelihood: 876.5042706661632\n",
      "    val_log_marginal: 568.2185258505892\n",
      "Train Epoch: 238 [512/17352 (3%)] Loss: -655.664551\n",
      "Train Epoch: 238 [10325/17352 (60%)] Loss: -613.720467\n",
      "Train Epoch: 238 [16992/17352 (98%)] Loss: -565.155097\n",
      "    epoch          : 238\n",
      "    loss           : -606.1232374039902\n",
      "    val_loss       : -540.2421097233542\n",
      "    val_log_likelihood: 871.9172890210315\n",
      "    val_log_marginal: 564.5975332126563\n",
      "Train Epoch: 239 [512/17352 (3%)] Loss: -650.367310\n",
      "Train Epoch: 239 [9697/17352 (56%)] Loss: -654.599062\n",
      "Train Epoch: 239 [17049/17352 (98%)] Loss: -476.178080\n",
      "    epoch          : 239\n",
      "    loss           : -606.6288021554942\n",
      "    val_loss       : -542.5792433000342\n",
      "    val_log_likelihood: 882.781728281248\n",
      "    val_log_marginal: 568.228268270467\n",
      "Train Epoch: 240 [512/17352 (3%)] Loss: -631.939697\n",
      "Train Epoch: 240 [10009/17352 (58%)] Loss: -609.082847\n",
      "Train Epoch: 240 [16957/17352 (98%)] Loss: -568.084784\n",
      "    epoch          : 240\n",
      "    loss           : -613.8288315799773\n",
      "    val_loss       : -548.7056783695906\n",
      "    val_log_likelihood: 887.2195940223316\n",
      "    val_log_marginal: 572.077175193927\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch240.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 241 [512/17352 (3%)] Loss: -653.902466\n",
      "Train Epoch: 241 [9869/17352 (57%)] Loss: -688.306836\n",
      "Train Epoch: 241 [17090/17352 (98%)] Loss: -706.654920\n",
      "    epoch          : 241\n",
      "    loss           : -618.9085803342022\n",
      "    val_loss       : -553.9495780240107\n",
      "    val_log_likelihood: 882.4886594397634\n",
      "    val_log_marginal: 578.6413087377962\n",
      "Train Epoch: 242 [512/17352 (3%)] Loss: -665.504028\n",
      "Train Epoch: 242 [10960/17352 (63%)] Loss: -679.462645\n",
      "Train Epoch: 242 [17133/17352 (99%)] Loss: -572.180323\n",
      "    epoch          : 242\n",
      "    loss           : -615.0113936944829\n",
      "    val_loss       : -541.4454801667156\n",
      "    val_log_likelihood: 890.2936641610814\n",
      "    val_log_marginal: 567.2330102906822\n",
      "Train Epoch: 243 [512/17352 (3%)] Loss: -635.055298\n",
      "Train Epoch: 243 [10249/17352 (59%)] Loss: -499.901634\n",
      "Train Epoch: 243 [16992/17352 (98%)] Loss: -658.897122\n",
      "    epoch          : 243\n",
      "    loss           : -585.3248290532817\n",
      "    val_loss       : -495.154481002611\n",
      "    val_log_likelihood: 868.1710665320253\n",
      "    val_log_marginal: 539.8854362566012\n",
      "Train Epoch: 244 [512/17352 (3%)] Loss: -644.379578\n",
      "Train Epoch: 244 [10338/17352 (60%)] Loss: -576.614504\n",
      "Train Epoch: 244 [17101/17352 (99%)] Loss: -373.762560\n",
      "    epoch          : 244\n",
      "    loss           : -532.810275045114\n",
      "    val_loss       : -460.89654308084266\n",
      "    val_log_likelihood: 828.5117585485174\n",
      "    val_log_marginal: 489.3414399181404\n",
      "Train Epoch: 245 [512/17352 (3%)] Loss: -570.627136\n",
      "Train Epoch: 245 [10744/17352 (62%)] Loss: -509.746528\n",
      "Train Epoch: 245 [17335/17352 (100%)] Loss: -622.451453\n",
      "    epoch          : 245\n",
      "    loss           : -561.58769569492\n",
      "    val_loss       : -494.86856075691657\n",
      "    val_log_likelihood: 844.4657085024281\n",
      "    val_log_marginal: 524.1236207510395\n",
      "Train Epoch: 246 [512/17352 (3%)] Loss: -626.958801\n",
      "Train Epoch: 246 [10540/17352 (61%)] Loss: -666.150398\n",
      "Train Epoch: 246 [16883/17352 (97%)] Loss: -582.740132\n",
      "    epoch          : 246\n",
      "    loss           : -604.9024866434521\n",
      "    val_loss       : -550.6402510162408\n",
      "    val_log_likelihood: 883.310021572159\n",
      "    val_log_marginal: 570.1734642278567\n",
      "Train Epoch: 247 [512/17352 (3%)] Loss: -665.375488\n",
      "Train Epoch: 247 [10537/17352 (61%)] Loss: -740.918023\n",
      "Train Epoch: 247 [17049/17352 (98%)] Loss: -631.682669\n",
      "    epoch          : 247\n",
      "    loss           : -606.6166932599945\n",
      "    val_loss       : -538.6428197018289\n",
      "    val_log_likelihood: 888.629587231069\n",
      "    val_log_marginal: 564.7295087078171\n",
      "Train Epoch: 248 [512/17352 (3%)] Loss: -611.227356\n",
      "Train Epoch: 248 [10440/17352 (60%)] Loss: -592.612380\n",
      "Train Epoch: 248 [17106/17352 (99%)] Loss: 83.865926\n",
      "    epoch          : 248\n",
      "    loss           : -494.53907556296565\n",
      "    val_loss       : -248.74266522711721\n",
      "    val_log_likelihood: 829.0961463991734\n",
      "    val_log_marginal: 280.0830545514114\n",
      "Train Epoch: 249 [512/17352 (3%)] Loss: -361.302734\n",
      "Train Epoch: 249 [10397/17352 (60%)] Loss: -340.380828\n",
      "Train Epoch: 249 [16878/17352 (97%)] Loss: -632.951650\n",
      "    epoch          : 249\n",
      "    loss           : -415.42255527520865\n",
      "    val_loss       : -463.584788095619\n",
      "    val_log_likelihood: 829.0324267892137\n",
      "    val_log_marginal: 507.80263815350946\n",
      "Train Epoch: 250 [512/17352 (3%)] Loss: -588.568970\n",
      "Train Epoch: 250 [10278/17352 (59%)] Loss: -544.054845\n",
      "Train Epoch: 250 [16922/17352 (98%)] Loss: -658.918511\n",
      "    epoch          : 250\n",
      "    loss           : -551.398336221664\n",
      "    val_loss       : -518.8500540387217\n",
      "    val_log_likelihood: 868.3048549395152\n",
      "    val_log_marginal: 550.9424338613961\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch250.pth ...\n",
      "Train Epoch: 251 [512/17352 (3%)] Loss: -620.282898\n",
      "Train Epoch: 251 [10298/17352 (59%)] Loss: -392.892405\n",
      "Train Epoch: 251 [16882/17352 (97%)] Loss: -645.339552\n",
      "    epoch          : 251\n",
      "    loss           : -514.0079372717086\n",
      "    val_loss       : -465.8371175000634\n",
      "    val_log_likelihood: 841.5447411059486\n",
      "    val_log_marginal: 514.0068669749865\n",
      "Train Epoch: 252 [512/17352 (3%)] Loss: -614.198975\n",
      "Train Epoch: 252 [10009/17352 (58%)] Loss: -409.033117\n",
      "Train Epoch: 252 [17108/17352 (99%)] Loss: -679.235201\n",
      "    epoch          : 252\n",
      "    loss           : -555.7111934968706\n",
      "    val_loss       : -474.1319481293361\n",
      "    val_log_likelihood: 846.9695508852145\n",
      "    val_log_marginal: 490.98093539455755\n",
      "Train Epoch: 253 [512/17352 (3%)] Loss: -594.363159\n",
      "Train Epoch: 253 [10763/17352 (62%)] Loss: -467.915280\n",
      "Train Epoch: 253 [16883/17352 (97%)] Loss: -440.563265\n",
      "    epoch          : 253\n",
      "    loss           : -574.8694501295009\n",
      "    val_loss       : -482.5212531569991\n",
      "    val_log_likelihood: 873.4131828521419\n",
      "    val_log_marginal: 504.1358525372054\n",
      "Train Epoch: 254 [512/17352 (3%)] Loss: -596.918213\n",
      "Train Epoch: 254 [10249/17352 (59%)] Loss: -662.919062\n",
      "Train Epoch: 254 [17090/17352 (98%)] Loss: -640.926432\n",
      "    epoch          : 254\n",
      "    loss           : -587.5963937651904\n",
      "    val_loss       : -542.6533613438482\n",
      "    val_log_likelihood: 876.9081438565165\n",
      "    val_log_marginal: 564.1610480689128\n",
      "Train Epoch: 255 [512/17352 (3%)] Loss: -670.806030\n",
      "Train Epoch: 255 [10343/17352 (60%)] Loss: -715.496189\n",
      "Train Epoch: 255 [16878/17352 (97%)] Loss: -569.481207\n",
      "    epoch          : 255\n",
      "    loss           : -624.1169286870867\n",
      "    val_loss       : -549.4193113818894\n",
      "    val_log_likelihood: 889.1143168614018\n",
      "    val_log_marginal: 564.7512319796766\n",
      "Train Epoch: 256 [512/17352 (3%)] Loss: -673.618408\n",
      "Train Epoch: 256 [10577/17352 (61%)] Loss: -574.996176\n",
      "Train Epoch: 256 [16934/17352 (98%)] Loss: -705.874867\n",
      "    epoch          : 256\n",
      "    loss           : -628.0263741056664\n",
      "    val_loss       : -567.9834060951077\n",
      "    val_log_likelihood: 910.9804960748847\n",
      "    val_log_marginal: 596.3416322752375\n",
      "Train Epoch: 257 [512/17352 (3%)] Loss: -659.594788\n",
      "Train Epoch: 257 [10169/17352 (59%)] Loss: -669.545117\n",
      "Train Epoch: 257 [16958/17352 (98%)] Loss: -567.464900\n",
      "    epoch          : 257\n",
      "    loss           : -636.8311132519033\n",
      "    val_loss       : -570.5386189049979\n",
      "    val_log_likelihood: 912.3061632501232\n",
      "    val_log_marginal: 596.6927514326457\n",
      "Train Epoch: 258 [512/17352 (3%)] Loss: -685.617615\n",
      "Train Epoch: 258 [10399/17352 (60%)] Loss: -704.067031\n",
      "Train Epoch: 258 [17090/17352 (98%)] Loss: -676.697489\n",
      "    epoch          : 258\n",
      "    loss           : -629.3688259550321\n",
      "    val_loss       : -533.8585379205957\n",
      "    val_log_likelihood: 905.470247398977\n",
      "    val_log_marginal: 556.6220064204599\n",
      "Train Epoch: 259 [512/17352 (3%)] Loss: -649.093567\n",
      "Train Epoch: 259 [10687/17352 (62%)] Loss: -701.156450\n",
      "Train Epoch: 259 [16957/17352 (98%)] Loss: -593.382301\n",
      "    epoch          : 259\n",
      "    loss           : -613.1917716223066\n",
      "    val_loss       : -506.9068584737448\n",
      "    val_log_likelihood: 901.0084115255861\n",
      "    val_log_marginal: 537.8678212081535\n",
      "Train Epoch: 260 [512/17352 (3%)] Loss: -630.313721\n",
      "Train Epoch: 260 [10919/17352 (63%)] Loss: -717.491024\n",
      "Train Epoch: 260 [17124/17352 (99%)] Loss: -695.689563\n",
      "    epoch          : 260\n",
      "    loss           : -614.5861478962214\n",
      "    val_loss       : -521.3699708243117\n",
      "    val_log_likelihood: 894.4584207753317\n",
      "    val_log_marginal: 549.1988598606035\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch260.pth ...\n",
      "Train Epoch: 261 [512/17352 (3%)] Loss: -641.991455\n",
      "Train Epoch: 261 [10612/17352 (61%)] Loss: -712.721296\n",
      "Train Epoch: 261 [16878/17352 (97%)] Loss: -581.960977\n",
      "    epoch          : 261\n",
      "    loss           : -600.1713784326618\n",
      "    val_loss       : -530.2394262708483\n",
      "    val_log_likelihood: 885.4415695946391\n",
      "    val_log_marginal: 560.7583858689194\n",
      "Train Epoch: 262 [512/17352 (3%)] Loss: -600.291626\n",
      "Train Epoch: 262 [10202/17352 (59%)] Loss: -509.687407\n",
      "Train Epoch: 262 [17153/17352 (99%)] Loss: -684.901684\n",
      "    epoch          : 262\n",
      "    loss           : -582.1620714035464\n",
      "    val_loss       : -213.42276738032703\n",
      "    val_log_likelihood: 890.5655487889343\n",
      "    val_log_marginal: 244.91890924426977\n",
      "Train Epoch: 263 [512/17352 (3%)] Loss: -309.910370\n",
      "Train Epoch: 263 [10179/17352 (59%)] Loss: -551.784798\n",
      "Train Epoch: 263 [17126/17352 (99%)] Loss: -647.691889\n",
      "    epoch          : 263\n",
      "    loss           : -477.78975019779\n",
      "    val_loss       : -460.4421442573245\n",
      "    val_log_likelihood: 850.9739600375387\n",
      "    val_log_marginal: 492.2718071785062\n",
      "Train Epoch: 264 [512/17352 (3%)] Loss: -606.489990\n",
      "Train Epoch: 264 [10362/17352 (60%)] Loss: -529.151310\n",
      "Train Epoch: 264 [16988/17352 (98%)] Loss: -681.533269\n",
      "    epoch          : 264\n",
      "    loss           : -592.5209846062984\n",
      "    val_loss       : -534.2669140994844\n",
      "    val_log_likelihood: 897.4649431934748\n",
      "    val_log_marginal: 556.5395476817716\n",
      "Train Epoch: 265 [512/17352 (3%)] Loss: -488.218750\n",
      "Train Epoch: 265 [10312/17352 (59%)] Loss: -378.155502\n",
      "Train Epoch: 265 [16882/17352 (97%)] Loss: -706.095084\n",
      "    epoch          : 265\n",
      "    loss           : -616.6121991272281\n",
      "    val_loss       : -562.3282063188741\n",
      "    val_log_likelihood: 915.6173536485524\n",
      "    val_log_marginal: 587.5693032804174\n",
      "Train Epoch: 266 [512/17352 (3%)] Loss: -677.499207\n",
      "Train Epoch: 266 [10663/17352 (61%)] Loss: -603.621047\n",
      "Train Epoch: 266 [17277/17352 (100%)] Loss: -676.773320\n",
      "    epoch          : 266\n",
      "    loss           : -641.1548580555653\n",
      "    val_loss       : -533.5981923458046\n",
      "    val_log_likelihood: 910.3757184373511\n",
      "    val_log_marginal: 553.2283374177774\n",
      "Train Epoch: 267 [512/17352 (3%)] Loss: -668.990356\n",
      "Train Epoch: 267 [10243/17352 (59%)] Loss: -594.328673\n",
      "Train Epoch: 267 [17133/17352 (99%)] Loss: -575.293933\n",
      "    epoch          : 267\n",
      "    loss           : -636.0090832247184\n",
      "    val_loss       : -506.18864013669304\n",
      "    val_log_likelihood: 916.5024034603746\n",
      "    val_log_marginal: 531.7508111062153\n",
      "Train Epoch: 268 [512/17352 (3%)] Loss: -633.447693\n",
      "Train Epoch: 268 [10176/17352 (59%)] Loss: -598.206757\n",
      "Train Epoch: 268 [16934/17352 (98%)] Loss: -501.040154\n",
      "    epoch          : 268\n",
      "    loss           : -609.8456800960649\n",
      "    val_loss       : -557.5184193776281\n",
      "    val_log_likelihood: 916.9324823781755\n",
      "    val_log_marginal: 576.3702579286874\n",
      "Train Epoch: 269 [512/17352 (3%)] Loss: -661.205627\n",
      "Train Epoch: 269 [9294/17352 (54%)] Loss: -423.606876\n",
      "Train Epoch: 269 [16922/17352 (98%)] Loss: -391.096912\n",
      "    epoch          : 269\n",
      "    loss           : -491.62004279657515\n",
      "    val_loss       : -416.3497319948411\n",
      "    val_log_likelihood: 769.0414626319878\n",
      "    val_log_marginal: 445.8595445608888\n",
      "Train Epoch: 270 [512/17352 (3%)] Loss: -499.944397\n",
      "Train Epoch: 270 [10868/17352 (63%)] Loss: -633.226013\n",
      "Train Epoch: 270 [16992/17352 (98%)] Loss: -567.936395\n",
      "    epoch          : 270\n",
      "    loss           : -551.0184501939268\n",
      "    val_loss       : -449.9487436694532\n",
      "    val_log_likelihood: 838.0371926058862\n",
      "    val_log_marginal: 485.57954224224284\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch270.pth ...\n",
      "Train Epoch: 271 [512/17352 (3%)] Loss: -607.288635\n",
      "Train Epoch: 271 [10589/17352 (61%)] Loss: -638.349886\n",
      "Train Epoch: 271 [16958/17352 (98%)] Loss: -669.172310\n",
      "    epoch          : 271\n",
      "    loss           : -598.1414818576493\n",
      "    val_loss       : -539.9612180713995\n",
      "    val_log_likelihood: 899.3430664500379\n",
      "    val_log_marginal: 574.4892552908026\n",
      "Train Epoch: 272 [512/17352 (3%)] Loss: -666.285889\n",
      "Train Epoch: 272 [10288/17352 (59%)] Loss: -553.060715\n",
      "Train Epoch: 272 [17016/17352 (98%)] Loss: -686.658890\n",
      "    epoch          : 272\n",
      "    loss           : -624.2361397453924\n",
      "    val_loss       : -556.3366705248457\n",
      "    val_log_likelihood: 916.8733549403796\n",
      "    val_log_marginal: 592.0149022957801\n",
      "Train Epoch: 273 [512/17352 (3%)] Loss: -689.042786\n",
      "Train Epoch: 273 [10739/17352 (62%)] Loss: -612.045666\n",
      "Train Epoch: 273 [16939/17352 (98%)] Loss: -594.415471\n",
      "    epoch          : 273\n",
      "    loss           : -652.6305429804219\n",
      "    val_loss       : -589.8777233742696\n",
      "    val_log_likelihood: 924.4009694734589\n",
      "    val_log_marginal: 607.5375696771498\n",
      "Train Epoch: 274 [512/17352 (3%)] Loss: -683.530457\n",
      "Train Epoch: 274 [10510/17352 (61%)] Loss: -705.765991\n",
      "Train Epoch: 274 [16923/17352 (98%)] Loss: -627.105642\n",
      "    epoch          : 274\n",
      "    loss           : -623.1834423692864\n",
      "    val_loss       : -557.5061007289912\n",
      "    val_log_likelihood: 914.1229909891141\n",
      "    val_log_marginal: 580.4781071174456\n",
      "Train Epoch: 275 [512/17352 (3%)] Loss: -679.554565\n",
      "Train Epoch: 275 [10421/17352 (60%)] Loss: -549.428176\n",
      "Train Epoch: 275 [16878/17352 (97%)] Loss: -759.863313\n",
      "    epoch          : 275\n",
      "    loss           : -650.069785174736\n",
      "    val_loss       : -585.5382164242195\n",
      "    val_log_likelihood: 926.7803802020059\n",
      "    val_log_marginal: 603.5535481373968\n",
      "Train Epoch: 276 [512/17352 (3%)] Loss: -673.891602\n",
      "Train Epoch: 276 [9836/17352 (57%)] Loss: -672.675663\n",
      "Train Epoch: 276 [17126/17352 (99%)] Loss: -652.791724\n",
      "    epoch          : 276\n",
      "    loss           : -660.3662653300547\n",
      "    val_loss       : -586.0401985332643\n",
      "    val_log_likelihood: 944.8414702295438\n",
      "    val_log_marginal: 612.1487338458845\n",
      "Train Epoch: 277 [512/17352 (3%)] Loss: -701.113037\n",
      "Train Epoch: 277 [10587/17352 (61%)] Loss: -750.729537\n",
      "Train Epoch: 277 [17263/17352 (99%)] Loss: -661.983904\n",
      "    epoch          : 277\n",
      "    loss           : -659.1923423050677\n",
      "    val_loss       : -574.1499419823401\n",
      "    val_log_likelihood: 932.4166796520396\n",
      "    val_log_marginal: 592.6620277657315\n",
      "Train Epoch: 278 [512/17352 (3%)] Loss: -703.818848\n",
      "Train Epoch: 278 [10205/17352 (59%)] Loss: -537.742360\n",
      "Train Epoch: 278 [16992/17352 (98%)] Loss: -712.899115\n",
      "    epoch          : 278\n",
      "    loss           : -656.8585299692575\n",
      "    val_loss       : -577.3517373186218\n",
      "    val_log_likelihood: 940.0971272750108\n",
      "    val_log_marginal: 603.8888769177272\n",
      "Train Epoch: 279 [512/17352 (3%)] Loss: -705.292603\n",
      "Train Epoch: 279 [10248/17352 (59%)] Loss: -663.958656\n",
      "Train Epoch: 279 [17049/17352 (98%)] Loss: -721.211544\n",
      "    epoch          : 279\n",
      "    loss           : -654.2822413044386\n",
      "    val_loss       : -548.3387720276098\n",
      "    val_log_likelihood: 942.0390832415166\n",
      "    val_log_marginal: 572.2777798303092\n",
      "Train Epoch: 280 [512/17352 (3%)] Loss: -689.680359\n",
      "Train Epoch: 280 [10075/17352 (58%)] Loss: -637.361568\n",
      "Train Epoch: 280 [17126/17352 (99%)] Loss: -673.838281\n",
      "    epoch          : 280\n",
      "    loss           : -649.5790866726793\n",
      "    val_loss       : -542.4652743044876\n",
      "    val_log_likelihood: 934.9686257853326\n",
      "    val_log_marginal: 567.9273771656043\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch280.pth ...\n",
      "Train Epoch: 281 [512/17352 (3%)] Loss: -681.291626\n",
      "Train Epoch: 281 [10449/17352 (60%)] Loss: -785.803928\n",
      "Train Epoch: 281 [16939/17352 (98%)] Loss: -728.869029\n",
      "    epoch          : 281\n",
      "    loss           : -630.5275224360544\n",
      "    val_loss       : -542.9000753490749\n",
      "    val_log_likelihood: 933.0249258292976\n",
      "    val_log_marginal: 566.7761353506737\n",
      "Train Epoch: 282 [512/17352 (3%)] Loss: -673.874451\n",
      "Train Epoch: 282 [10846/17352 (63%)] Loss: -691.437438\n",
      "Train Epoch: 282 [16939/17352 (98%)] Loss: -479.887311\n",
      "    epoch          : 282\n",
      "    loss           : -629.1886222077468\n",
      "    val_loss       : -532.347785836761\n",
      "    val_log_likelihood: 926.3347079012493\n",
      "    val_log_marginal: 555.0017050098303\n",
      "Train Epoch: 283 [512/17352 (3%)] Loss: -628.258362\n",
      "Train Epoch: 283 [10629/17352 (61%)] Loss: -546.055651\n",
      "Train Epoch: 283 [16958/17352 (98%)] Loss: -679.815625\n",
      "    epoch          : 283\n",
      "    loss           : -624.2020431769866\n",
      "    val_loss       : -531.9293050064298\n",
      "    val_log_likelihood: 931.2758624613459\n",
      "    val_log_marginal: 593.8005393129372\n",
      "Train Epoch: 284 [512/17352 (3%)] Loss: -516.096558\n",
      "Train Epoch: 284 [10382/17352 (60%)] Loss: -641.267600\n",
      "Train Epoch: 284 [17090/17352 (98%)] Loss: -332.879423\n",
      "    epoch          : 284\n",
      "    loss           : -619.827279391042\n",
      "    val_loss       : -544.8048790456113\n",
      "    val_log_likelihood: 917.5667791970725\n",
      "    val_log_marginal: 576.8127402431517\n",
      "Train Epoch: 285 [512/17352 (3%)] Loss: -683.580872\n",
      "Train Epoch: 285 [10523/17352 (61%)] Loss: -657.474539\n",
      "Train Epoch: 285 [17106/17352 (99%)] Loss: 15.668282\n",
      "    epoch          : 285\n",
      "    loss           : -246.45760363885034\n",
      "    val_loss       : 195.0931520689254\n",
      "    val_log_likelihood: 640.1279341791908\n",
      "    val_log_marginal: -116.55708630963073\n",
      "Train Epoch: 286 [512/17352 (3%)] Loss: -52.086834\n",
      "Train Epoch: 286 [10005/17352 (58%)] Loss: -198.423557\n",
      "Train Epoch: 286 [16882/17352 (97%)] Loss: -591.030729\n",
      "    epoch          : 286\n",
      "    loss           : -358.8095858197412\n",
      "    val_loss       : -463.44317798823965\n",
      "    val_log_likelihood: 824.591940079311\n",
      "    val_log_marginal: 508.77651198713295\n",
      "Train Epoch: 287 [512/17352 (3%)] Loss: -599.415527\n",
      "Train Epoch: 287 [10365/17352 (60%)] Loss: -648.323281\n",
      "Train Epoch: 287 [16923/17352 (98%)] Loss: -725.996144\n",
      "    epoch          : 287\n",
      "    loss           : -591.8680102452098\n",
      "    val_loss       : -555.8785302316126\n",
      "    val_log_likelihood: 908.8499328835527\n",
      "    val_log_marginal: 583.2243902559658\n",
      "Train Epoch: 288 [512/17352 (3%)] Loss: -685.880737\n",
      "Train Epoch: 288 [10838/17352 (62%)] Loss: -639.764938\n",
      "Train Epoch: 288 [17263/17352 (99%)] Loss: -595.770106\n",
      "    epoch          : 288\n",
      "    loss           : -635.1104243916105\n",
      "    val_loss       : -553.8077222047909\n",
      "    val_log_likelihood: 914.572451532933\n",
      "    val_log_marginal: 582.0766854051307\n",
      "Train Epoch: 289 [512/17352 (3%)] Loss: -690.356262\n",
      "Train Epoch: 289 [10226/17352 (59%)] Loss: -689.080061\n",
      "Train Epoch: 289 [16934/17352 (98%)] Loss: -750.309549\n",
      "    epoch          : 289\n",
      "    loss           : -641.2287269729072\n",
      "    val_loss       : -580.4507225361874\n",
      "    val_log_likelihood: 937.0781755556727\n",
      "    val_log_marginal: 608.9701632631045\n",
      "Train Epoch: 290 [512/17352 (3%)] Loss: -711.730591\n",
      "Train Epoch: 290 [9682/17352 (56%)] Loss: -673.988731\n",
      "Train Epoch: 290 [17090/17352 (98%)] Loss: -705.599349\n",
      "    epoch          : 290\n",
      "    loss           : -639.6158074104687\n",
      "    val_loss       : -570.8366981505741\n",
      "    val_log_likelihood: 929.6299732428979\n",
      "    val_log_marginal: 598.9632613466968\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch290.pth ...\n",
      "Train Epoch: 291 [512/17352 (3%)] Loss: -715.426147\n",
      "Train Epoch: 291 [10458/17352 (60%)] Loss: -605.363021\n",
      "Train Epoch: 291 [17124/17352 (99%)] Loss: -592.613001\n",
      "    epoch          : 291\n",
      "    loss           : -648.3674081435676\n",
      "    val_loss       : -573.8163968482525\n",
      "    val_log_likelihood: 937.597332935088\n",
      "    val_log_marginal: 602.5072150147396\n",
      "Train Epoch: 292 [512/17352 (3%)] Loss: -711.694214\n",
      "Train Epoch: 292 [10123/17352 (58%)] Loss: -501.705755\n",
      "Train Epoch: 292 [16883/17352 (97%)] Loss: -755.169937\n",
      "    epoch          : 292\n",
      "    loss           : -664.8730910329344\n",
      "    val_loss       : -591.777173703685\n",
      "    val_log_likelihood: 943.4390202870247\n",
      "    val_log_marginal: 609.5382719994847\n",
      "Train Epoch: 293 [512/17352 (3%)] Loss: -714.858643\n",
      "Train Epoch: 293 [10673/17352 (62%)] Loss: -715.970534\n",
      "Train Epoch: 293 [16922/17352 (98%)] Loss: -760.946994\n",
      "    epoch          : 293\n",
      "    loss           : -668.1546890512154\n",
      "    val_loss       : -587.9314244999011\n",
      "    val_log_likelihood: 948.9041455873313\n",
      "    val_log_marginal: 608.3139502128713\n",
      "Train Epoch: 294 [512/17352 (3%)] Loss: -724.420715\n",
      "Train Epoch: 294 [10691/17352 (62%)] Loss: -752.997383\n",
      "Train Epoch: 294 [16922/17352 (98%)] Loss: -779.751135\n",
      "    epoch          : 294\n",
      "    loss           : -676.4763752346247\n",
      "    val_loss       : -604.013926790291\n",
      "    val_log_likelihood: 959.6103067526153\n",
      "    val_log_marginal: 627.09443793751\n",
      "Train Epoch: 295 [512/17352 (3%)] Loss: -709.948608\n",
      "Train Epoch: 295 [10184/17352 (59%)] Loss: -722.551875\n",
      "Train Epoch: 295 [17263/17352 (99%)] Loss: -730.086337\n",
      "    epoch          : 295\n",
      "    loss           : -673.7536495888613\n",
      "    val_loss       : -554.2415295895834\n",
      "    val_log_likelihood: 949.5956055477635\n",
      "    val_log_marginal: 574.9370394055586\n",
      "Train Epoch: 296 [512/17352 (3%)] Loss: -525.018494\n",
      "Train Epoch: 296 [10372/17352 (60%)] Loss: -694.979706\n",
      "Train Epoch: 296 [16992/17352 (98%)] Loss: -689.109635\n",
      "    epoch          : 296\n",
      "    loss           : -622.9469406176061\n",
      "    val_loss       : -535.2932085980494\n",
      "    val_log_likelihood: 893.4340310647495\n",
      "    val_log_marginal: 561.1984633050331\n",
      "Train Epoch: 297 [512/17352 (3%)] Loss: -695.607483\n",
      "Train Epoch: 297 [10614/17352 (61%)] Loss: -557.333993\n",
      "Train Epoch: 297 [16958/17352 (98%)] Loss: -762.972331\n",
      "    epoch          : 297\n",
      "    loss           : -616.6290253543459\n",
      "    val_loss       : -564.6609941712362\n",
      "    val_log_likelihood: 937.172593280445\n",
      "    val_log_marginal: 590.7393132490956\n",
      "Train Epoch: 298 [512/17352 (3%)] Loss: -703.735962\n",
      "Train Epoch: 298 [10428/17352 (60%)] Loss: -726.131725\n",
      "Train Epoch: 298 [17277/17352 (100%)] Loss: -765.743085\n",
      "    epoch          : 298\n",
      "    loss           : -634.9282494343023\n",
      "    val_loss       : -558.1497994356786\n",
      "    val_log_likelihood: 933.7799741284056\n",
      "    val_log_marginal: 589.2579362933375\n",
      "Train Epoch: 299 [512/17352 (3%)] Loss: -691.461731\n",
      "Train Epoch: 299 [9810/17352 (57%)] Loss: -701.409172\n",
      "Train Epoch: 299 [16883/17352 (97%)] Loss: -568.148026\n",
      "    epoch          : 299\n",
      "    loss           : -650.1558193720311\n",
      "    val_loss       : -549.0257372482739\n",
      "    val_log_likelihood: 938.2358054731565\n",
      "    val_log_marginal: 580.0035906205183\n",
      "Train Epoch: 300 [512/17352 (3%)] Loss: -704.427490\n",
      "Train Epoch: 300 [10448/17352 (60%)] Loss: -557.805382\n",
      "Train Epoch: 300 [16988/17352 (98%)] Loss: -535.790280\n",
      "    epoch          : 300\n",
      "    loss           : -639.905547693088\n",
      "    val_loss       : -549.7407959520726\n",
      "    val_log_likelihood: 943.0083472424114\n",
      "    val_log_marginal: 576.7504977746844\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch300.pth ...\n",
      "Train Epoch: 301 [512/17352 (3%)] Loss: -696.812561\n",
      "Train Epoch: 301 [10860/17352 (63%)] Loss: -770.285372\n",
      "Train Epoch: 301 [16872/17352 (97%)] Loss: -624.768038\n",
      "    epoch          : 301\n",
      "    loss           : -663.1814034546479\n",
      "    val_loss       : -577.229815615229\n",
      "    val_log_likelihood: 944.220171059015\n",
      "    val_log_marginal: 597.1360617300596\n",
      "Train Epoch: 302 [512/17352 (3%)] Loss: -709.759766\n",
      "Train Epoch: 302 [10094/17352 (58%)] Loss: -605.433536\n",
      "Train Epoch: 302 [17124/17352 (99%)] Loss: -747.383576\n",
      "    epoch          : 302\n",
      "    loss           : -683.2324657182238\n",
      "    val_loss       : -589.7699757388476\n",
      "    val_log_likelihood: 959.5442900514724\n",
      "    val_log_marginal: 607.7680134945495\n",
      "Train Epoch: 303 [512/17352 (3%)] Loss: -723.193726\n",
      "Train Epoch: 303 [10644/17352 (61%)] Loss: -739.715152\n",
      "Train Epoch: 303 [17126/17352 (99%)] Loss: -652.967934\n",
      "    epoch          : 303\n",
      "    loss           : -673.0236859703759\n",
      "    val_loss       : -555.0738314161691\n",
      "    val_log_likelihood: 943.1309676758437\n",
      "    val_log_marginal: 586.0593553145362\n",
      "Train Epoch: 304 [512/17352 (3%)] Loss: -660.949463\n",
      "Train Epoch: 304 [10773/17352 (62%)] Loss: -488.604067\n",
      "Train Epoch: 304 [16887/17352 (97%)] Loss: -624.652280\n",
      "    epoch          : 304\n",
      "    loss           : -663.2584028318852\n",
      "    val_loss       : -589.493622586009\n",
      "    val_log_likelihood: 961.6990287560699\n",
      "    val_log_marginal: 616.8577152651183\n",
      "Train Epoch: 305 [512/17352 (3%)] Loss: -730.672791\n",
      "Train Epoch: 305 [10652/17352 (61%)] Loss: -542.632626\n",
      "Train Epoch: 305 [16957/17352 (98%)] Loss: -734.685729\n",
      "    epoch          : 305\n",
      "    loss           : -674.9025789600137\n",
      "    val_loss       : -615.1275445845627\n",
      "    val_log_likelihood: 971.4730403291744\n",
      "    val_log_marginal: 637.7441416422525\n",
      "Train Epoch: 306 [512/17352 (3%)] Loss: -550.115723\n",
      "Train Epoch: 306 [10658/17352 (61%)] Loss: -825.260091\n",
      "Train Epoch: 306 [17133/17352 (99%)] Loss: -754.663287\n",
      "    epoch          : 306\n",
      "    loss           : -679.6531067011528\n",
      "    val_loss       : -573.1001597974755\n",
      "    val_log_likelihood: 956.8155993321063\n",
      "    val_log_marginal: 600.7832005779968\n",
      "Train Epoch: 307 [512/17352 (3%)] Loss: -715.873352\n",
      "Train Epoch: 307 [9669/17352 (56%)] Loss: -710.464612\n",
      "Train Epoch: 307 [17049/17352 (98%)] Loss: -766.378027\n",
      "    epoch          : 307\n",
      "    loss           : -666.0975154796773\n",
      "    val_loss       : -592.0218349146787\n",
      "    val_log_likelihood: 960.2556318487512\n",
      "    val_log_marginal: 612.3421809032903\n",
      "Train Epoch: 308 [512/17352 (3%)] Loss: -730.701050\n",
      "Train Epoch: 308 [10365/17352 (60%)] Loss: -720.465765\n",
      "Train Epoch: 308 [17143/17352 (99%)] Loss: -707.629070\n",
      "    epoch          : 308\n",
      "    loss           : -678.8609027034171\n",
      "    val_loss       : -474.87876576881655\n",
      "    val_log_likelihood: 963.2657016106454\n",
      "    val_log_marginal: 497.1093833113353\n",
      "Train Epoch: 309 [512/17352 (3%)] Loss: -604.040283\n",
      "Train Epoch: 309 [10198/17352 (59%)] Loss: -703.879984\n",
      "Train Epoch: 309 [16922/17352 (98%)] Loss: -791.600911\n",
      "    epoch          : 309\n",
      "    loss           : -662.5342071962224\n",
      "    val_loss       : -586.1350229056939\n",
      "    val_log_likelihood: 969.05475937566\n",
      "    val_log_marginal: 610.846034666083\n",
      "Train Epoch: 310 [512/17352 (3%)] Loss: -750.482605\n",
      "Train Epoch: 310 [9957/17352 (57%)] Loss: -805.384332\n",
      "Train Epoch: 310 [17335/17352 (100%)] Loss: -649.127565\n",
      "    epoch          : 310\n",
      "    loss           : -668.7600832429874\n",
      "    val_loss       : -461.9576102636821\n",
      "    val_log_likelihood: 921.0818535343823\n",
      "    val_log_marginal: 489.4815666115389\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch310.pth ...\n",
      "Train Epoch: 311 [512/17352 (3%)] Loss: -609.721924\n",
      "Train Epoch: 311 [10072/17352 (58%)] Loss: -740.005785\n",
      "Train Epoch: 311 [17108/17352 (99%)] Loss: -740.716463\n",
      "    epoch          : 311\n",
      "    loss           : -656.4941800980862\n",
      "    val_loss       : -596.0797456501674\n",
      "    val_log_likelihood: 968.8833146016879\n",
      "    val_log_marginal: 612.970523359532\n",
      "Train Epoch: 312 [512/17352 (3%)] Loss: -733.140015\n",
      "Train Epoch: 312 [10390/17352 (60%)] Loss: -703.444635\n",
      "Train Epoch: 312 [17124/17352 (99%)] Loss: -340.136072\n",
      "    epoch          : 312\n",
      "    loss           : -656.4806285180023\n",
      "    val_loss       : -473.69676684793137\n",
      "    val_log_likelihood: 965.8440931797835\n",
      "    val_log_marginal: 496.2787515500601\n",
      "Train Epoch: 313 [512/17352 (3%)] Loss: -565.401794\n",
      "Train Epoch: 313 [9989/17352 (58%)] Loss: -762.436230\n",
      "Train Epoch: 313 [16887/17352 (97%)] Loss: -579.299517\n",
      "    epoch          : 313\n",
      "    loss           : -662.4042208500994\n",
      "    val_loss       : -573.8863828228067\n",
      "    val_log_likelihood: 955.4906971642928\n",
      "    val_log_marginal: 596.4000886610273\n",
      "Train Epoch: 314 [512/17352 (3%)] Loss: -697.963074\n",
      "Train Epoch: 314 [9648/17352 (56%)] Loss: -760.803934\n",
      "Train Epoch: 314 [17143/17352 (99%)] Loss: -679.321337\n",
      "    epoch          : 314\n",
      "    loss           : -694.4438209159927\n",
      "    val_loss       : -598.7024960209053\n",
      "    val_log_likelihood: 983.3749181803553\n",
      "    val_log_marginal: 622.1479720276931\n",
      "Train Epoch: 315 [512/17352 (3%)] Loss: -733.455017\n",
      "Train Epoch: 315 [10731/17352 (62%)] Loss: -534.861319\n",
      "Train Epoch: 315 [17101/17352 (99%)] Loss: -578.164037\n",
      "    epoch          : 315\n",
      "    loss           : -678.1590423391378\n",
      "    val_loss       : -570.3082802197158\n",
      "    val_log_likelihood: 976.3056014932655\n",
      "    val_log_marginal: 593.8727693911721\n",
      "Train Epoch: 316 [512/17352 (3%)] Loss: -720.410645\n",
      "Train Epoch: 316 [10315/17352 (59%)] Loss: -628.496181\n",
      "Train Epoch: 316 [16988/17352 (98%)] Loss: -753.978634\n",
      "    epoch          : 316\n",
      "    loss           : -689.6954628514264\n",
      "    val_loss       : -614.466174275895\n",
      "    val_log_likelihood: 987.5715937481771\n",
      "    val_log_marginal: 638.5431801322574\n",
      "Train Epoch: 317 [512/17352 (3%)] Loss: -738.838501\n",
      "Train Epoch: 317 [10252/17352 (59%)] Loss: -548.229889\n",
      "Train Epoch: 317 [16883/17352 (97%)] Loss: -590.852779\n",
      "    epoch          : 317\n",
      "    loss           : -685.7352947703245\n",
      "    val_loss       : -575.7562508756689\n",
      "    val_log_likelihood: 971.9363263413627\n",
      "    val_log_marginal: 611.0194242318827\n",
      "Train Epoch: 318 [512/17352 (3%)] Loss: -705.583435\n",
      "Train Epoch: 318 [10198/17352 (59%)] Loss: -569.936732\n",
      "Train Epoch: 318 [17263/17352 (99%)] Loss: -633.862540\n",
      "    epoch          : 318\n",
      "    loss           : -611.2042332369592\n",
      "    val_loss       : -456.26474533600066\n",
      "    val_log_likelihood: 939.4481219749742\n",
      "    val_log_marginal: 501.9909109907485\n",
      "Train Epoch: 319 [512/17352 (3%)] Loss: -630.838318\n",
      "Train Epoch: 319 [10938/17352 (63%)] Loss: -605.849005\n",
      "Train Epoch: 319 [17253/17352 (99%)] Loss: -447.030315\n",
      "    epoch          : 319\n",
      "    loss           : -568.665026784786\n",
      "    val_loss       : -404.79619346057154\n",
      "    val_log_likelihood: 946.7602077430037\n",
      "    val_log_marginal: 438.7213138109315\n",
      "Train Epoch: 320 [512/17352 (3%)] Loss: -575.535034\n",
      "Train Epoch: 320 [10384/17352 (60%)] Loss: -707.776394\n",
      "Train Epoch: 320 [17335/17352 (100%)] Loss: -502.370586\n",
      "    epoch          : 320\n",
      "    loss           : -608.4624526411848\n",
      "    val_loss       : -394.3958882383651\n",
      "    val_log_likelihood: 951.0647612349696\n",
      "    val_log_marginal: 435.17625570981346\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch320.pth ...\n",
      "Train Epoch: 321 [512/17352 (3%)] Loss: -539.160034\n",
      "Train Epoch: 321 [10303/17352 (59%)] Loss: -691.369803\n",
      "Train Epoch: 321 [16957/17352 (98%)] Loss: -726.537109\n",
      "    epoch          : 321\n",
      "    loss           : -632.7466539093363\n",
      "    val_loss       : -589.0098163466165\n",
      "    val_log_likelihood: 963.446939739351\n",
      "    val_log_marginal: 619.8861670143469\n",
      "Train Epoch: 322 [512/17352 (3%)] Loss: -755.518616\n",
      "Train Epoch: 322 [10409/17352 (60%)] Loss: -787.258487\n",
      "Train Epoch: 322 [16883/17352 (97%)] Loss: -597.134324\n",
      "    epoch          : 322\n",
      "    loss           : -703.6649260167907\n",
      "    val_loss       : -616.3550540683251\n",
      "    val_log_likelihood: 982.9152440147025\n",
      "    val_log_marginal: 634.1598057694239\n",
      "Train Epoch: 323 [512/17352 (3%)] Loss: -747.034058\n",
      "Train Epoch: 323 [10569/17352 (61%)] Loss: -754.150597\n",
      "Train Epoch: 323 [17101/17352 (99%)] Loss: -742.341039\n",
      "    epoch          : 323\n",
      "    loss           : -704.7725048316678\n",
      "    val_loss       : -611.9365445387451\n",
      "    val_log_likelihood: 988.4847832155216\n",
      "    val_log_marginal: 638.232638597325\n",
      "Train Epoch: 324 [512/17352 (3%)] Loss: -709.209839\n",
      "Train Epoch: 324 [10214/17352 (59%)] Loss: -639.747458\n",
      "Train Epoch: 324 [17277/17352 (100%)] Loss: -614.863979\n",
      "    epoch          : 324\n",
      "    loss           : -699.5111077010417\n",
      "    val_loss       : -570.9025173257418\n",
      "    val_log_likelihood: 991.8571873309014\n",
      "    val_log_marginal: 588.4022943015655\n",
      "Train Epoch: 325 [512/17352 (3%)] Loss: -713.712952\n",
      "Train Epoch: 325 [10995/17352 (63%)] Loss: -673.656510\n",
      "Train Epoch: 325 [16988/17352 (98%)] Loss: -726.934766\n",
      "    epoch          : 325\n",
      "    loss           : -701.1742728543776\n",
      "    val_loss       : -566.2812991285953\n",
      "    val_log_likelihood: 980.9081020104398\n",
      "    val_log_marginal: 610.7655899807081\n",
      "Train Epoch: 326 [512/17352 (3%)] Loss: -656.875122\n",
      "Train Epoch: 326 [10077/17352 (58%)] Loss: -533.968853\n",
      "Train Epoch: 326 [17253/17352 (99%)] Loss: -417.383635\n",
      "    epoch          : 326\n",
      "    loss           : -649.7569586587431\n",
      "    val_loss       : -588.429013763743\n",
      "    val_log_likelihood: 981.8356886698082\n",
      "    val_log_marginal: 624.79800460408\n",
      "Train Epoch: 327 [512/17352 (3%)] Loss: -666.147461\n",
      "Train Epoch: 327 [10143/17352 (58%)] Loss: -640.404253\n",
      "Train Epoch: 327 [17106/17352 (99%)] Loss: -758.823627\n",
      "    epoch          : 327\n",
      "    loss           : -694.5175515533406\n",
      "    val_loss       : -582.7302839336148\n",
      "    val_log_likelihood: 979.394052928928\n",
      "    val_log_marginal: 606.254821835941\n",
      "Train Epoch: 328 [512/17352 (3%)] Loss: -719.775085\n",
      "Train Epoch: 328 [10962/17352 (63%)] Loss: -764.081383\n",
      "Train Epoch: 328 [16887/17352 (97%)] Loss: -815.713687\n",
      "    epoch          : 328\n",
      "    loss           : -705.3860813763952\n",
      "    val_loss       : -611.5411727568132\n",
      "    val_log_likelihood: 998.5556983905384\n",
      "    val_log_marginal: 639.143258180948\n",
      "Train Epoch: 329 [512/17352 (3%)] Loss: -754.457825\n",
      "Train Epoch: 329 [10195/17352 (59%)] Loss: -723.992773\n",
      "Train Epoch: 329 [16934/17352 (98%)] Loss: -542.802083\n",
      "    epoch          : 329\n",
      "    loss           : -716.1644105726409\n",
      "    val_loss       : -609.4662814297632\n",
      "    val_log_likelihood: 983.9602101457469\n",
      "    val_log_marginal: 630.6308621282911\n",
      "Train Epoch: 330 [512/17352 (3%)] Loss: -744.622009\n",
      "Train Epoch: 330 [10149/17352 (58%)] Loss: -674.832854\n",
      "Train Epoch: 330 [16957/17352 (98%)] Loss: -631.097706\n",
      "    epoch          : 330\n",
      "    loss           : -716.6826322349559\n",
      "    val_loss       : -623.4766892349217\n",
      "    val_log_likelihood: 1005.9762546662996\n",
      "    val_log_marginal: 651.2422829777809\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch330.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 331 [512/17352 (3%)] Loss: -767.946228\n",
      "Train Epoch: 331 [9778/17352 (56%)] Loss: -760.973406\n",
      "Train Epoch: 331 [17124/17352 (99%)] Loss: -755.715183\n",
      "    epoch          : 331\n",
      "    loss           : -700.6890498809796\n",
      "    val_loss       : -581.7201414284569\n",
      "    val_log_likelihood: 988.3541647553869\n",
      "    val_log_marginal: 614.1122932169505\n",
      "Train Epoch: 332 [512/17352 (3%)] Loss: -728.326538\n",
      "Train Epoch: 332 [10091/17352 (58%)] Loss: -577.824422\n",
      "Train Epoch: 332 [16923/17352 (98%)] Loss: -634.591957\n",
      "    epoch          : 332\n",
      "    loss           : -661.0336412825253\n",
      "    val_loss       : -602.2655250645709\n",
      "    val_log_likelihood: 1000.4538447030085\n",
      "    val_log_marginal: 629.2625644460127\n",
      "Train Epoch: 333 [512/17352 (3%)] Loss: -753.921570\n",
      "Train Epoch: 333 [10653/17352 (61%)] Loss: -735.843514\n",
      "Train Epoch: 333 [17101/17352 (99%)] Loss: -724.416759\n",
      "    epoch          : 333\n",
      "    loss           : -704.5808287980382\n",
      "    val_loss       : -590.9665671975929\n",
      "    val_log_likelihood: 997.0659430446079\n",
      "    val_log_marginal: 614.8245107163913\n",
      "Train Epoch: 334 [512/17352 (3%)] Loss: -729.345459\n",
      "Train Epoch: 334 [10699/17352 (62%)] Loss: -735.507041\n",
      "Train Epoch: 334 [17277/17352 (100%)] Loss: -479.270318\n",
      "    epoch          : 334\n",
      "    loss           : -655.7643099894728\n",
      "    val_loss       : -401.8429792957848\n",
      "    val_log_likelihood: 960.1869929484463\n",
      "    val_log_marginal: 457.20679227359034\n",
      "Train Epoch: 335 [512/17352 (3%)] Loss: -613.753235\n",
      "Train Epoch: 335 [9721/17352 (56%)] Loss: -387.872267\n",
      "Train Epoch: 335 [17133/17352 (99%)] Loss: -501.940721\n",
      "    epoch          : 335\n",
      "    loss           : -566.3590176080675\n",
      "    val_loss       : -421.78495494982195\n",
      "    val_log_likelihood: 924.315726265954\n",
      "    val_log_marginal: 451.6820730810867\n",
      "Train Epoch: 336 [512/17352 (3%)] Loss: -563.984497\n",
      "Train Epoch: 336 [9939/17352 (57%)] Loss: -770.931261\n",
      "Train Epoch: 336 [17016/17352 (98%)] Loss: -708.781966\n",
      "    epoch          : 336\n",
      "    loss           : -559.7736737984405\n",
      "    val_loss       : -449.2309446569755\n",
      "    val_log_likelihood: 960.255166206583\n",
      "    val_log_marginal: 501.32951879484443\n",
      "Train Epoch: 337 [512/17352 (3%)] Loss: -603.781494\n",
      "Train Epoch: 337 [10316/17352 (59%)] Loss: -585.697234\n",
      "Train Epoch: 337 [17126/17352 (99%)] Loss: -744.503931\n",
      "    epoch          : 337\n",
      "    loss           : -633.3494286759832\n",
      "    val_loss       : -582.0719225498829\n",
      "    val_log_likelihood: 971.7384116301498\n",
      "    val_log_marginal: 615.5538575185004\n",
      "Train Epoch: 338 [512/17352 (3%)] Loss: -721.925049\n",
      "Train Epoch: 338 [9991/17352 (58%)] Loss: -606.025423\n",
      "Train Epoch: 338 [16934/17352 (98%)] Loss: -587.243116\n",
      "    epoch          : 338\n",
      "    loss           : -693.0076617752156\n",
      "    val_loss       : -629.8286818850809\n",
      "    val_log_likelihood: 993.0924627308638\n",
      "    val_log_marginal: 645.8500123223715\n",
      "Train Epoch: 339 [512/17352 (3%)] Loss: -761.755432\n",
      "Train Epoch: 339 [10301/17352 (59%)] Loss: -746.679753\n",
      "Train Epoch: 339 [17106/17352 (99%)] Loss: -787.608344\n",
      "    epoch          : 339\n",
      "    loss           : -723.0320696844334\n",
      "    val_loss       : -602.5072062901386\n",
      "    val_log_likelihood: 1006.371417852246\n",
      "    val_log_marginal: 637.368642882152\n",
      "Train Epoch: 340 [512/17352 (3%)] Loss: -754.761780\n",
      "Train Epoch: 340 [10073/17352 (58%)] Loss: -552.871347\n",
      "Train Epoch: 340 [16988/17352 (98%)] Loss: -741.369304\n",
      "    epoch          : 340\n",
      "    loss           : -695.6775724943637\n",
      "    val_loss       : -598.664482148293\n",
      "    val_log_likelihood: 989.1270550497771\n",
      "    val_log_marginal: 624.1109210537707\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch340.pth ...\n",
      "Train Epoch: 341 [512/17352 (3%)] Loss: -739.103516\n",
      "Train Epoch: 341 [10180/17352 (59%)] Loss: -753.516937\n",
      "Train Epoch: 341 [16934/17352 (98%)] Loss: -761.058731\n",
      "    epoch          : 341\n",
      "    loss           : -709.0076258176427\n",
      "    val_loss       : -589.2740078961276\n",
      "    val_log_likelihood: 991.1070033148768\n",
      "    val_log_marginal: 635.2133372379859\n",
      "Train Epoch: 342 [512/17352 (3%)] Loss: -545.892090\n",
      "Train Epoch: 342 [10643/17352 (61%)] Loss: -753.581962\n",
      "Train Epoch: 342 [16887/17352 (97%)] Loss: -782.009393\n",
      "    epoch          : 342\n",
      "    loss           : -664.3565437382528\n",
      "    val_loss       : -545.1700332455837\n",
      "    val_log_likelihood: 952.5437900869597\n",
      "    val_log_marginal: 582.7642034575231\n",
      "Train Epoch: 343 [512/17352 (3%)] Loss: -680.953491\n",
      "Train Epoch: 343 [10681/17352 (62%)] Loss: -774.142837\n",
      "Train Epoch: 343 [16872/17352 (97%)] Loss: -648.728376\n",
      "    epoch          : 343\n",
      "    loss           : -690.9930380829139\n",
      "    val_loss       : -597.9534608029792\n",
      "    val_log_likelihood: 997.6456611863632\n",
      "    val_log_marginal: 626.2666899506412\n",
      "Train Epoch: 344 [512/17352 (3%)] Loss: -749.838196\n",
      "Train Epoch: 344 [10574/17352 (61%)] Loss: -639.496956\n",
      "Train Epoch: 344 [16939/17352 (98%)] Loss: -570.783622\n",
      "    epoch          : 344\n",
      "    loss           : -707.1411652270502\n",
      "    val_loss       : -614.0367396143974\n",
      "    val_log_likelihood: 1007.6076515445868\n",
      "    val_log_marginal: 638.7773514534063\n",
      "Train Epoch: 345 [512/17352 (3%)] Loss: -756.119385\n",
      "Train Epoch: 345 [10303/17352 (59%)] Loss: -703.930747\n",
      "Train Epoch: 345 [16957/17352 (98%)] Loss: -356.187276\n",
      "    epoch          : 345\n",
      "    loss           : -696.2457457614183\n",
      "    val_loss       : -602.4384678343469\n",
      "    val_log_likelihood: 983.5804023554037\n",
      "    val_log_marginal: 627.814752368421\n",
      "Train Epoch: 346 [512/17352 (3%)] Loss: -762.845093\n",
      "Train Epoch: 346 [10267/17352 (59%)] Loss: -655.710047\n",
      "Train Epoch: 346 [17277/17352 (100%)] Loss: -729.823652\n",
      "    epoch          : 346\n",
      "    loss           : -690.0875323265384\n",
      "    val_loss       : -593.5158829544387\n",
      "    val_log_likelihood: 986.0559846678395\n",
      "    val_log_marginal: 612.1970369670266\n",
      "Train Epoch: 347 [512/17352 (3%)] Loss: -570.926025\n",
      "Train Epoch: 347 [10490/17352 (60%)] Loss: -746.746701\n",
      "Train Epoch: 347 [16934/17352 (98%)] Loss: -679.397554\n",
      "    epoch          : 347\n",
      "    loss           : -691.5714532975101\n",
      "    val_loss       : -576.8942287638254\n",
      "    val_log_likelihood: 982.0535793100083\n",
      "    val_log_marginal: 613.9563896844372\n",
      "Train Epoch: 348 [512/17352 (3%)] Loss: -745.681763\n",
      "Train Epoch: 348 [9968/17352 (57%)] Loss: -689.124293\n",
      "Train Epoch: 348 [17253/17352 (99%)] Loss: -794.167044\n",
      "    epoch          : 348\n",
      "    loss           : -707.6838511858731\n",
      "    val_loss       : -621.5624197517561\n",
      "    val_log_likelihood: 1004.4578052259183\n",
      "    val_log_marginal: 647.8139353273469\n",
      "Train Epoch: 349 [512/17352 (3%)] Loss: -763.266113\n",
      "Train Epoch: 349 [10774/17352 (62%)] Loss: -800.066165\n",
      "Train Epoch: 349 [16934/17352 (98%)] Loss: -692.752585\n",
      "    epoch          : 349\n",
      "    loss           : -723.3924348716404\n",
      "    val_loss       : -648.4680579801346\n",
      "    val_log_likelihood: 1023.4889420405107\n",
      "    val_log_marginal: 666.9299365315637\n",
      "Train Epoch: 350 [512/17352 (3%)] Loss: -791.378296\n",
      "Train Epoch: 350 [10737/17352 (62%)] Loss: -681.125101\n",
      "Train Epoch: 350 [17153/17352 (99%)] Loss: -785.182073\n",
      "    epoch          : 350\n",
      "    loss           : -750.9916891830823\n",
      "    val_loss       : -653.9396272820378\n",
      "    val_log_likelihood: 1034.949602372047\n",
      "    val_log_marginal: 674.390806869484\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch350.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 351 [512/17352 (3%)] Loss: -776.311462\n",
      "Train Epoch: 351 [9867/17352 (57%)] Loss: -779.928660\n",
      "Train Epoch: 351 [16939/17352 (98%)] Loss: -873.166395\n",
      "    epoch          : 351\n",
      "    loss           : -749.8086850096007\n",
      "    val_loss       : -641.9545712043389\n",
      "    val_log_likelihood: 1030.3634955772632\n",
      "    val_log_marginal: 662.2139525397012\n",
      "Train Epoch: 352 [512/17352 (3%)] Loss: -800.866028\n",
      "Train Epoch: 352 [10376/17352 (60%)] Loss: -802.392058\n",
      "Train Epoch: 352 [17263/17352 (99%)] Loss: -602.230736\n",
      "    epoch          : 352\n",
      "    loss           : -730.6388736722514\n",
      "    val_loss       : -579.0126510983542\n",
      "    val_log_likelihood: 1025.0802520389807\n",
      "    val_log_marginal: 600.1568892747437\n",
      "Train Epoch: 353 [512/17352 (3%)] Loss: -747.381104\n",
      "Train Epoch: 353 [10182/17352 (59%)] Loss: -751.534271\n",
      "Train Epoch: 353 [17064/17352 (98%)] Loss: -149.065316\n",
      "    epoch          : 353\n",
      "    loss           : -524.0743116157286\n",
      "    val_loss       : -403.69940398984374\n",
      "    val_log_likelihood: 877.5086243978893\n",
      "    val_log_marginal: 438.73800048211655\n",
      "Train Epoch: 354 [512/17352 (3%)] Loss: -630.293091\n",
      "Train Epoch: 354 [10646/17352 (61%)] Loss: -652.146904\n",
      "Train Epoch: 354 [16882/17352 (97%)] Loss: -618.448403\n",
      "    epoch          : 354\n",
      "    loss           : -576.3830039599417\n",
      "    val_loss       : -544.9850456433107\n",
      "    val_log_likelihood: 949.7564990690945\n",
      "    val_log_marginal: 572.9630161566105\n",
      "Train Epoch: 355 [512/17352 (3%)] Loss: -718.056213\n",
      "Train Epoch: 355 [10339/17352 (60%)] Loss: -747.184041\n",
      "Train Epoch: 355 [16957/17352 (98%)] Loss: -706.521228\n",
      "    epoch          : 355\n",
      "    loss           : -683.3956059969124\n",
      "    val_loss       : -595.4092930475152\n",
      "    val_log_likelihood: 986.2072840934901\n",
      "    val_log_marginal: 616.7855109000686\n",
      "Train Epoch: 356 [512/17352 (3%)] Loss: -734.503235\n",
      "Train Epoch: 356 [10764/17352 (62%)] Loss: -644.533026\n",
      "Train Epoch: 356 [16883/17352 (97%)] Loss: -721.535669\n",
      "    epoch          : 356\n",
      "    loss           : -713.7448479221397\n",
      "    val_loss       : -631.8555027731715\n",
      "    val_log_likelihood: 1015.4315884894572\n",
      "    val_log_marginal: 654.2009087501592\n",
      "Train Epoch: 357 [512/17352 (3%)] Loss: -746.773071\n",
      "Train Epoch: 357 [10306/17352 (59%)] Loss: -806.355810\n",
      "Train Epoch: 357 [17277/17352 (100%)] Loss: -752.418420\n",
      "    epoch          : 357\n",
      "    loss           : -732.1561279098586\n",
      "    val_loss       : -637.9727149069965\n",
      "    val_log_likelihood: 1017.221727030161\n",
      "    val_log_marginal: 658.7699432647645\n",
      "Train Epoch: 358 [512/17352 (3%)] Loss: -784.953186\n",
      "Train Epoch: 358 [10461/17352 (60%)] Loss: -823.281850\n",
      "Train Epoch: 358 [17124/17352 (99%)] Loss: -698.199870\n",
      "    epoch          : 358\n",
      "    loss           : -739.789868178205\n",
      "    val_loss       : -602.7012584952777\n",
      "    val_log_likelihood: 999.3870485927503\n",
      "    val_log_marginal: 621.2448025294802\n",
      "Train Epoch: 359 [512/17352 (3%)] Loss: -759.207397\n",
      "Train Epoch: 359 [9930/17352 (57%)] Loss: -681.531297\n",
      "Train Epoch: 359 [17124/17352 (99%)] Loss: -792.265696\n",
      "    epoch          : 359\n",
      "    loss           : -727.5146618254292\n",
      "    val_loss       : -626.5407445734156\n",
      "    val_log_likelihood: 1016.6380001793958\n",
      "    val_log_marginal: 644.4103589842223\n",
      "Train Epoch: 360 [512/17352 (3%)] Loss: -766.207153\n",
      "Train Epoch: 360 [10301/17352 (59%)] Loss: -702.106983\n",
      "Train Epoch: 360 [16922/17352 (98%)] Loss: -838.167903\n",
      "    epoch          : 360\n",
      "    loss           : -718.7632756249149\n",
      "    val_loss       : -640.6221195566719\n",
      "    val_log_likelihood: 1029.2976020268825\n",
      "    val_log_marginal: 664.5967475520558\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch360.pth ...\n",
      "Train Epoch: 361 [512/17352 (3%)] Loss: -760.620850\n",
      "Train Epoch: 361 [10200/17352 (59%)] Loss: -321.478389\n",
      "Train Epoch: 361 [17153/17352 (99%)] Loss: -392.285115\n",
      "    epoch          : 361\n",
      "    loss           : -423.7664467806735\n",
      "    val_loss       : 390.3662918362146\n",
      "    val_log_likelihood: 900.8625592496954\n",
      "    val_log_marginal: -330.11431871454454\n",
      "Train Epoch: 362 [512/17352 (3%)] Loss: 118.262177\n",
      "Train Epoch: 362 [10421/17352 (60%)] Loss: -377.434152\n",
      "Train Epoch: 362 [17064/17352 (98%)] Loss: -696.090041\n",
      "    epoch          : 362\n",
      "    loss           : -419.07431640865985\n",
      "    val_loss       : -502.4830163166736\n",
      "    val_log_likelihood: 932.2494008931093\n",
      "    val_log_marginal: 559.7901283804292\n",
      "Train Epoch: 363 [512/17352 (3%)] Loss: -691.271729\n",
      "Train Epoch: 363 [10073/17352 (58%)] Loss: -562.973690\n",
      "Train Epoch: 363 [16958/17352 (98%)] Loss: -770.017995\n",
      "    epoch          : 363\n",
      "    loss           : -671.7434797485656\n",
      "    val_loss       : -621.0134847603563\n",
      "    val_log_likelihood: 1007.7783842137349\n",
      "    val_log_marginal: 642.7426209936759\n",
      "Train Epoch: 364 [512/17352 (3%)] Loss: -771.790039\n",
      "Train Epoch: 364 [10868/17352 (63%)] Loss: -812.306977\n",
      "Train Epoch: 364 [17049/17352 (98%)] Loss: -764.602216\n",
      "    epoch          : 364\n",
      "    loss           : -714.5445153897555\n",
      "    val_loss       : -599.9115885009485\n",
      "    val_log_likelihood: 1007.9378532640735\n",
      "    val_log_marginal: 638.3312119271915\n",
      "Train Epoch: 365 [512/17352 (3%)] Loss: -763.093506\n",
      "Train Epoch: 365 [10254/17352 (59%)] Loss: -746.178867\n",
      "Train Epoch: 365 [16887/17352 (97%)] Loss: -797.136061\n",
      "    epoch          : 365\n",
      "    loss           : -726.8187993696293\n",
      "    val_loss       : -636.0759138736613\n",
      "    val_log_likelihood: 1017.1115526608382\n",
      "    val_log_marginal: 653.6636543713776\n",
      "Train Epoch: 366 [512/17352 (3%)] Loss: -784.439209\n",
      "Train Epoch: 366 [10414/17352 (60%)] Loss: -779.869833\n",
      "Train Epoch: 366 [17335/17352 (100%)] Loss: -815.862711\n",
      "    epoch          : 366\n",
      "    loss           : -746.5199903067677\n",
      "    val_loss       : -610.2175998173507\n",
      "    val_log_likelihood: 1027.805507818329\n",
      "    val_log_marginal: 629.7515068463391\n",
      "Train Epoch: 367 [512/17352 (3%)] Loss: -765.191040\n",
      "Train Epoch: 367 [9813/17352 (57%)] Loss: -813.682500\n",
      "Train Epoch: 367 [16887/17352 (97%)] Loss: -812.755597\n",
      "    epoch          : 367\n",
      "    loss           : -740.9092460392575\n",
      "    val_loss       : -641.8260899780083\n",
      "    val_log_likelihood: 1042.1386251240033\n",
      "    val_log_marginal: 668.9149423166931\n",
      "Train Epoch: 368 [512/17352 (3%)] Loss: -600.471497\n",
      "Train Epoch: 368 [10278/17352 (59%)] Loss: -555.112198\n",
      "Train Epoch: 368 [16934/17352 (98%)] Loss: -632.853245\n",
      "    epoch          : 368\n",
      "    loss           : -736.5071618882216\n",
      "    val_loss       : -600.5131566503918\n",
      "    val_log_likelihood: 1031.777965058951\n",
      "    val_log_marginal: 664.625478335623\n",
      "Train Epoch: 369 [512/17352 (3%)] Loss: -707.094238\n",
      "Train Epoch: 369 [9963/17352 (57%)] Loss: -688.457479\n",
      "Train Epoch: 369 [17124/17352 (99%)] Loss: -816.526330\n",
      "    epoch          : 369\n",
      "    loss           : -696.9719055526117\n",
      "    val_loss       : -592.5588604342211\n",
      "    val_log_likelihood: 1005.7331620761015\n",
      "    val_log_marginal: 626.8574501151037\n",
      "Train Epoch: 370 [512/17352 (3%)] Loss: -752.767578\n",
      "Train Epoch: 370 [10309/17352 (59%)] Loss: -597.355972\n",
      "Train Epoch: 370 [16878/17352 (97%)] Loss: -709.493624\n",
      "    epoch          : 370\n",
      "    loss           : -726.0217680809317\n",
      "    val_loss       : -632.3628160867582\n",
      "    val_log_likelihood: 1023.0918608276339\n",
      "    val_log_marginal: 661.9119952958016\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch370.pth ...\n",
      "Train Epoch: 371 [512/17352 (3%)] Loss: -788.118713\n",
      "Train Epoch: 371 [10575/17352 (61%)] Loss: -653.585243\n",
      "Train Epoch: 371 [17106/17352 (99%)] Loss: -726.005580\n",
      "    epoch          : 371\n",
      "    loss           : -749.4603091004354\n",
      "    val_loss       : -667.336311854766\n",
      "    val_log_likelihood: 1047.235382213674\n",
      "    val_log_marginal: 688.0401632344257\n",
      "Train Epoch: 372 [512/17352 (3%)] Loss: -814.088928\n",
      "Train Epoch: 372 [10475/17352 (60%)] Loss: -731.316214\n",
      "Train Epoch: 372 [17263/17352 (99%)] Loss: -737.740972\n",
      "    epoch          : 372\n",
      "    loss           : -767.379378421191\n",
      "    val_loss       : -661.1071515464614\n",
      "    val_log_likelihood: 1046.8278237998795\n",
      "    val_log_marginal: 681.583845233524\n",
      "Train Epoch: 373 [512/17352 (3%)] Loss: -800.626221\n",
      "Train Epoch: 373 [10679/17352 (62%)] Loss: -766.962940\n",
      "Train Epoch: 373 [17108/17352 (99%)] Loss: -709.799716\n",
      "    epoch          : 373\n",
      "    loss           : -742.8594838286525\n",
      "    val_loss       : -633.879700704252\n",
      "    val_log_likelihood: 1033.3354284504867\n",
      "    val_log_marginal: 657.6272443384476\n",
      "Train Epoch: 374 [512/17352 (3%)] Loss: -773.478882\n",
      "Train Epoch: 374 [10540/17352 (61%)] Loss: -696.304036\n",
      "Train Epoch: 374 [16922/17352 (98%)] Loss: -831.193279\n",
      "    epoch          : 374\n",
      "    loss           : -759.6193358748768\n",
      "    val_loss       : -671.4249794747193\n",
      "    val_log_likelihood: 1046.6215259839762\n",
      "    val_log_marginal: 687.6507104615521\n",
      "Train Epoch: 375 [512/17352 (3%)] Loss: -638.896362\n",
      "Train Epoch: 375 [10252/17352 (59%)] Loss: -838.301308\n",
      "Train Epoch: 375 [17106/17352 (99%)] Loss: -755.551471\n",
      "    epoch          : 375\n",
      "    loss           : -762.0404490523389\n",
      "    val_loss       : -627.3746113655072\n",
      "    val_log_likelihood: 1035.0742135037735\n",
      "    val_log_marginal: 650.032615545167\n",
      "Train Epoch: 376 [512/17352 (3%)] Loss: -770.531982\n",
      "Train Epoch: 376 [10174/17352 (59%)] Loss: -800.033676\n",
      "Train Epoch: 376 [16923/17352 (98%)] Loss: -760.348564\n",
      "    epoch          : 376\n",
      "    loss           : -741.6558716894687\n",
      "    val_loss       : -654.6372131358052\n",
      "    val_log_likelihood: 1041.003071545215\n",
      "    val_log_marginal: 672.7370568445668\n",
      "Train Epoch: 377 [512/17352 (3%)] Loss: -792.806335\n",
      "Train Epoch: 377 [10362/17352 (60%)] Loss: -804.914599\n",
      "Train Epoch: 377 [17106/17352 (99%)] Loss: -790.205117\n",
      "    epoch          : 377\n",
      "    loss           : -751.4207156744213\n",
      "    val_loss       : -628.9466863129658\n",
      "    val_log_likelihood: 1042.290678851082\n",
      "    val_log_marginal: 651.1772800091486\n",
      "Train Epoch: 378 [512/17352 (3%)] Loss: -785.430847\n",
      "Train Epoch: 378 [10470/17352 (60%)] Loss: -833.643560\n",
      "Train Epoch: 378 [16887/17352 (97%)] Loss: -673.048600\n",
      "    epoch          : 378\n",
      "    loss           : -758.444230195353\n",
      "    val_loss       : -622.1269938663768\n",
      "    val_log_likelihood: 1052.569394856671\n",
      "    val_log_marginal: 645.759517844619\n",
      "Train Epoch: 379 [512/17352 (3%)] Loss: -797.084534\n",
      "Train Epoch: 379 [10356/17352 (60%)] Loss: -849.143956\n",
      "Train Epoch: 379 [16992/17352 (98%)] Loss: -850.665824\n",
      "    epoch          : 379\n",
      "    loss           : -758.9002288971973\n",
      "    val_loss       : -646.432518924135\n",
      "    val_log_likelihood: 1048.916526661599\n",
      "    val_log_marginal: 669.6972796437847\n",
      "Train Epoch: 380 [512/17352 (3%)] Loss: -802.908508\n",
      "Train Epoch: 380 [10416/17352 (60%)] Loss: -841.407199\n",
      "Train Epoch: 380 [17153/17352 (99%)] Loss: -733.531576\n",
      "    epoch          : 380\n",
      "    loss           : -765.6351688413131\n",
      "    val_loss       : -654.1864797084637\n",
      "    val_log_likelihood: 1051.8640507122657\n",
      "    val_log_marginal: 675.2724296723868\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch380.pth ...\n",
      "Train Epoch: 381 [512/17352 (3%)] Loss: -819.349731\n",
      "Train Epoch: 381 [10191/17352 (59%)] Loss: -820.734814\n",
      "Train Epoch: 381 [17153/17352 (99%)] Loss: -649.038053\n",
      "    epoch          : 381\n",
      "    loss           : -767.5541299557634\n",
      "    val_loss       : -665.5663111361151\n",
      "    val_log_likelihood: 1062.7065758512906\n",
      "    val_log_marginal: 683.3153014788027\n",
      "Train Epoch: 382 [512/17352 (3%)] Loss: -817.101929\n",
      "Train Epoch: 382 [10388/17352 (60%)] Loss: -813.328333\n",
      "Train Epoch: 382 [16923/17352 (98%)] Loss: -665.663882\n",
      "    epoch          : 382\n",
      "    loss           : -778.0458110886859\n",
      "    val_loss       : -657.0544940055926\n",
      "    val_log_likelihood: 1062.7009705145144\n",
      "    val_log_marginal: 679.2362060206641\n",
      "Train Epoch: 383 [512/17352 (3%)] Loss: -808.364136\n",
      "Train Epoch: 383 [10454/17352 (60%)] Loss: -848.925545\n",
      "Train Epoch: 383 [17101/17352 (99%)] Loss: -754.229193\n",
      "    epoch          : 383\n",
      "    loss           : -726.9907111492939\n",
      "    val_loss       : -615.5099201742823\n",
      "    val_log_likelihood: 1031.863308689219\n",
      "    val_log_marginal: 639.4220626098413\n",
      "Train Epoch: 384 [512/17352 (3%)] Loss: -776.922119\n",
      "Train Epoch: 384 [9570/17352 (55%)] Loss: -748.886822\n",
      "Train Epoch: 384 [16883/17352 (97%)] Loss: -708.446484\n",
      "    epoch          : 384\n",
      "    loss           : -743.6080649103851\n",
      "    val_loss       : -628.2650553669451\n",
      "    val_log_likelihood: 1045.6118901324712\n",
      "    val_log_marginal: 649.827313937501\n",
      "Train Epoch: 385 [512/17352 (3%)] Loss: -775.656494\n",
      "Train Epoch: 385 [10760/17352 (62%)] Loss: -816.503362\n",
      "Train Epoch: 385 [17124/17352 (99%)] Loss: -655.450321\n",
      "    epoch          : 385\n",
      "    loss           : -746.724727608986\n",
      "    val_loss       : -640.3173761971818\n",
      "    val_log_likelihood: 1050.808346850254\n",
      "    val_log_marginal: 666.553271406141\n",
      "Train Epoch: 386 [512/17352 (3%)] Loss: -802.191284\n",
      "Train Epoch: 386 [10192/17352 (59%)] Loss: -792.083576\n",
      "Train Epoch: 386 [17101/17352 (99%)] Loss: -672.419956\n",
      "    epoch          : 386\n",
      "    loss           : -736.0729471500752\n",
      "    val_loss       : -447.40067274631537\n",
      "    val_log_likelihood: 1031.7406194283715\n",
      "    val_log_marginal: 469.1461132039158\n",
      "Train Epoch: 387 [512/17352 (3%)] Loss: -672.457520\n",
      "Train Epoch: 387 [10179/17352 (59%)] Loss: -665.275996\n",
      "Train Epoch: 387 [16992/17352 (98%)] Loss: -766.581120\n",
      "    epoch          : 387\n",
      "    loss           : -701.9444266463415\n",
      "    val_loss       : -609.967060021957\n",
      "    val_log_likelihood: 1039.1602845352531\n",
      "    val_log_marginal: 636.9461437024001\n",
      "Train Epoch: 388 [512/17352 (3%)] Loss: -775.435059\n",
      "Train Epoch: 388 [10018/17352 (58%)] Loss: -711.081008\n",
      "Train Epoch: 388 [17143/17352 (99%)] Loss: -742.253217\n",
      "    epoch          : 388\n",
      "    loss           : -766.4348503585163\n",
      "    val_loss       : -645.8872715236892\n",
      "    val_log_likelihood: 1060.4426820286046\n",
      "    val_log_marginal: 671.2392142111321\n",
      "Train Epoch: 389 [512/17352 (3%)] Loss: -825.248657\n",
      "Train Epoch: 389 [10237/17352 (59%)] Loss: -690.281504\n",
      "Train Epoch: 389 [17133/17352 (99%)] Loss: -696.133671\n",
      "    epoch          : 389\n",
      "    loss           : -709.772257109501\n",
      "    val_loss       : -490.3459848302711\n",
      "    val_log_likelihood: 1019.8127415456019\n",
      "    val_log_marginal: 516.9694629244736\n",
      "Train Epoch: 390 [512/17352 (3%)] Loss: -635.643127\n",
      "Train Epoch: 390 [10252/17352 (59%)] Loss: -748.936244\n",
      "Train Epoch: 390 [17124/17352 (99%)] Loss: 297.988062\n",
      "    epoch          : 390\n",
      "    loss           : -393.3697986796691\n",
      "    val_loss       : -313.13551722656314\n",
      "    val_log_likelihood: 830.4369522021369\n",
      "    val_log_marginal: 342.1284141104105\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch390.pth ...\n",
      "Train Epoch: 391 [512/17352 (3%)] Loss: -506.717682\n",
      "Train Epoch: 391 [10573/17352 (61%)] Loss: -507.344122\n",
      "Train Epoch: 391 [16923/17352 (98%)] Loss: -658.085547\n",
      "    epoch          : 391\n",
      "    loss           : -461.72009224490466\n",
      "    val_loss       : -533.2409870830007\n",
      "    val_log_likelihood: 940.6655277899907\n",
      "    val_log_marginal: 574.5383725784774\n",
      "Train Epoch: 392 [512/17352 (3%)] Loss: -682.030457\n",
      "Train Epoch: 392 [10099/17352 (58%)] Loss: -689.264258\n",
      "Train Epoch: 392 [17106/17352 (99%)] Loss: -497.316986\n",
      "    epoch          : 392\n",
      "    loss           : -689.0197826826158\n",
      "    val_loss       : -614.8882264588384\n",
      "    val_log_likelihood: 1013.8536648406268\n",
      "    val_log_marginal: 642.9306369070607\n",
      "Train Epoch: 393 [512/17352 (3%)] Loss: -761.137756\n",
      "Train Epoch: 393 [10150/17352 (58%)] Loss: -701.871701\n",
      "Train Epoch: 393 [16939/17352 (98%)] Loss: -784.018114\n",
      "    epoch          : 393\n",
      "    loss           : -754.6465905846226\n",
      "    val_loss       : -653.6683041122744\n",
      "    val_log_likelihood: 1043.5746189429606\n",
      "    val_log_marginal: 672.185271099325\n",
      "Train Epoch: 394 [512/17352 (3%)] Loss: -800.375366\n",
      "Train Epoch: 394 [10520/17352 (61%)] Loss: -728.592448\n",
      "Train Epoch: 394 [17133/17352 (99%)] Loss: -709.453509\n",
      "    epoch          : 394\n",
      "    loss           : -762.1290228608665\n",
      "    val_loss       : -650.832069658812\n",
      "    val_log_likelihood: 1046.6579964869686\n",
      "    val_log_marginal: 672.8068652124983\n",
      "Train Epoch: 395 [512/17352 (3%)] Loss: -802.677124\n",
      "Train Epoch: 395 [10270/17352 (59%)] Loss: -709.949462\n",
      "Train Epoch: 395 [16988/17352 (98%)] Loss: -640.174014\n",
      "    epoch          : 395\n",
      "    loss           : -768.6114083185485\n",
      "    val_loss       : -661.9860420095094\n",
      "    val_log_likelihood: 1058.6094861920114\n",
      "    val_log_marginal: 684.5709470746019\n",
      "Train Epoch: 396 [512/17352 (3%)] Loss: -615.698914\n",
      "Train Epoch: 396 [10540/17352 (61%)] Loss: -865.990426\n",
      "Train Epoch: 396 [17126/17352 (99%)] Loss: -826.382719\n",
      "    epoch          : 396\n",
      "    loss           : -767.0707713215809\n",
      "    val_loss       : -654.0812467284477\n",
      "    val_log_likelihood: 1058.7813797561118\n",
      "    val_log_marginal: 671.0453562156903\n",
      "Train Epoch: 397 [512/17352 (3%)] Loss: -809.925415\n",
      "Train Epoch: 397 [10353/17352 (60%)] Loss: -840.082122\n",
      "Train Epoch: 397 [17124/17352 (99%)] Loss: -835.364714\n",
      "    epoch          : 397\n",
      "    loss           : -783.9789104507515\n",
      "    val_loss       : -668.7993378632116\n",
      "    val_log_likelihood: 1069.6807881638192\n",
      "    val_log_marginal: 686.5961400436612\n",
      "Train Epoch: 398 [512/17352 (3%)] Loss: -820.330505\n",
      "Train Epoch: 398 [10701/17352 (62%)] Loss: -819.181139\n",
      "Train Epoch: 398 [17106/17352 (99%)] Loss: -740.115002\n",
      "    epoch          : 398\n",
      "    loss           : -778.3856614475169\n",
      "    val_loss       : -643.5534987309129\n",
      "    val_log_likelihood: 1060.4599192926742\n",
      "    val_log_marginal: 661.0707709901199\n",
      "Train Epoch: 399 [512/17352 (3%)] Loss: -813.555725\n",
      "Train Epoch: 399 [10295/17352 (59%)] Loss: -863.087367\n",
      "Train Epoch: 399 [17049/17352 (98%)] Loss: -814.484256\n",
      "    epoch          : 399\n",
      "    loss           : -774.9101946951761\n",
      "    val_loss       : -673.2107677593825\n",
      "    val_log_likelihood: 1071.2086505016932\n",
      "    val_log_marginal: 695.7710458716577\n",
      "Train Epoch: 400 [512/17352 (3%)] Loss: -837.197144\n",
      "Train Epoch: 400 [9528/17352 (55%)] Loss: -719.896887\n",
      "Train Epoch: 400 [16923/17352 (98%)] Loss: -732.388889\n",
      "    epoch          : 400\n",
      "    loss           : -759.5825301756448\n",
      "    val_loss       : -662.2554370043789\n",
      "    val_log_likelihood: 1068.374353361449\n",
      "    val_log_marginal: 690.7331034127999\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch400.pth ...\n",
      "Train Epoch: 401 [512/17352 (3%)] Loss: -826.639709\n",
      "Train Epoch: 401 [9657/17352 (56%)] Loss: -871.787530\n",
      "Train Epoch: 401 [16882/17352 (97%)] Loss: -816.373271\n",
      "    epoch          : 401\n",
      "    loss           : -786.7034641270759\n",
      "    val_loss       : -672.1770943272383\n",
      "    val_log_likelihood: 1078.103088963844\n",
      "    val_log_marginal: 694.51167189353\n",
      "Train Epoch: 402 [512/17352 (3%)] Loss: -838.891785\n",
      "Train Epoch: 402 [10550/17352 (61%)] Loss: -759.139063\n",
      "Train Epoch: 402 [16958/17352 (98%)] Loss: -857.102545\n",
      "    epoch          : 402\n",
      "    loss           : -796.8870448966559\n",
      "    val_loss       : -651.1698043011215\n",
      "    val_log_likelihood: 1077.8896337701688\n",
      "    val_log_marginal: 669.65110217098\n",
      "Train Epoch: 403 [512/17352 (3%)] Loss: -807.971924\n",
      "Train Epoch: 403 [10295/17352 (59%)] Loss: -622.624709\n",
      "Train Epoch: 403 [16887/17352 (97%)] Loss: -822.382719\n",
      "    epoch          : 403\n",
      "    loss           : -742.6081568832188\n",
      "    val_loss       : -651.3217446809763\n",
      "    val_log_likelihood: 1073.6227365171183\n",
      "    val_log_marginal: 671.4794356236646\n",
      "Train Epoch: 404 [512/17352 (3%)] Loss: -797.022522\n",
      "Train Epoch: 404 [10120/17352 (58%)] Loss: -818.235008\n",
      "Train Epoch: 404 [17253/17352 (99%)] Loss: -811.981520\n",
      "    epoch          : 404\n",
      "    loss           : -724.3806979289568\n",
      "    val_loss       : -592.3981003021356\n",
      "    val_log_likelihood: 1023.8876411915354\n",
      "    val_log_marginal: 616.8661782914717\n",
      "Train Epoch: 405 [512/17352 (3%)] Loss: -766.062744\n",
      "Train Epoch: 405 [10434/17352 (60%)] Loss: -853.793592\n",
      "Train Epoch: 405 [17106/17352 (99%)] Loss: -683.157971\n",
      "    epoch          : 405\n",
      "    loss           : -754.4742488977895\n",
      "    val_loss       : -612.1379284106363\n",
      "    val_log_likelihood: 1039.3357626164106\n",
      "    val_log_marginal: 636.0510396174283\n",
      "Train Epoch: 406 [512/17352 (3%)] Loss: -802.866394\n",
      "Train Epoch: 406 [10634/17352 (61%)] Loss: -576.204691\n",
      "Train Epoch: 406 [17124/17352 (99%)] Loss: -781.486558\n",
      "    epoch          : 406\n",
      "    loss           : -763.6302179938697\n",
      "    val_loss       : -654.5184523310567\n",
      "    val_log_likelihood: 1064.3070095974304\n",
      "    val_log_marginal: 676.9725263825337\n",
      "Train Epoch: 407 [512/17352 (3%)] Loss: -826.107056\n",
      "Train Epoch: 407 [10770/17352 (62%)] Loss: -642.212634\n",
      "Train Epoch: 407 [16992/17352 (98%)] Loss: -620.861014\n",
      "    epoch          : 407\n",
      "    loss           : -787.2340116642401\n",
      "    val_loss       : -656.629788973532\n",
      "    val_log_likelihood: 1070.9111813272973\n",
      "    val_log_marginal: 681.1580427379336\n",
      "Train Epoch: 408 [512/17352 (3%)] Loss: -785.162109\n",
      "Train Epoch: 408 [9633/17352 (56%)] Loss: -819.996489\n",
      "Train Epoch: 408 [17101/17352 (99%)] Loss: -881.120173\n",
      "    epoch          : 408\n",
      "    loss           : -769.8421441909289\n",
      "    val_loss       : -618.8039769226161\n",
      "    val_log_likelihood: 1064.1654252488167\n",
      "    val_log_marginal: 638.1631731457979\n",
      "Train Epoch: 409 [512/17352 (3%)] Loss: -758.995239\n",
      "Train Epoch: 409 [10748/17352 (62%)] Loss: -539.919657\n",
      "Train Epoch: 409 [16988/17352 (98%)] Loss: -585.083042\n",
      "    epoch          : 409\n",
      "    loss           : -716.8597791442336\n",
      "    val_loss       : -638.7221401946495\n",
      "    val_log_likelihood: 1065.2716247829017\n",
      "    val_log_marginal: 661.4862942198513\n",
      "Train Epoch: 410 [512/17352 (3%)] Loss: -787.914795\n",
      "Train Epoch: 410 [10555/17352 (61%)] Loss: -631.913801\n",
      "Train Epoch: 410 [17108/17352 (99%)] Loss: -847.754446\n",
      "    epoch          : 410\n",
      "    loss           : -750.2885009034136\n",
      "    val_loss       : -579.2682307672947\n",
      "    val_log_likelihood: 1006.0923709587892\n",
      "    val_log_marginal: 605.0697948268446\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch410.pth ...\n",
      "Train Epoch: 411 [512/17352 (3%)] Loss: -717.829773\n",
      "Train Epoch: 411 [10279/17352 (59%)] Loss: -673.446311\n",
      "Train Epoch: 411 [17064/17352 (98%)] Loss: -802.663438\n",
      "    epoch          : 411\n",
      "    loss           : -738.9606597695125\n",
      "    val_loss       : -630.4374611803007\n",
      "    val_log_likelihood: 1053.3288437632325\n",
      "    val_log_marginal: 658.9652106968239\n",
      "Train Epoch: 412 [512/17352 (3%)] Loss: -806.439209\n",
      "Train Epoch: 412 [9608/17352 (55%)] Loss: -869.215194\n",
      "Train Epoch: 412 [17277/17352 (100%)] Loss: -848.492733\n",
      "    epoch          : 412\n",
      "    loss           : -764.4385682828038\n",
      "    val_loss       : -645.7489009234915\n",
      "    val_log_likelihood: 1065.817962689556\n",
      "    val_log_marginal: 669.576317719758\n",
      "Train Epoch: 413 [512/17352 (3%)] Loss: -824.932861\n",
      "Train Epoch: 413 [10542/17352 (61%)] Loss: -817.687500\n",
      "Train Epoch: 413 [16883/17352 (97%)] Loss: -618.859375\n",
      "    epoch          : 413\n",
      "    loss           : -726.4796586728123\n",
      "    val_loss       : -639.6922451074065\n",
      "    val_log_likelihood: 1066.817663612665\n",
      "    val_log_marginal: 658.913474341091\n",
      "Train Epoch: 414 [512/17352 (3%)] Loss: -785.212769\n",
      "Train Epoch: 414 [10877/17352 (63%)] Loss: -692.394996\n",
      "Train Epoch: 414 [17253/17352 (99%)] Loss: -885.896341\n",
      "    epoch          : 414\n",
      "    loss           : -754.3947816166964\n",
      "    val_loss       : -641.549096396005\n",
      "    val_log_likelihood: 1076.358453280072\n",
      "    val_log_marginal: 668.2102237169026\n",
      "Train Epoch: 415 [512/17352 (3%)] Loss: -807.273376\n",
      "Train Epoch: 415 [10482/17352 (60%)] Loss: -799.122253\n",
      "Train Epoch: 415 [17106/17352 (99%)] Loss: -667.177333\n",
      "    epoch          : 415\n",
      "    loss           : -789.7300750145754\n",
      "    val_loss       : -682.5889633209046\n",
      "    val_log_likelihood: 1092.9623357264638\n",
      "    val_log_marginal: 708.3401990699352\n",
      "Train Epoch: 416 [512/17352 (3%)] Loss: -848.033081\n",
      "Train Epoch: 416 [10705/17352 (62%)] Loss: -888.307424\n",
      "Train Epoch: 416 [16988/17352 (98%)] Loss: -746.621441\n",
      "    epoch          : 416\n",
      "    loss           : -804.7431962144915\n",
      "    val_loss       : -668.3504710651712\n",
      "    val_log_likelihood: 1088.3768280572074\n",
      "    val_log_marginal: 690.6712759751889\n",
      "Train Epoch: 417 [512/17352 (3%)] Loss: -843.966980\n",
      "Train Epoch: 417 [9928/17352 (57%)] Loss: -813.165122\n",
      "Train Epoch: 417 [16958/17352 (98%)] Loss: -757.174690\n",
      "    epoch          : 417\n",
      "    loss           : -769.4120227898829\n",
      "    val_loss       : -635.534984157211\n",
      "    val_log_likelihood: 1060.6813722887712\n",
      "    val_log_marginal: 661.818887289801\n",
      "Train Epoch: 418 [512/17352 (3%)] Loss: -803.013428\n",
      "Train Epoch: 418 [9976/17352 (57%)] Loss: -721.551107\n",
      "Train Epoch: 418 [16958/17352 (98%)] Loss: -686.477577\n",
      "    epoch          : 418\n",
      "    loss           : -772.1156200241173\n",
      "    val_loss       : -658.8407018029633\n",
      "    val_log_likelihood: 1083.1496897191385\n",
      "    val_log_marginal: 677.4291454974699\n",
      "Train Epoch: 419 [512/17352 (3%)] Loss: -828.716614\n",
      "Train Epoch: 419 [10131/17352 (58%)] Loss: -738.897837\n",
      "Train Epoch: 419 [16958/17352 (98%)] Loss: -765.011068\n",
      "    epoch          : 419\n",
      "    loss           : -708.5315364583824\n",
      "    val_loss       : -588.0958355650498\n",
      "    val_log_likelihood: 1057.8221447928188\n",
      "    val_log_marginal: 610.9940866277029\n",
      "Train Epoch: 420 [512/17352 (3%)] Loss: -773.145874\n",
      "Train Epoch: 420 [10367/17352 (60%)] Loss: -528.830242\n",
      "Train Epoch: 420 [16872/17352 (97%)] Loss: -807.286695\n",
      "    epoch          : 420\n",
      "    loss           : -687.7067171873451\n",
      "    val_loss       : -640.7512890835916\n",
      "    val_log_likelihood: 1065.2062365977706\n",
      "    val_log_marginal: 664.7255833879066\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch420.pth ...\n",
      "Train Epoch: 421 [512/17352 (3%)] Loss: -796.002869\n",
      "Train Epoch: 421 [10382/17352 (60%)] Loss: -705.605024\n",
      "Train Epoch: 421 [17253/17352 (99%)] Loss: -824.610775\n",
      "    epoch          : 421\n",
      "    loss           : -673.8441430608449\n",
      "    val_loss       : -158.7009883004054\n",
      "    val_log_likelihood: 1021.5702911222384\n",
      "    val_log_marginal: 188.47249057676464\n",
      "Train Epoch: 422 [512/17352 (3%)] Loss: -289.192627\n",
      "Train Epoch: 422 [10434/17352 (60%)] Loss: -626.264130\n",
      "Train Epoch: 422 [17133/17352 (99%)] Loss: -768.843496\n",
      "    epoch          : 422\n",
      "    loss           : -681.6536862589521\n",
      "    val_loss       : -633.7509401408441\n",
      "    val_log_likelihood: 1059.442737140874\n",
      "    val_log_marginal: 657.0450125788948\n",
      "Train Epoch: 423 [512/17352 (3%)] Loss: -773.377319\n",
      "Train Epoch: 423 [10341/17352 (60%)] Loss: -870.438553\n",
      "Train Epoch: 423 [17253/17352 (99%)] Loss: -581.063667\n",
      "    epoch          : 423\n",
      "    loss           : -741.2868898211354\n",
      "    val_loss       : -472.0029737830905\n",
      "    val_log_likelihood: 1054.825036538857\n",
      "    val_log_marginal: 487.53527886327316\n",
      "Train Epoch: 424 [512/17352 (3%)] Loss: -697.842224\n",
      "Train Epoch: 424 [10666/17352 (61%)] Loss: -845.297708\n",
      "Train Epoch: 424 [17090/17352 (98%)] Loss: -834.641253\n",
      "    epoch          : 424\n",
      "    loss           : -751.7703556654976\n",
      "    val_loss       : -668.759569337343\n",
      "    val_log_likelihood: 1078.6279838777805\n",
      "    val_log_marginal: 683.2450740369738\n",
      "Train Epoch: 425 [512/17352 (3%)] Loss: -823.397217\n",
      "Train Epoch: 425 [10248/17352 (59%)] Loss: -859.617343\n",
      "Train Epoch: 425 [16923/17352 (98%)] Loss: -898.332753\n",
      "    epoch          : 425\n",
      "    loss           : -799.2378192422576\n",
      "    val_loss       : -653.5909417513034\n",
      "    val_log_likelihood: 1080.9555493328683\n",
      "    val_log_marginal: 679.2416407256532\n",
      "Train Epoch: 426 [512/17352 (3%)] Loss: -817.150085\n",
      "Train Epoch: 426 [9813/17352 (57%)] Loss: -697.683594\n",
      "Train Epoch: 426 [16922/17352 (98%)] Loss: -843.094435\n",
      "    epoch          : 426\n",
      "    loss           : -783.1915335039296\n",
      "    val_loss       : -683.6656909043653\n",
      "    val_log_likelihood: 1082.4073815306128\n",
      "    val_log_marginal: 698.0985132351384\n",
      "Train Epoch: 427 [512/17352 (3%)] Loss: -660.490051\n",
      "Train Epoch: 427 [10544/17352 (61%)] Loss: -919.128038\n",
      "Train Epoch: 427 [16887/17352 (97%)] Loss: -734.707031\n",
      "    epoch          : 427\n",
      "    loss           : -792.3838590233375\n",
      "    val_loss       : -672.8426891263779\n",
      "    val_log_likelihood: 1094.4220794232797\n",
      "    val_log_marginal: 687.926312761009\n",
      "Train Epoch: 428 [512/17352 (3%)] Loss: -850.583740\n",
      "Train Epoch: 428 [10506/17352 (61%)] Loss: -828.211954\n",
      "Train Epoch: 428 [17016/17352 (98%)] Loss: 3092.714286\n",
      "    epoch          : 428\n",
      "    loss           : -425.03372807710247\n",
      "    val_loss       : 1130.2302520235978\n",
      "    val_log_likelihood: 927.423179502912\n",
      "    val_log_marginal: -1075.584178352153\n",
      "Train Epoch: 429 [512/17352 (3%)] Loss: 760.062378\n",
      "Train Epoch: 429 [10833/17352 (62%)] Loss: -472.547908\n",
      "Train Epoch: 429 [17101/17352 (99%)] Loss: -527.682812\n",
      "    epoch          : 429\n",
      "    loss           : -214.00959435258767\n",
      "    val_loss       : -430.55720154153875\n",
      "    val_log_likelihood: 865.6959099035021\n",
      "    val_log_marginal: 473.3951116770467\n",
      "Train Epoch: 430 [512/17352 (3%)] Loss: -665.626892\n",
      "Train Epoch: 430 [10399/17352 (60%)] Loss: -592.151177\n",
      "Train Epoch: 430 [16988/17352 (98%)] Loss: -766.717082\n",
      "    epoch          : 430\n",
      "    loss           : -656.8683294928888\n",
      "    val_loss       : -565.5351614792863\n",
      "    val_log_likelihood: 996.2938193097477\n",
      "    val_log_marginal: 610.4497655392322\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch430.pth ...\n",
      "Train Epoch: 431 [512/17352 (3%)] Loss: -657.078613\n",
      "Train Epoch: 431 [9896/17352 (57%)] Loss: -794.952774\n",
      "Train Epoch: 431 [16923/17352 (98%)] Loss: -685.332944\n",
      "    epoch          : 431\n",
      "    loss           : -737.2200171416428\n",
      "    val_loss       : -650.4483610405917\n",
      "    val_log_likelihood: 1047.3858515352624\n",
      "    val_log_marginal: 679.429307511195\n",
      "Train Epoch: 432 [512/17352 (3%)] Loss: -816.119995\n",
      "Train Epoch: 432 [10269/17352 (59%)] Loss: -762.225329\n",
      "Train Epoch: 432 [16882/17352 (97%)] Loss: -741.659697\n",
      "    epoch          : 432\n",
      "    loss           : -778.8854802743662\n",
      "    val_loss       : -663.8232787343256\n",
      "    val_log_likelihood: 1064.4251673813283\n",
      "    val_log_marginal: 690.9061847114403\n",
      "Train Epoch: 433 [512/17352 (3%)] Loss: -807.085938\n",
      "Train Epoch: 433 [10667/17352 (61%)] Loss: -899.079222\n",
      "Train Epoch: 433 [17126/17352 (99%)] Loss: -638.545027\n",
      "    epoch          : 433\n",
      "    loss           : -777.746002821329\n",
      "    val_loss       : -679.8007956055637\n",
      "    val_log_likelihood: 1082.4290104322092\n",
      "    val_log_marginal: 702.7741409132279\n",
      "Train Epoch: 434 [512/17352 (3%)] Loss: -821.895752\n",
      "Train Epoch: 434 [10305/17352 (59%)] Loss: -682.382284\n",
      "Train Epoch: 434 [16887/17352 (97%)] Loss: -900.667810\n",
      "    epoch          : 434\n",
      "    loss           : -793.9309825112028\n",
      "    val_loss       : -683.1692837339364\n",
      "    val_log_likelihood: 1083.2114993843863\n",
      "    val_log_marginal: 700.9403588800876\n",
      "Train Epoch: 435 [512/17352 (3%)] Loss: -839.079956\n",
      "Train Epoch: 435 [10103/17352 (58%)] Loss: -767.722369\n",
      "Train Epoch: 435 [17133/17352 (99%)] Loss: -870.050781\n",
      "    epoch          : 435\n",
      "    loss           : -794.7667557569682\n",
      "    val_loss       : -671.9144536087447\n",
      "    val_log_likelihood: 1079.619253666591\n",
      "    val_log_marginal: 692.2090011638364\n",
      "Train Epoch: 436 [512/17352 (3%)] Loss: -839.773071\n",
      "Train Epoch: 436 [10198/17352 (59%)] Loss: -873.444363\n",
      "Train Epoch: 436 [16939/17352 (98%)] Loss: -895.626905\n",
      "    epoch          : 436\n",
      "    loss           : -801.7524620208649\n",
      "    val_loss       : -683.968334399551\n",
      "    val_log_likelihood: 1091.7695770358648\n",
      "    val_log_marginal: 704.2334350618669\n",
      "Train Epoch: 437 [512/17352 (3%)] Loss: -857.765564\n",
      "Train Epoch: 437 [10579/17352 (61%)] Loss: -826.275195\n",
      "Train Epoch: 437 [16887/17352 (97%)] Loss: -888.461410\n",
      "    epoch          : 437\n",
      "    loss           : -804.4730642929991\n",
      "    val_loss       : -687.9033359112669\n",
      "    val_log_likelihood: 1096.4815102325517\n",
      "    val_log_marginal: 706.1285149467784\n",
      "Train Epoch: 438 [512/17352 (3%)] Loss: -841.130676\n",
      "Train Epoch: 438 [9583/17352 (55%)] Loss: -750.030963\n",
      "Train Epoch: 438 [16923/17352 (98%)] Loss: -765.132208\n",
      "    epoch          : 438\n",
      "    loss           : -807.7396340353546\n",
      "    val_loss       : -689.7398079454811\n",
      "    val_log_likelihood: 1099.0640254032635\n",
      "    val_log_marginal: 710.9079092688431\n",
      "Train Epoch: 439 [512/17352 (3%)] Loss: -786.345154\n",
      "Train Epoch: 439 [10350/17352 (60%)] Loss: -879.048471\n",
      "Train Epoch: 439 [16878/17352 (97%)] Loss: -745.233160\n",
      "    epoch          : 439\n",
      "    loss           : -796.5403522996438\n",
      "    val_loss       : -682.7428076415057\n",
      "    val_log_likelihood: 1095.7334187190388\n",
      "    val_log_marginal: 704.4539347189977\n",
      "Train Epoch: 440 [512/17352 (3%)] Loss: -856.942688\n",
      "Train Epoch: 440 [10263/17352 (59%)] Loss: -691.455784\n",
      "Train Epoch: 440 [17049/17352 (98%)] Loss: -854.786780\n",
      "    epoch          : 440\n",
      "    loss           : -803.8578048316999\n",
      "    val_loss       : -654.5102732452258\n",
      "    val_log_likelihood: 1060.053459712583\n",
      "    val_log_marginal: 673.6972175135943\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch440.pth ...\n",
      "Train Epoch: 441 [512/17352 (3%)] Loss: -830.632812\n",
      "Train Epoch: 441 [9624/17352 (55%)] Loss: -664.520933\n",
      "Train Epoch: 441 [16878/17352 (97%)] Loss: -754.726837\n",
      "    epoch          : 441\n",
      "    loss           : -778.9502211757115\n",
      "    val_loss       : -671.019545911839\n",
      "    val_log_likelihood: 1090.0764277918452\n",
      "    val_log_marginal: 695.4119514256429\n",
      "Train Epoch: 442 [512/17352 (3%)] Loss: -830.481262\n",
      "Train Epoch: 442 [10313/17352 (59%)] Loss: -865.878021\n",
      "Train Epoch: 442 [16872/17352 (97%)] Loss: -652.348522\n",
      "    epoch          : 442\n",
      "    loss           : -790.7060654452862\n",
      "    val_loss       : -673.5231477080433\n",
      "    val_log_likelihood: 1089.742307265311\n",
      "    val_log_marginal: 695.9507932612847\n",
      "Train Epoch: 443 [512/17352 (3%)] Loss: -845.335083\n",
      "Train Epoch: 443 [10382/17352 (60%)] Loss: -746.354567\n",
      "Train Epoch: 443 [17153/17352 (99%)] Loss: -758.850026\n",
      "    epoch          : 443\n",
      "    loss           : -801.0958747019325\n",
      "    val_loss       : -665.5622498519148\n",
      "    val_log_likelihood: 1094.9608519836502\n",
      "    val_log_marginal: 682.6229923932997\n",
      "Train Epoch: 444 [512/17352 (3%)] Loss: -814.090759\n",
      "Train Epoch: 444 [9707/17352 (56%)] Loss: -908.425495\n",
      "Train Epoch: 444 [17124/17352 (99%)] Loss: -945.034722\n",
      "    epoch          : 444\n",
      "    loss           : -787.9509019749661\n",
      "    val_loss       : -675.2962951649049\n",
      "    val_log_likelihood: 1098.2213093956393\n",
      "    val_log_marginal: 695.8502557148317\n",
      "Train Epoch: 445 [512/17352 (3%)] Loss: -842.439148\n",
      "Train Epoch: 445 [10235/17352 (59%)] Loss: -761.371573\n",
      "Train Epoch: 445 [17016/17352 (98%)] Loss: -832.021278\n",
      "    epoch          : 445\n",
      "    loss           : -793.6395907960873\n",
      "    val_loss       : -662.8008601258108\n",
      "    val_log_likelihood: 1091.8670966536295\n",
      "    val_log_marginal: 683.1004824567866\n",
      "Train Epoch: 446 [512/17352 (3%)] Loss: -833.497253\n",
      "Train Epoch: 446 [10077/17352 (58%)] Loss: -912.701280\n",
      "Train Epoch: 446 [17108/17352 (99%)] Loss: -781.145716\n",
      "    epoch          : 446\n",
      "    loss           : -778.2494684082892\n",
      "    val_loss       : -495.24856106941246\n",
      "    val_log_likelihood: 1086.2156523193823\n",
      "    val_log_marginal: 514.4317589171112\n",
      "Train Epoch: 447 [512/17352 (3%)] Loss: -693.001160\n",
      "Train Epoch: 447 [10463/17352 (60%)] Loss: -810.260601\n",
      "Train Epoch: 447 [16878/17352 (97%)] Loss: -811.444076\n",
      "    epoch          : 447\n",
      "    loss           : -726.0938644041469\n",
      "    val_loss       : -645.6867222332661\n",
      "    val_log_likelihood: 1078.26582925059\n",
      "    val_log_marginal: 668.4365701332235\n",
      "Train Epoch: 448 [512/17352 (3%)] Loss: -818.379028\n",
      "Train Epoch: 448 [10785/17352 (62%)] Loss: -749.029931\n",
      "Train Epoch: 448 [17263/17352 (99%)] Loss: -580.582997\n",
      "    epoch          : 448\n",
      "    loss           : -771.3735881843626\n",
      "    val_loss       : -646.7186844062803\n",
      "    val_log_likelihood: 1081.632596851723\n",
      "    val_log_marginal: 677.911145554753\n",
      "Train Epoch: 449 [512/17352 (3%)] Loss: -769.353271\n",
      "Train Epoch: 449 [10690/17352 (62%)] Loss: -837.169663\n",
      "Train Epoch: 449 [17064/17352 (98%)] Loss: -750.593021\n",
      "    epoch          : 449\n",
      "    loss           : -743.2861907703693\n",
      "    val_loss       : -567.1240150478627\n",
      "    val_log_likelihood: 1041.6787188415624\n",
      "    val_log_marginal: 621.7064667624808\n",
      "Train Epoch: 450 [512/17352 (3%)] Loss: -757.026978\n",
      "Train Epoch: 450 [10025/17352 (58%)] Loss: -613.747954\n",
      "Train Epoch: 450 [16878/17352 (97%)] Loss: -635.236489\n",
      "    epoch          : 450\n",
      "    loss           : -715.533820938884\n",
      "    val_loss       : -642.6512924897893\n",
      "    val_log_likelihood: 1068.919761205388\n",
      "    val_log_marginal: 680.4911007053156\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch450.pth ...\n",
      "Train Epoch: 451 [512/17352 (3%)] Loss: -814.614746\n",
      "Train Epoch: 451 [10094/17352 (58%)] Loss: -867.721208\n",
      "Train Epoch: 451 [17108/17352 (99%)] Loss: -864.791459\n",
      "    epoch          : 451\n",
      "    loss           : -788.255613407326\n",
      "    val_loss       : -664.1178738364893\n",
      "    val_log_likelihood: 1084.5111328733353\n",
      "    val_log_marginal: 691.1339690139828\n",
      "Train Epoch: 452 [512/17352 (3%)] Loss: -790.863037\n",
      "Train Epoch: 452 [10892/17352 (63%)] Loss: -749.619330\n",
      "Train Epoch: 452 [17049/17352 (98%)] Loss: -740.841315\n",
      "    epoch          : 452\n",
      "    loss           : -800.0062907879724\n",
      "    val_loss       : -661.818384076741\n",
      "    val_log_likelihood: 1088.9587591308323\n",
      "    val_log_marginal: 688.4040982054936\n",
      "Train Epoch: 453 [512/17352 (3%)] Loss: -843.875183\n",
      "Train Epoch: 453 [10742/17352 (62%)] Loss: -709.121926\n",
      "Train Epoch: 453 [17253/17352 (99%)] Loss: -823.739354\n",
      "    epoch          : 453\n",
      "    loss           : -814.4732908570458\n",
      "    val_loss       : -678.9617228782172\n",
      "    val_log_likelihood: 1111.0457040144972\n",
      "    val_log_marginal: 704.5599795376455\n",
      "Train Epoch: 454 [512/17352 (3%)] Loss: -823.496887\n",
      "Train Epoch: 454 [10861/17352 (63%)] Loss: -718.043415\n",
      "Train Epoch: 454 [16878/17352 (97%)] Loss: -861.620312\n",
      "    epoch          : 454\n",
      "    loss           : -818.0742572524176\n",
      "    val_loss       : -686.7403693709014\n",
      "    val_log_likelihood: 1113.3893954845655\n",
      "    val_log_marginal: 712.0184634130045\n",
      "Train Epoch: 455 [512/17352 (3%)] Loss: -861.339600\n",
      "Train Epoch: 455 [10434/17352 (60%)] Loss: -866.341011\n",
      "Train Epoch: 455 [17044/17352 (98%)] Loss: -855.501894\n",
      "    epoch          : 455\n",
      "    loss           : -823.5671856988415\n",
      "    val_loss       : -691.2342796159451\n",
      "    val_log_likelihood: 1115.1301768892988\n",
      "    val_log_marginal: 710.9472546242745\n",
      "Train Epoch: 456 [512/17352 (3%)] Loss: -879.827576\n",
      "Train Epoch: 456 [10592/17352 (61%)] Loss: -923.350610\n",
      "Train Epoch: 456 [17090/17352 (98%)] Loss: -839.790122\n",
      "    epoch          : 456\n",
      "    loss           : -807.40668825796\n",
      "    val_loss       : -644.0338154015648\n",
      "    val_log_likelihood: 1073.7671427438465\n",
      "    val_log_marginal: 665.4947664874576\n",
      "Train Epoch: 457 [512/17352 (3%)] Loss: -789.261230\n",
      "Train Epoch: 457 [9727/17352 (56%)] Loss: -882.444814\n",
      "Train Epoch: 457 [16958/17352 (98%)] Loss: -848.703581\n",
      "    epoch          : 457\n",
      "    loss           : -804.7755968207318\n",
      "    val_loss       : -688.3173571984186\n",
      "    val_log_likelihood: 1114.477790554156\n",
      "    val_log_marginal: 705.6404257747298\n",
      "Train Epoch: 458 [512/17352 (3%)] Loss: -869.928406\n",
      "Train Epoch: 458 [9870/17352 (57%)] Loss: -900.589583\n",
      "Train Epoch: 458 [16939/17352 (98%)] Loss: -851.794598\n",
      "    epoch          : 458\n",
      "    loss           : -819.6819343020348\n",
      "    val_loss       : -688.3212111280914\n",
      "    val_log_likelihood: 1119.7086774188626\n",
      "    val_log_marginal: 706.3835903577257\n",
      "Train Epoch: 459 [512/17352 (3%)] Loss: -877.328125\n",
      "Train Epoch: 459 [10089/17352 (58%)] Loss: -725.072170\n",
      "Train Epoch: 459 [16922/17352 (98%)] Loss: 2182.755696\n",
      "    epoch          : 459\n",
      "    loss           : 2218.751228197426\n",
      "    val_loss       : 1359.9241646089738\n",
      "    val_log_likelihood: 162.24353306996082\n",
      "    val_log_marginal: -1237.9437815190854\n",
      "Train Epoch: 460 [512/17352 (3%)] Loss: 1755.540161\n",
      "Train Epoch: 460 [10515/17352 (61%)] Loss: 20.730077\n",
      "Train Epoch: 460 [16957/17352 (98%)] Loss: -99.945364\n",
      "    epoch          : 460\n",
      "    loss           : 205.98959901957997\n",
      "    val_loss       : -276.4117307088964\n",
      "    val_log_likelihood: 777.225994071064\n",
      "    val_log_marginal: 327.4016799211337\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch460.pth ...\n",
      "Train Epoch: 461 [512/17352 (3%)] Loss: -379.360107\n",
      "Train Epoch: 461 [9856/17352 (57%)] Loss: -682.007856\n",
      "Train Epoch: 461 [17277/17352 (100%)] Loss: -654.279043\n",
      "    epoch          : 461\n",
      "    loss           : -529.0019806311908\n",
      "    val_loss       : -522.1082292109215\n",
      "    val_log_likelihood: 929.9961514400723\n",
      "    val_log_marginal: 561.7108829913861\n",
      "Train Epoch: 462 [512/17352 (3%)] Loss: -687.577209\n",
      "Train Epoch: 462 [10489/17352 (60%)] Loss: -746.626936\n",
      "Train Epoch: 462 [16958/17352 (98%)] Loss: -819.619930\n",
      "    epoch          : 462\n",
      "    loss           : -664.6915392915874\n",
      "    val_loss       : -595.3811380402254\n",
      "    val_log_likelihood: 991.1941564367802\n",
      "    val_log_marginal: 629.464091699682\n",
      "Train Epoch: 463 [512/17352 (3%)] Loss: -742.835388\n",
      "Train Epoch: 463 [9940/17352 (57%)] Loss: -670.243967\n",
      "Train Epoch: 463 [16922/17352 (98%)] Loss: -677.152536\n",
      "    epoch          : 463\n",
      "    loss           : -719.1752407061687\n",
      "    val_loss       : -640.2141368140122\n",
      "    val_log_likelihood: 1019.8457938527952\n",
      "    val_log_marginal: 665.2924443314262\n",
      "Train Epoch: 464 [512/17352 (3%)] Loss: -782.453186\n",
      "Train Epoch: 464 [10387/17352 (60%)] Loss: -789.655420\n",
      "Train Epoch: 464 [16958/17352 (98%)] Loss: -797.748134\n",
      "    epoch          : 464\n",
      "    loss           : -743.5097124211003\n",
      "    val_loss       : -655.8291690424952\n",
      "    val_log_likelihood: 1025.8757726689173\n",
      "    val_log_marginal: 674.1162366822908\n",
      "Train Epoch: 465 [512/17352 (3%)] Loss: -789.924194\n",
      "Train Epoch: 465 [10361/17352 (60%)] Loss: -735.622489\n",
      "Train Epoch: 465 [16878/17352 (97%)] Loss: -730.736842\n",
      "    epoch          : 465\n",
      "    loss           : -751.1443612305105\n",
      "    val_loss       : -664.2692480180846\n",
      "    val_log_likelihood: 1039.9457942698405\n",
      "    val_log_marginal: 683.6547987143061\n",
      "Train Epoch: 466 [512/17352 (3%)] Loss: -808.992004\n",
      "Train Epoch: 466 [10477/17352 (60%)] Loss: -826.838185\n",
      "Train Epoch: 466 [17143/17352 (99%)] Loss: -829.271041\n",
      "    epoch          : 466\n",
      "    loss           : -765.8585394666852\n",
      "    val_loss       : -666.169426378245\n",
      "    val_log_likelihood: 1050.6284670381144\n",
      "    val_log_marginal: 687.8109005523871\n",
      "Train Epoch: 467 [512/17352 (3%)] Loss: -804.644104\n",
      "Train Epoch: 467 [10270/17352 (59%)] Loss: -754.192210\n",
      "Train Epoch: 467 [16957/17352 (98%)] Loss: -813.165653\n",
      "    epoch          : 467\n",
      "    loss           : -773.0179475014928\n",
      "    val_loss       : -671.6489261156439\n",
      "    val_log_likelihood: 1055.968393992614\n",
      "    val_log_marginal: 691.5274696363083\n",
      "Train Epoch: 468 [512/17352 (3%)] Loss: -828.478394\n",
      "Train Epoch: 468 [10269/17352 (59%)] Loss: -734.309759\n",
      "Train Epoch: 468 [17153/17352 (99%)] Loss: -851.525933\n",
      "    epoch          : 468\n",
      "    loss           : -769.8250302761221\n",
      "    val_loss       : -664.135009366267\n",
      "    val_log_likelihood: 1054.614394413934\n",
      "    val_log_marginal: 684.4425999386145\n",
      "Train Epoch: 469 [512/17352 (3%)] Loss: -769.084900\n",
      "Train Epoch: 469 [9988/17352 (58%)] Loss: -797.526181\n",
      "Train Epoch: 469 [17277/17352 (100%)] Loss: -764.784856\n",
      "    epoch          : 469\n",
      "    loss           : -735.2198086495187\n",
      "    val_loss       : -661.0174383335891\n",
      "    val_log_likelihood: 1051.4126711983827\n",
      "    val_log_marginal: 681.6655533142573\n",
      "Train Epoch: 470 [512/17352 (3%)] Loss: -806.888428\n",
      "Train Epoch: 470 [10545/17352 (61%)] Loss: -761.465831\n",
      "Train Epoch: 470 [16922/17352 (98%)] Loss: -875.906117\n",
      "    epoch          : 470\n",
      "    loss           : -773.9840482619167\n",
      "    val_loss       : -671.0023878680937\n",
      "    val_log_likelihood: 1067.7409710934967\n",
      "    val_log_marginal: 696.2216471687822\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch470.pth ...\n",
      "Train Epoch: 471 [512/17352 (3%)] Loss: -829.380310\n",
      "Train Epoch: 471 [10687/17352 (62%)] Loss: -828.582487\n",
      "Train Epoch: 471 [16958/17352 (98%)] Loss: -831.851977\n",
      "    epoch          : 471\n",
      "    loss           : -783.4881730838837\n",
      "    val_loss       : -669.5285276318946\n",
      "    val_log_likelihood: 1067.2224847173918\n",
      "    val_log_marginal: 696.8013919595423\n",
      "Train Epoch: 472 [512/17352 (3%)] Loss: -809.462097\n",
      "Train Epoch: 472 [10466/17352 (60%)] Loss: -665.695953\n",
      "Train Epoch: 472 [17143/17352 (99%)] Loss: -694.709310\n",
      "    epoch          : 472\n",
      "    loss           : -785.6762848738309\n",
      "    val_loss       : -676.0225031752274\n",
      "    val_log_likelihood: 1076.1138541957616\n",
      "    val_log_marginal: 697.4337299777927\n",
      "Train Epoch: 473 [512/17352 (3%)] Loss: -835.587585\n",
      "Train Epoch: 473 [10527/17352 (61%)] Loss: -804.651278\n",
      "Train Epoch: 473 [17101/17352 (99%)] Loss: -862.480885\n",
      "    epoch          : 473\n",
      "    loss           : -790.7428303315595\n",
      "    val_loss       : -681.5518506147104\n",
      "    val_log_likelihood: 1078.5307879306934\n",
      "    val_log_marginal: 695.7897609555937\n",
      "Train Epoch: 474 [512/17352 (3%)] Loss: -845.765015\n",
      "Train Epoch: 474 [10261/17352 (59%)] Loss: -742.218229\n",
      "Train Epoch: 474 [16883/17352 (97%)] Loss: -734.127181\n",
      "    epoch          : 474\n",
      "    loss           : -800.3814427749716\n",
      "    val_loss       : -692.51632197891\n",
      "    val_log_likelihood: 1086.1639535648371\n",
      "    val_log_marginal: 708.7461070950692\n",
      "Train Epoch: 475 [512/17352 (3%)] Loss: -858.603943\n",
      "Train Epoch: 475 [10276/17352 (59%)] Loss: -853.737123\n",
      "Train Epoch: 475 [16882/17352 (97%)] Loss: -834.373330\n",
      "    epoch          : 475\n",
      "    loss           : -807.5131303894238\n",
      "    val_loss       : -694.1762849911177\n",
      "    val_log_likelihood: 1087.2829965551982\n",
      "    val_log_marginal: 707.1266063569685\n",
      "Train Epoch: 476 [512/17352 (3%)] Loss: -853.896240\n",
      "Train Epoch: 476 [10042/17352 (58%)] Loss: -895.436611\n",
      "Train Epoch: 476 [16887/17352 (97%)] Loss: -855.185502\n",
      "    epoch          : 476\n",
      "    loss           : -809.3307717022743\n",
      "    val_loss       : -697.1940370482985\n",
      "    val_log_likelihood: 1091.0973967866807\n",
      "    val_log_marginal: 714.3669421905281\n",
      "Train Epoch: 477 [512/17352 (3%)] Loss: -855.246704\n",
      "Train Epoch: 477 [10243/17352 (59%)] Loss: -830.970242\n",
      "Train Epoch: 477 [16887/17352 (97%)] Loss: -768.025670\n",
      "    epoch          : 477\n",
      "    loss           : -800.8355257087313\n",
      "    val_loss       : -682.1413151117142\n",
      "    val_log_likelihood: 1093.115259097994\n",
      "    val_log_marginal: 709.9221173932979\n",
      "Train Epoch: 478 [512/17352 (3%)] Loss: -844.689575\n",
      "Train Epoch: 478 [10479/17352 (60%)] Loss: -740.859045\n",
      "Train Epoch: 478 [16882/17352 (97%)] Loss: -888.302215\n",
      "    epoch          : 478\n",
      "    loss           : -796.9449566601604\n",
      "    val_loss       : -690.179984209927\n",
      "    val_log_likelihood: 1095.8846174555008\n",
      "    val_log_marginal: 711.5609959178532\n",
      "Train Epoch: 479 [512/17352 (3%)] Loss: -843.478271\n",
      "Train Epoch: 479 [10499/17352 (61%)] Loss: -758.441927\n",
      "Train Epoch: 479 [17335/17352 (100%)] Loss: -669.372917\n",
      "    epoch          : 479\n",
      "    loss           : -813.4391472859453\n",
      "    val_loss       : -692.7823059203876\n",
      "    val_log_likelihood: 1094.4026386605028\n",
      "    val_log_marginal: 708.8551065934017\n",
      "Train Epoch: 480 [512/17352 (3%)] Loss: -695.053223\n",
      "Train Epoch: 480 [10380/17352 (60%)] Loss: -841.610210\n",
      "Train Epoch: 480 [16923/17352 (98%)] Loss: -889.476213\n",
      "    epoch          : 480\n",
      "    loss           : -822.304832186697\n",
      "    val_loss       : -690.9109256823774\n",
      "    val_log_likelihood: 1099.7338074566492\n",
      "    val_log_marginal: 711.1642330904461\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch480.pth ...\n",
      "Train Epoch: 481 [512/17352 (3%)] Loss: -852.044861\n",
      "Train Epoch: 481 [10872/17352 (63%)] Loss: -898.332516\n",
      "Train Epoch: 481 [17126/17352 (99%)] Loss: -892.526919\n",
      "    epoch          : 481\n",
      "    loss           : -821.382334029134\n",
      "    val_loss       : -697.0332526200796\n",
      "    val_log_likelihood: 1104.2079396419888\n",
      "    val_log_marginal: 716.7058157233147\n",
      "Train Epoch: 482 [512/17352 (3%)] Loss: -869.531982\n",
      "Train Epoch: 482 [9996/17352 (58%)] Loss: -764.596453\n",
      "Train Epoch: 482 [17253/17352 (99%)] Loss: -763.848164\n",
      "    epoch          : 482\n",
      "    loss           : -824.7199014591902\n",
      "    val_loss       : -693.6602873729663\n",
      "    val_log_likelihood: 1103.4500896590573\n",
      "    val_log_marginal: 709.2470170071198\n",
      "Train Epoch: 483 [512/17352 (3%)] Loss: -862.336060\n",
      "Train Epoch: 483 [10600/17352 (61%)] Loss: -679.380390\n",
      "Train Epoch: 483 [17090/17352 (98%)] Loss: -880.530983\n",
      "    epoch          : 483\n",
      "    loss           : -816.238265724748\n",
      "    val_loss       : -685.8830747044135\n",
      "    val_log_likelihood: 1099.2096130152925\n",
      "    val_log_marginal: 705.8498739022635\n",
      "Train Epoch: 484 [512/17352 (3%)] Loss: -852.512817\n",
      "Train Epoch: 484 [10220/17352 (59%)] Loss: -667.045754\n",
      "Train Epoch: 484 [17143/17352 (99%)] Loss: -946.102539\n",
      "    epoch          : 484\n",
      "    loss           : -823.5586091757048\n",
      "    val_loss       : -697.5815279677511\n",
      "    val_log_likelihood: 1108.9108580087757\n",
      "    val_log_marginal: 713.0237146652014\n",
      "Train Epoch: 485 [512/17352 (3%)] Loss: -867.077759\n",
      "Train Epoch: 485 [10514/17352 (61%)] Loss: -819.502810\n",
      "Train Epoch: 485 [17106/17352 (99%)] Loss: -931.944386\n",
      "    epoch          : 485\n",
      "    loss           : -827.5854851325414\n",
      "    val_loss       : -671.6037076257311\n",
      "    val_log_likelihood: 1096.1277485577664\n",
      "    val_log_marginal: 689.5140024797324\n",
      "Train Epoch: 486 [512/17352 (3%)] Loss: -848.426086\n",
      "Train Epoch: 486 [10432/17352 (60%)] Loss: -658.180126\n",
      "Train Epoch: 486 [16878/17352 (97%)] Loss: -782.198832\n",
      "    epoch          : 486\n",
      "    loss           : -800.1162878213491\n",
      "    val_loss       : -678.0133501380539\n",
      "    val_log_likelihood: 1108.4550309312526\n",
      "    val_log_marginal: 701.7131999213518\n",
      "Train Epoch: 487 [512/17352 (3%)] Loss: -863.872681\n",
      "Train Epoch: 487 [10327/17352 (60%)] Loss: -686.095761\n",
      "Train Epoch: 487 [17335/17352 (100%)] Loss: -883.349796\n",
      "    epoch          : 487\n",
      "    loss           : -805.185026771644\n",
      "    val_loss       : -676.22177186463\n",
      "    val_log_likelihood: 1103.9859964188272\n",
      "    val_log_marginal: 698.9204456479648\n",
      "Train Epoch: 488 [512/17352 (3%)] Loss: -848.978149\n",
      "Train Epoch: 488 [10827/17352 (62%)] Loss: -906.882832\n",
      "Train Epoch: 488 [17108/17352 (99%)] Loss: -717.315632\n",
      "    epoch          : 488\n",
      "    loss           : -825.6276592142514\n",
      "    val_loss       : -706.4434863867575\n",
      "    val_log_likelihood: 1120.067786332374\n",
      "    val_log_marginal: 725.0894997004217\n",
      "Train Epoch: 489 [512/17352 (3%)] Loss: -861.665588\n",
      "Train Epoch: 489 [11230/17352 (65%)] Loss: -662.514180\n",
      "Train Epoch: 489 [16934/17352 (98%)] Loss: -930.250908\n",
      "    epoch          : 489\n",
      "    loss           : -825.0532450935951\n",
      "    val_loss       : -696.9096901713748\n",
      "    val_log_likelihood: 1115.5202208024343\n",
      "    val_log_marginal: 720.1783752434417\n",
      "Train Epoch: 490 [512/17352 (3%)] Loss: -851.027039\n",
      "Train Epoch: 490 [10855/17352 (63%)] Loss: -895.723765\n",
      "Train Epoch: 490 [17049/17352 (98%)] Loss: -814.215436\n",
      "    epoch          : 490\n",
      "    loss           : -824.6358799853189\n",
      "    val_loss       : -682.3072755501912\n",
      "    val_log_likelihood: 1112.2117325260697\n",
      "    val_log_marginal: 708.9752961339917\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch490.pth ...\n",
      "Train Epoch: 491 [512/17352 (3%)] Loss: -686.621216\n",
      "Train Epoch: 491 [10659/17352 (61%)] Loss: -866.915467\n",
      "Train Epoch: 491 [17016/17352 (98%)] Loss: -889.591667\n",
      "    epoch          : 491\n",
      "    loss           : -811.5745466336157\n",
      "    val_loss       : -641.1758051154377\n",
      "    val_log_likelihood: 1105.0781249802058\n",
      "    val_log_marginal: 694.3049174280803\n",
      "Train Epoch: 492 [512/17352 (3%)] Loss: -866.011230\n",
      "Train Epoch: 492 [10386/17352 (60%)] Loss: -724.311688\n",
      "Train Epoch: 492 [17253/17352 (99%)] Loss: -822.743086\n",
      "    epoch          : 492\n",
      "    loss           : -784.208327914163\n",
      "    val_loss       : -644.7408476364999\n",
      "    val_log_likelihood: 1102.6094983883277\n",
      "    val_log_marginal: 681.6956899595033\n",
      "Train Epoch: 493 [512/17352 (3%)] Loss: -807.274780\n",
      "Train Epoch: 493 [10009/17352 (58%)] Loss: -732.919632\n",
      "Train Epoch: 493 [16887/17352 (97%)] Loss: -897.125176\n",
      "    epoch          : 493\n",
      "    loss           : -805.9156057728098\n",
      "    val_loss       : -699.5676250236586\n",
      "    val_log_likelihood: 1118.3057959004395\n",
      "    val_log_marginal: 719.4106885111444\n",
      "Train Epoch: 494 [512/17352 (3%)] Loss: -865.748169\n",
      "Train Epoch: 494 [10549/17352 (61%)] Loss: -758.817840\n",
      "Train Epoch: 494 [16988/17352 (98%)] Loss: -761.941964\n",
      "    epoch          : 494\n",
      "    loss           : -832.9544801446845\n",
      "    val_loss       : -703.4914473652442\n",
      "    val_log_likelihood: 1127.7218353444405\n",
      "    val_log_marginal: 726.2850195905469\n",
      "Train Epoch: 495 [512/17352 (3%)] Loss: -856.227783\n",
      "Train Epoch: 495 [10950/17352 (63%)] Loss: -950.452482\n",
      "Train Epoch: 495 [17016/17352 (98%)] Loss: -680.417165\n",
      "    epoch          : 495\n",
      "    loss           : -836.2202744987803\n",
      "    val_loss       : -704.2145174987875\n",
      "    val_log_likelihood: 1124.8871139991988\n",
      "    val_log_marginal: 719.3985615737969\n",
      "Train Epoch: 496 [512/17352 (3%)] Loss: -885.229248\n",
      "Train Epoch: 496 [10201/17352 (59%)] Loss: -911.392880\n",
      "Train Epoch: 496 [17108/17352 (99%)] Loss: -803.584635\n",
      "    epoch          : 496\n",
      "    loss           : -838.5551166304533\n",
      "    val_loss       : -697.4186735358613\n",
      "    val_log_likelihood: 1126.6443348089863\n",
      "    val_log_marginal: 719.5631169067859\n",
      "Train Epoch: 497 [512/17352 (3%)] Loss: -864.218323\n",
      "Train Epoch: 497 [10186/17352 (59%)] Loss: -836.817096\n",
      "Train Epoch: 497 [16934/17352 (98%)] Loss: -886.086840\n",
      "    epoch          : 497\n",
      "    loss           : -841.7131402099541\n",
      "    val_loss       : -701.9863275954618\n",
      "    val_log_likelihood: 1131.4703360294636\n",
      "    val_log_marginal: 726.2087814950238\n",
      "Train Epoch: 498 [512/17352 (3%)] Loss: -855.029114\n",
      "Train Epoch: 498 [10522/17352 (61%)] Loss: -878.745220\n",
      "Train Epoch: 498 [16957/17352 (98%)] Loss: -778.415216\n",
      "    epoch          : 498\n",
      "    loss           : -842.4285935795407\n",
      "    val_loss       : -710.1690821696524\n",
      "    val_log_likelihood: 1129.3263338870202\n",
      "    val_log_marginal: 727.2910025537803\n",
      "Train Epoch: 499 [512/17352 (3%)] Loss: -882.838867\n",
      "Train Epoch: 499 [10176/17352 (59%)] Loss: -952.183414\n",
      "Train Epoch: 499 [17106/17352 (99%)] Loss: -900.960323\n",
      "    epoch          : 499\n",
      "    loss           : -845.3385960248152\n",
      "    val_loss       : -711.3524526415498\n",
      "    val_log_likelihood: 1136.420890112662\n",
      "    val_log_marginal: 729.1783126737926\n",
      "Train Epoch: 500 [512/17352 (3%)] Loss: -885.309204\n",
      "Train Epoch: 500 [10221/17352 (59%)] Loss: -924.297540\n",
      "Train Epoch: 500 [17253/17352 (99%)] Loss: -777.958201\n",
      "    epoch          : 500\n",
      "    loss           : -844.1986533276217\n",
      "    val_loss       : -693.7591031524931\n",
      "    val_log_likelihood: 1130.916512240707\n",
      "    val_log_marginal: 710.996484345841\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch500.pth ...\n",
      "Train Epoch: 501 [512/17352 (3%)] Loss: -881.666077\n",
      "Train Epoch: 501 [10210/17352 (59%)] Loss: -903.069970\n",
      "Train Epoch: 501 [16878/17352 (97%)] Loss: -870.735317\n",
      "    epoch          : 501\n",
      "    loss           : -843.0768033471824\n",
      "    val_loss       : -720.56129120773\n",
      "    val_log_likelihood: 1138.121184382668\n",
      "    val_log_marginal: 735.6555898463076\n",
      "Train Epoch: 502 [512/17352 (3%)] Loss: -898.033997\n",
      "Train Epoch: 502 [10059/17352 (58%)] Loss: -969.784831\n",
      "Train Epoch: 502 [16988/17352 (98%)] Loss: -921.738873\n",
      "    epoch          : 502\n",
      "    loss           : -845.4746728686471\n",
      "    val_loss       : -709.8917482617425\n",
      "    val_log_likelihood: 1141.3589689272571\n",
      "    val_log_marginal: 726.8668261525416\n",
      "Train Epoch: 503 [512/17352 (3%)] Loss: -874.286377\n",
      "Train Epoch: 503 [10756/17352 (62%)] Loss: -963.813257\n",
      "Train Epoch: 503 [17106/17352 (99%)] Loss: -908.363301\n",
      "    epoch          : 503\n",
      "    loss           : -845.8029441292173\n",
      "    val_loss       : -690.8474248551041\n",
      "    val_log_likelihood: 1127.5909013162523\n",
      "    val_log_marginal: 709.4609457516103\n",
      "Train Epoch: 504 [512/17352 (3%)] Loss: -825.595154\n",
      "Train Epoch: 504 [9973/17352 (57%)] Loss: -737.248953\n",
      "Train Epoch: 504 [16939/17352 (98%)] Loss: -831.667219\n",
      "    epoch          : 504\n",
      "    loss           : -832.1310546106081\n",
      "    val_loss       : -705.2272782653573\n",
      "    val_log_likelihood: 1142.8019792161074\n",
      "    val_log_marginal: 730.1963336668082\n",
      "Train Epoch: 505 [512/17352 (3%)] Loss: -868.995117\n",
      "Train Epoch: 505 [10272/17352 (59%)] Loss: -894.966135\n",
      "Train Epoch: 505 [17253/17352 (99%)] Loss: -933.558693\n",
      "    epoch          : 505\n",
      "    loss           : -843.492189958036\n",
      "    val_loss       : -681.9154793061821\n",
      "    val_log_likelihood: 1127.5120977295\n",
      "    val_log_marginal: 700.9595361082921\n",
      "Train Epoch: 506 [512/17352 (3%)] Loss: -849.673340\n",
      "Train Epoch: 506 [10563/17352 (61%)] Loss: -933.309962\n",
      "Train Epoch: 506 [17253/17352 (99%)] Loss: -881.947266\n",
      "    epoch          : 506\n",
      "    loss           : -845.575533969154\n",
      "    val_loss       : -702.670410765544\n",
      "    val_log_likelihood: 1136.754910943348\n",
      "    val_log_marginal: 717.6309713825987\n",
      "Train Epoch: 507 [512/17352 (3%)] Loss: -895.089478\n",
      "Train Epoch: 507 [10402/17352 (60%)] Loss: -686.288374\n",
      "Train Epoch: 507 [17143/17352 (99%)] Loss: -891.324621\n",
      "    epoch          : 507\n",
      "    loss           : -851.6993635517503\n",
      "    val_loss       : -692.4754496707841\n",
      "    val_log_likelihood: 1134.4432464811641\n",
      "    val_log_marginal: 705.8917186510147\n",
      "Train Epoch: 508 [512/17352 (3%)] Loss: -888.614014\n",
      "Train Epoch: 508 [10002/17352 (58%)] Loss: -885.058203\n",
      "Train Epoch: 508 [16922/17352 (98%)] Loss: -735.751547\n",
      "    epoch          : 508\n",
      "    loss           : -840.8511576552522\n",
      "    val_loss       : -702.7903231316271\n",
      "    val_log_likelihood: 1147.8329801237041\n",
      "    val_log_marginal: 731.3007702456146\n",
      "Train Epoch: 509 [512/17352 (3%)] Loss: -884.614258\n",
      "Train Epoch: 509 [10026/17352 (58%)] Loss: -960.305196\n",
      "Train Epoch: 509 [17133/17352 (99%)] Loss: -771.467853\n",
      "    epoch          : 509\n",
      "    loss           : -838.4470186812379\n",
      "    val_loss       : -655.5668469224946\n",
      "    val_log_likelihood: 1114.7790013033846\n",
      "    val_log_marginal: 671.2342881286528\n",
      "Train Epoch: 510 [512/17352 (3%)] Loss: -870.347229\n",
      "Train Epoch: 510 [10623/17352 (61%)] Loss: -772.813021\n",
      "Train Epoch: 510 [17263/17352 (99%)] Loss: -773.022626\n",
      "    epoch          : 510\n",
      "    loss           : -832.1537954158142\n",
      "    val_loss       : -677.8831490840165\n",
      "    val_log_likelihood: 1144.0304398837693\n",
      "    val_log_marginal: 696.7635113636641\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch510.pth ...\n",
      "Train Epoch: 511 [512/17352 (3%)] Loss: -857.249329\n",
      "Train Epoch: 511 [11042/17352 (64%)] Loss: -809.824045\n",
      "Train Epoch: 511 [17133/17352 (99%)] Loss: -927.450826\n",
      "    epoch          : 511\n",
      "    loss           : -845.0524306693409\n",
      "    val_loss       : -684.3923930711352\n",
      "    val_log_likelihood: 1138.4628840526975\n",
      "    val_log_marginal: 702.3162048067001\n",
      "Train Epoch: 512 [512/17352 (3%)] Loss: -887.765686\n",
      "Train Epoch: 512 [10258/17352 (59%)] Loss: -800.200800\n",
      "Train Epoch: 512 [16872/17352 (97%)] Loss: -909.935759\n",
      "    epoch          : 512\n",
      "    loss           : -843.8588277527537\n",
      "    val_loss       : -693.7546604276973\n",
      "    val_log_likelihood: 1140.4405821106177\n",
      "    val_log_marginal: 717.0651408745241\n",
      "Train Epoch: 513 [512/17352 (3%)] Loss: -889.284912\n",
      "Train Epoch: 513 [10583/17352 (61%)] Loss: -814.485471\n",
      "Train Epoch: 513 [17253/17352 (99%)] Loss: -766.609973\n",
      "    epoch          : 513\n",
      "    loss           : -841.763857294615\n",
      "    val_loss       : -700.0066635763185\n",
      "    val_log_likelihood: 1148.4847501051286\n",
      "    val_log_marginal: 720.2102372996632\n",
      "Train Epoch: 514 [512/17352 (3%)] Loss: -686.259644\n",
      "Train Epoch: 514 [10177/17352 (59%)] Loss: -731.633086\n",
      "Train Epoch: 514 [17277/17352 (100%)] Loss: -898.872649\n",
      "    epoch          : 514\n",
      "    loss           : -856.3058238847309\n",
      "    val_loss       : -701.0925702731478\n",
      "    val_log_likelihood: 1152.983285868077\n",
      "    val_log_marginal: 730.3359864220564\n",
      "Train Epoch: 515 [512/17352 (3%)] Loss: -704.809753\n",
      "Train Epoch: 515 [10389/17352 (60%)] Loss: -922.707598\n",
      "Train Epoch: 515 [16923/17352 (98%)] Loss: -962.477388\n",
      "    epoch          : 515\n",
      "    loss           : -859.8432947713299\n",
      "    val_loss       : -707.8382559710409\n",
      "    val_log_likelihood: 1151.2876374138157\n",
      "    val_log_marginal: 726.0093464667445\n",
      "Train Epoch: 516 [512/17352 (3%)] Loss: -907.065247\n",
      "Train Epoch: 516 [10243/17352 (59%)] Loss: -789.955035\n",
      "Train Epoch: 516 [16957/17352 (98%)] Loss: -845.337377\n",
      "    epoch          : 516\n",
      "    loss           : -861.4472024058138\n",
      "    val_loss       : -714.7301817862101\n",
      "    val_log_likelihood: 1160.9219547727266\n",
      "    val_log_marginal: 733.7435899446172\n",
      "Train Epoch: 517 [512/17352 (3%)] Loss: -913.650208\n",
      "Train Epoch: 517 [9901/17352 (57%)] Loss: -838.405331\n",
      "Train Epoch: 517 [16922/17352 (98%)] Loss: -910.956763\n",
      "    epoch          : 517\n",
      "    loss           : -855.2019220155655\n",
      "    val_loss       : -706.1229499519816\n",
      "    val_log_likelihood: 1159.8991632488737\n",
      "    val_log_marginal: 724.5929507360055\n",
      "Train Epoch: 518 [512/17352 (3%)] Loss: -911.322571\n",
      "Train Epoch: 518 [10855/17352 (63%)] Loss: -915.091447\n",
      "Train Epoch: 518 [17124/17352 (99%)] Loss: -806.503819\n",
      "    epoch          : 518\n",
      "    loss           : -848.3652338035238\n",
      "    val_loss       : -682.6250652217477\n",
      "    val_log_likelihood: 1149.589902542159\n",
      "    val_log_marginal: 702.2397514651843\n",
      "Train Epoch: 519 [512/17352 (3%)] Loss: -869.075195\n",
      "Train Epoch: 519 [9980/17352 (58%)] Loss: -858.032320\n",
      "Train Epoch: 519 [16988/17352 (98%)] Loss: -902.916424\n",
      "    epoch          : 519\n",
      "    loss           : -803.0946594318735\n",
      "    val_loss       : -658.9681175082026\n",
      "    val_log_likelihood: 1140.4851500898208\n",
      "    val_log_marginal: 686.1148109366119\n",
      "Train Epoch: 520 [512/17352 (3%)] Loss: -890.567749\n",
      "Train Epoch: 520 [10392/17352 (60%)] Loss: -699.213891\n",
      "Train Epoch: 520 [16958/17352 (98%)] Loss: -782.539161\n",
      "    epoch          : 520\n",
      "    loss           : -838.5671277767991\n",
      "    val_loss       : -662.2314334860903\n",
      "    val_log_likelihood: 1123.1668183992247\n",
      "    val_log_marginal: 679.0232775098702\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch520.pth ...\n",
      "Train Epoch: 521 [512/17352 (3%)] Loss: -847.905518\n",
      "Train Epoch: 521 [10435/17352 (60%)] Loss: -792.472403\n",
      "Train Epoch: 521 [16958/17352 (98%)] Loss: -789.142603\n",
      "    epoch          : 521\n",
      "    loss           : -854.6619171370849\n",
      "    val_loss       : -697.9112467316907\n",
      "    val_log_likelihood: 1150.484214875506\n",
      "    val_log_marginal: 719.4154541931388\n",
      "Train Epoch: 522 [512/17352 (3%)] Loss: -905.859253\n",
      "Train Epoch: 522 [10853/17352 (63%)] Loss: -697.101207\n",
      "Train Epoch: 522 [17143/17352 (99%)] Loss: -852.878331\n",
      "    epoch          : 522\n",
      "    loss           : -834.7843129862824\n",
      "    val_loss       : -673.2854640334943\n",
      "    val_log_likelihood: 1142.3297019941244\n",
      "    val_log_marginal: 697.2866411603744\n",
      "Train Epoch: 523 [512/17352 (3%)] Loss: -871.100525\n",
      "Train Epoch: 523 [10506/17352 (61%)] Loss: -686.807491\n",
      "Train Epoch: 523 [17153/17352 (99%)] Loss: -918.707041\n",
      "    epoch          : 523\n",
      "    loss           : -837.662891449062\n",
      "    val_loss       : -650.1113364430523\n",
      "    val_log_likelihood: 1144.6641458130434\n",
      "    val_log_marginal: 676.864696226617\n",
      "Train Epoch: 524 [512/17352 (3%)] Loss: -847.911682\n",
      "Train Epoch: 524 [10655/17352 (61%)] Loss: -781.180195\n",
      "Train Epoch: 524 [17153/17352 (99%)] Loss: -657.892793\n",
      "    epoch          : 524\n",
      "    loss           : -818.4224014459999\n",
      "    val_loss       : -673.0225835199699\n",
      "    val_log_likelihood: 1145.0721631100648\n",
      "    val_log_marginal: 690.5358772446015\n",
      "Train Epoch: 525 [512/17352 (3%)] Loss: -871.100403\n",
      "Train Epoch: 525 [10470/17352 (60%)] Loss: -744.912711\n",
      "Train Epoch: 525 [17044/17352 (98%)] Loss: -896.692431\n",
      "    epoch          : 525\n",
      "    loss           : -828.4690647687355\n",
      "    val_loss       : -617.681822827976\n",
      "    val_log_likelihood: 1135.5408389612444\n",
      "    val_log_marginal: 643.5279105470502\n",
      "Train Epoch: 526 [512/17352 (3%)] Loss: -794.866211\n",
      "Train Epoch: 526 [10308/17352 (59%)] Loss: -891.774403\n",
      "Train Epoch: 526 [17277/17352 (100%)] Loss: -934.955887\n",
      "    epoch          : 526\n",
      "    loss           : -798.501690541493\n",
      "    val_loss       : -642.1890696044051\n",
      "    val_log_likelihood: 1125.933144970494\n",
      "    val_log_marginal: 671.9057144101911\n",
      "Train Epoch: 527 [512/17352 (3%)] Loss: -817.480347\n",
      "Train Epoch: 527 [10569/17352 (61%)] Loss: -907.197207\n",
      "Train Epoch: 527 [17108/17352 (99%)] Loss: -848.884549\n",
      "    epoch          : 527\n",
      "    loss           : -796.3314556226496\n",
      "    val_loss       : -636.5974890839619\n",
      "    val_log_likelihood: 1104.2185016627081\n",
      "    val_log_marginal: 667.8865847068801\n",
      "Train Epoch: 528 [512/17352 (3%)] Loss: -820.534973\n",
      "Train Epoch: 528 [10087/17352 (58%)] Loss: -842.936547\n",
      "Train Epoch: 528 [16882/17352 (97%)] Loss: -833.634846\n",
      "    epoch          : 528\n",
      "    loss           : -812.2290970175131\n",
      "    val_loss       : -680.3885637122956\n",
      "    val_log_likelihood: 1138.6391854435087\n",
      "    val_log_marginal: 709.1673642717285\n",
      "Train Epoch: 529 [512/17352 (3%)] Loss: -889.859009\n",
      "Train Epoch: 529 [9931/17352 (57%)] Loss: -930.984375\n",
      "Train Epoch: 529 [17335/17352 (100%)] Loss: -928.287992\n",
      "    epoch          : 529\n",
      "    loss           : -843.3954120976017\n",
      "    val_loss       : -688.4736291448817\n",
      "    val_log_likelihood: 1134.0524982244142\n",
      "    val_log_marginal: 715.9876118014183\n",
      "Train Epoch: 530 [512/17352 (3%)] Loss: -694.818848\n",
      "Train Epoch: 530 [11004/17352 (63%)] Loss: -710.664247\n",
      "Train Epoch: 530 [17044/17352 (98%)] Loss: -774.767735\n",
      "    epoch          : 530\n",
      "    loss           : -855.6032237570653\n",
      "    val_loss       : -694.3650271280948\n",
      "    val_log_likelihood: 1150.221303569336\n",
      "    val_log_marginal: 720.3443987658525\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch530.pth ...\n",
      "Train Epoch: 531 [512/17352 (3%)] Loss: -910.660034\n",
      "Train Epoch: 531 [10378/17352 (60%)] Loss: -917.796252\n",
      "Train Epoch: 531 [17049/17352 (98%)] Loss: -937.137342\n",
      "    epoch          : 531\n",
      "    loss           : -861.5247033008329\n",
      "    val_loss       : -707.0778460749505\n",
      "    val_log_likelihood: 1162.0455506114067\n",
      "    val_log_marginal: 727.8509660803011\n",
      "Train Epoch: 532 [512/17352 (3%)] Loss: -904.806519\n",
      "Train Epoch: 532 [10247/17352 (59%)] Loss: -981.652018\n",
      "Train Epoch: 532 [17124/17352 (99%)] Loss: -775.437155\n",
      "    epoch          : 532\n",
      "    loss           : -861.0416232499718\n",
      "    val_loss       : -674.3905556590064\n",
      "    val_log_likelihood: 1140.4570396698414\n",
      "    val_log_marginal: 691.2923483429574\n",
      "Train Epoch: 533 [512/17352 (3%)] Loss: -896.084595\n",
      "Train Epoch: 533 [10395/17352 (60%)] Loss: -700.345349\n",
      "Train Epoch: 533 [16882/17352 (97%)] Loss: -818.944997\n",
      "    epoch          : 533\n",
      "    loss           : -847.5199977762935\n",
      "    val_loss       : -688.7081444974781\n",
      "    val_log_likelihood: 1145.0507292075176\n",
      "    val_log_marginal: 714.3756494318794\n",
      "Train Epoch: 534 [512/17352 (3%)] Loss: -881.081360\n",
      "Train Epoch: 534 [10442/17352 (60%)] Loss: -785.008074\n",
      "Train Epoch: 534 [16992/17352 (98%)] Loss: -971.022473\n",
      "    epoch          : 534\n",
      "    loss           : -850.9564240273063\n",
      "    val_loss       : -693.8781781747512\n",
      "    val_log_likelihood: 1150.1016109563682\n",
      "    val_log_marginal: 711.7349856662165\n",
      "Train Epoch: 535 [512/17352 (3%)] Loss: -889.847229\n",
      "Train Epoch: 535 [10301/17352 (59%)] Loss: -815.705729\n",
      "Train Epoch: 535 [16992/17352 (98%)] Loss: -952.697176\n",
      "    epoch          : 535\n",
      "    loss           : -862.8422236025176\n",
      "    val_loss       : -724.2790840480095\n",
      "    val_log_likelihood: 1172.7309357901174\n",
      "    val_log_marginal: 745.6585212682138\n",
      "Train Epoch: 536 [512/17352 (3%)] Loss: -914.001587\n",
      "Train Epoch: 536 [10702/17352 (62%)] Loss: -931.136952\n",
      "Train Epoch: 536 [16923/17352 (98%)] Loss: -1016.089627\n",
      "    epoch          : 536\n",
      "    loss           : -871.9435821173117\n",
      "    val_loss       : -696.9846889317021\n",
      "    val_log_likelihood: 1153.2882132713573\n",
      "    val_log_marginal: 719.8634149678016\n",
      "Train Epoch: 537 [512/17352 (3%)] Loss: -716.606689\n",
      "Train Epoch: 537 [10406/17352 (60%)] Loss: -977.904964\n",
      "Train Epoch: 537 [17101/17352 (99%)] Loss: -913.115499\n",
      "    epoch          : 537\n",
      "    loss           : -863.5936354195543\n",
      "    val_loss       : -711.4948031841465\n",
      "    val_log_likelihood: 1159.7706536004994\n",
      "    val_log_marginal: 731.791999297927\n",
      "Train Epoch: 538 [512/17352 (3%)] Loss: -900.251221\n",
      "Train Epoch: 538 [9975/17352 (57%)] Loss: -917.581193\n",
      "Train Epoch: 538 [17143/17352 (99%)] Loss: -810.222470\n",
      "    epoch          : 538\n",
      "    loss           : -855.7554876878721\n",
      "    val_loss       : -701.5540046731106\n",
      "    val_log_likelihood: 1157.4945877830137\n",
      "    val_log_marginal: 722.7539727768828\n",
      "Train Epoch: 539 [512/17352 (3%)] Loss: -923.080933\n",
      "Train Epoch: 539 [10248/17352 (59%)] Loss: -807.891555\n",
      "Train Epoch: 539 [17126/17352 (99%)] Loss: -935.696103\n",
      "    epoch          : 539\n",
      "    loss           : -874.0927137454771\n",
      "    val_loss       : -699.2294261905387\n",
      "    val_log_likelihood: 1159.985886053517\n",
      "    val_log_marginal: 725.7798130372362\n",
      "Train Epoch: 540 [512/17352 (3%)] Loss: -913.608521\n",
      "Train Epoch: 540 [10352/17352 (60%)] Loss: -972.479865\n",
      "Train Epoch: 540 [17253/17352 (99%)] Loss: -774.024382\n",
      "    epoch          : 540\n",
      "    loss           : -848.8067611863638\n",
      "    val_loss       : -685.4136833870494\n",
      "    val_log_likelihood: 1151.4002591860672\n",
      "    val_log_marginal: 704.4899126196664\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch540.pth ...\n",
      "Train Epoch: 541 [512/17352 (3%)] Loss: -895.564636\n",
      "Train Epoch: 541 [10224/17352 (59%)] Loss: -874.298279\n",
      "Train Epoch: 541 [16887/17352 (97%)] Loss: -743.198639\n",
      "    epoch          : 541\n",
      "    loss           : -850.0022778863722\n",
      "    val_loss       : -687.4606003275518\n",
      "    val_log_likelihood: 1156.6541218141083\n",
      "    val_log_marginal: 706.6805805446958\n",
      "Train Epoch: 542 [512/17352 (3%)] Loss: -880.354126\n",
      "Train Epoch: 542 [10631/17352 (61%)] Loss: -891.172498\n",
      "Train Epoch: 542 [16958/17352 (98%)] Loss: -760.056424\n",
      "    epoch          : 542\n",
      "    loss           : -846.2490400538101\n",
      "    val_loss       : -678.7569579751638\n",
      "    val_log_likelihood: 1134.4751500737211\n",
      "    val_log_marginal: 698.3728213710764\n",
      "Train Epoch: 543 [512/17352 (3%)] Loss: -868.490784\n",
      "Train Epoch: 543 [10464/17352 (60%)] Loss: -730.308402\n",
      "Train Epoch: 543 [17126/17352 (99%)] Loss: -888.860396\n",
      "    epoch          : 543\n",
      "    loss           : -783.6271570290511\n",
      "    val_loss       : -646.36948153193\n",
      "    val_log_likelihood: 1125.6249811587002\n",
      "    val_log_marginal: 683.9025790817966\n",
      "Train Epoch: 544 [512/17352 (3%)] Loss: -777.253784\n",
      "Train Epoch: 544 [10928/17352 (63%)] Loss: -943.803571\n",
      "Train Epoch: 544 [17090/17352 (98%)] Loss: -777.151017\n",
      "    epoch          : 544\n",
      "    loss           : -835.4387567325437\n",
      "    val_loss       : -700.5195482851689\n",
      "    val_log_likelihood: 1148.1786274003728\n",
      "    val_log_marginal: 720.8981956190514\n",
      "Train Epoch: 545 [512/17352 (3%)] Loss: -894.317810\n",
      "Train Epoch: 545 [10015/17352 (58%)] Loss: -858.984770\n",
      "Train Epoch: 545 [16992/17352 (98%)] Loss: -910.538720\n",
      "    epoch          : 545\n",
      "    loss           : -863.5116046451909\n",
      "    val_loss       : -711.6270035472513\n",
      "    val_log_likelihood: 1164.4342848771644\n",
      "    val_log_marginal: 732.9100059582049\n",
      "Train Epoch: 546 [512/17352 (3%)] Loss: -907.550476\n",
      "Train Epoch: 546 [10673/17352 (62%)] Loss: -961.532278\n",
      "Train Epoch: 546 [17124/17352 (99%)] Loss: -868.274198\n",
      "    epoch          : 546\n",
      "    loss           : -862.2206589242205\n",
      "    val_loss       : -703.3422294409323\n",
      "    val_log_likelihood: 1167.913787004351\n",
      "    val_log_marginal: 725.2174962877434\n",
      "Train Epoch: 547 [512/17352 (3%)] Loss: -906.988831\n",
      "Train Epoch: 547 [9694/17352 (56%)] Loss: -981.905707\n",
      "Train Epoch: 547 [16922/17352 (98%)] Loss: -787.254972\n",
      "    epoch          : 547\n",
      "    loss           : -856.0719729315462\n",
      "    val_loss       : -688.0441925097781\n",
      "    val_log_likelihood: 1162.2287894268222\n",
      "    val_log_marginal: 718.5976669249864\n",
      "Train Epoch: 548 [512/17352 (3%)] Loss: -926.401367\n",
      "Train Epoch: 548 [10327/17352 (60%)] Loss: -923.836342\n",
      "Train Epoch: 548 [17106/17352 (99%)] Loss: -853.675910\n",
      "    epoch          : 548\n",
      "    loss           : -864.0519674781029\n",
      "    val_loss       : -693.4934549151246\n",
      "    val_log_likelihood: 1156.020518339147\n",
      "    val_log_marginal: 717.5883007279643\n",
      "Train Epoch: 549 [512/17352 (3%)] Loss: -922.390991\n",
      "Train Epoch: 549 [9870/17352 (57%)] Loss: -862.152401\n",
      "Train Epoch: 549 [16988/17352 (98%)] Loss: -936.710739\n",
      "    epoch          : 549\n",
      "    loss           : -864.2690487616355\n",
      "    val_loss       : -703.1402524661017\n",
      "    val_log_likelihood: 1167.9484947172793\n",
      "    val_log_marginal: 730.1156883149375\n",
      "Train Epoch: 550 [512/17352 (3%)] Loss: -907.271606\n",
      "Train Epoch: 550 [10503/17352 (61%)] Loss: -733.077094\n",
      "Train Epoch: 550 [16878/17352 (97%)] Loss: -844.268630\n",
      "    epoch          : 550\n",
      "    loss           : -868.9928887342375\n",
      "    val_loss       : -714.9304453048736\n",
      "    val_log_likelihood: 1175.7248698236294\n",
      "    val_log_marginal: 734.1062002915573\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch550.pth ...\n",
      "Train Epoch: 551 [512/17352 (3%)] Loss: -922.887085\n",
      "Train Epoch: 551 [10463/17352 (60%)] Loss: -937.213039\n",
      "Train Epoch: 551 [17049/17352 (98%)] Loss: -653.516062\n",
      "    epoch          : 551\n",
      "    loss           : -853.0608248164048\n",
      "    val_loss       : -698.458110086236\n",
      "    val_log_likelihood: 1163.8226838404305\n",
      "    val_log_marginal: 720.8833247075202\n",
      "Train Epoch: 552 [512/17352 (3%)] Loss: -876.796326\n",
      "Train Epoch: 552 [10516/17352 (61%)] Loss: -1007.001953\n",
      "Train Epoch: 552 [17049/17352 (98%)] Loss: -944.960762\n",
      "    epoch          : 552\n",
      "    loss           : -876.989696665684\n",
      "    val_loss       : -732.4067665134486\n",
      "    val_log_likelihood: 1177.4078727668345\n",
      "    val_log_marginal: 750.1176551209786\n",
      "Train Epoch: 553 [512/17352 (3%)] Loss: -743.135315\n",
      "Train Epoch: 553 [9938/17352 (57%)] Loss: -795.576958\n",
      "Train Epoch: 553 [16923/17352 (98%)] Loss: -888.894800\n",
      "    epoch          : 553\n",
      "    loss           : -875.7167631796101\n",
      "    val_loss       : -722.8723108094761\n",
      "    val_log_likelihood: 1179.5426827119254\n",
      "    val_log_marginal: 745.2362873526878\n",
      "Train Epoch: 554 [512/17352 (3%)] Loss: -913.063416\n",
      "Train Epoch: 554 [10408/17352 (60%)] Loss: -823.171701\n",
      "Train Epoch: 554 [17126/17352 (99%)] Loss: -790.665923\n",
      "    epoch          : 554\n",
      "    loss           : -851.2652255148702\n",
      "    val_loss       : -668.8805731793279\n",
      "    val_log_likelihood: 1145.9802239242358\n",
      "    val_log_marginal: 694.0800494570818\n",
      "Train Epoch: 555 [512/17352 (3%)] Loss: -879.234558\n",
      "Train Epoch: 555 [10237/17352 (59%)] Loss: -939.580053\n",
      "Train Epoch: 555 [17064/17352 (98%)] Loss: -729.383671\n",
      "    epoch          : 555\n",
      "    loss           : -805.8032237774144\n",
      "    val_loss       : -625.3549719241755\n",
      "    val_log_likelihood: 1123.6930467321502\n",
      "    val_log_marginal: 659.0714696140354\n",
      "Train Epoch: 556 [512/17352 (3%)] Loss: -831.748291\n",
      "Train Epoch: 556 [10232/17352 (59%)] Loss: -829.330492\n",
      "Train Epoch: 556 [17126/17352 (99%)] Loss: -633.115843\n",
      "    epoch          : 556\n",
      "    loss           : -773.7250609320606\n",
      "    val_loss       : -642.8240480631885\n",
      "    val_log_likelihood: 1125.8404334549875\n",
      "    val_log_marginal: 678.7664435107779\n",
      "Train Epoch: 557 [512/17352 (3%)] Loss: -876.391235\n",
      "Train Epoch: 557 [10259/17352 (59%)] Loss: -657.232654\n",
      "Train Epoch: 557 [17133/17352 (99%)] Loss: -929.169858\n",
      "    epoch          : 557\n",
      "    loss           : -815.2963860625648\n",
      "    val_loss       : -645.9501792394531\n",
      "    val_log_likelihood: 1141.662965893325\n",
      "    val_log_marginal: 676.6561905426925\n",
      "Train Epoch: 558 [512/17352 (3%)] Loss: -867.985413\n",
      "Train Epoch: 558 [10218/17352 (59%)] Loss: -813.030594\n",
      "Train Epoch: 558 [17124/17352 (99%)] Loss: -922.782922\n",
      "    epoch          : 558\n",
      "    loss           : -820.6537822578134\n",
      "    val_loss       : -689.0776546072697\n",
      "    val_log_likelihood: 1161.6241240391469\n",
      "    val_log_marginal: 722.9688462752679\n",
      "Train Epoch: 559 [512/17352 (3%)] Loss: -913.480957\n",
      "Train Epoch: 559 [10149/17352 (58%)] Loss: -782.175333\n",
      "Train Epoch: 559 [17064/17352 (98%)] Loss: -834.996112\n",
      "    epoch          : 559\n",
      "    loss           : -866.2114026155804\n",
      "    val_loss       : -708.430076035594\n",
      "    val_log_likelihood: 1163.078844019594\n",
      "    val_log_marginal: 725.4175914651644\n",
      "Train Epoch: 560 [512/17352 (3%)] Loss: -865.753296\n",
      "Train Epoch: 560 [10184/17352 (59%)] Loss: -869.706360\n",
      "Train Epoch: 560 [16878/17352 (97%)] Loss: -813.405048\n",
      "    epoch          : 560\n",
      "    loss           : -868.7259911245748\n",
      "    val_loss       : -665.5277407006068\n",
      "    val_log_likelihood: 1166.1505967496826\n",
      "    val_log_marginal: 708.6929898186871\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch560.pth ...\n",
      "Train Epoch: 561 [512/17352 (3%)] Loss: -916.231567\n",
      "Train Epoch: 561 [10564/17352 (61%)] Loss: -796.917461\n",
      "Train Epoch: 561 [16992/17352 (98%)] Loss: -919.782742\n",
      "    epoch          : 561\n",
      "    loss           : -845.095594658491\n",
      "    val_loss       : -693.3394033460411\n",
      "    val_log_likelihood: 1166.0245651735345\n",
      "    val_log_marginal: 713.2462550804306\n",
      "Train Epoch: 562 [512/17352 (3%)] Loss: -869.014893\n",
      "Train Epoch: 562 [10238/17352 (59%)] Loss: -869.772468\n",
      "Train Epoch: 562 [17277/17352 (100%)] Loss: -930.296984\n",
      "    epoch          : 562\n",
      "    loss           : -823.7348658201291\n",
      "    val_loss       : -666.2690183189908\n",
      "    val_log_likelihood: 1148.5936298771387\n",
      "    val_log_marginal: 690.4696875579256\n",
      "Train Epoch: 563 [512/17352 (3%)] Loss: -866.276611\n",
      "Train Epoch: 563 [10405/17352 (60%)] Loss: -831.206483\n",
      "Train Epoch: 563 [16957/17352 (98%)] Loss: -900.635102\n",
      "    epoch          : 563\n",
      "    loss           : -849.9383285082473\n",
      "    val_loss       : -686.4259914413244\n",
      "    val_log_likelihood: 1154.9325941605484\n",
      "    val_log_marginal: 700.5234623144927\n",
      "Train Epoch: 564 [512/17352 (3%)] Loss: -896.885986\n",
      "Train Epoch: 564 [10394/17352 (60%)] Loss: -889.424388\n",
      "Train Epoch: 564 [17143/17352 (99%)] Loss: -835.211486\n",
      "    epoch          : 564\n",
      "    loss           : -865.4562920581299\n",
      "    val_loss       : -671.2675017047512\n",
      "    val_log_likelihood: 1150.1048887351478\n",
      "    val_log_marginal: 688.8566178682992\n",
      "Train Epoch: 565 [512/17352 (3%)] Loss: -894.270447\n",
      "Train Epoch: 565 [10439/17352 (60%)] Loss: -882.847746\n",
      "Train Epoch: 565 [17263/17352 (99%)] Loss: -800.217228\n",
      "    epoch          : 565\n",
      "    loss           : -834.2220696768087\n",
      "    val_loss       : -676.7767612654532\n",
      "    val_log_likelihood: 1161.8189135472428\n",
      "    val_log_marginal: 696.9964370598758\n",
      "Train Epoch: 566 [512/17352 (3%)] Loss: -901.926147\n",
      "Train Epoch: 566 [10241/17352 (59%)] Loss: -798.432726\n",
      "Train Epoch: 566 [17126/17352 (99%)] Loss: -755.953125\n",
      "    epoch          : 566\n",
      "    loss           : -867.6750767413056\n",
      "    val_loss       : -718.2661658079419\n",
      "    val_log_likelihood: 1172.4409646676143\n",
      "    val_log_marginal: 739.847632109451\n",
      "Train Epoch: 567 [512/17352 (3%)] Loss: -914.432739\n",
      "Train Epoch: 567 [9997/17352 (58%)] Loss: -963.491772\n",
      "Train Epoch: 567 [16883/17352 (97%)] Loss: -799.530459\n",
      "    epoch          : 567\n",
      "    loss           : -873.3062679609017\n",
      "    val_loss       : -687.3355878707672\n",
      "    val_log_likelihood: 1145.5696845577224\n",
      "    val_log_marginal: 711.8685046063856\n",
      "Train Epoch: 568 [512/17352 (3%)] Loss: -709.968018\n",
      "Train Epoch: 568 [10234/17352 (59%)] Loss: -969.853085\n",
      "Train Epoch: 568 [17124/17352 (99%)] Loss: -806.876420\n",
      "    epoch          : 568\n",
      "    loss           : -877.908110363566\n",
      "    val_loss       : -701.8646714560552\n",
      "    val_log_likelihood: 1162.9596177803735\n",
      "    val_log_marginal: 726.6704404229615\n",
      "Train Epoch: 569 [512/17352 (3%)] Loss: -912.373291\n",
      "Train Epoch: 569 [10943/17352 (63%)] Loss: -979.316139\n",
      "Train Epoch: 569 [17044/17352 (98%)] Loss: -927.144840\n",
      "    epoch          : 569\n",
      "    loss           : -861.886715545995\n",
      "    val_loss       : -689.6287990552026\n",
      "    val_log_likelihood: 1148.2940141673485\n",
      "    val_log_marginal: 713.2617744810236\n",
      "Train Epoch: 570 [512/17352 (3%)] Loss: -901.849609\n",
      "Train Epoch: 570 [9969/17352 (57%)] Loss: -822.155946\n",
      "Train Epoch: 570 [17090/17352 (98%)] Loss: -934.146156\n",
      "    epoch          : 570\n",
      "    loss           : -875.3857816370428\n",
      "    val_loss       : -727.4599442195813\n",
      "    val_log_likelihood: 1177.3543500662877\n",
      "    val_log_marginal: 743.8249434043214\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch570.pth ...\n",
      "Train Epoch: 571 [512/17352 (3%)] Loss: -933.644531\n",
      "Train Epoch: 571 [10132/17352 (58%)] Loss: -936.226458\n",
      "Train Epoch: 571 [16922/17352 (98%)] Loss: -932.983809\n",
      "    epoch          : 571\n",
      "    loss           : -883.1102635986921\n",
      "    val_loss       : -702.5125307233213\n",
      "    val_log_likelihood: 1176.7007441346757\n",
      "    val_log_marginal: 728.5118157498974\n",
      "Train Epoch: 572 [512/17352 (3%)] Loss: -910.168823\n",
      "Train Epoch: 572 [10185/17352 (59%)] Loss: -753.613339\n",
      "Train Epoch: 572 [17016/17352 (98%)] Loss: -753.007508\n",
      "    epoch          : 572\n",
      "    loss           : -859.6138012257867\n",
      "    val_loss       : -713.1204849865737\n",
      "    val_log_likelihood: 1173.776461387634\n",
      "    val_log_marginal: 730.9779199888812\n",
      "Train Epoch: 573 [512/17352 (3%)] Loss: -911.059814\n",
      "Train Epoch: 573 [9935/17352 (57%)] Loss: -740.878661\n",
      "Train Epoch: 573 [16878/17352 (97%)] Loss: -941.930000\n",
      "    epoch          : 573\n",
      "    loss           : -882.3757327909761\n",
      "    val_loss       : -709.6513768479246\n",
      "    val_log_likelihood: 1179.6271825129159\n",
      "    val_log_marginal: 734.433942720293\n",
      "Train Epoch: 574 [512/17352 (3%)] Loss: -928.213684\n",
      "Train Epoch: 574 [10603/17352 (61%)] Loss: -821.548785\n",
      "Train Epoch: 574 [16957/17352 (98%)] Loss: -931.629557\n",
      "    epoch          : 574\n",
      "    loss           : -867.9398992583527\n",
      "    val_loss       : -703.887363309495\n",
      "    val_log_likelihood: 1181.672658446128\n",
      "    val_log_marginal: 734.8907368361229\n",
      "Train Epoch: 575 [512/17352 (3%)] Loss: -935.858398\n",
      "Train Epoch: 575 [10621/17352 (61%)] Loss: -997.814467\n",
      "Train Epoch: 575 [17090/17352 (98%)] Loss: -917.151526\n",
      "    epoch          : 575\n",
      "    loss           : -880.4124244184304\n",
      "    val_loss       : -688.2725938983209\n",
      "    val_log_likelihood: 1163.8077991731734\n",
      "    val_log_marginal: 706.4306615645874\n",
      "Train Epoch: 576 [512/17352 (3%)] Loss: -909.493713\n",
      "Train Epoch: 576 [10032/17352 (58%)] Loss: -701.524933\n",
      "Train Epoch: 576 [16883/17352 (97%)] Loss: -847.424885\n",
      "    epoch          : 576\n",
      "    loss           : -882.0053351219171\n",
      "    val_loss       : -716.9449844632788\n",
      "    val_log_likelihood: 1194.93409056425\n",
      "    val_log_marginal: 743.7796247878508\n",
      "Train Epoch: 577 [512/17352 (3%)] Loss: -938.439331\n",
      "Train Epoch: 577 [10583/17352 (61%)] Loss: -721.300389\n",
      "Train Epoch: 577 [17016/17352 (98%)] Loss: -936.425650\n",
      "    epoch          : 577\n",
      "    loss           : -865.015642792385\n",
      "    val_loss       : -694.312301213208\n",
      "    val_log_likelihood: 1166.675311288114\n",
      "    val_log_marginal: 718.9531667995768\n",
      "Train Epoch: 578 [512/17352 (3%)] Loss: -917.819580\n",
      "Train Epoch: 578 [10271/17352 (59%)] Loss: -801.192675\n",
      "Train Epoch: 578 [17335/17352 (100%)] Loss: -739.208333\n",
      "    epoch          : 578\n",
      "    loss           : -885.189796628138\n",
      "    val_loss       : -705.9164160896378\n",
      "    val_log_likelihood: 1177.9433848737267\n",
      "    val_log_marginal: 720.4696055310498\n",
      "Train Epoch: 579 [512/17352 (3%)] Loss: -890.322266\n",
      "Train Epoch: 579 [10116/17352 (58%)] Loss: -937.386952\n",
      "Train Epoch: 579 [17253/17352 (99%)] Loss: -851.712661\n",
      "    epoch          : 579\n",
      "    loss           : -867.5214111469271\n",
      "    val_loss       : -666.8909047507665\n",
      "    val_log_likelihood: 1164.3335398196277\n",
      "    val_log_marginal: 698.2541791815643\n",
      "Train Epoch: 580 [512/17352 (3%)] Loss: -826.982605\n",
      "Train Epoch: 580 [10814/17352 (62%)] Loss: -742.804368\n",
      "Train Epoch: 580 [16878/17352 (97%)] Loss: -810.725090\n",
      "    epoch          : 580\n",
      "    loss           : -849.5209047343276\n",
      "    val_loss       : -684.622706318564\n",
      "    val_log_likelihood: 1165.362877823464\n",
      "    val_log_marginal: 727.7157390310899\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch580.pth ...\n",
      "Train Epoch: 581 [512/17352 (3%)] Loss: -895.296143\n",
      "Train Epoch: 581 [9632/17352 (56%)] Loss: -896.650369\n",
      "Train Epoch: 581 [16957/17352 (98%)] Loss: -840.546875\n",
      "    epoch          : 581\n",
      "    loss           : -872.9801783871245\n",
      "    val_loss       : -714.5985615798029\n",
      "    val_log_likelihood: 1179.6765159575712\n",
      "    val_log_marginal: 738.4109018317354\n",
      "Train Epoch: 582 [512/17352 (3%)] Loss: -942.886902\n",
      "Train Epoch: 582 [10532/17352 (61%)] Loss: -990.078692\n",
      "Train Epoch: 582 [17133/17352 (99%)] Loss: -746.979570\n",
      "    epoch          : 582\n",
      "    loss           : -890.9701131230456\n",
      "    val_loss       : -717.2698338402066\n",
      "    val_log_likelihood: 1179.4738152035388\n",
      "    val_log_marginal: 735.8068330595265\n",
      "Train Epoch: 583 [512/17352 (3%)] Loss: -949.628174\n",
      "Train Epoch: 583 [10427/17352 (60%)] Loss: -911.440484\n",
      "Train Epoch: 583 [17335/17352 (100%)] Loss: -701.087694\n",
      "    epoch          : 583\n",
      "    loss           : -883.4076432845419\n",
      "    val_loss       : -693.1049170093332\n",
      "    val_log_likelihood: 1170.8745530672577\n",
      "    val_log_marginal: 713.6911631924014\n",
      "Train Epoch: 584 [512/17352 (3%)] Loss: -899.934082\n",
      "Train Epoch: 584 [10355/17352 (60%)] Loss: -883.782413\n",
      "Train Epoch: 584 [16939/17352 (98%)] Loss: -845.016593\n",
      "    epoch          : 584\n",
      "    loss           : -854.6765532853243\n",
      "    val_loss       : -708.5775974866552\n",
      "    val_log_likelihood: 1185.0950988445597\n",
      "    val_log_marginal: 736.2003202515855\n",
      "Train Epoch: 585 [512/17352 (3%)] Loss: -930.557068\n",
      "Train Epoch: 585 [10487/17352 (60%)] Loss: -929.782202\n",
      "Train Epoch: 585 [16883/17352 (97%)] Loss: -724.727367\n",
      "    epoch          : 585\n",
      "    loss           : -773.8087389352033\n",
      "    val_loss       : -640.2575084910574\n",
      "    val_log_likelihood: 1141.7633528083616\n",
      "    val_log_marginal: 664.0182298296431\n",
      "Train Epoch: 586 [512/17352 (3%)] Loss: -857.761230\n",
      "Train Epoch: 586 [10245/17352 (59%)] Loss: -920.604459\n",
      "Train Epoch: 586 [16872/17352 (97%)] Loss: -451.456784\n",
      "    epoch          : 586\n",
      "    loss           : -747.2598874918413\n",
      "    val_loss       : -251.3431477834739\n",
      "    val_log_likelihood: 1130.3840392369673\n",
      "    val_log_marginal: 286.18165897493355\n",
      "Train Epoch: 587 [512/17352 (3%)] Loss: -318.435547\n",
      "Train Epoch: 587 [9889/17352 (57%)] Loss: -588.868371\n",
      "Train Epoch: 587 [16992/17352 (98%)] Loss: 251.385431\n",
      "    epoch          : 587\n",
      "    loss           : -338.5159076841155\n",
      "    val_loss       : 551.2319755870933\n",
      "    val_log_likelihood: 940.9761591831303\n",
      "    val_log_marginal: -473.0267397688027\n",
      "Train Epoch: 588 [512/17352 (3%)] Loss: 166.230148\n",
      "Train Epoch: 588 [10572/17352 (61%)] Loss: -291.524128\n",
      "Train Epoch: 588 [17106/17352 (99%)] Loss: -623.518095\n",
      "    epoch          : 588\n",
      "    loss           : -458.1820228595902\n",
      "    val_loss       : -347.72150173937206\n",
      "    val_log_likelihood: 1012.3378741451322\n",
      "    val_log_marginal: 402.1923610087054\n",
      "Train Epoch: 589 [512/17352 (3%)] Loss: -252.337921\n",
      "Train Epoch: 589 [10641/17352 (61%)] Loss: -409.336996\n",
      "Train Epoch: 589 [17090/17352 (98%)] Loss: -736.685451\n",
      "    epoch          : 589\n",
      "    loss           : -700.1223842238712\n",
      "    val_loss       : -635.2160770253105\n",
      "    val_log_likelihood: 1118.2779028112323\n",
      "    val_log_marginal: 666.8550203137572\n",
      "Train Epoch: 590 [512/17352 (3%)] Loss: -780.945557\n",
      "Train Epoch: 590 [10582/17352 (61%)] Loss: -837.668183\n",
      "Train Epoch: 590 [16939/17352 (98%)] Loss: -961.623404\n",
      "    epoch          : 590\n",
      "    loss           : -830.6462317946364\n",
      "    val_loss       : -712.1815492846305\n",
      "    val_log_likelihood: 1148.904394668902\n",
      "    val_log_marginal: 732.6423495099345\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch590.pth ...\n",
      "Train Epoch: 591 [512/17352 (3%)] Loss: -896.777893\n",
      "Train Epoch: 591 [10688/17352 (62%)] Loss: -903.279258\n",
      "Train Epoch: 591 [17016/17352 (98%)] Loss: -713.645627\n",
      "    epoch          : 591\n",
      "    loss           : -857.4466382706596\n",
      "    val_loss       : -711.350922498441\n",
      "    val_log_likelihood: 1155.5052512446562\n",
      "    val_log_marginal: 732.154233121618\n",
      "Train Epoch: 592 [512/17352 (3%)] Loss: -924.755066\n",
      "Train Epoch: 592 [10204/17352 (59%)] Loss: -838.218471\n",
      "Train Epoch: 592 [17090/17352 (98%)] Loss: -736.521926\n",
      "    epoch          : 592\n",
      "    loss           : -882.9370074601845\n",
      "    val_loss       : -723.7308253641182\n",
      "    val_log_likelihood: 1165.747036748377\n",
      "    val_log_marginal: 745.1043607871148\n",
      "Train Epoch: 593 [512/17352 (3%)] Loss: -912.363525\n",
      "Train Epoch: 593 [10383/17352 (60%)] Loss: -807.561485\n",
      "Train Epoch: 593 [16882/17352 (97%)] Loss: -777.169348\n",
      "    epoch          : 593\n",
      "    loss           : -889.5326875663858\n",
      "    val_loss       : -735.7505211055757\n",
      "    val_log_likelihood: 1176.9240537133312\n",
      "    val_log_marginal: 758.9864432191771\n",
      "Train Epoch: 594 [512/17352 (3%)] Loss: -927.493591\n",
      "Train Epoch: 594 [10370/17352 (60%)] Loss: -892.258498\n",
      "Train Epoch: 594 [17106/17352 (99%)] Loss: -964.589687\n",
      "    epoch          : 594\n",
      "    loss           : -900.520819393035\n",
      "    val_loss       : -731.3077344300024\n",
      "    val_log_likelihood: 1179.6742347093307\n",
      "    val_log_marginal: 751.1869217596928\n",
      "Train Epoch: 595 [512/17352 (3%)] Loss: -935.436401\n",
      "Train Epoch: 595 [10223/17352 (59%)] Loss: -976.102079\n",
      "Train Epoch: 595 [16957/17352 (98%)] Loss: -855.729632\n",
      "    epoch          : 595\n",
      "    loss           : -889.8505283117414\n",
      "    val_loss       : -736.4167728248092\n",
      "    val_log_likelihood: 1180.2904537889196\n",
      "    val_log_marginal: 750.3034677322233\n",
      "Train Epoch: 596 [512/17352 (3%)] Loss: -729.526428\n",
      "Train Epoch: 596 [10760/17352 (62%)] Loss: -984.344282\n",
      "Train Epoch: 596 [17143/17352 (99%)] Loss: -1020.072700\n",
      "    epoch          : 596\n",
      "    loss           : -891.0494636735567\n",
      "    val_loss       : -723.1950442464084\n",
      "    val_log_likelihood: 1177.1464313870729\n",
      "    val_log_marginal: 740.3249529186897\n",
      "Train Epoch: 597 [512/17352 (3%)] Loss: -923.186890\n",
      "Train Epoch: 597 [10111/17352 (58%)] Loss: -921.222048\n",
      "Train Epoch: 597 [16934/17352 (98%)] Loss: -950.578516\n",
      "    epoch          : 597\n",
      "    loss           : -900.5678818107408\n",
      "    val_loss       : -736.2415026103255\n",
      "    val_log_likelihood: 1187.4135507069252\n",
      "    val_log_marginal: 758.8880260351438\n",
      "Train Epoch: 598 [512/17352 (3%)] Loss: -941.751953\n",
      "Train Epoch: 598 [10551/17352 (61%)] Loss: -978.663958\n",
      "Train Epoch: 598 [17253/17352 (99%)] Loss: -958.009501\n",
      "    epoch          : 598\n",
      "    loss           : -905.5981981123809\n",
      "    val_loss       : -747.0513618742431\n",
      "    val_log_likelihood: 1196.7618811261884\n",
      "    val_log_marginal: 768.0262367111129\n",
      "Train Epoch: 599 [512/17352 (3%)] Loss: -936.583801\n",
      "Train Epoch: 599 [9817/17352 (57%)] Loss: -826.359567\n",
      "Train Epoch: 599 [16923/17352 (98%)] Loss: -797.906456\n",
      "    epoch          : 599\n",
      "    loss           : -906.7893273324182\n",
      "    val_loss       : -740.1775962550604\n",
      "    val_log_likelihood: 1193.4347153319384\n",
      "    val_log_marginal: 754.910645241868\n",
      "Train Epoch: 600 [512/17352 (3%)] Loss: -936.267822\n",
      "Train Epoch: 600 [10654/17352 (61%)] Loss: -785.657925\n",
      "Train Epoch: 600 [16988/17352 (98%)] Loss: -979.357005\n",
      "    epoch          : 600\n",
      "    loss           : -906.178611166549\n",
      "    val_loss       : -746.056213691813\n",
      "    val_log_likelihood: 1206.2915709255794\n",
      "    val_log_marginal: 768.2071393866507\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch600.pth ...\n",
      "Train Epoch: 601 [512/17352 (3%)] Loss: -961.489380\n",
      "Train Epoch: 601 [10607/17352 (61%)] Loss: -795.526712\n",
      "Train Epoch: 601 [16992/17352 (98%)] Loss: -975.979056\n",
      "    epoch          : 601\n",
      "    loss           : -906.5311195186902\n",
      "    val_loss       : -719.1093820096029\n",
      "    val_log_likelihood: 1201.975184823971\n",
      "    val_log_marginal: 737.2270494541734\n",
      "Train Epoch: 602 [512/17352 (3%)] Loss: -926.961060\n",
      "Train Epoch: 602 [10499/17352 (61%)] Loss: -965.550174\n",
      "Train Epoch: 602 [16878/17352 (97%)] Loss: -1006.357342\n",
      "    epoch          : 602\n",
      "    loss           : -904.7577705658526\n",
      "    val_loss       : -739.1696903060296\n",
      "    val_log_likelihood: 1202.2524892197375\n",
      "    val_log_marginal: 756.8086285691061\n",
      "Train Epoch: 603 [512/17352 (3%)] Loss: -950.608215\n",
      "Train Epoch: 603 [10634/17352 (61%)] Loss: -791.623980\n",
      "Train Epoch: 603 [16992/17352 (98%)] Loss: -837.140625\n",
      "    epoch          : 603\n",
      "    loss           : -908.3154341989145\n",
      "    val_loss       : -720.3483710891982\n",
      "    val_log_likelihood: 1188.0519102049143\n",
      "    val_log_marginal: 735.8781658007728\n",
      "Train Epoch: 604 [512/17352 (3%)] Loss: -952.547729\n",
      "Train Epoch: 604 [10624/17352 (61%)] Loss: -850.244365\n",
      "Train Epoch: 604 [17049/17352 (98%)] Loss: -984.052427\n",
      "    epoch          : 604\n",
      "    loss           : -909.8915760243544\n",
      "    val_loss       : -732.367010126681\n",
      "    val_log_likelihood: 1198.1930853611168\n",
      "    val_log_marginal: 747.5389399698792\n",
      "Train Epoch: 605 [512/17352 (3%)] Loss: -958.936096\n",
      "Train Epoch: 605 [10965/17352 (63%)] Loss: -951.759658\n",
      "Train Epoch: 605 [17049/17352 (98%)] Loss: -997.686367\n",
      "    epoch          : 605\n",
      "    loss           : -911.7231583569403\n",
      "    val_loss       : -723.944223641377\n",
      "    val_log_likelihood: 1198.170220126544\n",
      "    val_log_marginal: 739.8988549368867\n",
      "Train Epoch: 606 [512/17352 (3%)] Loss: -956.203857\n",
      "Train Epoch: 606 [10858/17352 (63%)] Loss: -939.551544\n",
      "Train Epoch: 606 [16872/17352 (97%)] Loss: -881.914062\n",
      "    epoch          : 606\n",
      "    loss           : -909.6858179787938\n",
      "    val_loss       : -732.028440894663\n",
      "    val_log_likelihood: 1197.4406134161097\n",
      "    val_log_marginal: 748.8623056915309\n",
      "Train Epoch: 607 [512/17352 (3%)] Loss: -942.641541\n",
      "Train Epoch: 607 [10536/17352 (61%)] Loss: -931.207300\n",
      "Train Epoch: 607 [17101/17352 (99%)] Loss: -939.059701\n",
      "    epoch          : 607\n",
      "    loss           : -905.1648003324253\n",
      "    val_loss       : -721.6758617892376\n",
      "    val_log_likelihood: 1196.7034528156928\n",
      "    val_log_marginal: 737.6401522313172\n",
      "Train Epoch: 608 [512/17352 (3%)] Loss: -944.424866\n",
      "Train Epoch: 608 [10339/17352 (60%)] Loss: -975.562355\n",
      "Train Epoch: 608 [16923/17352 (98%)] Loss: -828.509537\n",
      "    epoch          : 608\n",
      "    loss           : -909.76146482803\n",
      "    val_loss       : -725.7318377564668\n",
      "    val_log_likelihood: 1199.9000438491705\n",
      "    val_log_marginal: 742.7607692315307\n",
      "Train Epoch: 609 [512/17352 (3%)] Loss: -911.842529\n",
      "Train Epoch: 609 [10419/17352 (60%)] Loss: -1050.476237\n",
      "Train Epoch: 609 [16939/17352 (98%)] Loss: -943.587370\n",
      "    epoch          : 609\n",
      "    loss           : -909.2207831780438\n",
      "    val_loss       : -740.1801776311636\n",
      "    val_log_likelihood: 1206.6961693863768\n",
      "    val_log_marginal: 760.6738443487355\n",
      "Train Epoch: 610 [512/17352 (3%)] Loss: -957.335022\n",
      "Train Epoch: 610 [10248/17352 (59%)] Loss: -788.358447\n",
      "Train Epoch: 610 [17263/17352 (99%)] Loss: -817.440266\n",
      "    epoch          : 610\n",
      "    loss           : -907.6791636414641\n",
      "    val_loss       : -713.5802180544463\n",
      "    val_log_likelihood: 1196.794236492816\n",
      "    val_log_marginal: 731.8770972386372\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch610.pth ...\n",
      "Train Epoch: 611 [512/17352 (3%)] Loss: -711.541443\n",
      "Train Epoch: 611 [10696/17352 (62%)] Loss: -836.818359\n",
      "Train Epoch: 611 [17064/17352 (98%)] Loss: -988.243021\n",
      "    epoch          : 611\n",
      "    loss           : -893.493832668651\n",
      "    val_loss       : -713.2350036957763\n",
      "    val_log_likelihood: 1187.260006115214\n",
      "    val_log_marginal: 726.4546347623157\n",
      "Train Epoch: 612 [512/17352 (3%)] Loss: -936.475891\n",
      "Train Epoch: 612 [9416/17352 (54%)] Loss: -863.708656\n",
      "Train Epoch: 612 [17090/17352 (98%)] Loss: -965.632277\n",
      "    epoch          : 612\n",
      "    loss           : -887.6110534702558\n",
      "    val_loss       : -700.6392103867162\n",
      "    val_log_likelihood: 1188.367075379591\n",
      "    val_log_marginal: 720.8321447966307\n",
      "Train Epoch: 613 [512/17352 (3%)] Loss: -927.076843\n",
      "Train Epoch: 613 [10198/17352 (59%)] Loss: -859.478844\n",
      "Train Epoch: 613 [16988/17352 (98%)] Loss: -1002.603950\n",
      "    epoch          : 613\n",
      "    loss           : -879.2572880019575\n",
      "    val_loss       : -693.8291578578206\n",
      "    val_log_likelihood: 1200.1005476064724\n",
      "    val_log_marginal: 713.2727698699236\n",
      "Train Epoch: 614 [512/17352 (3%)] Loss: -923.193176\n",
      "Train Epoch: 614 [10414/17352 (60%)] Loss: -860.090940\n",
      "Train Epoch: 614 [17253/17352 (99%)] Loss: -810.571397\n",
      "    epoch          : 614\n",
      "    loss           : -901.8343843303883\n",
      "    val_loss       : -714.1540304032577\n",
      "    val_log_likelihood: 1200.5866911906348\n",
      "    val_log_marginal: 734.908804124931\n",
      "Train Epoch: 615 [512/17352 (3%)] Loss: -949.075989\n",
      "Train Epoch: 615 [10590/17352 (61%)] Loss: -950.005546\n",
      "Train Epoch: 615 [17108/17352 (99%)] Loss: -882.357445\n",
      "    epoch          : 615\n",
      "    loss           : -899.7689221081617\n",
      "    val_loss       : -722.1571548787604\n",
      "    val_log_likelihood: 1203.5883485322108\n",
      "    val_log_marginal: 736.8846449446646\n",
      "Train Epoch: 616 [512/17352 (3%)] Loss: -941.019897\n",
      "Train Epoch: 616 [10307/17352 (59%)] Loss: -919.450284\n",
      "Train Epoch: 616 [17133/17352 (99%)] Loss: -885.223069\n",
      "    epoch          : 616\n",
      "    loss           : -855.3327457994828\n",
      "    val_loss       : -633.8112712219639\n",
      "    val_log_likelihood: 1140.5649287787853\n",
      "    val_log_marginal: 663.7105535629092\n",
      "Train Epoch: 617 [512/17352 (3%)] Loss: -842.544678\n",
      "Train Epoch: 617 [11051/17352 (64%)] Loss: -954.753173\n",
      "Train Epoch: 617 [17335/17352 (100%)] Loss: -843.372234\n",
      "    epoch          : 617\n",
      "    loss           : -831.271698786872\n",
      "    val_loss       : -674.5066234199179\n",
      "    val_log_likelihood: 1182.0514058553767\n",
      "    val_log_marginal: 712.9730018846365\n",
      "Train Epoch: 618 [512/17352 (3%)] Loss: -733.253113\n",
      "Train Epoch: 618 [10658/17352 (61%)] Loss: -828.948180\n",
      "Train Epoch: 618 [16887/17352 (97%)] Loss: -945.434177\n",
      "    epoch          : 618\n",
      "    loss           : -851.9999134921437\n",
      "    val_loss       : -689.0969323096509\n",
      "    val_log_likelihood: 1183.9807948700989\n",
      "    val_log_marginal: 730.0195298501945\n",
      "Train Epoch: 619 [512/17352 (3%)] Loss: -932.330261\n",
      "Train Epoch: 619 [10742/17352 (62%)] Loss: -921.752143\n",
      "Train Epoch: 619 [17143/17352 (99%)] Loss: -917.462071\n",
      "    epoch          : 619\n",
      "    loss           : -886.1469692207127\n",
      "    val_loss       : -726.7690873181655\n",
      "    val_log_likelihood: 1196.3798451072166\n",
      "    val_log_marginal: 747.3457484871662\n",
      "Train Epoch: 620 [512/17352 (3%)] Loss: -958.015808\n",
      "Train Epoch: 620 [10491/17352 (60%)] Loss: -734.863636\n",
      "Train Epoch: 620 [17106/17352 (99%)] Loss: -978.031383\n",
      "    epoch          : 620\n",
      "    loss           : -881.6091680129299\n",
      "    val_loss       : -717.5616907746644\n",
      "    val_log_likelihood: 1191.1038950614827\n",
      "    val_log_marginal: 740.5441992721236\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch620.pth ...\n",
      "Train Epoch: 621 [512/17352 (3%)] Loss: -927.961548\n",
      "Train Epoch: 621 [9536/17352 (55%)] Loss: -858.373783\n",
      "Train Epoch: 621 [16883/17352 (97%)] Loss: -846.736024\n",
      "    epoch          : 621\n",
      "    loss           : -902.5910916146705\n",
      "    val_loss       : -734.7634459829184\n",
      "    val_log_likelihood: 1205.758048478064\n",
      "    val_log_marginal: 753.0782559509796\n",
      "Train Epoch: 622 [512/17352 (3%)] Loss: -957.554077\n",
      "Train Epoch: 622 [10807/17352 (62%)] Loss: -1042.661675\n",
      "Train Epoch: 622 [17277/17352 (100%)] Loss: -1027.011123\n",
      "    epoch          : 622\n",
      "    loss           : -916.9329956399266\n",
      "    val_loss       : -733.8056610404582\n",
      "    val_log_likelihood: 1206.9149427727361\n",
      "    val_log_marginal: 753.3300263859741\n",
      "Train Epoch: 623 [512/17352 (3%)] Loss: -958.974792\n",
      "Train Epoch: 623 [9949/17352 (57%)] Loss: -1034.165148\n",
      "Train Epoch: 623 [17277/17352 (100%)] Loss: -746.413577\n",
      "    epoch          : 623\n",
      "    loss           : -915.0930327115349\n",
      "    val_loss       : -712.816389231364\n",
      "    val_log_likelihood: 1199.759547934536\n",
      "    val_log_marginal: 730.0545515307747\n",
      "Train Epoch: 624 [512/17352 (3%)] Loss: -915.752502\n",
      "Train Epoch: 624 [10389/17352 (60%)] Loss: -999.486234\n",
      "Train Epoch: 624 [16923/17352 (98%)] Loss: -1019.413032\n",
      "    epoch          : 624\n",
      "    loss           : -915.0541135163811\n",
      "    val_loss       : -748.5999737438578\n",
      "    val_log_likelihood: 1214.952993425128\n",
      "    val_log_marginal: 764.7881238309625\n",
      "Train Epoch: 625 [512/17352 (3%)] Loss: -971.781860\n",
      "Train Epoch: 625 [10087/17352 (58%)] Loss: -999.237786\n",
      "Train Epoch: 625 [16878/17352 (97%)] Loss: -1025.166314\n",
      "    epoch          : 625\n",
      "    loss           : -917.4907495458797\n",
      "    val_loss       : -734.0031527065939\n",
      "    val_log_likelihood: 1214.3659504006334\n",
      "    val_log_marginal: 748.6373491964297\n",
      "Train Epoch: 626 [512/17352 (3%)] Loss: -974.051147\n",
      "Train Epoch: 626 [10573/17352 (61%)] Loss: -934.123927\n",
      "Train Epoch: 626 [16988/17352 (98%)] Loss: -785.404497\n",
      "    epoch          : 626\n",
      "    loss           : -912.280334796231\n",
      "    val_loss       : -729.781176825832\n",
      "    val_log_likelihood: 1214.6839270865714\n",
      "    val_log_marginal: 750.8766977253914\n",
      "Train Epoch: 627 [512/17352 (3%)] Loss: -751.673462\n",
      "Train Epoch: 627 [10704/17352 (62%)] Loss: -1039.496519\n",
      "Train Epoch: 627 [16887/17352 (97%)] Loss: -818.911458\n",
      "    epoch          : 627\n",
      "    loss           : -918.2394582438186\n",
      "    val_loss       : -732.7808125326409\n",
      "    val_log_likelihood: 1213.3773073188966\n",
      "    val_log_marginal: 746.0236991564107\n",
      "Train Epoch: 628 [512/17352 (3%)] Loss: -977.578796\n",
      "Train Epoch: 628 [10894/17352 (63%)] Loss: -958.639453\n",
      "Train Epoch: 628 [17143/17352 (99%)] Loss: -947.099590\n",
      "    epoch          : 628\n",
      "    loss           : -917.2038528833674\n",
      "    val_loss       : -711.9859101948848\n",
      "    val_log_likelihood: 1208.681041528641\n",
      "    val_log_marginal: 728.2200382281402\n",
      "Train Epoch: 629 [512/17352 (3%)] Loss: -955.436035\n",
      "Train Epoch: 629 [10121/17352 (58%)] Loss: -961.145277\n",
      "Train Epoch: 629 [17153/17352 (99%)] Loss: -960.127697\n",
      "    epoch          : 629\n",
      "    loss           : -899.7079044561141\n",
      "    val_loss       : -682.1075924697842\n",
      "    val_log_likelihood: 1191.7256411366914\n",
      "    val_log_marginal: 702.1765586919058\n",
      "Train Epoch: 630 [512/17352 (3%)] Loss: -897.553284\n",
      "Train Epoch: 630 [10203/17352 (59%)] Loss: -956.713272\n",
      "Train Epoch: 630 [17253/17352 (99%)] Loss: -952.474631\n",
      "    epoch          : 630\n",
      "    loss           : -892.6342482045549\n",
      "    val_loss       : -615.6142767427572\n",
      "    val_log_likelihood: 1161.888704262372\n",
      "    val_log_marginal: 645.4368299605851\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch630.pth ...\n",
      "Train Epoch: 631 [512/17352 (3%)] Loss: -823.922302\n",
      "Train Epoch: 631 [10722/17352 (62%)] Loss: -642.878092\n",
      "Train Epoch: 631 [16922/17352 (98%)] Loss: -884.542405\n",
      "    epoch          : 631\n",
      "    loss           : -693.4014536179876\n",
      "    val_loss       : -610.157547649854\n",
      "    val_log_likelihood: 1133.52527177758\n",
      "    val_log_marginal: 662.0427976988475\n",
      "Train Epoch: 632 [512/17352 (3%)] Loss: -867.699524\n",
      "Train Epoch: 632 [10061/17352 (58%)] Loss: -788.280996\n",
      "Train Epoch: 632 [16923/17352 (98%)] Loss: -817.532122\n",
      "    epoch          : 632\n",
      "    loss           : -677.9308121341062\n",
      "    val_loss       : -601.1838059054382\n",
      "    val_log_likelihood: 1126.3066526883474\n",
      "    val_log_marginal: 653.8166764622252\n",
      "Train Epoch: 633 [512/17352 (3%)] Loss: -843.488403\n",
      "Train Epoch: 633 [10378/17352 (60%)] Loss: -843.206098\n",
      "Train Epoch: 633 [17044/17352 (98%)] Loss: -910.226693\n",
      "    epoch          : 633\n",
      "    loss           : -822.2973238674348\n",
      "    val_loss       : -694.613449366297\n",
      "    val_log_likelihood: 1173.0102075815369\n",
      "    val_log_marginal: 720.361206460226\n",
      "Train Epoch: 634 [512/17352 (3%)] Loss: -886.240356\n",
      "Train Epoch: 634 [10420/17352 (60%)] Loss: -912.808731\n",
      "Train Epoch: 634 [17049/17352 (98%)] Loss: -953.704624\n",
      "    epoch          : 634\n",
      "    loss           : -885.6475323518603\n",
      "    val_loss       : -684.9394656073523\n",
      "    val_log_likelihood: 1184.5690916269693\n",
      "    val_log_marginal: 711.9933593076012\n",
      "Train Epoch: 635 [512/17352 (3%)] Loss: -909.398987\n",
      "Train Epoch: 635 [10468/17352 (60%)] Loss: -994.807912\n",
      "Train Epoch: 635 [17263/17352 (99%)] Loss: -800.607582\n",
      "    epoch          : 635\n",
      "    loss           : -877.1378104691834\n",
      "    val_loss       : -639.046248748905\n",
      "    val_log_likelihood: 1144.2168284242243\n",
      "    val_log_marginal: 660.6591476750464\n",
      "Train Epoch: 636 [512/17352 (3%)] Loss: -867.380859\n",
      "Train Epoch: 636 [10588/17352 (61%)] Loss: -981.883729\n",
      "Train Epoch: 636 [17153/17352 (99%)] Loss: -833.872971\n",
      "    epoch          : 636\n",
      "    loss           : -885.0234432854398\n",
      "    val_loss       : -686.2737298007585\n",
      "    val_log_likelihood: 1164.5103741608548\n",
      "    val_log_marginal: 699.8615698599996\n",
      "Train Epoch: 637 [512/17352 (3%)] Loss: -870.702515\n",
      "Train Epoch: 637 [10180/17352 (59%)] Loss: -836.251803\n",
      "Train Epoch: 637 [16872/17352 (97%)] Loss: -974.823229\n",
      "    epoch          : 637\n",
      "    loss           : -896.3980911461174\n",
      "    val_loss       : -712.5926035315143\n",
      "    val_log_likelihood: 1178.6727712284537\n",
      "    val_log_marginal: 738.9389848547762\n",
      "Train Epoch: 638 [512/17352 (3%)] Loss: -943.530029\n",
      "Train Epoch: 638 [9855/17352 (57%)] Loss: -888.469124\n",
      "Train Epoch: 638 [17335/17352 (100%)] Loss: -1003.709897\n",
      "    epoch          : 638\n",
      "    loss           : -829.2535201076078\n",
      "    val_loss       : -662.6322433304372\n",
      "    val_log_likelihood: 1161.8269658267493\n",
      "    val_log_marginal: 700.7256438313926\n",
      "Train Epoch: 639 [512/17352 (3%)] Loss: -900.698608\n",
      "Train Epoch: 639 [10892/17352 (63%)] Loss: -691.332984\n",
      "Train Epoch: 639 [17044/17352 (98%)] Loss: -950.290833\n",
      "    epoch          : 639\n",
      "    loss           : -870.0069327711915\n",
      "    val_loss       : -687.5921721988732\n",
      "    val_log_likelihood: 1167.3099288726014\n",
      "    val_log_marginal: 714.370577629718\n",
      "Train Epoch: 640 [512/17352 (3%)] Loss: -903.167847\n",
      "Train Epoch: 640 [10166/17352 (59%)] Loss: -1008.668837\n",
      "Train Epoch: 640 [16882/17352 (97%)] Loss: -774.259462\n",
      "    epoch          : 640\n",
      "    loss           : -875.2928408048242\n",
      "    val_loss       : -714.4607530186707\n",
      "    val_log_likelihood: 1181.88198210793\n",
      "    val_log_marginal: 737.5702058664099\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch640.pth ...\n",
      "Train Epoch: 641 [512/17352 (3%)] Loss: -947.178650\n",
      "Train Epoch: 641 [9878/17352 (57%)] Loss: -1010.902344\n",
      "Train Epoch: 641 [17153/17352 (99%)] Loss: -983.170811\n",
      "    epoch          : 641\n",
      "    loss           : -889.9408070293639\n",
      "    val_loss       : -698.6256716745713\n",
      "    val_log_likelihood: 1189.300159373821\n",
      "    val_log_marginal: 727.7458920365502\n",
      "Train Epoch: 642 [512/17352 (3%)] Loss: -907.828857\n",
      "Train Epoch: 642 [10815/17352 (62%)] Loss: -895.193338\n",
      "Train Epoch: 642 [16934/17352 (98%)] Loss: -966.392724\n",
      "    epoch          : 642\n",
      "    loss           : -885.717648039173\n",
      "    val_loss       : -704.0928741909972\n",
      "    val_log_likelihood: 1191.0238328122666\n",
      "    val_log_marginal: 728.6763833515613\n",
      "Train Epoch: 643 [512/17352 (3%)] Loss: -933.488342\n",
      "Train Epoch: 643 [10431/17352 (60%)] Loss: -891.466944\n",
      "Train Epoch: 643 [16988/17352 (98%)] Loss: -814.530951\n",
      "    epoch          : 643\n",
      "    loss           : -888.4175952351127\n",
      "    val_loss       : -723.9535825314787\n",
      "    val_log_likelihood: 1197.7782700595023\n",
      "    val_log_marginal: 747.683720116801\n",
      "Train Epoch: 644 [512/17352 (3%)] Loss: -951.658081\n",
      "Train Epoch: 644 [10068/17352 (58%)] Loss: -861.864200\n",
      "Train Epoch: 644 [16992/17352 (98%)] Loss: -673.004032\n",
      "    epoch          : 644\n",
      "    loss           : -879.7911999351105\n",
      "    val_loss       : -709.6954585889769\n",
      "    val_log_likelihood: 1193.8254323491183\n",
      "    val_log_marginal: 740.5573665465017\n",
      "Train Epoch: 645 [512/17352 (3%)] Loss: -654.823853\n",
      "Train Epoch: 645 [10400/17352 (60%)] Loss: -971.370469\n",
      "Train Epoch: 645 [17277/17352 (100%)] Loss: -949.675442\n",
      "    epoch          : 645\n",
      "    loss           : -892.8743757959095\n",
      "    val_loss       : -701.2101644528157\n",
      "    val_log_likelihood: 1191.1416874320423\n",
      "    val_log_marginal: 725.9972810192058\n",
      "Train Epoch: 646 [512/17352 (3%)] Loss: -928.228577\n",
      "Train Epoch: 646 [11039/17352 (64%)] Loss: -845.452438\n",
      "Train Epoch: 646 [17106/17352 (99%)] Loss: -794.890574\n",
      "    epoch          : 646\n",
      "    loss           : -898.8632441821178\n",
      "    val_loss       : -748.2993911580103\n",
      "    val_log_likelihood: 1211.3542537768383\n",
      "    val_log_marginal: 767.4603585251532\n",
      "Train Epoch: 647 [512/17352 (3%)] Loss: -948.664490\n",
      "Train Epoch: 647 [10059/17352 (58%)] Loss: -857.894976\n",
      "Train Epoch: 647 [16887/17352 (97%)] Loss: -858.656808\n",
      "    epoch          : 647\n",
      "    loss           : -903.8012445304361\n",
      "    val_loss       : -745.9564156130767\n",
      "    val_log_likelihood: 1216.8107953314836\n",
      "    val_log_marginal: 762.6305864411771\n",
      "Train Epoch: 648 [512/17352 (3%)] Loss: -945.964478\n",
      "Train Epoch: 648 [9989/17352 (58%)] Loss: -975.502426\n",
      "Train Epoch: 648 [16883/17352 (97%)] Loss: -881.045673\n",
      "    epoch          : 648\n",
      "    loss           : -892.8016817204766\n",
      "    val_loss       : -680.9989512931592\n",
      "    val_log_likelihood: 1198.8075991608966\n",
      "    val_log_marginal: 703.83805374067\n",
      "Train Epoch: 649 [512/17352 (3%)] Loss: -926.718689\n",
      "Train Epoch: 649 [10049/17352 (58%)] Loss: -838.276796\n",
      "Train Epoch: 649 [17153/17352 (99%)] Loss: -1000.391058\n",
      "    epoch          : 649\n",
      "    loss           : -904.429848709597\n",
      "    val_loss       : -680.0813278300803\n",
      "    val_log_likelihood: 1193.5112475077367\n",
      "    val_log_marginal: 703.225431441367\n",
      "Train Epoch: 650 [512/17352 (3%)] Loss: -916.732300\n",
      "Train Epoch: 650 [10017/17352 (58%)] Loss: -1018.449653\n",
      "Train Epoch: 650 [17143/17352 (99%)] Loss: -950.647500\n",
      "    epoch          : 650\n",
      "    loss           : -901.9610552358919\n",
      "    val_loss       : -706.0348211818224\n",
      "    val_log_likelihood: 1204.6441286092256\n",
      "    val_log_marginal: 722.510143524278\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch650.pth ...\n",
      "Train Epoch: 651 [512/17352 (3%)] Loss: -736.976501\n",
      "Train Epoch: 651 [10641/17352 (61%)] Loss: -954.003733\n",
      "Train Epoch: 651 [16922/17352 (98%)] Loss: -1017.879843\n",
      "    epoch          : 651\n",
      "    loss           : -907.8186622974665\n",
      "    val_loss       : -742.249820882734\n",
      "    val_log_likelihood: 1219.9311127245214\n",
      "    val_log_marginal: 757.8303945259559\n",
      "Train Epoch: 652 [512/17352 (3%)] Loss: -962.089966\n",
      "Train Epoch: 652 [10074/17352 (58%)] Loss: -944.871660\n",
      "Train Epoch: 652 [16934/17352 (98%)] Loss: -1004.596367\n",
      "    epoch          : 652\n",
      "    loss           : -917.8660845789724\n",
      "    val_loss       : -733.2117371096119\n",
      "    val_log_likelihood: 1214.9635978142492\n",
      "    val_log_marginal: 750.1267045014251\n",
      "Train Epoch: 653 [512/17352 (3%)] Loss: -956.229126\n",
      "Train Epoch: 653 [10026/17352 (58%)] Loss: -1017.078601\n",
      "Train Epoch: 653 [16883/17352 (97%)] Loss: -853.632711\n",
      "    epoch          : 653\n",
      "    loss           : -924.3275227751975\n",
      "    val_loss       : -749.4964980809051\n",
      "    val_log_likelihood: 1220.6398699415827\n",
      "    val_log_marginal: 772.1594976178278\n",
      "Train Epoch: 654 [512/17352 (3%)] Loss: -975.152344\n",
      "Train Epoch: 654 [9870/17352 (57%)] Loss: -750.910693\n",
      "Train Epoch: 654 [16922/17352 (98%)] Loss: -962.119573\n",
      "    epoch          : 654\n",
      "    loss           : -908.0541847640711\n",
      "    val_loss       : -724.528176684172\n",
      "    val_log_likelihood: 1204.9656186784089\n",
      "    val_log_marginal: 744.1704204694935\n",
      "Train Epoch: 655 [512/17352 (3%)] Loss: -948.262573\n",
      "Train Epoch: 655 [10798/17352 (62%)] Loss: -1010.102612\n",
      "Train Epoch: 655 [16992/17352 (98%)] Loss: -986.721440\n",
      "    epoch          : 655\n",
      "    loss           : -898.9624928047439\n",
      "    val_loss       : -722.696707830238\n",
      "    val_log_likelihood: 1204.702343952535\n",
      "    val_log_marginal: 739.1461581965841\n",
      "Train Epoch: 656 [512/17352 (3%)] Loss: -932.926086\n",
      "Train Epoch: 656 [9700/17352 (56%)] Loss: -939.803028\n",
      "Train Epoch: 656 [17277/17352 (100%)] Loss: -1052.991102\n",
      "    epoch          : 656\n",
      "    loss           : -910.0551769261145\n",
      "    val_loss       : -722.18013971763\n",
      "    val_log_likelihood: 1211.1049890836787\n",
      "    val_log_marginal: 744.9944253997156\n",
      "Train Epoch: 657 [512/17352 (3%)] Loss: -956.748108\n",
      "Train Epoch: 657 [10745/17352 (62%)] Loss: -1022.716223\n",
      "Train Epoch: 657 [17277/17352 (100%)] Loss: -837.311558\n",
      "    epoch          : 657\n",
      "    loss           : -904.3360430054717\n",
      "    val_loss       : -718.697914768018\n",
      "    val_log_likelihood: 1208.6779118309844\n",
      "    val_log_marginal: 729.6256112321153\n",
      "Train Epoch: 658 [512/17352 (3%)] Loss: -926.033813\n",
      "Train Epoch: 658 [10136/17352 (58%)] Loss: -850.482292\n",
      "Train Epoch: 658 [16923/17352 (98%)] Loss: -820.235166\n",
      "    epoch          : 658\n",
      "    loss           : -900.9603284240467\n",
      "    val_loss       : -702.2318540251131\n",
      "    val_log_likelihood: 1212.1558908370084\n",
      "    val_log_marginal: 719.0524713450108\n",
      "Train Epoch: 659 [512/17352 (3%)] Loss: -906.161011\n",
      "Train Epoch: 659 [10464/17352 (60%)] Loss: -989.297589\n",
      "Train Epoch: 659 [16882/17352 (97%)] Loss: -985.689479\n",
      "    epoch          : 659\n",
      "    loss           : -905.4164840057545\n",
      "    val_loss       : -746.213590595111\n",
      "    val_log_likelihood: 1224.8363586606597\n",
      "    val_log_marginal: 765.7033773766176\n",
      "Train Epoch: 660 [512/17352 (3%)] Loss: -970.202026\n",
      "Train Epoch: 660 [10297/17352 (59%)] Loss: -774.914247\n",
      "Train Epoch: 660 [16922/17352 (98%)] Loss: -861.430147\n",
      "    epoch          : 660\n",
      "    loss           : -929.9986492683929\n",
      "    val_loss       : -742.6419488344801\n",
      "    val_log_likelihood: 1221.5757371786126\n",
      "    val_log_marginal: 763.0676156789544\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch660.pth ...\n",
      "Train Epoch: 661 [512/17352 (3%)] Loss: -987.888916\n",
      "Train Epoch: 661 [10503/17352 (61%)] Loss: -931.464196\n",
      "Train Epoch: 661 [16922/17352 (98%)] Loss: -775.168654\n",
      "    epoch          : 661\n",
      "    loss           : -896.8598598258699\n",
      "    val_loss       : -682.8104805925882\n",
      "    val_log_likelihood: 1195.5527145406943\n",
      "    val_log_marginal: 715.8348947005873\n",
      "Train Epoch: 662 [512/17352 (3%)] Loss: -835.274597\n",
      "Train Epoch: 662 [10113/17352 (58%)] Loss: -844.255761\n",
      "Train Epoch: 662 [17133/17352 (99%)] Loss: -700.619318\n",
      "    epoch          : 662\n",
      "    loss           : -846.3353108641878\n",
      "    val_loss       : -637.8582218584681\n",
      "    val_log_likelihood: 1175.7016108444275\n",
      "    val_log_marginal: 677.5936594947634\n",
      "Train Epoch: 663 [512/17352 (3%)] Loss: -902.714661\n",
      "Train Epoch: 663 [9934/17352 (57%)] Loss: -915.931531\n",
      "Train Epoch: 663 [17090/17352 (98%)] Loss: -744.505578\n",
      "    epoch          : 663\n",
      "    loss           : -844.120688920541\n",
      "    val_loss       : -666.2087556445032\n",
      "    val_log_likelihood: 1168.9161490862737\n",
      "    val_log_marginal: 688.8342853886152\n",
      "Train Epoch: 664 [512/17352 (3%)] Loss: -898.735107\n",
      "Train Epoch: 664 [10230/17352 (59%)] Loss: -840.394980\n",
      "Train Epoch: 664 [16882/17352 (97%)] Loss: -959.813378\n",
      "    epoch          : 664\n",
      "    loss           : -901.2074680058438\n",
      "    val_loss       : -709.9984897869199\n",
      "    val_log_likelihood: 1199.4031718581775\n",
      "    val_log_marginal: 726.1225925516511\n",
      "Train Epoch: 665 [512/17352 (3%)] Loss: -959.428223\n",
      "Train Epoch: 665 [10179/17352 (59%)] Loss: -802.112500\n",
      "Train Epoch: 665 [16934/17352 (98%)] Loss: -992.028474\n",
      "    epoch          : 665\n",
      "    loss           : -889.9356519340453\n",
      "    val_loss       : -703.1004904866462\n",
      "    val_log_likelihood: 1192.7008508687045\n",
      "    val_log_marginal: 723.6959029624941\n",
      "Train Epoch: 666 [512/17352 (3%)] Loss: -933.884644\n",
      "Train Epoch: 666 [10047/17352 (58%)] Loss: -921.501321\n",
      "Train Epoch: 666 [17090/17352 (98%)] Loss: -993.069840\n",
      "    epoch          : 666\n",
      "    loss           : -902.6965456688272\n",
      "    val_loss       : -708.0989783414884\n",
      "    val_log_likelihood: 1202.9986790090022\n",
      "    val_log_marginal: 730.4324224978577\n",
      "Train Epoch: 667 [512/17352 (3%)] Loss: -935.862549\n",
      "Train Epoch: 667 [9807/17352 (57%)] Loss: -1004.930259\n",
      "Train Epoch: 667 [16883/17352 (97%)] Loss: -811.618080\n",
      "    epoch          : 667\n",
      "    loss           : -920.3491027424767\n",
      "    val_loss       : -737.787678076099\n",
      "    val_log_likelihood: 1223.163943586988\n",
      "    val_log_marginal: 757.6429009611503\n",
      "Train Epoch: 668 [512/17352 (3%)] Loss: -943.919800\n",
      "Train Epoch: 668 [10418/17352 (60%)] Loss: -1004.294017\n",
      "Train Epoch: 668 [17016/17352 (98%)] Loss: -807.074979\n",
      "    epoch          : 668\n",
      "    loss           : -923.2591248134887\n",
      "    val_loss       : -728.5032981202664\n",
      "    val_log_likelihood: 1216.6913525134482\n",
      "    val_log_marginal: 748.7315347994083\n",
      "Train Epoch: 669 [512/17352 (3%)] Loss: -973.418091\n",
      "Train Epoch: 669 [10617/17352 (61%)] Loss: -933.010646\n",
      "Train Epoch: 669 [16872/17352 (97%)] Loss: -857.742795\n",
      "    epoch          : 669\n",
      "    loss           : -931.3972046528507\n",
      "    val_loss       : -734.4788416155807\n",
      "    val_log_likelihood: 1227.963764060145\n",
      "    val_log_marginal: 756.1055842994451\n",
      "Train Epoch: 670 [512/17352 (3%)] Loss: -985.084045\n",
      "Train Epoch: 670 [10823/17352 (62%)] Loss: -913.997396\n",
      "Train Epoch: 670 [17263/17352 (99%)] Loss: -891.248798\n",
      "    epoch          : 670\n",
      "    loss           : -923.2300126540847\n",
      "    val_loss       : -688.0026920544055\n",
      "    val_log_likelihood: 1219.6260527291795\n",
      "    val_log_marginal: 719.7255877362888\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch670.pth ...\n",
      "Train Epoch: 671 [512/17352 (3%)] Loss: -937.727417\n",
      "Train Epoch: 671 [10665/17352 (61%)] Loss: -948.849714\n",
      "Train Epoch: 671 [17126/17352 (99%)] Loss: -1003.985625\n",
      "    epoch          : 671\n",
      "    loss           : -906.9399094116513\n",
      "    val_loss       : -726.4001498167484\n",
      "    val_log_likelihood: 1222.5520537808118\n",
      "    val_log_marginal: 752.855994144563\n",
      "Train Epoch: 672 [512/17352 (3%)] Loss: -966.048828\n",
      "Train Epoch: 672 [10488/17352 (60%)] Loss: -1068.602214\n",
      "Train Epoch: 672 [16882/17352 (97%)] Loss: -841.964926\n",
      "    epoch          : 672\n",
      "    loss           : -923.4428243881247\n",
      "    val_loss       : -733.0803708146817\n",
      "    val_log_likelihood: 1224.3225417845686\n",
      "    val_log_marginal: 750.3652661489688\n",
      "Train Epoch: 673 [512/17352 (3%)] Loss: -971.516174\n",
      "Train Epoch: 673 [10014/17352 (58%)] Loss: -886.351226\n",
      "Train Epoch: 673 [16872/17352 (97%)] Loss: -803.240520\n",
      "    epoch          : 673\n",
      "    loss           : -900.4790541315905\n",
      "    val_loss       : -651.4666183661801\n",
      "    val_log_likelihood: 1216.5739999170053\n",
      "    val_log_marginal: 677.1778753949274\n",
      "Train Epoch: 674 [512/17352 (3%)] Loss: -869.928711\n",
      "Train Epoch: 674 [10889/17352 (63%)] Loss: -941.361992\n",
      "Train Epoch: 674 [17016/17352 (98%)] Loss: -959.561358\n",
      "    epoch          : 674\n",
      "    loss           : -850.8315521940664\n",
      "    val_loss       : -667.0475103074843\n",
      "    val_log_likelihood: 1198.8956702276457\n",
      "    val_log_marginal: 690.2463158924486\n",
      "Train Epoch: 675 [512/17352 (3%)] Loss: -889.409302\n",
      "Train Epoch: 675 [10471/17352 (60%)] Loss: -948.197820\n",
      "Train Epoch: 675 [16958/17352 (98%)] Loss: -990.354196\n",
      "    epoch          : 675\n",
      "    loss           : -889.0689685372745\n",
      "    val_loss       : -733.5573136378634\n",
      "    val_log_likelihood: 1213.9321179905075\n",
      "    val_log_marginal: 752.6532242731512\n",
      "Train Epoch: 676 [512/17352 (3%)] Loss: -959.400269\n",
      "Train Epoch: 676 [10987/17352 (63%)] Loss: -726.301136\n",
      "Train Epoch: 676 [16923/17352 (98%)] Loss: -916.383759\n",
      "    epoch          : 676\n",
      "    loss           : -914.0309022377535\n",
      "    val_loss       : -732.6516175282372\n",
      "    val_log_likelihood: 1210.803441631102\n",
      "    val_log_marginal: 753.0454171883842\n",
      "Train Epoch: 677 [512/17352 (3%)] Loss: -970.276489\n",
      "Train Epoch: 677 [10041/17352 (58%)] Loss: -971.420733\n",
      "Train Epoch: 677 [16887/17352 (97%)] Loss: -769.593386\n",
      "    epoch          : 677\n",
      "    loss           : -915.9301298036908\n",
      "    val_loss       : -740.6828542460482\n",
      "    val_log_likelihood: 1223.812900753455\n",
      "    val_log_marginal: 760.7781914144908\n",
      "Train Epoch: 678 [512/17352 (3%)] Loss: -991.105103\n",
      "Train Epoch: 678 [10465/17352 (60%)] Loss: -916.763706\n",
      "Train Epoch: 678 [17335/17352 (100%)] Loss: -991.214218\n",
      "    epoch          : 678\n",
      "    loss           : -927.8333669438724\n",
      "    val_loss       : -720.9910602991051\n",
      "    val_log_likelihood: 1220.153026018125\n",
      "    val_log_marginal: 745.3315492301368\n",
      "Train Epoch: 679 [512/17352 (3%)] Loss: -937.353821\n",
      "Train Epoch: 679 [10417/17352 (60%)] Loss: -1002.086903\n",
      "Train Epoch: 679 [17044/17352 (98%)] Loss: -904.671703\n",
      "    epoch          : 679\n",
      "    loss           : -908.5439518550677\n",
      "    val_loss       : -739.9691217967691\n",
      "    val_log_likelihood: 1221.7179520371278\n",
      "    val_log_marginal: 756.5965813543146\n",
      "Train Epoch: 680 [512/17352 (3%)] Loss: -974.352661\n",
      "Train Epoch: 680 [9976/17352 (57%)] Loss: -845.266538\n",
      "Train Epoch: 680 [16922/17352 (98%)] Loss: -813.832168\n",
      "    epoch          : 680\n",
      "    loss           : -917.4314179431578\n",
      "    val_loss       : -737.4081595020722\n",
      "    val_log_likelihood: 1227.0719416762786\n",
      "    val_log_marginal: 757.7366459950216\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch680.pth ...\n",
      "Train Epoch: 681 [512/17352 (3%)] Loss: -948.238159\n",
      "Train Epoch: 681 [10466/17352 (60%)] Loss: -998.552939\n",
      "Train Epoch: 681 [17277/17352 (100%)] Loss: -1047.772421\n",
      "    epoch          : 681\n",
      "    loss           : -932.8728554567467\n",
      "    val_loss       : -703.9277945123579\n",
      "    val_log_likelihood: 1207.624790490946\n",
      "    val_log_marginal: 721.7704832702892\n",
      "Train Epoch: 682 [512/17352 (3%)] Loss: -739.083984\n",
      "Train Epoch: 682 [9999/17352 (58%)] Loss: -867.536650\n",
      "Train Epoch: 682 [17044/17352 (98%)] Loss: -1022.128465\n",
      "    epoch          : 682\n",
      "    loss           : -927.7850488565923\n",
      "    val_loss       : -747.3407101528248\n",
      "    val_log_likelihood: 1238.5303214501398\n",
      "    val_log_marginal: 764.6541215748382\n",
      "Train Epoch: 683 [512/17352 (3%)] Loss: -961.645874\n",
      "Train Epoch: 683 [9967/17352 (57%)] Loss: -883.335361\n",
      "Train Epoch: 683 [16887/17352 (97%)] Loss: -1016.829942\n",
      "    epoch          : 683\n",
      "    loss           : -939.1211975023855\n",
      "    val_loss       : -738.4876886964486\n",
      "    val_log_likelihood: 1234.9105165987714\n",
      "    val_log_marginal: 762.5595519349486\n",
      "Train Epoch: 684 [512/17352 (3%)] Loss: -986.137085\n",
      "Train Epoch: 684 [10297/17352 (59%)] Loss: -869.251218\n",
      "Train Epoch: 684 [17153/17352 (99%)] Loss: -992.568414\n",
      "    epoch          : 684\n",
      "    loss           : -941.9701374954996\n",
      "    val_loss       : -737.3258442244772\n",
      "    val_log_likelihood: 1236.4063114059245\n",
      "    val_log_marginal: 755.5062013339837\n",
      "Train Epoch: 685 [512/17352 (3%)] Loss: -984.861450\n",
      "Train Epoch: 685 [10534/17352 (61%)] Loss: -994.878219\n",
      "Train Epoch: 685 [17143/17352 (99%)] Loss: -1034.598958\n",
      "    epoch          : 685\n",
      "    loss           : -938.970525264639\n",
      "    val_loss       : -709.7595083811757\n",
      "    val_log_likelihood: 1227.1743141098195\n",
      "    val_log_marginal: 732.609105901037\n",
      "Train Epoch: 686 [512/17352 (3%)] Loss: -960.828613\n",
      "Train Epoch: 686 [10063/17352 (58%)] Loss: -656.222312\n",
      "Train Epoch: 686 [16958/17352 (98%)] Loss: -742.111485\n",
      "    epoch          : 686\n",
      "    loss           : -870.927058678491\n",
      "    val_loss       : -665.2608397081173\n",
      "    val_log_likelihood: 1194.375667592813\n",
      "    val_log_marginal: 693.7819035645118\n",
      "Train Epoch: 687 [512/17352 (3%)] Loss: -921.903442\n",
      "Train Epoch: 687 [10038/17352 (58%)] Loss: -896.617619\n",
      "Train Epoch: 687 [16872/17352 (97%)] Loss: -849.459991\n",
      "    epoch          : 687\n",
      "    loss           : -799.406186094337\n",
      "    val_loss       : -384.4567983879022\n",
      "    val_log_likelihood: 1073.8452073132\n",
      "    val_log_marginal: 556.4887926133255\n",
      "Train Epoch: 688 [512/17352 (3%)] Loss: -638.414917\n",
      "Train Epoch: 688 [10718/17352 (62%)] Loss: -790.013706\n",
      "Train Epoch: 688 [16872/17352 (97%)] Loss: -835.101299\n",
      "    epoch          : 688\n",
      "    loss           : -778.5017550748919\n",
      "    val_loss       : -665.2591333754566\n",
      "    val_log_likelihood: 1186.4989231543968\n",
      "    val_log_marginal: 693.4545868840637\n",
      "Train Epoch: 689 [512/17352 (3%)] Loss: -905.702026\n",
      "Train Epoch: 689 [10378/17352 (60%)] Loss: -796.323450\n",
      "Train Epoch: 689 [16992/17352 (98%)] Loss: -955.404375\n",
      "    epoch          : 689\n",
      "    loss           : -880.3221495735779\n",
      "    val_loss       : -699.3172228978841\n",
      "    val_log_likelihood: 1206.1665042884936\n",
      "    val_log_marginal: 739.6519778304704\n",
      "Train Epoch: 690 [512/17352 (3%)] Loss: -898.518005\n",
      "Train Epoch: 690 [10292/17352 (59%)] Loss: -893.415228\n",
      "Train Epoch: 690 [16923/17352 (98%)] Loss: -1028.352906\n",
      "    epoch          : 690\n",
      "    loss           : -894.5632223950912\n",
      "    val_loss       : -725.4615907264107\n",
      "    val_log_likelihood: 1215.78619909888\n",
      "    val_log_marginal: 744.7136364567785\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch690.pth ...\n",
      "Train Epoch: 691 [512/17352 (3%)] Loss: -960.641724\n",
      "Train Epoch: 691 [10674/17352 (62%)] Loss: -1018.870412\n",
      "Train Epoch: 691 [17016/17352 (98%)] Loss: -894.492960\n",
      "    epoch          : 691\n",
      "    loss           : -906.836386751173\n",
      "    val_loss       : -721.1654474319923\n",
      "    val_log_likelihood: 1214.0567630769597\n",
      "    val_log_marginal: 742.3367881395204\n",
      "Train Epoch: 692 [512/17352 (3%)] Loss: -947.993225\n",
      "Train Epoch: 692 [10172/17352 (59%)] Loss: -971.591607\n",
      "Train Epoch: 692 [17090/17352 (98%)] Loss: -902.012249\n",
      "    epoch          : 692\n",
      "    loss           : -910.4878369102065\n",
      "    val_loss       : -701.824157147437\n",
      "    val_log_likelihood: 1207.1616230282775\n",
      "    val_log_marginal: 726.1114267908908\n",
      "Train Epoch: 693 [512/17352 (3%)] Loss: -913.402832\n",
      "Train Epoch: 693 [10879/17352 (63%)] Loss: -1031.869348\n",
      "Train Epoch: 693 [17143/17352 (99%)] Loss: -815.863237\n",
      "    epoch          : 693\n",
      "    loss           : -862.2933169551817\n",
      "    val_loss       : -667.0943218259171\n",
      "    val_log_likelihood: 1190.368487280151\n",
      "    val_log_marginal: 691.3926663261143\n",
      "Train Epoch: 694 [512/17352 (3%)] Loss: -904.742004\n",
      "Train Epoch: 694 [10285/17352 (59%)] Loss: -662.657440\n",
      "Train Epoch: 694 [16922/17352 (98%)] Loss: -210.041448\n",
      "    epoch          : 694\n",
      "    loss           : -667.6678239974334\n",
      "    val_loss       : -130.56037180987707\n",
      "    val_log_likelihood: 1116.792774714134\n",
      "    val_log_marginal: 170.38223861673006\n",
      "Train Epoch: 695 [512/17352 (3%)] Loss: -486.684845\n",
      "Train Epoch: 695 [10727/17352 (62%)] Loss: -685.985870\n",
      "Train Epoch: 695 [17335/17352 (100%)] Loss: -583.271573\n",
      "    epoch          : 695\n",
      "    loss           : -698.2185669712181\n",
      "    val_loss       : -241.67352741110818\n",
      "    val_log_likelihood: 1138.3713829314052\n",
      "    val_log_marginal: 271.7149154214591\n",
      "Train Epoch: 696 [512/17352 (3%)] Loss: -545.992371\n",
      "Train Epoch: 696 [10210/17352 (59%)] Loss: -871.000550\n",
      "Train Epoch: 696 [17090/17352 (98%)] Loss: -793.870944\n",
      "    epoch          : 696\n",
      "    loss           : -728.6663940722534\n",
      "    val_loss       : -541.6779237194208\n",
      "    val_log_likelihood: 1165.1408888367166\n",
      "    val_log_marginal: 569.7734560220248\n",
      "Train Epoch: 697 [512/17352 (3%)] Loss: -767.939209\n",
      "Train Epoch: 697 [10911/17352 (63%)] Loss: -679.905476\n",
      "Train Epoch: 697 [17108/17352 (99%)] Loss: -961.189854\n",
      "    epoch          : 697\n",
      "    loss           : -869.6871207203695\n",
      "    val_loss       : -710.4737542828163\n",
      "    val_log_likelihood: 1188.77387957878\n",
      "    val_log_marginal: 731.263054031947\n",
      "Train Epoch: 698 [512/17352 (3%)] Loss: -943.103271\n",
      "Train Epoch: 698 [10197/17352 (59%)] Loss: -749.894513\n",
      "Train Epoch: 698 [17106/17352 (99%)] Loss: -909.703468\n",
      "    epoch          : 698\n",
      "    loss           : -907.6239389311203\n",
      "    val_loss       : -722.9291556841504\n",
      "    val_log_likelihood: 1209.417494103067\n",
      "    val_log_marginal: 744.1807015119488\n",
      "Train Epoch: 699 [512/17352 (3%)] Loss: -970.766479\n",
      "Train Epoch: 699 [10620/17352 (61%)] Loss: -1009.302187\n",
      "Train Epoch: 699 [17253/17352 (99%)] Loss: -800.644288\n",
      "    epoch          : 699\n",
      "    loss           : -929.0850505305596\n",
      "    val_loss       : -743.017820645402\n",
      "    val_log_likelihood: 1224.2717682689088\n",
      "    val_log_marginal: 764.0657946584097\n",
      "Train Epoch: 700 [512/17352 (3%)] Loss: -965.081848\n",
      "Train Epoch: 700 [9996/17352 (58%)] Loss: -984.757097\n",
      "Train Epoch: 700 [17106/17352 (99%)] Loss: -859.656026\n",
      "    epoch          : 700\n",
      "    loss           : -939.5691586512278\n",
      "    val_loss       : -749.0171599035816\n",
      "    val_log_likelihood: 1221.868550033251\n",
      "    val_log_marginal: 762.9418668437595\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch700.pth ...\n",
      "Train Epoch: 701 [512/17352 (3%)] Loss: -993.169434\n",
      "Train Epoch: 701 [9864/17352 (57%)] Loss: -993.275996\n",
      "Train Epoch: 701 [17153/17352 (99%)] Loss: -764.870920\n",
      "    epoch          : 701\n",
      "    loss           : -929.8453946075808\n",
      "    val_loss       : -730.0687437922983\n",
      "    val_log_likelihood: 1225.7945362444711\n",
      "    val_log_marginal: 751.3265036317639\n",
      "Train Epoch: 702 [512/17352 (3%)] Loss: -980.886475\n",
      "Train Epoch: 702 [10451/17352 (60%)] Loss: -1019.658861\n",
      "Train Epoch: 702 [16958/17352 (98%)] Loss: -1009.041178\n",
      "    epoch          : 702\n",
      "    loss           : -907.3557211619401\n",
      "    val_loss       : -716.9578303448665\n",
      "    val_log_likelihood: 1211.2555150969654\n",
      "    val_log_marginal: 746.3065551962852\n",
      "Train Epoch: 703 [512/17352 (3%)] Loss: -976.095825\n",
      "Train Epoch: 703 [10289/17352 (59%)] Loss: -993.185832\n",
      "Train Epoch: 703 [16887/17352 (97%)] Loss: -808.979200\n",
      "    epoch          : 703\n",
      "    loss           : -918.9610938696994\n",
      "    val_loss       : -732.1391103893643\n",
      "    val_log_likelihood: 1223.379436427437\n",
      "    val_log_marginal: 754.5174502821731\n",
      "Train Epoch: 704 [512/17352 (3%)] Loss: -965.134033\n",
      "Train Epoch: 704 [10723/17352 (62%)] Loss: -1026.883262\n",
      "Train Epoch: 704 [17049/17352 (98%)] Loss: -1027.865093\n",
      "    epoch          : 704\n",
      "    loss           : -919.625765747618\n",
      "    val_loss       : -711.217181659352\n",
      "    val_log_likelihood: 1220.3905733215458\n",
      "    val_log_marginal: 751.5276663226296\n",
      "Train Epoch: 705 [512/17352 (3%)] Loss: -972.298096\n",
      "Train Epoch: 705 [9759/17352 (56%)] Loss: -834.837130\n",
      "Train Epoch: 705 [16988/17352 (98%)] Loss: -943.221390\n",
      "    epoch          : 705\n",
      "    loss           : -867.6801100215318\n",
      "    val_loss       : -668.1630744956229\n",
      "    val_log_likelihood: 1159.6349462940443\n",
      "    val_log_marginal: 697.8026796083974\n",
      "Train Epoch: 706 [512/17352 (3%)] Loss: -702.006958\n",
      "Train Epoch: 706 [10203/17352 (59%)] Loss: -996.596471\n",
      "Train Epoch: 706 [17106/17352 (99%)] Loss: -996.810537\n",
      "    epoch          : 706\n",
      "    loss           : -911.6567907813316\n",
      "    val_loss       : -729.2440733795976\n",
      "    val_log_likelihood: 1220.3296599602768\n",
      "    val_log_marginal: 749.1743036374364\n",
      "Train Epoch: 707 [512/17352 (3%)] Loss: -966.093750\n",
      "Train Epoch: 707 [10377/17352 (60%)] Loss: -803.349887\n",
      "Train Epoch: 707 [17016/17352 (98%)] Loss: -764.518092\n",
      "    epoch          : 707\n",
      "    loss           : -931.5259567680362\n",
      "    val_loss       : -754.5563991524072\n",
      "    val_log_likelihood: 1230.5117841430435\n",
      "    val_log_marginal: 767.2252894183479\n",
      "Train Epoch: 708 [512/17352 (3%)] Loss: -977.260498\n",
      "Train Epoch: 708 [10289/17352 (59%)] Loss: -976.743405\n",
      "Train Epoch: 708 [17335/17352 (100%)] Loss: -998.061287\n",
      "    epoch          : 708\n",
      "    loss           : -946.0980630146711\n",
      "    val_loss       : -735.172884172818\n",
      "    val_log_likelihood: 1219.5299888232007\n",
      "    val_log_marginal: 755.0898629500095\n",
      "Train Epoch: 709 [512/17352 (3%)] Loss: -959.013000\n",
      "Train Epoch: 709 [10303/17352 (59%)] Loss: -765.965685\n",
      "Train Epoch: 709 [16882/17352 (97%)] Loss: -833.067957\n",
      "    epoch          : 709\n",
      "    loss           : -945.3529267734119\n",
      "    val_loss       : -756.9210439206971\n",
      "    val_log_likelihood: 1237.3419244495483\n",
      "    val_log_marginal: 773.4652296245129\n",
      "Train Epoch: 710 [512/17352 (3%)] Loss: -997.766113\n",
      "Train Epoch: 710 [10322/17352 (59%)] Loss: -996.358854\n",
      "Train Epoch: 710 [16878/17352 (97%)] Loss: -1026.144400\n",
      "    epoch          : 710\n",
      "    loss           : -952.5366355800248\n",
      "    val_loss       : -745.0853419382148\n",
      "    val_log_likelihood: 1239.1747926403277\n",
      "    val_log_marginal: 764.5271744295429\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch710.pth ...\n",
      "Train Epoch: 711 [512/17352 (3%)] Loss: -1007.735596\n",
      "Train Epoch: 711 [10966/17352 (63%)] Loss: -1039.510794\n",
      "Train Epoch: 711 [17253/17352 (99%)] Loss: -840.435835\n",
      "    epoch          : 711\n",
      "    loss           : -928.0688918615989\n",
      "    val_loss       : -717.54093305587\n",
      "    val_log_likelihood: 1229.2236379802157\n",
      "    val_log_marginal: 736.4034358998689\n",
      "Train Epoch: 712 [512/17352 (3%)] Loss: -935.951355\n",
      "Train Epoch: 712 [10604/17352 (61%)] Loss: -1075.943359\n",
      "Train Epoch: 712 [16958/17352 (98%)] Loss: -892.208262\n",
      "    epoch          : 712\n",
      "    loss           : -916.976788667527\n",
      "    val_loss       : -631.9090431847299\n",
      "    val_log_likelihood: 1210.7142626147972\n",
      "    val_log_marginal: 650.6101934152123\n",
      "Train Epoch: 713 [512/17352 (3%)] Loss: -672.678894\n",
      "Train Epoch: 713 [10709/17352 (62%)] Loss: -867.030382\n",
      "Train Epoch: 713 [16883/17352 (97%)] Loss: -1011.294946\n",
      "    epoch          : 713\n",
      "    loss           : -888.9738762710468\n",
      "    val_loss       : -717.0293172442181\n",
      "    val_log_likelihood: 1238.051828822391\n",
      "    val_log_marginal: 741.3377968884087\n",
      "Train Epoch: 714 [512/17352 (3%)] Loss: -782.416748\n",
      "Train Epoch: 714 [9834/17352 (57%)] Loss: -977.656458\n",
      "Train Epoch: 714 [16922/17352 (98%)] Loss: -927.614189\n",
      "    epoch          : 714\n",
      "    loss           : -925.250617542927\n",
      "    val_loss       : -751.2377441924541\n",
      "    val_log_likelihood: 1231.4667239645678\n",
      "    val_log_marginal: 766.3210147967552\n",
      "Train Epoch: 715 [512/17352 (3%)] Loss: -808.375977\n",
      "Train Epoch: 715 [10010/17352 (58%)] Loss: -964.319064\n",
      "Train Epoch: 715 [16923/17352 (98%)] Loss: -974.213896\n",
      "    epoch          : 715\n",
      "    loss           : -926.5451705210313\n",
      "    val_loss       : -677.9789721635493\n",
      "    val_log_likelihood: 1216.9104982296483\n",
      "    val_log_marginal: 704.1914782435466\n",
      "Train Epoch: 716 [512/17352 (3%)] Loss: -917.747253\n",
      "Train Epoch: 716 [10162/17352 (59%)] Loss: -751.474866\n",
      "Train Epoch: 716 [16923/17352 (98%)] Loss: -957.906486\n",
      "    epoch          : 716\n",
      "    loss           : -912.1376635449167\n",
      "    val_loss       : -743.7475905002834\n",
      "    val_log_likelihood: 1240.6273081885583\n",
      "    val_log_marginal: 765.5653899023306\n",
      "Train Epoch: 717 [512/17352 (3%)] Loss: -981.184509\n",
      "Train Epoch: 717 [10361/17352 (60%)] Loss: -908.330558\n",
      "Train Epoch: 717 [17044/17352 (98%)] Loss: -994.610210\n",
      "    epoch          : 717\n",
      "    loss           : -938.888338942757\n",
      "    val_loss       : -745.9663680847871\n",
      "    val_log_likelihood: 1239.6881856019315\n",
      "    val_log_marginal: 760.7102655207732\n",
      "Train Epoch: 718 [512/17352 (3%)] Loss: -981.591064\n",
      "Train Epoch: 718 [9768/17352 (56%)] Loss: -870.426946\n",
      "Train Epoch: 718 [17108/17352 (99%)] Loss: -1038.628405\n",
      "    epoch          : 718\n",
      "    loss           : -941.3871066336013\n",
      "    val_loss       : -725.1344357808869\n",
      "    val_log_likelihood: 1235.5644495388303\n",
      "    val_log_marginal: 745.6767199465027\n",
      "Train Epoch: 719 [512/17352 (3%)] Loss: -952.776611\n",
      "Train Epoch: 719 [10219/17352 (59%)] Loss: -931.803977\n",
      "Train Epoch: 719 [17153/17352 (99%)] Loss: -1017.606915\n",
      "    epoch          : 719\n",
      "    loss           : -909.8122148305151\n",
      "    val_loss       : -692.4581946240818\n",
      "    val_log_likelihood: 1218.7247292375378\n",
      "    val_log_marginal: 706.9941899918686\n",
      "Train Epoch: 720 [512/17352 (3%)] Loss: -741.399658\n",
      "Train Epoch: 720 [10886/17352 (63%)] Loss: -1054.259928\n",
      "Train Epoch: 720 [17090/17352 (98%)] Loss: -875.537574\n",
      "    epoch          : 720\n",
      "    loss           : -928.4919834788266\n",
      "    val_loss       : -716.5944120506205\n",
      "    val_log_likelihood: 1247.9423590137121\n",
      "    val_log_marginal: 735.5923941332045\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch720.pth ...\n",
      "Train Epoch: 721 [512/17352 (3%)] Loss: -942.117798\n",
      "Train Epoch: 721 [10546/17352 (61%)] Loss: -878.542911\n",
      "Train Epoch: 721 [16922/17352 (98%)] Loss: -767.426075\n",
      "    epoch          : 721\n",
      "    loss           : -938.2497807991992\n",
      "    val_loss       : -723.6716278011412\n",
      "    val_log_likelihood: 1241.0914505542817\n",
      "    val_log_marginal: 741.3637275641361\n",
      "Train Epoch: 722 [512/17352 (3%)] Loss: -989.252136\n",
      "Train Epoch: 722 [10496/17352 (60%)] Loss: -797.340972\n",
      "Train Epoch: 722 [16988/17352 (98%)] Loss: -750.688322\n",
      "    epoch          : 722\n",
      "    loss           : -901.6706083417657\n",
      "    val_loss       : -698.9222898239193\n",
      "    val_log_likelihood: 1220.1190144743834\n",
      "    val_log_marginal: 731.2882763496551\n",
      "Train Epoch: 723 [512/17352 (3%)] Loss: -926.180786\n",
      "Train Epoch: 723 [10557/17352 (61%)] Loss: -816.477647\n",
      "Train Epoch: 723 [17108/17352 (99%)] Loss: -892.572452\n",
      "    epoch          : 723\n",
      "    loss           : -916.4058606147785\n",
      "    val_loss       : -658.2653402112876\n",
      "    val_log_likelihood: 1188.909775698308\n",
      "    val_log_marginal: 687.7445778631401\n",
      "Train Epoch: 724 [512/17352 (3%)] Loss: -948.380859\n",
      "Train Epoch: 724 [10917/17352 (63%)] Loss: -830.475818\n",
      "Train Epoch: 724 [16939/17352 (98%)] Loss: -781.532035\n",
      "    epoch          : 724\n",
      "    loss           : -853.3837664202179\n",
      "    val_loss       : -559.1922235046493\n",
      "    val_log_likelihood: 1149.061244231657\n",
      "    val_log_marginal: 638.5403696431425\n",
      "Train Epoch: 725 [512/17352 (3%)] Loss: -901.156128\n",
      "Train Epoch: 725 [10140/17352 (58%)] Loss: -538.538108\n",
      "Train Epoch: 725 [16883/17352 (97%)] Loss: -282.652589\n",
      "    epoch          : 725\n",
      "    loss           : -545.7456757070728\n",
      "    val_loss       : -421.3418969679197\n",
      "    val_log_likelihood: 1002.6199864550524\n",
      "    val_log_marginal: 483.0414335632495\n",
      "Train Epoch: 726 [512/17352 (3%)] Loss: -369.433319\n",
      "Train Epoch: 726 [10304/17352 (59%)] Loss: -707.995921\n",
      "Train Epoch: 726 [16988/17352 (98%)] Loss: -885.421718\n",
      "    epoch          : 726\n",
      "    loss           : -764.6412427431565\n",
      "    val_loss       : -611.4140413246084\n",
      "    val_log_likelihood: 1175.0459770280586\n",
      "    val_log_marginal: 654.3391530774171\n",
      "Train Epoch: 727 [512/17352 (3%)] Loss: -857.496704\n",
      "Train Epoch: 727 [10374/17352 (60%)] Loss: -924.034312\n",
      "Train Epoch: 727 [16992/17352 (98%)] Loss: -915.385512\n",
      "    epoch          : 727\n",
      "    loss           : -848.1320235126477\n",
      "    val_loss       : -707.3827255039367\n",
      "    val_log_likelihood: 1197.14805315481\n",
      "    val_log_marginal: 733.4590495814548\n",
      "Train Epoch: 728 [512/17352 (3%)] Loss: -928.127441\n",
      "Train Epoch: 728 [9927/17352 (57%)] Loss: -918.623430\n",
      "Train Epoch: 728 [16887/17352 (97%)] Loss: -767.258373\n",
      "    epoch          : 728\n",
      "    loss           : -901.9360137055772\n",
      "    val_loss       : -719.8183591598357\n",
      "    val_log_likelihood: 1211.70873309032\n",
      "    val_log_marginal: 747.5904138700199\n",
      "Train Epoch: 729 [512/17352 (3%)] Loss: -948.325745\n",
      "Train Epoch: 729 [9875/17352 (57%)] Loss: -832.620060\n",
      "Train Epoch: 729 [17253/17352 (99%)] Loss: -728.938634\n",
      "    epoch          : 729\n",
      "    loss           : -920.2230572797542\n",
      "    val_loss       : -717.745108073913\n",
      "    val_log_likelihood: 1212.2049159305234\n",
      "    val_log_marginal: 747.557458267164\n",
      "Train Epoch: 730 [512/17352 (3%)] Loss: -956.447632\n",
      "Train Epoch: 730 [10410/17352 (60%)] Loss: -902.801991\n",
      "Train Epoch: 730 [16923/17352 (98%)] Loss: -911.273986\n",
      "    epoch          : 730\n",
      "    loss           : -918.7138669271744\n",
      "    val_loss       : -741.5883104686407\n",
      "    val_log_likelihood: 1221.908456810755\n",
      "    val_log_marginal: 761.8929543904769\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch730.pth ...\n",
      "Train Epoch: 731 [512/17352 (3%)] Loss: -948.997009\n",
      "Train Epoch: 731 [10465/17352 (60%)] Loss: -956.915668\n",
      "Train Epoch: 731 [17277/17352 (100%)] Loss: -1017.060680\n",
      "    epoch          : 731\n",
      "    loss           : -905.5819686269597\n",
      "    val_loss       : -721.7446268039498\n",
      "    val_log_likelihood: 1219.126318296912\n",
      "    val_log_marginal: 750.7270587078474\n",
      "Train Epoch: 732 [512/17352 (3%)] Loss: -954.025696\n",
      "Train Epoch: 732 [10484/17352 (60%)] Loss: -1008.331536\n",
      "Train Epoch: 732 [17049/17352 (98%)] Loss: -940.162642\n",
      "    epoch          : 732\n",
      "    loss           : -918.9055594482691\n",
      "    val_loss       : -714.6733577976116\n",
      "    val_log_likelihood: 1220.4950620391476\n",
      "    val_log_marginal: 728.5109054670419\n",
      "Train Epoch: 733 [512/17352 (3%)] Loss: -948.317078\n",
      "Train Epoch: 733 [10613/17352 (61%)] Loss: -1004.587292\n",
      "Train Epoch: 733 [17143/17352 (99%)] Loss: -921.725184\n",
      "    epoch          : 733\n",
      "    loss           : -905.3611785384743\n",
      "    val_loss       : -715.4052748490849\n",
      "    val_log_likelihood: 1212.8448185033812\n",
      "    val_log_marginal: 732.8782231598142\n",
      "Train Epoch: 734 [512/17352 (3%)] Loss: -966.243469\n",
      "Train Epoch: 734 [10590/17352 (61%)] Loss: -875.574566\n",
      "Train Epoch: 734 [17124/17352 (99%)] Loss: -911.552849\n",
      "    epoch          : 734\n",
      "    loss           : -902.6069495030166\n",
      "    val_loss       : -686.7669127381337\n",
      "    val_log_likelihood: 1176.9164897997655\n",
      "    val_log_marginal: 712.3834300032731\n",
      "Train Epoch: 735 [512/17352 (3%)] Loss: -904.182251\n",
      "Train Epoch: 735 [10872/17352 (63%)] Loss: -864.938753\n",
      "Train Epoch: 735 [17153/17352 (99%)] Loss: -1022.267420\n",
      "    epoch          : 735\n",
      "    loss           : -898.4722717127871\n",
      "    val_loss       : -714.3656501326684\n",
      "    val_log_likelihood: 1222.8744297558976\n",
      "    val_log_marginal: 743.5742436583268\n",
      "Train Epoch: 736 [512/17352 (3%)] Loss: -954.046021\n",
      "Train Epoch: 736 [10380/17352 (60%)] Loss: -1054.482748\n",
      "Train Epoch: 736 [16872/17352 (97%)] Loss: -913.395079\n",
      "    epoch          : 736\n",
      "    loss           : -930.1405588789974\n",
      "    val_loss       : -749.0386866402437\n",
      "    val_log_likelihood: 1237.195797352917\n",
      "    val_log_marginal: 766.892905186568\n",
      "Train Epoch: 737 [512/17352 (3%)] Loss: -985.531250\n",
      "Train Epoch: 737 [10253/17352 (59%)] Loss: -1058.768235\n",
      "Train Epoch: 737 [17153/17352 (99%)] Loss: -1017.879826\n",
      "    epoch          : 737\n",
      "    loss           : -938.4941978796886\n",
      "    val_loss       : -733.896851847376\n",
      "    val_log_likelihood: 1214.8930059880033\n",
      "    val_log_marginal: 749.7767004277772\n",
      "Train Epoch: 738 [512/17352 (3%)] Loss: -960.884277\n",
      "Train Epoch: 738 [9875/17352 (57%)] Loss: -943.348044\n",
      "Train Epoch: 738 [16988/17352 (98%)] Loss: -983.906641\n",
      "    epoch          : 738\n",
      "    loss           : -935.2968981881103\n",
      "    val_loss       : -739.9999879120842\n",
      "    val_log_likelihood: 1231.680831223264\n",
      "    val_log_marginal: 764.1602519890785\n",
      "Train Epoch: 739 [512/17352 (3%)] Loss: -965.021423\n",
      "Train Epoch: 739 [10652/17352 (61%)] Loss: -843.612977\n",
      "Train Epoch: 739 [17064/17352 (98%)] Loss: -749.582312\n",
      "    epoch          : 739\n",
      "    loss           : -927.79536693353\n",
      "    val_loss       : -711.3632251853338\n",
      "    val_log_likelihood: 1225.2866526508985\n",
      "    val_log_marginal: 755.1236652079893\n",
      "Train Epoch: 740 [512/17352 (3%)] Loss: -989.855591\n",
      "Train Epoch: 740 [10446/17352 (60%)] Loss: -1069.903212\n",
      "Train Epoch: 740 [16934/17352 (98%)] Loss: -894.272653\n",
      "    epoch          : 740\n",
      "    loss           : -918.4568243349038\n",
      "    val_loss       : -688.3145407666493\n",
      "    val_log_likelihood: 1221.4685798197213\n",
      "    val_log_marginal: 753.9817746409682\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch740.pth ...\n",
      "Train Epoch: 741 [512/17352 (3%)] Loss: -972.990967\n",
      "Train Epoch: 741 [10571/17352 (61%)] Loss: -1003.189483\n",
      "Train Epoch: 741 [17064/17352 (98%)] Loss: -853.698056\n",
      "    epoch          : 741\n",
      "    loss           : -867.2215639225125\n",
      "    val_loss       : -652.4262994827816\n",
      "    val_log_likelihood: 1165.8187283437433\n",
      "    val_log_marginal: 682.3160357673538\n",
      "Train Epoch: 742 [512/17352 (3%)] Loss: -890.740356\n",
      "Train Epoch: 742 [10352/17352 (60%)] Loss: -966.635904\n",
      "Train Epoch: 742 [16939/17352 (98%)] Loss: -816.320609\n",
      "    epoch          : 742\n",
      "    loss           : -877.0158390691012\n",
      "    val_loss       : -685.016026102829\n",
      "    val_log_likelihood: 1207.682073564196\n",
      "    val_log_marginal: 721.2153478568329\n",
      "Train Epoch: 743 [512/17352 (3%)] Loss: -935.017822\n",
      "Train Epoch: 743 [10640/17352 (61%)] Loss: -763.250150\n",
      "Train Epoch: 743 [17263/17352 (99%)] Loss: -816.785528\n",
      "    epoch          : 743\n",
      "    loss           : -885.7360823133009\n",
      "    val_loss       : -716.581975336502\n",
      "    val_log_likelihood: 1220.9930519874663\n",
      "    val_log_marginal: 744.8212628840104\n",
      "Train Epoch: 744 [512/17352 (3%)] Loss: -739.326233\n",
      "Train Epoch: 744 [10105/17352 (58%)] Loss: -856.319623\n",
      "Train Epoch: 744 [16922/17352 (98%)] Loss: -835.158110\n",
      "    epoch          : 744\n",
      "    loss           : -912.3274000904701\n",
      "    val_loss       : -715.4474612978706\n",
      "    val_log_likelihood: 1221.4243887070604\n",
      "    val_log_marginal: 737.7613984672018\n",
      "Train Epoch: 745 [512/17352 (3%)] Loss: -979.673889\n",
      "Train Epoch: 745 [10709/17352 (62%)] Loss: -996.973803\n",
      "Train Epoch: 745 [17108/17352 (99%)] Loss: -846.039012\n",
      "    epoch          : 745\n",
      "    loss           : -924.0069452400409\n",
      "    val_loss       : -742.0824830525609\n",
      "    val_log_likelihood: 1237.3372217848355\n",
      "    val_log_marginal: 762.3183165199974\n",
      "Train Epoch: 746 [512/17352 (3%)] Loss: -979.522827\n",
      "Train Epoch: 746 [10281/17352 (59%)] Loss: -869.385153\n",
      "Train Epoch: 746 [17049/17352 (98%)] Loss: -981.331478\n",
      "    epoch          : 746\n",
      "    loss           : -947.0119969807023\n",
      "    val_loss       : -763.3028257968674\n",
      "    val_log_likelihood: 1244.3875591375377\n",
      "    val_log_marginal: 775.8924341134054\n",
      "Train Epoch: 747 [512/17352 (3%)] Loss: -1000.535522\n",
      "Train Epoch: 747 [10034/17352 (58%)] Loss: -864.842938\n",
      "Train Epoch: 747 [16988/17352 (98%)] Loss: -1044.033182\n",
      "    epoch          : 747\n",
      "    loss           : -955.4455995712634\n",
      "    val_loss       : -747.7693918322223\n",
      "    val_log_likelihood: 1235.5506552828938\n",
      "    val_log_marginal: 765.5110726175848\n",
      "Train Epoch: 748 [512/17352 (3%)] Loss: -996.735596\n",
      "Train Epoch: 748 [10803/17352 (62%)] Loss: -1044.823101\n",
      "Train Epoch: 748 [16992/17352 (98%)] Loss: -918.654619\n",
      "    epoch          : 748\n",
      "    loss           : -943.217468254907\n",
      "    val_loss       : -723.7306244171415\n",
      "    val_log_likelihood: 1226.932934546613\n",
      "    val_log_marginal: 745.8881661643969\n",
      "Train Epoch: 749 [512/17352 (3%)] Loss: -951.069885\n",
      "Train Epoch: 749 [10234/17352 (59%)] Loss: -949.264520\n",
      "Train Epoch: 749 [17143/17352 (99%)] Loss: -1007.507906\n",
      "    epoch          : 749\n",
      "    loss           : -947.5424963307615\n",
      "    val_loss       : -720.8975616971305\n",
      "    val_log_likelihood: 1231.1371538317394\n",
      "    val_log_marginal: 745.6041126221329\n",
      "Train Epoch: 750 [512/17352 (3%)] Loss: -1002.540649\n",
      "Train Epoch: 750 [10315/17352 (59%)] Loss: -1014.866010\n",
      "Train Epoch: 750 [16883/17352 (97%)] Loss: -808.132258\n",
      "    epoch          : 750\n",
      "    loss           : -953.5470817137744\n",
      "    val_loss       : -768.4364313740278\n",
      "    val_log_likelihood: 1252.801072505244\n",
      "    val_log_marginal: 784.7073377521972\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch750.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 751 [512/17352 (3%)] Loss: -993.297729\n",
      "Train Epoch: 751 [10235/17352 (59%)] Loss: -987.625125\n",
      "Train Epoch: 751 [16878/17352 (97%)] Loss: -806.495047\n",
      "    epoch          : 751\n",
      "    loss           : -952.0479430519449\n",
      "    val_loss       : -748.4323572347439\n",
      "    val_log_likelihood: 1254.4991504223676\n",
      "    val_log_marginal: 766.0981647882272\n",
      "Train Epoch: 752 [512/17352 (3%)] Loss: -1004.357300\n",
      "Train Epoch: 752 [10259/17352 (59%)] Loss: -1017.300436\n",
      "Train Epoch: 752 [17124/17352 (99%)] Loss: -1003.235833\n",
      "    epoch          : 752\n",
      "    loss           : -941.8579175112899\n",
      "    val_loss       : -640.7740732120087\n",
      "    val_log_likelihood: 1198.5532455219118\n",
      "    val_log_marginal: 659.0842783872592\n",
      "Train Epoch: 753 [512/17352 (3%)] Loss: -904.101135\n",
      "Train Epoch: 753 [10045/17352 (58%)] Loss: -883.546219\n",
      "Train Epoch: 753 [17064/17352 (98%)] Loss: -852.439560\n",
      "    epoch          : 753\n",
      "    loss           : -889.5272936957573\n",
      "    val_loss       : -710.9251042750418\n",
      "    val_log_likelihood: 1218.108132522172\n",
      "    val_log_marginal: 734.9186758868577\n",
      "Train Epoch: 754 [512/17352 (3%)] Loss: -956.836487\n",
      "Train Epoch: 754 [10683/17352 (62%)] Loss: -1045.568034\n",
      "Train Epoch: 754 [17335/17352 (100%)] Loss: -710.905502\n",
      "    epoch          : 754\n",
      "    loss           : -928.7765343615857\n",
      "    val_loss       : -698.3785915001419\n",
      "    val_log_likelihood: 1232.8370039178442\n",
      "    val_log_marginal: 719.7049057260792\n",
      "Train Epoch: 755 [512/17352 (3%)] Loss: -923.218506\n",
      "Train Epoch: 755 [10691/17352 (62%)] Loss: -875.728420\n",
      "Train Epoch: 755 [17335/17352 (100%)] Loss: -881.174842\n",
      "    epoch          : 755\n",
      "    loss           : -939.859952711419\n",
      "    val_loss       : -731.9341954715214\n",
      "    val_log_likelihood: 1244.072574916575\n",
      "    val_log_marginal: 747.8968217045103\n",
      "Train Epoch: 756 [512/17352 (3%)] Loss: -975.955200\n",
      "Train Epoch: 756 [10451/17352 (60%)] Loss: -1050.161966\n",
      "Train Epoch: 756 [17124/17352 (99%)] Loss: -1059.154080\n",
      "    epoch          : 756\n",
      "    loss           : -937.4645566815599\n",
      "    val_loss       : -728.1417717834812\n",
      "    val_log_likelihood: 1239.9055500418012\n",
      "    val_log_marginal: 749.3686912703158\n",
      "Train Epoch: 757 [512/17352 (3%)] Loss: -919.169495\n",
      "Train Epoch: 757 [10494/17352 (60%)] Loss: -998.012450\n",
      "Train Epoch: 757 [17124/17352 (99%)] Loss: -1014.010104\n",
      "    epoch          : 757\n",
      "    loss           : -944.0393343231945\n",
      "    val_loss       : -752.7159705972638\n",
      "    val_log_likelihood: 1247.7688675182467\n",
      "    val_log_marginal: 772.9390605641561\n",
      "Train Epoch: 758 [512/17352 (3%)] Loss: -993.753418\n",
      "Train Epoch: 758 [10054/17352 (58%)] Loss: -1039.971685\n",
      "Train Epoch: 758 [17064/17352 (98%)] Loss: -1003.405417\n",
      "    epoch          : 758\n",
      "    loss           : -953.9267054079273\n",
      "    val_loss       : -734.4849006667354\n",
      "    val_log_likelihood: 1234.5328904862367\n",
      "    val_log_marginal: 749.4246229434171\n",
      "Train Epoch: 759 [512/17352 (3%)] Loss: -988.782654\n",
      "Train Epoch: 759 [11018/17352 (63%)] Loss: -999.159300\n",
      "Train Epoch: 759 [16992/17352 (98%)] Loss: -765.612521\n",
      "    epoch          : 759\n",
      "    loss           : -929.8156464279774\n",
      "    val_loss       : -714.242546137239\n",
      "    val_log_likelihood: 1248.9266128264046\n",
      "    val_log_marginal: 728.5849888616601\n",
      "Train Epoch: 760 [512/17352 (3%)] Loss: -967.666565\n",
      "Train Epoch: 760 [10333/17352 (60%)] Loss: -983.801042\n",
      "Train Epoch: 760 [16957/17352 (98%)] Loss: -888.139152\n",
      "    epoch          : 760\n",
      "    loss           : -951.5801420193371\n",
      "    val_loss       : -762.1752680808913\n",
      "    val_log_likelihood: 1256.8824912701523\n",
      "    val_log_marginal: 780.6211541754648\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch760.pth ...\n",
      "Train Epoch: 761 [512/17352 (3%)] Loss: -983.476257\n",
      "Train Epoch: 761 [10523/17352 (61%)] Loss: -1099.850260\n",
      "Train Epoch: 761 [16883/17352 (97%)] Loss: -944.185834\n",
      "    epoch          : 761\n",
      "    loss           : -945.0590875412373\n",
      "    val_loss       : -750.3901827518775\n",
      "    val_log_likelihood: 1250.4353055422944\n",
      "    val_log_marginal: 765.4187955437901\n",
      "Train Epoch: 762 [512/17352 (3%)] Loss: -1003.816650\n",
      "Train Epoch: 762 [10451/17352 (60%)] Loss: -802.751128\n",
      "Train Epoch: 762 [16957/17352 (98%)] Loss: -1015.847093\n",
      "    epoch          : 762\n",
      "    loss           : -940.6923036779444\n",
      "    val_loss       : -740.4221381851557\n",
      "    val_log_likelihood: 1251.8950142788392\n",
      "    val_log_marginal: 756.5278251096163\n",
      "Train Epoch: 763 [512/17352 (3%)] Loss: -1003.534180\n",
      "Train Epoch: 763 [10619/17352 (61%)] Loss: -854.395730\n",
      "Train Epoch: 763 [16882/17352 (97%)] Loss: -724.165348\n",
      "    epoch          : 763\n",
      "    loss           : -882.0941335825272\n",
      "    val_loss       : -350.916803017241\n",
      "    val_log_likelihood: 1206.6966074000488\n",
      "    val_log_marginal: 367.5768230341851\n",
      "Train Epoch: 764 [512/17352 (3%)] Loss: -449.847900\n",
      "Train Epoch: 764 [9939/17352 (57%)] Loss: -1061.120117\n",
      "Train Epoch: 764 [16957/17352 (98%)] Loss: -882.363089\n",
      "    epoch          : 764\n",
      "    loss           : -836.2349716454567\n",
      "    val_loss       : -685.799927946114\n",
      "    val_log_likelihood: 1215.2920346669932\n",
      "    val_log_marginal: 708.707340672901\n",
      "Train Epoch: 765 [512/17352 (3%)] Loss: -969.802917\n",
      "Train Epoch: 765 [9954/17352 (57%)] Loss: -872.328987\n",
      "Train Epoch: 765 [16939/17352 (98%)] Loss: -865.312240\n",
      "    epoch          : 765\n",
      "    loss           : -911.7775488386652\n",
      "    val_loss       : -723.2920190908377\n",
      "    val_log_likelihood: 1237.8928734427147\n",
      "    val_log_marginal: 751.1588696081942\n",
      "Train Epoch: 766 [512/17352 (3%)] Loss: -963.027710\n",
      "Train Epoch: 766 [10584/17352 (61%)] Loss: -870.488188\n",
      "Train Epoch: 766 [17090/17352 (98%)] Loss: -1024.357215\n",
      "    epoch          : 766\n",
      "    loss           : -932.922263427306\n",
      "    val_loss       : -740.3779568810063\n",
      "    val_log_likelihood: 1239.3434212955642\n",
      "    val_log_marginal: 757.1848912032973\n",
      "Train Epoch: 767 [512/17352 (3%)] Loss: -975.168884\n",
      "Train Epoch: 767 [10438/17352 (60%)] Loss: -1022.957602\n",
      "Train Epoch: 767 [17277/17352 (100%)] Loss: -820.270952\n",
      "    epoch          : 767\n",
      "    loss           : -941.3195660002424\n",
      "    val_loss       : -690.9781117943664\n",
      "    val_log_likelihood: 1229.7657697813509\n",
      "    val_log_marginal: 706.684101453254\n",
      "Train Epoch: 768 [512/17352 (3%)] Loss: -953.851257\n",
      "Train Epoch: 768 [10452/17352 (60%)] Loss: -1023.781962\n",
      "Train Epoch: 768 [16882/17352 (97%)] Loss: -904.351992\n",
      "    epoch          : 768\n",
      "    loss           : -934.4404807217927\n",
      "    val_loss       : -694.1438936788433\n",
      "    val_log_likelihood: 1246.3195546958536\n",
      "    val_log_marginal: 716.4727226949473\n",
      "Train Epoch: 769 [512/17352 (3%)] Loss: -952.790771\n",
      "Train Epoch: 769 [9955/17352 (57%)] Loss: -948.492741\n",
      "Train Epoch: 769 [17101/17352 (99%)] Loss: -995.857604\n",
      "    epoch          : 769\n",
      "    loss           : -908.8248550360687\n",
      "    val_loss       : -686.516087496405\n",
      "    val_log_likelihood: 1229.9573501027076\n",
      "    val_log_marginal: 705.8101372746147\n",
      "Train Epoch: 770 [512/17352 (3%)] Loss: -948.000671\n",
      "Train Epoch: 770 [9885/17352 (57%)] Loss: -968.730864\n",
      "Train Epoch: 770 [17106/17352 (99%)] Loss: -973.634275\n",
      "    epoch          : 770\n",
      "    loss           : -907.6111482010598\n",
      "    val_loss       : -687.2470812088127\n",
      "    val_log_likelihood: 1243.2758608319348\n",
      "    val_log_marginal: 709.8847484914646\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch770.pth ...\n",
      "Train Epoch: 771 [512/17352 (3%)] Loss: -944.921875\n",
      "Train Epoch: 771 [10791/17352 (62%)] Loss: -967.263984\n",
      "Train Epoch: 771 [16922/17352 (98%)] Loss: -925.968048\n",
      "    epoch          : 771\n",
      "    loss           : -911.9064330624162\n",
      "    val_loss       : -710.056858181272\n",
      "    val_log_likelihood: 1231.097891785864\n",
      "    val_log_marginal: 722.7410323136598\n",
      "Train Epoch: 772 [512/17352 (3%)] Loss: -984.474854\n",
      "Train Epoch: 772 [10726/17352 (62%)] Loss: -866.639931\n",
      "Train Epoch: 772 [17124/17352 (99%)] Loss: -14.112341\n",
      "    epoch          : 772\n",
      "    loss           : -726.0345334492672\n",
      "    val_loss       : -353.8242824577008\n",
      "    val_log_likelihood: 1157.1678355672786\n",
      "    val_log_marginal: 405.45858871216024\n",
      "Train Epoch: 773 [512/17352 (3%)] Loss: -577.526001\n",
      "Train Epoch: 773 [10474/17352 (60%)] Loss: -727.567191\n",
      "Train Epoch: 773 [17106/17352 (99%)] Loss: -812.786458\n",
      "    epoch          : 773\n",
      "    loss           : -601.5854905214667\n",
      "    val_loss       : -600.0564983252945\n",
      "    val_log_likelihood: 1172.883945503638\n",
      "    val_log_marginal: 625.9507757468988\n",
      "Train Epoch: 774 [512/17352 (3%)] Loss: -867.148376\n",
      "Train Epoch: 774 [10527/17352 (61%)] Loss: -810.211212\n",
      "Train Epoch: 774 [17253/17352 (99%)] Loss: -933.323547\n",
      "    epoch          : 774\n",
      "    loss           : -818.7739991168074\n",
      "    val_loss       : -645.8468911395936\n",
      "    val_log_likelihood: 1202.554306506902\n",
      "    val_log_marginal: 676.4393057046607\n",
      "Train Epoch: 775 [512/17352 (3%)] Loss: -867.621826\n",
      "Train Epoch: 775 [10617/17352 (61%)] Loss: -882.389768\n",
      "Train Epoch: 775 [17124/17352 (99%)] Loss: -1044.681725\n",
      "    epoch          : 775\n",
      "    loss           : -904.9031560637708\n",
      "    val_loss       : -515.6563045860875\n",
      "    val_log_likelihood: 1230.2302494717812\n",
      "    val_log_marginal: 535.772015797367\n",
      "Train Epoch: 776 [512/17352 (3%)] Loss: -759.947998\n",
      "Train Epoch: 776 [10894/17352 (63%)] Loss: -1018.513166\n",
      "Train Epoch: 776 [17277/17352 (100%)] Loss: -951.651594\n",
      "    epoch          : 776\n",
      "    loss           : -903.8759472175778\n",
      "    val_loss       : -727.4220319386616\n",
      "    val_log_likelihood: 1228.7195280526514\n",
      "    val_log_marginal: 746.3744249550138\n",
      "Train Epoch: 777 [512/17352 (3%)] Loss: -960.016663\n",
      "Train Epoch: 777 [10002/17352 (58%)] Loss: -1041.310722\n",
      "Train Epoch: 777 [16934/17352 (98%)] Loss: -1003.287386\n",
      "    epoch          : 777\n",
      "    loss           : -919.3965476230886\n",
      "    val_loss       : -735.3516056969056\n",
      "    val_log_likelihood: 1232.9384433596736\n",
      "    val_log_marginal: 757.782921822937\n",
      "Train Epoch: 778 [512/17352 (3%)] Loss: -938.130615\n",
      "Train Epoch: 778 [10747/17352 (62%)] Loss: -940.522272\n",
      "Train Epoch: 778 [16957/17352 (98%)] Loss: -920.012860\n",
      "    epoch          : 778\n",
      "    loss           : -932.6204089746934\n",
      "    val_loss       : -725.8088514715461\n",
      "    val_log_likelihood: 1239.550546788864\n",
      "    val_log_marginal: 746.2341700598046\n",
      "Train Epoch: 779 [512/17352 (3%)] Loss: -983.375671\n",
      "Train Epoch: 779 [9871/17352 (57%)] Loss: -839.999252\n",
      "Train Epoch: 779 [17153/17352 (99%)] Loss: -1050.960421\n",
      "    epoch          : 779\n",
      "    loss           : -938.7683544817221\n",
      "    val_loss       : -731.3659225646279\n",
      "    val_log_likelihood: 1247.3079956095717\n",
      "    val_log_marginal: 747.359963869544\n",
      "Train Epoch: 780 [512/17352 (3%)] Loss: -976.894531\n",
      "Train Epoch: 780 [9889/17352 (57%)] Loss: -1057.540027\n",
      "Train Epoch: 780 [16988/17352 (98%)] Loss: -1097.287760\n",
      "    epoch          : 780\n",
      "    loss           : -947.6836189958655\n",
      "    val_loss       : -748.9188530032972\n",
      "    val_log_likelihood: 1248.9862590858877\n",
      "    val_log_marginal: 768.1014056101662\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch780.pth ...\n",
      "Train Epoch: 781 [512/17352 (3%)] Loss: -1004.736572\n",
      "Train Epoch: 781 [10369/17352 (60%)] Loss: -1023.154758\n",
      "Train Epoch: 781 [17016/17352 (98%)] Loss: -1043.675712\n",
      "    epoch          : 781\n",
      "    loss           : -962.2394479068162\n",
      "    val_loss       : -760.9641263559552\n",
      "    val_log_likelihood: 1257.0292279831526\n",
      "    val_log_marginal: 779.5909738466728\n",
      "Train Epoch: 782 [512/17352 (3%)] Loss: -1009.931335\n",
      "Train Epoch: 782 [10599/17352 (61%)] Loss: -1103.720920\n",
      "Train Epoch: 782 [17049/17352 (98%)] Loss: -1003.728930\n",
      "    epoch          : 782\n",
      "    loss           : -963.1548378264557\n",
      "    val_loss       : -744.3634406013832\n",
      "    val_log_likelihood: 1254.2549062068244\n",
      "    val_log_marginal: 763.3571636053086\n",
      "Train Epoch: 783 [512/17352 (3%)] Loss: -1010.767822\n",
      "Train Epoch: 783 [10581/17352 (61%)] Loss: -995.901894\n",
      "Train Epoch: 783 [16883/17352 (97%)] Loss: -885.031944\n",
      "    epoch          : 783\n",
      "    loss           : -966.364606994275\n",
      "    val_loss       : -761.4357998594985\n",
      "    val_log_likelihood: 1266.3079209253444\n",
      "    val_log_marginal: 779.2164128283333\n",
      "Train Epoch: 784 [512/17352 (3%)] Loss: -824.244751\n",
      "Train Epoch: 784 [10111/17352 (58%)] Loss: -858.632775\n",
      "Train Epoch: 784 [16992/17352 (98%)] Loss: -1048.502690\n",
      "    epoch          : 784\n",
      "    loss           : -973.1208402383128\n",
      "    val_loss       : -767.1212711676621\n",
      "    val_log_likelihood: 1264.480120381594\n",
      "    val_log_marginal: 786.2312701257312\n",
      "Train Epoch: 785 [512/17352 (3%)] Loss: -1034.882690\n",
      "Train Epoch: 785 [9887/17352 (57%)] Loss: -995.650304\n",
      "Train Epoch: 785 [16923/17352 (98%)] Loss: -734.966790\n",
      "    epoch          : 785\n",
      "    loss           : -955.055361768909\n",
      "    val_loss       : -723.2031519440852\n",
      "    val_log_likelihood: 1237.355502674528\n",
      "    val_log_marginal: 746.8721198553609\n",
      "Train Epoch: 786 [512/17352 (3%)] Loss: -961.328796\n",
      "Train Epoch: 786 [9897/17352 (57%)] Loss: -767.647741\n",
      "Train Epoch: 786 [17108/17352 (99%)] Loss: -893.428194\n",
      "    epoch          : 786\n",
      "    loss           : -943.3421374437457\n",
      "    val_loss       : -734.4090910552487\n",
      "    val_log_likelihood: 1248.899060352133\n",
      "    val_log_marginal: 752.2864445302434\n",
      "Train Epoch: 787 [512/17352 (3%)] Loss: -976.622925\n",
      "Train Epoch: 787 [9965/17352 (57%)] Loss: -1061.666857\n",
      "Train Epoch: 787 [16883/17352 (97%)] Loss: -989.865690\n",
      "    epoch          : 787\n",
      "    loss           : -962.59547418558\n",
      "    val_loss       : -750.5706491347732\n",
      "    val_log_likelihood: 1265.600977984553\n",
      "    val_log_marginal: 765.4137039171995\n",
      "Train Epoch: 788 [512/17352 (3%)] Loss: -1009.849670\n",
      "Train Epoch: 788 [10394/17352 (60%)] Loss: -892.106771\n",
      "Train Epoch: 788 [17143/17352 (99%)] Loss: -1038.256145\n",
      "    epoch          : 788\n",
      "    loss           : -967.4771233544149\n",
      "    val_loss       : -755.0330747565948\n",
      "    val_log_likelihood: 1265.979822581907\n",
      "    val_log_marginal: 770.7065478567831\n",
      "Train Epoch: 789 [512/17352 (3%)] Loss: -1014.205811\n",
      "Train Epoch: 789 [10847/17352 (63%)] Loss: -1012.067685\n",
      "Train Epoch: 789 [17106/17352 (99%)] Loss: -829.080929\n",
      "    epoch          : 789\n",
      "    loss           : -971.8777875267116\n",
      "    val_loss       : -757.2184604499527\n",
      "    val_log_likelihood: 1265.2386948260482\n",
      "    val_log_marginal: 773.2052627312552\n",
      "Train Epoch: 790 [512/17352 (3%)] Loss: -1013.766174\n",
      "Train Epoch: 790 [10321/17352 (59%)] Loss: -945.224502\n",
      "Train Epoch: 790 [17044/17352 (98%)] Loss: -1061.120203\n",
      "    epoch          : 790\n",
      "    loss           : -966.1381921879912\n",
      "    val_loss       : -703.1217473911414\n",
      "    val_log_likelihood: 1256.9424587234023\n",
      "    val_log_marginal: 726.8595693302451\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch790.pth ...\n",
      "Train Epoch: 791 [512/17352 (3%)] Loss: -975.519653\n",
      "Train Epoch: 791 [10347/17352 (60%)] Loss: -944.946126\n",
      "Train Epoch: 791 [17101/17352 (99%)] Loss: -727.639766\n",
      "    epoch          : 791\n",
      "    loss           : -799.1868391578143\n",
      "    val_loss       : -484.5743976317857\n",
      "    val_log_likelihood: 1093.5435315138807\n",
      "    val_log_marginal: 545.0539801285804\n",
      "Train Epoch: 792 [512/17352 (3%)] Loss: -855.700806\n",
      "Train Epoch: 792 [10410/17352 (60%)] Loss: -795.752790\n",
      "Train Epoch: 792 [17253/17352 (99%)] Loss: -914.934409\n",
      "    epoch          : 792\n",
      "    loss           : -889.2391994525362\n",
      "    val_loss       : -688.8499030778686\n",
      "    val_log_likelihood: 1218.0848757649778\n",
      "    val_log_marginal: 724.9655750805882\n",
      "Train Epoch: 793 [512/17352 (3%)] Loss: -951.633301\n",
      "Train Epoch: 793 [10721/17352 (62%)] Loss: -847.521577\n",
      "Train Epoch: 793 [16934/17352 (98%)] Loss: -999.169141\n",
      "    epoch          : 793\n",
      "    loss           : -937.1028029408513\n",
      "    val_loss       : -725.402680119131\n",
      "    val_log_likelihood: 1245.4431951279485\n",
      "    val_log_marginal: 753.5172156526993\n",
      "Train Epoch: 794 [512/17352 (3%)] Loss: -1000.097595\n",
      "Train Epoch: 794 [10314/17352 (59%)] Loss: -1011.152037\n",
      "Train Epoch: 794 [16887/17352 (97%)] Loss: -877.814225\n",
      "    epoch          : 794\n",
      "    loss           : -961.8875675084456\n",
      "    val_loss       : -747.4595176619422\n",
      "    val_log_likelihood: 1258.1234844298397\n",
      "    val_log_marginal: 767.5855706342174\n",
      "Train Epoch: 795 [512/17352 (3%)] Loss: -1011.198364\n",
      "Train Epoch: 795 [9883/17352 (57%)] Loss: -1009.643426\n",
      "Train Epoch: 795 [17106/17352 (99%)] Loss: -830.016437\n",
      "    epoch          : 795\n",
      "    loss           : -955.0885174936209\n",
      "    val_loss       : -738.4710574215709\n",
      "    val_log_likelihood: 1246.8426917405986\n",
      "    val_log_marginal: 759.3112499842067\n",
      "Train Epoch: 796 [512/17352 (3%)] Loss: -994.664368\n",
      "Train Epoch: 796 [9896/17352 (57%)] Loss: -930.534234\n",
      "Train Epoch: 796 [17106/17352 (99%)] Loss: -933.822888\n",
      "    epoch          : 796\n",
      "    loss           : -931.1316700533438\n",
      "    val_loss       : -704.5988573432267\n",
      "    val_log_likelihood: 1251.9930894191182\n",
      "    val_log_marginal: 726.7057029435158\n",
      "Train Epoch: 797 [512/17352 (3%)] Loss: -950.332642\n",
      "Train Epoch: 797 [10358/17352 (60%)] Loss: -813.185953\n",
      "Train Epoch: 797 [16934/17352 (98%)] Loss: -912.527344\n",
      "    epoch          : 797\n",
      "    loss           : -942.4751993859527\n",
      "    val_loss       : -746.4184837312685\n",
      "    val_log_likelihood: 1261.8814754473399\n",
      "    val_log_marginal: 768.4619161533086\n",
      "Train Epoch: 798 [512/17352 (3%)] Loss: -997.493530\n",
      "Train Epoch: 798 [10360/17352 (60%)] Loss: -950.172560\n",
      "Train Epoch: 798 [17277/17352 (100%)] Loss: -981.645450\n",
      "    epoch          : 798\n",
      "    loss           : -955.0636862496962\n",
      "    val_loss       : -691.9753674672804\n",
      "    val_log_likelihood: 1249.7191613018258\n",
      "    val_log_marginal: 713.8809318686763\n",
      "Train Epoch: 799 [512/17352 (3%)] Loss: -957.570129\n",
      "Train Epoch: 799 [10268/17352 (59%)] Loss: -983.720506\n",
      "Train Epoch: 799 [17064/17352 (98%)] Loss: -975.008049\n",
      "    epoch          : 799\n",
      "    loss           : -942.8301971058814\n",
      "    val_loss       : -739.902179876405\n",
      "    val_log_likelihood: 1251.3932390995976\n",
      "    val_log_marginal: 761.6345536768564\n",
      "Train Epoch: 800 [512/17352 (3%)] Loss: -1004.886292\n",
      "Train Epoch: 800 [10416/17352 (60%)] Loss: -929.268115\n",
      "Train Epoch: 800 [17090/17352 (98%)] Loss: -783.688515\n",
      "    epoch          : 800\n",
      "    loss           : -936.5398334072601\n",
      "    val_loss       : -729.1375270299271\n",
      "    val_log_likelihood: 1251.0388006278595\n",
      "    val_log_marginal: 746.4225686256465\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch800.pth ...\n",
      "Train Epoch: 801 [512/17352 (3%)] Loss: -962.635498\n",
      "Train Epoch: 801 [10029/17352 (58%)] Loss: -917.583612\n",
      "Train Epoch: 801 [17016/17352 (98%)] Loss: -977.563260\n",
      "    epoch          : 801\n",
      "    loss           : -918.2333554405373\n",
      "    val_loss       : -677.7657238230732\n",
      "    val_log_likelihood: 1247.0744203380102\n",
      "    val_log_marginal: 710.1006963355675\n",
      "Train Epoch: 802 [512/17352 (3%)] Loss: -968.132629\n",
      "Train Epoch: 802 [10557/17352 (61%)] Loss: -933.889611\n",
      "Train Epoch: 802 [16923/17352 (98%)] Loss: -1059.360312\n",
      "    epoch          : 802\n",
      "    loss           : -900.8994461360894\n",
      "    val_loss       : -709.2153285028472\n",
      "    val_log_likelihood: 1232.607305024747\n",
      "    val_log_marginal: 737.8885059395661\n",
      "Train Epoch: 803 [512/17352 (3%)] Loss: -969.033020\n",
      "Train Epoch: 803 [10409/17352 (60%)] Loss: -999.415417\n",
      "Train Epoch: 803 [17126/17352 (99%)] Loss: -827.956647\n",
      "    epoch          : 803\n",
      "    loss           : -930.2723156443038\n",
      "    val_loss       : -740.1039385505536\n",
      "    val_log_likelihood: 1258.2287411706438\n",
      "    val_log_marginal: 761.560135444569\n",
      "Train Epoch: 804 [512/17352 (3%)] Loss: -1012.950867\n",
      "Train Epoch: 804 [10745/17352 (62%)] Loss: -1051.735674\n",
      "Train Epoch: 804 [17143/17352 (99%)] Loss: -928.097833\n",
      "    epoch          : 804\n",
      "    loss           : -945.4410536225109\n",
      "    val_loss       : -729.1116341479008\n",
      "    val_log_likelihood: 1264.3353980040079\n",
      "    val_log_marginal: 747.324620505038\n",
      "Train Epoch: 805 [512/17352 (3%)] Loss: -993.446228\n",
      "Train Epoch: 805 [10515/17352 (61%)] Loss: -945.272613\n",
      "Train Epoch: 805 [16957/17352 (98%)] Loss: -868.600192\n",
      "    epoch          : 805\n",
      "    loss           : -908.928647592081\n",
      "    val_loss       : -717.8614616861969\n",
      "    val_log_likelihood: 1235.4498694185431\n",
      "    val_log_marginal: 743.7418781007705\n",
      "Train Epoch: 806 [512/17352 (3%)] Loss: -963.946045\n",
      "Train Epoch: 806 [10264/17352 (59%)] Loss: -1017.360674\n",
      "Train Epoch: 806 [16992/17352 (98%)] Loss: -993.145703\n",
      "    epoch          : 806\n",
      "    loss           : -918.9930346875063\n",
      "    val_loss       : -685.3595642735316\n",
      "    val_log_likelihood: 1222.235686194639\n",
      "    val_log_marginal: 707.336400964314\n",
      "Train Epoch: 807 [512/17352 (3%)] Loss: -949.781738\n",
      "Train Epoch: 807 [10391/17352 (60%)] Loss: -969.598640\n",
      "Train Epoch: 807 [17277/17352 (100%)] Loss: -826.639903\n",
      "    epoch          : 807\n",
      "    loss           : -953.3920119561762\n",
      "    val_loss       : -746.3111163680975\n",
      "    val_log_likelihood: 1257.5824349286358\n",
      "    val_log_marginal: 772.4038923749097\n",
      "Train Epoch: 808 [512/17352 (3%)] Loss: -1013.329773\n",
      "Train Epoch: 808 [10126/17352 (58%)] Loss: -1091.032012\n",
      "Train Epoch: 808 [16939/17352 (98%)] Loss: -1010.735417\n",
      "    epoch          : 808\n",
      "    loss           : -975.5005102686927\n",
      "    val_loss       : -742.1925337294637\n",
      "    val_log_likelihood: 1265.8208333570985\n",
      "    val_log_marginal: 755.9188748613676\n",
      "Train Epoch: 809 [512/17352 (3%)] Loss: -996.306274\n",
      "Train Epoch: 809 [10158/17352 (59%)] Loss: -854.528045\n",
      "Train Epoch: 809 [16992/17352 (98%)] Loss: -1030.851916\n",
      "    epoch          : 809\n",
      "    loss           : -945.644434453238\n",
      "    val_loss       : -753.2179874123442\n",
      "    val_log_likelihood: 1266.776423515619\n",
      "    val_log_marginal: 776.7286701919683\n",
      "Train Epoch: 810 [512/17352 (3%)] Loss: -1008.548157\n",
      "Train Epoch: 810 [10334/17352 (60%)] Loss: -892.536047\n",
      "Train Epoch: 810 [16988/17352 (98%)] Loss: -398.171352\n",
      "    epoch          : 810\n",
      "    loss           : -866.7171633157975\n",
      "    val_loss       : -568.7463400262126\n",
      "    val_log_likelihood: 1202.7335843619678\n",
      "    val_log_marginal: 591.7165519256873\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch810.pth ...\n",
      "Train Epoch: 811 [512/17352 (3%)] Loss: -805.756104\n",
      "Train Epoch: 811 [10589/17352 (61%)] Loss: -650.215503\n",
      "Train Epoch: 811 [16988/17352 (98%)] Loss: 1119.906901\n",
      "    epoch          : 811\n",
      "    loss           : -642.3193372635745\n",
      "    val_loss       : -0.02049540739917759\n",
      "    val_log_likelihood: 1108.9437699259797\n",
      "    val_log_marginal: 31.31395709426505\n",
      "Train Epoch: 812 [512/17352 (3%)] Loss: -75.872490\n",
      "Train Epoch: 812 [10591/17352 (61%)] Loss: -887.481072\n",
      "Train Epoch: 812 [16939/17352 (98%)] Loss: -733.224432\n",
      "    epoch          : 812\n",
      "    loss           : -653.6873180531952\n",
      "    val_loss       : -647.6182226762668\n",
      "    val_log_likelihood: 1195.4934773205093\n",
      "    val_log_marginal: 674.4596665113114\n",
      "Train Epoch: 813 [512/17352 (3%)] Loss: -915.442261\n",
      "Train Epoch: 813 [10103/17352 (58%)] Loss: -921.229395\n",
      "Train Epoch: 813 [16878/17352 (97%)] Loss: -655.280990\n",
      "    epoch          : 813\n",
      "    loss           : -685.3558732665273\n",
      "    val_loss       : -272.5518382202746\n",
      "    val_log_likelihood: 1168.7398021450465\n",
      "    val_log_marginal: 333.2374066814976\n",
      "Train Epoch: 814 [512/17352 (3%)] Loss: -598.311096\n",
      "Train Epoch: 814 [10783/17352 (62%)] Loss: -875.853030\n",
      "Train Epoch: 814 [17016/17352 (98%)] Loss: -778.109786\n",
      "    epoch          : 814\n",
      "    loss           : -757.4053587444387\n",
      "    val_loss       : -414.79901427828503\n",
      "    val_log_likelihood: 1130.9833744262055\n",
      "    val_log_marginal: 474.62105537235055\n",
      "Train Epoch: 815 [512/17352 (3%)] Loss: -641.910645\n",
      "Train Epoch: 815 [10573/17352 (61%)] Loss: -776.134834\n",
      "Train Epoch: 815 [16872/17352 (97%)] Loss: -826.359439\n",
      "    epoch          : 815\n",
      "    loss           : -836.305948495801\n",
      "    val_loss       : -735.0353406653604\n",
      "    val_log_likelihood: 1216.9999818675751\n",
      "    val_log_marginal: 755.8730603846011\n",
      "Train Epoch: 816 [512/17352 (3%)] Loss: -986.671570\n",
      "Train Epoch: 816 [10074/17352 (58%)] Loss: -917.321683\n",
      "Train Epoch: 816 [16988/17352 (98%)] Loss: -997.310570\n",
      "    epoch          : 816\n",
      "    loss           : -956.7625725094258\n",
      "    val_loss       : -760.8996740713957\n",
      "    val_log_likelihood: 1242.770234216661\n",
      "    val_log_marginal: 775.540705229959\n",
      "Train Epoch: 817 [512/17352 (3%)] Loss: -1011.597595\n",
      "Train Epoch: 817 [10248/17352 (59%)] Loss: -984.633917\n",
      "Train Epoch: 817 [17044/17352 (98%)] Loss: -908.514280\n",
      "    epoch          : 817\n",
      "    loss           : -960.6318557483892\n",
      "    val_loss       : -735.5997942464659\n",
      "    val_log_likelihood: 1233.5227403243266\n",
      "    val_log_marginal: 763.3731488638533\n",
      "Train Epoch: 818 [512/17352 (3%)] Loss: -992.493164\n",
      "Train Epoch: 818 [10993/17352 (63%)] Loss: -1043.940355\n",
      "Train Epoch: 818 [17277/17352 (100%)] Loss: -1046.997407\n",
      "    epoch          : 818\n",
      "    loss           : -960.0413521329159\n",
      "    val_loss       : -728.3076797399217\n",
      "    val_log_likelihood: 1237.8912219174874\n",
      "    val_log_marginal: 748.2629365744435\n",
      "Train Epoch: 819 [512/17352 (3%)] Loss: -919.871582\n",
      "Train Epoch: 819 [10471/17352 (60%)] Loss: -899.599641\n",
      "Train Epoch: 819 [16958/17352 (98%)] Loss: -928.296464\n",
      "    epoch          : 819\n",
      "    loss           : -956.7721587514186\n",
      "    val_loss       : -750.082270928244\n",
      "    val_log_likelihood: 1250.6373669304899\n",
      "    val_log_marginal: 777.6026315914559\n",
      "Train Epoch: 820 [512/17352 (3%)] Loss: -975.138062\n",
      "Train Epoch: 820 [10020/17352 (58%)] Loss: -1028.587953\n",
      "Train Epoch: 820 [16922/17352 (98%)] Loss: -1005.079195\n",
      "    epoch          : 820\n",
      "    loss           : -942.3742156283787\n",
      "    val_loss       : -748.4489176605397\n",
      "    val_log_likelihood: 1250.439964945453\n",
      "    val_log_marginal: 771.6855567259354\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch820.pth ...\n",
      "Train Epoch: 821 [512/17352 (3%)] Loss: -987.017822\n",
      "Train Epoch: 821 [10744/17352 (62%)] Loss: -992.424400\n",
      "Train Epoch: 821 [16992/17352 (98%)] Loss: -959.221217\n",
      "    epoch          : 821\n",
      "    loss           : -973.1162040019468\n",
      "    val_loss       : -743.6032314680689\n",
      "    val_log_likelihood: 1249.1190684708731\n",
      "    val_log_marginal: 764.0607304537798\n",
      "Train Epoch: 822 [512/17352 (3%)] Loss: -1019.268005\n",
      "Train Epoch: 822 [9774/17352 (56%)] Loss: -1005.975031\n",
      "Train Epoch: 822 [17126/17352 (99%)] Loss: -1044.179283\n",
      "    epoch          : 822\n",
      "    loss           : -983.9605804220736\n",
      "    val_loss       : -778.1971244891365\n",
      "    val_log_likelihood: 1270.441524862116\n",
      "    val_log_marginal: 790.7584772688181\n",
      "Train Epoch: 823 [512/17352 (3%)] Loss: -1033.298096\n",
      "Train Epoch: 823 [10009/17352 (58%)] Loss: -939.599769\n",
      "Train Epoch: 823 [17124/17352 (99%)] Loss: -1091.736683\n",
      "    epoch          : 823\n",
      "    loss           : -985.478110858418\n",
      "    val_loss       : -753.0991598625117\n",
      "    val_log_likelihood: 1269.5928689837042\n",
      "    val_log_marginal: 773.8291294383461\n",
      "Train Epoch: 824 [512/17352 (3%)] Loss: -1011.795837\n",
      "Train Epoch: 824 [10251/17352 (59%)] Loss: -888.425164\n",
      "Train Epoch: 824 [16958/17352 (98%)] Loss: -1054.220719\n",
      "    epoch          : 824\n",
      "    loss           : -931.4945127564453\n",
      "    val_loss       : -732.1964218681456\n",
      "    val_log_likelihood: 1246.551399495132\n",
      "    val_log_marginal: 752.6521115790929\n",
      "Train Epoch: 825 [512/17352 (3%)] Loss: -985.401489\n",
      "Train Epoch: 825 [10605/17352 (61%)] Loss: -1102.384983\n",
      "Train Epoch: 825 [17253/17352 (99%)] Loss: -911.849055\n",
      "    epoch          : 825\n",
      "    loss           : -893.0892804320655\n",
      "    val_loss       : -631.0204686072631\n",
      "    val_log_likelihood: 1149.6434483003113\n",
      "    val_log_marginal: 654.5014780174132\n",
      "Train Epoch: 826 [512/17352 (3%)] Loss: -699.252197\n",
      "Train Epoch: 826 [9832/17352 (57%)] Loss: -1008.211330\n",
      "Train Epoch: 826 [17335/17352 (100%)] Loss: -1036.714752\n",
      "    epoch          : 826\n",
      "    loss           : -934.5415277673007\n",
      "    val_loss       : -719.1524618653498\n",
      "    val_log_likelihood: 1244.0657225556313\n",
      "    val_log_marginal: 744.5860431524376\n",
      "Train Epoch: 827 [512/17352 (3%)] Loss: -789.962830\n",
      "Train Epoch: 827 [9834/17352 (57%)] Loss: -1022.962718\n",
      "Train Epoch: 827 [17049/17352 (98%)] Loss: -914.398904\n",
      "    epoch          : 827\n",
      "    loss           : -943.7430596749139\n",
      "    val_loss       : -731.3109676191142\n",
      "    val_log_likelihood: 1247.5796075974308\n",
      "    val_log_marginal: 742.2129077740896\n",
      "Train Epoch: 828 [512/17352 (3%)] Loss: -1000.426697\n",
      "Train Epoch: 828 [10278/17352 (59%)] Loss: -1017.541134\n",
      "Train Epoch: 828 [17106/17352 (99%)] Loss: -988.086370\n",
      "    epoch          : 828\n",
      "    loss           : -951.5491718143414\n",
      "    val_loss       : -632.6857542339868\n",
      "    val_log_likelihood: 1256.1234960007198\n",
      "    val_log_marginal: 652.8284817419211\n",
      "Train Epoch: 829 [512/17352 (3%)] Loss: -907.408569\n",
      "Train Epoch: 829 [10158/17352 (59%)] Loss: -1040.103230\n",
      "Train Epoch: 829 [17153/17352 (99%)] Loss: -1076.495336\n",
      "    epoch          : 829\n",
      "    loss           : -968.757693384265\n",
      "    val_loss       : -752.5098241376235\n",
      "    val_log_likelihood: 1255.4935564895832\n",
      "    val_log_marginal: 772.9864483124985\n",
      "Train Epoch: 830 [512/17352 (3%)] Loss: -1023.561157\n",
      "Train Epoch: 830 [10573/17352 (61%)] Loss: -955.411181\n",
      "Train Epoch: 830 [17106/17352 (99%)] Loss: -957.212200\n",
      "    epoch          : 830\n",
      "    loss           : -976.6696078502026\n",
      "    val_loss       : -760.1728840861931\n",
      "    val_log_likelihood: 1270.9645809525907\n",
      "    val_log_marginal: 777.3128491537364\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch830.pth ...\n",
      "Train Epoch: 831 [512/17352 (3%)] Loss: -997.797852\n",
      "Train Epoch: 831 [10551/17352 (61%)] Loss: -1047.027907\n",
      "Train Epoch: 831 [17101/17352 (99%)] Loss: -1045.971875\n",
      "    epoch          : 831\n",
      "    loss           : -977.284016323828\n",
      "    val_loss       : -762.5804500405228\n",
      "    val_log_likelihood: 1273.0332816728273\n",
      "    val_log_marginal: 775.9212295977152\n",
      "Train Epoch: 832 [512/17352 (3%)] Loss: -1039.051758\n",
      "Train Epoch: 832 [10141/17352 (58%)] Loss: -1040.030316\n",
      "Train Epoch: 832 [17263/17352 (99%)] Loss: -812.010215\n",
      "    epoch          : 832\n",
      "    loss           : -978.9474254663214\n",
      "    val_loss       : -732.0414304443443\n",
      "    val_log_likelihood: 1264.0534493264656\n",
      "    val_log_marginal: 753.8622525091719\n",
      "Train Epoch: 833 [512/17352 (3%)] Loss: -817.230591\n",
      "Train Epoch: 833 [10169/17352 (59%)] Loss: -1000.500065\n",
      "Train Epoch: 833 [16923/17352 (98%)] Loss: -942.532087\n",
      "    epoch          : 833\n",
      "    loss           : -963.5579460157863\n",
      "    val_loss       : -751.426989635758\n",
      "    val_log_likelihood: 1276.0132091664066\n",
      "    val_log_marginal: 783.4034858495277\n",
      "Train Epoch: 834 [512/17352 (3%)] Loss: -1018.788086\n",
      "Train Epoch: 834 [9939/17352 (57%)] Loss: -950.999857\n",
      "Train Epoch: 834 [17016/17352 (98%)] Loss: -887.691493\n",
      "    epoch          : 834\n",
      "    loss           : -917.7133441695619\n",
      "    val_loss       : -726.7417696281593\n",
      "    val_log_likelihood: 1244.2990234682834\n",
      "    val_log_marginal: 741.8835995226821\n",
      "Train Epoch: 835 [512/17352 (3%)] Loss: -985.556824\n",
      "Train Epoch: 835 [10242/17352 (59%)] Loss: -767.182790\n",
      "Train Epoch: 835 [16883/17352 (97%)] Loss: -894.180147\n",
      "    epoch          : 835\n",
      "    loss           : -931.6630172520345\n",
      "    val_loss       : -741.0329949501524\n",
      "    val_log_likelihood: 1264.6984927397148\n",
      "    val_log_marginal: 760.746659324434\n",
      "Train Epoch: 836 [512/17352 (3%)] Loss: -1021.966980\n",
      "Train Epoch: 836 [10230/17352 (59%)] Loss: -914.457480\n",
      "Train Epoch: 836 [17106/17352 (99%)] Loss: -1036.970181\n",
      "    epoch          : 836\n",
      "    loss           : -959.8514419034817\n",
      "    val_loss       : -735.0301589209171\n",
      "    val_log_likelihood: 1259.4345559281921\n",
      "    val_log_marginal: 748.5520363796429\n",
      "Train Epoch: 837 [512/17352 (3%)] Loss: -988.876404\n",
      "Train Epoch: 837 [10503/17352 (61%)] Loss: -1001.239006\n",
      "Train Epoch: 837 [17253/17352 (99%)] Loss: -943.047093\n",
      "    epoch          : 837\n",
      "    loss           : -931.5462429666327\n",
      "    val_loss       : -573.5962955405994\n",
      "    val_log_likelihood: 1256.6038822141659\n",
      "    val_log_marginal: 599.415321940977\n",
      "Train Epoch: 838 [512/17352 (3%)] Loss: -859.766968\n",
      "Train Epoch: 838 [9999/17352 (58%)] Loss: -956.324023\n",
      "Train Epoch: 838 [17263/17352 (99%)] Loss: -1007.358875\n",
      "    epoch          : 838\n",
      "    loss           : -907.5175751487246\n",
      "    val_loss       : -498.666470279364\n",
      "    val_log_likelihood: 1237.3198742770282\n",
      "    val_log_marginal: 517.4628151250192\n",
      "Train Epoch: 839 [512/17352 (3%)] Loss: -795.178101\n",
      "Train Epoch: 839 [10150/17352 (58%)] Loss: -805.272277\n",
      "Train Epoch: 839 [16882/17352 (97%)] Loss: -733.677688\n",
      "    epoch          : 839\n",
      "    loss           : -940.5382514757763\n",
      "    val_loss       : -716.6663684288816\n",
      "    val_log_likelihood: 1257.6352948335577\n",
      "    val_log_marginal: 748.1902187724796\n",
      "Train Epoch: 840 [512/17352 (3%)] Loss: -981.449219\n",
      "Train Epoch: 840 [10524/17352 (61%)] Loss: -824.709779\n",
      "Train Epoch: 840 [17090/17352 (98%)] Loss: -1005.172503\n",
      "    epoch          : 840\n",
      "    loss           : -946.8586362003497\n",
      "    val_loss       : -692.0530383497639\n",
      "    val_log_likelihood: 1255.0973335130107\n",
      "    val_log_marginal: 712.5902607125425\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch840.pth ...\n",
      "Train Epoch: 841 [512/17352 (3%)] Loss: -931.327026\n",
      "Train Epoch: 841 [9997/17352 (58%)] Loss: -961.539141\n",
      "Train Epoch: 841 [17108/17352 (99%)] Loss: -1011.327409\n",
      "    epoch          : 841\n",
      "    loss           : -950.4637689865925\n",
      "    val_loss       : -768.2372647215475\n",
      "    val_log_likelihood: 1276.4929340071747\n",
      "    val_log_marginal: 788.0924792818689\n",
      "Train Epoch: 842 [512/17352 (3%)] Loss: -1027.319580\n",
      "Train Epoch: 842 [10370/17352 (60%)] Loss: -883.755059\n",
      "Train Epoch: 842 [17064/17352 (98%)] Loss: -953.369162\n",
      "    epoch          : 842\n",
      "    loss           : -961.1797628921289\n",
      "    val_loss       : -726.1765139903644\n",
      "    val_log_likelihood: 1251.0203180869323\n",
      "    val_log_marginal: 743.2385182054961\n",
      "Train Epoch: 843 [512/17352 (3%)] Loss: -1005.291260\n",
      "Train Epoch: 843 [10451/17352 (60%)] Loss: -1053.967464\n",
      "Train Epoch: 843 [16988/17352 (98%)] Loss: -1022.477526\n",
      "    epoch          : 843\n",
      "    loss           : -950.8166707737713\n",
      "    val_loss       : -754.4545025754595\n",
      "    val_log_likelihood: 1275.749262020998\n",
      "    val_log_marginal: 777.3193381735598\n",
      "Train Epoch: 844 [512/17352 (3%)] Loss: -1026.344238\n",
      "Train Epoch: 844 [10105/17352 (58%)] Loss: -740.666492\n",
      "Train Epoch: 844 [16883/17352 (97%)] Loss: -857.526952\n",
      "    epoch          : 844\n",
      "    loss           : -950.3661905412766\n",
      "    val_loss       : -715.315565617628\n",
      "    val_log_likelihood: 1261.9614388324721\n",
      "    val_log_marginal: 734.50648212822\n",
      "Train Epoch: 845 [512/17352 (3%)] Loss: -982.798706\n",
      "Train Epoch: 845 [10492/17352 (60%)] Loss: -933.265970\n",
      "Train Epoch: 845 [17016/17352 (98%)] Loss: -964.608744\n",
      "    epoch          : 845\n",
      "    loss           : -942.089262334087\n",
      "    val_loss       : -735.374490770529\n",
      "    val_log_likelihood: 1262.5586049478027\n",
      "    val_log_marginal: 756.7215279210269\n",
      "Train Epoch: 846 [512/17352 (3%)] Loss: -789.644531\n",
      "Train Epoch: 846 [10543/17352 (61%)] Loss: -1061.693343\n",
      "Train Epoch: 846 [16934/17352 (98%)] Loss: -1009.512367\n",
      "    epoch          : 846\n",
      "    loss           : -967.6871225578346\n",
      "    val_loss       : -720.9629827402589\n",
      "    val_log_likelihood: 1271.558645810589\n",
      "    val_log_marginal: 738.7760562576818\n",
      "Train Epoch: 847 [512/17352 (3%)] Loss: -998.716431\n",
      "Train Epoch: 847 [10699/17352 (62%)] Loss: -1089.347836\n",
      "Train Epoch: 847 [16988/17352 (98%)] Loss: -840.271052\n",
      "    epoch          : 847\n",
      "    loss           : -974.2820373077617\n",
      "    val_loss       : -750.9355599538776\n",
      "    val_log_likelihood: 1270.3740431160923\n",
      "    val_log_marginal: 767.4394402136193\n",
      "Train Epoch: 848 [512/17352 (3%)] Loss: -1029.524536\n",
      "Train Epoch: 848 [10723/17352 (62%)] Loss: -1089.499267\n",
      "Train Epoch: 848 [17049/17352 (98%)] Loss: -1068.360775\n",
      "    epoch          : 848\n",
      "    loss           : -988.6223700328944\n",
      "    val_loss       : -705.1174209705254\n",
      "    val_log_likelihood: 1279.5291170241271\n",
      "    val_log_marginal: 723.3857191659672\n",
      "Train Epoch: 849 [512/17352 (3%)] Loss: -985.521240\n",
      "Train Epoch: 849 [10090/17352 (58%)] Loss: -803.867252\n",
      "Train Epoch: 849 [17016/17352 (98%)] Loss: -738.877019\n",
      "    epoch          : 849\n",
      "    loss           : -926.9649825461622\n",
      "    val_loss       : -708.4491443433919\n",
      "    val_log_likelihood: 1243.9891038473531\n",
      "    val_log_marginal: 730.1655540278505\n",
      "Train Epoch: 850 [512/17352 (3%)] Loss: -966.533936\n",
      "Train Epoch: 850 [9980/17352 (58%)] Loss: -949.414200\n",
      "Train Epoch: 850 [16878/17352 (97%)] Loss: -1094.418584\n",
      "    epoch          : 850\n",
      "    loss           : -952.9045771131604\n",
      "    val_loss       : -738.3678020561348\n",
      "    val_log_likelihood: 1260.387277314232\n",
      "    val_log_marginal: 754.7435995601442\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch850.pth ...\n",
      "Train Epoch: 851 [512/17352 (3%)] Loss: -1017.505859\n",
      "Train Epoch: 851 [10057/17352 (58%)] Loss: -923.830751\n",
      "Train Epoch: 851 [16878/17352 (97%)] Loss: -1055.815355\n",
      "    epoch          : 851\n",
      "    loss           : -977.1337185658643\n",
      "    val_loss       : -752.223356741409\n",
      "    val_log_likelihood: 1277.4925187298284\n",
      "    val_log_marginal: 777.2701538803176\n",
      "Train Epoch: 852 [512/17352 (3%)] Loss: -1008.499146\n",
      "Train Epoch: 852 [9985/17352 (58%)] Loss: -1018.467319\n",
      "Train Epoch: 852 [16882/17352 (97%)] Loss: -1026.510678\n",
      "    epoch          : 852\n",
      "    loss           : -987.1991087374864\n",
      "    val_loss       : -755.5099367214743\n",
      "    val_log_likelihood: 1287.1370247425043\n",
      "    val_log_marginal: 789.2182956088106\n",
      "Train Epoch: 853 [512/17352 (3%)] Loss: -1046.720337\n",
      "Train Epoch: 853 [9784/17352 (56%)] Loss: -988.745368\n",
      "Train Epoch: 853 [16923/17352 (98%)] Loss: -1024.512563\n",
      "    epoch          : 853\n",
      "    loss           : -987.2475550529399\n",
      "    val_loss       : -775.6769409812307\n",
      "    val_log_likelihood: 1289.28469700285\n",
      "    val_log_marginal: 792.6060026249485\n",
      "Train Epoch: 854 [512/17352 (3%)] Loss: -1050.641846\n",
      "Train Epoch: 854 [10221/17352 (59%)] Loss: -1096.766325\n",
      "Train Epoch: 854 [17143/17352 (99%)] Loss: -914.453850\n",
      "    epoch          : 854\n",
      "    loss           : -979.0518489094899\n",
      "    val_loss       : -727.7072422332825\n",
      "    val_log_likelihood: 1268.697449907961\n",
      "    val_log_marginal: 746.851667376132\n",
      "Train Epoch: 855 [512/17352 (3%)] Loss: -1010.024963\n",
      "Train Epoch: 855 [9896/17352 (57%)] Loss: -1074.365727\n",
      "Train Epoch: 855 [17253/17352 (99%)] Loss: -1021.402284\n",
      "    epoch          : 855\n",
      "    loss           : -963.1393219073783\n",
      "    val_loss       : -618.9750617860751\n",
      "    val_log_likelihood: 1255.2293310716902\n",
      "    val_log_marginal: 646.7432779485073\n",
      "Train Epoch: 856 [512/17352 (3%)] Loss: -897.409546\n",
      "Train Epoch: 856 [10273/17352 (59%)] Loss: -964.858295\n",
      "Train Epoch: 856 [16923/17352 (98%)] Loss: -993.313356\n",
      "    epoch          : 856\n",
      "    loss           : -896.2855015134176\n",
      "    val_loss       : -684.3058826983054\n",
      "    val_log_likelihood: 1233.0984006049773\n",
      "    val_log_marginal: 705.5541082516971\n",
      "Train Epoch: 857 [512/17352 (3%)] Loss: -918.949341\n",
      "Train Epoch: 857 [10400/17352 (60%)] Loss: -779.654201\n",
      "Train Epoch: 857 [17124/17352 (99%)] Loss: -566.917539\n",
      "    epoch          : 857\n",
      "    loss           : -891.474555636444\n",
      "    val_loss       : -574.3874501024671\n",
      "    val_log_likelihood: 1203.2713491415827\n",
      "    val_log_marginal: 609.4288076721957\n",
      "Train Epoch: 858 [512/17352 (3%)] Loss: -809.239502\n",
      "Train Epoch: 858 [10674/17352 (62%)] Loss: -799.990895\n",
      "Train Epoch: 858 [16887/17352 (97%)] Loss: -868.884569\n",
      "    epoch          : 858\n",
      "    loss           : -892.8599097707472\n",
      "    val_loss       : -731.2937461358963\n",
      "    val_log_likelihood: 1261.4042100149923\n",
      "    val_log_marginal: 755.2318161151843\n",
      "Train Epoch: 859 [512/17352 (3%)] Loss: -1013.978516\n",
      "Train Epoch: 859 [10036/17352 (58%)] Loss: -907.688709\n",
      "Train Epoch: 859 [16957/17352 (98%)] Loss: -1082.708206\n",
      "    epoch          : 859\n",
      "    loss           : -958.0386521163088\n",
      "    val_loss       : -720.9373214361807\n",
      "    val_log_likelihood: 1249.4743968067316\n",
      "    val_log_marginal: 742.2129556897777\n",
      "Train Epoch: 860 [512/17352 (3%)] Loss: -976.026672\n",
      "Train Epoch: 860 [9927/17352 (57%)] Loss: -827.513906\n",
      "Train Epoch: 860 [17049/17352 (98%)] Loss: -1045.516851\n",
      "    epoch          : 860\n",
      "    loss           : -948.7557289603377\n",
      "    val_loss       : -670.8946802516016\n",
      "    val_log_likelihood: 1267.200477753514\n",
      "    val_log_marginal: 689.0347201845692\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch860.pth ...\n",
      "Train Epoch: 861 [512/17352 (3%)] Loss: -901.361267\n",
      "Train Epoch: 861 [10041/17352 (58%)] Loss: -977.484138\n",
      "Train Epoch: 861 [16883/17352 (97%)] Loss: -1069.467014\n",
      "    epoch          : 861\n",
      "    loss           : -925.3077907144029\n",
      "    val_loss       : -728.6108666085778\n",
      "    val_log_likelihood: 1276.9717582231337\n",
      "    val_log_marginal: 751.6087985769618\n",
      "Train Epoch: 862 [512/17352 (3%)] Loss: -992.457092\n",
      "Train Epoch: 862 [10475/17352 (60%)] Loss: -957.488152\n",
      "Train Epoch: 862 [17277/17352 (100%)] Loss: -804.648723\n",
      "    epoch          : 862\n",
      "    loss           : -939.453871268239\n",
      "    val_loss       : -671.3902157515339\n",
      "    val_log_likelihood: 1230.0363532166512\n",
      "    val_log_marginal: 691.4738914777604\n",
      "Train Epoch: 863 [512/17352 (3%)] Loss: -942.316162\n",
      "Train Epoch: 863 [10189/17352 (59%)] Loss: -1086.494149\n",
      "Train Epoch: 863 [17253/17352 (99%)] Loss: -880.119537\n",
      "    epoch          : 863\n",
      "    loss           : -974.61435384459\n",
      "    val_loss       : -732.6874185297733\n",
      "    val_log_likelihood: 1261.9141437557396\n",
      "    val_log_marginal: 755.6402709170577\n",
      "Train Epoch: 864 [512/17352 (3%)] Loss: -987.896423\n",
      "Train Epoch: 864 [10609/17352 (61%)] Loss: -1059.220654\n",
      "Train Epoch: 864 [16872/17352 (97%)] Loss: -926.646788\n",
      "    epoch          : 864\n",
      "    loss           : -970.324066010715\n",
      "    val_loss       : -759.4239676228234\n",
      "    val_log_likelihood: 1279.3466738339823\n",
      "    val_log_marginal: 772.3806191526725\n",
      "Train Epoch: 865 [512/17352 (3%)] Loss: -1021.923462\n",
      "Train Epoch: 865 [10712/17352 (62%)] Loss: -1037.489981\n",
      "Train Epoch: 865 [16934/17352 (98%)] Loss: -986.636933\n",
      "    epoch          : 865\n",
      "    loss           : -978.8609637538808\n",
      "    val_loss       : -776.9795355281589\n",
      "    val_log_likelihood: 1292.5587404394698\n",
      "    val_log_marginal: 793.9658503264797\n",
      "Train Epoch: 866 [512/17352 (3%)] Loss: -1046.790039\n",
      "Train Epoch: 866 [9609/17352 (55%)] Loss: -1086.158283\n",
      "Train Epoch: 866 [16957/17352 (98%)] Loss: -1025.291738\n",
      "    epoch          : 866\n",
      "    loss           : -986.4226708186324\n",
      "    val_loss       : -759.1451371868079\n",
      "    val_log_likelihood: 1268.5310091959238\n",
      "    val_log_marginal: 775.0067979155128\n",
      "Train Epoch: 867 [512/17352 (3%)] Loss: -1020.772583\n",
      "Train Epoch: 867 [11057/17352 (64%)] Loss: -819.500000\n",
      "Train Epoch: 867 [16883/17352 (97%)] Loss: -872.307137\n",
      "    epoch          : 867\n",
      "    loss           : -987.2566240757202\n",
      "    val_loss       : -760.9025015393781\n",
      "    val_log_likelihood: 1292.6191452164167\n",
      "    val_log_marginal: 778.2471284207438\n",
      "Train Epoch: 868 [512/17352 (3%)] Loss: -1038.209595\n",
      "Train Epoch: 868 [10580/17352 (61%)] Loss: -872.119974\n",
      "Train Epoch: 868 [16939/17352 (98%)] Loss: -944.446117\n",
      "    epoch          : 868\n",
      "    loss           : -978.721251680929\n",
      "    val_loss       : -779.1055152273015\n",
      "    val_log_likelihood: 1291.6804741591052\n",
      "    val_log_marginal: 795.2728109961691\n",
      "Train Epoch: 869 [512/17352 (3%)] Loss: -1045.636963\n",
      "Train Epoch: 869 [10029/17352 (58%)] Loss: -1060.305452\n",
      "Train Epoch: 869 [17133/17352 (99%)] Loss: -995.736554\n",
      "    epoch          : 869\n",
      "    loss           : -975.1660195405133\n",
      "    val_loss       : -721.5432344510023\n",
      "    val_log_likelihood: 1258.4473455839225\n",
      "    val_log_marginal: 745.521783098074\n",
      "Train Epoch: 870 [512/17352 (3%)] Loss: -1005.634766\n",
      "Train Epoch: 870 [10274/17352 (59%)] Loss: -1071.423138\n",
      "Train Epoch: 870 [16939/17352 (98%)] Loss: -1096.686834\n",
      "    epoch          : 870\n",
      "    loss           : -966.1236252757865\n",
      "    val_loss       : -750.3043124486037\n",
      "    val_log_likelihood: 1279.5879727003648\n",
      "    val_log_marginal: 772.9364440059044\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch870.pth ...\n",
      "Train Epoch: 871 [512/17352 (3%)] Loss: -1022.429810\n",
      "Train Epoch: 871 [10399/17352 (60%)] Loss: -1022.591846\n",
      "Train Epoch: 871 [16923/17352 (98%)] Loss: -902.596055\n",
      "    epoch          : 871\n",
      "    loss           : -970.3339606632974\n",
      "    val_loss       : -753.8306253808548\n",
      "    val_log_likelihood: 1284.6111881999268\n",
      "    val_log_marginal: 777.6166489942789\n",
      "Train Epoch: 872 [512/17352 (3%)] Loss: -1028.912231\n",
      "Train Epoch: 872 [10666/17352 (61%)] Loss: -1011.916025\n",
      "Train Epoch: 872 [17124/17352 (99%)] Loss: -1037.212430\n",
      "    epoch          : 872\n",
      "    loss           : -952.8974246920621\n",
      "    val_loss       : -725.9582772931229\n",
      "    val_log_likelihood: 1277.2743108546847\n",
      "    val_log_marginal: 749.1281181277317\n",
      "Train Epoch: 873 [512/17352 (3%)] Loss: -1001.637451\n",
      "Train Epoch: 873 [10742/17352 (62%)] Loss: -1075.456782\n",
      "Train Epoch: 873 [17153/17352 (99%)] Loss: -1032.024525\n",
      "    epoch          : 873\n",
      "    loss           : -963.4906523269633\n",
      "    val_loss       : -682.9141449948902\n",
      "    val_log_likelihood: 1250.797903095447\n",
      "    val_log_marginal: 700.2564268300055\n",
      "Train Epoch: 874 [512/17352 (3%)] Loss: -984.215332\n",
      "Train Epoch: 874 [9844/17352 (57%)] Loss: -804.958807\n",
      "Train Epoch: 874 [16887/17352 (97%)] Loss: -980.073497\n",
      "    epoch          : 874\n",
      "    loss           : -903.0855423439724\n",
      "    val_loss       : -692.7285994843193\n",
      "    val_log_likelihood: 1262.7597103969142\n",
      "    val_log_marginal: 715.7474467348779\n",
      "Train Epoch: 875 [512/17352 (3%)] Loss: -971.544922\n",
      "Train Epoch: 875 [10367/17352 (60%)] Loss: -569.003564\n",
      "Train Epoch: 875 [16923/17352 (98%)] Loss: 2068.128612\n",
      "    epoch          : 875\n",
      "    loss           : 244.5689059202827\n",
      "    val_loss       : 367.1392436510817\n",
      "    val_log_likelihood: 883.3166245529716\n",
      "    val_log_marginal: -290.5537428568423\n",
      "Train Epoch: 876 [512/17352 (3%)] Loss: 161.342102\n",
      "Train Epoch: 876 [10528/17352 (61%)] Loss: 1441.858292\n",
      "Train Epoch: 876 [17090/17352 (98%)] Loss: -471.374841\n",
      "    epoch          : 876\n",
      "    loss           : 696.7948546492681\n",
      "    val_loss       : -89.19821320569815\n",
      "    val_log_likelihood: 874.0419029857196\n",
      "    val_log_marginal: 231.32779493858627\n",
      "Train Epoch: 877 [512/17352 (3%)] Loss: -519.301392\n",
      "Train Epoch: 877 [10348/17352 (60%)] Loss: -532.385918\n",
      "Train Epoch: 877 [17277/17352 (100%)] Loss: -692.822191\n",
      "    epoch          : 877\n",
      "    loss           : -610.5685229008214\n",
      "    val_loss       : -627.3862596777014\n",
      "    val_log_likelihood: 1110.742688022104\n",
      "    val_log_marginal: 655.1752573240549\n",
      "Train Epoch: 878 [512/17352 (3%)] Loss: -865.115784\n",
      "Train Epoch: 878 [10316/17352 (59%)] Loss: -941.316860\n",
      "Train Epoch: 878 [17153/17352 (99%)] Loss: -826.304079\n",
      "    epoch          : 878\n",
      "    loss           : -856.534158229788\n",
      "    val_loss       : -713.1668714584129\n",
      "    val_log_likelihood: 1182.215234611212\n",
      "    val_log_marginal: 744.4486147610163\n",
      "Train Epoch: 879 [512/17352 (3%)] Loss: -928.294739\n",
      "Train Epoch: 879 [9867/17352 (57%)] Loss: -854.051339\n",
      "Train Epoch: 879 [17090/17352 (98%)] Loss: -853.012261\n",
      "    epoch          : 879\n",
      "    loss           : -923.2554284393933\n",
      "    val_loss       : -760.611726127815\n",
      "    val_log_likelihood: 1220.795334561384\n",
      "    val_log_marginal: 782.416186532853\n",
      "Train Epoch: 880 [512/17352 (3%)] Loss: -980.871094\n",
      "Train Epoch: 880 [10114/17352 (58%)] Loss: -890.549043\n",
      "Train Epoch: 880 [17106/17352 (99%)] Loss: -983.906721\n",
      "    epoch          : 880\n",
      "    loss           : -939.750135409575\n",
      "    val_loss       : -754.9875128205817\n",
      "    val_log_likelihood: 1229.4683868939576\n",
      "    val_log_marginal: 776.7690683460112\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch880.pth ...\n",
      "Train Epoch: 881 [512/17352 (3%)] Loss: -789.245117\n",
      "Train Epoch: 881 [10470/17352 (60%)] Loss: -883.332183\n",
      "Train Epoch: 881 [17143/17352 (99%)] Loss: -804.757271\n",
      "    epoch          : 881\n",
      "    loss           : -953.7059387859683\n",
      "    val_loss       : -765.6431983612249\n",
      "    val_log_likelihood: 1236.9717193605165\n",
      "    val_log_marginal: 784.3430177498014\n",
      "Train Epoch: 882 [512/17352 (3%)] Loss: -789.577637\n",
      "Train Epoch: 882 [10288/17352 (59%)] Loss: -1014.694223\n",
      "Train Epoch: 882 [16923/17352 (98%)] Loss: -1009.089184\n",
      "    epoch          : 882\n",
      "    loss           : -962.1521577737491\n",
      "    val_loss       : -765.9898045977902\n",
      "    val_log_likelihood: 1245.5675590741646\n",
      "    val_log_marginal: 782.4980747547759\n",
      "Train Epoch: 883 [512/17352 (3%)] Loss: -1002.518555\n",
      "Train Epoch: 883 [10397/17352 (60%)] Loss: -919.852980\n",
      "Train Epoch: 883 [16872/17352 (97%)] Loss: -929.681296\n",
      "    epoch          : 883\n",
      "    loss           : -964.8393548814132\n",
      "    val_loss       : -767.364082863789\n",
      "    val_log_likelihood: 1255.9406688412132\n",
      "    val_log_marginal: 791.3132559282534\n",
      "Train Epoch: 884 [512/17352 (3%)] Loss: -978.573914\n",
      "Train Epoch: 884 [10364/17352 (60%)] Loss: -1051.225102\n",
      "Train Epoch: 884 [16878/17352 (97%)] Loss: -865.214525\n",
      "    epoch          : 884\n",
      "    loss           : -964.6128039429326\n",
      "    val_loss       : -775.7894271685834\n",
      "    val_log_likelihood: 1262.4774383598246\n",
      "    val_log_marginal: 795.8897889829149\n",
      "Train Epoch: 885 [512/17352 (3%)] Loss: -1018.363586\n",
      "Train Epoch: 885 [10358/17352 (60%)] Loss: -1032.015982\n",
      "Train Epoch: 885 [16882/17352 (97%)] Loss: -920.629219\n",
      "    epoch          : 885\n",
      "    loss           : -982.2471159128893\n",
      "    val_loss       : -783.7752059277047\n",
      "    val_log_likelihood: 1270.3597905866682\n",
      "    val_log_marginal: 801.7814479428207\n",
      "Train Epoch: 886 [512/17352 (3%)] Loss: -1023.704712\n",
      "Train Epoch: 886 [10080/17352 (58%)] Loss: -918.687244\n",
      "Train Epoch: 886 [17044/17352 (98%)] Loss: -964.528674\n",
      "    epoch          : 886\n",
      "    loss           : -983.8299553434424\n",
      "    val_loss       : -785.952548998584\n",
      "    val_log_likelihood: 1272.3505966755404\n",
      "    val_log_marginal: 805.1638534993656\n",
      "Train Epoch: 887 [512/17352 (3%)] Loss: -1025.059448\n",
      "Train Epoch: 887 [11010/17352 (63%)] Loss: -826.538844\n",
      "Train Epoch: 887 [17143/17352 (99%)] Loss: -965.899357\n",
      "    epoch          : 887\n",
      "    loss           : -983.2426788053236\n",
      "    val_loss       : -756.8911140694158\n",
      "    val_log_likelihood: 1258.9924762201124\n",
      "    val_log_marginal: 767.363760807892\n",
      "Train Epoch: 888 [512/17352 (3%)] Loss: -1000.595215\n",
      "Train Epoch: 888 [10698/17352 (62%)] Loss: -1032.929688\n",
      "Train Epoch: 888 [17090/17352 (98%)] Loss: -827.975269\n",
      "    epoch          : 888\n",
      "    loss           : -983.226938101455\n",
      "    val_loss       : -787.360811035609\n",
      "    val_log_likelihood: 1280.114261692967\n",
      "    val_log_marginal: 804.9079305532241\n",
      "Train Epoch: 889 [512/17352 (3%)] Loss: -1031.686157\n",
      "Train Epoch: 889 [10050/17352 (58%)] Loss: -1048.227454\n",
      "Train Epoch: 889 [16992/17352 (98%)] Loss: -1084.052128\n",
      "    epoch          : 889\n",
      "    loss           : -985.5633844712274\n",
      "    val_loss       : -765.4284138360183\n",
      "    val_log_likelihood: 1271.4746199554595\n",
      "    val_log_marginal: 786.2509413893029\n",
      "Train Epoch: 890 [512/17352 (3%)] Loss: -1010.366882\n",
      "Train Epoch: 890 [10250/17352 (59%)] Loss: -1022.496541\n",
      "Train Epoch: 890 [16923/17352 (98%)] Loss: -1046.039716\n",
      "    epoch          : 890\n",
      "    loss           : -986.6722483432941\n",
      "    val_loss       : -785.552603613342\n",
      "    val_log_likelihood: 1283.517351035249\n",
      "    val_log_marginal: 805.7414683799244\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch890.pth ...\n",
      "Train Epoch: 891 [512/17352 (3%)] Loss: -1033.650879\n",
      "Train Epoch: 891 [10472/17352 (60%)] Loss: -926.436709\n",
      "Train Epoch: 891 [17090/17352 (98%)] Loss: -935.789703\n",
      "    epoch          : 891\n",
      "    loss           : -986.8829848454242\n",
      "    val_loss       : -767.8428894013092\n",
      "    val_log_likelihood: 1283.8130815221639\n",
      "    val_log_marginal: 785.8654316792534\n",
      "Train Epoch: 892 [512/17352 (3%)] Loss: -1023.428894\n",
      "Train Epoch: 892 [10446/17352 (60%)] Loss: -1021.720420\n",
      "Train Epoch: 892 [17108/17352 (99%)] Loss: -1097.283537\n",
      "    epoch          : 892\n",
      "    loss           : -995.9630651630468\n",
      "    val_loss       : -780.4888784892562\n",
      "    val_log_likelihood: 1284.437760809654\n",
      "    val_log_marginal: 798.6538478462427\n",
      "Train Epoch: 893 [512/17352 (3%)] Loss: -1036.938232\n",
      "Train Epoch: 893 [10643/17352 (61%)] Loss: -1101.711255\n",
      "Train Epoch: 893 [17064/17352 (98%)] Loss: -1059.151458\n",
      "    epoch          : 893\n",
      "    loss           : -999.2588394380579\n",
      "    val_loss       : -775.4165862962626\n",
      "    val_log_likelihood: 1285.705649170649\n",
      "    val_log_marginal: 789.1685606105307\n",
      "Train Epoch: 894 [512/17352 (3%)] Loss: -1048.084961\n",
      "Train Epoch: 894 [10224/17352 (59%)] Loss: -945.590402\n",
      "Train Epoch: 894 [17335/17352 (100%)] Loss: -1033.681894\n",
      "    epoch          : 894\n",
      "    loss           : -992.6752689878384\n",
      "    val_loss       : -741.2516475759105\n",
      "    val_log_likelihood: 1273.5544369351455\n",
      "    val_log_marginal: 759.0399170407364\n",
      "Train Epoch: 895 [512/17352 (3%)] Loss: -1014.148926\n",
      "Train Epoch: 895 [10095/17352 (58%)] Loss: -872.000977\n",
      "Train Epoch: 895 [16922/17352 (98%)] Loss: -1081.908791\n",
      "    epoch          : 895\n",
      "    loss           : -987.7620486386598\n",
      "    val_loss       : -774.381920512183\n",
      "    val_log_likelihood: 1286.2865850034177\n",
      "    val_log_marginal: 796.3872286526453\n",
      "Train Epoch: 896 [512/17352 (3%)] Loss: -1037.508667\n",
      "Train Epoch: 896 [10039/17352 (58%)] Loss: -1114.974576\n",
      "Train Epoch: 896 [17263/17352 (99%)] Loss: -1031.973481\n",
      "    epoch          : 896\n",
      "    loss           : -997.1227493139081\n",
      "    val_loss       : -774.9962108461523\n",
      "    val_log_likelihood: 1288.1083183360688\n",
      "    val_log_marginal: 789.3666988843331\n",
      "Train Epoch: 897 [512/17352 (3%)] Loss: -1053.088501\n",
      "Train Epoch: 897 [9933/17352 (57%)] Loss: -1086.799070\n",
      "Train Epoch: 897 [17253/17352 (99%)] Loss: -1085.110089\n",
      "    epoch          : 897\n",
      "    loss           : -996.3510866070036\n",
      "    val_loss       : -761.4567064269222\n",
      "    val_log_likelihood: 1285.233781120465\n",
      "    val_log_marginal: 785.767685083981\n",
      "Train Epoch: 898 [512/17352 (3%)] Loss: -1012.917603\n",
      "Train Epoch: 898 [10351/17352 (60%)] Loss: -1075.927992\n",
      "Train Epoch: 898 [16883/17352 (97%)] Loss: -1069.307122\n",
      "    epoch          : 898\n",
      "    loss           : -991.2279814066226\n",
      "    val_loss       : -776.7669764248909\n",
      "    val_log_likelihood: 1286.265804175685\n",
      "    val_log_marginal: 793.9567440597996\n",
      "Train Epoch: 899 [512/17352 (3%)] Loss: -1042.088623\n",
      "Train Epoch: 899 [10291/17352 (59%)] Loss: -877.481935\n",
      "Train Epoch: 899 [17106/17352 (99%)] Loss: -1130.034722\n",
      "    epoch          : 899\n",
      "    loss           : -999.5607503704108\n",
      "    val_loss       : -772.0809853525159\n",
      "    val_log_likelihood: 1292.7526029372461\n",
      "    val_log_marginal: 787.6444468296369\n",
      "Train Epoch: 900 [512/17352 (3%)] Loss: -1054.436279\n",
      "Train Epoch: 900 [10641/17352 (61%)] Loss: -835.831183\n",
      "Train Epoch: 900 [17126/17352 (99%)] Loss: -962.486168\n",
      "    epoch          : 900\n",
      "    loss           : -1002.9504483626516\n",
      "    val_loss       : -751.5416279254506\n",
      "    val_log_likelihood: 1281.069969631003\n",
      "    val_log_marginal: 772.6657373278433\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch900.pth ...\n",
      "Train Epoch: 901 [512/17352 (3%)] Loss: -1045.814453\n",
      "Train Epoch: 901 [9983/17352 (58%)] Loss: -1005.474370\n",
      "Train Epoch: 901 [17106/17352 (99%)] Loss: -742.731160\n",
      "    epoch          : 901\n",
      "    loss           : -989.2291459281412\n",
      "    val_loss       : -743.8356412195479\n",
      "    val_log_likelihood: 1293.71804202756\n",
      "    val_log_marginal: 762.0925691070122\n",
      "Train Epoch: 902 [512/17352 (3%)] Loss: -1046.501099\n",
      "Train Epoch: 902 [9582/17352 (55%)] Loss: -959.766906\n",
      "Train Epoch: 902 [17106/17352 (99%)] Loss: -945.788976\n",
      "    epoch          : 902\n",
      "    loss           : -993.5936458347259\n",
      "    val_loss       : -769.7807414734797\n",
      "    val_log_likelihood: 1296.4672883990493\n",
      "    val_log_marginal: 787.3073070599877\n",
      "Train Epoch: 903 [512/17352 (3%)] Loss: -1039.291016\n",
      "Train Epoch: 903 [10575/17352 (61%)] Loss: -1082.062659\n",
      "Train Epoch: 903 [16883/17352 (97%)] Loss: -1093.465585\n",
      "    epoch          : 903\n",
      "    loss           : -991.5718137382486\n",
      "    val_loss       : -757.4989179477267\n",
      "    val_log_likelihood: 1290.0094578571527\n",
      "    val_log_marginal: 778.4325341827814\n",
      "Train Epoch: 904 [512/17352 (3%)] Loss: -1019.722290\n",
      "Train Epoch: 904 [10257/17352 (59%)] Loss: -1072.433438\n",
      "Train Epoch: 904 [17049/17352 (98%)] Loss: -1037.440239\n",
      "    epoch          : 904\n",
      "    loss           : -998.4998885954661\n",
      "    val_loss       : -744.2389762684539\n",
      "    val_log_likelihood: 1281.6645638588204\n",
      "    val_log_marginal: 759.3754497920633\n",
      "Train Epoch: 905 [512/17352 (3%)] Loss: -1023.681885\n",
      "Train Epoch: 905 [10494/17352 (60%)] Loss: -1089.449441\n",
      "Train Epoch: 905 [17124/17352 (99%)] Loss: -862.862981\n",
      "    epoch          : 905\n",
      "    loss           : -985.9652269934246\n",
      "    val_loss       : -758.6526697612334\n",
      "    val_log_likelihood: 1284.7855546653923\n",
      "    val_log_marginal: 773.000140185349\n",
      "Train Epoch: 906 [512/17352 (3%)] Loss: -1033.427368\n",
      "Train Epoch: 906 [9941/17352 (57%)] Loss: -841.060334\n",
      "Train Epoch: 906 [16988/17352 (98%)] Loss: -936.808644\n",
      "    epoch          : 906\n",
      "    loss           : -998.6822865728428\n",
      "    val_loss       : -773.5010447399364\n",
      "    val_log_likelihood: 1301.0814756368688\n",
      "    val_log_marginal: 793.7529989797054\n",
      "Train Epoch: 907 [512/17352 (3%)] Loss: -1037.804565\n",
      "Train Epoch: 907 [10504/17352 (61%)] Loss: -952.694103\n",
      "Train Epoch: 907 [17049/17352 (98%)] Loss: -1008.050663\n",
      "    epoch          : 907\n",
      "    loss           : -992.8135249821349\n",
      "    val_loss       : -765.5813451561912\n",
      "    val_log_likelihood: 1294.068288635586\n",
      "    val_log_marginal: 781.1011681450054\n",
      "Train Epoch: 908 [512/17352 (3%)] Loss: -1047.485352\n",
      "Train Epoch: 908 [10821/17352 (62%)] Loss: -963.918380\n",
      "Train Epoch: 908 [17153/17352 (99%)] Loss: -823.212433\n",
      "    epoch          : 908\n",
      "    loss           : -1005.8274062739955\n",
      "    val_loss       : -768.8404725628542\n",
      "    val_log_likelihood: 1300.0847223949575\n",
      "    val_log_marginal: 788.5722156638018\n",
      "Train Epoch: 909 [512/17352 (3%)] Loss: -1055.283447\n",
      "Train Epoch: 909 [10136/17352 (58%)] Loss: -846.720544\n",
      "Train Epoch: 909 [17016/17352 (98%)] Loss: -963.843046\n",
      "    epoch          : 909\n",
      "    loss           : -1011.4932645703495\n",
      "    val_loss       : -774.8921823935386\n",
      "    val_log_likelihood: 1301.2359580188893\n",
      "    val_log_marginal: 790.9254489655311\n",
      "Train Epoch: 910 [512/17352 (3%)] Loss: -1049.006592\n",
      "Train Epoch: 910 [10393/17352 (60%)] Loss: -1067.023901\n",
      "Train Epoch: 910 [17335/17352 (100%)] Loss: -1143.208876\n",
      "    epoch          : 910\n",
      "    loss           : -1004.4976837908487\n",
      "    val_loss       : -746.5261051640194\n",
      "    val_log_likelihood: 1291.3512897451662\n",
      "    val_log_marginal: 769.2788107700129\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch910.pth ...\n",
      "Train Epoch: 911 [512/17352 (3%)] Loss: -1042.749634\n",
      "Train Epoch: 911 [10377/17352 (60%)] Loss: -1139.629883\n",
      "Train Epoch: 911 [16957/17352 (98%)] Loss: -1041.297928\n",
      "    epoch          : 911\n",
      "    loss           : -998.7186495982286\n",
      "    val_loss       : -729.9902563607891\n",
      "    val_log_likelihood: 1270.0825782288666\n",
      "    val_log_marginal: 747.8084513889542\n",
      "Train Epoch: 912 [512/17352 (3%)] Loss: -1051.697998\n",
      "Train Epoch: 912 [10895/17352 (63%)] Loss: -924.162075\n",
      "Train Epoch: 912 [16883/17352 (97%)] Loss: -894.905482\n",
      "    epoch          : 912\n",
      "    loss           : -924.8334932792831\n",
      "    val_loss       : -699.2706546290575\n",
      "    val_log_likelihood: 1258.5090469503784\n",
      "    val_log_marginal: 717.6849215001561\n",
      "Train Epoch: 913 [512/17352 (3%)] Loss: -1024.675903\n",
      "Train Epoch: 913 [10361/17352 (60%)] Loss: -832.504785\n",
      "Train Epoch: 913 [16923/17352 (98%)] Loss: -959.712225\n",
      "    epoch          : 913\n",
      "    loss           : -969.4118781331673\n",
      "    val_loss       : -746.0097806628476\n",
      "    val_log_likelihood: 1281.3315287604707\n",
      "    val_log_marginal: 769.8549462346061\n",
      "Train Epoch: 914 [512/17352 (3%)] Loss: -1032.277466\n",
      "Train Epoch: 914 [10344/17352 (60%)] Loss: -1021.798611\n",
      "Train Epoch: 914 [16883/17352 (97%)] Loss: -888.855188\n",
      "    epoch          : 914\n",
      "    loss           : -969.8969626368809\n",
      "    val_loss       : -726.0906264705224\n",
      "    val_log_likelihood: 1274.774435392507\n",
      "    val_log_marginal: 748.1977150318538\n",
      "Train Epoch: 915 [512/17352 (3%)] Loss: -1022.080872\n",
      "Train Epoch: 915 [10405/17352 (60%)] Loss: -994.141356\n",
      "Train Epoch: 915 [16883/17352 (97%)] Loss: -1109.492947\n",
      "    epoch          : 915\n",
      "    loss           : -942.6194148716473\n",
      "    val_loss       : -725.3299258394915\n",
      "    val_log_likelihood: 1282.56880355807\n",
      "    val_log_marginal: 748.6996362460104\n",
      "Train Epoch: 916 [512/17352 (3%)] Loss: -794.854675\n",
      "Train Epoch: 916 [10032/17352 (58%)] Loss: -1059.533777\n",
      "Train Epoch: 916 [16992/17352 (98%)] Loss: -1056.175761\n",
      "    epoch          : 916\n",
      "    loss           : -976.4302626930609\n",
      "    val_loss       : -726.5652720600082\n",
      "    val_log_likelihood: 1288.8934312677277\n",
      "    val_log_marginal: 741.719990659026\n",
      "Train Epoch: 917 [512/17352 (3%)] Loss: -1017.502686\n",
      "Train Epoch: 917 [10535/17352 (61%)] Loss: -1003.331518\n",
      "Train Epoch: 917 [17106/17352 (99%)] Loss: -1021.548944\n",
      "    epoch          : 917\n",
      "    loss           : -978.0921080947758\n",
      "    val_loss       : -675.5795778184201\n",
      "    val_log_likelihood: 1244.4114667832805\n",
      "    val_log_marginal: 700.2217619843668\n",
      "Train Epoch: 918 [512/17352 (3%)] Loss: -979.173767\n",
      "Train Epoch: 918 [10453/17352 (60%)] Loss: -1127.422635\n",
      "Train Epoch: 918 [17106/17352 (99%)] Loss: -991.454492\n",
      "    epoch          : 918\n",
      "    loss           : -917.2621524789628\n",
      "    val_loss       : -108.31901810157429\n",
      "    val_log_likelihood: 1230.3517279851803\n",
      "    val_log_marginal: 123.98986138734993\n",
      "Train Epoch: 919 [512/17352 (3%)] Loss: -535.816772\n",
      "Train Epoch: 919 [10104/17352 (58%)] Loss: -949.292751\n",
      "Train Epoch: 919 [16957/17352 (98%)] Loss: -682.398101\n",
      "    epoch          : 919\n",
      "    loss           : -687.0113864205298\n",
      "    val_loss       : -676.6989684761138\n",
      "    val_log_likelihood: 1247.0447522174154\n",
      "    val_log_marginal: 704.7332451951022\n",
      "Train Epoch: 920 [512/17352 (3%)] Loss: -943.390015\n",
      "Train Epoch: 920 [9787/17352 (56%)] Loss: -1003.866352\n",
      "Train Epoch: 920 [16939/17352 (98%)] Loss: -1064.896835\n",
      "    epoch          : 920\n",
      "    loss           : -944.7743801787517\n",
      "    val_loss       : -748.502801095182\n",
      "    val_log_likelihood: 1275.510051935842\n",
      "    val_log_marginal: 769.8844243086259\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch920.pth ...\n",
      "Train Epoch: 921 [512/17352 (3%)] Loss: -1002.541016\n",
      "Train Epoch: 921 [10342/17352 (60%)] Loss: -1006.850525\n",
      "Train Epoch: 921 [16872/17352 (97%)] Loss: -1045.397547\n",
      "    epoch          : 921\n",
      "    loss           : -976.5036851566756\n",
      "    val_loss       : -724.7450620811676\n",
      "    val_log_likelihood: 1283.6745064539668\n",
      "    val_log_marginal: 746.4216831047089\n",
      "Train Epoch: 922 [512/17352 (3%)] Loss: -1014.950256\n",
      "Train Epoch: 922 [9974/17352 (57%)] Loss: -877.366477\n",
      "Train Epoch: 922 [16887/17352 (97%)] Loss: -976.550692\n",
      "    epoch          : 922\n",
      "    loss           : -979.2853190669459\n",
      "    val_loss       : -731.238215153459\n",
      "    val_log_likelihood: 1290.0442959764237\n",
      "    val_log_marginal: 749.9958448544251\n",
      "Train Epoch: 923 [512/17352 (3%)] Loss: -972.140381\n",
      "Train Epoch: 923 [10076/17352 (58%)] Loss: -933.604428\n",
      "Train Epoch: 923 [16988/17352 (98%)] Loss: -921.329824\n",
      "    epoch          : 923\n",
      "    loss           : -934.3502727647199\n",
      "    val_loss       : -697.7869418341496\n",
      "    val_log_likelihood: 1275.1005767098602\n",
      "    val_log_marginal: 721.3803043066903\n",
      "Train Epoch: 924 [512/17352 (3%)] Loss: -985.189941\n",
      "Train Epoch: 924 [10453/17352 (60%)] Loss: -948.197173\n",
      "Train Epoch: 924 [16957/17352 (98%)] Loss: -1065.526367\n",
      "    epoch          : 924\n",
      "    loss           : -950.0564889957175\n",
      "    val_loss       : -712.7870666962799\n",
      "    val_log_likelihood: 1258.160423059068\n",
      "    val_log_marginal: 736.7184803499463\n",
      "Train Epoch: 925 [512/17352 (3%)] Loss: -847.968933\n",
      "Train Epoch: 925 [10256/17352 (59%)] Loss: -819.354911\n",
      "Train Epoch: 925 [17016/17352 (98%)] Loss: -750.312573\n",
      "    epoch          : 925\n",
      "    loss           : -852.7502249327187\n",
      "    val_loss       : -615.7896812595603\n",
      "    val_log_likelihood: 1209.2557213924629\n",
      "    val_log_marginal: 671.9593345919607\n",
      "Train Epoch: 926 [512/17352 (3%)] Loss: -693.510132\n",
      "Train Epoch: 926 [10561/17352 (61%)] Loss: -893.378198\n",
      "Train Epoch: 926 [16988/17352 (98%)] Loss: -1020.090104\n",
      "    epoch          : 926\n",
      "    loss           : -857.6064743899591\n",
      "    val_loss       : -629.2580497181724\n",
      "    val_log_likelihood: 1208.1512246024758\n",
      "    val_log_marginal: 678.301795782037\n",
      "Train Epoch: 927 [512/17352 (3%)] Loss: -676.120850\n",
      "Train Epoch: 927 [10385/17352 (60%)] Loss: -809.805376\n",
      "Train Epoch: 927 [17016/17352 (98%)] Loss: -921.086300\n",
      "    epoch          : 927\n",
      "    loss           : -955.7253722360996\n",
      "    val_loss       : -755.5751013510364\n",
      "    val_log_likelihood: 1273.933189334528\n",
      "    val_log_marginal: 779.9578525863885\n",
      "Train Epoch: 928 [512/17352 (3%)] Loss: -1027.671875\n",
      "Train Epoch: 928 [10255/17352 (59%)] Loss: -931.249209\n",
      "Train Epoch: 928 [17277/17352 (100%)] Loss: -891.728445\n",
      "    epoch          : 928\n",
      "    loss           : -999.8354253568597\n",
      "    val_loss       : -749.9267484925306\n",
      "    val_log_likelihood: 1278.1867083249297\n",
      "    val_log_marginal: 771.7243450848848\n",
      "Train Epoch: 929 [512/17352 (3%)] Loss: -811.706360\n",
      "Train Epoch: 929 [10237/17352 (59%)] Loss: -947.917315\n",
      "Train Epoch: 929 [16992/17352 (98%)] Loss: -973.326923\n",
      "    epoch          : 929\n",
      "    loss           : -1000.2220855288543\n",
      "    val_loss       : -758.69761624001\n",
      "    val_log_likelihood: 1288.341653939573\n",
      "    val_log_marginal: 779.3102285360892\n",
      "Train Epoch: 930 [512/17352 (3%)] Loss: -864.051208\n",
      "Train Epoch: 930 [10054/17352 (58%)] Loss: -1087.339557\n",
      "Train Epoch: 930 [16992/17352 (98%)] Loss: -962.487935\n",
      "    epoch          : 930\n",
      "    loss           : -997.3270234576174\n",
      "    val_loss       : -781.3042248955359\n",
      "    val_log_likelihood: 1295.970251626582\n",
      "    val_log_marginal: 798.2099028185588\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch930.pth ...\n",
      "Train Epoch: 931 [512/17352 (3%)] Loss: -1059.171753\n",
      "Train Epoch: 931 [10367/17352 (60%)] Loss: -990.264476\n",
      "Train Epoch: 931 [17090/17352 (98%)] Loss: -1090.365958\n",
      "    epoch          : 931\n",
      "    loss           : -1011.7899524866244\n",
      "    val_loss       : -779.5085865800819\n",
      "    val_log_likelihood: 1302.6780424996316\n",
      "    val_log_marginal: 803.5877106946484\n",
      "Train Epoch: 932 [512/17352 (3%)] Loss: -1067.914795\n",
      "Train Epoch: 932 [9742/17352 (56%)] Loss: -1130.589844\n",
      "Train Epoch: 932 [16872/17352 (97%)] Loss: -1043.626659\n",
      "    epoch          : 932\n",
      "    loss           : -1009.4966592721353\n",
      "    val_loss       : -775.3899771364598\n",
      "    val_log_likelihood: 1302.9349746827127\n",
      "    val_log_marginal: 796.9553734356182\n",
      "Train Epoch: 933 [512/17352 (3%)] Loss: -1064.675171\n",
      "Train Epoch: 933 [10508/17352 (61%)] Loss: -855.369422\n",
      "Train Epoch: 933 [16878/17352 (97%)] Loss: -1105.276875\n",
      "    epoch          : 933\n",
      "    loss           : -1014.6276532294946\n",
      "    val_loss       : -780.6809599482824\n",
      "    val_log_likelihood: 1309.488154621813\n",
      "    val_log_marginal: 799.7327815074224\n",
      "Train Epoch: 934 [512/17352 (3%)] Loss: -1039.126709\n",
      "Train Epoch: 934 [10269/17352 (59%)] Loss: -1112.982143\n",
      "Train Epoch: 934 [16939/17352 (98%)] Loss: -962.806311\n",
      "    epoch          : 934\n",
      "    loss           : -1013.9652008898058\n",
      "    val_loss       : -768.5510003397725\n",
      "    val_log_likelihood: 1306.947653223717\n",
      "    val_log_marginal: 789.0544816712452\n",
      "Train Epoch: 935 [512/17352 (3%)] Loss: -1058.944458\n",
      "Train Epoch: 935 [9626/17352 (55%)] Loss: -1159.094618\n",
      "Train Epoch: 935 [17153/17352 (99%)] Loss: -986.339286\n",
      "    epoch          : 935\n",
      "    loss           : -1002.8087359104647\n",
      "    val_loss       : -751.7693865846634\n",
      "    val_log_likelihood: 1290.9164780992096\n",
      "    val_log_marginal: 776.8993659153336\n",
      "Train Epoch: 936 [512/17352 (3%)] Loss: -1039.258667\n",
      "Train Epoch: 936 [10193/17352 (59%)] Loss: -937.934827\n",
      "Train Epoch: 936 [17106/17352 (99%)] Loss: -1077.452028\n",
      "    epoch          : 936\n",
      "    loss           : -955.4559397732575\n",
      "    val_loss       : -716.4423579214226\n",
      "    val_log_likelihood: 1282.111098580619\n",
      "    val_log_marginal: 752.1121177936072\n",
      "Train Epoch: 937 [512/17352 (3%)] Loss: -1004.314209\n",
      "Train Epoch: 937 [10549/17352 (61%)] Loss: -1010.367844\n",
      "Train Epoch: 937 [17124/17352 (99%)] Loss: -840.653633\n",
      "    epoch          : 937\n",
      "    loss           : -973.9114748430616\n",
      "    val_loss       : -750.5884460881653\n",
      "    val_log_likelihood: 1300.7807800229136\n",
      "    val_log_marginal: 770.9836797259452\n",
      "Train Epoch: 938 [512/17352 (3%)] Loss: -982.917236\n",
      "Train Epoch: 938 [9512/17352 (55%)] Loss: -1079.868504\n",
      "Train Epoch: 938 [17049/17352 (98%)] Loss: -920.811181\n",
      "    epoch          : 938\n",
      "    loss           : -998.945692947076\n",
      "    val_loss       : -750.7766093458322\n",
      "    val_log_likelihood: 1300.7472272406044\n",
      "    val_log_marginal: 774.8373343854513\n",
      "Train Epoch: 939 [512/17352 (3%)] Loss: -1037.106079\n",
      "Train Epoch: 939 [10850/17352 (63%)] Loss: -1041.503578\n",
      "Train Epoch: 939 [16887/17352 (97%)] Loss: -931.351004\n",
      "    epoch          : 939\n",
      "    loss           : -986.1463759820974\n",
      "    val_loss       : -734.8748910582133\n",
      "    val_log_likelihood: 1299.4608697825124\n",
      "    val_log_marginal: 755.8646402332915\n",
      "Train Epoch: 940 [512/17352 (3%)] Loss: -1037.952881\n",
      "Train Epoch: 940 [10433/17352 (60%)] Loss: -887.716077\n",
      "Train Epoch: 940 [17064/17352 (98%)] Loss: -888.481301\n",
      "    epoch          : 940\n",
      "    loss           : -935.8114091590876\n",
      "    val_loss       : -629.9223640446039\n",
      "    val_log_likelihood: 1271.6223399578075\n",
      "    val_log_marginal: 645.008064100625\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch940.pth ...\n",
      "Train Epoch: 941 [512/17352 (3%)] Loss: -726.832092\n",
      "Train Epoch: 941 [10671/17352 (61%)] Loss: -917.574132\n",
      "Train Epoch: 941 [16957/17352 (98%)] Loss: -968.935658\n",
      "    epoch          : 941\n",
      "    loss           : -941.13138213391\n",
      "    val_loss       : -728.594163828171\n",
      "    val_log_likelihood: 1293.313910753591\n",
      "    val_log_marginal: 751.6591702022823\n",
      "Train Epoch: 942 [512/17352 (3%)] Loss: -1014.789490\n",
      "Train Epoch: 942 [10274/17352 (59%)] Loss: -882.475306\n",
      "Train Epoch: 942 [17253/17352 (99%)] Loss: -990.039982\n",
      "    epoch          : 942\n",
      "    loss           : -986.0130216381965\n",
      "    val_loss       : -657.7244374872564\n",
      "    val_log_likelihood: 1293.0427661811561\n",
      "    val_log_marginal: 681.9133418153673\n",
      "Train Epoch: 943 [512/17352 (3%)] Loss: -952.166992\n",
      "Train Epoch: 943 [10279/17352 (59%)] Loss: -930.021713\n",
      "Train Epoch: 943 [16882/17352 (97%)] Loss: -976.581597\n",
      "    epoch          : 943\n",
      "    loss           : -977.7214641747414\n",
      "    val_loss       : -763.5734232265174\n",
      "    val_log_likelihood: 1292.4488753741377\n",
      "    val_log_marginal: 776.2713812212819\n",
      "Train Epoch: 944 [512/17352 (3%)] Loss: -843.601074\n",
      "Train Epoch: 944 [10294/17352 (59%)] Loss: -1049.703320\n",
      "Train Epoch: 944 [16992/17352 (98%)] Loss: -1043.500477\n",
      "    epoch          : 944\n",
      "    loss           : -1004.2774306403015\n",
      "    val_loss       : -758.088041775324\n",
      "    val_log_likelihood: 1303.8946861582542\n",
      "    val_log_marginal: 777.5205484121767\n",
      "Train Epoch: 945 [512/17352 (3%)] Loss: -1024.193481\n",
      "Train Epoch: 945 [10448/17352 (60%)] Loss: -794.676258\n",
      "Train Epoch: 945 [17108/17352 (99%)] Loss: -1057.896659\n",
      "    epoch          : 945\n",
      "    loss           : -980.6156928001064\n",
      "    val_loss       : -736.6971652176417\n",
      "    val_log_likelihood: 1284.5323448369413\n",
      "    val_log_marginal: 753.9127409134995\n",
      "Train Epoch: 946 [512/17352 (3%)] Loss: -1020.062927\n",
      "Train Epoch: 946 [10622/17352 (61%)] Loss: -966.327102\n",
      "Train Epoch: 946 [17277/17352 (100%)] Loss: -959.928022\n",
      "    epoch          : 946\n",
      "    loss           : -1015.6228196875761\n",
      "    val_loss       : -754.4317560192819\n",
      "    val_log_likelihood: 1299.6465097864034\n",
      "    val_log_marginal: 773.0418307837984\n",
      "Train Epoch: 947 [512/17352 (3%)] Loss: -1059.394043\n",
      "Train Epoch: 947 [9996/17352 (58%)] Loss: -1055.550371\n",
      "Train Epoch: 947 [17143/17352 (99%)] Loss: -1043.176693\n",
      "    epoch          : 947\n",
      "    loss           : -1019.8496215218906\n",
      "    val_loss       : -747.1616688112119\n",
      "    val_log_likelihood: 1311.1503026535613\n",
      "    val_log_marginal: 768.6998994528027\n",
      "Train Epoch: 948 [512/17352 (3%)] Loss: -1052.175293\n",
      "Train Epoch: 948 [10385/17352 (60%)] Loss: -1118.745411\n",
      "Train Epoch: 948 [16988/17352 (98%)] Loss: -935.581564\n",
      "    epoch          : 948\n",
      "    loss           : -1017.2493794655536\n",
      "    val_loss       : -772.0692388100272\n",
      "    val_log_likelihood: 1312.95996169088\n",
      "    val_log_marginal: 791.334954498635\n",
      "Train Epoch: 949 [512/17352 (3%)] Loss: -1073.873291\n",
      "Train Epoch: 949 [10165/17352 (59%)] Loss: -1123.567835\n",
      "Train Epoch: 949 [17253/17352 (99%)] Loss: -858.689757\n",
      "    epoch          : 949\n",
      "    loss           : -1002.256195216637\n",
      "    val_loss       : -696.0846044003487\n",
      "    val_log_likelihood: 1289.044008639979\n",
      "    val_log_marginal: 715.6060193923962\n",
      "Train Epoch: 950 [512/17352 (3%)] Loss: -1000.763123\n",
      "Train Epoch: 950 [10128/17352 (58%)] Loss: -1027.430959\n",
      "Train Epoch: 950 [16992/17352 (98%)] Loss: -1099.252532\n",
      "    epoch          : 950\n",
      "    loss           : -980.0491260627547\n",
      "    val_loss       : -738.0679827434416\n",
      "    val_log_likelihood: 1295.9500285634156\n",
      "    val_log_marginal: 752.3797218311234\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch950.pth ...\n",
      "Train Epoch: 951 [512/17352 (3%)] Loss: -1018.437134\n",
      "Train Epoch: 951 [9870/17352 (57%)] Loss: -889.382426\n",
      "Train Epoch: 951 [17153/17352 (99%)] Loss: -1113.467861\n",
      "    epoch          : 951\n",
      "    loss           : -996.6333128556595\n",
      "    val_loss       : -710.6352791557404\n",
      "    val_log_likelihood: 1297.256346922382\n",
      "    val_log_marginal: 730.8746240810364\n",
      "Train Epoch: 952 [512/17352 (3%)] Loss: -1007.345520\n",
      "Train Epoch: 952 [10043/17352 (58%)] Loss: -1001.270123\n",
      "Train Epoch: 952 [16883/17352 (97%)] Loss: -938.280032\n",
      "    epoch          : 952\n",
      "    loss           : -1007.2109839333751\n",
      "    val_loss       : -769.2822362597352\n",
      "    val_log_likelihood: 1310.8930880295775\n",
      "    val_log_marginal: 789.932673921172\n",
      "Train Epoch: 953 [512/17352 (3%)] Loss: -1068.228760\n",
      "Train Epoch: 953 [10613/17352 (61%)] Loss: -901.504538\n",
      "Train Epoch: 953 [16922/17352 (98%)] Loss: -1116.622473\n",
      "    epoch          : 953\n",
      "    loss           : -1012.2213783017135\n",
      "    val_loss       : -724.5848611252936\n",
      "    val_log_likelihood: 1287.8614814387856\n",
      "    val_log_marginal: 749.0058148057984\n",
      "Train Epoch: 954 [512/17352 (3%)] Loss: -1028.502930\n",
      "Train Epoch: 954 [9850/17352 (57%)] Loss: -1048.098958\n",
      "Train Epoch: 954 [17335/17352 (100%)] Loss: -1034.143466\n",
      "    epoch          : 954\n",
      "    loss           : -1007.7860427311286\n",
      "    val_loss       : -750.7529647237584\n",
      "    val_log_likelihood: 1303.4401679411328\n",
      "    val_log_marginal: 762.1515258619921\n",
      "Train Epoch: 955 [512/17352 (3%)] Loss: -1040.375488\n",
      "Train Epoch: 955 [10213/17352 (59%)] Loss: -1068.739372\n",
      "Train Epoch: 955 [17143/17352 (99%)] Loss: -945.906163\n",
      "    epoch          : 955\n",
      "    loss           : -1000.3543456933534\n",
      "    val_loss       : -754.463584177953\n",
      "    val_log_likelihood: 1306.2321042305284\n",
      "    val_log_marginal: 780.2837103639429\n",
      "Train Epoch: 956 [512/17352 (3%)] Loss: -1047.930176\n",
      "Train Epoch: 956 [10601/17352 (61%)] Loss: -961.773734\n",
      "Train Epoch: 956 [17335/17352 (100%)] Loss: -1097.789340\n",
      "    epoch          : 956\n",
      "    loss           : -1016.8426221734125\n",
      "    val_loss       : -751.1658636398813\n",
      "    val_log_likelihood: 1308.4627057367309\n",
      "    val_log_marginal: 769.109986511403\n",
      "Train Epoch: 957 [512/17352 (3%)] Loss: -1066.315186\n",
      "Train Epoch: 957 [10458/17352 (60%)] Loss: -960.397503\n",
      "Train Epoch: 957 [16872/17352 (97%)] Loss: -1137.818024\n",
      "    epoch          : 957\n",
      "    loss           : -1013.5274292788038\n",
      "    val_loss       : -732.8572097333614\n",
      "    val_log_likelihood: 1295.8486464441105\n",
      "    val_log_marginal: 748.5346846617307\n",
      "Train Epoch: 958 [512/17352 (3%)] Loss: -1047.153320\n",
      "Train Epoch: 958 [10169/17352 (59%)] Loss: -841.233468\n",
      "Train Epoch: 958 [17044/17352 (98%)] Loss: -931.686752\n",
      "    epoch          : 958\n",
      "    loss           : -993.9706633236755\n",
      "    val_loss       : -749.2201307961061\n",
      "    val_log_likelihood: 1311.6040329632704\n",
      "    val_log_marginal: 774.8467770576939\n",
      "Train Epoch: 959 [512/17352 (3%)] Loss: -1045.871582\n",
      "Train Epoch: 959 [10116/17352 (58%)] Loss: -1106.317708\n",
      "Train Epoch: 959 [16883/17352 (97%)] Loss: -1069.231445\n",
      "    epoch          : 959\n",
      "    loss           : -1015.9606661372159\n",
      "    val_loss       : -759.467756990239\n",
      "    val_log_likelihood: 1306.7572432181926\n",
      "    val_log_marginal: 777.1469112033682\n",
      "Train Epoch: 960 [512/17352 (3%)] Loss: -1045.590942\n",
      "Train Epoch: 960 [10525/17352 (61%)] Loss: -948.277690\n",
      "Train Epoch: 960 [17277/17352 (100%)] Loss: -1125.141117\n",
      "    epoch          : 960\n",
      "    loss           : -1014.207130510539\n",
      "    val_loss       : -735.8563959063665\n",
      "    val_log_likelihood: 1303.279479604095\n",
      "    val_log_marginal: 758.245082455498\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch960.pth ...\n",
      "Train Epoch: 961 [512/17352 (3%)] Loss: -1044.299072\n",
      "Train Epoch: 961 [10265/17352 (59%)] Loss: -1050.739680\n",
      "Train Epoch: 961 [16958/17352 (98%)] Loss: -1115.135290\n",
      "    epoch          : 961\n",
      "    loss           : -1003.6709527073335\n",
      "    val_loss       : -758.6044922900014\n",
      "    val_log_likelihood: 1308.6492388766178\n",
      "    val_log_marginal: 774.9790661403891\n",
      "Train Epoch: 962 [512/17352 (3%)] Loss: -1056.385986\n",
      "Train Epoch: 962 [10172/17352 (59%)] Loss: -1042.606445\n",
      "Train Epoch: 962 [17124/17352 (99%)] Loss: -859.362908\n",
      "    epoch          : 962\n",
      "    loss           : -986.9657627082394\n",
      "    val_loss       : -713.486816525408\n",
      "    val_log_likelihood: 1279.9276962160263\n",
      "    val_log_marginal: 736.3552876390564\n",
      "Train Epoch: 963 [512/17352 (3%)] Loss: -1004.171326\n",
      "Train Epoch: 963 [10030/17352 (58%)] Loss: -873.015427\n",
      "Train Epoch: 963 [17133/17352 (99%)] Loss: -844.666151\n",
      "    epoch          : 963\n",
      "    loss           : -989.2833615208431\n",
      "    val_loss       : -696.0235513820741\n",
      "    val_log_likelihood: 1290.930933171932\n",
      "    val_log_marginal: 713.8360339123426\n",
      "Train Epoch: 964 [512/17352 (3%)] Loss: -1017.578796\n",
      "Train Epoch: 964 [10621/17352 (61%)] Loss: -1055.428938\n",
      "Train Epoch: 964 [17126/17352 (99%)] Loss: -1030.774527\n",
      "    epoch          : 964\n",
      "    loss           : -991.8047213827315\n",
      "    val_loss       : -710.2506400101506\n",
      "    val_log_likelihood: 1297.9982160448403\n",
      "    val_log_marginal: 726.134889534381\n",
      "Train Epoch: 965 [512/17352 (3%)] Loss: -1011.237915\n",
      "Train Epoch: 965 [10094/17352 (58%)] Loss: -914.610795\n",
      "Train Epoch: 965 [16882/17352 (97%)] Loss: -914.642494\n",
      "    epoch          : 965\n",
      "    loss           : -1002.952692169515\n",
      "    val_loss       : -755.192791989131\n",
      "    val_log_likelihood: 1315.1881033804814\n",
      "    val_log_marginal: 776.1494608330308\n",
      "Train Epoch: 966 [512/17352 (3%)] Loss: -1054.971924\n",
      "Train Epoch: 966 [10343/17352 (60%)] Loss: -933.501846\n",
      "Train Epoch: 966 [17090/17352 (98%)] Loss: -947.682899\n",
      "    epoch          : 966\n",
      "    loss           : -1016.873280719549\n",
      "    val_loss       : -752.9818014798163\n",
      "    val_log_likelihood: 1310.705497157156\n",
      "    val_log_marginal: 772.6959586885391\n",
      "Train Epoch: 967 [512/17352 (3%)] Loss: -1060.928467\n",
      "Train Epoch: 967 [10596/17352 (61%)] Loss: -1057.408789\n",
      "Train Epoch: 967 [16923/17352 (98%)] Loss: -1070.113009\n",
      "    epoch          : 967\n",
      "    loss           : -1017.3541409666929\n",
      "    val_loss       : -761.3181258769041\n",
      "    val_log_likelihood: 1318.0066467068332\n",
      "    val_log_marginal: 780.0284225665645\n",
      "Train Epoch: 968 [512/17352 (3%)] Loss: -1049.196167\n",
      "Train Epoch: 968 [10583/17352 (61%)] Loss: -865.495589\n",
      "Train Epoch: 968 [17106/17352 (99%)] Loss: -1060.347622\n",
      "    epoch          : 968\n",
      "    loss           : -1028.7000186117384\n",
      "    val_loss       : -768.4222687559584\n",
      "    val_log_likelihood: 1321.2711705221134\n",
      "    val_log_marginal: 786.7114473262823\n",
      "Train Epoch: 969 [512/17352 (3%)] Loss: -1077.708618\n",
      "Train Epoch: 969 [10478/17352 (60%)] Loss: -1112.127538\n",
      "Train Epoch: 969 [17090/17352 (98%)] Loss: -1006.217716\n",
      "    epoch          : 969\n",
      "    loss           : -1023.7449316531804\n",
      "    val_loss       : -757.0488190645938\n",
      "    val_log_likelihood: 1297.0460304484347\n",
      "    val_log_marginal: 770.6213488584847\n",
      "Train Epoch: 970 [512/17352 (3%)] Loss: -1047.921143\n",
      "Train Epoch: 970 [10190/17352 (59%)] Loss: -803.540751\n",
      "Train Epoch: 970 [16923/17352 (98%)] Loss: -778.972264\n",
      "    epoch          : 970\n",
      "    loss           : -886.8239421249749\n",
      "    val_loss       : -633.527068067068\n",
      "    val_log_likelihood: 1252.7621980341876\n",
      "    val_log_marginal: 655.548899928832\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch970.pth ...\n",
      "Train Epoch: 971 [512/17352 (3%)] Loss: -945.978638\n",
      "Train Epoch: 971 [10180/17352 (59%)] Loss: -1037.590833\n",
      "Train Epoch: 971 [17108/17352 (99%)] Loss: -1006.352316\n",
      "    epoch          : 971\n",
      "    loss           : -874.3882709885443\n",
      "    val_loss       : -696.1591134667326\n",
      "    val_log_likelihood: 1270.0887331033791\n",
      "    val_log_marginal: 716.6650046973083\n",
      "Train Epoch: 972 [512/17352 (3%)] Loss: -975.746582\n",
      "Train Epoch: 972 [10903/17352 (63%)] Loss: -941.878646\n",
      "Train Epoch: 972 [17016/17352 (98%)] Loss: -843.917913\n",
      "    epoch          : 972\n",
      "    loss           : -988.3614208140283\n",
      "    val_loss       : -746.6608025557438\n",
      "    val_log_likelihood: 1295.8147097006156\n",
      "    val_log_marginal: 768.8320748269227\n",
      "Train Epoch: 973 [512/17352 (3%)] Loss: -1045.952515\n",
      "Train Epoch: 973 [10747/17352 (62%)] Loss: -1104.118737\n",
      "Train Epoch: 973 [16939/17352 (98%)] Loss: -945.844878\n",
      "    epoch          : 973\n",
      "    loss           : -1003.8828575292224\n",
      "    val_loss       : -753.4881150093886\n",
      "    val_log_likelihood: 1303.8428749458733\n",
      "    val_log_marginal: 772.9970739288722\n",
      "Train Epoch: 974 [512/17352 (3%)] Loss: -1080.294800\n",
      "Train Epoch: 974 [10667/17352 (61%)] Loss: -953.367898\n",
      "Train Epoch: 974 [16939/17352 (98%)] Loss: -1080.684646\n",
      "    epoch          : 974\n",
      "    loss           : -1012.4070238964026\n",
      "    val_loss       : -774.1914603473601\n",
      "    val_log_likelihood: 1320.8027820165871\n",
      "    val_log_marginal: 796.6495314736655\n",
      "Train Epoch: 975 [512/17352 (3%)] Loss: -1076.988159\n",
      "Train Epoch: 975 [10363/17352 (60%)] Loss: -1085.379271\n",
      "Train Epoch: 975 [17143/17352 (99%)] Loss: -937.349035\n",
      "    epoch          : 975\n",
      "    loss           : -985.1607530979949\n",
      "    val_loss       : -680.3633763938567\n",
      "    val_log_likelihood: 1271.9601405443645\n",
      "    val_log_marginal: 700.0793033441348\n",
      "Train Epoch: 976 [512/17352 (3%)] Loss: -967.244080\n",
      "Train Epoch: 976 [9830/17352 (57%)] Loss: -977.810202\n",
      "Train Epoch: 976 [16883/17352 (97%)] Loss: -944.949168\n",
      "    epoch          : 976\n",
      "    loss           : -991.5430399412301\n",
      "    val_loss       : -752.8114256049846\n",
      "    val_log_likelihood: 1315.7562696066727\n",
      "    val_log_marginal: 769.4331990204035\n",
      "Train Epoch: 977 [512/17352 (3%)] Loss: -1065.450562\n",
      "Train Epoch: 977 [9687/17352 (56%)] Loss: -1033.980417\n",
      "Train Epoch: 977 [16882/17352 (97%)] Loss: -898.365057\n",
      "    epoch          : 977\n",
      "    loss           : -960.9324896740615\n",
      "    val_loss       : -734.4763508780753\n",
      "    val_log_likelihood: 1300.5670765181355\n",
      "    val_log_marginal: 764.2892423479336\n",
      "Train Epoch: 978 [512/17352 (3%)] Loss: -1041.692261\n",
      "Train Epoch: 978 [10064/17352 (58%)] Loss: -1042.858747\n",
      "Train Epoch: 978 [16939/17352 (98%)] Loss: -880.477099\n",
      "    epoch          : 978\n",
      "    loss           : -990.082746350785\n",
      "    val_loss       : -735.9051077453587\n",
      "    val_log_likelihood: 1304.1139842017285\n",
      "    val_log_marginal: 756.6037447778674\n",
      "Train Epoch: 979 [512/17352 (3%)] Loss: -1059.795654\n",
      "Train Epoch: 979 [9939/17352 (57%)] Loss: -1033.278325\n",
      "Train Epoch: 979 [16887/17352 (97%)] Loss: -1063.389761\n",
      "    epoch          : 979\n",
      "    loss           : -951.653088723475\n",
      "    val_loss       : -744.7880316303784\n",
      "    val_log_likelihood: 1299.6708109937192\n",
      "    val_log_marginal: 762.5330748981197\n",
      "Train Epoch: 980 [512/17352 (3%)] Loss: -1036.945190\n",
      "Train Epoch: 980 [10565/17352 (61%)] Loss: -1056.982485\n",
      "Train Epoch: 980 [17049/17352 (98%)] Loss: -728.102177\n",
      "    epoch          : 980\n",
      "    loss           : -953.800011420704\n",
      "    val_loss       : -701.9811196978422\n",
      "    val_log_likelihood: 1271.7430783852374\n",
      "    val_log_marginal: 732.8285116446272\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch980.pth ...\n",
      "Train Epoch: 981 [512/17352 (3%)] Loss: -1005.392517\n",
      "Train Epoch: 981 [10340/17352 (60%)] Loss: -751.743944\n",
      "Train Epoch: 981 [16872/17352 (97%)] Loss: -831.472043\n",
      "    epoch          : 981\n",
      "    loss           : -922.8143897466227\n",
      "    val_loss       : -736.6602970775125\n",
      "    val_log_likelihood: 1301.6772999842728\n",
      "    val_log_marginal: 764.5984498521643\n",
      "Train Epoch: 982 [512/17352 (3%)] Loss: -1038.239624\n",
      "Train Epoch: 982 [10339/17352 (60%)] Loss: -889.579923\n",
      "Train Epoch: 982 [17153/17352 (99%)] Loss: -911.845992\n",
      "    epoch          : 982\n",
      "    loss           : -963.4519835231132\n",
      "    val_loss       : -694.4761466902222\n",
      "    val_log_likelihood: 1287.93301616739\n",
      "    val_log_marginal: 712.9856819331068\n",
      "Train Epoch: 983 [512/17352 (3%)] Loss: -949.185547\n",
      "Train Epoch: 983 [10577/17352 (61%)] Loss: -1091.975237\n",
      "Train Epoch: 983 [17133/17352 (99%)] Loss: -1127.418054\n",
      "    epoch          : 983\n",
      "    loss           : -1002.6433949434896\n",
      "    val_loss       : -759.2714024835855\n",
      "    val_log_likelihood: 1312.2606805688474\n",
      "    val_log_marginal: 778.272435704049\n",
      "Train Epoch: 984 [512/17352 (3%)] Loss: -1040.305298\n",
      "Train Epoch: 984 [11077/17352 (64%)] Loss: -874.943705\n",
      "Train Epoch: 984 [17277/17352 (100%)] Loss: -1039.372376\n",
      "    epoch          : 984\n",
      "    loss           : -1016.4677929403615\n",
      "    val_loss       : -749.6945803633888\n",
      "    val_log_likelihood: 1308.4269582507397\n",
      "    val_log_marginal: 770.4845161221652\n",
      "Train Epoch: 985 [512/17352 (3%)] Loss: -869.325623\n",
      "Train Epoch: 985 [10313/17352 (59%)] Loss: -969.326287\n",
      "Train Epoch: 985 [17126/17352 (99%)] Loss: -1075.347876\n",
      "    epoch          : 985\n",
      "    loss           : -960.3794878085317\n",
      "    val_loss       : -684.3678774715805\n",
      "    val_log_likelihood: 1296.1558186661998\n",
      "    val_log_marginal: 700.8756432949308\n",
      "Train Epoch: 986 [512/17352 (3%)] Loss: -998.500610\n",
      "Train Epoch: 986 [10198/17352 (59%)] Loss: -1055.522142\n",
      "Train Epoch: 986 [16939/17352 (98%)] Loss: -1039.806641\n",
      "    epoch          : 986\n",
      "    loss           : -981.6886708257601\n",
      "    val_loss       : -724.5597930431938\n",
      "    val_log_likelihood: 1278.3735665410443\n",
      "    val_log_marginal: 744.231593323487\n",
      "Train Epoch: 987 [512/17352 (3%)] Loss: -1042.128174\n",
      "Train Epoch: 987 [10396/17352 (60%)] Loss: -923.031901\n",
      "Train Epoch: 987 [16887/17352 (97%)] Loss: -1004.097610\n",
      "    epoch          : 987\n",
      "    loss           : -1002.5478786639862\n",
      "    val_loss       : -740.3745808853721\n",
      "    val_log_likelihood: 1310.63706751876\n",
      "    val_log_marginal: 767.2342158474266\n",
      "Train Epoch: 988 [512/17352 (3%)] Loss: -1051.272461\n",
      "Train Epoch: 988 [10474/17352 (60%)] Loss: -898.226691\n",
      "Train Epoch: 988 [17124/17352 (99%)] Loss: -1089.246005\n",
      "    epoch          : 988\n",
      "    loss           : -1018.343943060198\n",
      "    val_loss       : -711.7614425034396\n",
      "    val_log_likelihood: 1297.9986317204937\n",
      "    val_log_marginal: 729.9186532583778\n",
      "Train Epoch: 989 [512/17352 (3%)] Loss: -1018.700195\n",
      "Train Epoch: 989 [10709/17352 (62%)] Loss: -1002.331510\n",
      "Train Epoch: 989 [17090/17352 (98%)] Loss: -378.556590\n",
      "    epoch          : 989\n",
      "    loss           : -919.7446920323048\n",
      "    val_loss       : -624.1066518645744\n",
      "    val_log_likelihood: 1261.940544695206\n",
      "    val_log_marginal: 649.2547029003999\n",
      "Train Epoch: 990 [512/17352 (3%)] Loss: -939.511108\n",
      "Train Epoch: 990 [10410/17352 (60%)] Loss: -853.262168\n",
      "Train Epoch: 990 [17101/17352 (99%)] Loss: -925.784151\n",
      "    epoch          : 990\n",
      "    loss           : -834.8020322317121\n",
      "    val_loss       : -665.3527634345343\n",
      "    val_log_likelihood: 1256.1317279823015\n",
      "    val_log_marginal: 683.8151887093326\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch990.pth ...\n",
      "Train Epoch: 991 [512/17352 (3%)] Loss: -1002.805298\n",
      "Train Epoch: 991 [10074/17352 (58%)] Loss: -811.816537\n",
      "Train Epoch: 991 [17049/17352 (98%)] Loss: -1070.112074\n",
      "    epoch          : 991\n",
      "    loss           : -980.8715500079795\n",
      "    val_loss       : -666.43708297704\n",
      "    val_log_likelihood: 1283.6924264668942\n",
      "    val_log_marginal: 689.2170740166449\n",
      "Train Epoch: 992 [512/17352 (3%)] Loss: -997.449890\n",
      "Train Epoch: 992 [10582/17352 (61%)] Loss: -909.354516\n",
      "Train Epoch: 992 [17133/17352 (99%)] Loss: -961.752056\n",
      "    epoch          : 992\n",
      "    loss           : -987.1510767174215\n",
      "    val_loss       : -707.9968043007913\n",
      "    val_log_likelihood: 1267.7046185657082\n",
      "    val_log_marginal: 732.0679929813018\n",
      "Train Epoch: 993 [512/17352 (3%)] Loss: -1025.738403\n",
      "Train Epoch: 993 [10393/17352 (60%)] Loss: -890.078032\n",
      "Train Epoch: 993 [16887/17352 (97%)] Loss: -1027.230166\n",
      "    epoch          : 993\n",
      "    loss           : -994.3036484549511\n",
      "    val_loss       : -733.8767496597112\n",
      "    val_log_likelihood: 1304.891455120491\n",
      "    val_log_marginal: 755.2659341787518\n",
      "Train Epoch: 994 [512/17352 (3%)] Loss: -1045.583984\n",
      "Train Epoch: 994 [10153/17352 (59%)] Loss: -1083.197917\n",
      "Train Epoch: 994 [17126/17352 (99%)] Loss: -1023.282703\n",
      "    epoch          : 994\n",
      "    loss           : -997.4672807899276\n",
      "    val_loss       : -605.1532476938523\n",
      "    val_log_likelihood: 1297.0337879367632\n",
      "    val_log_marginal: 624.9822839393556\n",
      "Train Epoch: 995 [512/17352 (3%)] Loss: -942.165039\n",
      "Train Epoch: 995 [10281/17352 (59%)] Loss: -1041.564284\n",
      "Train Epoch: 995 [16934/17352 (98%)] Loss: -990.162570\n",
      "    epoch          : 995\n",
      "    loss           : -970.5063583364899\n",
      "    val_loss       : -708.2888994648774\n",
      "    val_log_likelihood: 1289.1353749163538\n",
      "    val_log_marginal: 748.0854973867541\n",
      "Train Epoch: 996 [512/17352 (3%)] Loss: -963.201904\n",
      "Train Epoch: 996 [10140/17352 (58%)] Loss: -956.321250\n",
      "Train Epoch: 996 [17044/17352 (98%)] Loss: -1014.358040\n",
      "    epoch          : 996\n",
      "    loss           : -907.0834442063435\n",
      "    val_loss       : -631.0644740222987\n",
      "    val_log_likelihood: 1223.2857751770534\n",
      "    val_log_marginal: 670.970036124014\n",
      "Train Epoch: 997 [512/17352 (3%)] Loss: -899.323853\n",
      "Train Epoch: 997 [10256/17352 (59%)] Loss: -1090.944741\n",
      "Train Epoch: 997 [16923/17352 (98%)] Loss: -1012.659430\n",
      "    epoch          : 997\n",
      "    loss           : -974.3501607941267\n",
      "    val_loss       : -718.8351159717621\n",
      "    val_log_likelihood: 1286.522981455472\n",
      "    val_log_marginal: 742.9865232737731\n",
      "Train Epoch: 998 [512/17352 (3%)] Loss: -1047.455933\n",
      "Train Epoch: 998 [10353/17352 (60%)] Loss: -1008.615528\n",
      "Train Epoch: 998 [16923/17352 (98%)] Loss: -1136.047972\n",
      "    epoch          : 998\n",
      "    loss           : -989.2015747466139\n",
      "    val_loss       : -762.5361402415472\n",
      "    val_log_likelihood: 1316.3464422567297\n",
      "    val_log_marginal: 790.111196938331\n",
      "Train Epoch: 999 [512/17352 (3%)] Loss: -1064.522461\n",
      "Train Epoch: 999 [9852/17352 (57%)] Loss: -890.214831\n",
      "Train Epoch: 999 [17108/17352 (99%)] Loss: -931.946796\n",
      "    epoch          : 999\n",
      "    loss           : -1014.5693517366946\n",
      "    val_loss       : -774.6276915017752\n",
      "    val_log_likelihood: 1321.9585363937133\n",
      "    val_log_marginal: 793.3262265966732\n",
      "Train Epoch: 1000 [512/17352 (3%)] Loss: -1080.583008\n",
      "Train Epoch: 1000 [10145/17352 (58%)] Loss: -1096.741534\n",
      "Train Epoch: 1000 [17153/17352 (99%)] Loss: -1105.639535\n",
      "    epoch          : 1000\n",
      "    loss           : -1033.819092283826\n",
      "    val_loss       : -778.6231449881042\n",
      "    val_log_likelihood: 1320.512407491381\n",
      "    val_log_marginal: 793.5842926247941\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch1000.pth ...\n",
      "Train Epoch: 1001 [512/17352 (3%)] Loss: -1095.888916\n",
      "Train Epoch: 1001 [9983/17352 (58%)] Loss: -924.855769\n",
      "Train Epoch: 1001 [16958/17352 (98%)] Loss: -1142.541311\n",
      "    epoch          : 1001\n",
      "    loss           : -1039.9625580978914\n",
      "    val_loss       : -769.2055036476947\n",
      "    val_log_likelihood: 1321.8640182633403\n",
      "    val_log_marginal: 788.435761024408\n",
      "Train Epoch: 1002 [512/17352 (3%)] Loss: -1083.445923\n",
      "Train Epoch: 1002 [10339/17352 (60%)] Loss: -1072.691347\n",
      "Train Epoch: 1002 [17101/17352 (99%)] Loss: -1181.725803\n",
      "    epoch          : 1002\n",
      "    loss           : -1036.9570156920518\n",
      "    val_loss       : -765.8061837307813\n",
      "    val_log_likelihood: 1325.7830936036517\n",
      "    val_log_marginal: 787.8624668091993\n",
      "Train Epoch: 1003 [512/17352 (3%)] Loss: -1072.768921\n",
      "Train Epoch: 1003 [10006/17352 (58%)] Loss: -1135.671598\n",
      "Train Epoch: 1003 [16882/17352 (97%)] Loss: -1091.403111\n",
      "    epoch          : 1003\n",
      "    loss           : -1035.0504408703428\n",
      "    val_loss       : -761.170380684786\n",
      "    val_log_likelihood: 1322.5243795309975\n",
      "    val_log_marginal: 781.1758723599332\n",
      "Train Epoch: 1004 [512/17352 (3%)] Loss: -1066.634766\n",
      "Train Epoch: 1004 [10568/17352 (61%)] Loss: -908.917249\n",
      "Train Epoch: 1004 [16872/17352 (97%)] Loss: -1043.316636\n",
      "    epoch          : 1004\n",
      "    loss           : -1035.1419191806524\n",
      "    val_loss       : -786.3524884802722\n",
      "    val_log_likelihood: 1333.2117876588825\n",
      "    val_log_marginal: 802.0909286633745\n",
      "Train Epoch: 1005 [512/17352 (3%)] Loss: -1081.140747\n",
      "Train Epoch: 1005 [10612/17352 (61%)] Loss: -972.715461\n",
      "Train Epoch: 1005 [17126/17352 (99%)] Loss: -981.399130\n",
      "    epoch          : 1005\n",
      "    loss           : -1030.7694155787522\n",
      "    val_loss       : -765.4127649896291\n",
      "    val_log_likelihood: 1325.8718113197579\n",
      "    val_log_marginal: 782.695608779223\n",
      "Train Epoch: 1006 [512/17352 (3%)] Loss: -1065.792236\n",
      "Train Epoch: 1006 [10599/17352 (61%)] Loss: -1115.208122\n",
      "Train Epoch: 1006 [17253/17352 (99%)] Loss: -948.415819\n",
      "    epoch          : 1006\n",
      "    loss           : -1036.2358078959735\n",
      "    val_loss       : -769.7100196119119\n",
      "    val_log_likelihood: 1328.625361428206\n",
      "    val_log_marginal: 789.6629399381643\n",
      "Train Epoch: 1007 [512/17352 (3%)] Loss: -1073.847656\n",
      "Train Epoch: 1007 [10348/17352 (60%)] Loss: -950.688109\n",
      "Train Epoch: 1007 [16992/17352 (98%)] Loss: -1025.366319\n",
      "    epoch          : 1007\n",
      "    loss           : -1038.9525681687396\n",
      "    val_loss       : -744.5319236448445\n",
      "    val_log_likelihood: 1320.490934605986\n",
      "    val_log_marginal: 761.4674153768102\n",
      "Train Epoch: 1008 [512/17352 (3%)] Loss: -1069.209351\n",
      "Train Epoch: 1008 [9974/17352 (57%)] Loss: -1105.595728\n",
      "Train Epoch: 1008 [16934/17352 (98%)] Loss: -945.366702\n",
      "    epoch          : 1008\n",
      "    loss           : -1016.9313741108882\n",
      "    val_loss       : -763.5427797311406\n",
      "    val_log_likelihood: 1332.309440180955\n",
      "    val_log_marginal: 781.9130334571437\n",
      "Train Epoch: 1009 [512/17352 (3%)] Loss: -1069.472168\n",
      "Train Epoch: 1009 [10282/17352 (59%)] Loss: -1123.510200\n",
      "Train Epoch: 1009 [16878/17352 (97%)] Loss: -954.288462\n",
      "    epoch          : 1009\n",
      "    loss           : -1010.2070846537129\n",
      "    val_loss       : -718.9320660396018\n",
      "    val_log_likelihood: 1323.5002138703458\n",
      "    val_log_marginal: 740.7577828042785\n",
      "Train Epoch: 1010 [512/17352 (3%)] Loss: -1029.030151\n",
      "Train Epoch: 1010 [10385/17352 (60%)] Loss: -1074.133323\n",
      "Train Epoch: 1010 [16883/17352 (97%)] Loss: -1073.935115\n",
      "    epoch          : 1010\n",
      "    loss           : -985.0135375937462\n",
      "    val_loss       : -625.4092365855892\n",
      "    val_log_likelihood: 1287.4599134281839\n",
      "    val_log_marginal: 645.6655484791012\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch1010.pth ...\n",
      "Train Epoch: 1011 [512/17352 (3%)] Loss: -1006.683350\n",
      "Train Epoch: 1011 [10197/17352 (59%)] Loss: -851.757068\n",
      "Train Epoch: 1011 [17277/17352 (100%)] Loss: -1110.411436\n",
      "    epoch          : 1011\n",
      "    loss           : -984.509884552706\n",
      "    val_loss       : -725.9293828526293\n",
      "    val_log_likelihood: 1315.6323085934175\n",
      "    val_log_marginal: 747.3340805587209\n",
      "Train Epoch: 1012 [512/17352 (3%)] Loss: -1028.927979\n",
      "Train Epoch: 1012 [10469/17352 (60%)] Loss: -690.352799\n",
      "Train Epoch: 1012 [16878/17352 (97%)] Loss: -1055.047138\n",
      "    epoch          : 1012\n",
      "    loss           : -916.3980262523888\n",
      "    val_loss       : -575.4672231624918\n",
      "    val_log_likelihood: 1210.7218542882251\n",
      "    val_log_marginal: 629.2864588382441\n",
      "Train Epoch: 1013 [512/17352 (3%)] Loss: 30.321915\n",
      "Train Epoch: 1013 [10439/17352 (60%)] Loss: -784.378941\n",
      "Train Epoch: 1013 [17335/17352 (100%)] Loss: -560.923803\n",
      "    epoch          : 1013\n",
      "    loss           : -740.6419071547385\n",
      "    val_loss       : -503.8109010582014\n",
      "    val_log_likelihood: 1129.4469921651978\n",
      "    val_log_marginal: 571.5584332946437\n",
      "Train Epoch: 1014 [512/17352 (3%)] Loss: -789.137878\n",
      "Train Epoch: 1014 [10684/17352 (62%)] Loss: -964.655129\n",
      "Train Epoch: 1014 [17108/17352 (99%)] Loss: -901.073414\n",
      "    epoch          : 1014\n",
      "    loss           : -860.9223235484642\n",
      "    val_loss       : -662.4427484910722\n",
      "    val_log_likelihood: 1225.542927578753\n",
      "    val_log_marginal: 701.989736027741\n",
      "Train Epoch: 1015 [512/17352 (3%)] Loss: -1003.336304\n",
      "Train Epoch: 1015 [10392/17352 (60%)] Loss: -1038.797111\n",
      "Train Epoch: 1015 [17064/17352 (98%)] Loss: -939.081903\n",
      "    epoch          : 1015\n",
      "    loss           : -977.2338541153576\n",
      "    val_loss       : -739.3959936599236\n",
      "    val_log_likelihood: 1289.6180185373375\n",
      "    val_log_marginal: 767.239725889928\n",
      "Train Epoch: 1016 [512/17352 (3%)] Loss: -1027.676758\n",
      "Train Epoch: 1016 [10229/17352 (59%)] Loss: -909.056737\n",
      "Train Epoch: 1016 [17101/17352 (99%)] Loss: -1115.638015\n",
      "    epoch          : 1016\n",
      "    loss           : -995.1851896718771\n",
      "    val_loss       : -740.6033229130065\n",
      "    val_log_likelihood: 1302.9243495062244\n",
      "    val_log_marginal: 772.6360682741072\n",
      "Train Epoch: 1017 [512/17352 (3%)] Loss: -1039.886108\n",
      "Train Epoch: 1017 [10256/17352 (59%)] Loss: -1064.896912\n",
      "Train Epoch: 1017 [17064/17352 (98%)] Loss: -1066.719979\n",
      "    epoch          : 1017\n",
      "    loss           : -1005.5074386909121\n",
      "    val_loss       : -775.0443385935519\n",
      "    val_log_likelihood: 1308.225476451155\n",
      "    val_log_marginal: 795.2318243234287\n",
      "Train Epoch: 1018 [512/17352 (3%)] Loss: -1059.182861\n",
      "Train Epoch: 1018 [10097/17352 (58%)] Loss: -900.833698\n",
      "Train Epoch: 1018 [16939/17352 (98%)] Loss: -861.369758\n",
      "    epoch          : 1018\n",
      "    loss           : -1012.9579162487158\n",
      "    val_loss       : -751.544194922166\n",
      "    val_log_likelihood: 1305.7314487405492\n",
      "    val_log_marginal: 775.0156797693865\n",
      "Train Epoch: 1019 [512/17352 (3%)] Loss: -1061.552612\n",
      "Train Epoch: 1019 [9947/17352 (57%)] Loss: -979.248698\n",
      "Train Epoch: 1019 [17108/17352 (99%)] Loss: -915.388185\n",
      "    epoch          : 1019\n",
      "    loss           : -1029.3918870834145\n",
      "    val_loss       : -725.8323870767072\n",
      "    val_log_likelihood: 1294.580303288898\n",
      "    val_log_marginal: 745.6952820591767\n",
      "Train Epoch: 1020 [512/17352 (3%)] Loss: -1043.808105\n",
      "Train Epoch: 1020 [10628/17352 (61%)] Loss: -1128.792553\n",
      "Train Epoch: 1020 [17064/17352 (98%)] Loss: -1075.256849\n",
      "    epoch          : 1020\n",
      "    loss           : -1032.9893827700225\n",
      "    val_loss       : -742.7802876989804\n",
      "    val_log_likelihood: 1307.8397318274879\n",
      "    val_log_marginal: 763.687519328902\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch1020.pth ...\n",
      "Train Epoch: 1021 [512/17352 (3%)] Loss: -1052.991455\n",
      "Train Epoch: 1021 [10757/17352 (62%)] Loss: -1078.755087\n",
      "Train Epoch: 1021 [17101/17352 (99%)] Loss: -1100.564873\n",
      "    epoch          : 1021\n",
      "    loss           : -1006.2196154215683\n",
      "    val_loss       : -751.2285893512835\n",
      "    val_log_likelihood: 1304.952544941014\n",
      "    val_log_marginal: 770.8768073196468\n",
      "Train Epoch: 1022 [512/17352 (3%)] Loss: -1060.944702\n",
      "Train Epoch: 1022 [9928/17352 (57%)] Loss: -975.591829\n",
      "Train Epoch: 1022 [16878/17352 (97%)] Loss: -1007.412349\n",
      "    epoch          : 1022\n",
      "    loss           : -1016.8790729698121\n",
      "    val_loss       : -686.6572870991267\n",
      "    val_log_likelihood: 1272.4133737868071\n",
      "    val_log_marginal: 714.7607120775625\n",
      "Train Epoch: 1023 [512/17352 (3%)] Loss: -989.513550\n",
      "Train Epoch: 1023 [10022/17352 (58%)] Loss: -1088.165291\n",
      "Train Epoch: 1023 [17106/17352 (99%)] Loss: -1042.678443\n",
      "    epoch          : 1023\n",
      "    loss           : -1016.694272877931\n",
      "    val_loss       : -778.0854336950647\n",
      "    val_log_likelihood: 1321.0426549965837\n",
      "    val_log_marginal: 792.8287752799017\n",
      "Train Epoch: 1024 [512/17352 (3%)] Loss: -1076.554688\n",
      "Train Epoch: 1024 [10649/17352 (61%)] Loss: -888.635467\n",
      "Train Epoch: 1024 [16883/17352 (97%)] Loss: -953.750632\n",
      "    epoch          : 1024\n",
      "    loss           : -1006.0100765550561\n",
      "    val_loss       : -720.1993573196894\n",
      "    val_log_likelihood: 1289.1848336584908\n",
      "    val_log_marginal: 737.4297012519711\n",
      "Train Epoch: 1025 [512/17352 (3%)] Loss: -1057.062256\n",
      "Train Epoch: 1025 [10490/17352 (60%)] Loss: -1111.412500\n",
      "Train Epoch: 1025 [16992/17352 (98%)] Loss: -1091.798104\n",
      "    epoch          : 1025\n",
      "    loss           : -1003.0610587971661\n",
      "    val_loss       : -767.8565385522936\n",
      "    val_log_likelihood: 1320.6190787405053\n",
      "    val_log_marginal: 784.7894452120275\n",
      "Train Epoch: 1026 [512/17352 (3%)] Loss: -1081.881836\n",
      "Train Epoch: 1026 [10583/17352 (61%)] Loss: -1111.671658\n",
      "Train Epoch: 1026 [16988/17352 (98%)] Loss: -911.499417\n",
      "    epoch          : 1026\n",
      "    loss           : -1011.9223770198695\n",
      "    val_loss       : -763.6852738182042\n",
      "    val_log_likelihood: 1317.1520471470033\n",
      "    val_log_marginal: 786.8197392103519\n",
      "Train Epoch: 1027 [512/17352 (3%)] Loss: -1071.730225\n",
      "Train Epoch: 1027 [10128/17352 (58%)] Loss: -1024.878289\n",
      "Train Epoch: 1027 [16957/17352 (98%)] Loss: -875.706949\n",
      "    epoch          : 1027\n",
      "    loss           : -1020.1387764929589\n",
      "    val_loss       : -743.4006301605947\n",
      "    val_log_likelihood: 1303.4872466567529\n",
      "    val_log_marginal: 756.2257822428572\n",
      "Train Epoch: 1028 [512/17352 (3%)] Loss: -1037.930420\n",
      "Train Epoch: 1028 [10554/17352 (61%)] Loss: -1061.286159\n",
      "Train Epoch: 1028 [16883/17352 (97%)] Loss: -1108.348936\n",
      "    epoch          : 1028\n",
      "    loss           : -998.7230659603903\n",
      "    val_loss       : -739.9570147837383\n",
      "    val_log_likelihood: 1312.517482591261\n",
      "    val_log_marginal: 765.767326411171\n",
      "Train Epoch: 1029 [512/17352 (3%)] Loss: -789.877686\n",
      "Train Epoch: 1029 [10191/17352 (59%)] Loss: -1073.714258\n",
      "Train Epoch: 1029 [16922/17352 (98%)] Loss: -890.189460\n",
      "    epoch          : 1029\n",
      "    loss           : -1015.7048921246982\n",
      "    val_loss       : -747.6096823910602\n",
      "    val_log_likelihood: 1307.0591292544334\n",
      "    val_log_marginal: 770.8524507231147\n",
      "Train Epoch: 1030 [512/17352 (3%)] Loss: -1052.229614\n",
      "Train Epoch: 1030 [10255/17352 (59%)] Loss: -911.390677\n",
      "Train Epoch: 1030 [17124/17352 (99%)] Loss: -992.179276\n",
      "    epoch          : 1030\n",
      "    loss           : -1037.5739772820252\n",
      "    val_loss       : -766.1817748279547\n",
      "    val_log_likelihood: 1326.3473473558079\n",
      "    val_log_marginal: 787.5495676230163\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch1030.pth ...\n",
      "Train Epoch: 1031 [512/17352 (3%)] Loss: -1070.362915\n",
      "Train Epoch: 1031 [10204/17352 (59%)] Loss: -981.377697\n",
      "Train Epoch: 1031 [16939/17352 (98%)] Loss: -939.480519\n",
      "    epoch          : 1031\n",
      "    loss           : -1045.0867331602617\n",
      "    val_loss       : -766.7562513291737\n",
      "    val_log_likelihood: 1320.9214330749164\n",
      "    val_log_marginal: 792.0445268505993\n",
      "Train Epoch: 1032 [512/17352 (3%)] Loss: -877.044434\n",
      "Train Epoch: 1032 [10884/17352 (63%)] Loss: -883.729435\n",
      "Train Epoch: 1032 [17090/17352 (98%)] Loss: -1090.578997\n",
      "    epoch          : 1032\n",
      "    loss           : -1009.4759591705882\n",
      "    val_loss       : -712.5744102903427\n",
      "    val_log_likelihood: 1306.1049426125492\n",
      "    val_log_marginal: 737.7132095629183\n",
      "Train Epoch: 1033 [512/17352 (3%)] Loss: -1026.928223\n",
      "Train Epoch: 1033 [10123/17352 (58%)] Loss: -1072.556531\n",
      "Train Epoch: 1033 [17016/17352 (98%)] Loss: -1114.292044\n",
      "    epoch          : 1033\n",
      "    loss           : -1009.9869537833963\n",
      "    val_loss       : -724.2797766015166\n",
      "    val_log_likelihood: 1300.3870661161368\n",
      "    val_log_marginal: 744.6811702610453\n",
      "Train Epoch: 1034 [512/17352 (3%)] Loss: -1026.751953\n",
      "Train Epoch: 1034 [10180/17352 (59%)] Loss: -1169.523546\n",
      "Train Epoch: 1034 [17124/17352 (99%)] Loss: -1092.159731\n",
      "    epoch          : 1034\n",
      "    loss           : -1014.4425981430417\n",
      "    val_loss       : -590.8610449181931\n",
      "    val_log_likelihood: 1311.949530493327\n",
      "    val_log_marginal: 615.0628213107597\n",
      "Train Epoch: 1035 [512/17352 (3%)] Loss: -918.488770\n",
      "Train Epoch: 1035 [10333/17352 (60%)] Loss: -952.676693\n",
      "Train Epoch: 1035 [16988/17352 (98%)] Loss: -958.557962\n",
      "    epoch          : 1035\n",
      "    loss           : -935.5717088695237\n",
      "    val_loss       : -626.6011189723944\n",
      "    val_log_likelihood: 1226.9370202898128\n",
      "    val_log_marginal: 646.2750772093732\n",
      "Train Epoch: 1036 [512/17352 (3%)] Loss: -972.992065\n",
      "Train Epoch: 1036 [10737/17352 (62%)] Loss: -1044.566288\n",
      "Train Epoch: 1036 [16939/17352 (98%)] Loss: -1002.561266\n",
      "    epoch          : 1036\n",
      "    loss           : -998.4385354376046\n",
      "    val_loss       : -765.1885145523977\n",
      "    val_log_likelihood: 1320.3361493919535\n",
      "    val_log_marginal: 783.8526448969429\n",
      "Train Epoch: 1037 [512/17352 (3%)] Loss: -1087.953613\n",
      "Train Epoch: 1037 [10450/17352 (60%)] Loss: -976.364498\n",
      "Train Epoch: 1037 [17106/17352 (99%)] Loss: -1047.359831\n",
      "    epoch          : 1037\n",
      "    loss           : -1037.2475696507086\n",
      "    val_loss       : -734.3731706181508\n",
      "    val_log_likelihood: 1327.6517326308008\n",
      "    val_log_marginal: 751.9458325983774\n",
      "Train Epoch: 1038 [512/17352 (3%)] Loss: -1039.956055\n",
      "Train Epoch: 1038 [10067/17352 (58%)] Loss: -1081.281407\n",
      "Train Epoch: 1038 [16887/17352 (97%)] Loss: -925.452723\n",
      "    epoch          : 1038\n",
      "    loss           : -1024.8315377571437\n",
      "    val_loss       : -701.6359675018891\n",
      "    val_log_likelihood: 1319.9837688966588\n",
      "    val_log_marginal: 718.5171777941702\n",
      "Train Epoch: 1039 [512/17352 (3%)] Loss: -835.076843\n",
      "Train Epoch: 1039 [10468/17352 (60%)] Loss: -1112.577406\n",
      "Train Epoch: 1039 [16957/17352 (98%)] Loss: -1024.007641\n",
      "    epoch          : 1039\n",
      "    loss           : -1006.0628379267902\n",
      "    val_loss       : -755.2533219290871\n",
      "    val_log_likelihood: 1325.4479763534805\n",
      "    val_log_marginal: 773.3010392086562\n",
      "Train Epoch: 1040 [512/17352 (3%)] Loss: -1087.804321\n",
      "Train Epoch: 1040 [10157/17352 (59%)] Loss: -1072.591633\n",
      "Train Epoch: 1040 [16878/17352 (97%)] Loss: -1039.995028\n",
      "    epoch          : 1040\n",
      "    loss           : -1032.2241214300345\n",
      "    val_loss       : -740.2692206775484\n",
      "    val_log_likelihood: 1319.227346144324\n",
      "    val_log_marginal: 769.2574807048956\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch1040.pth ...\n",
      "Train Epoch: 1041 [512/17352 (3%)] Loss: -1095.348999\n",
      "Train Epoch: 1041 [10305/17352 (59%)] Loss: -913.528053\n",
      "Train Epoch: 1041 [16883/17352 (97%)] Loss: -1043.382212\n",
      "    epoch          : 1041\n",
      "    loss           : -1040.3185564062933\n",
      "    val_loss       : -767.1777444090319\n",
      "    val_log_likelihood: 1330.5994990842928\n",
      "    val_log_marginal: 791.322065645616\n",
      "Train Epoch: 1042 [512/17352 (3%)] Loss: -1044.703979\n",
      "Train Epoch: 1042 [9766/17352 (56%)] Loss: -1081.732437\n",
      "Train Epoch: 1042 [17124/17352 (99%)] Loss: -874.030063\n",
      "    epoch          : 1042\n",
      "    loss           : -992.793341002172\n",
      "    val_loss       : -694.5780756406235\n",
      "    val_log_likelihood: 1289.5136018627404\n",
      "    val_log_marginal: 719.6877937033871\n",
      "Train Epoch: 1043 [512/17352 (3%)] Loss: -1045.400391\n",
      "Train Epoch: 1043 [10287/17352 (59%)] Loss: -934.073328\n",
      "Train Epoch: 1043 [16958/17352 (98%)] Loss: -1000.812324\n",
      "    epoch          : 1043\n",
      "    loss           : -1009.0121435197466\n",
      "    val_loss       : -730.7419850485179\n",
      "    val_log_likelihood: 1321.5074040635502\n",
      "    val_log_marginal: 743.1689482932796\n",
      "Train Epoch: 1044 [512/17352 (3%)] Loss: -1007.914673\n",
      "Train Epoch: 1044 [10285/17352 (59%)] Loss: -965.955235\n",
      "Train Epoch: 1044 [17049/17352 (98%)] Loss: -753.852419\n",
      "    epoch          : 1044\n",
      "    loss           : -996.4839277740932\n",
      "    val_loss       : -656.801447537998\n",
      "    val_log_likelihood: 1273.1401234876153\n",
      "    val_log_marginal: 688.6880736956846\n",
      "Train Epoch: 1045 [512/17352 (3%)] Loss: -1012.594727\n",
      "Train Epoch: 1045 [9888/17352 (57%)] Loss: -1013.137232\n",
      "Train Epoch: 1045 [17126/17352 (99%)] Loss: -948.125384\n",
      "    epoch          : 1045\n",
      "    loss           : -1002.7589483576339\n",
      "    val_loss       : -706.8840198679228\n",
      "    val_log_likelihood: 1298.4827518728252\n",
      "    val_log_marginal: 730.8942564068449\n",
      "Train Epoch: 1046 [512/17352 (3%)] Loss: -1042.814209\n",
      "Train Epoch: 1046 [10410/17352 (60%)] Loss: -968.839264\n",
      "Train Epoch: 1046 [17124/17352 (99%)] Loss: -891.890726\n",
      "    epoch          : 1046\n",
      "    loss           : -974.5399039148784\n",
      "    val_loss       : -628.8695692485041\n",
      "    val_log_likelihood: 1269.1232050216881\n",
      "    val_log_marginal: 654.6563743734171\n",
      "Train Epoch: 1047 [512/17352 (3%)] Loss: -807.912537\n",
      "Train Epoch: 1047 [10226/17352 (59%)] Loss: -923.681145\n",
      "Train Epoch: 1047 [17106/17352 (99%)] Loss: -1027.119479\n",
      "    epoch          : 1047\n",
      "    loss           : -879.7861705191298\n",
      "    val_loss       : -314.148101500803\n",
      "    val_log_likelihood: 1272.8185503229943\n",
      "    val_log_marginal: 332.118742174937\n",
      "Train Epoch: 1048 [512/17352 (3%)] Loss: -702.444275\n",
      "Train Epoch: 1048 [9894/17352 (57%)] Loss: -801.281723\n",
      "Train Epoch: 1048 [16882/17352 (97%)] Loss: -1004.160833\n",
      "    epoch          : 1048\n",
      "    loss           : -771.55842072405\n",
      "    val_loss       : -638.3880951777601\n",
      "    val_log_likelihood: 1238.573660600144\n",
      "    val_log_marginal: 659.7400781399872\n",
      "Train Epoch: 1049 [512/17352 (3%)] Loss: -929.479614\n",
      "Train Epoch: 1049 [10423/17352 (60%)] Loss: -816.634889\n",
      "Train Epoch: 1049 [16872/17352 (97%)] Loss: -684.214277\n",
      "    epoch          : 1049\n",
      "    loss           : -902.370340061667\n",
      "    val_loss       : -464.29820775855643\n",
      "    val_log_likelihood: 1279.6234196197022\n",
      "    val_log_marginal: 484.15235964251946\n",
      "Train Epoch: 1050 [512/17352 (3%)] Loss: -733.371521\n",
      "Train Epoch: 1050 [10161/17352 (59%)] Loss: -558.945545\n",
      "Train Epoch: 1050 [16878/17352 (97%)] Loss: 723.758794\n",
      "    epoch          : 1050\n",
      "    loss           : -462.8952062420896\n",
      "    val_loss       : 312.8707696958945\n",
      "    val_log_likelihood: 1118.1441477958085\n",
      "    val_log_marginal: -288.040209330794\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch1050.pth ...\n",
      "Train Epoch: 1051 [512/17352 (3%)] Loss: 15.322499\n",
      "Train Epoch: 1051 [9905/17352 (57%)] Loss: -510.888968\n",
      "Train Epoch: 1051 [17133/17352 (99%)] Loss: 30.001322\n",
      "    epoch          : 1051\n",
      "    loss           : -489.0955419809121\n",
      "    val_loss       : -378.70258993366264\n",
      "    val_log_likelihood: 1182.4786600144985\n",
      "    val_log_marginal: 401.41868806936793\n",
      "Train Epoch: 1052 [512/17352 (3%)] Loss: -717.161743\n",
      "Train Epoch: 1052 [10262/17352 (59%)] Loss: -1064.767403\n",
      "Train Epoch: 1052 [17335/17352 (100%)] Loss: -949.123534\n",
      "    epoch          : 1052\n",
      "    loss           : -810.8658202014209\n",
      "    val_loss       : -481.14832029651467\n",
      "    val_log_likelihood: 1262.792630614504\n",
      "    val_log_marginal: 503.53572585323826\n",
      "Train Epoch: 1053 [512/17352 (3%)] Loss: -803.286743\n",
      "Train Epoch: 1053 [10314/17352 (59%)] Loss: -1105.924045\n",
      "Train Epoch: 1053 [17133/17352 (99%)] Loss: -1010.682349\n",
      "    epoch          : 1053\n",
      "    loss           : -971.3689892999922\n",
      "    val_loss       : -736.7674317965225\n",
      "    val_log_likelihood: 1282.3689443413057\n",
      "    val_log_marginal: 752.7807507984425\n",
      "Train Epoch: 1054 [512/17352 (3%)] Loss: -1037.688965\n",
      "Train Epoch: 1054 [10243/17352 (59%)] Loss: -967.399275\n",
      "Train Epoch: 1054 [17049/17352 (98%)] Loss: -1038.281013\n",
      "    epoch          : 1054\n",
      "    loss           : -1024.8899125510811\n",
      "    val_loss       : -772.3557344567079\n",
      "    val_log_likelihood: 1300.6888415187773\n",
      "    val_log_marginal: 791.6706819063851\n",
      "Train Epoch: 1055 [512/17352 (3%)] Loss: -1073.433716\n",
      "Train Epoch: 1055 [9997/17352 (58%)] Loss: -1137.668085\n",
      "Train Epoch: 1055 [16992/17352 (98%)] Loss: -1079.609766\n",
      "    epoch          : 1055\n",
      "    loss           : -1033.4783128582847\n",
      "    val_loss       : -760.3302350099789\n",
      "    val_log_likelihood: 1307.3713593010796\n",
      "    val_log_marginal: 774.6951906056959\n",
      "Train Epoch: 1056 [512/17352 (3%)] Loss: -1072.555542\n",
      "Train Epoch: 1056 [10699/17352 (62%)] Loss: -830.129435\n",
      "Train Epoch: 1056 [17126/17352 (99%)] Loss: -1140.565073\n",
      "    epoch          : 1056\n",
      "    loss           : -1030.3055655961193\n",
      "    val_loss       : -778.5708787854124\n",
      "    val_log_likelihood: 1321.0936365766481\n",
      "    val_log_marginal: 799.6762480410871\n",
      "Train Epoch: 1057 [512/17352 (3%)] Loss: -1075.823608\n",
      "Train Epoch: 1057 [10548/17352 (61%)] Loss: -1119.092083\n",
      "Train Epoch: 1057 [17133/17352 (99%)] Loss: -1084.543539\n",
      "    epoch          : 1057\n",
      "    loss           : -1043.8488016521076\n",
      "    val_loss       : -783.5863439912628\n",
      "    val_log_likelihood: 1325.2420612552496\n",
      "    val_log_marginal: 799.0233204912972\n",
      "Train Epoch: 1058 [512/17352 (3%)] Loss: -1092.430542\n",
      "Train Epoch: 1058 [10427/17352 (60%)] Loss: -1124.603268\n",
      "Train Epoch: 1058 [17335/17352 (100%)] Loss: -1152.053874\n",
      "    epoch          : 1058\n",
      "    loss           : -1045.1100095561894\n",
      "    val_loss       : -781.2930052643479\n",
      "    val_log_likelihood: 1324.2814915756032\n",
      "    val_log_marginal: 799.0713304031588\n",
      "Train Epoch: 1059 [512/17352 (3%)] Loss: -1096.751221\n",
      "Train Epoch: 1059 [10036/17352 (58%)] Loss: -1109.627396\n",
      "Train Epoch: 1059 [16992/17352 (98%)] Loss: -1084.209974\n",
      "    epoch          : 1059\n",
      "    loss           : -1041.2998367297027\n",
      "    val_loss       : -760.5715973297059\n",
      "    val_log_likelihood: 1317.6091122154178\n",
      "    val_log_marginal: 779.400506242202\n",
      "Train Epoch: 1060 [512/17352 (3%)] Loss: -1059.928589\n",
      "Train Epoch: 1060 [10880/17352 (63%)] Loss: -1088.834910\n",
      "Train Epoch: 1060 [17335/17352 (100%)] Loss: -899.567657\n",
      "    epoch          : 1060\n",
      "    loss           : -1039.6572889904344\n",
      "    val_loss       : -753.3105123321265\n",
      "    val_log_likelihood: 1332.1824952051224\n",
      "    val_log_marginal: 773.5043862779328\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch1060.pth ...\n",
      "Train Epoch: 1061 [512/17352 (3%)] Loss: -1063.771484\n",
      "Train Epoch: 1061 [10555/17352 (61%)] Loss: -971.598644\n",
      "Train Epoch: 1061 [16878/17352 (97%)] Loss: -980.139306\n",
      "    epoch          : 1061\n",
      "    loss           : -1038.9511540908118\n",
      "    val_loss       : -776.5327943539797\n",
      "    val_log_likelihood: 1333.521538587495\n",
      "    val_log_marginal: 793.393261577556\n",
      "Train Epoch: 1062 [512/17352 (3%)] Loss: -1103.497314\n",
      "Train Epoch: 1062 [10140/17352 (58%)] Loss: -920.965108\n",
      "Train Epoch: 1062 [17124/17352 (99%)] Loss: -978.627691\n",
      "    epoch          : 1062\n",
      "    loss           : -1047.145035025353\n",
      "    val_loss       : -765.8986478806099\n",
      "    val_log_likelihood: 1335.0252520200236\n",
      "    val_log_marginal: 780.4212062795749\n",
      "Train Epoch: 1063 [512/17352 (3%)] Loss: -1071.107910\n",
      "Train Epoch: 1063 [9924/17352 (57%)] Loss: -974.218061\n",
      "Train Epoch: 1063 [17044/17352 (98%)] Loss: -1050.257278\n",
      "    epoch          : 1063\n",
      "    loss           : -1040.3145948117133\n",
      "    val_loss       : -743.332832492483\n",
      "    val_log_likelihood: 1336.199229683302\n",
      "    val_log_marginal: 758.6420283047225\n",
      "Train Epoch: 1064 [512/17352 (3%)] Loss: -865.542969\n",
      "Train Epoch: 1064 [10128/17352 (58%)] Loss: -1142.457090\n",
      "Train Epoch: 1064 [16988/17352 (98%)] Loss: -922.581751\n",
      "    epoch          : 1064\n",
      "    loss           : -1030.4173620992033\n",
      "    val_loss       : -691.9380056048518\n",
      "    val_log_likelihood: 1336.1598326033234\n",
      "    val_log_marginal: 711.1488756537907\n",
      "Train Epoch: 1065 [512/17352 (3%)] Loss: -1007.135193\n",
      "Train Epoch: 1065 [10306/17352 (59%)] Loss: -1060.412956\n",
      "Train Epoch: 1065 [16922/17352 (98%)] Loss: -939.115463\n",
      "    epoch          : 1065\n",
      "    loss           : -1007.7622524784917\n",
      "    val_loss       : -749.4454832942848\n",
      "    val_log_likelihood: 1328.0816922529575\n",
      "    val_log_marginal: 765.5233496878707\n",
      "Train Epoch: 1066 [512/17352 (3%)] Loss: -1067.648315\n",
      "Train Epoch: 1066 [9780/17352 (56%)] Loss: -821.888098\n",
      "Train Epoch: 1066 [16992/17352 (98%)] Loss: -1037.373106\n",
      "    epoch          : 1066\n",
      "    loss           : -1024.5797185261204\n",
      "    val_loss       : -777.5276081717395\n",
      "    val_log_likelihood: 1339.0303440824375\n",
      "    val_log_marginal: 794.6263836076819\n",
      "Train Epoch: 1067 [512/17352 (3%)] Loss: -1083.395020\n",
      "Train Epoch: 1067 [10324/17352 (59%)] Loss: -1170.484867\n",
      "Train Epoch: 1067 [17106/17352 (99%)] Loss: -969.590292\n",
      "    epoch          : 1067\n",
      "    loss           : -1041.4464909753444\n",
      "    val_loss       : -742.5840597499356\n",
      "    val_log_likelihood: 1318.9471937722953\n",
      "    val_log_marginal: 753.2034896450944\n",
      "Train Epoch: 1068 [512/17352 (3%)] Loss: -1079.990723\n",
      "Train Epoch: 1068 [10075/17352 (58%)] Loss: -1097.721458\n",
      "Train Epoch: 1068 [17126/17352 (99%)] Loss: -1121.101890\n",
      "    epoch          : 1068\n",
      "    loss           : -1045.1620651099718\n",
      "    val_loss       : -758.7934529463263\n",
      "    val_log_likelihood: 1330.4249589899662\n",
      "    val_log_marginal: 777.1026637513816\n",
      "Train Epoch: 1069 [512/17352 (3%)] Loss: -1088.074219\n",
      "Train Epoch: 1069 [10184/17352 (59%)] Loss: -899.774403\n",
      "Train Epoch: 1069 [16934/17352 (98%)] Loss: -1001.706044\n",
      "    epoch          : 1069\n",
      "    loss           : -1036.5368129916567\n",
      "    val_loss       : -779.2622318707301\n",
      "    val_log_likelihood: 1344.1413703542805\n",
      "    val_log_marginal: 796.2746164636975\n",
      "Train Epoch: 1070 [512/17352 (3%)] Loss: -1089.052856\n",
      "Train Epoch: 1070 [10262/17352 (59%)] Loss: -1113.218169\n",
      "Train Epoch: 1070 [16939/17352 (98%)] Loss: -980.695414\n",
      "    epoch          : 1070\n",
      "    loss           : -1048.3567113422325\n",
      "    val_loss       : -765.7094955032721\n",
      "    val_log_likelihood: 1332.71879438823\n",
      "    val_log_marginal: 778.457258926271\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch1070.pth ...\n",
      "Train Epoch: 1071 [512/17352 (3%)] Loss: -1090.197021\n",
      "Train Epoch: 1071 [10020/17352 (58%)] Loss: -989.840461\n",
      "Train Epoch: 1071 [17253/17352 (99%)] Loss: -976.167283\n",
      "    epoch          : 1071\n",
      "    loss           : -1035.9612275902705\n",
      "    val_loss       : -711.2391366269421\n",
      "    val_log_likelihood: 1302.0480340747563\n",
      "    val_log_marginal: 727.434438081719\n",
      "Train Epoch: 1072 [512/17352 (3%)] Loss: -1050.532349\n",
      "Train Epoch: 1072 [10281/17352 (59%)] Loss: -637.392187\n",
      "Train Epoch: 1072 [16878/17352 (97%)] Loss: -842.055043\n",
      "    epoch          : 1072\n",
      "    loss           : -926.3768309131717\n",
      "    val_loss       : -694.0650620809105\n",
      "    val_log_likelihood: 1300.9790970895508\n",
      "    val_log_marginal: 731.994253515462\n",
      "Train Epoch: 1073 [512/17352 (3%)] Loss: -1028.462402\n",
      "Train Epoch: 1073 [10210/17352 (59%)] Loss: -945.442751\n",
      "Train Epoch: 1073 [17101/17352 (99%)] Loss: -869.368090\n",
      "    epoch          : 1073\n",
      "    loss           : -1004.272844429424\n",
      "    val_loss       : -756.1986283655239\n",
      "    val_log_likelihood: 1325.145823701731\n",
      "    val_log_marginal: 773.8221952041754\n",
      "Train Epoch: 1074 [512/17352 (3%)] Loss: -1078.988525\n",
      "Train Epoch: 1074 [10426/17352 (60%)] Loss: -967.548549\n",
      "Train Epoch: 1074 [17108/17352 (99%)] Loss: -1126.649375\n",
      "    epoch          : 1074\n",
      "    loss           : -1027.6174701682323\n",
      "    val_loss       : -776.8560983993784\n",
      "    val_log_likelihood: 1335.3772777477895\n",
      "    val_log_marginal: 792.0886873329076\n",
      "Train Epoch: 1075 [512/17352 (3%)] Loss: -1089.331055\n",
      "Train Epoch: 1075 [10347/17352 (60%)] Loss: -1114.836552\n",
      "Train Epoch: 1075 [16992/17352 (98%)] Loss: -824.330891\n",
      "    epoch          : 1075\n",
      "    loss           : -1026.515319524027\n",
      "    val_loss       : -685.5280371818438\n",
      "    val_log_likelihood: 1308.8057298766796\n",
      "    val_log_marginal: 713.1157046554263\n",
      "Train Epoch: 1076 [512/17352 (3%)] Loss: -1017.670288\n",
      "Train Epoch: 1076 [10270/17352 (59%)] Loss: -1059.042057\n",
      "Train Epoch: 1076 [16939/17352 (98%)] Loss: -1064.609017\n",
      "    epoch          : 1076\n",
      "    loss           : -1021.4734126063943\n",
      "    val_loss       : -767.5572013967237\n",
      "    val_log_likelihood: 1331.0574995870265\n",
      "    val_log_marginal: 785.0242593431968\n",
      "Train Epoch: 1077 [512/17352 (3%)] Loss: -1082.005737\n",
      "Train Epoch: 1077 [10291/17352 (59%)] Loss: -1133.446145\n",
      "Train Epoch: 1077 [17126/17352 (99%)] Loss: -100.762886\n",
      "    epoch          : 1077\n",
      "    loss           : -932.4989266332046\n",
      "    val_loss       : -41.90663209141625\n",
      "    val_log_likelihood: 1185.172114754801\n",
      "    val_log_marginal: 62.63799668236179\n",
      "Train Epoch: 1078 [512/17352 (3%)] Loss: -561.339355\n",
      "Train Epoch: 1078 [10225/17352 (59%)] Loss: -774.541521\n",
      "Train Epoch: 1078 [16992/17352 (98%)] Loss: -1027.862184\n",
      "    epoch          : 1078\n",
      "    loss           : -808.3481012165842\n",
      "    val_loss       : -652.0957621425765\n",
      "    val_log_likelihood: 1280.779857457221\n",
      "    val_log_marginal: 678.9504428366974\n",
      "Train Epoch: 1079 [512/17352 (3%)] Loss: -981.536255\n",
      "Train Epoch: 1079 [10025/17352 (58%)] Loss: -666.723460\n",
      "Train Epoch: 1079 [17064/17352 (98%)] Loss: -1041.504735\n",
      "    epoch          : 1079\n",
      "    loss           : -985.1085041104554\n",
      "    val_loss       : -733.3851420812758\n",
      "    val_log_likelihood: 1296.220053518909\n",
      "    val_log_marginal: 759.7152361772762\n",
      "Train Epoch: 1080 [512/17352 (3%)] Loss: -1045.563721\n",
      "Train Epoch: 1080 [10391/17352 (60%)] Loss: -973.695425\n",
      "Train Epoch: 1080 [17263/17352 (99%)] Loss: -807.831632\n",
      "    epoch          : 1080\n",
      "    loss           : -1013.0015701603297\n",
      "    val_loss       : -541.4526975811785\n",
      "    val_log_likelihood: 1285.8535800181012\n",
      "    val_log_marginal: 558.0638198825025\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/1012_104758/checkpoint-epoch1080.pth ...\n",
      "Train Epoch: 1081 [512/17352 (3%)] Loss: -858.223022\n",
      "Train Epoch: 1081 [10378/17352 (60%)] Loss: -867.644961\n",
      "Train Epoch: 1081 [16882/17352 (97%)] Loss: -1075.003860\n",
      "    epoch          : 1081\n",
      "    loss           : -1006.1647512790125\n",
      "    val_loss       : -738.083198890254\n",
      "    val_log_likelihood: 1311.5666193694801\n",
      "    val_log_marginal: 766.2559994816208\n",
      "Train Epoch: 1082 [512/17352 (3%)] Loss: -1090.151001\n",
      "Train Epoch: 1082 [10042/17352 (58%)] Loss: -1050.301576\n",
      "Train Epoch: 1082 [16882/17352 (97%)] Loss: -1028.440124\n",
      "    epoch          : 1082\n",
      "    loss           : -1031.8494435603845\n",
      "    val_loss       : -752.9694338018562\n",
      "    val_log_likelihood: 1322.2519714437385\n",
      "    val_log_marginal: 770.6758884967979\n",
      "Train Epoch: 1083 [512/17352 (3%)] Loss: -911.977661\n",
      "Train Epoch: 1083 [10329/17352 (60%)] Loss: -1129.023882\n",
      "Train Epoch: 1083 [16872/17352 (97%)] Loss: -1082.873069\n",
      "    epoch          : 1083\n",
      "    loss           : -1022.7485447873171\n",
      "    val_loss       : -746.9160646939105\n",
      "    val_log_likelihood: 1312.6766015394305\n",
      "    val_log_marginal: 770.7515174749457\n",
      "Train Epoch: 1084 [512/17352 (3%)] Loss: -1035.114136\n",
      "Train Epoch: 1084 [10620/17352 (61%)] Loss: -990.523470\n",
      "Train Epoch: 1084 [16923/17352 (98%)] Loss: -1082.796233\n",
      "    epoch          : 1084\n",
      "    loss           : -1040.3719110590368\n",
      "    val_loss       : -784.1440471726676\n",
      "    val_log_likelihood: 1339.4312522008356\n",
      "    val_log_marginal: 798.485776501145\n",
      "Train Epoch: 1085 [512/17352 (3%)] Loss: -913.727966\n",
      "Train Epoch: 1085 [9869/17352 (57%)] Loss: -1078.102839\n",
      "Train Epoch: 1085 [16883/17352 (97%)] Loss: -1148.141260\n",
      "    epoch          : 1085\n",
      "    loss           : -1051.8158228077805\n",
      "    val_loss       : -757.6107594774783\n",
      "    val_log_likelihood: 1335.542847429348\n",
      "    val_log_marginal: 774.5332953980247\n",
      "Train Epoch: 1086 [512/17352 (3%)] Loss: -1085.463989\n",
      "Train Epoch: 1086 [10178/17352 (59%)] Loss: -1117.007725\n",
      "Train Epoch: 1086 [16887/17352 (97%)] Loss: -1125.488658\n",
      "    epoch          : 1086\n",
      "    loss           : -1046.5504549465368\n",
      "    val_loss       : -782.6378951308908\n",
      "    val_log_likelihood: 1347.6896162868604\n",
      "    val_log_marginal: 803.3229071380001\n",
      "Train Epoch: 1087 [512/17352 (3%)] Loss: -1096.940186\n",
      "Train Epoch: 1087 [10208/17352 (59%)] Loss: -1195.827799\n",
      "Train Epoch: 1087 [16878/17352 (97%)] Loss: -969.524012\n",
      "    epoch          : 1087\n",
      "    loss           : -1051.821280394037\n",
      "    val_loss       : -752.1968556529401\n",
      "    val_log_likelihood: 1334.6519118129122\n",
      "    val_log_marginal: 772.7961516991347\n",
      "Train Epoch: 1088 [512/17352 (3%)] Loss: -1100.892822\n",
      "Train Epoch: 1088 [10474/17352 (60%)] Loss: -1162.340320\n",
      "Train Epoch: 1088 [16872/17352 (97%)] Loss: -1042.726218\n",
      "    epoch          : 1088\n",
      "    loss           : -1055.667978629787\n",
      "    val_loss       : -784.3330897037773\n",
      "    val_log_likelihood: 1349.5852680603791\n",
      "    val_log_marginal: 800.894008130636\n",
      "Train Epoch: 1089 [512/17352 (3%)] Loss: -1113.634033\n",
      "Train Epoch: 1089 [10433/17352 (60%)] Loss: -1170.239180\n",
      "Train Epoch: 1089 [16958/17352 (98%)] Loss: -1148.977690\n",
      "    epoch          : 1089\n",
      "    loss           : -1059.623404250806\n",
      "    val_loss       : -770.8760879913066\n",
      "    val_log_likelihood: 1345.8414251089964\n",
      "    val_log_marginal: 787.4226037008372\n",
      "Validation performance didn't improve for 200 epochs. Training stops.\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:categorical_bpl] *",
   "language": "python",
   "name": "conda-env-categorical_bpl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
