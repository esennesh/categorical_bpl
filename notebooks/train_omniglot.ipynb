{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = collections.namedtuple('Args', 'config resume device')\n",
    "config = ConfigParser.from_args(Args(config='omniglot_config.json', resume=None, device=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = config.get_logger('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = config.init_obj('optimizer', pyro.optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, [], optimizer, config=config,\n",
    "                  data_loader=data_loader,\n",
    "                  valid_data_loader=valid_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [128/17352 (1%)] Loss: 2406.018799\n",
      "Train Epoch: 1 [1536/17352 (9%)] Loss: -1836.407837\n",
      "Train Epoch: 1 [2944/17352 (17%)] Loss: -4300.581055\n",
      "Train Epoch: 1 [4352/17352 (25%)] Loss: -87383.414062\n",
      "Train Epoch: 1 [5760/17352 (33%)] Loss: -108304.609375\n",
      "Train Epoch: 1 [7168/17352 (41%)] Loss: -524791.250000\n",
      "Train Epoch: 1 [8576/17352 (49%)] Loss: -1136335.625000\n",
      "Train Epoch: 1 [9984/17352 (58%)] Loss: -1492160.625000\n",
      "Train Epoch: 1 [11392/17352 (66%)] Loss: -1452701.000000\n",
      "Train Epoch: 1 [12800/17352 (74%)] Loss: -1534118.000000\n",
      "Train Epoch: 1 [14208/17352 (82%)] Loss: -1204400.500000\n",
      "Train Epoch: 1 [15616/17352 (90%)] Loss: -982818.750000\n",
      "Train Epoch: 1 [17024/17352 (98%)] Loss: -1285145.375000\n",
      "    epoch          : 1\n",
      "    loss           : -817037.1347279268\n",
      "    val_loss       : -1444248.693649292\n",
      "Train Epoch: 2 [128/17352 (1%)] Loss: -1573962.625000\n",
      "Train Epoch: 2 [1536/17352 (9%)] Loss: -1565323.250000\n",
      "Train Epoch: 2 [2944/17352 (17%)] Loss: -1584666.000000\n",
      "Train Epoch: 2 [4352/17352 (25%)] Loss: -1576037.625000\n",
      "Train Epoch: 2 [5760/17352 (33%)] Loss: -1368211.500000\n",
      "Train Epoch: 2 [7168/17352 (41%)] Loss: -1601849.250000\n",
      "Train Epoch: 2 [8576/17352 (49%)] Loss: -1581396.750000\n",
      "Train Epoch: 2 [9984/17352 (58%)] Loss: -1588225.250000\n",
      "Train Epoch: 2 [11392/17352 (66%)] Loss: -1595200.750000\n",
      "Train Epoch: 2 [12800/17352 (74%)] Loss: -1603631.625000\n",
      "Train Epoch: 2 [14208/17352 (82%)] Loss: -1524408.250000\n",
      "Train Epoch: 2 [15616/17352 (90%)] Loss: -1595530.750000\n",
      "Train Epoch: 2 [17024/17352 (98%)] Loss: -1619477.250000\n",
      "    epoch          : 2\n",
      "    loss           : -1550784.0932904412\n",
      "    val_loss       : -1509305.7949695587\n",
      "Train Epoch: 3 [128/17352 (1%)] Loss: -1600352.375000\n",
      "Train Epoch: 3 [1536/17352 (9%)] Loss: -1600260.000000\n",
      "Train Epoch: 3 [2944/17352 (17%)] Loss: -1600161.500000\n",
      "Train Epoch: 3 [4352/17352 (25%)] Loss: -1601146.750000\n",
      "Train Epoch: 3 [5760/17352 (33%)] Loss: -1408212.375000\n",
      "Train Epoch: 3 [7168/17352 (41%)] Loss: -1607657.375000\n",
      "Train Epoch: 3 [8576/17352 (49%)] Loss: -1605002.375000\n",
      "Train Epoch: 3 [9984/17352 (58%)] Loss: -1609019.375000\n",
      "Train Epoch: 3 [11392/17352 (66%)] Loss: -1602756.500000\n",
      "Train Epoch: 3 [12800/17352 (74%)] Loss: -1607535.750000\n",
      "Train Epoch: 3 [14208/17352 (82%)] Loss: -1514825.750000\n",
      "Train Epoch: 3 [15616/17352 (90%)] Loss: -1605819.750000\n",
      "Train Epoch: 3 [17024/17352 (98%)] Loss: -1598472.000000\n",
      "    epoch          : 3\n",
      "    loss           : -1591191.9411764706\n",
      "    val_loss       : -1511831.8763923645\n",
      "Train Epoch: 4 [128/17352 (1%)] Loss: -1606557.500000\n",
      "Train Epoch: 4 [1536/17352 (9%)] Loss: -1622870.375000\n",
      "Train Epoch: 4 [2944/17352 (17%)] Loss: -1611314.500000\n",
      "Train Epoch: 4 [4352/17352 (25%)] Loss: -1612592.750000\n",
      "Train Epoch: 4 [5760/17352 (33%)] Loss: -1628693.625000\n",
      "Train Epoch: 4 [7168/17352 (41%)] Loss: -1607740.875000\n",
      "Train Epoch: 4 [8576/17352 (49%)] Loss: -1603316.000000\n",
      "Train Epoch: 4 [9984/17352 (58%)] Loss: -1615779.750000\n",
      "Train Epoch: 4 [11392/17352 (66%)] Loss: -1610899.000000\n",
      "Train Epoch: 4 [12800/17352 (74%)] Loss: -1622082.625000\n",
      "Train Epoch: 4 [14208/17352 (82%)] Loss: -1603152.875000\n",
      "Train Epoch: 4 [15616/17352 (90%)] Loss: -1614686.000000\n",
      "Train Epoch: 4 [17024/17352 (98%)] Loss: -1609254.250000\n",
      "    epoch          : 4\n",
      "    loss           : -1606494.0096507352\n",
      "    val_loss       : -1518409.664056778\n",
      "Train Epoch: 5 [128/17352 (1%)] Loss: -1623348.500000\n",
      "Train Epoch: 5 [1536/17352 (9%)] Loss: -1622762.625000\n",
      "Train Epoch: 5 [2944/17352 (17%)] Loss: -1634060.250000\n",
      "Train Epoch: 5 [4352/17352 (25%)] Loss: -1615460.125000\n",
      "Train Epoch: 5 [5760/17352 (33%)] Loss: -1618473.375000\n",
      "Train Epoch: 5 [7168/17352 (41%)] Loss: -1611004.250000\n",
      "Train Epoch: 5 [8576/17352 (49%)] Loss: -1624550.875000\n",
      "Train Epoch: 5 [9984/17352 (58%)] Loss: -1628054.625000\n",
      "Train Epoch: 5 [11392/17352 (66%)] Loss: -1619476.500000\n",
      "Train Epoch: 5 [12800/17352 (74%)] Loss: -1620988.250000\n",
      "Train Epoch: 5 [14208/17352 (82%)] Loss: -1608660.500000\n",
      "Train Epoch: 5 [15616/17352 (90%)] Loss: -1607776.250000\n",
      "Train Epoch: 5 [17024/17352 (98%)] Loss: -1615764.125000\n",
      "    epoch          : 5\n",
      "    loss           : -1610114.4439338236\n",
      "    val_loss       : -1520095.8772096634\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch5.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 6 [128/17352 (1%)] Loss: -1607195.500000\n",
      "Train Epoch: 6 [1536/17352 (9%)] Loss: -1619244.750000\n",
      "Train Epoch: 6 [2944/17352 (17%)] Loss: -1617147.750000\n",
      "Train Epoch: 6 [4352/17352 (25%)] Loss: -1620191.375000\n",
      "Train Epoch: 6 [5760/17352 (33%)] Loss: -1622739.125000\n",
      "Train Epoch: 6 [7168/17352 (41%)] Loss: -1623687.000000\n",
      "Train Epoch: 6 [8576/17352 (49%)] Loss: -1608704.500000\n",
      "Train Epoch: 6 [9984/17352 (58%)] Loss: -1625467.750000\n",
      "Train Epoch: 6 [11392/17352 (66%)] Loss: -1609447.500000\n",
      "Train Epoch: 6 [12800/17352 (74%)] Loss: -1623472.375000\n",
      "Train Epoch: 6 [14208/17352 (82%)] Loss: -1612986.500000\n",
      "Train Epoch: 6 [15616/17352 (90%)] Loss: -1615948.625000\n",
      "Train Epoch: 6 [17024/17352 (98%)] Loss: -1609107.750000\n",
      "    epoch          : 6\n",
      "    loss           : -1611402.6636029412\n",
      "    val_loss       : -1520939.510629654\n",
      "Train Epoch: 7 [128/17352 (1%)] Loss: -1622387.000000\n",
      "Train Epoch: 7 [1536/17352 (9%)] Loss: -1598053.500000\n",
      "Train Epoch: 7 [2944/17352 (17%)] Loss: -1613300.125000\n",
      "Train Epoch: 7 [4352/17352 (25%)] Loss: -1616342.000000\n",
      "Train Epoch: 7 [5760/17352 (33%)] Loss: -1601946.250000\n",
      "Train Epoch: 7 [7168/17352 (41%)] Loss: -1618984.250000\n",
      "Train Epoch: 7 [8576/17352 (49%)] Loss: -1611194.375000\n",
      "Train Epoch: 7 [9984/17352 (58%)] Loss: -1607533.750000\n",
      "Train Epoch: 7 [11392/17352 (66%)] Loss: -1627847.250000\n",
      "Train Epoch: 7 [12800/17352 (74%)] Loss: -1615150.125000\n",
      "Train Epoch: 7 [14208/17352 (82%)] Loss: -1617371.750000\n",
      "Train Epoch: 7 [15616/17352 (90%)] Loss: -1627991.750000\n",
      "Train Epoch: 7 [17024/17352 (98%)] Loss: -1619254.000000\n",
      "    epoch          : 7\n",
      "    loss           : -1612164.6484375\n",
      "    val_loss       : -1521690.9974021912\n",
      "Train Epoch: 8 [128/17352 (1%)] Loss: -1618974.000000\n",
      "Train Epoch: 8 [1536/17352 (9%)] Loss: -1616748.875000\n",
      "Train Epoch: 8 [2944/17352 (17%)] Loss: -1609486.250000\n",
      "Train Epoch: 8 [4352/17352 (25%)] Loss: -1623073.375000\n",
      "Train Epoch: 8 [5760/17352 (33%)] Loss: -1618972.500000\n",
      "Train Epoch: 8 [7168/17352 (41%)] Loss: -1623954.375000\n",
      "Train Epoch: 8 [8576/17352 (49%)] Loss: -1611043.500000\n",
      "Train Epoch: 8 [9984/17352 (58%)] Loss: -1618333.750000\n",
      "Train Epoch: 8 [11392/17352 (66%)] Loss: -1612945.125000\n",
      "Train Epoch: 8 [12800/17352 (74%)] Loss: -1616963.250000\n",
      "Train Epoch: 8 [14208/17352 (82%)] Loss: -1619247.750000\n",
      "Train Epoch: 8 [15616/17352 (90%)] Loss: -1622333.250000\n",
      "Train Epoch: 8 [17024/17352 (98%)] Loss: -1626755.125000\n",
      "    epoch          : 8\n",
      "    loss           : -1612550.346507353\n",
      "    val_loss       : -1521970.8722906113\n",
      "Train Epoch: 9 [128/17352 (1%)] Loss: -1600759.500000\n",
      "Train Epoch: 9 [1536/17352 (9%)] Loss: -1619600.375000\n",
      "Train Epoch: 9 [2944/17352 (17%)] Loss: -1604625.250000\n",
      "Train Epoch: 9 [4352/17352 (25%)] Loss: -1621460.125000\n",
      "Train Epoch: 9 [5760/17352 (33%)] Loss: -1621165.250000\n",
      "Train Epoch: 9 [7168/17352 (41%)] Loss: -1628628.125000\n",
      "Train Epoch: 9 [8576/17352 (49%)] Loss: -1621923.750000\n",
      "Train Epoch: 9 [9984/17352 (58%)] Loss: -1616345.375000\n",
      "Train Epoch: 9 [11392/17352 (66%)] Loss: -1607838.125000\n",
      "Train Epoch: 9 [12800/17352 (74%)] Loss: -1617705.000000\n",
      "Train Epoch: 9 [14208/17352 (82%)] Loss: -1615462.250000\n",
      "Train Epoch: 9 [15616/17352 (90%)] Loss: -1612951.500000\n",
      "Train Epoch: 9 [17024/17352 (98%)] Loss: -1626069.750000\n",
      "    epoch          : 9\n",
      "    loss           : -1612955.2334558824\n",
      "    val_loss       : -1522233.0963659286\n",
      "Train Epoch: 10 [128/17352 (1%)] Loss: -1612678.000000\n",
      "Train Epoch: 10 [1536/17352 (9%)] Loss: -1617799.500000\n",
      "Train Epoch: 10 [2944/17352 (17%)] Loss: -1631334.875000\n",
      "Train Epoch: 10 [4352/17352 (25%)] Loss: -1623477.750000\n",
      "Train Epoch: 10 [5760/17352 (33%)] Loss: -1618652.125000\n",
      "Train Epoch: 10 [7168/17352 (41%)] Loss: -1619267.625000\n",
      "Train Epoch: 10 [8576/17352 (49%)] Loss: -1610840.625000\n",
      "Train Epoch: 10 [9984/17352 (58%)] Loss: -1616132.750000\n",
      "Train Epoch: 10 [11392/17352 (66%)] Loss: -1627411.500000\n",
      "Train Epoch: 10 [12800/17352 (74%)] Loss: -1612987.375000\n",
      "Train Epoch: 10 [14208/17352 (82%)] Loss: -1617906.625000\n",
      "Train Epoch: 10 [15616/17352 (90%)] Loss: -1634133.750000\n",
      "Train Epoch: 10 [17024/17352 (98%)] Loss: -1623531.250000\n",
      "    epoch          : 10\n",
      "    loss           : -1613220.0583639706\n",
      "    val_loss       : -1522380.2427101135\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch10.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 11 [128/17352 (1%)] Loss: -1610610.875000\n",
      "Train Epoch: 11 [1536/17352 (9%)] Loss: -1627743.250000\n",
      "Train Epoch: 11 [2944/17352 (17%)] Loss: -1631195.250000\n",
      "Train Epoch: 11 [4352/17352 (25%)] Loss: -1625273.500000\n",
      "Train Epoch: 11 [5760/17352 (33%)] Loss: -1618486.500000\n",
      "Train Epoch: 11 [7168/17352 (41%)] Loss: -1614498.875000\n",
      "Train Epoch: 11 [8576/17352 (49%)] Loss: -1626717.000000\n",
      "Train Epoch: 11 [9984/17352 (58%)] Loss: -1613915.625000\n",
      "Train Epoch: 11 [11392/17352 (66%)] Loss: -1611389.375000\n",
      "Train Epoch: 11 [12800/17352 (74%)] Loss: -1617387.750000\n",
      "Train Epoch: 11 [14208/17352 (82%)] Loss: -1612878.000000\n",
      "Train Epoch: 11 [15616/17352 (90%)] Loss: -1647570.125000\n",
      "Train Epoch: 11 [17024/17352 (98%)] Loss: -1615948.375000\n",
      "    epoch          : 11\n",
      "    loss           : -1613432.3363970588\n",
      "    val_loss       : -1522732.9063444138\n",
      "Train Epoch: 12 [128/17352 (1%)] Loss: -1607307.375000\n",
      "Train Epoch: 12 [1536/17352 (9%)] Loss: -1612447.500000\n",
      "Train Epoch: 12 [2944/17352 (17%)] Loss: -1621411.750000\n",
      "Train Epoch: 12 [4352/17352 (25%)] Loss: -1622039.500000\n",
      "Train Epoch: 12 [5760/17352 (33%)] Loss: -1599909.750000\n",
      "Train Epoch: 12 [7168/17352 (41%)] Loss: -1615678.500000\n",
      "Train Epoch: 12 [8576/17352 (49%)] Loss: -1620966.375000\n",
      "Train Epoch: 12 [9984/17352 (58%)] Loss: -1625670.000000\n",
      "Train Epoch: 12 [11392/17352 (66%)] Loss: -1632385.125000\n",
      "Train Epoch: 12 [12800/17352 (74%)] Loss: -1614681.500000\n",
      "Train Epoch: 12 [14208/17352 (82%)] Loss: -1623678.125000\n",
      "Train Epoch: 12 [15616/17352 (90%)] Loss: -1624228.375000\n",
      "Train Epoch: 12 [17024/17352 (98%)] Loss: -1623848.000000\n",
      "    epoch          : 12\n",
      "    loss           : -1613613.6024816176\n",
      "    val_loss       : -1522688.6684417725\n",
      "Train Epoch: 13 [128/17352 (1%)] Loss: -1627589.625000\n",
      "Train Epoch: 13 [1536/17352 (9%)] Loss: -1634630.375000\n",
      "Train Epoch: 13 [2944/17352 (17%)] Loss: -1614310.000000\n",
      "Train Epoch: 13 [4352/17352 (25%)] Loss: -1616684.125000\n",
      "Train Epoch: 13 [5760/17352 (33%)] Loss: -1602601.750000\n",
      "Train Epoch: 13 [7168/17352 (41%)] Loss: -1613317.500000\n",
      "Train Epoch: 13 [8576/17352 (49%)] Loss: -1628070.250000\n",
      "Train Epoch: 13 [9984/17352 (58%)] Loss: -1616106.375000\n",
      "Train Epoch: 13 [11392/17352 (66%)] Loss: -1616930.000000\n",
      "Train Epoch: 13 [12800/17352 (74%)] Loss: -1618447.875000\n",
      "Train Epoch: 13 [14208/17352 (82%)] Loss: -1607125.250000\n",
      "Train Epoch: 13 [15616/17352 (90%)] Loss: -1615073.000000\n",
      "Train Epoch: 13 [17024/17352 (98%)] Loss: -1611818.750000\n",
      "    epoch          : 13\n",
      "    loss           : -1613705.8965992648\n",
      "    val_loss       : -1522811.6653871536\n",
      "Train Epoch: 14 [128/17352 (1%)] Loss: -1620486.625000\n",
      "Train Epoch: 14 [1536/17352 (9%)] Loss: -1622934.125000\n",
      "Train Epoch: 14 [2944/17352 (17%)] Loss: -1619285.375000\n",
      "Train Epoch: 14 [4352/17352 (25%)] Loss: -1625619.500000\n",
      "Train Epoch: 14 [5760/17352 (33%)] Loss: -1607425.875000\n",
      "Train Epoch: 14 [7168/17352 (41%)] Loss: -1625807.000000\n",
      "Train Epoch: 14 [8576/17352 (49%)] Loss: -1615459.125000\n",
      "Train Epoch: 14 [9984/17352 (58%)] Loss: -1612372.750000\n",
      "Train Epoch: 14 [11392/17352 (66%)] Loss: -1633381.250000\n",
      "Train Epoch: 14 [12800/17352 (74%)] Loss: -1631522.000000\n",
      "Train Epoch: 14 [14208/17352 (82%)] Loss: -1617966.875000\n",
      "Train Epoch: 14 [15616/17352 (90%)] Loss: -1618982.375000\n",
      "Train Epoch: 14 [17024/17352 (98%)] Loss: -1633476.625000\n",
      "    epoch          : 14\n",
      "    loss           : -1613910.6580882352\n",
      "    val_loss       : -1522972.975288391\n",
      "Train Epoch: 15 [128/17352 (1%)] Loss: -1611588.750000\n",
      "Train Epoch: 15 [1536/17352 (9%)] Loss: -1607616.250000\n",
      "Train Epoch: 15 [2944/17352 (17%)] Loss: -1595517.000000\n",
      "Train Epoch: 15 [4352/17352 (25%)] Loss: -1619537.750000\n",
      "Train Epoch: 15 [5760/17352 (33%)] Loss: -1626969.875000\n",
      "Train Epoch: 15 [7168/17352 (41%)] Loss: -1620451.125000\n",
      "Train Epoch: 15 [8576/17352 (49%)] Loss: -1623113.500000\n",
      "Train Epoch: 15 [9984/17352 (58%)] Loss: -1617462.500000\n",
      "Train Epoch: 15 [11392/17352 (66%)] Loss: -1630376.625000\n",
      "Train Epoch: 15 [12800/17352 (74%)] Loss: -1614608.500000\n",
      "Train Epoch: 15 [14208/17352 (82%)] Loss: -1620553.125000\n",
      "Train Epoch: 15 [15616/17352 (90%)] Loss: -1621295.375000\n",
      "Train Epoch: 15 [17024/17352 (98%)] Loss: -1610155.125000\n",
      "    epoch          : 15\n",
      "    loss           : -1613990.8350183824\n",
      "    val_loss       : -1522985.7699270248\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch15.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 16 [128/17352 (1%)] Loss: -1630111.750000\n",
      "Train Epoch: 16 [1536/17352 (9%)] Loss: -1605273.500000\n",
      "Train Epoch: 16 [2944/17352 (17%)] Loss: -1626979.625000\n",
      "Train Epoch: 16 [4352/17352 (25%)] Loss: -1625248.000000\n",
      "Train Epoch: 16 [5760/17352 (33%)] Loss: -1615969.500000\n",
      "Train Epoch: 16 [7168/17352 (41%)] Loss: -1617829.125000\n",
      "Train Epoch: 16 [8576/17352 (49%)] Loss: -1622499.000000\n",
      "Train Epoch: 16 [9984/17352 (58%)] Loss: -1625294.125000\n",
      "Train Epoch: 16 [11392/17352 (66%)] Loss: -1625244.500000\n",
      "Train Epoch: 16 [12800/17352 (74%)] Loss: -1631281.750000\n",
      "Train Epoch: 16 [14208/17352 (82%)] Loss: -1620496.750000\n",
      "Train Epoch: 16 [15616/17352 (90%)] Loss: -1607628.750000\n",
      "Train Epoch: 16 [17024/17352 (98%)] Loss: -1617213.250000\n",
      "    epoch          : 16\n",
      "    loss           : -1614082.083180147\n",
      "    val_loss       : -1523126.0877399445\n",
      "Train Epoch: 17 [128/17352 (1%)] Loss: -1617231.500000\n",
      "Train Epoch: 17 [1536/17352 (9%)] Loss: -1617997.000000\n",
      "Train Epoch: 17 [2944/17352 (17%)] Loss: -1610878.000000\n",
      "Train Epoch: 17 [4352/17352 (25%)] Loss: -1623593.500000\n",
      "Train Epoch: 17 [5760/17352 (33%)] Loss: -1624058.500000\n",
      "Train Epoch: 17 [7168/17352 (41%)] Loss: -1616761.875000\n",
      "Train Epoch: 17 [8576/17352 (49%)] Loss: -1629244.750000\n",
      "Train Epoch: 17 [9984/17352 (58%)] Loss: -1626753.875000\n",
      "Train Epoch: 17 [11392/17352 (66%)] Loss: -1616087.625000\n",
      "Train Epoch: 17 [12800/17352 (74%)] Loss: -1620468.125000\n",
      "Train Epoch: 17 [14208/17352 (82%)] Loss: -1616646.250000\n",
      "Train Epoch: 17 [15616/17352 (90%)] Loss: -1615871.750000\n",
      "Train Epoch: 17 [17024/17352 (98%)] Loss: -1636819.750000\n",
      "    epoch          : 17\n",
      "    loss           : -1614155.5059742648\n",
      "    val_loss       : -1523203.8809900284\n",
      "Train Epoch: 18 [128/17352 (1%)] Loss: -1626230.125000\n",
      "Train Epoch: 18 [1536/17352 (9%)] Loss: -1632316.750000\n",
      "Train Epoch: 18 [2944/17352 (17%)] Loss: -1629121.500000\n",
      "Train Epoch: 18 [4352/17352 (25%)] Loss: -1618606.500000\n",
      "Train Epoch: 18 [5760/17352 (33%)] Loss: -1615288.500000\n",
      "Train Epoch: 18 [7168/17352 (41%)] Loss: -1616046.125000\n",
      "Train Epoch: 18 [8576/17352 (49%)] Loss: -1614384.750000\n",
      "Train Epoch: 18 [9984/17352 (58%)] Loss: -1623059.125000\n",
      "Train Epoch: 18 [11392/17352 (66%)] Loss: -1605303.375000\n",
      "Train Epoch: 18 [12800/17352 (74%)] Loss: -1621461.125000\n",
      "Train Epoch: 18 [14208/17352 (82%)] Loss: -1622430.375000\n",
      "Train Epoch: 18 [15616/17352 (90%)] Loss: -1634036.375000\n",
      "Train Epoch: 18 [17024/17352 (98%)] Loss: -1619738.000000\n",
      "    epoch          : 18\n",
      "    loss           : -1614205.9806985294\n",
      "    val_loss       : -1523326.089925766\n",
      "Train Epoch: 19 [128/17352 (1%)] Loss: -1619881.500000\n",
      "Train Epoch: 19 [1536/17352 (9%)] Loss: -1627692.750000\n",
      "Train Epoch: 19 [2944/17352 (17%)] Loss: -1620139.500000\n",
      "Train Epoch: 19 [4352/17352 (25%)] Loss: -1609933.750000\n",
      "Train Epoch: 19 [5760/17352 (33%)] Loss: -1618437.500000\n",
      "Train Epoch: 19 [7168/17352 (41%)] Loss: -1610917.750000\n",
      "Train Epoch: 19 [8576/17352 (49%)] Loss: -1621585.750000\n",
      "Train Epoch: 19 [9984/17352 (58%)] Loss: -1625195.375000\n",
      "Train Epoch: 19 [11392/17352 (66%)] Loss: -1620753.625000\n",
      "Train Epoch: 19 [12800/17352 (74%)] Loss: -1630254.375000\n",
      "Train Epoch: 19 [14208/17352 (82%)] Loss: -1621796.125000\n",
      "Train Epoch: 19 [15616/17352 (90%)] Loss: -1615494.250000\n",
      "Train Epoch: 19 [17024/17352 (98%)] Loss: -1620991.125000\n",
      "    epoch          : 19\n",
      "    loss           : -1614356.3713235294\n",
      "    val_loss       : -1523346.2682600021\n",
      "Train Epoch: 20 [128/17352 (1%)] Loss: -1626360.625000\n",
      "Train Epoch: 20 [1536/17352 (9%)] Loss: -1628839.625000\n",
      "Train Epoch: 20 [2944/17352 (17%)] Loss: -1631701.750000\n",
      "Train Epoch: 20 [4352/17352 (25%)] Loss: -1617700.500000\n",
      "Train Epoch: 20 [5760/17352 (33%)] Loss: -1629243.000000\n",
      "Train Epoch: 20 [7168/17352 (41%)] Loss: -1635568.000000\n",
      "Train Epoch: 20 [8576/17352 (49%)] Loss: -1629653.000000\n",
      "Train Epoch: 20 [9984/17352 (58%)] Loss: -1632022.250000\n",
      "Train Epoch: 20 [11392/17352 (66%)] Loss: -1620561.500000\n",
      "Train Epoch: 20 [12800/17352 (74%)] Loss: -1616894.375000\n",
      "Train Epoch: 20 [14208/17352 (82%)] Loss: -1615468.250000\n",
      "Train Epoch: 20 [15616/17352 (90%)] Loss: -1630253.750000\n",
      "Train Epoch: 20 [17024/17352 (98%)] Loss: -1622684.875000\n",
      "    epoch          : 20\n",
      "    loss           : -1614364.9356617648\n",
      "    val_loss       : -1523370.0886821747\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch20.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 21 [128/17352 (1%)] Loss: -1619190.000000\n",
      "Train Epoch: 21 [1536/17352 (9%)] Loss: -1626016.000000\n",
      "Train Epoch: 21 [2944/17352 (17%)] Loss: -1623246.625000\n",
      "Train Epoch: 21 [4352/17352 (25%)] Loss: -1610270.750000\n",
      "Train Epoch: 21 [5760/17352 (33%)] Loss: -1621488.875000\n",
      "Train Epoch: 21 [7168/17352 (41%)] Loss: -1604142.750000\n",
      "Train Epoch: 21 [8576/17352 (49%)] Loss: -1633126.000000\n",
      "Train Epoch: 21 [9984/17352 (58%)] Loss: -1615602.125000\n",
      "Train Epoch: 21 [11392/17352 (66%)] Loss: -1620648.500000\n",
      "Train Epoch: 21 [12800/17352 (74%)] Loss: -1626849.000000\n",
      "Train Epoch: 21 [14208/17352 (82%)] Loss: -1620290.625000\n",
      "Train Epoch: 21 [15616/17352 (90%)] Loss: -1615573.875000\n",
      "Train Epoch: 21 [17024/17352 (98%)] Loss: -1611009.500000\n",
      "    epoch          : 21\n",
      "    loss           : -1614496.1125919118\n",
      "    val_loss       : -1523500.017832756\n",
      "Train Epoch: 22 [128/17352 (1%)] Loss: -1613658.750000\n",
      "Train Epoch: 22 [1536/17352 (9%)] Loss: -1607283.000000\n",
      "Train Epoch: 22 [2944/17352 (17%)] Loss: -1626119.875000\n",
      "Train Epoch: 22 [4352/17352 (25%)] Loss: -1613791.500000\n",
      "Train Epoch: 22 [5760/17352 (33%)] Loss: -1613975.000000\n",
      "Train Epoch: 22 [7168/17352 (41%)] Loss: -1623939.000000\n",
      "Train Epoch: 22 [8576/17352 (49%)] Loss: -1617054.875000\n",
      "Train Epoch: 22 [9984/17352 (58%)] Loss: -1618387.000000\n",
      "Train Epoch: 22 [11392/17352 (66%)] Loss: -1627994.500000\n",
      "Train Epoch: 22 [12800/17352 (74%)] Loss: -1621105.000000\n",
      "Train Epoch: 22 [14208/17352 (82%)] Loss: -1634563.375000\n",
      "Train Epoch: 22 [15616/17352 (90%)] Loss: -1603976.000000\n",
      "Train Epoch: 22 [17024/17352 (98%)] Loss: -1615127.875000\n",
      "    epoch          : 22\n",
      "    loss           : -1614495.4099264706\n",
      "    val_loss       : -1523571.5658817291\n",
      "Train Epoch: 23 [128/17352 (1%)] Loss: -1620191.625000\n",
      "Train Epoch: 23 [1536/17352 (9%)] Loss: -1619885.000000\n",
      "Train Epoch: 23 [2944/17352 (17%)] Loss: -1607700.375000\n",
      "Train Epoch: 23 [4352/17352 (25%)] Loss: -1615862.000000\n",
      "Train Epoch: 23 [5760/17352 (33%)] Loss: -1622495.250000\n",
      "Train Epoch: 23 [7168/17352 (41%)] Loss: -1628343.000000\n",
      "Train Epoch: 23 [8576/17352 (49%)] Loss: -1615853.500000\n",
      "Train Epoch: 23 [9984/17352 (58%)] Loss: -1611778.625000\n",
      "Train Epoch: 23 [11392/17352 (66%)] Loss: -1610520.875000\n",
      "Train Epoch: 23 [12800/17352 (74%)] Loss: -1622601.125000\n",
      "Train Epoch: 23 [14208/17352 (82%)] Loss: -1624932.250000\n",
      "Train Epoch: 23 [15616/17352 (90%)] Loss: -1604295.000000\n",
      "Train Epoch: 23 [17024/17352 (98%)] Loss: -1610195.875000\n",
      "    epoch          : 23\n",
      "    loss           : -1614533.8051470588\n",
      "    val_loss       : -1523477.1156425476\n",
      "Train Epoch: 24 [128/17352 (1%)] Loss: -1619603.250000\n",
      "Train Epoch: 24 [1536/17352 (9%)] Loss: -1609495.250000\n",
      "Train Epoch: 24 [2944/17352 (17%)] Loss: -1602072.500000\n",
      "Train Epoch: 24 [4352/17352 (25%)] Loss: -1625895.750000\n",
      "Train Epoch: 24 [5760/17352 (33%)] Loss: -1610454.875000\n",
      "Train Epoch: 24 [7168/17352 (41%)] Loss: -1609085.750000\n",
      "Train Epoch: 24 [8576/17352 (49%)] Loss: -1628947.000000\n",
      "Train Epoch: 24 [9984/17352 (58%)] Loss: -1632634.375000\n",
      "Train Epoch: 24 [11392/17352 (66%)] Loss: -1617434.500000\n",
      "Train Epoch: 24 [12800/17352 (74%)] Loss: -1620460.250000\n",
      "Train Epoch: 24 [14208/17352 (82%)] Loss: -1617542.125000\n",
      "Train Epoch: 24 [15616/17352 (90%)] Loss: -1613291.750000\n",
      "Train Epoch: 24 [17024/17352 (98%)] Loss: -1616963.125000\n",
      "    epoch          : 24\n",
      "    loss           : -1614638.1240808824\n",
      "    val_loss       : -1523572.9052038193\n",
      "Train Epoch: 25 [128/17352 (1%)] Loss: -1592256.500000\n",
      "Train Epoch: 25 [1536/17352 (9%)] Loss: -1616548.750000\n",
      "Train Epoch: 25 [2944/17352 (17%)] Loss: -1616514.500000\n",
      "Train Epoch: 25 [4352/17352 (25%)] Loss: -1631558.000000\n",
      "Train Epoch: 25 [5760/17352 (33%)] Loss: -1614467.250000\n",
      "Train Epoch: 25 [7168/17352 (41%)] Loss: -1607528.375000\n",
      "Train Epoch: 25 [8576/17352 (49%)] Loss: -1611265.750000\n",
      "Train Epoch: 25 [9984/17352 (58%)] Loss: -1609399.000000\n",
      "Train Epoch: 25 [11392/17352 (66%)] Loss: -1621759.375000\n",
      "Train Epoch: 25 [12800/17352 (74%)] Loss: -1622126.125000\n",
      "Train Epoch: 25 [14208/17352 (82%)] Loss: -1630855.250000\n",
      "Train Epoch: 25 [15616/17352 (90%)] Loss: -1618776.500000\n",
      "Train Epoch: 25 [17024/17352 (98%)] Loss: -1619404.500000\n",
      "    epoch          : 25\n",
      "    loss           : -1614646.0119485294\n",
      "    val_loss       : -1523561.8392772675\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch25.pth ...\n",
      "Train Epoch: 26 [128/17352 (1%)] Loss: -1618895.750000\n",
      "Train Epoch: 26 [1536/17352 (9%)] Loss: -1626559.125000\n",
      "Train Epoch: 26 [2944/17352 (17%)] Loss: -1608508.000000\n",
      "Train Epoch: 26 [4352/17352 (25%)] Loss: -1616651.000000\n",
      "Train Epoch: 26 [5760/17352 (33%)] Loss: -1614803.125000\n",
      "Train Epoch: 26 [7168/17352 (41%)] Loss: -1608525.500000\n",
      "Train Epoch: 26 [8576/17352 (49%)] Loss: -1614104.375000\n",
      "Train Epoch: 26 [9984/17352 (58%)] Loss: -1627678.375000\n",
      "Train Epoch: 26 [11392/17352 (66%)] Loss: -1625329.000000\n",
      "Train Epoch: 26 [12800/17352 (74%)] Loss: -1620456.250000\n",
      "Train Epoch: 26 [14208/17352 (82%)] Loss: -1609607.250000\n",
      "Train Epoch: 26 [15616/17352 (90%)] Loss: -1608504.875000\n",
      "Train Epoch: 26 [17024/17352 (98%)] Loss: -1620244.500000\n",
      "    epoch          : 26\n",
      "    loss           : -1614693.4549632352\n",
      "    val_loss       : -1523661.481467247\n",
      "Train Epoch: 27 [128/17352 (1%)] Loss: -1627977.250000\n",
      "Train Epoch: 27 [1536/17352 (9%)] Loss: -1612551.000000\n",
      "Train Epoch: 27 [2944/17352 (17%)] Loss: -1608461.625000\n",
      "Train Epoch: 27 [4352/17352 (25%)] Loss: -1601319.375000\n",
      "Train Epoch: 27 [5760/17352 (33%)] Loss: -1642834.250000\n",
      "Train Epoch: 27 [7168/17352 (41%)] Loss: -1612475.375000\n",
      "Train Epoch: 27 [8576/17352 (49%)] Loss: -1638523.750000\n",
      "Train Epoch: 27 [9984/17352 (58%)] Loss: -1628491.250000\n",
      "Train Epoch: 27 [11392/17352 (66%)] Loss: -1619443.500000\n",
      "Train Epoch: 27 [12800/17352 (74%)] Loss: -1624578.250000\n",
      "Train Epoch: 27 [14208/17352 (82%)] Loss: -1616132.875000\n",
      "Train Epoch: 27 [15616/17352 (90%)] Loss: -1624820.500000\n",
      "Train Epoch: 27 [17024/17352 (98%)] Loss: -1607735.250000\n",
      "    epoch          : 27\n",
      "    loss           : -1614728.127757353\n",
      "    val_loss       : -1523580.9648704529\n",
      "Train Epoch: 28 [128/17352 (1%)] Loss: -1618532.000000\n",
      "Train Epoch: 28 [1536/17352 (9%)] Loss: -1621724.250000\n",
      "Train Epoch: 28 [2944/17352 (17%)] Loss: -1626348.875000\n",
      "Train Epoch: 28 [4352/17352 (25%)] Loss: -1623390.375000\n",
      "Train Epoch: 28 [5760/17352 (33%)] Loss: -1617886.500000\n",
      "Train Epoch: 28 [7168/17352 (41%)] Loss: -1622011.000000\n",
      "Train Epoch: 28 [8576/17352 (49%)] Loss: -1627683.375000\n",
      "Train Epoch: 28 [9984/17352 (58%)] Loss: -1617079.375000\n",
      "Train Epoch: 28 [11392/17352 (66%)] Loss: -1627717.625000\n",
      "Train Epoch: 28 [12800/17352 (74%)] Loss: -1622260.375000\n",
      "Train Epoch: 28 [14208/17352 (82%)] Loss: -1622646.750000\n",
      "Train Epoch: 28 [15616/17352 (90%)] Loss: -1612425.375000\n",
      "Train Epoch: 28 [17024/17352 (98%)] Loss: -1624968.250000\n",
      "    epoch          : 28\n",
      "    loss           : -1614805.3979779412\n",
      "    val_loss       : -1523610.867693901\n",
      "Train Epoch: 29 [128/17352 (1%)] Loss: -1614870.000000\n",
      "Train Epoch: 29 [1536/17352 (9%)] Loss: -1618066.000000\n",
      "Train Epoch: 29 [2944/17352 (17%)] Loss: -1618018.250000\n",
      "Train Epoch: 29 [4352/17352 (25%)] Loss: -1622408.500000\n",
      "Train Epoch: 29 [5760/17352 (33%)] Loss: -1618686.875000\n",
      "Train Epoch: 29 [7168/17352 (41%)] Loss: -1626318.875000\n",
      "Train Epoch: 29 [8576/17352 (49%)] Loss: -1623723.875000\n",
      "Train Epoch: 29 [9984/17352 (58%)] Loss: -1629480.750000\n",
      "Train Epoch: 29 [11392/17352 (66%)] Loss: -1618175.500000\n",
      "Train Epoch: 29 [12800/17352 (74%)] Loss: -1629836.500000\n",
      "Train Epoch: 29 [14208/17352 (82%)] Loss: -1630644.625000\n",
      "Train Epoch: 29 [15616/17352 (90%)] Loss: -1626501.125000\n",
      "Train Epoch: 29 [17024/17352 (98%)] Loss: -1622501.125000\n",
      "    epoch          : 29\n",
      "    loss           : -1614816.979319853\n",
      "    val_loss       : -1523788.6667556763\n",
      "Train Epoch: 30 [128/17352 (1%)] Loss: -1619078.750000\n",
      "Train Epoch: 30 [1536/17352 (9%)] Loss: -1623266.125000\n",
      "Train Epoch: 30 [2944/17352 (17%)] Loss: -1617640.875000\n",
      "Train Epoch: 30 [4352/17352 (25%)] Loss: -1611212.500000\n",
      "Train Epoch: 30 [5760/17352 (33%)] Loss: -1614850.250000\n",
      "Train Epoch: 30 [7168/17352 (41%)] Loss: -1615392.375000\n",
      "Train Epoch: 30 [8576/17352 (49%)] Loss: -1624505.500000\n",
      "Train Epoch: 30 [9984/17352 (58%)] Loss: -1609025.625000\n",
      "Train Epoch: 30 [11392/17352 (66%)] Loss: -1616698.000000\n",
      "Train Epoch: 30 [12800/17352 (74%)] Loss: -1621303.375000\n",
      "Train Epoch: 30 [14208/17352 (82%)] Loss: -1604439.375000\n",
      "Train Epoch: 30 [15616/17352 (90%)] Loss: -1630390.250000\n",
      "Train Epoch: 30 [17024/17352 (98%)] Loss: -1627695.750000\n",
      "    epoch          : 30\n",
      "    loss           : -1614838.0716911764\n",
      "    val_loss       : -1523519.51642704\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch30.pth ...\n",
      "Train Epoch: 31 [128/17352 (1%)] Loss: -1626987.250000\n",
      "Train Epoch: 31 [1536/17352 (9%)] Loss: -1631513.500000\n",
      "Train Epoch: 31 [2944/17352 (17%)] Loss: -1610211.375000\n",
      "Train Epoch: 31 [4352/17352 (25%)] Loss: -1607178.500000\n",
      "Train Epoch: 31 [5760/17352 (33%)] Loss: -1626985.000000\n",
      "Train Epoch: 31 [7168/17352 (41%)] Loss: -1599763.875000\n",
      "Train Epoch: 31 [8576/17352 (49%)] Loss: -1619691.500000\n",
      "Train Epoch: 31 [9984/17352 (58%)] Loss: -1594997.250000\n",
      "Train Epoch: 31 [11392/17352 (66%)] Loss: -1627311.250000\n",
      "Train Epoch: 31 [12800/17352 (74%)] Loss: -1622598.875000\n",
      "Train Epoch: 31 [14208/17352 (82%)] Loss: -1621463.125000\n",
      "Train Epoch: 31 [15616/17352 (90%)] Loss: -1611126.000000\n",
      "Train Epoch: 31 [17024/17352 (98%)] Loss: -1623953.625000\n",
      "    epoch          : 31\n",
      "    loss           : -1614847.4030330882\n",
      "    val_loss       : -1523935.3912858963\n",
      "Train Epoch: 32 [128/17352 (1%)] Loss: -1611834.250000\n",
      "Train Epoch: 32 [1536/17352 (9%)] Loss: -1618803.750000\n",
      "Train Epoch: 32 [2944/17352 (17%)] Loss: -1628608.000000\n",
      "Train Epoch: 32 [4352/17352 (25%)] Loss: -1613285.625000\n",
      "Train Epoch: 32 [5760/17352 (33%)] Loss: -1628872.625000\n",
      "Train Epoch: 32 [7168/17352 (41%)] Loss: -1627584.000000\n",
      "Train Epoch: 32 [8576/17352 (49%)] Loss: -1628447.000000\n",
      "Train Epoch: 32 [9984/17352 (58%)] Loss: -1610013.250000\n",
      "Train Epoch: 32 [11392/17352 (66%)] Loss: -1614021.875000\n",
      "Train Epoch: 32 [12800/17352 (74%)] Loss: -1622295.125000\n",
      "Train Epoch: 32 [14208/17352 (82%)] Loss: -1618677.500000\n",
      "Train Epoch: 32 [15616/17352 (90%)] Loss: -1621459.625000\n",
      "Train Epoch: 32 [17024/17352 (98%)] Loss: -1605615.375000\n",
      "    epoch          : 32\n",
      "    loss           : -1614912.6415441176\n",
      "    val_loss       : -1523884.9376850128\n",
      "Train Epoch: 33 [128/17352 (1%)] Loss: -1619882.500000\n",
      "Train Epoch: 33 [1536/17352 (9%)] Loss: -1624560.750000\n",
      "Train Epoch: 33 [2944/17352 (17%)] Loss: -1618321.125000\n",
      "Train Epoch: 33 [4352/17352 (25%)] Loss: -1630128.375000\n",
      "Train Epoch: 33 [5760/17352 (33%)] Loss: -1632032.875000\n",
      "Train Epoch: 33 [7168/17352 (41%)] Loss: -1617567.625000\n",
      "Train Epoch: 33 [8576/17352 (49%)] Loss: -1623233.375000\n",
      "Train Epoch: 33 [9984/17352 (58%)] Loss: -1626603.000000\n",
      "Train Epoch: 33 [11392/17352 (66%)] Loss: -1610671.000000\n",
      "Train Epoch: 33 [12800/17352 (74%)] Loss: -1632291.750000\n",
      "Train Epoch: 33 [14208/17352 (82%)] Loss: -1626327.750000\n",
      "Train Epoch: 33 [15616/17352 (90%)] Loss: -1637001.500000\n",
      "Train Epoch: 33 [17024/17352 (98%)] Loss: -1617516.750000\n",
      "    epoch          : 33\n",
      "    loss           : -1614893.7766544118\n",
      "    val_loss       : -1523691.367570877\n",
      "Train Epoch: 34 [128/17352 (1%)] Loss: -1617955.625000\n",
      "Train Epoch: 34 [1536/17352 (9%)] Loss: -1638416.250000\n",
      "Train Epoch: 34 [2944/17352 (17%)] Loss: -1613175.375000\n",
      "Train Epoch: 34 [4352/17352 (25%)] Loss: -1610497.875000\n",
      "Train Epoch: 34 [5760/17352 (33%)] Loss: -1616793.750000\n",
      "Train Epoch: 34 [7168/17352 (41%)] Loss: -1612367.750000\n",
      "Train Epoch: 34 [8576/17352 (49%)] Loss: -1616122.500000\n",
      "Train Epoch: 34 [9984/17352 (58%)] Loss: -1614673.375000\n",
      "Train Epoch: 34 [11392/17352 (66%)] Loss: -1628189.250000\n",
      "Train Epoch: 34 [12800/17352 (74%)] Loss: -1621229.625000\n",
      "Train Epoch: 34 [14208/17352 (82%)] Loss: -1610846.375000\n",
      "Train Epoch: 34 [15616/17352 (90%)] Loss: -1615082.500000\n",
      "Train Epoch: 34 [17024/17352 (98%)] Loss: -1604871.250000\n",
      "    epoch          : 34\n",
      "    loss           : -1614937.5744485294\n",
      "    val_loss       : -1523946.2787399292\n",
      "Train Epoch: 35 [128/17352 (1%)] Loss: -1599919.000000\n",
      "Train Epoch: 35 [1536/17352 (9%)] Loss: -1610590.625000\n",
      "Train Epoch: 35 [2944/17352 (17%)] Loss: -1617903.750000\n",
      "Train Epoch: 35 [4352/17352 (25%)] Loss: -1617830.750000\n",
      "Train Epoch: 35 [5760/17352 (33%)] Loss: -1615940.750000\n",
      "Train Epoch: 35 [7168/17352 (41%)] Loss: -1617101.750000\n",
      "Train Epoch: 35 [8576/17352 (49%)] Loss: -1631032.750000\n",
      "Train Epoch: 35 [9984/17352 (58%)] Loss: -1620157.375000\n",
      "Train Epoch: 35 [11392/17352 (66%)] Loss: -1624692.750000\n",
      "Train Epoch: 35 [12800/17352 (74%)] Loss: -1635181.375000\n",
      "Train Epoch: 35 [14208/17352 (82%)] Loss: -1628877.375000\n",
      "Train Epoch: 35 [15616/17352 (90%)] Loss: -1620909.125000\n",
      "Train Epoch: 35 [17024/17352 (98%)] Loss: -1603450.875000\n",
      "    epoch          : 35\n",
      "    loss           : -1614959.1245404412\n",
      "    val_loss       : -1524052.9582538605\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch35.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 36 [128/17352 (1%)] Loss: -1630223.375000\n",
      "Train Epoch: 36 [1536/17352 (9%)] Loss: -1613388.375000\n",
      "Train Epoch: 36 [2944/17352 (17%)] Loss: -1619296.750000\n",
      "Train Epoch: 36 [4352/17352 (25%)] Loss: -1618234.250000\n",
      "Train Epoch: 36 [5760/17352 (33%)] Loss: -1609296.750000\n",
      "Train Epoch: 36 [7168/17352 (41%)] Loss: -1624287.375000\n",
      "Train Epoch: 36 [8576/17352 (49%)] Loss: -1618297.000000\n",
      "Train Epoch: 36 [9984/17352 (58%)] Loss: -1625404.000000\n",
      "Train Epoch: 36 [11392/17352 (66%)] Loss: -1619483.000000\n",
      "Train Epoch: 36 [12800/17352 (74%)] Loss: -1605955.625000\n",
      "Train Epoch: 36 [14208/17352 (82%)] Loss: -1630416.500000\n",
      "Train Epoch: 36 [15616/17352 (90%)] Loss: -1625722.000000\n",
      "Train Epoch: 36 [17024/17352 (98%)] Loss: -1631665.750000\n",
      "    epoch          : 36\n",
      "    loss           : -1614981.3313419118\n",
      "    val_loss       : -1523958.842844963\n",
      "Train Epoch: 37 [128/17352 (1%)] Loss: -1621724.625000\n",
      "Train Epoch: 37 [1536/17352 (9%)] Loss: -1631386.000000\n",
      "Train Epoch: 37 [2944/17352 (17%)] Loss: -1617673.500000\n",
      "Train Epoch: 37 [4352/17352 (25%)] Loss: -1616785.875000\n",
      "Train Epoch: 37 [5760/17352 (33%)] Loss: -1630861.625000\n",
      "Train Epoch: 37 [7168/17352 (41%)] Loss: -1621016.000000\n",
      "Train Epoch: 37 [8576/17352 (49%)] Loss: -1619824.875000\n",
      "Train Epoch: 37 [9984/17352 (58%)] Loss: -1608720.375000\n",
      "Train Epoch: 37 [11392/17352 (66%)] Loss: -1618110.750000\n",
      "Train Epoch: 37 [12800/17352 (74%)] Loss: -1624810.250000\n",
      "Train Epoch: 37 [14208/17352 (82%)] Loss: -1631635.000000\n",
      "Train Epoch: 37 [15616/17352 (90%)] Loss: -1640586.000000\n",
      "Train Epoch: 37 [17024/17352 (98%)] Loss: -1610039.000000\n",
      "    epoch          : 37\n",
      "    loss           : -1614994.9126838236\n",
      "    val_loss       : -1523966.434764862\n",
      "Train Epoch: 38 [128/17352 (1%)] Loss: -1617974.625000\n",
      "Train Epoch: 38 [1536/17352 (9%)] Loss: -1607431.750000\n",
      "Train Epoch: 38 [2944/17352 (17%)] Loss: -1631076.625000\n",
      "Train Epoch: 38 [4352/17352 (25%)] Loss: -1627192.500000\n",
      "Train Epoch: 38 [5760/17352 (33%)] Loss: -1620982.125000\n",
      "Train Epoch: 38 [7168/17352 (41%)] Loss: -1603375.000000\n",
      "Train Epoch: 38 [8576/17352 (49%)] Loss: -1628218.500000\n",
      "Train Epoch: 38 [9984/17352 (58%)] Loss: -1620080.000000\n",
      "Train Epoch: 38 [11392/17352 (66%)] Loss: -1626250.250000\n",
      "Train Epoch: 38 [12800/17352 (74%)] Loss: -1615513.125000\n",
      "Train Epoch: 38 [14208/17352 (82%)] Loss: -1627488.250000\n",
      "Train Epoch: 38 [15616/17352 (90%)] Loss: -1610345.000000\n",
      "Train Epoch: 38 [17024/17352 (98%)] Loss: -1617486.500000\n",
      "    epoch          : 38\n",
      "    loss           : -1615023.8244485294\n",
      "    val_loss       : -1523858.826997757\n",
      "Train Epoch: 39 [128/17352 (1%)] Loss: -1616013.000000\n",
      "Train Epoch: 39 [1536/17352 (9%)] Loss: -1603665.500000\n",
      "Train Epoch: 39 [2944/17352 (17%)] Loss: -1616693.250000\n",
      "Train Epoch: 39 [4352/17352 (25%)] Loss: -1607148.500000\n",
      "Train Epoch: 39 [5760/17352 (33%)] Loss: -1621705.000000\n",
      "Train Epoch: 39 [7168/17352 (41%)] Loss: -1620061.250000\n",
      "Train Epoch: 39 [8576/17352 (49%)] Loss: -1635611.000000\n",
      "Train Epoch: 39 [9984/17352 (58%)] Loss: -1625066.750000\n",
      "Train Epoch: 39 [11392/17352 (66%)] Loss: -1634480.250000\n",
      "Train Epoch: 39 [12800/17352 (74%)] Loss: -1608152.125000\n",
      "Train Epoch: 39 [14208/17352 (82%)] Loss: -1614057.250000\n",
      "Train Epoch: 39 [15616/17352 (90%)] Loss: -1629827.875000\n",
      "Train Epoch: 39 [17024/17352 (98%)] Loss: -1604227.250000\n",
      "    epoch          : 39\n",
      "    loss           : -1615017.5018382352\n",
      "    val_loss       : -1524083.200302124\n",
      "Train Epoch: 40 [128/17352 (1%)] Loss: -1626046.750000\n",
      "Train Epoch: 40 [1536/17352 (9%)] Loss: -1626966.750000\n",
      "Train Epoch: 40 [2944/17352 (17%)] Loss: -1615637.750000\n",
      "Train Epoch: 40 [4352/17352 (25%)] Loss: -1614383.625000\n",
      "Train Epoch: 40 [5760/17352 (33%)] Loss: -1613457.250000\n",
      "Train Epoch: 40 [7168/17352 (41%)] Loss: -1633467.250000\n",
      "Train Epoch: 40 [8576/17352 (49%)] Loss: -1626234.125000\n",
      "Train Epoch: 40 [9984/17352 (58%)] Loss: -1614572.500000\n",
      "Train Epoch: 40 [11392/17352 (66%)] Loss: -1630187.375000\n",
      "Train Epoch: 40 [12800/17352 (74%)] Loss: -1625937.250000\n",
      "Train Epoch: 40 [14208/17352 (82%)] Loss: -1616918.250000\n",
      "Train Epoch: 40 [15616/17352 (90%)] Loss: -1637901.500000\n",
      "Train Epoch: 40 [17024/17352 (98%)] Loss: -1614322.500000\n",
      "    epoch          : 40\n",
      "    loss           : -1615082.9875919118\n",
      "    val_loss       : -1523957.6997766495\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch40.pth ...\n",
      "Train Epoch: 41 [128/17352 (1%)] Loss: -1634631.000000\n",
      "Train Epoch: 41 [1536/17352 (9%)] Loss: -1617535.125000\n",
      "Train Epoch: 41 [2944/17352 (17%)] Loss: -1621222.125000\n",
      "Train Epoch: 41 [4352/17352 (25%)] Loss: -1623747.500000\n",
      "Train Epoch: 41 [5760/17352 (33%)] Loss: -1613696.750000\n",
      "Train Epoch: 41 [7168/17352 (41%)] Loss: -1621654.000000\n",
      "Train Epoch: 41 [8576/17352 (49%)] Loss: -1600810.625000\n",
      "Train Epoch: 41 [9984/17352 (58%)] Loss: -1614527.500000\n",
      "Train Epoch: 41 [11392/17352 (66%)] Loss: -1630359.750000\n",
      "Train Epoch: 41 [12800/17352 (74%)] Loss: -1624250.500000\n",
      "Train Epoch: 41 [14208/17352 (82%)] Loss: -1625658.250000\n",
      "Train Epoch: 41 [15616/17352 (90%)] Loss: -1614134.875000\n",
      "Train Epoch: 41 [17024/17352 (98%)] Loss: -1615652.125000\n",
      "    epoch          : 41\n",
      "    loss           : -1615118.2660845588\n",
      "    val_loss       : -1524020.9749116898\n",
      "Train Epoch: 42 [128/17352 (1%)] Loss: -1617779.500000\n",
      "Train Epoch: 42 [1536/17352 (9%)] Loss: -1621617.500000\n",
      "Train Epoch: 42 [2944/17352 (17%)] Loss: -1618645.750000\n",
      "Train Epoch: 42 [4352/17352 (25%)] Loss: -1613616.250000\n",
      "Train Epoch: 42 [5760/17352 (33%)] Loss: -1614954.000000\n",
      "Train Epoch: 42 [7168/17352 (41%)] Loss: -1621773.375000\n",
      "Train Epoch: 42 [8576/17352 (49%)] Loss: -1628077.500000\n",
      "Train Epoch: 42 [9984/17352 (58%)] Loss: -1622758.750000\n",
      "Train Epoch: 42 [11392/17352 (66%)] Loss: -1611443.000000\n",
      "Train Epoch: 42 [12800/17352 (74%)] Loss: -1644633.625000\n",
      "Train Epoch: 42 [14208/17352 (82%)] Loss: -1626071.625000\n",
      "Train Epoch: 42 [15616/17352 (90%)] Loss: -1622177.500000\n",
      "Train Epoch: 42 [17024/17352 (98%)] Loss: -1614202.875000\n",
      "    epoch          : 42\n",
      "    loss           : -1615113.619944853\n",
      "    val_loss       : -1524102.3114395142\n",
      "Train Epoch: 43 [128/17352 (1%)] Loss: -1625825.500000\n",
      "Train Epoch: 43 [1536/17352 (9%)] Loss: -1623206.750000\n",
      "Train Epoch: 43 [2944/17352 (17%)] Loss: -1634933.875000\n",
      "Train Epoch: 43 [4352/17352 (25%)] Loss: -1612616.375000\n",
      "Train Epoch: 43 [5760/17352 (33%)] Loss: -1623602.000000\n",
      "Train Epoch: 43 [7168/17352 (41%)] Loss: -1616380.000000\n",
      "Train Epoch: 43 [8576/17352 (49%)] Loss: -1649215.500000\n",
      "Train Epoch: 43 [9984/17352 (58%)] Loss: -1622932.250000\n",
      "Train Epoch: 43 [11392/17352 (66%)] Loss: -1627376.250000\n",
      "Train Epoch: 43 [12800/17352 (74%)] Loss: -1627885.125000\n",
      "Train Epoch: 43 [14208/17352 (82%)] Loss: -1617578.250000\n",
      "Train Epoch: 43 [15616/17352 (90%)] Loss: -1620802.250000\n",
      "Train Epoch: 43 [17024/17352 (98%)] Loss: -1608577.750000\n",
      "    epoch          : 43\n",
      "    loss           : -1615132.9756433824\n",
      "    val_loss       : -1524060.5495443344\n",
      "Train Epoch: 44 [128/17352 (1%)] Loss: -1620752.875000\n",
      "Train Epoch: 44 [1536/17352 (9%)] Loss: -1617223.250000\n",
      "Train Epoch: 44 [2944/17352 (17%)] Loss: -1621675.500000\n",
      "Train Epoch: 44 [4352/17352 (25%)] Loss: -1628593.250000\n",
      "Train Epoch: 44 [5760/17352 (33%)] Loss: -1614367.750000\n",
      "Train Epoch: 44 [7168/17352 (41%)] Loss: -1619260.625000\n",
      "Train Epoch: 44 [8576/17352 (49%)] Loss: -1626329.750000\n",
      "Train Epoch: 44 [9984/17352 (58%)] Loss: -1607233.250000\n",
      "Train Epoch: 44 [11392/17352 (66%)] Loss: -1614020.875000\n",
      "Train Epoch: 44 [12800/17352 (74%)] Loss: -1617205.250000\n",
      "Train Epoch: 44 [14208/17352 (82%)] Loss: -1616612.750000\n",
      "Train Epoch: 44 [15616/17352 (90%)] Loss: -1623961.250000\n",
      "Train Epoch: 44 [17024/17352 (98%)] Loss: -1623257.375000\n",
      "    epoch          : 44\n",
      "    loss           : -1615155.3258272058\n",
      "    val_loss       : -1524139.511973381\n",
      "Train Epoch: 45 [128/17352 (1%)] Loss: -1621673.250000\n",
      "Train Epoch: 45 [1536/17352 (9%)] Loss: -1626748.500000\n",
      "Train Epoch: 45 [2944/17352 (17%)] Loss: -1624087.375000\n",
      "Train Epoch: 45 [4352/17352 (25%)] Loss: -1625736.500000\n",
      "Train Epoch: 45 [5760/17352 (33%)] Loss: -1629502.000000\n",
      "Train Epoch: 45 [7168/17352 (41%)] Loss: -1614293.250000\n",
      "Train Epoch: 45 [8576/17352 (49%)] Loss: -1624851.625000\n",
      "Train Epoch: 45 [9984/17352 (58%)] Loss: -1615446.875000\n",
      "Train Epoch: 45 [11392/17352 (66%)] Loss: -1621647.000000\n",
      "Train Epoch: 45 [12800/17352 (74%)] Loss: -1618869.000000\n",
      "Train Epoch: 45 [14208/17352 (82%)] Loss: -1636001.750000\n",
      "Train Epoch: 45 [15616/17352 (90%)] Loss: -1613665.000000\n",
      "Train Epoch: 45 [17024/17352 (98%)] Loss: -1625180.500000\n",
      "    epoch          : 45\n",
      "    loss           : -1615176.364430147\n",
      "    val_loss       : -1524157.3777999878\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch45.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 46 [128/17352 (1%)] Loss: -1610687.000000\n",
      "Train Epoch: 46 [1536/17352 (9%)] Loss: -1612769.375000\n",
      "Train Epoch: 46 [2944/17352 (17%)] Loss: -1632667.375000\n",
      "Train Epoch: 46 [4352/17352 (25%)] Loss: -1614120.375000\n",
      "Train Epoch: 46 [5760/17352 (33%)] Loss: -1641141.500000\n",
      "Train Epoch: 46 [7168/17352 (41%)] Loss: -1614496.125000\n",
      "Train Epoch: 46 [8576/17352 (49%)] Loss: -1622286.000000\n",
      "Train Epoch: 46 [9984/17352 (58%)] Loss: -1623658.250000\n",
      "Train Epoch: 46 [11392/17352 (66%)] Loss: -1631819.375000\n",
      "Train Epoch: 46 [12800/17352 (74%)] Loss: -1632773.000000\n",
      "Train Epoch: 46 [14208/17352 (82%)] Loss: -1598975.000000\n",
      "Train Epoch: 46 [15616/17352 (90%)] Loss: -1618470.625000\n",
      "Train Epoch: 46 [17024/17352 (98%)] Loss: -1620148.000000\n",
      "    epoch          : 46\n",
      "    loss           : -1615146.130055147\n",
      "    val_loss       : -1524098.2810678482\n",
      "Train Epoch: 47 [128/17352 (1%)] Loss: -1630559.750000\n",
      "Train Epoch: 47 [1536/17352 (9%)] Loss: -1612874.125000\n",
      "Train Epoch: 47 [2944/17352 (17%)] Loss: -1621510.375000\n",
      "Train Epoch: 47 [4352/17352 (25%)] Loss: -1611712.500000\n",
      "Train Epoch: 47 [5760/17352 (33%)] Loss: -1624697.000000\n",
      "Train Epoch: 47 [7168/17352 (41%)] Loss: -1621769.750000\n",
      "Train Epoch: 47 [8576/17352 (49%)] Loss: -1623745.500000\n",
      "Train Epoch: 47 [9984/17352 (58%)] Loss: -1614906.750000\n",
      "Train Epoch: 47 [11392/17352 (66%)] Loss: -1621802.500000\n",
      "Train Epoch: 47 [12800/17352 (74%)] Loss: -1609549.000000\n",
      "Train Epoch: 47 [14208/17352 (82%)] Loss: -1618354.250000\n",
      "Train Epoch: 47 [15616/17352 (90%)] Loss: -1624112.875000\n",
      "Train Epoch: 47 [17024/17352 (98%)] Loss: -1624769.250000\n",
      "    epoch          : 47\n",
      "    loss           : -1615208.1236213236\n",
      "    val_loss       : -1524171.9974565506\n",
      "Train Epoch: 48 [128/17352 (1%)] Loss: -1635959.375000\n",
      "Train Epoch: 48 [1536/17352 (9%)] Loss: -1618798.250000\n",
      "Train Epoch: 48 [2944/17352 (17%)] Loss: -1613338.500000\n",
      "Train Epoch: 48 [4352/17352 (25%)] Loss: -1617791.500000\n",
      "Train Epoch: 48 [5760/17352 (33%)] Loss: -1619947.625000\n",
      "Train Epoch: 48 [7168/17352 (41%)] Loss: -1618046.750000\n",
      "Train Epoch: 48 [8576/17352 (49%)] Loss: -1624756.875000\n",
      "Train Epoch: 48 [9984/17352 (58%)] Loss: -1626399.875000\n",
      "Train Epoch: 48 [11392/17352 (66%)] Loss: -1623578.000000\n",
      "Train Epoch: 48 [12800/17352 (74%)] Loss: -1617600.125000\n",
      "Train Epoch: 48 [14208/17352 (82%)] Loss: -1623261.875000\n",
      "Train Epoch: 48 [15616/17352 (90%)] Loss: -1626922.375000\n",
      "Train Epoch: 48 [17024/17352 (98%)] Loss: -1614806.250000\n",
      "    epoch          : 48\n",
      "    loss           : -1615174.1213235294\n",
      "    val_loss       : -1524110.0396184921\n",
      "Train Epoch: 49 [128/17352 (1%)] Loss: -1625111.750000\n",
      "Train Epoch: 49 [1536/17352 (9%)] Loss: -1605770.500000\n",
      "Train Epoch: 49 [2944/17352 (17%)] Loss: -1603787.750000\n",
      "Train Epoch: 49 [4352/17352 (25%)] Loss: -1612575.000000\n",
      "Train Epoch: 49 [5760/17352 (33%)] Loss: -1628969.250000\n",
      "Train Epoch: 49 [7168/17352 (41%)] Loss: -1608217.250000\n",
      "Train Epoch: 49 [8576/17352 (49%)] Loss: -1620153.000000\n",
      "Train Epoch: 49 [9984/17352 (58%)] Loss: -1619908.375000\n",
      "Train Epoch: 49 [11392/17352 (66%)] Loss: -1619431.250000\n",
      "Train Epoch: 49 [12800/17352 (74%)] Loss: -1626953.875000\n",
      "Train Epoch: 49 [14208/17352 (82%)] Loss: -1618455.250000\n",
      "Train Epoch: 49 [15616/17352 (90%)] Loss: -1613242.500000\n",
      "Train Epoch: 49 [17024/17352 (98%)] Loss: -1624704.750000\n",
      "    epoch          : 49\n",
      "    loss           : -1615231.1838235294\n",
      "    val_loss       : -1524238.1124887466\n",
      "Train Epoch: 50 [128/17352 (1%)] Loss: -1629899.000000\n",
      "Train Epoch: 50 [1536/17352 (9%)] Loss: -1616029.500000\n",
      "Train Epoch: 50 [2944/17352 (17%)] Loss: -1615287.250000\n",
      "Train Epoch: 50 [4352/17352 (25%)] Loss: -1606536.250000\n",
      "Train Epoch: 50 [5760/17352 (33%)] Loss: -1617048.875000\n",
      "Train Epoch: 50 [7168/17352 (41%)] Loss: -1608024.875000\n",
      "Train Epoch: 50 [8576/17352 (49%)] Loss: -1630144.875000\n",
      "Train Epoch: 50 [9984/17352 (58%)] Loss: -1615743.625000\n",
      "Train Epoch: 50 [11392/17352 (66%)] Loss: -1625241.250000\n",
      "Train Epoch: 50 [12800/17352 (74%)] Loss: -1618365.250000\n",
      "Train Epoch: 50 [14208/17352 (82%)] Loss: -1624718.125000\n",
      "Train Epoch: 50 [15616/17352 (90%)] Loss: -1626351.375000\n",
      "Train Epoch: 50 [17024/17352 (98%)] Loss: -1611830.500000\n",
      "    epoch          : 50\n",
      "    loss           : -1615240.838694853\n",
      "    val_loss       : -1524243.426372528\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch50.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 51 [128/17352 (1%)] Loss: -1615850.625000\n",
      "Train Epoch: 51 [1536/17352 (9%)] Loss: -1606449.750000\n",
      "Train Epoch: 51 [2944/17352 (17%)] Loss: -1611253.250000\n",
      "Train Epoch: 51 [4352/17352 (25%)] Loss: -1615809.250000\n",
      "Train Epoch: 51 [5760/17352 (33%)] Loss: -1620127.750000\n",
      "Train Epoch: 51 [7168/17352 (41%)] Loss: -1620058.625000\n",
      "Train Epoch: 51 [8576/17352 (49%)] Loss: -1619104.750000\n",
      "Train Epoch: 51 [9984/17352 (58%)] Loss: -1615703.375000\n",
      "Train Epoch: 51 [11392/17352 (66%)] Loss: -1622906.000000\n",
      "Train Epoch: 51 [12800/17352 (74%)] Loss: -1612549.000000\n",
      "Train Epoch: 51 [14208/17352 (82%)] Loss: -1616295.750000\n",
      "Train Epoch: 51 [15616/17352 (90%)] Loss: -1631515.125000\n",
      "Train Epoch: 51 [17024/17352 (98%)] Loss: -1623282.375000\n",
      "    epoch          : 51\n",
      "    loss           : -1615285.690257353\n",
      "    val_loss       : -1524190.741060257\n",
      "Train Epoch: 52 [128/17352 (1%)] Loss: -1615899.625000\n",
      "Train Epoch: 52 [1536/17352 (9%)] Loss: -1615553.000000\n",
      "Train Epoch: 52 [2944/17352 (17%)] Loss: -1611134.500000\n",
      "Train Epoch: 52 [4352/17352 (25%)] Loss: -1602449.875000\n",
      "Train Epoch: 52 [5760/17352 (33%)] Loss: -1625313.625000\n",
      "Train Epoch: 52 [7168/17352 (41%)] Loss: -1619645.500000\n",
      "Train Epoch: 52 [8576/17352 (49%)] Loss: -1604188.875000\n",
      "Train Epoch: 52 [9984/17352 (58%)] Loss: -1623218.875000\n",
      "Train Epoch: 52 [11392/17352 (66%)] Loss: -1617020.750000\n",
      "Train Epoch: 52 [12800/17352 (74%)] Loss: -1626959.875000\n",
      "Train Epoch: 52 [14208/17352 (82%)] Loss: -1619567.250000\n",
      "Train Epoch: 52 [15616/17352 (90%)] Loss: -1630474.250000\n",
      "Train Epoch: 52 [17024/17352 (98%)] Loss: -1625637.875000\n",
      "    epoch          : 52\n",
      "    loss           : -1615231.3262867648\n",
      "    val_loss       : -1524285.4438152313\n",
      "Train Epoch: 53 [128/17352 (1%)] Loss: -1606068.250000\n",
      "Train Epoch: 53 [1536/17352 (9%)] Loss: -1637336.500000\n",
      "Train Epoch: 53 [2944/17352 (17%)] Loss: -1623587.875000\n",
      "Train Epoch: 53 [4352/17352 (25%)] Loss: -1603305.000000\n",
      "Train Epoch: 53 [5760/17352 (33%)] Loss: -1626578.625000\n",
      "Train Epoch: 53 [7168/17352 (41%)] Loss: -1627707.500000\n",
      "Train Epoch: 53 [8576/17352 (49%)] Loss: -1616529.750000\n",
      "Train Epoch: 53 [9984/17352 (58%)] Loss: -1623734.500000\n",
      "Train Epoch: 53 [11392/17352 (66%)] Loss: -1621071.625000\n",
      "Train Epoch: 53 [12800/17352 (74%)] Loss: -1614612.875000\n",
      "Train Epoch: 53 [14208/17352 (82%)] Loss: -1616202.125000\n",
      "Train Epoch: 53 [15616/17352 (90%)] Loss: -1629693.500000\n",
      "Train Epoch: 53 [17024/17352 (98%)] Loss: -1623673.500000\n",
      "    epoch          : 53\n",
      "    loss           : -1615286.0721507352\n",
      "    val_loss       : -1524119.2731523514\n",
      "Train Epoch: 54 [128/17352 (1%)] Loss: -1617654.000000\n",
      "Train Epoch: 54 [1536/17352 (9%)] Loss: -1618130.625000\n",
      "Train Epoch: 54 [2944/17352 (17%)] Loss: -1610534.750000\n",
      "Train Epoch: 54 [4352/17352 (25%)] Loss: -1636528.000000\n",
      "Train Epoch: 54 [5760/17352 (33%)] Loss: -1605149.625000\n",
      "Train Epoch: 54 [7168/17352 (41%)] Loss: -1620118.250000\n",
      "Train Epoch: 54 [8576/17352 (49%)] Loss: -1624563.000000\n",
      "Train Epoch: 54 [9984/17352 (58%)] Loss: -1631154.250000\n",
      "Train Epoch: 54 [11392/17352 (66%)] Loss: -1623565.000000\n",
      "Train Epoch: 54 [12800/17352 (74%)] Loss: -1614451.750000\n",
      "Train Epoch: 54 [14208/17352 (82%)] Loss: -1614000.250000\n",
      "Train Epoch: 54 [15616/17352 (90%)] Loss: -1619838.250000\n",
      "Train Epoch: 54 [17024/17352 (98%)] Loss: -1629984.750000\n",
      "    epoch          : 54\n",
      "    loss           : -1615310.9806985294\n",
      "    val_loss       : -1524218.385526657\n",
      "Train Epoch: 55 [128/17352 (1%)] Loss: -1633783.250000\n",
      "Train Epoch: 55 [1536/17352 (9%)] Loss: -1618590.375000\n",
      "Train Epoch: 55 [2944/17352 (17%)] Loss: -1615873.000000\n",
      "Train Epoch: 55 [4352/17352 (25%)] Loss: -1618149.000000\n",
      "Train Epoch: 55 [5760/17352 (33%)] Loss: -1612966.375000\n",
      "Train Epoch: 55 [7168/17352 (41%)] Loss: -1608804.250000\n",
      "Train Epoch: 55 [8576/17352 (49%)] Loss: -1618810.000000\n",
      "Train Epoch: 55 [9984/17352 (58%)] Loss: -1618994.375000\n",
      "Train Epoch: 55 [11392/17352 (66%)] Loss: -1638496.500000\n",
      "Train Epoch: 55 [12800/17352 (74%)] Loss: -1621365.000000\n",
      "Train Epoch: 55 [14208/17352 (82%)] Loss: -1615987.375000\n",
      "Train Epoch: 55 [15616/17352 (90%)] Loss: -1609673.750000\n",
      "Train Epoch: 55 [17024/17352 (98%)] Loss: -1636460.500000\n",
      "    epoch          : 55\n",
      "    loss           : -1615312.921875\n",
      "    val_loss       : -1524209.8271169662\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch55.pth ...\n",
      "Train Epoch: 56 [128/17352 (1%)] Loss: -1631373.750000\n",
      "Train Epoch: 56 [1536/17352 (9%)] Loss: -1629432.125000\n",
      "Train Epoch: 56 [2944/17352 (17%)] Loss: -1617659.125000\n",
      "Train Epoch: 56 [4352/17352 (25%)] Loss: -1615218.125000\n",
      "Train Epoch: 56 [5760/17352 (33%)] Loss: -1612997.500000\n",
      "Train Epoch: 56 [7168/17352 (41%)] Loss: -1613670.625000\n",
      "Train Epoch: 56 [8576/17352 (49%)] Loss: -1611625.500000\n",
      "Train Epoch: 56 [9984/17352 (58%)] Loss: -1620769.000000\n",
      "Train Epoch: 56 [11392/17352 (66%)] Loss: -1618712.500000\n",
      "Train Epoch: 56 [12800/17352 (74%)] Loss: -1608769.500000\n",
      "Train Epoch: 56 [14208/17352 (82%)] Loss: -1626184.750000\n",
      "Train Epoch: 56 [15616/17352 (90%)] Loss: -1635015.625000\n",
      "Train Epoch: 56 [17024/17352 (98%)] Loss: -1624923.875000\n",
      "    epoch          : 56\n",
      "    loss           : -1615312.2178308824\n",
      "    val_loss       : -1524355.3681678772\n",
      "Train Epoch: 57 [128/17352 (1%)] Loss: -1621321.250000\n",
      "Train Epoch: 57 [1536/17352 (9%)] Loss: -1621807.500000\n",
      "Train Epoch: 57 [2944/17352 (17%)] Loss: -1618125.375000\n",
      "Train Epoch: 57 [4352/17352 (25%)] Loss: -1621138.375000\n",
      "Train Epoch: 57 [5760/17352 (33%)] Loss: -1613356.750000\n",
      "Train Epoch: 57 [7168/17352 (41%)] Loss: -1622145.250000\n",
      "Train Epoch: 57 [8576/17352 (49%)] Loss: -1628020.375000\n",
      "Train Epoch: 57 [9984/17352 (58%)] Loss: -1614598.125000\n",
      "Train Epoch: 57 [11392/17352 (66%)] Loss: -1629192.000000\n",
      "Train Epoch: 57 [12800/17352 (74%)] Loss: -1624412.750000\n",
      "Train Epoch: 57 [14208/17352 (82%)] Loss: -1629247.500000\n",
      "Train Epoch: 57 [15616/17352 (90%)] Loss: -1622285.875000\n",
      "Train Epoch: 57 [17024/17352 (98%)] Loss: -1615274.750000\n",
      "    epoch          : 57\n",
      "    loss           : -1615358.9779411764\n",
      "    val_loss       : -1524385.7458467484\n",
      "Train Epoch: 58 [128/17352 (1%)] Loss: -1620897.000000\n",
      "Train Epoch: 58 [1536/17352 (9%)] Loss: -1626342.375000\n",
      "Train Epoch: 58 [2944/17352 (17%)] Loss: -1635730.375000\n",
      "Train Epoch: 58 [4352/17352 (25%)] Loss: -1625348.500000\n",
      "Train Epoch: 58 [5760/17352 (33%)] Loss: -1606789.125000\n",
      "Train Epoch: 58 [7168/17352 (41%)] Loss: -1619126.375000\n",
      "Train Epoch: 58 [8576/17352 (49%)] Loss: -1615646.500000\n",
      "Train Epoch: 58 [9984/17352 (58%)] Loss: -1627785.750000\n",
      "Train Epoch: 58 [11392/17352 (66%)] Loss: -1605055.500000\n",
      "Train Epoch: 58 [12800/17352 (74%)] Loss: -1632307.500000\n",
      "Train Epoch: 58 [14208/17352 (82%)] Loss: -1618651.000000\n",
      "Train Epoch: 58 [15616/17352 (90%)] Loss: -1618313.875000\n",
      "Train Epoch: 58 [17024/17352 (98%)] Loss: -1615503.500000\n",
      "    epoch          : 58\n",
      "    loss           : -1615285.6011029412\n",
      "    val_loss       : -1524146.5928993225\n",
      "Train Epoch: 59 [128/17352 (1%)] Loss: -1618691.250000\n",
      "Train Epoch: 59 [1536/17352 (9%)] Loss: -1633441.625000\n",
      "Train Epoch: 59 [2944/17352 (17%)] Loss: -1625225.000000\n",
      "Train Epoch: 59 [4352/17352 (25%)] Loss: -1612160.875000\n",
      "Train Epoch: 59 [5760/17352 (33%)] Loss: -1627560.750000\n",
      "Train Epoch: 59 [7168/17352 (41%)] Loss: -1613282.250000\n",
      "Train Epoch: 59 [8576/17352 (49%)] Loss: -1620190.625000\n",
      "Train Epoch: 59 [9984/17352 (58%)] Loss: -1621123.875000\n",
      "Train Epoch: 59 [11392/17352 (66%)] Loss: -1619446.750000\n",
      "Train Epoch: 59 [12800/17352 (74%)] Loss: -1613037.375000\n",
      "Train Epoch: 59 [14208/17352 (82%)] Loss: -1613681.500000\n",
      "Train Epoch: 59 [15616/17352 (90%)] Loss: -1614918.375000\n",
      "Train Epoch: 59 [17024/17352 (98%)] Loss: -1615504.500000\n",
      "    epoch          : 59\n",
      "    loss           : -1615336.3745404412\n",
      "    val_loss       : -1524319.2235774994\n",
      "Train Epoch: 60 [128/17352 (1%)] Loss: -1614840.250000\n",
      "Train Epoch: 60 [1536/17352 (9%)] Loss: -1621106.000000\n",
      "Train Epoch: 60 [2944/17352 (17%)] Loss: -1615720.000000\n",
      "Train Epoch: 60 [4352/17352 (25%)] Loss: -1623644.125000\n",
      "Train Epoch: 60 [5760/17352 (33%)] Loss: -1621979.500000\n",
      "Train Epoch: 60 [7168/17352 (41%)] Loss: -1622788.375000\n",
      "Train Epoch: 60 [8576/17352 (49%)] Loss: -1623034.750000\n",
      "Train Epoch: 60 [9984/17352 (58%)] Loss: -1633812.375000\n",
      "Train Epoch: 60 [11392/17352 (66%)] Loss: -1619563.500000\n",
      "Train Epoch: 60 [12800/17352 (74%)] Loss: -1605857.500000\n",
      "Train Epoch: 60 [14208/17352 (82%)] Loss: -1628337.625000\n",
      "Train Epoch: 60 [15616/17352 (90%)] Loss: -1623446.250000\n",
      "Train Epoch: 60 [17024/17352 (98%)] Loss: -1623073.000000\n",
      "    epoch          : 60\n",
      "    loss           : -1615337.4080882352\n",
      "    val_loss       : -1524226.5464801788\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch60.pth ...\n",
      "Train Epoch: 61 [128/17352 (1%)] Loss: -1630951.625000\n",
      "Train Epoch: 61 [1536/17352 (9%)] Loss: -1626410.000000\n",
      "Train Epoch: 61 [2944/17352 (17%)] Loss: -1610523.125000\n",
      "Train Epoch: 61 [4352/17352 (25%)] Loss: -1627855.000000\n",
      "Train Epoch: 61 [5760/17352 (33%)] Loss: -1617809.625000\n",
      "Train Epoch: 61 [7168/17352 (41%)] Loss: -1611708.875000\n",
      "Train Epoch: 61 [8576/17352 (49%)] Loss: -1610954.250000\n",
      "Train Epoch: 61 [9984/17352 (58%)] Loss: -1614454.375000\n",
      "Train Epoch: 61 [11392/17352 (66%)] Loss: -1618023.000000\n",
      "Train Epoch: 61 [12800/17352 (74%)] Loss: -1635575.625000\n",
      "Train Epoch: 61 [14208/17352 (82%)] Loss: -1620976.750000\n",
      "Train Epoch: 61 [15616/17352 (90%)] Loss: -1617310.250000\n",
      "Train Epoch: 61 [17024/17352 (98%)] Loss: -1624944.500000\n",
      "    epoch          : 61\n",
      "    loss           : -1615319.5390625\n",
      "    val_loss       : -1524308.5196285248\n",
      "Train Epoch: 62 [128/17352 (1%)] Loss: -1615938.750000\n",
      "Train Epoch: 62 [1536/17352 (9%)] Loss: -1609558.625000\n",
      "Train Epoch: 62 [2944/17352 (17%)] Loss: -1626403.875000\n",
      "Train Epoch: 62 [4352/17352 (25%)] Loss: -1610553.250000\n",
      "Train Epoch: 62 [5760/17352 (33%)] Loss: -1617105.000000\n",
      "Train Epoch: 62 [7168/17352 (41%)] Loss: -1630832.375000\n",
      "Train Epoch: 62 [8576/17352 (49%)] Loss: -1614064.125000\n",
      "Train Epoch: 62 [9984/17352 (58%)] Loss: -1630947.250000\n",
      "Train Epoch: 62 [11392/17352 (66%)] Loss: -1620660.250000\n",
      "Train Epoch: 62 [12800/17352 (74%)] Loss: -1616607.875000\n",
      "Train Epoch: 62 [14208/17352 (82%)] Loss: -1620365.250000\n",
      "Train Epoch: 62 [15616/17352 (90%)] Loss: -1621145.375000\n",
      "Train Epoch: 62 [17024/17352 (98%)] Loss: -1615694.750000\n",
      "    epoch          : 62\n",
      "    loss           : -1615398.9067095588\n",
      "    val_loss       : -1524380.51308918\n",
      "Train Epoch: 63 [128/17352 (1%)] Loss: -1615783.125000\n",
      "Train Epoch: 63 [1536/17352 (9%)] Loss: -1626095.000000\n",
      "Train Epoch: 63 [2944/17352 (17%)] Loss: -1622251.750000\n",
      "Train Epoch: 63 [4352/17352 (25%)] Loss: -1623202.750000\n",
      "Train Epoch: 63 [5760/17352 (33%)] Loss: -1621365.500000\n",
      "Train Epoch: 63 [7168/17352 (41%)] Loss: -1623415.625000\n",
      "Train Epoch: 63 [8576/17352 (49%)] Loss: -1627123.500000\n",
      "Train Epoch: 63 [9984/17352 (58%)] Loss: -1631477.875000\n",
      "Train Epoch: 63 [11392/17352 (66%)] Loss: -1619365.250000\n",
      "Train Epoch: 63 [12800/17352 (74%)] Loss: -1636787.875000\n",
      "Train Epoch: 63 [14208/17352 (82%)] Loss: -1616181.375000\n",
      "Train Epoch: 63 [15616/17352 (90%)] Loss: -1617874.750000\n",
      "Train Epoch: 63 [17024/17352 (98%)] Loss: -1612077.750000\n",
      "    epoch          : 63\n",
      "    loss           : -1615387.7463235294\n",
      "    val_loss       : -1524313.2326202393\n",
      "Train Epoch: 64 [128/17352 (1%)] Loss: -1609010.500000\n",
      "Train Epoch: 64 [1536/17352 (9%)] Loss: -1617045.625000\n",
      "Train Epoch: 64 [2944/17352 (17%)] Loss: -1631465.250000\n",
      "Train Epoch: 64 [4352/17352 (25%)] Loss: -1621899.625000\n",
      "Train Epoch: 64 [5760/17352 (33%)] Loss: -1613732.875000\n",
      "Train Epoch: 64 [7168/17352 (41%)] Loss: -1606198.125000\n",
      "Train Epoch: 64 [8576/17352 (49%)] Loss: -1618464.875000\n",
      "Train Epoch: 64 [9984/17352 (58%)] Loss: -1619502.625000\n",
      "Train Epoch: 64 [11392/17352 (66%)] Loss: -1626570.875000\n",
      "Train Epoch: 64 [12800/17352 (74%)] Loss: -1605620.500000\n",
      "Train Epoch: 64 [14208/17352 (82%)] Loss: -1615788.250000\n",
      "Train Epoch: 64 [15616/17352 (90%)] Loss: -1613272.875000\n",
      "Train Epoch: 64 [17024/17352 (98%)] Loss: -1633005.250000\n",
      "    epoch          : 64\n",
      "    loss           : -1615374.1346507352\n",
      "    val_loss       : -1524125.2100009918\n",
      "Train Epoch: 65 [128/17352 (1%)] Loss: -1610596.500000\n",
      "Train Epoch: 65 [1536/17352 (9%)] Loss: -1605732.750000\n",
      "Train Epoch: 65 [2944/17352 (17%)] Loss: -1623770.750000\n",
      "Train Epoch: 65 [4352/17352 (25%)] Loss: -1612747.000000\n",
      "Train Epoch: 65 [5760/17352 (33%)] Loss: -1616570.375000\n",
      "Train Epoch: 65 [7168/17352 (41%)] Loss: -1612268.875000\n",
      "Train Epoch: 65 [8576/17352 (49%)] Loss: -1607830.375000\n",
      "Train Epoch: 65 [9984/17352 (58%)] Loss: -1631993.625000\n",
      "Train Epoch: 65 [11392/17352 (66%)] Loss: -1632651.875000\n",
      "Train Epoch: 65 [12800/17352 (74%)] Loss: -1622531.875000\n",
      "Train Epoch: 65 [14208/17352 (82%)] Loss: -1623314.125000\n",
      "Train Epoch: 65 [15616/17352 (90%)] Loss: -1622211.250000\n",
      "Train Epoch: 65 [17024/17352 (98%)] Loss: -1619638.500000\n",
      "    epoch          : 65\n",
      "    loss           : -1615411.3768382352\n",
      "    val_loss       : -1524377.1969299316\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch65.pth ...\n",
      "Train Epoch: 66 [128/17352 (1%)] Loss: -1616337.375000\n",
      "Train Epoch: 66 [1536/17352 (9%)] Loss: -1627538.750000\n",
      "Train Epoch: 66 [2944/17352 (17%)] Loss: -1618791.750000\n",
      "Train Epoch: 66 [4352/17352 (25%)] Loss: -1626745.625000\n",
      "Train Epoch: 66 [5760/17352 (33%)] Loss: -1628021.000000\n",
      "Train Epoch: 66 [7168/17352 (41%)] Loss: -1612052.750000\n",
      "Train Epoch: 66 [8576/17352 (49%)] Loss: -1626402.250000\n",
      "Train Epoch: 66 [9984/17352 (58%)] Loss: -1622904.125000\n",
      "Train Epoch: 66 [11392/17352 (66%)] Loss: -1619936.250000\n",
      "Train Epoch: 66 [12800/17352 (74%)] Loss: -1604662.500000\n",
      "Train Epoch: 66 [14208/17352 (82%)] Loss: -1607122.000000\n",
      "Train Epoch: 66 [15616/17352 (90%)] Loss: -1604799.000000\n",
      "Train Epoch: 66 [17024/17352 (98%)] Loss: -1605845.000000\n",
      "    epoch          : 66\n",
      "    loss           : -1615409.5873161764\n",
      "    val_loss       : -1524265.5537757874\n",
      "Train Epoch: 67 [128/17352 (1%)] Loss: -1614247.875000\n",
      "Train Epoch: 67 [1536/17352 (9%)] Loss: -1631611.500000\n",
      "Train Epoch: 67 [2944/17352 (17%)] Loss: -1618083.250000\n",
      "Train Epoch: 67 [4352/17352 (25%)] Loss: -1609884.250000\n",
      "Train Epoch: 67 [5760/17352 (33%)] Loss: -1627922.500000\n",
      "Train Epoch: 67 [7168/17352 (41%)] Loss: -1613885.750000\n",
      "Train Epoch: 67 [8576/17352 (49%)] Loss: -1612392.125000\n",
      "Train Epoch: 67 [9984/17352 (58%)] Loss: -1617150.125000\n",
      "Train Epoch: 67 [11392/17352 (66%)] Loss: -1625369.000000\n",
      "Train Epoch: 67 [12800/17352 (74%)] Loss: -1623959.125000\n",
      "Train Epoch: 67 [14208/17352 (82%)] Loss: -1628243.500000\n",
      "Train Epoch: 67 [15616/17352 (90%)] Loss: -1622353.500000\n",
      "Train Epoch: 67 [17024/17352 (98%)] Loss: -1614797.875000\n",
      "    epoch          : 67\n",
      "    loss           : -1615415.5602022058\n",
      "    val_loss       : -1524381.304968834\n",
      "Train Epoch: 68 [128/17352 (1%)] Loss: -1617689.125000\n",
      "Train Epoch: 68 [1536/17352 (9%)] Loss: -1606314.500000\n",
      "Train Epoch: 68 [2944/17352 (17%)] Loss: -1621622.875000\n",
      "Train Epoch: 68 [4352/17352 (25%)] Loss: -1632962.750000\n",
      "Train Epoch: 68 [5760/17352 (33%)] Loss: -1611657.250000\n",
      "Train Epoch: 68 [7168/17352 (41%)] Loss: -1604142.000000\n",
      "Train Epoch: 68 [8576/17352 (49%)] Loss: -1626198.250000\n",
      "Train Epoch: 68 [9984/17352 (58%)] Loss: -1626183.500000\n",
      "Train Epoch: 68 [11392/17352 (66%)] Loss: -1606811.500000\n",
      "Train Epoch: 68 [12800/17352 (74%)] Loss: -1624877.875000\n",
      "Train Epoch: 68 [14208/17352 (82%)] Loss: -1608579.250000\n",
      "Train Epoch: 68 [15616/17352 (90%)] Loss: -1619658.000000\n",
      "Train Epoch: 68 [17024/17352 (98%)] Loss: -1633851.875000\n",
      "    epoch          : 68\n",
      "    loss           : -1615429.0399816176\n",
      "    val_loss       : -1524415.25776577\n",
      "Train Epoch: 69 [128/17352 (1%)] Loss: -1622361.000000\n",
      "Train Epoch: 69 [1536/17352 (9%)] Loss: -1627831.000000\n",
      "Train Epoch: 69 [2944/17352 (17%)] Loss: -1617484.000000\n",
      "Train Epoch: 69 [4352/17352 (25%)] Loss: -1617573.500000\n",
      "Train Epoch: 69 [5760/17352 (33%)] Loss: -1622269.875000\n",
      "Train Epoch: 69 [7168/17352 (41%)] Loss: -1619206.250000\n",
      "Train Epoch: 69 [8576/17352 (49%)] Loss: -1626537.250000\n",
      "Train Epoch: 69 [9984/17352 (58%)] Loss: -1618684.250000\n",
      "Train Epoch: 69 [11392/17352 (66%)] Loss: -1620759.500000\n",
      "Train Epoch: 69 [12800/17352 (74%)] Loss: -1627891.250000\n",
      "Train Epoch: 69 [14208/17352 (82%)] Loss: -1619790.500000\n",
      "Train Epoch: 69 [15616/17352 (90%)] Loss: -1614439.625000\n",
      "Train Epoch: 69 [17024/17352 (98%)] Loss: -1622889.750000\n",
      "    epoch          : 69\n",
      "    loss           : -1615441.635569853\n",
      "    val_loss       : -1524205.5269565582\n",
      "Train Epoch: 70 [128/17352 (1%)] Loss: -1620823.375000\n",
      "Train Epoch: 70 [1536/17352 (9%)] Loss: -1613353.375000\n",
      "Train Epoch: 70 [2944/17352 (17%)] Loss: -1649099.250000\n",
      "Train Epoch: 70 [4352/17352 (25%)] Loss: -1613164.875000\n",
      "Train Epoch: 70 [5760/17352 (33%)] Loss: -1626583.125000\n",
      "Train Epoch: 70 [7168/17352 (41%)] Loss: -1621155.250000\n",
      "Train Epoch: 70 [8576/17352 (49%)] Loss: -1627186.875000\n",
      "Train Epoch: 70 [9984/17352 (58%)] Loss: -1613750.500000\n",
      "Train Epoch: 70 [11392/17352 (66%)] Loss: -1624742.125000\n",
      "Train Epoch: 70 [12800/17352 (74%)] Loss: -1623261.750000\n",
      "Train Epoch: 70 [14208/17352 (82%)] Loss: -1610760.500000\n",
      "Train Epoch: 70 [15616/17352 (90%)] Loss: -1619880.875000\n",
      "Train Epoch: 70 [17024/17352 (98%)] Loss: -1619825.125000\n",
      "    epoch          : 70\n",
      "    loss           : -1615454.3276654412\n",
      "    val_loss       : -1524385.2675552368\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch70.pth ...\n",
      "Train Epoch: 71 [128/17352 (1%)] Loss: -1634890.000000\n",
      "Train Epoch: 71 [1536/17352 (9%)] Loss: -1614903.000000\n",
      "Train Epoch: 71 [2944/17352 (17%)] Loss: -1630100.375000\n",
      "Train Epoch: 71 [4352/17352 (25%)] Loss: -1624145.000000\n",
      "Train Epoch: 71 [5760/17352 (33%)] Loss: -1619405.750000\n",
      "Train Epoch: 71 [7168/17352 (41%)] Loss: -1610147.500000\n",
      "Train Epoch: 71 [8576/17352 (49%)] Loss: -1624964.875000\n",
      "Train Epoch: 71 [9984/17352 (58%)] Loss: -1618039.250000\n",
      "Train Epoch: 71 [11392/17352 (66%)] Loss: -1613481.625000\n",
      "Train Epoch: 71 [12800/17352 (74%)] Loss: -1631070.500000\n",
      "Train Epoch: 71 [14208/17352 (82%)] Loss: -1625472.125000\n",
      "Train Epoch: 71 [15616/17352 (90%)] Loss: -1623817.750000\n",
      "Train Epoch: 71 [17024/17352 (98%)] Loss: -1617046.875000\n",
      "    epoch          : 71\n",
      "    loss           : -1615422.9122242648\n",
      "    val_loss       : -1524140.156402588\n",
      "Train Epoch: 72 [128/17352 (1%)] Loss: -1646922.375000\n",
      "Train Epoch: 72 [1536/17352 (9%)] Loss: -1620149.750000\n",
      "Train Epoch: 72 [2944/17352 (17%)] Loss: -1608005.500000\n",
      "Train Epoch: 72 [4352/17352 (25%)] Loss: -1618863.750000\n",
      "Train Epoch: 72 [5760/17352 (33%)] Loss: -1602734.750000\n",
      "Train Epoch: 72 [7168/17352 (41%)] Loss: -1616672.000000\n",
      "Train Epoch: 72 [8576/17352 (49%)] Loss: -1601873.125000\n",
      "Train Epoch: 72 [9984/17352 (58%)] Loss: -1614132.250000\n",
      "Train Epoch: 72 [11392/17352 (66%)] Loss: -1616434.875000\n",
      "Train Epoch: 72 [12800/17352 (74%)] Loss: -1621328.375000\n",
      "Train Epoch: 72 [14208/17352 (82%)] Loss: -1621790.625000\n",
      "Train Epoch: 72 [15616/17352 (90%)] Loss: -1624130.250000\n",
      "Train Epoch: 72 [17024/17352 (98%)] Loss: -1618483.250000\n",
      "    epoch          : 72\n",
      "    loss           : -1615377.8088235294\n",
      "    val_loss       : -1524289.8843250275\n",
      "Train Epoch: 73 [128/17352 (1%)] Loss: -1636358.750000\n",
      "Train Epoch: 73 [1536/17352 (9%)] Loss: -1622944.250000\n",
      "Train Epoch: 73 [2944/17352 (17%)] Loss: -1625181.125000\n",
      "Train Epoch: 73 [4352/17352 (25%)] Loss: -1617154.500000\n",
      "Train Epoch: 73 [5760/17352 (33%)] Loss: -1613900.375000\n",
      "Train Epoch: 73 [7168/17352 (41%)] Loss: -1619874.125000\n",
      "Train Epoch: 73 [8576/17352 (49%)] Loss: -1612180.250000\n",
      "Train Epoch: 73 [9984/17352 (58%)] Loss: -1629743.125000\n",
      "Train Epoch: 73 [11392/17352 (66%)] Loss: -1614669.000000\n",
      "Train Epoch: 73 [12800/17352 (74%)] Loss: -1624242.375000\n",
      "Train Epoch: 73 [14208/17352 (82%)] Loss: -1626203.750000\n",
      "Train Epoch: 73 [15616/17352 (90%)] Loss: -1630023.375000\n",
      "Train Epoch: 73 [17024/17352 (98%)] Loss: -1614566.500000\n",
      "    epoch          : 73\n",
      "    loss           : -1615408.3023897058\n",
      "    val_loss       : -1524385.0645484924\n",
      "Train Epoch: 74 [128/17352 (1%)] Loss: -1617263.750000\n",
      "Train Epoch: 74 [1536/17352 (9%)] Loss: -1618155.625000\n",
      "Train Epoch: 74 [2944/17352 (17%)] Loss: -1613008.125000\n",
      "Train Epoch: 74 [4352/17352 (25%)] Loss: -1623017.375000\n",
      "Train Epoch: 74 [5760/17352 (33%)] Loss: -1626742.125000\n",
      "Train Epoch: 74 [7168/17352 (41%)] Loss: -1605758.250000\n",
      "Train Epoch: 74 [8576/17352 (49%)] Loss: -1624351.125000\n",
      "Train Epoch: 74 [9984/17352 (58%)] Loss: -1617175.250000\n",
      "Train Epoch: 74 [11392/17352 (66%)] Loss: -1622152.000000\n",
      "Train Epoch: 74 [12800/17352 (74%)] Loss: -1636316.750000\n",
      "Train Epoch: 74 [14208/17352 (82%)] Loss: -1645041.125000\n",
      "Train Epoch: 74 [15616/17352 (90%)] Loss: -1624685.375000\n",
      "Train Epoch: 74 [17024/17352 (98%)] Loss: -1616087.000000\n",
      "    epoch          : 74\n",
      "    loss           : -1615460.0188419118\n",
      "    val_loss       : -1524424.1057434082\n",
      "Train Epoch: 75 [128/17352 (1%)] Loss: -1622144.625000\n",
      "Train Epoch: 75 [1536/17352 (9%)] Loss: -1612416.375000\n",
      "Train Epoch: 75 [2944/17352 (17%)] Loss: -1631936.125000\n",
      "Train Epoch: 75 [4352/17352 (25%)] Loss: -1619900.000000\n",
      "Train Epoch: 75 [5760/17352 (33%)] Loss: -1618374.625000\n",
      "Train Epoch: 75 [7168/17352 (41%)] Loss: -1631256.500000\n",
      "Train Epoch: 75 [8576/17352 (49%)] Loss: -1617056.750000\n",
      "Train Epoch: 75 [9984/17352 (58%)] Loss: -1636673.750000\n",
      "Train Epoch: 75 [11392/17352 (66%)] Loss: -1622227.250000\n",
      "Train Epoch: 75 [12800/17352 (74%)] Loss: -1629821.500000\n",
      "Train Epoch: 75 [14208/17352 (82%)] Loss: -1625185.750000\n",
      "Train Epoch: 75 [15616/17352 (90%)] Loss: -1626324.625000\n",
      "Train Epoch: 75 [17024/17352 (98%)] Loss: -1629305.750000\n",
      "    epoch          : 75\n",
      "    loss           : -1615465.7587316176\n",
      "    val_loss       : -1524328.8630580902\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch75.pth ...\n",
      "Train Epoch: 76 [128/17352 (1%)] Loss: -1618616.750000\n",
      "Train Epoch: 76 [1536/17352 (9%)] Loss: -1607737.375000\n",
      "Train Epoch: 76 [2944/17352 (17%)] Loss: -1626395.625000\n",
      "Train Epoch: 76 [4352/17352 (25%)] Loss: -1613391.500000\n",
      "Train Epoch: 76 [5760/17352 (33%)] Loss: -1628881.125000\n",
      "Train Epoch: 76 [7168/17352 (41%)] Loss: -1626368.375000\n",
      "Train Epoch: 76 [8576/17352 (49%)] Loss: -1618121.625000\n",
      "Train Epoch: 76 [9984/17352 (58%)] Loss: -1629433.875000\n",
      "Train Epoch: 76 [11392/17352 (66%)] Loss: -1605372.375000\n",
      "Train Epoch: 76 [12800/17352 (74%)] Loss: -1621925.000000\n",
      "Train Epoch: 76 [14208/17352 (82%)] Loss: -1622285.250000\n",
      "Train Epoch: 76 [15616/17352 (90%)] Loss: -1625421.750000\n",
      "Train Epoch: 76 [17024/17352 (98%)] Loss: -1610721.625000\n",
      "    epoch          : 76\n",
      "    loss           : -1615478.9728860294\n",
      "    val_loss       : -1524417.1754074097\n",
      "Train Epoch: 77 [128/17352 (1%)] Loss: -1626440.500000\n",
      "Train Epoch: 77 [1536/17352 (9%)] Loss: -1624209.000000\n",
      "Train Epoch: 77 [2944/17352 (17%)] Loss: -1612400.750000\n",
      "Train Epoch: 77 [4352/17352 (25%)] Loss: -1621891.875000\n",
      "Train Epoch: 77 [5760/17352 (33%)] Loss: -1621488.625000\n",
      "Train Epoch: 77 [7168/17352 (41%)] Loss: -1610030.250000\n",
      "Train Epoch: 77 [8576/17352 (49%)] Loss: -1601734.625000\n",
      "Train Epoch: 77 [9984/17352 (58%)] Loss: -1630132.500000\n",
      "Train Epoch: 77 [11392/17352 (66%)] Loss: -1629627.125000\n",
      "Train Epoch: 77 [12800/17352 (74%)] Loss: -1611953.250000\n",
      "Train Epoch: 77 [14208/17352 (82%)] Loss: -1624703.250000\n",
      "Train Epoch: 77 [15616/17352 (90%)] Loss: -1629492.375000\n",
      "Train Epoch: 77 [17024/17352 (98%)] Loss: -1627473.625000\n",
      "    epoch          : 77\n",
      "    loss           : -1615549.3005514706\n",
      "    val_loss       : -1524416.2119207382\n",
      "Train Epoch: 78 [128/17352 (1%)] Loss: -1623626.250000\n",
      "Train Epoch: 78 [1536/17352 (9%)] Loss: -1630070.625000\n",
      "Train Epoch: 78 [2944/17352 (17%)] Loss: -1630674.125000\n",
      "Train Epoch: 78 [4352/17352 (25%)] Loss: -1632438.875000\n",
      "Train Epoch: 78 [5760/17352 (33%)] Loss: -1610091.000000\n",
      "Train Epoch: 78 [7168/17352 (41%)] Loss: -1618786.000000\n",
      "Train Epoch: 78 [8576/17352 (49%)] Loss: -1614590.250000\n",
      "Train Epoch: 78 [9984/17352 (58%)] Loss: -1617991.000000\n",
      "Train Epoch: 78 [11392/17352 (66%)] Loss: -1608417.375000\n",
      "Train Epoch: 78 [12800/17352 (74%)] Loss: -1619639.750000\n",
      "Train Epoch: 78 [14208/17352 (82%)] Loss: -1632932.250000\n",
      "Train Epoch: 78 [15616/17352 (90%)] Loss: -1614758.250000\n",
      "Train Epoch: 78 [17024/17352 (98%)] Loss: -1625679.875000\n",
      "    epoch          : 78\n",
      "    loss           : -1615450.5951286764\n",
      "    val_loss       : -1524427.5988006592\n",
      "Train Epoch: 79 [128/17352 (1%)] Loss: -1612297.875000\n",
      "Train Epoch: 79 [1536/17352 (9%)] Loss: -1630295.500000\n",
      "Train Epoch: 79 [2944/17352 (17%)] Loss: -1624594.250000\n",
      "Train Epoch: 79 [4352/17352 (25%)] Loss: -1617210.125000\n",
      "Train Epoch: 79 [5760/17352 (33%)] Loss: -1618677.750000\n",
      "Train Epoch: 79 [7168/17352 (41%)] Loss: -1617072.500000\n",
      "Train Epoch: 79 [8576/17352 (49%)] Loss: -1613308.500000\n",
      "Train Epoch: 79 [9984/17352 (58%)] Loss: -1623305.750000\n",
      "Train Epoch: 79 [11392/17352 (66%)] Loss: -1624940.750000\n",
      "Train Epoch: 79 [12800/17352 (74%)] Loss: -1630849.375000\n",
      "Train Epoch: 79 [14208/17352 (82%)] Loss: -1600249.750000\n",
      "Train Epoch: 79 [15616/17352 (90%)] Loss: -1622128.500000\n",
      "Train Epoch: 79 [17024/17352 (98%)] Loss: -1623277.000000\n",
      "    epoch          : 79\n",
      "    loss           : -1615496.3033088236\n",
      "    val_loss       : -1524459.2411956787\n",
      "Train Epoch: 80 [128/17352 (1%)] Loss: -1609077.625000\n",
      "Train Epoch: 80 [1536/17352 (9%)] Loss: -1619656.875000\n",
      "Train Epoch: 80 [2944/17352 (17%)] Loss: -1628259.750000\n",
      "Train Epoch: 80 [4352/17352 (25%)] Loss: -1635107.750000\n",
      "Train Epoch: 80 [5760/17352 (33%)] Loss: -1619952.750000\n",
      "Train Epoch: 80 [7168/17352 (41%)] Loss: -1617301.500000\n",
      "Train Epoch: 80 [8576/17352 (49%)] Loss: -1614229.250000\n",
      "Train Epoch: 80 [9984/17352 (58%)] Loss: -1632188.500000\n",
      "Train Epoch: 80 [11392/17352 (66%)] Loss: -1634006.500000\n",
      "Train Epoch: 80 [12800/17352 (74%)] Loss: -1608555.000000\n",
      "Train Epoch: 80 [14208/17352 (82%)] Loss: -1626547.125000\n",
      "Train Epoch: 80 [15616/17352 (90%)] Loss: -1628902.375000\n",
      "Train Epoch: 80 [17024/17352 (98%)] Loss: -1628377.500000\n",
      "    epoch          : 80\n",
      "    loss           : -1615563.7435661764\n",
      "    val_loss       : -1524455.779086113\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch80.pth ...\n",
      "Train Epoch: 81 [128/17352 (1%)] Loss: -1609034.000000\n",
      "Train Epoch: 81 [1536/17352 (9%)] Loss: -1629529.500000\n",
      "Train Epoch: 81 [2944/17352 (17%)] Loss: -1627941.375000\n",
      "Train Epoch: 81 [4352/17352 (25%)] Loss: -1619065.750000\n",
      "Train Epoch: 81 [5760/17352 (33%)] Loss: -1638781.000000\n",
      "Train Epoch: 81 [7168/17352 (41%)] Loss: -1626975.625000\n",
      "Train Epoch: 81 [8576/17352 (49%)] Loss: -1622702.375000\n",
      "Train Epoch: 81 [9984/17352 (58%)] Loss: -1622571.500000\n",
      "Train Epoch: 81 [11392/17352 (66%)] Loss: -1615021.750000\n",
      "Train Epoch: 81 [12800/17352 (74%)] Loss: -1628286.625000\n",
      "Train Epoch: 81 [14208/17352 (82%)] Loss: -1629089.875000\n",
      "Train Epoch: 81 [15616/17352 (90%)] Loss: -1632755.250000\n",
      "Train Epoch: 81 [17024/17352 (98%)] Loss: -1624062.125000\n",
      "    epoch          : 81\n",
      "    loss           : -1615514.6603860294\n",
      "    val_loss       : -1524515.6987113953\n",
      "Train Epoch: 82 [128/17352 (1%)] Loss: -1622820.500000\n",
      "Train Epoch: 82 [1536/17352 (9%)] Loss: -1619531.125000\n",
      "Train Epoch: 82 [2944/17352 (17%)] Loss: -1620780.500000\n",
      "Train Epoch: 82 [4352/17352 (25%)] Loss: -1636040.125000\n",
      "Train Epoch: 82 [5760/17352 (33%)] Loss: -1611388.000000\n",
      "Train Epoch: 82 [7168/17352 (41%)] Loss: -1626625.500000\n",
      "Train Epoch: 82 [8576/17352 (49%)] Loss: -1623882.500000\n",
      "Train Epoch: 82 [9984/17352 (58%)] Loss: -1625435.375000\n",
      "Train Epoch: 82 [11392/17352 (66%)] Loss: -1623961.750000\n",
      "Train Epoch: 82 [12800/17352 (74%)] Loss: -1614274.375000\n",
      "Train Epoch: 82 [14208/17352 (82%)] Loss: -1622335.500000\n",
      "Train Epoch: 82 [15616/17352 (90%)] Loss: -1628604.500000\n",
      "Train Epoch: 82 [17024/17352 (98%)] Loss: -1604122.875000\n",
      "    epoch          : 82\n",
      "    loss           : -1615468.3979779412\n",
      "    val_loss       : -1524407.1348848343\n",
      "Train Epoch: 83 [128/17352 (1%)] Loss: -1617513.500000\n",
      "Train Epoch: 83 [1536/17352 (9%)] Loss: -1637236.000000\n",
      "Train Epoch: 83 [2944/17352 (17%)] Loss: -1607491.625000\n",
      "Train Epoch: 83 [4352/17352 (25%)] Loss: -1636968.375000\n",
      "Train Epoch: 83 [5760/17352 (33%)] Loss: -1633868.000000\n",
      "Train Epoch: 83 [7168/17352 (41%)] Loss: -1626658.125000\n",
      "Train Epoch: 83 [8576/17352 (49%)] Loss: -1624275.250000\n",
      "Train Epoch: 83 [9984/17352 (58%)] Loss: -1620431.000000\n",
      "Train Epoch: 83 [11392/17352 (66%)] Loss: -1603671.875000\n",
      "Train Epoch: 83 [12800/17352 (74%)] Loss: -1611194.250000\n",
      "Train Epoch: 83 [14208/17352 (82%)] Loss: -1621175.500000\n",
      "Train Epoch: 83 [15616/17352 (90%)] Loss: -1640965.375000\n",
      "Train Epoch: 83 [17024/17352 (98%)] Loss: -1620523.500000\n",
      "    epoch          : 83\n",
      "    loss           : -1615550.5974264706\n",
      "    val_loss       : -1524502.4456701279\n",
      "Train Epoch: 84 [128/17352 (1%)] Loss: -1619818.250000\n",
      "Train Epoch: 84 [1536/17352 (9%)] Loss: -1608199.125000\n",
      "Train Epoch: 84 [2944/17352 (17%)] Loss: -1604035.250000\n",
      "Train Epoch: 84 [4352/17352 (25%)] Loss: -1622144.500000\n",
      "Train Epoch: 84 [5760/17352 (33%)] Loss: -1625676.500000\n",
      "Train Epoch: 84 [7168/17352 (41%)] Loss: -1615080.250000\n",
      "Train Epoch: 84 [8576/17352 (49%)] Loss: -1608006.250000\n",
      "Train Epoch: 84 [9984/17352 (58%)] Loss: -1618040.875000\n",
      "Train Epoch: 84 [11392/17352 (66%)] Loss: -1604445.000000\n",
      "Train Epoch: 84 [12800/17352 (74%)] Loss: -1604574.750000\n",
      "Train Epoch: 84 [14208/17352 (82%)] Loss: -1611416.125000\n",
      "Train Epoch: 84 [15616/17352 (90%)] Loss: -1626255.125000\n",
      "Train Epoch: 84 [17024/17352 (98%)] Loss: -1620419.875000\n",
      "    epoch          : 84\n",
      "    loss           : -1615503.3258272058\n",
      "    val_loss       : -1524446.3837957382\n",
      "Train Epoch: 85 [128/17352 (1%)] Loss: -1629919.500000\n",
      "Train Epoch: 85 [1536/17352 (9%)] Loss: -1614920.250000\n",
      "Train Epoch: 85 [2944/17352 (17%)] Loss: -1604618.000000\n",
      "Train Epoch: 85 [4352/17352 (25%)] Loss: -1602261.500000\n",
      "Train Epoch: 85 [5760/17352 (33%)] Loss: -1618895.375000\n",
      "Train Epoch: 85 [7168/17352 (41%)] Loss: -1630570.750000\n",
      "Train Epoch: 85 [8576/17352 (49%)] Loss: -1621818.500000\n",
      "Train Epoch: 85 [9984/17352 (58%)] Loss: -1615295.625000\n",
      "Train Epoch: 85 [11392/17352 (66%)] Loss: -1624414.000000\n",
      "Train Epoch: 85 [12800/17352 (74%)] Loss: -1619178.750000\n",
      "Train Epoch: 85 [14208/17352 (82%)] Loss: -1618687.500000\n",
      "Train Epoch: 85 [15616/17352 (90%)] Loss: -1616290.000000\n",
      "Train Epoch: 85 [17024/17352 (98%)] Loss: -1612646.250000\n",
      "    epoch          : 85\n",
      "    loss           : -1615490.1530330882\n",
      "    val_loss       : -1524500.9317045212\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch85.pth ...\n",
      "Train Epoch: 86 [128/17352 (1%)] Loss: -1631631.625000\n",
      "Train Epoch: 86 [1536/17352 (9%)] Loss: -1631752.500000\n",
      "Train Epoch: 86 [2944/17352 (17%)] Loss: -1615102.000000\n",
      "Train Epoch: 86 [4352/17352 (25%)] Loss: -1626566.125000\n",
      "Train Epoch: 86 [5760/17352 (33%)] Loss: -1611355.250000\n",
      "Train Epoch: 86 [7168/17352 (41%)] Loss: -1616778.375000\n",
      "Train Epoch: 86 [8576/17352 (49%)] Loss: -1625393.875000\n",
      "Train Epoch: 86 [9984/17352 (58%)] Loss: -1620745.500000\n",
      "Train Epoch: 86 [11392/17352 (66%)] Loss: -1623810.000000\n",
      "Train Epoch: 86 [12800/17352 (74%)] Loss: -1628834.375000\n",
      "Train Epoch: 86 [14208/17352 (82%)] Loss: -1619653.250000\n",
      "Train Epoch: 86 [15616/17352 (90%)] Loss: -1625300.750000\n",
      "Train Epoch: 86 [17024/17352 (98%)] Loss: -1618654.625000\n",
      "    epoch          : 86\n",
      "    loss           : -1615572.7757352942\n",
      "    val_loss       : -1524577.993095398\n",
      "Train Epoch: 87 [128/17352 (1%)] Loss: -1635331.625000\n",
      "Train Epoch: 87 [1536/17352 (9%)] Loss: -1623426.500000\n",
      "Train Epoch: 87 [2944/17352 (17%)] Loss: -1625742.500000\n",
      "Train Epoch: 87 [4352/17352 (25%)] Loss: -1630191.125000\n",
      "Train Epoch: 87 [5760/17352 (33%)] Loss: -1627986.250000\n",
      "Train Epoch: 87 [7168/17352 (41%)] Loss: -1630474.625000\n",
      "Train Epoch: 87 [8576/17352 (49%)] Loss: -1618362.875000\n",
      "Train Epoch: 87 [9984/17352 (58%)] Loss: -1627656.250000\n",
      "Train Epoch: 87 [11392/17352 (66%)] Loss: -1631493.500000\n",
      "Train Epoch: 87 [12800/17352 (74%)] Loss: -1610112.750000\n",
      "Train Epoch: 87 [14208/17352 (82%)] Loss: -1631005.625000\n",
      "Train Epoch: 87 [15616/17352 (90%)] Loss: -1620370.500000\n",
      "Train Epoch: 87 [17024/17352 (98%)] Loss: -1621352.625000\n",
      "    epoch          : 87\n",
      "    loss           : -1615545.0477941176\n",
      "    val_loss       : -1524498.123506546\n",
      "Train Epoch: 88 [128/17352 (1%)] Loss: -1631585.125000\n",
      "Train Epoch: 88 [1536/17352 (9%)] Loss: -1607443.250000\n",
      "Train Epoch: 88 [2944/17352 (17%)] Loss: -1626045.000000\n",
      "Train Epoch: 88 [4352/17352 (25%)] Loss: -1611110.750000\n",
      "Train Epoch: 88 [5760/17352 (33%)] Loss: -1613450.000000\n",
      "Train Epoch: 88 [7168/17352 (41%)] Loss: -1608918.375000\n",
      "Train Epoch: 88 [8576/17352 (49%)] Loss: -1628712.500000\n",
      "Train Epoch: 88 [9984/17352 (58%)] Loss: -1613620.000000\n",
      "Train Epoch: 88 [11392/17352 (66%)] Loss: -1635213.250000\n",
      "Train Epoch: 88 [12800/17352 (74%)] Loss: -1621944.625000\n",
      "Train Epoch: 88 [14208/17352 (82%)] Loss: -1629521.750000\n",
      "Train Epoch: 88 [15616/17352 (90%)] Loss: -1607118.375000\n",
      "Train Epoch: 88 [17024/17352 (98%)] Loss: -1632497.250000\n",
      "    epoch          : 88\n",
      "    loss           : -1615592.4797794118\n",
      "    val_loss       : -1524338.5571098328\n",
      "Train Epoch: 89 [128/17352 (1%)] Loss: -1621573.750000\n",
      "Train Epoch: 89 [1536/17352 (9%)] Loss: -1621246.875000\n",
      "Train Epoch: 89 [2944/17352 (17%)] Loss: -1607908.250000\n",
      "Train Epoch: 89 [4352/17352 (25%)] Loss: -1615528.250000\n",
      "Train Epoch: 89 [5760/17352 (33%)] Loss: -1607927.125000\n",
      "Train Epoch: 89 [7168/17352 (41%)] Loss: -1618566.250000\n",
      "Train Epoch: 89 [8576/17352 (49%)] Loss: -1623715.875000\n",
      "Train Epoch: 89 [9984/17352 (58%)] Loss: -1613322.750000\n",
      "Train Epoch: 89 [11392/17352 (66%)] Loss: -1622728.375000\n",
      "Train Epoch: 89 [12800/17352 (74%)] Loss: -1620628.375000\n",
      "Train Epoch: 89 [14208/17352 (82%)] Loss: -1617057.750000\n",
      "Train Epoch: 89 [15616/17352 (90%)] Loss: -1625482.375000\n",
      "Train Epoch: 89 [17024/17352 (98%)] Loss: -1609078.625000\n",
      "    epoch          : 89\n",
      "    loss           : -1615606.4356617648\n",
      "    val_loss       : -1524482.050649643\n",
      "Train Epoch: 90 [128/17352 (1%)] Loss: -1625345.125000\n",
      "Train Epoch: 90 [1536/17352 (9%)] Loss: -1599121.125000\n",
      "Train Epoch: 90 [2944/17352 (17%)] Loss: -1609701.625000\n",
      "Train Epoch: 90 [4352/17352 (25%)] Loss: -1617302.125000\n",
      "Train Epoch: 90 [5760/17352 (33%)] Loss: -1637236.000000\n",
      "Train Epoch: 90 [7168/17352 (41%)] Loss: -1618773.250000\n",
      "Train Epoch: 90 [8576/17352 (49%)] Loss: -1617582.250000\n",
      "Train Epoch: 90 [9984/17352 (58%)] Loss: -1623693.500000\n",
      "Train Epoch: 90 [11392/17352 (66%)] Loss: -1641109.500000\n",
      "Train Epoch: 90 [12800/17352 (74%)] Loss: -1626276.375000\n",
      "Train Epoch: 90 [14208/17352 (82%)] Loss: -1620235.375000\n",
      "Train Epoch: 90 [15616/17352 (90%)] Loss: -1635355.500000\n",
      "Train Epoch: 90 [17024/17352 (98%)] Loss: -1615086.125000\n",
      "    epoch          : 90\n",
      "    loss           : -1615601.4273897058\n",
      "    val_loss       : -1524620.2146167755\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch90.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 91 [128/17352 (1%)] Loss: -1627828.125000\n",
      "Train Epoch: 91 [1536/17352 (9%)] Loss: -1622625.500000\n",
      "Train Epoch: 91 [2944/17352 (17%)] Loss: -1627558.250000\n",
      "Train Epoch: 91 [4352/17352 (25%)] Loss: -1613538.000000\n",
      "Train Epoch: 91 [5760/17352 (33%)] Loss: -1626020.500000\n",
      "Train Epoch: 91 [7168/17352 (41%)] Loss: -1636842.625000\n",
      "Train Epoch: 91 [8576/17352 (49%)] Loss: -1621397.000000\n",
      "Train Epoch: 91 [9984/17352 (58%)] Loss: -1625757.250000\n",
      "Train Epoch: 91 [11392/17352 (66%)] Loss: -1631333.875000\n",
      "Train Epoch: 91 [12800/17352 (74%)] Loss: -1614411.250000\n",
      "Train Epoch: 91 [14208/17352 (82%)] Loss: -1621323.875000\n",
      "Train Epoch: 91 [15616/17352 (90%)] Loss: -1617441.500000\n",
      "Train Epoch: 91 [17024/17352 (98%)] Loss: -1627902.500000\n",
      "    epoch          : 91\n",
      "    loss           : -1615566.2927389706\n",
      "    val_loss       : -1524436.3497171402\n",
      "Train Epoch: 92 [128/17352 (1%)] Loss: -1616335.750000\n",
      "Train Epoch: 92 [1536/17352 (9%)] Loss: -1619796.875000\n",
      "Train Epoch: 92 [2944/17352 (17%)] Loss: -1613557.500000\n",
      "Train Epoch: 92 [4352/17352 (25%)] Loss: -1614609.625000\n",
      "Train Epoch: 92 [5760/17352 (33%)] Loss: -1625851.750000\n",
      "Train Epoch: 92 [7168/17352 (41%)] Loss: -1609934.500000\n",
      "Train Epoch: 92 [8576/17352 (49%)] Loss: -1623221.750000\n",
      "Train Epoch: 92 [9984/17352 (58%)] Loss: -1627485.250000\n",
      "Train Epoch: 92 [11392/17352 (66%)] Loss: -1631652.000000\n",
      "Train Epoch: 92 [12800/17352 (74%)] Loss: -1634656.000000\n",
      "Train Epoch: 92 [14208/17352 (82%)] Loss: -1635028.750000\n",
      "Train Epoch: 92 [15616/17352 (90%)] Loss: -1629115.000000\n",
      "Train Epoch: 92 [17024/17352 (98%)] Loss: -1623803.500000\n",
      "    epoch          : 92\n",
      "    loss           : -1615650.4747242648\n",
      "    val_loss       : -1524530.602268219\n",
      "Train Epoch: 93 [128/17352 (1%)] Loss: -1625576.000000\n",
      "Train Epoch: 93 [1536/17352 (9%)] Loss: -1620999.875000\n",
      "Train Epoch: 93 [2944/17352 (17%)] Loss: -1636453.625000\n",
      "Train Epoch: 93 [4352/17352 (25%)] Loss: -1631129.000000\n",
      "Train Epoch: 93 [5760/17352 (33%)] Loss: -1616849.125000\n",
      "Train Epoch: 93 [7168/17352 (41%)] Loss: -1613538.125000\n",
      "Train Epoch: 93 [8576/17352 (49%)] Loss: -1624164.000000\n",
      "Train Epoch: 93 [9984/17352 (58%)] Loss: -1629575.500000\n",
      "Train Epoch: 93 [11392/17352 (66%)] Loss: -1610650.375000\n",
      "Train Epoch: 93 [12800/17352 (74%)] Loss: -1619334.625000\n",
      "Train Epoch: 93 [14208/17352 (82%)] Loss: -1610337.500000\n",
      "Train Epoch: 93 [15616/17352 (90%)] Loss: -1610073.625000\n",
      "Train Epoch: 93 [17024/17352 (98%)] Loss: -1626033.250000\n",
      "    epoch          : 93\n",
      "    loss           : -1615621.7619485294\n",
      "    val_loss       : -1524491.2038583755\n",
      "Train Epoch: 94 [128/17352 (1%)] Loss: -1610805.500000\n",
      "Train Epoch: 94 [1536/17352 (9%)] Loss: -1617670.750000\n",
      "Train Epoch: 94 [2944/17352 (17%)] Loss: -1630001.625000\n",
      "Train Epoch: 94 [4352/17352 (25%)] Loss: -1616884.250000\n",
      "Train Epoch: 94 [5760/17352 (33%)] Loss: -1632743.875000\n",
      "Train Epoch: 94 [7168/17352 (41%)] Loss: -1623583.125000\n",
      "Train Epoch: 94 [8576/17352 (49%)] Loss: -1625410.250000\n",
      "Train Epoch: 94 [9984/17352 (58%)] Loss: -1618455.875000\n",
      "Train Epoch: 94 [11392/17352 (66%)] Loss: -1620168.000000\n",
      "Train Epoch: 94 [12800/17352 (74%)] Loss: -1617102.375000\n",
      "Train Epoch: 94 [14208/17352 (82%)] Loss: -1627524.750000\n",
      "Train Epoch: 94 [15616/17352 (90%)] Loss: -1609400.750000\n",
      "Train Epoch: 94 [17024/17352 (98%)] Loss: -1630519.000000\n",
      "    epoch          : 94\n",
      "    loss           : -1615581.8740808824\n",
      "    val_loss       : -1524537.7117204666\n",
      "Train Epoch: 95 [128/17352 (1%)] Loss: -1618436.000000\n",
      "Train Epoch: 95 [1536/17352 (9%)] Loss: -1642838.000000\n",
      "Train Epoch: 95 [2944/17352 (17%)] Loss: -1622888.750000\n",
      "Train Epoch: 95 [4352/17352 (25%)] Loss: -1620953.375000\n",
      "Train Epoch: 95 [5760/17352 (33%)] Loss: -1611684.625000\n",
      "Train Epoch: 95 [7168/17352 (41%)] Loss: -1620878.000000\n",
      "Train Epoch: 95 [8576/17352 (49%)] Loss: -1606389.500000\n",
      "Train Epoch: 95 [9984/17352 (58%)] Loss: -1622580.375000\n",
      "Train Epoch: 95 [11392/17352 (66%)] Loss: -1625342.000000\n",
      "Train Epoch: 95 [12800/17352 (74%)] Loss: -1622086.250000\n",
      "Train Epoch: 95 [14208/17352 (82%)] Loss: -1609850.375000\n",
      "Train Epoch: 95 [15616/17352 (90%)] Loss: -1619757.625000\n",
      "Train Epoch: 95 [17024/17352 (98%)] Loss: -1628826.000000\n",
      "    epoch          : 95\n",
      "    loss           : -1615621.9986213236\n",
      "    val_loss       : -1524485.9196329117\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch95.pth ...\n",
      "Train Epoch: 96 [128/17352 (1%)] Loss: -1614574.250000\n",
      "Train Epoch: 96 [1536/17352 (9%)] Loss: -1631484.250000\n",
      "Train Epoch: 96 [2944/17352 (17%)] Loss: -1623530.500000\n",
      "Train Epoch: 96 [4352/17352 (25%)] Loss: -1613839.750000\n",
      "Train Epoch: 96 [5760/17352 (33%)] Loss: -1620560.375000\n",
      "Train Epoch: 96 [7168/17352 (41%)] Loss: -1616621.750000\n",
      "Train Epoch: 96 [8576/17352 (49%)] Loss: -1627370.875000\n",
      "Train Epoch: 96 [9984/17352 (58%)] Loss: -1616783.000000\n",
      "Train Epoch: 96 [11392/17352 (66%)] Loss: -1630649.125000\n",
      "Train Epoch: 96 [12800/17352 (74%)] Loss: -1632824.750000\n",
      "Train Epoch: 96 [14208/17352 (82%)] Loss: -1620201.500000\n",
      "Train Epoch: 96 [15616/17352 (90%)] Loss: -1619955.875000\n",
      "Train Epoch: 96 [17024/17352 (98%)] Loss: -1610577.250000\n",
      "    epoch          : 96\n",
      "    loss           : -1615608.1778492648\n",
      "    val_loss       : -1524547.4292078018\n",
      "Train Epoch: 97 [128/17352 (1%)] Loss: -1615312.000000\n",
      "Train Epoch: 97 [1536/17352 (9%)] Loss: -1617135.500000\n",
      "Train Epoch: 97 [2944/17352 (17%)] Loss: -1616969.250000\n",
      "Train Epoch: 97 [4352/17352 (25%)] Loss: -1624455.750000\n",
      "Train Epoch: 97 [5760/17352 (33%)] Loss: -1612596.625000\n",
      "Train Epoch: 97 [7168/17352 (41%)] Loss: -1620372.000000\n",
      "Train Epoch: 97 [8576/17352 (49%)] Loss: -1623659.750000\n",
      "Train Epoch: 97 [9984/17352 (58%)] Loss: -1609535.875000\n",
      "Train Epoch: 97 [11392/17352 (66%)] Loss: -1621542.500000\n",
      "Train Epoch: 97 [12800/17352 (74%)] Loss: -1622997.125000\n",
      "Train Epoch: 97 [14208/17352 (82%)] Loss: -1629163.625000\n",
      "Train Epoch: 97 [15616/17352 (90%)] Loss: -1617702.000000\n",
      "Train Epoch: 97 [17024/17352 (98%)] Loss: -1601521.000000\n",
      "    epoch          : 97\n",
      "    loss           : -1615636.8556985294\n",
      "    val_loss       : -1524356.5866632462\n",
      "Train Epoch: 98 [128/17352 (1%)] Loss: -1621544.625000\n",
      "Train Epoch: 98 [1536/17352 (9%)] Loss: -1634215.375000\n",
      "Train Epoch: 98 [2944/17352 (17%)] Loss: -1622816.500000\n",
      "Train Epoch: 98 [4352/17352 (25%)] Loss: -1634634.000000\n",
      "Train Epoch: 98 [5760/17352 (33%)] Loss: -1626555.250000\n",
      "Train Epoch: 98 [7168/17352 (41%)] Loss: -1624624.250000\n",
      "Train Epoch: 98 [8576/17352 (49%)] Loss: -1620373.500000\n",
      "Train Epoch: 98 [9984/17352 (58%)] Loss: -1608463.750000\n",
      "Train Epoch: 98 [11392/17352 (66%)] Loss: -1621078.125000\n",
      "Train Epoch: 98 [12800/17352 (74%)] Loss: -1627653.375000\n",
      "Train Epoch: 98 [14208/17352 (82%)] Loss: -1637276.625000\n",
      "Train Epoch: 98 [15616/17352 (90%)] Loss: -1608481.125000\n",
      "Train Epoch: 98 [17024/17352 (98%)] Loss: -1613184.125000\n",
      "    epoch          : 98\n",
      "    loss           : -1615610.0877757352\n",
      "    val_loss       : -1524497.2963409424\n",
      "Train Epoch: 99 [128/17352 (1%)] Loss: -1617467.125000\n",
      "Train Epoch: 99 [1536/17352 (9%)] Loss: -1619479.250000\n",
      "Train Epoch: 99 [2944/17352 (17%)] Loss: -1622199.500000\n",
      "Train Epoch: 99 [4352/17352 (25%)] Loss: -1624840.500000\n",
      "Train Epoch: 99 [5760/17352 (33%)] Loss: -1622316.750000\n",
      "Train Epoch: 99 [7168/17352 (41%)] Loss: -1630776.500000\n",
      "Train Epoch: 99 [8576/17352 (49%)] Loss: -1625075.750000\n",
      "Train Epoch: 99 [9984/17352 (58%)] Loss: -1615251.500000\n",
      "Train Epoch: 99 [11392/17352 (66%)] Loss: -1625077.375000\n",
      "Train Epoch: 99 [12800/17352 (74%)] Loss: -1632189.125000\n",
      "Train Epoch: 99 [14208/17352 (82%)] Loss: -1624281.125000\n",
      "Train Epoch: 99 [15616/17352 (90%)] Loss: -1628846.000000\n",
      "Train Epoch: 99 [17024/17352 (98%)] Loss: -1620553.250000\n",
      "    epoch          : 99\n",
      "    loss           : -1615633.8037683824\n",
      "    val_loss       : -1524431.9283065796\n",
      "Train Epoch: 100 [128/17352 (1%)] Loss: -1613759.875000\n",
      "Train Epoch: 100 [1536/17352 (9%)] Loss: -1624801.250000\n",
      "Train Epoch: 100 [2944/17352 (17%)] Loss: -1620896.750000\n",
      "Train Epoch: 100 [4352/17352 (25%)] Loss: -1621514.000000\n",
      "Train Epoch: 100 [5760/17352 (33%)] Loss: -1612037.000000\n",
      "Train Epoch: 100 [7168/17352 (41%)] Loss: -1625183.750000\n",
      "Train Epoch: 100 [8576/17352 (49%)] Loss: -1614980.000000\n",
      "Train Epoch: 100 [9984/17352 (58%)] Loss: -1618229.875000\n",
      "Train Epoch: 100 [11392/17352 (66%)] Loss: -1623870.750000\n",
      "Train Epoch: 100 [12800/17352 (74%)] Loss: -1620348.000000\n",
      "Train Epoch: 100 [14208/17352 (82%)] Loss: -1617847.500000\n",
      "Train Epoch: 100 [15616/17352 (90%)] Loss: -1618031.375000\n",
      "Train Epoch: 100 [17024/17352 (98%)] Loss: -1620864.875000\n",
      "    epoch          : 100\n",
      "    loss           : -1615614.3795955882\n",
      "    val_loss       : -1524530.6635313034\n",
      "Saving checkpoint: saved/models/Omniglot_VaeCategory/0703_153846/checkpoint-epoch100.pth ...\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:RoutingCategories] *",
   "language": "python",
   "name": "conda-env-RoutingCategories-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
