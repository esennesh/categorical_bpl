{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/categorical_bpl\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = collections.namedtuple('Args', 'config resume device')\n",
    "config = ConfigParser.from_args(Args(config='omniglot_config.json', resume=None, device=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = config.get_logger('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = pyro.optim.ReduceLROnPlateau({\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'optim_args': {\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": 0,\n",
    "        \"amsgrad\": True\n",
    "    },\n",
    "    \"patience\": 50,\n",
    "    \"cooldown\": 25,\n",
    "    \"factor\": 0.1,\n",
    "    \"verbose\": True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, [], optimizer, config=config,\n",
    "                  data_loader=data_loader,\n",
    "                  valid_data_loader=valid_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [512/17352 (3%)] Loss: 1552.681641\n",
      "Train Epoch: 1 [9592/17352 (55%)] Loss: 988.651357\n",
      "Train Epoch: 1 [16939/17352 (98%)] Loss: 889.311752\n",
      "    epoch          : 1\n",
      "    loss           : 1044.2989977842685\n",
      "    val_loss       : 889.4338993343251\n",
      "    val_log_likelihood: -800.0936571734068\n",
      "    val_log_marginal: -880.3878252848282\n",
      "Train Epoch: 2 [512/17352 (3%)] Loss: 973.112305\n",
      "Train Epoch: 2 [9476/17352 (55%)] Loss: 820.424800\n",
      "Train Epoch: 2 [16883/17352 (97%)] Loss: 778.588976\n",
      "    epoch          : 2\n",
      "    loss           : 830.7503319373307\n",
      "    val_loss       : 792.3946961293615\n",
      "    val_log_likelihood: -744.1384637221156\n",
      "    val_log_marginal: -785.3045041801646\n",
      "Train Epoch: 3 [512/17352 (3%)] Loss: 787.868774\n",
      "Train Epoch: 3 [10373/17352 (60%)] Loss: 753.989139\n",
      "Train Epoch: 3 [16883/17352 (97%)] Loss: 745.425087\n",
      "    epoch          : 3\n",
      "    loss           : 764.7033451544048\n",
      "    val_loss       : 744.6411603976234\n",
      "    val_log_likelihood: -710.7182737689758\n",
      "    val_log_marginal: -741.4852658094045\n",
      "Train Epoch: 4 [512/17352 (3%)] Loss: 741.886414\n",
      "Train Epoch: 4 [10376/17352 (60%)] Loss: 717.636104\n",
      "Train Epoch: 4 [16872/17352 (97%)] Loss: 723.340300\n",
      "    epoch          : 4\n",
      "    loss           : 727.9992721967755\n",
      "    val_loss       : 711.8778141672656\n",
      "    val_log_likelihood: -685.2228744915807\n",
      "    val_log_marginal: -708.3423286358909\n",
      "Train Epoch: 5 [512/17352 (3%)] Loss: 711.482666\n",
      "Train Epoch: 5 [10467/17352 (60%)] Loss: 696.564453\n",
      "Train Epoch: 5 [16992/17352 (98%)] Loss: 686.813531\n",
      "    epoch          : 5\n",
      "    loss           : 702.6398561395087\n",
      "    val_loss       : 688.0791487561597\n",
      "    val_log_likelihood: -664.7323649749559\n",
      "    val_log_marginal: -684.1829508232821\n",
      "Train Epoch: 6 [512/17352 (3%)] Loss: 685.010925\n",
      "Train Epoch: 6 [11130/17352 (64%)] Loss: 667.662869\n",
      "Train Epoch: 6 [16957/17352 (98%)] Loss: 666.107581\n",
      "    epoch          : 6\n",
      "    loss           : 678.5229345420668\n",
      "    val_loss       : 665.5558589444927\n",
      "    val_log_likelihood: -644.2824637831745\n",
      "    val_log_marginal: -660.9076374179655\n",
      "Train Epoch: 7 [512/17352 (3%)] Loss: 661.341736\n",
      "Train Epoch: 7 [9836/17352 (57%)] Loss: 657.015885\n",
      "Train Epoch: 7 [17126/17352 (99%)] Loss: 654.798295\n",
      "    epoch          : 7\n",
      "    loss           : 657.9943543818662\n",
      "    val_loss       : 657.0691905242818\n",
      "    val_log_likelihood: -630.5067026967171\n",
      "    val_log_marginal: -653.5841872300214\n",
      "Train Epoch: 8 [512/17352 (3%)] Loss: 653.031128\n",
      "Train Epoch: 8 [10798/17352 (62%)] Loss: 634.888393\n",
      "Train Epoch: 8 [16922/17352 (98%)] Loss: 628.741797\n",
      "    epoch          : 8\n",
      "    loss           : 642.1539500789843\n",
      "    val_loss       : 630.8727920065987\n",
      "    val_log_likelihood: -611.0890347191076\n",
      "    val_log_marginal: -627.6631359682522\n",
      "Train Epoch: 9 [512/17352 (3%)] Loss: 641.207275\n",
      "Train Epoch: 9 [10189/17352 (59%)] Loss: 616.019976\n",
      "Train Epoch: 9 [17263/17352 (99%)] Loss: 623.154605\n",
      "    epoch          : 9\n",
      "    loss           : 621.2083149842852\n",
      "    val_loss       : 613.8961670006302\n",
      "    val_log_likelihood: -595.2690588116978\n",
      "    val_log_marginal: -611.9127681865505\n",
      "Train Epoch: 10 [512/17352 (3%)] Loss: 621.386780\n",
      "Train Epoch: 10 [10575/17352 (61%)] Loss: 606.570476\n",
      "Train Epoch: 10 [16922/17352 (98%)] Loss: 595.561523\n",
      "    epoch          : 10\n",
      "    loss           : 605.9277058073719\n",
      "    val_loss       : 593.7718107766374\n",
      "    val_log_likelihood: -578.678188787448\n",
      "    val_log_marginal: -591.7998187596785\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch10.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 11 [512/17352 (3%)] Loss: 592.262817\n",
      "Train Epoch: 11 [10041/17352 (58%)] Loss: 577.328541\n",
      "Train Epoch: 11 [17143/17352 (99%)] Loss: 582.653449\n",
      "    epoch          : 11\n",
      "    loss           : 588.3930139019945\n",
      "    val_loss       : 579.7911280917087\n",
      "    val_log_likelihood: -562.7915016882379\n",
      "    val_log_marginal: -577.616489392282\n",
      "Train Epoch: 12 [512/17352 (3%)] Loss: 583.114624\n",
      "Train Epoch: 12 [10556/17352 (61%)] Loss: 569.960807\n",
      "Train Epoch: 12 [16878/17352 (97%)] Loss: 568.540215\n",
      "    epoch          : 12\n",
      "    loss           : 572.9585001070493\n",
      "    val_loss       : 563.0648416140707\n",
      "    val_log_likelihood: -547.4585528935842\n",
      "    val_log_marginal: -561.2189467086736\n",
      "Train Epoch: 13 [512/17352 (3%)] Loss: 560.703796\n",
      "Train Epoch: 13 [9951/17352 (57%)] Loss: 545.362630\n",
      "Train Epoch: 13 [17143/17352 (99%)] Loss: 544.787602\n",
      "    epoch          : 13\n",
      "    loss           : 556.7996909708255\n",
      "    val_loss       : 570.2055455254784\n",
      "    val_log_likelihood: -533.0392676973825\n",
      "    val_log_marginal: -567.8925436974522\n",
      "Train Epoch: 14 [512/17352 (3%)] Loss: 569.781860\n",
      "Train Epoch: 14 [10303/17352 (59%)] Loss: 529.971015\n",
      "Train Epoch: 14 [16939/17352 (98%)] Loss: 541.522099\n",
      "    epoch          : 14\n",
      "    loss           : 540.9398557185453\n",
      "    val_loss       : 526.9001644428675\n",
      "    val_log_likelihood: -513.7893520531335\n",
      "    val_log_marginal: -525.9127307888267\n",
      "Train Epoch: 15 [512/17352 (3%)] Loss: 525.112915\n",
      "Train Epoch: 15 [10584/17352 (61%)] Loss: 511.905617\n",
      "Train Epoch: 15 [16882/17352 (97%)] Loss: 515.910225\n",
      "    epoch          : 15\n",
      "    loss           : 520.1578342671895\n",
      "    val_loss       : 508.27258967730387\n",
      "    val_log_likelihood: -497.19342026036475\n",
      "    val_log_marginal: -507.89269882178695\n",
      "Train Epoch: 16 [512/17352 (3%)] Loss: 507.518707\n",
      "Train Epoch: 16 [10178/17352 (59%)] Loss: 499.398047\n",
      "Train Epoch: 16 [17153/17352 (99%)] Loss: 499.833531\n",
      "    epoch          : 16\n",
      "    loss           : 502.59212180434713\n",
      "    val_loss       : 499.8619000996185\n",
      "    val_log_likelihood: -481.6261542165581\n",
      "    val_log_marginal: -498.1942754533573\n",
      "Train Epoch: 17 [512/17352 (3%)] Loss: 503.328186\n",
      "Train Epoch: 17 [10477/17352 (60%)] Loss: 476.508230\n",
      "Train Epoch: 17 [16958/17352 (98%)] Loss: 485.790956\n",
      "    epoch          : 17\n",
      "    loss           : 488.4273926948655\n",
      "    val_loss       : 478.71134397437714\n",
      "    val_log_likelihood: -464.86466373549376\n",
      "    val_log_marginal: -477.58018281547083\n",
      "Train Epoch: 18 [512/17352 (3%)] Loss: 477.266724\n",
      "Train Epoch: 18 [10437/17352 (60%)] Loss: 465.418227\n",
      "Train Epoch: 18 [17133/17352 (99%)] Loss: 458.657945\n",
      "    epoch          : 18\n",
      "    loss           : 472.76978407991515\n",
      "    val_loss       : 465.31190575457674\n",
      "    val_log_likelihood: -448.6336479686815\n",
      "    val_log_marginal: -464.48358987998756\n",
      "Train Epoch: 19 [512/17352 (3%)] Loss: 467.489441\n",
      "Train Epoch: 19 [10368/17352 (60%)] Loss: 461.557292\n",
      "Train Epoch: 19 [17253/17352 (99%)] Loss: 460.725528\n",
      "    epoch          : 19\n",
      "    loss           : 456.3798332211663\n",
      "    val_loss       : 461.0432837884768\n",
      "    val_log_likelihood: -434.0877246642033\n",
      "    val_log_marginal: -460.2810818722273\n",
      "Train Epoch: 20 [512/17352 (3%)] Loss: 457.832642\n",
      "Train Epoch: 20 [10048/17352 (58%)] Loss: 453.986626\n",
      "Train Epoch: 20 [17090/17352 (98%)] Loss: 431.431302\n",
      "    epoch          : 20\n",
      "    loss           : 442.1138833864394\n",
      "    val_loss       : 444.11611977582305\n",
      "    val_log_likelihood: -419.3899093741999\n",
      "    val_log_marginal: -443.4615425712252\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch20.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 21 [512/17352 (3%)] Loss: 445.828308\n",
      "Train Epoch: 21 [10621/17352 (61%)] Loss: 412.150253\n",
      "Train Epoch: 21 [17153/17352 (99%)] Loss: 421.293488\n",
      "    epoch          : 21\n",
      "    loss           : 425.77468313989147\n",
      "    val_loss       : 426.7970012894845\n",
      "    val_log_likelihood: -401.3978098971392\n",
      "    val_log_marginal: -425.8177222244263\n",
      "Train Epoch: 22 [512/17352 (3%)] Loss: 429.421936\n",
      "Train Epoch: 22 [10264/17352 (59%)] Loss: 402.255340\n",
      "Train Epoch: 22 [16887/17352 (97%)] Loss: 403.482787\n",
      "    epoch          : 22\n",
      "    loss           : 409.5271164419171\n",
      "    val_loss       : 403.1700312854988\n",
      "    val_log_likelihood: -384.5319287935575\n",
      "    val_log_marginal: -402.2710121454881\n",
      "Train Epoch: 23 [512/17352 (3%)] Loss: 406.491089\n",
      "Train Epoch: 23 [10597/17352 (61%)] Loss: 379.332023\n",
      "Train Epoch: 23 [17143/17352 (99%)] Loss: 412.649496\n",
      "    epoch          : 23\n",
      "    loss           : 393.41197125111825\n",
      "    val_loss       : 393.714578340442\n",
      "    val_log_likelihood: -369.68817612180015\n",
      "    val_log_marginal: -392.71187837986975\n",
      "Train Epoch: 24 [512/17352 (3%)] Loss: 391.727234\n",
      "Train Epoch: 24 [10339/17352 (60%)] Loss: 371.812579\n",
      "Train Epoch: 24 [16923/17352 (98%)] Loss: 365.362813\n",
      "    epoch          : 24\n",
      "    loss           : 376.54761121910855\n",
      "    val_loss       : 366.2244127567956\n",
      "    val_log_likelihood: -351.4227591068783\n",
      "    val_log_marginal: -365.6699735052007\n",
      "Train Epoch: 25 [512/17352 (3%)] Loss: 365.292786\n",
      "Train Epoch: 25 [10140/17352 (58%)] Loss: 374.556594\n",
      "Train Epoch: 25 [16883/17352 (97%)] Loss: 385.208778\n",
      "    epoch          : 25\n",
      "    loss           : 365.91465079887973\n",
      "    val_loss       : 354.1821174388603\n",
      "    val_log_likelihood: -339.7875831332212\n",
      "    val_log_marginal: -353.3458137844434\n",
      "Train Epoch: 26 [512/17352 (3%)] Loss: 351.358704\n",
      "Train Epoch: 26 [9767/17352 (56%)] Loss: 343.037865\n",
      "Train Epoch: 26 [16958/17352 (98%)] Loss: 346.895484\n",
      "    epoch          : 26\n",
      "    loss           : 353.28960333881986\n",
      "    val_loss       : 338.6083434648559\n",
      "    val_log_likelihood: -323.6680488409378\n",
      "    val_log_marginal: -337.93201882759894\n",
      "Train Epoch: 27 [512/17352 (3%)] Loss: 335.262421\n",
      "Train Epoch: 27 [10418/17352 (60%)] Loss: 331.546050\n",
      "Train Epoch: 27 [17263/17352 (99%)] Loss: 323.402441\n",
      "    epoch          : 27\n",
      "    loss           : 331.4784991816732\n",
      "    val_loss       : 331.2957146572607\n",
      "    val_log_likelihood: -307.8859834323639\n",
      "    val_log_marginal: -330.47664285019175\n",
      "Train Epoch: 28 [512/17352 (3%)] Loss: 331.996582\n",
      "Train Epoch: 28 [10731/17352 (62%)] Loss: 310.487972\n",
      "Train Epoch: 28 [16887/17352 (97%)] Loss: 320.796712\n",
      "    epoch          : 28\n",
      "    loss           : 317.8020076453678\n",
      "    val_loss       : 311.8380018069102\n",
      "    val_log_likelihood: -292.37570169704594\n",
      "    val_log_marginal: -310.98007065503907\n",
      "Train Epoch: 29 [512/17352 (3%)] Loss: 308.051208\n",
      "Train Epoch: 29 [10770/17352 (62%)] Loss: 290.701325\n",
      "Train Epoch: 29 [16988/17352 (98%)] Loss: 301.424265\n",
      "    epoch          : 29\n",
      "    loss           : 302.8621044301459\n",
      "    val_loss       : 296.3837837262964\n",
      "    val_log_likelihood: -276.8263260069009\n",
      "    val_log_marginal: -295.3540886354091\n",
      "Train Epoch: 30 [512/17352 (3%)] Loss: 313.691040\n",
      "Train Epoch: 30 [10608/17352 (61%)] Loss: 265.786133\n",
      "Train Epoch: 30 [16923/17352 (98%)] Loss: 272.526313\n",
      "    epoch          : 30\n",
      "    loss           : 287.27952435931167\n",
      "    val_loss       : 280.6610588052079\n",
      "    val_log_likelihood: -261.19933908251727\n",
      "    val_log_marginal: -280.20085118017374\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch30.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 31 [512/17352 (3%)] Loss: 278.875092\n",
      "Train Epoch: 31 [10137/17352 (58%)] Loss: 280.151989\n",
      "Train Epoch: 31 [17263/17352 (99%)] Loss: 260.097339\n",
      "    epoch          : 31\n",
      "    loss           : 274.7816711733224\n",
      "    val_loss       : 291.72649958596656\n",
      "    val_log_likelihood: -250.2494401146976\n",
      "    val_log_marginal: -291.2213652463059\n",
      "Train Epoch: 32 [512/17352 (3%)] Loss: 309.971191\n",
      "Train Epoch: 32 [10809/17352 (62%)] Loss: 258.728145\n",
      "Train Epoch: 32 [17335/17352 (100%)] Loss: 259.249801\n",
      "    epoch          : 32\n",
      "    loss           : 264.1221575875502\n",
      "    val_loss       : 306.940595179342\n",
      "    val_log_likelihood: -234.56489062010638\n",
      "    val_log_marginal: -305.73609108640665\n",
      "Train Epoch: 33 [512/17352 (3%)] Loss: 307.109955\n",
      "Train Epoch: 33 [10204/17352 (59%)] Loss: 268.890331\n",
      "Train Epoch: 33 [16883/17352 (97%)] Loss: 248.050037\n",
      "    epoch          : 33\n",
      "    loss           : 265.2236379383287\n",
      "    val_loss       : 247.19218820325668\n",
      "    val_log_likelihood: -224.07474830754734\n",
      "    val_log_marginal: -245.951093430845\n",
      "Train Epoch: 34 [512/17352 (3%)] Loss: 241.754425\n",
      "Train Epoch: 34 [10877/17352 (63%)] Loss: 271.008888\n",
      "Train Epoch: 34 [16957/17352 (98%)] Loss: 237.037896\n",
      "    epoch          : 34\n",
      "    loss           : 238.5706188786621\n",
      "    val_loss       : 229.19176621318638\n",
      "    val_log_likelihood: -208.54870022795544\n",
      "    val_log_marginal: -228.56717954378402\n",
      "Train Epoch: 35 [512/17352 (3%)] Loss: 228.148346\n",
      "Train Epoch: 35 [10164/17352 (59%)] Loss: 207.843464\n",
      "Train Epoch: 35 [17263/17352 (99%)] Loss: 215.458426\n",
      "    epoch          : 35\n",
      "    loss           : 223.02079254796058\n",
      "    val_loss       : 225.9187931586617\n",
      "    val_log_likelihood: -195.8337665542841\n",
      "    val_log_marginal: -224.49588414267802\n",
      "Train Epoch: 36 [512/17352 (3%)] Loss: 223.950165\n",
      "Train Epoch: 36 [10485/17352 (60%)] Loss: 195.781139\n",
      "Train Epoch: 36 [16958/17352 (98%)] Loss: 197.800692\n",
      "    epoch          : 36\n",
      "    loss           : 212.78750725565746\n",
      "    val_loss       : 206.3893690649302\n",
      "    val_log_likelihood: -182.36011855210663\n",
      "    val_log_marginal: -205.39086533336211\n",
      "Train Epoch: 37 [512/17352 (3%)] Loss: 204.079941\n",
      "Train Epoch: 37 [9814/17352 (57%)] Loss: 197.909448\n",
      "Train Epoch: 37 [17090/17352 (98%)] Loss: 190.913155\n",
      "    epoch          : 37\n",
      "    loss           : 199.06333674185026\n",
      "    val_loss       : 195.98503962790076\n",
      "    val_log_likelihood: -169.3658431181816\n",
      "    val_log_marginal: -194.64567270904104\n",
      "Train Epoch: 38 [512/17352 (3%)] Loss: 193.615143\n",
      "Train Epoch: 38 [10122/17352 (58%)] Loss: 168.719227\n",
      "Train Epoch: 38 [17143/17352 (99%)] Loss: 194.429773\n",
      "    epoch          : 38\n",
      "    loss           : 188.07625391545716\n",
      "    val_loss       : 191.27557112629307\n",
      "    val_log_likelihood: -157.36568117548327\n",
      "    val_log_marginal: -190.39184404494338\n",
      "Train Epoch: 39 [512/17352 (3%)] Loss: 191.991760\n",
      "Train Epoch: 39 [10605/17352 (61%)] Loss: 203.265771\n",
      "Train Epoch: 39 [17106/17352 (99%)] Loss: 174.026237\n",
      "    epoch          : 39\n",
      "    loss           : 190.92311412840579\n",
      "    val_loss       : 203.33059983532894\n",
      "    val_log_likelihood: -149.05721616135475\n",
      "    val_log_marginal: -202.5308680267405\n",
      "Train Epoch: 40 [512/17352 (3%)] Loss: 199.076843\n",
      "Train Epoch: 40 [10219/17352 (59%)] Loss: 170.478648\n",
      "Train Epoch: 40 [16988/17352 (98%)] Loss: 215.754402\n",
      "    epoch          : 40\n",
      "    loss           : 178.03976682736803\n",
      "    val_loss       : 171.68505919964474\n",
      "    val_log_likelihood: -134.83887213329157\n",
      "    val_log_marginal: -170.5520448928265\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch40.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 41 [512/17352 (3%)] Loss: 173.763519\n",
      "Train Epoch: 41 [10155/17352 (59%)] Loss: 157.181436\n",
      "Train Epoch: 41 [17253/17352 (99%)] Loss: 157.727721\n",
      "    epoch          : 41\n",
      "    loss           : 154.7393445021196\n",
      "    val_loss       : 149.29818742766318\n",
      "    val_log_likelihood: -121.067353325029\n",
      "    val_log_marginal: -148.2657862059108\n",
      "Train Epoch: 42 [512/17352 (3%)] Loss: 147.264389\n",
      "Train Epoch: 42 [10212/17352 (59%)] Loss: 140.490225\n",
      "Train Epoch: 42 [17090/17352 (98%)] Loss: 126.569049\n",
      "    epoch          : 42\n",
      "    loss           : 143.38533883486556\n",
      "    val_loss       : 142.77586819410516\n",
      "    val_log_likelihood: -109.70911691788407\n",
      "    val_log_marginal: -141.86902160231355\n",
      "Train Epoch: 43 [512/17352 (3%)] Loss: 139.785934\n",
      "Train Epoch: 43 [9995/17352 (58%)] Loss: 166.251715\n",
      "Train Epoch: 43 [17143/17352 (99%)] Loss: 142.155115\n",
      "    epoch          : 43\n",
      "    loss           : 135.74031483230436\n",
      "    val_loss       : 131.65116944147476\n",
      "    val_log_likelihood: -99.08185522258644\n",
      "    val_log_marginal: -130.64997647705576\n",
      "Train Epoch: 44 [512/17352 (3%)] Loss: 130.125351\n",
      "Train Epoch: 44 [10509/17352 (61%)] Loss: 108.360592\n",
      "Train Epoch: 44 [17044/17352 (98%)] Loss: 168.086610\n",
      "    epoch          : 44\n",
      "    loss           : 124.86060492374912\n",
      "    val_loss       : 129.3450315052105\n",
      "    val_log_likelihood: -88.19022219579618\n",
      "    val_log_marginal: -128.39845555209692\n",
      "Train Epoch: 45 [512/17352 (3%)] Loss: 126.380409\n",
      "Train Epoch: 45 [9937/17352 (57%)] Loss: 142.690183\n",
      "Train Epoch: 45 [17277/17352 (100%)] Loss: 155.638265\n",
      "    epoch          : 45\n",
      "    loss           : 133.77671532208643\n",
      "    val_loss       : 200.5248435895895\n",
      "    val_log_likelihood: -91.37682887919325\n",
      "    val_log_marginal: -199.09160611579736\n",
      "Train Epoch: 46 [512/17352 (3%)] Loss: 193.743347\n",
      "Train Epoch: 46 [10805/17352 (62%)] Loss: 135.705711\n",
      "Train Epoch: 46 [17064/17352 (98%)] Loss: 104.124122\n",
      "    epoch          : 46\n",
      "    loss           : 125.79364302961544\n",
      "    val_loss       : 118.30898312013322\n",
      "    val_log_likelihood: -73.49895210428356\n",
      "    val_log_marginal: -117.39218361845012\n",
      "Train Epoch: 47 [512/17352 (3%)] Loss: 147.903412\n",
      "Train Epoch: 47 [10172/17352 (59%)] Loss: 119.287782\n",
      "Train Epoch: 47 [16882/17352 (97%)] Loss: 111.783854\n",
      "    epoch          : 47\n",
      "    loss           : 99.76364637352759\n",
      "    val_loss       : 90.49686164960374\n",
      "    val_log_likelihood: -56.90155324000134\n",
      "    val_log_marginal: -89.89019696762048\n",
      "Train Epoch: 48 [512/17352 (3%)] Loss: 84.729507\n",
      "Train Epoch: 48 [10206/17352 (59%)] Loss: 108.082041\n",
      "Train Epoch: 48 [16939/17352 (98%)] Loss: 103.311491\n",
      "    epoch          : 48\n",
      "    loss           : 89.22048176135345\n",
      "    val_loss       : 89.10816777929587\n",
      "    val_log_likelihood: -49.259077485313\n",
      "    val_log_marginal: -87.45264628930589\n",
      "Train Epoch: 49 [512/17352 (3%)] Loss: 84.827232\n",
      "Train Epoch: 49 [10755/17352 (62%)] Loss: 49.865855\n",
      "Train Epoch: 49 [17263/17352 (99%)] Loss: 96.893739\n",
      "    epoch          : 49\n",
      "    loss           : 81.78376971686893\n",
      "    val_loss       : 76.09299326049899\n",
      "    val_log_likelihood: -37.4725760993766\n",
      "    val_log_marginal: -74.6697161513266\n",
      "Train Epoch: 50 [512/17352 (3%)] Loss: 73.293472\n",
      "Train Epoch: 50 [10309/17352 (59%)] Loss: 72.735228\n",
      "Train Epoch: 50 [16934/17352 (98%)] Loss: 93.270116\n",
      "    epoch          : 50\n",
      "    loss           : 70.98885500764106\n",
      "    val_loss       : 67.2092597454724\n",
      "    val_log_likelihood: -25.51392939922521\n",
      "    val_log_marginal: -66.30240507297856\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch50.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 51 [512/17352 (3%)] Loss: 112.615486\n",
      "Train Epoch: 51 [10305/17352 (59%)] Loss: 35.093091\n",
      "Train Epoch: 51 [17049/17352 (98%)] Loss: 102.033589\n",
      "    epoch          : 51\n",
      "    loss           : 65.18141461499962\n",
      "    val_loss       : 80.61193968390825\n",
      "    val_log_likelihood: -18.417945178942265\n",
      "    val_log_marginal: -79.89287739203507\n",
      "Train Epoch: 52 [512/17352 (3%)] Loss: 75.048576\n",
      "Train Epoch: 52 [10284/17352 (59%)] Loss: 105.702087\n",
      "Train Epoch: 52 [17143/17352 (99%)] Loss: 33.055533\n",
      "    epoch          : 52\n",
      "    loss           : 72.6328715742675\n",
      "    val_loss       : 64.11072424525901\n",
      "    val_log_likelihood: -12.370002038129787\n",
      "    val_log_marginal: -62.278450982101255\n",
      "Train Epoch: 53 [512/17352 (3%)] Loss: 58.870300\n",
      "Train Epoch: 53 [10521/17352 (61%)] Loss: 76.921071\n",
      "Train Epoch: 53 [17277/17352 (100%)] Loss: 29.164038\n",
      "    epoch          : 53\n",
      "    loss           : 55.113401272348085\n",
      "    val_loss       : 69.1210831017598\n",
      "    val_log_likelihood: -3.4485044331966352\n",
      "    val_log_marginal: -68.03034078435694\n",
      "Train Epoch: 54 [512/17352 (3%)] Loss: 65.428879\n",
      "Train Epoch: 54 [10538/17352 (61%)] Loss: 16.252819\n",
      "Train Epoch: 54 [16872/17352 (97%)] Loss: 69.068732\n",
      "    epoch          : 54\n",
      "    loss           : 46.64728583230339\n",
      "    val_loss       : 35.28464251356059\n",
      "    val_log_likelihood: 9.10642886166013\n",
      "    val_log_marginal: -34.79327474393161\n",
      "Train Epoch: 55 [512/17352 (3%)] Loss: 30.698326\n",
      "Train Epoch: 55 [10472/17352 (60%)] Loss: 57.874226\n",
      "Train Epoch: 55 [16934/17352 (98%)] Loss: 59.110776\n",
      "    epoch          : 55\n",
      "    loss           : 35.66427963533592\n",
      "    val_loss       : 33.69550242385454\n",
      "    val_log_likelihood: 16.73247576193429\n",
      "    val_log_marginal: -31.50067039949118\n",
      "Train Epoch: 56 [512/17352 (3%)] Loss: 27.079824\n",
      "Train Epoch: 56 [10232/17352 (59%)] Loss: 6.370641\n",
      "Train Epoch: 56 [17153/17352 (99%)] Loss: -17.368490\n",
      "    epoch          : 56\n",
      "    loss           : 30.24079019492423\n",
      "    val_loss       : 34.18620718202982\n",
      "    val_log_likelihood: 22.11658037570205\n",
      "    val_log_marginal: -33.22338459296721\n",
      "Train Epoch: 57 [512/17352 (3%)] Loss: 36.504021\n",
      "Train Epoch: 57 [10250/17352 (59%)] Loss: 24.968089\n",
      "Train Epoch: 57 [16883/17352 (97%)] Loss: 79.977117\n",
      "    epoch          : 57\n",
      "    loss           : 22.61378750458145\n",
      "    val_loss       : 23.03745182731179\n",
      "    val_log_likelihood: 39.99994527073479\n",
      "    val_log_marginal: -20.97486002309077\n",
      "Train Epoch: 58 [512/17352 (3%)] Loss: 16.392120\n",
      "Train Epoch: 58 [10668/17352 (61%)] Loss: -5.072674\n",
      "Train Epoch: 58 [17049/17352 (98%)] Loss: -12.878317\n",
      "    epoch          : 58\n",
      "    loss           : 19.485502125657405\n",
      "    val_loss       : 11.199319646661207\n",
      "    val_log_likelihood: 43.38166651139987\n",
      "    val_log_marginal: -10.195501238107736\n",
      "Train Epoch: 59 [512/17352 (3%)] Loss: 3.620907\n",
      "Train Epoch: 59 [10520/17352 (61%)] Loss: 25.441247\n",
      "Train Epoch: 59 [17064/17352 (98%)] Loss: 29.350577\n",
      "    epoch          : 59\n",
      "    loss           : 11.52791826911337\n",
      "    val_loss       : 9.259404030136945\n",
      "    val_log_likelihood: 52.99975639146651\n",
      "    val_log_marginal: -8.134567098644947\n",
      "Train Epoch: 60 [512/17352 (3%)] Loss: 3.526167\n",
      "Train Epoch: 60 [10121/17352 (58%)] Loss: -52.416178\n",
      "Train Epoch: 60 [17133/17352 (99%)] Loss: 2.428148\n",
      "    epoch          : 60\n",
      "    loss           : 7.999730870145545\n",
      "    val_loss       : 14.238223533407824\n",
      "    val_log_likelihood: 58.31908329357627\n",
      "    val_log_marginal: -12.116267549740156\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch60.pth ...\n",
      "Train Epoch: 61 [512/17352 (3%)] Loss: 8.177123\n",
      "Train Epoch: 61 [10131/17352 (58%)] Loss: -23.145925\n",
      "Train Epoch: 61 [17049/17352 (98%)] Loss: -38.558536\n",
      "    epoch          : 61\n",
      "    loss           : 2.7235615836499263\n",
      "    val_loss       : 0.4412901693152182\n",
      "    val_log_likelihood: 68.42587100621174\n",
      "    val_log_marginal: 1.6194241062720907\n",
      "Train Epoch: 62 [512/17352 (3%)] Loss: -3.982142\n",
      "Train Epoch: 62 [10053/17352 (58%)] Loss: 11.072411\n",
      "Train Epoch: 62 [17335/17352 (100%)] Loss: 69.804610\n",
      "    epoch          : 62\n",
      "    loss           : -3.019004497876738\n",
      "    val_loss       : 22.72997264109027\n",
      "    val_log_likelihood: 75.47887133414491\n",
      "    val_log_marginal: -19.83738488925544\n",
      "Train Epoch: 63 [512/17352 (3%)] Loss: 17.988541\n",
      "Train Epoch: 63 [10553/17352 (61%)] Loss: 15.194803\n",
      "Train Epoch: 63 [16988/17352 (98%)] Loss: -13.399408\n",
      "    epoch          : 63\n",
      "    loss           : 3.7071116931777537\n",
      "    val_loss       : 19.36874147792879\n",
      "    val_log_likelihood: 77.09607463106371\n",
      "    val_log_marginal: -17.105535462564767\n",
      "Train Epoch: 64 [512/17352 (3%)] Loss: 16.547428\n",
      "Train Epoch: 64 [10151/17352 (59%)] Loss: 6.245660\n",
      "Train Epoch: 64 [17101/17352 (99%)] Loss: 12.901886\n",
      "    epoch          : 64\n",
      "    loss           : 1.3479761719060885\n",
      "    val_loss       : 7.965592384633918\n",
      "    val_log_likelihood: 85.64508496236607\n",
      "    val_log_marginal: -4.851886414231737\n",
      "Train Epoch: 65 [512/17352 (3%)] Loss: 9.256571\n",
      "Train Epoch: 65 [10412/17352 (60%)] Loss: 2.931103\n",
      "Train Epoch: 65 [16872/17352 (97%)] Loss: -3.017842\n",
      "    epoch          : 65\n",
      "    loss           : -16.610264097344572\n",
      "    val_loss       : -26.627512857032933\n",
      "    val_log_likelihood: 100.1615498581579\n",
      "    val_log_marginal: 28.616925512505606\n",
      "Train Epoch: 66 [512/17352 (3%)] Loss: -21.148201\n",
      "Train Epoch: 66 [10585/17352 (61%)] Loss: 49.012452\n",
      "Train Epoch: 66 [17126/17352 (99%)] Loss: -67.019324\n",
      "    epoch          : 66\n",
      "    loss           : -27.925173919018018\n",
      "    val_loss       : -24.000764973742648\n",
      "    val_log_likelihood: 110.71743001373035\n",
      "    val_log_marginal: 26.311153858694375\n",
      "Train Epoch: 67 [512/17352 (3%)] Loss: -31.961109\n",
      "Train Epoch: 67 [10591/17352 (61%)] Loss: -72.535672\n",
      "Train Epoch: 67 [17335/17352 (100%)] Loss: -70.298838\n",
      "    epoch          : 67\n",
      "    loss           : -32.39198893187071\n",
      "    val_loss       : -14.54204918877633\n",
      "    val_log_likelihood: 119.52520772361858\n",
      "    val_log_marginal: 17.751514076749935\n",
      "Train Epoch: 68 [512/17352 (3%)] Loss: -20.807323\n",
      "Train Epoch: 68 [10775/17352 (62%)] Loss: -58.555664\n",
      "Train Epoch: 68 [17153/17352 (99%)] Loss: -57.980013\n",
      "    epoch          : 68\n",
      "    loss           : -35.02788518282259\n",
      "    val_loss       : -31.51564355800709\n",
      "    val_log_likelihood: 124.95382572261184\n",
      "    val_log_marginal: 36.41200918088871\n",
      "Train Epoch: 69 [512/17352 (3%)] Loss: -38.524765\n",
      "Train Epoch: 69 [9986/17352 (58%)] Loss: -27.892704\n",
      "Train Epoch: 69 [17143/17352 (99%)] Loss: -58.065234\n",
      "    epoch          : 69\n",
      "    loss           : -43.24166359398174\n",
      "    val_loss       : -49.480134405334354\n",
      "    val_log_likelihood: 139.85590855958458\n",
      "    val_log_marginal: 52.8357044166278\n",
      "Train Epoch: 70 [512/17352 (3%)] Loss: -56.310993\n",
      "Train Epoch: 70 [9941/17352 (57%)] Loss: -86.042203\n",
      "Train Epoch: 70 [16883/17352 (97%)] Loss: -92.056125\n",
      "    epoch          : 70\n",
      "    loss           : -53.097074140055554\n",
      "    val_loss       : -41.69464947963409\n",
      "    val_log_likelihood: 150.33419486087516\n",
      "    val_log_marginal: 46.147251877199\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch70.pth ...\n",
      "Train Epoch: 71 [512/17352 (3%)] Loss: -52.456413\n",
      "Train Epoch: 71 [10318/17352 (59%)] Loss: 60.519136\n",
      "Train Epoch: 71 [17106/17352 (99%)] Loss: -14.276881\n",
      "    epoch          : 71\n",
      "    loss           : -3.4127338801016918\n",
      "    val_loss       : 84.48783838479697\n",
      "    val_log_likelihood: 120.87656955009143\n",
      "    val_log_marginal: -80.73901909718454\n",
      "Train Epoch: 72 [512/17352 (3%)] Loss: 75.302574\n",
      "Train Epoch: 72 [10193/17352 (59%)] Loss: 0.713050\n",
      "Train Epoch: 72 [17153/17352 (99%)] Loss: -58.403329\n",
      "    epoch          : 72\n",
      "    loss           : 4.025702087744001\n",
      "    val_loss       : 26.779432451938444\n",
      "    val_log_likelihood: 125.64669757200616\n",
      "    val_log_marginal: -24.642925115131938\n",
      "Train Epoch: 73 [512/17352 (3%)] Loss: 22.302444\n",
      "Train Epoch: 73 [10401/17352 (60%)] Loss: -51.495288\n",
      "Train Epoch: 73 [16992/17352 (98%)] Loss: -47.799354\n",
      "    epoch          : 73\n",
      "    loss           : -34.84453795938571\n",
      "    val_loss       : -58.97224386546554\n",
      "    val_log_likelihood: 153.0824760425922\n",
      "    val_log_marginal: 64.67190830515497\n",
      "Train Epoch: 74 [512/17352 (3%)] Loss: -68.231796\n",
      "Train Epoch: 74 [10365/17352 (60%)] Loss: -79.195956\n",
      "Train Epoch: 74 [17253/17352 (99%)] Loss: 4.431253\n",
      "    epoch          : 74\n",
      "    loss           : -63.59060676204427\n",
      "    val_loss       : -66.36875782935844\n",
      "    val_log_likelihood: 167.19803421378762\n",
      "    val_log_marginal: 70.22204594254823\n",
      "Train Epoch: 75 [512/17352 (3%)] Loss: -79.065170\n",
      "Train Epoch: 75 [10519/17352 (61%)] Loss: -75.607145\n",
      "Train Epoch: 75 [17253/17352 (99%)] Loss: -93.749868\n",
      "    epoch          : 75\n",
      "    loss           : -72.24383796598131\n",
      "    val_loss       : -73.00279882161536\n",
      "    val_log_likelihood: 179.9877595211383\n",
      "    val_log_marginal: 76.35574043766297\n",
      "Train Epoch: 76 [512/17352 (3%)] Loss: -4.710729\n",
      "Train Epoch: 76 [10307/17352 (59%)] Loss: -116.422280\n",
      "Train Epoch: 76 [17253/17352 (99%)] Loss: -88.102482\n",
      "    epoch          : 76\n",
      "    loss           : -80.61666457411923\n",
      "    val_loss       : -84.26336408529804\n",
      "    val_log_likelihood: 193.7443193864303\n",
      "    val_log_marginal: 86.16646208236666\n",
      "Train Epoch: 77 [512/17352 (3%)] Loss: -91.885437\n",
      "Train Epoch: 77 [10675/17352 (62%)] Loss: -82.006420\n",
      "Train Epoch: 77 [17090/17352 (98%)] Loss: -89.195530\n",
      "    epoch          : 77\n",
      "    loss           : -83.40238106877737\n",
      "    val_loss       : -81.74651209521153\n",
      "    val_log_likelihood: 199.30992571048685\n",
      "    val_log_marginal: 88.45311199470054\n",
      "Train Epoch: 78 [512/17352 (3%)] Loss: -52.749428\n",
      "Train Epoch: 78 [9985/17352 (58%)] Loss: -5.933945\n",
      "Train Epoch: 78 [16957/17352 (98%)] Loss: -79.225586\n",
      "    epoch          : 78\n",
      "    loss           : -86.44014714069485\n",
      "    val_loss       : -95.63017500631831\n",
      "    val_log_likelihood: 208.33654108527773\n",
      "    val_log_marginal: 97.9277711264458\n",
      "Train Epoch: 79 [512/17352 (3%)] Loss: -104.597916\n",
      "Train Epoch: 79 [10097/17352 (58%)] Loss: -180.729664\n",
      "Train Epoch: 79 [16878/17352 (97%)] Loss: -121.086224\n",
      "    epoch          : 79\n",
      "    loss           : -98.37675293958667\n",
      "    val_loss       : -107.50235748493495\n",
      "    val_log_likelihood: 219.31288576332747\n",
      "    val_log_marginal: 107.96799414263543\n",
      "Train Epoch: 80 [512/17352 (3%)] Loss: -114.707565\n",
      "Train Epoch: 80 [10475/17352 (60%)] Loss: -90.069420\n",
      "Train Epoch: 80 [17133/17352 (99%)] Loss: -140.106342\n",
      "    epoch          : 80\n",
      "    loss           : -103.69053142893895\n",
      "    val_loss       : -105.75765402179347\n",
      "    val_log_likelihood: 228.14196845658304\n",
      "    val_log_marginal: 112.06424548661846\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch80.pth ...\n",
      "Train Epoch: 81 [512/17352 (3%)] Loss: -108.234070\n",
      "Train Epoch: 81 [10333/17352 (60%)] Loss: -16.471625\n",
      "Train Epoch: 81 [16939/17352 (98%)] Loss: -95.064769\n",
      "    epoch          : 81\n",
      "    loss           : -103.23693153004822\n",
      "    val_loss       : -102.32932318945984\n",
      "    val_log_likelihood: 226.16783589114897\n",
      "    val_log_marginal: 105.85151140053631\n",
      "Train Epoch: 82 [512/17352 (3%)] Loss: -108.628525\n",
      "Train Epoch: 82 [10201/17352 (59%)] Loss: -175.023763\n",
      "Train Epoch: 82 [16958/17352 (98%)] Loss: -122.679376\n",
      "    epoch          : 82\n",
      "    loss           : -101.54100434407462\n",
      "    val_loss       : -111.31234727630287\n",
      "    val_log_likelihood: 239.97974637897678\n",
      "    val_log_marginal: 116.49843096050887\n",
      "Train Epoch: 83 [512/17352 (3%)] Loss: -123.433395\n",
      "Train Epoch: 83 [10720/17352 (62%)] Loss: -156.601483\n",
      "Train Epoch: 83 [17016/17352 (98%)] Loss: -96.865262\n",
      "    epoch          : 83\n",
      "    loss           : -120.20488091874448\n",
      "    val_loss       : -128.89520342787353\n",
      "    val_log_likelihood: 255.02001354679803\n",
      "    val_log_marginal: 130.75498883886735\n",
      "Train Epoch: 84 [512/17352 (3%)] Loss: -114.535423\n",
      "Train Epoch: 84 [9692/17352 (56%)] Loss: -112.138776\n",
      "Train Epoch: 84 [16957/17352 (98%)] Loss: -206.927572\n",
      "    epoch          : 84\n",
      "    loss           : -129.54083847523302\n",
      "    val_loss       : -130.9812944542273\n",
      "    val_log_likelihood: 262.6573196994724\n",
      "    val_log_marginal: 134.79545883740136\n",
      "Train Epoch: 85 [512/17352 (3%)] Loss: -141.401123\n",
      "Train Epoch: 85 [10719/17352 (62%)] Loss: -112.930129\n",
      "Train Epoch: 85 [16958/17352 (98%)] Loss: -135.051049\n",
      "    epoch          : 85\n",
      "    loss           : -114.96159997774153\n",
      "    val_loss       : -113.76317238213657\n",
      "    val_log_likelihood: 257.7158088880042\n",
      "    val_log_marginal: 118.30352338609191\n",
      "Train Epoch: 86 [512/17352 (3%)] Loss: -96.059570\n",
      "Train Epoch: 86 [10375/17352 (60%)] Loss: -113.911361\n",
      "Train Epoch: 86 [17133/17352 (99%)] Loss: -55.225518\n",
      "    epoch          : 86\n",
      "    loss           : -116.32815916039887\n",
      "    val_loss       : -129.52518135819184\n",
      "    val_log_likelihood: 268.34460746567527\n",
      "    val_log_marginal: 134.74611396740124\n",
      "Train Epoch: 87 [512/17352 (3%)] Loss: -43.959267\n",
      "Train Epoch: 87 [10258/17352 (59%)] Loss: -128.236624\n",
      "Train Epoch: 87 [16872/17352 (97%)] Loss: -178.429957\n",
      "    epoch          : 87\n",
      "    loss           : -130.87888989441464\n",
      "    val_loss       : -134.7428469904679\n",
      "    val_log_likelihood: 276.2158854011908\n",
      "    val_log_marginal: 139.52928823471234\n",
      "Train Epoch: 88 [512/17352 (3%)] Loss: -106.604927\n",
      "Train Epoch: 88 [10123/17352 (58%)] Loss: -97.164548\n",
      "Train Epoch: 88 [16922/17352 (98%)] Loss: -144.509408\n",
      "    epoch          : 88\n",
      "    loss           : -133.8514656488649\n",
      "    val_loss       : -146.60886703941395\n",
      "    val_log_likelihood: 286.83759142237295\n",
      "    val_log_marginal: 152.20991807482267\n",
      "Train Epoch: 89 [512/17352 (3%)] Loss: -153.562225\n",
      "Train Epoch: 89 [10380/17352 (60%)] Loss: -145.209418\n",
      "Train Epoch: 89 [17153/17352 (99%)] Loss: -155.631536\n",
      "    epoch          : 89\n",
      "    loss           : -149.63409844603905\n",
      "    val_loss       : -152.7913959394611\n",
      "    val_log_likelihood: 300.32569170875684\n",
      "    val_log_marginal: 157.3709617031771\n",
      "Train Epoch: 90 [512/17352 (3%)] Loss: -159.072632\n",
      "Train Epoch: 90 [9972/17352 (57%)] Loss: -198.811940\n",
      "Train Epoch: 90 [17016/17352 (98%)] Loss: -207.072412\n",
      "    epoch          : 90\n",
      "    loss           : -149.22768181307373\n",
      "    val_loss       : -159.65932578262777\n",
      "    val_log_likelihood: 309.00559649555083\n",
      "    val_log_marginal: 165.41671792604237\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch90.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 91 [512/17352 (3%)] Loss: -164.330536\n",
      "Train Epoch: 91 [9927/17352 (57%)] Loss: -158.575590\n",
      "Train Epoch: 91 [16878/17352 (97%)] Loss: -123.049577\n",
      "    epoch          : 91\n",
      "    loss           : -155.54627782326534\n",
      "    val_loss       : -153.0536981317565\n",
      "    val_log_likelihood: 310.85122912995206\n",
      "    val_log_marginal: 158.4089455342341\n",
      "Train Epoch: 92 [512/17352 (3%)] Loss: -161.666962\n",
      "Train Epoch: 92 [10284/17352 (59%)] Loss: -150.843025\n",
      "Train Epoch: 92 [16887/17352 (97%)] Loss: -128.565766\n",
      "    epoch          : 92\n",
      "    loss           : -157.6665380259232\n",
      "    val_loss       : -164.05981809851474\n",
      "    val_log_likelihood: 317.3778223527598\n",
      "    val_log_marginal: 175.65337356438883\n",
      "Train Epoch: 93 [512/17352 (3%)] Loss: -177.211136\n",
      "Train Epoch: 93 [10482/17352 (60%)] Loss: -121.051364\n",
      "Train Epoch: 93 [17044/17352 (98%)] Loss: -210.491851\n",
      "    epoch          : 93\n",
      "    loss           : -155.03477810323974\n",
      "    val_loss       : -154.19445800657996\n",
      "    val_log_likelihood: 317.11513388327023\n",
      "    val_log_marginal: 159.48431867624814\n",
      "Train Epoch: 94 [512/17352 (3%)] Loss: -155.543808\n",
      "Train Epoch: 94 [11056/17352 (64%)] Loss: -163.389951\n",
      "Train Epoch: 94 [17064/17352 (98%)] Loss: -134.802370\n",
      "    epoch          : 94\n",
      "    loss           : -154.78878338520818\n",
      "    val_loss       : -157.59415251075276\n",
      "    val_log_likelihood: 324.98393599160255\n",
      "    val_log_marginal: 165.1162764000894\n",
      "Train Epoch: 95 [512/17352 (3%)] Loss: -161.243805\n",
      "Train Epoch: 95 [10875/17352 (63%)] Loss: -216.312445\n",
      "Train Epoch: 95 [17143/17352 (99%)] Loss: -167.715824\n",
      "    epoch          : 95\n",
      "    loss           : -157.3584084017667\n",
      "    val_loss       : -139.49004144456424\n",
      "    val_log_likelihood: 334.75822470234135\n",
      "    val_log_marginal: 149.74380542836835\n",
      "Train Epoch: 96 [512/17352 (3%)] Loss: -144.995422\n",
      "Train Epoch: 96 [10014/17352 (58%)] Loss: -189.140095\n",
      "Train Epoch: 96 [16872/17352 (97%)] Loss: -230.505469\n",
      "    epoch          : 96\n",
      "    loss           : -175.8780865376395\n",
      "    val_loss       : -190.75902541537545\n",
      "    val_log_likelihood: 351.8716594436284\n",
      "    val_log_marginal: 194.8765905504859\n",
      "Train Epoch: 97 [512/17352 (3%)] Loss: -196.400314\n",
      "Train Epoch: 97 [10372/17352 (60%)] Loss: -194.786012\n",
      "Train Epoch: 97 [16988/17352 (98%)] Loss: -212.712645\n",
      "    epoch          : 97\n",
      "    loss           : -189.68380282258747\n",
      "    val_loss       : -181.53756146807314\n",
      "    val_log_likelihood: 353.5844946878694\n",
      "    val_log_marginal: 185.35016442652065\n",
      "Train Epoch: 98 [512/17352 (3%)] Loss: -188.646606\n",
      "Train Epoch: 98 [10196/17352 (59%)] Loss: -207.266732\n",
      "Train Epoch: 98 [16957/17352 (98%)] Loss: -118.905412\n",
      "    epoch          : 98\n",
      "    loss           : -192.8818967636791\n",
      "    val_loss       : -198.9035419004154\n",
      "    val_log_likelihood: 360.43181752705704\n",
      "    val_log_marginal: 200.89814064793293\n",
      "Train Epoch: 99 [512/17352 (3%)] Loss: -202.771820\n",
      "Train Epoch: 99 [10174/17352 (59%)] Loss: -243.784844\n",
      "Train Epoch: 99 [17126/17352 (99%)] Loss: -172.266784\n",
      "    epoch          : 99\n",
      "    loss           : -206.33728872664912\n",
      "    val_loss       : -200.8263116461563\n",
      "    val_log_likelihood: 375.8455690468359\n",
      "    val_log_marginal: 207.96864534115986\n",
      "Train Epoch: 100 [512/17352 (3%)] Loss: -200.895508\n",
      "Train Epoch: 100 [10568/17352 (61%)] Loss: -142.647743\n",
      "Train Epoch: 100 [16882/17352 (97%)] Loss: -262.942486\n",
      "    epoch          : 100\n",
      "    loss           : -208.23338480368662\n",
      "    val_loss       : -214.65751954357904\n",
      "    val_log_likelihood: 379.9941979487934\n",
      "    val_log_marginal: 221.80499333496434\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch100.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 101 [512/17352 (3%)] Loss: -221.339249\n",
      "Train Epoch: 101 [10384/17352 (60%)] Loss: -203.332749\n",
      "Train Epoch: 101 [16872/17352 (97%)] Loss: -286.900316\n",
      "    epoch          : 101\n",
      "    loss           : -209.51062234272143\n",
      "    val_loss       : -212.83647710284254\n",
      "    val_log_likelihood: 388.8958677773779\n",
      "    val_log_marginal: 218.9196023800787\n",
      "Train Epoch: 102 [512/17352 (3%)] Loss: -102.020790\n",
      "Train Epoch: 102 [10598/17352 (61%)] Loss: -238.337225\n",
      "Train Epoch: 102 [16882/17352 (97%)] Loss: -213.571309\n",
      "    epoch          : 102\n",
      "    loss           : -179.5817016798611\n",
      "    val_loss       : -168.913392433842\n",
      "    val_log_likelihood: 381.886419136058\n",
      "    val_log_marginal: 180.8344828575068\n",
      "Train Epoch: 103 [512/17352 (3%)] Loss: -197.922699\n",
      "Train Epoch: 103 [10198/17352 (59%)] Loss: -150.764792\n",
      "Train Epoch: 103 [17101/17352 (99%)] Loss: -251.707397\n",
      "    epoch          : 103\n",
      "    loss           : -164.08896489020796\n",
      "    val_loss       : -199.4686775150296\n",
      "    val_log_likelihood: 386.8824301815671\n",
      "    val_log_marginal: 205.09510565808705\n",
      "Train Epoch: 104 [512/17352 (3%)] Loss: -209.358688\n",
      "Train Epoch: 104 [10132/17352 (58%)] Loss: -257.103395\n",
      "Train Epoch: 104 [17108/17352 (99%)] Loss: -231.680832\n",
      "    epoch          : 104\n",
      "    loss           : -220.8559190215458\n",
      "    val_loss       : -214.56542342563986\n",
      "    val_log_likelihood: 409.1587690979525\n",
      "    val_log_marginal: 223.5290522836287\n",
      "Train Epoch: 105 [512/17352 (3%)] Loss: -231.106659\n",
      "Train Epoch: 105 [9979/17352 (58%)] Loss: -303.851203\n",
      "Train Epoch: 105 [17277/17352 (100%)] Loss: -259.846996\n",
      "    epoch          : 105\n",
      "    loss           : -230.036117221751\n",
      "    val_loss       : -229.25802207185504\n",
      "    val_log_likelihood: 417.2319966637205\n",
      "    val_log_marginal: 236.87749950096935\n",
      "Train Epoch: 106 [512/17352 (3%)] Loss: -241.235855\n",
      "Train Epoch: 106 [10488/17352 (60%)] Loss: -283.517297\n",
      "Train Epoch: 106 [16958/17352 (98%)] Loss: -273.370940\n",
      "    epoch          : 106\n",
      "    loss           : -237.51121138587533\n",
      "    val_loss       : -233.24240776733123\n",
      "    val_log_likelihood: 418.81859431072223\n",
      "    val_log_marginal: 242.0860169600074\n",
      "Train Epoch: 107 [512/17352 (3%)] Loss: -249.145813\n",
      "Train Epoch: 107 [10409/17352 (60%)] Loss: -180.174959\n",
      "Train Epoch: 107 [17106/17352 (99%)] Loss: -133.378475\n",
      "    epoch          : 107\n",
      "    loss           : -186.92994050137787\n",
      "    val_loss       : -77.15152374926515\n",
      "    val_log_likelihood: 403.03443399498434\n",
      "    val_log_marginal: 88.15837541865422\n",
      "Train Epoch: 108 [512/17352 (3%)] Loss: 44.881859\n",
      "Train Epoch: 108 [10398/17352 (60%)] Loss: -263.112456\n",
      "Train Epoch: 108 [17016/17352 (98%)] Loss: -223.777116\n",
      "    epoch          : 108\n",
      "    loss           : -145.8336014769102\n",
      "    val_loss       : -152.93173834397396\n",
      "    val_log_likelihood: 397.7693059724879\n",
      "    val_log_marginal: 169.1227254721965\n",
      "Train Epoch: 109 [512/17352 (3%)] Loss: -168.280914\n",
      "Train Epoch: 109 [9934/17352 (57%)] Loss: -234.219823\n",
      "Train Epoch: 109 [16882/17352 (97%)] Loss: -229.435693\n",
      "    epoch          : 109\n",
      "    loss           : -206.63612284917764\n",
      "    val_loss       : -240.09907255228663\n",
      "    val_log_likelihood: 428.1359816341564\n",
      "    val_log_marginal: 246.2929129921643\n",
      "Train Epoch: 110 [512/17352 (3%)] Loss: -247.761246\n",
      "Train Epoch: 110 [9942/17352 (57%)] Loss: -340.019352\n",
      "Train Epoch: 110 [16923/17352 (98%)] Loss: -231.359166\n",
      "    epoch          : 110\n",
      "    loss           : -241.8783244444406\n",
      "    val_loss       : -261.321995288772\n",
      "    val_log_likelihood: 439.40446150033057\n",
      "    val_log_marginal: 265.0634490819302\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch110.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 111 [512/17352 (3%)] Loss: -266.178101\n",
      "Train Epoch: 111 [10252/17352 (59%)] Loss: -230.249594\n",
      "Train Epoch: 111 [16939/17352 (98%)] Loss: -185.596853\n",
      "    epoch          : 111\n",
      "    loss           : -264.3862615668638\n",
      "    val_loss       : -268.99311819997297\n",
      "    val_log_likelihood: 456.18414295197925\n",
      "    val_log_marginal: 276.08253994826316\n",
      "Train Epoch: 112 [512/17352 (3%)] Loss: -236.887558\n",
      "Train Epoch: 112 [9974/17352 (57%)] Loss: -353.300423\n",
      "Train Epoch: 112 [17044/17352 (98%)] Loss: -244.351998\n",
      "    epoch          : 112\n",
      "    loss           : -271.518480676535\n",
      "    val_loss       : -277.2920793352745\n",
      "    val_log_likelihood: 458.7163906793677\n",
      "    val_log_marginal: 279.99779867979174\n",
      "Train Epoch: 113 [512/17352 (3%)] Loss: -161.128479\n",
      "Train Epoch: 113 [9855/17352 (57%)] Loss: -154.944883\n",
      "Train Epoch: 113 [17124/17352 (99%)] Loss: -237.226077\n",
      "    epoch          : 113\n",
      "    loss           : -258.46025151499015\n",
      "    val_loss       : -266.7945330084785\n",
      "    val_log_likelihood: 464.63422531036684\n",
      "    val_log_marginal: 273.8774426947384\n",
      "Train Epoch: 114 [512/17352 (3%)] Loss: -269.341431\n",
      "Train Epoch: 114 [10222/17352 (59%)] Loss: -330.239529\n",
      "Train Epoch: 114 [16934/17352 (98%)] Loss: -324.079222\n",
      "    epoch          : 114\n",
      "    loss           : -260.84131432871726\n",
      "    val_loss       : -243.6103408418155\n",
      "    val_log_likelihood: 459.2864715437778\n",
      "    val_log_marginal: 256.5239562341549\n",
      "Train Epoch: 115 [512/17352 (3%)] Loss: -249.536407\n",
      "Train Epoch: 115 [10157/17352 (59%)] Loss: -235.315493\n",
      "Train Epoch: 115 [16958/17352 (98%)] Loss: -232.635205\n",
      "    epoch          : 115\n",
      "    loss           : -248.32297910619803\n",
      "    val_loss       : -260.14555922630296\n",
      "    val_log_likelihood: 465.3066506324739\n",
      "    val_log_marginal: 270.26849916115236\n",
      "Train Epoch: 116 [512/17352 (3%)] Loss: -254.558014\n",
      "Train Epoch: 116 [9746/17352 (56%)] Loss: -283.635811\n",
      "Train Epoch: 116 [16939/17352 (98%)] Loss: -285.560197\n",
      "    epoch          : 116\n",
      "    loss           : -269.32890797875086\n",
      "    val_loss       : -283.110389776574\n",
      "    val_log_likelihood: 481.01048649410063\n",
      "    val_log_marginal: 287.6845982833498\n",
      "Train Epoch: 117 [512/17352 (3%)] Loss: -290.460693\n",
      "Train Epoch: 117 [10550/17352 (61%)] Loss: -360.852964\n",
      "Train Epoch: 117 [17124/17352 (99%)] Loss: -353.737614\n",
      "    epoch          : 117\n",
      "    loss           : -280.28001891449486\n",
      "    val_loss       : -284.8358668179795\n",
      "    val_log_likelihood: 487.8457880272275\n",
      "    val_log_marginal: 290.4737922821558\n",
      "Train Epoch: 118 [512/17352 (3%)] Loss: -294.307007\n",
      "Train Epoch: 118 [10598/17352 (61%)] Loss: -313.349159\n",
      "Train Epoch: 118 [16887/17352 (97%)] Loss: -363.894635\n",
      "    epoch          : 118\n",
      "    loss           : -292.7781607115453\n",
      "    val_loss       : -299.60023408584135\n",
      "    val_log_likelihood: 495.74660500873205\n",
      "    val_log_marginal: 306.1710879972865\n",
      "Train Epoch: 119 [512/17352 (3%)] Loss: -310.267212\n",
      "Train Epoch: 119 [10285/17352 (59%)] Loss: -352.479661\n",
      "Train Epoch: 119 [17253/17352 (99%)] Loss: -398.121365\n",
      "    epoch          : 119\n",
      "    loss           : -301.2089600401457\n",
      "    val_loss       : -283.62536392201696\n",
      "    val_log_likelihood: 505.98401818461815\n",
      "    val_log_marginal: 290.79638480341987\n",
      "Train Epoch: 120 [512/17352 (3%)] Loss: -292.796387\n",
      "Train Epoch: 120 [10140/17352 (58%)] Loss: -356.375417\n",
      "Train Epoch: 120 [17124/17352 (99%)] Loss: -359.142630\n",
      "    epoch          : 120\n",
      "    loss           : -300.30214204799285\n",
      "    val_loss       : -291.18747766390067\n",
      "    val_log_likelihood: 512.9215310866842\n",
      "    val_log_marginal: 306.98828943106844\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch120.pth ...\n",
      "Train Epoch: 121 [512/17352 (3%)] Loss: -313.832275\n",
      "Train Epoch: 121 [10732/17352 (62%)] Loss: -224.214820\n",
      "Train Epoch: 121 [16992/17352 (98%)] Loss: -251.866477\n",
      "    epoch          : 121\n",
      "    loss           : -298.40358557743286\n",
      "    val_loss       : -272.43361521507455\n",
      "    val_log_likelihood: 505.3650587680325\n",
      "    val_log_marginal: 284.6794700301836\n",
      "Train Epoch: 122 [512/17352 (3%)] Loss: -225.382904\n",
      "Train Epoch: 122 [10633/17352 (61%)] Loss: -345.927762\n",
      "Train Epoch: 122 [17108/17352 (99%)] Loss: -273.190268\n",
      "    epoch          : 122\n",
      "    loss           : -302.40180571569437\n",
      "    val_loss       : -309.57197878332653\n",
      "    val_log_likelihood: 521.4599595872878\n",
      "    val_log_marginal: 317.2349275371801\n",
      "Train Epoch: 123 [512/17352 (3%)] Loss: -202.858078\n",
      "Train Epoch: 123 [9977/17352 (57%)] Loss: -335.146433\n",
      "Train Epoch: 123 [17044/17352 (98%)] Loss: -108.262198\n",
      "    epoch          : 123\n",
      "    loss           : -300.40008186141034\n",
      "    val_loss       : -313.156066651475\n",
      "    val_log_likelihood: 520.96893005272\n",
      "    val_log_marginal: 320.1116221696295\n",
      "Train Epoch: 124 [512/17352 (3%)] Loss: -325.935150\n",
      "Train Epoch: 124 [10342/17352 (60%)] Loss: -375.225130\n",
      "Train Epoch: 124 [16939/17352 (98%)] Loss: -281.807715\n",
      "    epoch          : 124\n",
      "    loss           : -308.55711629778637\n",
      "    val_loss       : -314.1582130351522\n",
      "    val_log_likelihood: 527.6551450909158\n",
      "    val_log_marginal: 320.80873908418243\n",
      "Train Epoch: 125 [512/17352 (3%)] Loss: -312.820007\n",
      "Train Epoch: 125 [10284/17352 (59%)] Loss: -320.680435\n",
      "Train Epoch: 125 [16939/17352 (98%)] Loss: -366.892500\n",
      "    epoch          : 125\n",
      "    loss           : -303.0559342341923\n",
      "    val_loss       : -308.115680022063\n",
      "    val_log_likelihood: 529.646434240221\n",
      "    val_log_marginal: 319.43857366083677\n",
      "Train Epoch: 126 [512/17352 (3%)] Loss: -313.529663\n",
      "Train Epoch: 126 [10177/17352 (59%)] Loss: -336.494434\n",
      "Train Epoch: 126 [17049/17352 (98%)] Loss: -293.194905\n",
      "    epoch          : 126\n",
      "    loss           : -302.012673849032\n",
      "    val_loss       : -295.86291457272984\n",
      "    val_log_likelihood: 529.9998509910557\n",
      "    val_log_marginal: 315.52748708018\n",
      "Train Epoch: 127 [512/17352 (3%)] Loss: -307.564484\n",
      "Train Epoch: 127 [9994/17352 (58%)] Loss: -395.893390\n",
      "Train Epoch: 127 [16882/17352 (97%)] Loss: -347.535608\n",
      "    epoch          : 127\n",
      "    loss           : -319.4528567286089\n",
      "    val_loss       : -320.5128455652705\n",
      "    val_log_likelihood: 543.6801609129061\n",
      "    val_log_marginal: 336.38151561126864\n",
      "Train Epoch: 128 [512/17352 (3%)] Loss: -341.256561\n",
      "Train Epoch: 128 [10355/17352 (60%)] Loss: -147.756367\n",
      "Train Epoch: 128 [17108/17352 (99%)] Loss: -288.695214\n",
      "    epoch          : 128\n",
      "    loss           : -315.0756099121609\n",
      "    val_loss       : -295.1367750606349\n",
      "    val_log_likelihood: 548.8735828766374\n",
      "    val_log_marginal: 300.5132426435299\n",
      "Train Epoch: 129 [512/17352 (3%)] Loss: -292.988098\n",
      "Train Epoch: 129 [10104/17352 (58%)] Loss: -121.064649\n",
      "Train Epoch: 129 [16872/17352 (97%)] Loss: -311.460251\n",
      "    epoch          : 129\n",
      "    loss           : -240.96970225858706\n",
      "    val_loss       : -274.05271938225223\n",
      "    val_log_likelihood: 537.4888800068284\n",
      "    val_log_marginal: 284.4542010984599\n",
      "Train Epoch: 130 [512/17352 (3%)] Loss: -281.513611\n",
      "Train Epoch: 130 [10155/17352 (59%)] Loss: -260.779657\n",
      "Train Epoch: 130 [17263/17352 (99%)] Loss: -384.595814\n",
      "    epoch          : 130\n",
      "    loss           : -295.618912057995\n",
      "    val_loss       : -272.7768090301738\n",
      "    val_log_likelihood: 540.6014882098553\n",
      "    val_log_marginal: 287.90192654846015\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch130.pth ...\n",
      "Train Epoch: 131 [512/17352 (3%)] Loss: -282.648193\n",
      "Train Epoch: 131 [10326/17352 (60%)] Loss: -207.247122\n",
      "Train Epoch: 131 [17124/17352 (99%)] Loss: -289.381596\n",
      "    epoch          : 131\n",
      "    loss           : -309.91737165166404\n",
      "    val_loss       : -306.1383803296239\n",
      "    val_log_likelihood: 552.4861407584355\n",
      "    val_log_marginal: 315.43711980457186\n",
      "Train Epoch: 132 [512/17352 (3%)] Loss: -308.520264\n",
      "Train Epoch: 132 [10534/17352 (61%)] Loss: -344.574498\n",
      "Train Epoch: 132 [17133/17352 (99%)] Loss: -391.906171\n",
      "    epoch          : 132\n",
      "    loss           : -329.352756452809\n",
      "    val_loss       : -342.00362756334374\n",
      "    val_log_likelihood: 572.2761238572723\n",
      "    val_log_marginal: 352.47736196913087\n",
      "Train Epoch: 133 [512/17352 (3%)] Loss: -355.935944\n",
      "Train Epoch: 133 [10411/17352 (60%)] Loss: -321.044666\n",
      "Train Epoch: 133 [16883/17352 (97%)] Loss: -419.440260\n",
      "    epoch          : 133\n",
      "    loss           : -350.66462941006154\n",
      "    val_loss       : -359.6299529567991\n",
      "    val_log_likelihood: 587.3745699236821\n",
      "    val_log_marginal: 372.32695415085976\n",
      "Train Epoch: 134 [512/17352 (3%)] Loss: -382.227173\n",
      "Train Epoch: 134 [10176/17352 (59%)] Loss: -330.762125\n",
      "Train Epoch: 134 [17049/17352 (98%)] Loss: -193.740860\n",
      "    epoch          : 134\n",
      "    loss           : -345.0028313575695\n",
      "    val_loss       : -319.49546283120367\n",
      "    val_log_likelihood: 563.6713619291886\n",
      "    val_log_marginal: 326.5354659607563\n",
      "Train Epoch: 135 [512/17352 (3%)] Loss: -274.461365\n",
      "Train Epoch: 135 [10680/17352 (62%)] Loss: -198.428279\n",
      "Train Epoch: 135 [16872/17352 (97%)] Loss: -423.299219\n",
      "    epoch          : 135\n",
      "    loss           : -329.86797877339984\n",
      "    val_loss       : -354.16435903665354\n",
      "    val_log_likelihood: 578.1695263851676\n",
      "    val_log_marginal: 367.1925241191669\n",
      "Train Epoch: 136 [512/17352 (3%)] Loss: -324.711487\n",
      "Train Epoch: 136 [10628/17352 (61%)] Loss: -347.848204\n",
      "Train Epoch: 136 [16878/17352 (97%)] Loss: -311.987104\n",
      "    epoch          : 136\n",
      "    loss           : -339.7875019173488\n",
      "    val_loss       : -359.8665807948044\n",
      "    val_log_likelihood: 581.4463166502436\n",
      "    val_log_marginal: 369.5460943135889\n",
      "Train Epoch: 137 [512/17352 (3%)] Loss: -318.504669\n",
      "Train Epoch: 137 [9654/17352 (56%)] Loss: -348.171619\n",
      "Train Epoch: 137 [16878/17352 (97%)] Loss: -160.729267\n",
      "    epoch          : 137\n",
      "    loss           : -354.5813051395621\n",
      "    val_loss       : -370.6196775606968\n",
      "    val_log_likelihood: 593.6410425795941\n",
      "    val_log_marginal: 380.26349357246266\n",
      "Train Epoch: 138 [512/17352 (3%)] Loss: -375.470276\n",
      "Train Epoch: 138 [10487/17352 (60%)] Loss: -398.831688\n",
      "Train Epoch: 138 [17101/17352 (99%)] Loss: -410.049684\n",
      "    epoch          : 138\n",
      "    loss           : -367.83378638409016\n",
      "    val_loss       : -369.83436395762465\n",
      "    val_log_likelihood: 602.2313897468159\n",
      "    val_log_marginal: 378.102061842256\n",
      "Train Epoch: 139 [512/17352 (3%)] Loss: -370.058228\n",
      "Train Epoch: 139 [10672/17352 (62%)] Loss: -293.346741\n",
      "Train Epoch: 139 [16883/17352 (97%)] Loss: -425.105381\n",
      "    epoch          : 139\n",
      "    loss           : -373.16052511839894\n",
      "    val_loss       : -376.61742010037756\n",
      "    val_log_likelihood: 611.7042854189255\n",
      "    val_log_marginal: 384.6016990595712\n",
      "Train Epoch: 140 [512/17352 (3%)] Loss: -387.061157\n",
      "Train Epoch: 140 [9866/17352 (57%)] Loss: -232.806672\n",
      "Train Epoch: 140 [16887/17352 (97%)] Loss: -403.792837\n",
      "    epoch          : 140\n",
      "    loss           : -371.87622630520065\n",
      "    val_loss       : -382.5314423633073\n",
      "    val_log_likelihood: 611.5506973650726\n",
      "    val_log_marginal: 393.1014655842688\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch140.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 141 [512/17352 (3%)] Loss: -331.418823\n",
      "Train Epoch: 141 [10537/17352 (61%)] Loss: -380.869209\n",
      "Train Epoch: 141 [17153/17352 (99%)] Loss: -460.050114\n",
      "    epoch          : 141\n",
      "    loss           : -384.81814161589676\n",
      "    val_loss       : -322.95886758278107\n",
      "    val_log_likelihood: 611.7496318889965\n",
      "    val_log_marginal: 331.3083081389298\n",
      "Train Epoch: 142 [512/17352 (3%)] Loss: -198.486694\n",
      "Train Epoch: 142 [10314/17352 (59%)] Loss: -425.938398\n",
      "Train Epoch: 142 [17335/17352 (100%)] Loss: -390.097686\n",
      "    epoch          : 142\n",
      "    loss           : -296.57986948288476\n",
      "    val_loss       : -286.6248417882974\n",
      "    val_log_likelihood: 572.5431611571254\n",
      "    val_log_marginal: 298.28344055102735\n",
      "Train Epoch: 143 [512/17352 (3%)] Loss: -274.191345\n",
      "Train Epoch: 143 [10491/17352 (60%)] Loss: -332.300432\n",
      "Train Epoch: 143 [16934/17352 (98%)] Loss: -323.742188\n",
      "    epoch          : 143\n",
      "    loss           : -304.5589093206969\n",
      "    val_loss       : -324.26341687186607\n",
      "    val_log_likelihood: 607.5379233650355\n",
      "    val_log_marginal: 331.63414386844136\n",
      "Train Epoch: 144 [512/17352 (3%)] Loss: -335.133453\n",
      "Train Epoch: 144 [10122/17352 (58%)] Loss: -258.660788\n",
      "Train Epoch: 144 [16878/17352 (97%)] Loss: -331.452733\n",
      "    epoch          : 144\n",
      "    loss           : -296.58948843249715\n",
      "    val_loss       : -291.4681891745689\n",
      "    val_log_likelihood: 606.9775570068088\n",
      "    val_log_marginal: 309.9701563227336\n",
      "Train Epoch: 145 [512/17352 (3%)] Loss: -242.604034\n",
      "Train Epoch: 145 [10473/17352 (60%)] Loss: -460.226026\n",
      "Train Epoch: 145 [17044/17352 (98%)] Loss: -365.154239\n",
      "    epoch          : 145\n",
      "    loss           : -369.4266177417695\n",
      "    val_loss       : -377.07893633864865\n",
      "    val_log_likelihood: 617.1342891945554\n",
      "    val_log_marginal: 379.23126375832504\n",
      "Train Epoch: 146 [512/17352 (3%)] Loss: -381.287659\n",
      "Train Epoch: 146 [10342/17352 (60%)] Loss: -328.653060\n",
      "Train Epoch: 146 [16958/17352 (98%)] Loss: -394.386973\n",
      "    epoch          : 146\n",
      "    loss           : -376.83696411179227\n",
      "    val_loss       : -364.96603133456057\n",
      "    val_log_likelihood: 622.5899815923269\n",
      "    val_log_marginal: 380.11376469574117\n",
      "Train Epoch: 147 [512/17352 (3%)] Loss: -359.657959\n",
      "Train Epoch: 147 [9767/17352 (56%)] Loss: -413.456868\n",
      "Train Epoch: 147 [17108/17352 (99%)] Loss: -378.711285\n",
      "    epoch          : 147\n",
      "    loss           : -390.8983046960297\n",
      "    val_loss       : -400.7772397092964\n",
      "    val_log_likelihood: 635.7034854281693\n",
      "    val_log_marginal: 412.7401012958279\n",
      "Train Epoch: 148 [512/17352 (3%)] Loss: -407.936005\n",
      "Train Epoch: 148 [9988/17352 (58%)] Loss: -401.101883\n",
      "Train Epoch: 148 [17064/17352 (98%)] Loss: -423.919496\n",
      "    epoch          : 148\n",
      "    loss           : -405.5634164019677\n",
      "    val_loss       : -410.5398283997327\n",
      "    val_log_likelihood: 648.507591069686\n",
      "    val_log_marginal: 416.84395729933277\n",
      "Train Epoch: 149 [512/17352 (3%)] Loss: -415.577759\n",
      "Train Epoch: 149 [10987/17352 (63%)] Loss: -278.882812\n",
      "Train Epoch: 149 [17016/17352 (98%)] Loss: -463.647812\n",
      "    epoch          : 149\n",
      "    loss           : -406.70655531739067\n",
      "    val_loss       : -402.9917630822739\n",
      "    val_log_likelihood: 652.7185555050129\n",
      "    val_log_marginal: 419.01537094100337\n",
      "Train Epoch: 150 [512/17352 (3%)] Loss: -380.315674\n",
      "Train Epoch: 150 [10275/17352 (59%)] Loss: -389.529731\n",
      "Train Epoch: 150 [17143/17352 (99%)] Loss: -245.966868\n",
      "    epoch          : 150\n",
      "    loss           : -408.7441655265533\n",
      "    val_loss       : -394.9697645815846\n",
      "    val_log_likelihood: 647.1094407033695\n",
      "    val_log_marginal: 408.0598363052657\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch150.pth ...\n",
      "Train Epoch: 151 [512/17352 (3%)] Loss: -394.436005\n",
      "Train Epoch: 151 [10192/17352 (59%)] Loss: -487.333216\n",
      "Train Epoch: 151 [17126/17352 (99%)] Loss: -489.199010\n",
      "    epoch          : 151\n",
      "    loss           : -418.3670875004585\n",
      "    val_loss       : -415.26484012538805\n",
      "    val_log_likelihood: 654.1695168854255\n",
      "    val_log_marginal: 422.07967806842726\n",
      "Train Epoch: 152 [512/17352 (3%)] Loss: -416.094849\n",
      "Train Epoch: 152 [10719/17352 (62%)] Loss: -287.104914\n",
      "Train Epoch: 152 [16923/17352 (98%)] Loss: -446.814646\n",
      "    epoch          : 152\n",
      "    loss           : -432.56084628201205\n",
      "    val_loss       : -433.6806427801767\n",
      "    val_log_likelihood: 670.4301885256411\n",
      "    val_log_marginal: 440.167114978854\n",
      "Train Epoch: 153 [512/17352 (3%)] Loss: -424.639648\n",
      "Train Epoch: 153 [10502/17352 (61%)] Loss: -491.490799\n",
      "Train Epoch: 153 [17101/17352 (99%)] Loss: -410.148917\n",
      "    epoch          : 153\n",
      "    loss           : -426.2753284110942\n",
      "    val_loss       : -405.67122314421596\n",
      "    val_log_likelihood: 669.1713757377732\n",
      "    val_log_marginal: 415.07144689147384\n",
      "Train Epoch: 154 [512/17352 (3%)] Loss: -422.675201\n",
      "Train Epoch: 154 [10049/17352 (58%)] Loss: -413.372231\n",
      "Train Epoch: 154 [16958/17352 (98%)] Loss: -508.250076\n",
      "    epoch          : 154\n",
      "    loss           : -428.82796505801934\n",
      "    val_loss       : -445.66085055393165\n",
      "    val_log_likelihood: 687.5354340020685\n",
      "    val_log_marginal: 451.76869026414755\n",
      "Train Epoch: 155 [512/17352 (3%)] Loss: -449.444916\n",
      "Train Epoch: 155 [10708/17352 (62%)] Loss: -293.666642\n",
      "Train Epoch: 155 [16957/17352 (98%)] Loss: -380.471591\n",
      "    epoch          : 155\n",
      "    loss           : -417.923113469207\n",
      "    val_loss       : -409.681995020777\n",
      "    val_log_likelihood: 675.7219631160054\n",
      "    val_log_marginal: 421.1853691042524\n",
      "Train Epoch: 156 [512/17352 (3%)] Loss: -420.643372\n",
      "Train Epoch: 156 [10476/17352 (60%)] Loss: -464.231727\n",
      "Train Epoch: 156 [16883/17352 (97%)] Loss: -421.716602\n",
      "    epoch          : 156\n",
      "    loss           : -420.16236793128036\n",
      "    val_loss       : -408.49846691494304\n",
      "    val_log_likelihood: 685.5311580149439\n",
      "    val_log_marginal: 420.7310138508696\n",
      "Train Epoch: 157 [512/17352 (3%)] Loss: -415.639252\n",
      "Train Epoch: 157 [10758/17352 (62%)] Loss: -526.814670\n",
      "Train Epoch: 157 [16992/17352 (98%)] Loss: -276.826304\n",
      "    epoch          : 157\n",
      "    loss           : -391.23570649593034\n",
      "    val_loss       : -373.6132916010523\n",
      "    val_log_likelihood: 672.0981899644141\n",
      "    val_log_marginal: 386.5298761467164\n",
      "Train Epoch: 158 [512/17352 (3%)] Loss: -376.978363\n",
      "Train Epoch: 158 [10365/17352 (60%)] Loss: -386.828639\n",
      "Train Epoch: 158 [17277/17352 (100%)] Loss: -229.558463\n",
      "    epoch          : 158\n",
      "    loss           : -307.78708085531247\n",
      "    val_loss       : 956.3913328871381\n",
      "    val_log_likelihood: 555.0066099014408\n",
      "    val_log_marginal: -936.9394830583991\n",
      "Train Epoch: 159 [512/17352 (3%)] Loss: 871.720703\n",
      "Train Epoch: 159 [10622/17352 (61%)] Loss: -49.974746\n",
      "Train Epoch: 159 [17016/17352 (98%)] Loss: -371.843003\n",
      "    epoch          : 159\n",
      "    loss           : -202.55409420488868\n",
      "    val_loss       : -355.7777750832205\n",
      "    val_log_likelihood: 633.3109250518042\n",
      "    val_log_marginal: 369.3419104834775\n",
      "Train Epoch: 160 [512/17352 (3%)] Loss: -218.911469\n",
      "Train Epoch: 160 [10542/17352 (61%)] Loss: -365.414497\n",
      "Train Epoch: 160 [17106/17352 (99%)] Loss: -438.677083\n",
      "    epoch          : 160\n",
      "    loss           : -379.4088552363113\n",
      "    val_loss       : -385.98788729560533\n",
      "    val_log_likelihood: 648.1983033330508\n",
      "    val_log_marginal: 395.54066724637676\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch160.pth ...\n",
      "Train Epoch: 161 [512/17352 (3%)] Loss: -368.520325\n",
      "Train Epoch: 161 [10266/17352 (59%)] Loss: -450.133759\n",
      "Train Epoch: 161 [17143/17352 (99%)] Loss: -477.600260\n",
      "    epoch          : 161\n",
      "    loss           : -409.28125575816813\n",
      "    val_loss       : -399.909664665598\n",
      "    val_log_likelihood: 669.1110047109574\n",
      "    val_log_marginal: 412.90522004321343\n",
      "Train Epoch: 162 [512/17352 (3%)] Loss: -401.830444\n",
      "Train Epoch: 162 [9813/17352 (57%)] Loss: -476.521615\n",
      "Train Epoch: 162 [17090/17352 (98%)] Loss: -532.170356\n",
      "    epoch          : 162\n",
      "    loss           : -414.52250264613696\n",
      "    val_loss       : -393.58306203597044\n",
      "    val_log_likelihood: 677.924569827945\n",
      "    val_log_marginal: 407.5041206917655\n",
      "Train Epoch: 163 [512/17352 (3%)] Loss: -402.371521\n",
      "Train Epoch: 163 [10015/17352 (58%)] Loss: -492.097812\n",
      "Train Epoch: 163 [16992/17352 (98%)] Loss: -492.091490\n",
      "    epoch          : 163\n",
      "    loss           : -413.8217118820453\n",
      "    val_loss       : -433.0670743703439\n",
      "    val_log_likelihood: 696.6290124663844\n",
      "    val_log_marginal: 447.00413963097054\n",
      "Train Epoch: 164 [512/17352 (3%)] Loss: -438.157898\n",
      "Train Epoch: 164 [10424/17352 (60%)] Loss: -302.795367\n",
      "Train Epoch: 164 [17016/17352 (98%)] Loss: -423.253589\n",
      "    epoch          : 164\n",
      "    loss           : -430.8813875722228\n",
      "    val_loss       : -444.9666906294268\n",
      "    val_log_likelihood: 702.9498472875954\n",
      "    val_log_marginal: 454.555917072517\n",
      "Train Epoch: 165 [512/17352 (3%)] Loss: -451.018280\n",
      "Train Epoch: 165 [10580/17352 (61%)] Loss: -428.318490\n",
      "Train Epoch: 165 [16878/17352 (97%)] Loss: -434.513021\n",
      "    epoch          : 165\n",
      "    loss           : -452.35066401677466\n",
      "    val_loss       : -457.6850012573497\n",
      "    val_log_likelihood: 708.4061389052819\n",
      "    val_log_marginal: 466.7745853442286\n",
      "Train Epoch: 166 [512/17352 (3%)] Loss: -470.420807\n",
      "Train Epoch: 166 [10798/17352 (62%)] Loss: -524.548541\n",
      "Train Epoch: 166 [16923/17352 (98%)] Loss: -327.940826\n",
      "    epoch          : 166\n",
      "    loss           : -450.33957337238144\n",
      "    val_loss       : -430.8041995540989\n",
      "    val_log_likelihood: 705.7490482961422\n",
      "    val_log_marginal: 442.90971559380364\n",
      "Train Epoch: 167 [512/17352 (3%)] Loss: -437.398315\n",
      "Train Epoch: 167 [10632/17352 (61%)] Loss: -570.449273\n",
      "Train Epoch: 167 [16992/17352 (98%)] Loss: -450.337804\n",
      "    epoch          : 167\n",
      "    loss           : -457.1721992663412\n",
      "    val_loss       : -441.9447686494097\n",
      "    val_log_likelihood: 720.3045061903695\n",
      "    val_log_marginal: 448.2602493939673\n",
      "Train Epoch: 168 [512/17352 (3%)] Loss: -443.837402\n",
      "Train Epoch: 168 [10793/17352 (62%)] Loss: -397.875874\n",
      "Train Epoch: 168 [17016/17352 (98%)] Loss: -287.423992\n",
      "    epoch          : 168\n",
      "    loss           : -457.1178703320885\n",
      "    val_loss       : -429.6383914616013\n",
      "    val_log_likelihood: 709.2100600348152\n",
      "    val_log_marginal: 452.72710240513015\n",
      "Train Epoch: 169 [512/17352 (3%)] Loss: -269.063110\n",
      "Train Epoch: 169 [10096/17352 (58%)] Loss: -485.126526\n",
      "Train Epoch: 169 [17101/17352 (99%)] Loss: -473.187223\n",
      "    epoch          : 169\n",
      "    loss           : -412.08658593060034\n",
      "    val_loss       : -406.9283868843296\n",
      "    val_log_likelihood: 696.7603884213239\n",
      "    val_log_marginal: 431.22657191026383\n",
      "Train Epoch: 170 [512/17352 (3%)] Loss: -424.376587\n",
      "Train Epoch: 170 [10573/17352 (61%)] Loss: -481.035495\n",
      "Train Epoch: 170 [16992/17352 (98%)] Loss: -429.003065\n",
      "    epoch          : 170\n",
      "    loss           : -429.2569220785255\n",
      "    val_loss       : -435.8081075883656\n",
      "    val_log_likelihood: 711.2660674943423\n",
      "    val_log_marginal: 458.7360138638277\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch170.pth ...\n",
      "Train Epoch: 171 [512/17352 (3%)] Loss: -467.167725\n",
      "Train Epoch: 171 [10417/17352 (60%)] Loss: -326.285287\n",
      "Train Epoch: 171 [16992/17352 (98%)] Loss: -358.133612\n",
      "    epoch          : 171\n",
      "    loss           : -462.9988677497154\n",
      "    val_loss       : -460.6020395299529\n",
      "    val_log_likelihood: 726.5873052138353\n",
      "    val_log_marginal: 472.3499370074508\n",
      "Train Epoch: 172 [512/17352 (3%)] Loss: -468.565704\n",
      "Train Epoch: 172 [10106/17352 (58%)] Loss: -460.162975\n",
      "Train Epoch: 172 [17064/17352 (98%)] Loss: -549.409502\n",
      "    epoch          : 172\n",
      "    loss           : -470.49501729687637\n",
      "    val_loss       : -484.9062989455239\n",
      "    val_log_likelihood: 747.7200892937018\n",
      "    val_log_marginal: 499.08526319221124\n",
      "Train Epoch: 173 [512/17352 (3%)] Loss: -498.192169\n",
      "Train Epoch: 173 [9961/17352 (57%)] Loss: -448.736693\n",
      "Train Epoch: 173 [16939/17352 (98%)] Loss: -456.691275\n",
      "    epoch          : 173\n",
      "    loss           : -444.03059252412476\n",
      "    val_loss       : -456.61669087689353\n",
      "    val_log_likelihood: 729.9169995330349\n",
      "    val_log_marginal: 465.12988836083423\n",
      "Train Epoch: 174 [512/17352 (3%)] Loss: -453.323425\n",
      "Train Epoch: 174 [10742/17352 (62%)] Loss: -325.629332\n",
      "Train Epoch: 174 [17101/17352 (99%)] Loss: -345.383333\n",
      "    epoch          : 174\n",
      "    loss           : -388.2185561778406\n",
      "    val_loss       : -394.79286844127836\n",
      "    val_log_likelihood: 724.4410285469428\n",
      "    val_log_marginal: 404.87875744256775\n",
      "Train Epoch: 175 [512/17352 (3%)] Loss: -388.903687\n",
      "Train Epoch: 175 [10548/17352 (61%)] Loss: -286.369131\n",
      "Train Epoch: 175 [17049/17352 (98%)] Loss: -436.137103\n",
      "    epoch          : 175\n",
      "    loss           : -452.97492209406886\n",
      "    val_loss       : -468.3856131261285\n",
      "    val_log_likelihood: 736.4669789002473\n",
      "    val_log_marginal: 480.9659927023206\n",
      "Train Epoch: 176 [512/17352 (3%)] Loss: -469.071655\n",
      "Train Epoch: 176 [9989/17352 (58%)] Loss: -541.014730\n",
      "Train Epoch: 176 [16882/17352 (97%)] Loss: -567.339687\n",
      "    epoch          : 176\n",
      "    loss           : -472.358179435065\n",
      "    val_loss       : -482.25620504867254\n",
      "    val_log_likelihood: 753.7513926341986\n",
      "    val_log_marginal: 503.62755984115597\n",
      "Train Epoch: 177 [512/17352 (3%)] Loss: -445.292786\n",
      "Train Epoch: 177 [9655/17352 (56%)] Loss: -436.877029\n",
      "Train Epoch: 177 [17016/17352 (98%)] Loss: -468.867171\n",
      "    epoch          : 177\n",
      "    loss           : -494.54847280765995\n",
      "    val_loss       : -472.537029158905\n",
      "    val_log_likelihood: 757.7197844152392\n",
      "    val_log_marginal: 499.8218745568346\n",
      "Train Epoch: 178 [512/17352 (3%)] Loss: -505.137268\n",
      "Train Epoch: 178 [10307/17352 (59%)] Loss: -523.713921\n",
      "Train Epoch: 178 [17090/17352 (98%)] Loss: -442.147333\n",
      "    epoch          : 178\n",
      "    loss           : -471.08493974854275\n",
      "    val_loss       : -399.7593490243095\n",
      "    val_log_likelihood: 710.8131539766371\n",
      "    val_log_marginal: 423.0354898688428\n",
      "Train Epoch: 179 [512/17352 (3%)] Loss: -175.711746\n",
      "Train Epoch: 179 [10462/17352 (60%)] Loss: -525.207002\n",
      "Train Epoch: 179 [16992/17352 (98%)] Loss: -450.107991\n",
      "    epoch          : 179\n",
      "    loss           : -453.2634081322281\n",
      "    val_loss       : -479.00254705304184\n",
      "    val_log_likelihood: 752.4867652326423\n",
      "    val_log_marginal: 488.31209764345834\n",
      "Train Epoch: 180 [512/17352 (3%)] Loss: -403.419464\n",
      "Train Epoch: 180 [10252/17352 (59%)] Loss: -439.579882\n",
      "Train Epoch: 180 [17049/17352 (98%)] Loss: -386.781217\n",
      "    epoch          : 180\n",
      "    loss           : -471.36060494419877\n",
      "    val_loss       : -465.0884294241235\n",
      "    val_log_likelihood: 744.0558593451411\n",
      "    val_log_marginal: 471.8515911248711\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch180.pth ...\n",
      "Train Epoch: 181 [512/17352 (3%)] Loss: -358.873779\n",
      "Train Epoch: 181 [9881/17352 (57%)] Loss: -482.069969\n",
      "Train Epoch: 181 [16922/17352 (98%)] Loss: -521.010969\n",
      "    epoch          : 181\n",
      "    loss           : -480.78563542346654\n",
      "    val_loss       : -475.27128186538215\n",
      "    val_log_likelihood: 753.6790410570491\n",
      "    val_log_marginal: 491.8724490384919\n",
      "Train Epoch: 182 [512/17352 (3%)] Loss: -475.600067\n",
      "Train Epoch: 182 [10699/17352 (62%)] Loss: -506.648047\n",
      "Train Epoch: 182 [16883/17352 (97%)] Loss: -546.657899\n",
      "    epoch          : 182\n",
      "    loss           : -491.45001512918907\n",
      "    val_loss       : -508.22883282393275\n",
      "    val_log_likelihood: 774.9661048088943\n",
      "    val_log_marginal: 515.6995731606048\n",
      "Train Epoch: 183 [512/17352 (3%)] Loss: -517.330566\n",
      "Train Epoch: 183 [10890/17352 (63%)] Loss: -610.759874\n",
      "Train Epoch: 183 [17153/17352 (99%)] Loss: -504.003486\n",
      "    epoch          : 183\n",
      "    loss           : -491.57152415427703\n",
      "    val_loss       : -467.77078424278096\n",
      "    val_log_likelihood: 770.4899931612922\n",
      "    val_log_marginal: 479.87749348399706\n",
      "Train Epoch: 184 [512/17352 (3%)] Loss: -466.301025\n",
      "Train Epoch: 184 [10552/17352 (61%)] Loss: -530.236006\n",
      "Train Epoch: 184 [16958/17352 (98%)] Loss: -431.759433\n",
      "    epoch          : 184\n",
      "    loss           : -492.22294190377636\n",
      "    val_loss       : -500.51426466839683\n",
      "    val_log_likelihood: 774.5322767531269\n",
      "    val_log_marginal: 509.75286766727714\n",
      "Train Epoch: 185 [512/17352 (3%)] Loss: -494.440338\n",
      "Train Epoch: 185 [10549/17352 (61%)] Loss: -486.262826\n",
      "Train Epoch: 185 [17106/17352 (99%)] Loss: -565.511393\n",
      "    epoch          : 185\n",
      "    loss           : -482.0138131909502\n",
      "    val_loss       : -441.11345137642496\n",
      "    val_log_likelihood: 745.044650426942\n",
      "    val_log_marginal: 449.0231702428822\n",
      "Train Epoch: 186 [512/17352 (3%)] Loss: -467.613190\n",
      "Train Epoch: 186 [10164/17352 (59%)] Loss: -575.790000\n",
      "Train Epoch: 186 [17335/17352 (100%)] Loss: -517.984933\n",
      "    epoch          : 186\n",
      "    loss           : -489.90469457936985\n",
      "    val_loss       : -410.9802730772812\n",
      "    val_log_likelihood: 774.3430102443915\n",
      "    val_log_marginal: 421.96046942406144\n",
      "Train Epoch: 187 [512/17352 (3%)] Loss: -408.050323\n",
      "Train Epoch: 187 [10769/17352 (62%)] Loss: -383.752269\n",
      "Train Epoch: 187 [17106/17352 (99%)] Loss: -458.337519\n",
      "    epoch          : 187\n",
      "    loss           : -474.920770986266\n",
      "    val_loss       : -480.3722136301468\n",
      "    val_log_likelihood: 773.3320641405362\n",
      "    val_log_marginal: 493.91897660298815\n",
      "Train Epoch: 188 [512/17352 (3%)] Loss: -488.101135\n",
      "Train Epoch: 188 [10629/17352 (61%)] Loss: -462.858507\n",
      "Train Epoch: 188 [17277/17352 (100%)] Loss: -564.275509\n",
      "    epoch          : 188\n",
      "    loss           : -489.54044669652205\n",
      "    val_loss       : -480.3629119129135\n",
      "    val_log_likelihood: 784.6241548703237\n",
      "    val_log_marginal: 488.109424116612\n",
      "Train Epoch: 189 [512/17352 (3%)] Loss: -485.384827\n",
      "Train Epoch: 189 [10385/17352 (60%)] Loss: -507.709505\n",
      "Train Epoch: 189 [17253/17352 (99%)] Loss: -499.516332\n",
      "    epoch          : 189\n",
      "    loss           : -468.03248329571585\n",
      "    val_loss       : -426.955619666002\n",
      "    val_log_likelihood: 755.6355216492888\n",
      "    val_log_marginal: 436.77510326902296\n",
      "Train Epoch: 190 [512/17352 (3%)] Loss: -411.277924\n",
      "Train Epoch: 190 [10272/17352 (59%)] Loss: -495.329848\n",
      "Train Epoch: 190 [17143/17352 (99%)] Loss: -538.892340\n",
      "    epoch          : 190\n",
      "    loss           : -486.9949887203431\n",
      "    val_loss       : -511.2588103300939\n",
      "    val_log_likelihood: 791.8489544935995\n",
      "    val_log_marginal: 519.4179963969998\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch190.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 191 [512/17352 (3%)] Loss: -518.980774\n",
      "Train Epoch: 191 [10217/17352 (59%)] Loss: -566.193377\n",
      "Train Epoch: 191 [17277/17352 (100%)] Loss: -588.904321\n",
      "    epoch          : 191\n",
      "    loss           : -517.5065039211819\n",
      "    val_loss       : -480.40971320072236\n",
      "    val_log_likelihood: 780.823437562431\n",
      "    val_log_marginal: 493.0752943537847\n",
      "Train Epoch: 192 [512/17352 (3%)] Loss: -484.525818\n",
      "Train Epoch: 192 [10721/17352 (62%)] Loss: -560.068019\n",
      "Train Epoch: 192 [16878/17352 (97%)] Loss: -391.019633\n",
      "    epoch          : 192\n",
      "    loss           : -495.9376887799464\n",
      "    val_loss       : -498.53213801575055\n",
      "    val_log_likelihood: 787.7247807487013\n",
      "    val_log_marginal: 508.8493768244381\n",
      "Train Epoch: 193 [512/17352 (3%)] Loss: -486.721436\n",
      "Train Epoch: 193 [10690/17352 (62%)] Loss: -607.440231\n",
      "Train Epoch: 193 [16887/17352 (97%)] Loss: -341.342878\n",
      "    epoch          : 193\n",
      "    loss           : -486.2261984962085\n",
      "    val_loss       : -430.1606824602462\n",
      "    val_log_likelihood: 778.6939775693427\n",
      "    val_log_marginal: 436.63704459178507\n",
      "Train Epoch: 194 [512/17352 (3%)] Loss: -438.847137\n",
      "Train Epoch: 194 [10124/17352 (58%)] Loss: -502.042048\n",
      "Train Epoch: 194 [17064/17352 (98%)] Loss: -185.260236\n",
      "    epoch          : 194\n",
      "    loss           : -414.6853550302256\n",
      "    val_loss       : -359.8288100012754\n",
      "    val_log_likelihood: 725.5190782191389\n",
      "    val_log_marginal: 379.29190506774165\n",
      "Train Epoch: 195 [512/17352 (3%)] Loss: -354.737549\n",
      "Train Epoch: 195 [10023/17352 (58%)] Loss: -520.961411\n",
      "Train Epoch: 195 [17049/17352 (98%)] Loss: -501.805481\n",
      "    epoch          : 195\n",
      "    loss           : -437.11147472615664\n",
      "    val_loss       : -465.9534369893014\n",
      "    val_log_likelihood: 777.8206483658057\n",
      "    val_log_marginal: 486.32862194104155\n",
      "Train Epoch: 196 [512/17352 (3%)] Loss: -446.758301\n",
      "Train Epoch: 196 [10549/17352 (61%)] Loss: -364.721261\n",
      "Train Epoch: 196 [17133/17352 (99%)] Loss: -579.381613\n",
      "    epoch          : 196\n",
      "    loss           : -486.2646052303595\n",
      "    val_loss       : -501.54902314738905\n",
      "    val_log_likelihood: 791.2663983042256\n",
      "    val_log_marginal: 509.44811692766416\n",
      "Train Epoch: 197 [512/17352 (3%)] Loss: -507.168488\n",
      "Train Epoch: 197 [9849/17352 (57%)] Loss: -520.414825\n",
      "Train Epoch: 197 [16922/17352 (98%)] Loss: -574.651956\n",
      "    epoch          : 197\n",
      "    loss           : -516.4324682058614\n",
      "    val_loss       : -483.3885111224049\n",
      "    val_log_likelihood: 795.545398655937\n",
      "    val_log_marginal: 498.7463511379895\n",
      "Train Epoch: 198 [512/17352 (3%)] Loss: -502.138336\n",
      "Train Epoch: 198 [10040/17352 (58%)] Loss: -526.822525\n",
      "Train Epoch: 198 [17090/17352 (98%)] Loss: -561.394857\n",
      "    epoch          : 198\n",
      "    loss           : -425.601450487179\n",
      "    val_loss       : -324.5058327026396\n",
      "    val_log_likelihood: 770.2462711496562\n",
      "    val_log_marginal: 340.0350611886675\n",
      "Train Epoch: 199 [512/17352 (3%)] Loss: -304.882050\n",
      "Train Epoch: 199 [10521/17352 (61%)] Loss: -513.582332\n",
      "Train Epoch: 199 [17016/17352 (98%)] Loss: -430.734519\n",
      "    epoch          : 199\n",
      "    loss           : -447.54720464533\n",
      "    val_loss       : -490.0320777169873\n",
      "    val_log_likelihood: 796.4767173437058\n",
      "    val_log_marginal: 517.9432377831093\n",
      "Train Epoch: 200 [512/17352 (3%)] Loss: -513.642151\n",
      "Train Epoch: 200 [10246/17352 (59%)] Loss: -281.955517\n",
      "Train Epoch: 200 [17044/17352 (98%)] Loss: -598.118908\n",
      "    epoch          : 200\n",
      "    loss           : -503.0937725748009\n",
      "    val_loss       : -506.9887393522775\n",
      "    val_log_likelihood: 804.4847079437244\n",
      "    val_log_marginal: 520.6521522567173\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch200.pth ...\n",
      "Train Epoch: 201 [512/17352 (3%)] Loss: -519.097778\n",
      "Train Epoch: 201 [10407/17352 (60%)] Loss: -591.421510\n",
      "Train Epoch: 201 [17133/17352 (99%)] Loss: -502.666548\n",
      "    epoch          : 201\n",
      "    loss           : -501.8859260434684\n",
      "    val_loss       : -516.6247691757553\n",
      "    val_log_likelihood: 807.8306967346265\n",
      "    val_log_marginal: 528.2465694440195\n",
      "Train Epoch: 202 [512/17352 (3%)] Loss: -523.157349\n",
      "Train Epoch: 202 [10217/17352 (59%)] Loss: -641.884494\n",
      "Train Epoch: 202 [16992/17352 (98%)] Loss: -529.255604\n",
      "    epoch          : 202\n",
      "    loss           : -537.0590244792231\n",
      "    val_loss       : -535.0320334563221\n",
      "    val_log_likelihood: 825.7948487325853\n",
      "    val_log_marginal: 553.6140535528888\n",
      "Train Epoch: 203 [512/17352 (3%)] Loss: -554.877319\n",
      "Train Epoch: 203 [10443/17352 (60%)] Loss: -421.703985\n",
      "Train Epoch: 203 [17126/17352 (99%)] Loss: -500.307224\n",
      "    epoch          : 203\n",
      "    loss           : -545.2558055428478\n",
      "    val_loss       : -549.629966972663\n",
      "    val_log_likelihood: 831.0954329858413\n",
      "    val_log_marginal: 552.8215767673533\n",
      "Train Epoch: 204 [512/17352 (3%)] Loss: -549.763794\n",
      "Train Epoch: 204 [10113/17352 (58%)] Loss: -591.048401\n",
      "Train Epoch: 204 [17090/17352 (98%)] Loss: -274.423216\n",
      "    epoch          : 204\n",
      "    loss           : -495.64076361494557\n",
      "    val_loss       : -458.64754153130644\n",
      "    val_log_likelihood: 796.5988631811962\n",
      "    val_log_marginal: 483.3486462884812\n",
      "Train Epoch: 205 [512/17352 (3%)] Loss: -341.793396\n",
      "Train Epoch: 205 [10217/17352 (59%)] Loss: -383.739178\n",
      "Train Epoch: 205 [17016/17352 (98%)] Loss: -613.356771\n",
      "    epoch          : 205\n",
      "    loss           : -471.8728611201057\n",
      "    val_loss       : -507.2036186016947\n",
      "    val_log_likelihood: 811.2095637483156\n",
      "    val_log_marginal: 515.7207468745223\n",
      "Train Epoch: 206 [512/17352 (3%)] Loss: -513.930054\n",
      "Train Epoch: 206 [10227/17352 (59%)] Loss: -443.228918\n",
      "Train Epoch: 206 [17253/17352 (99%)] Loss: -546.354653\n",
      "    epoch          : 206\n",
      "    loss           : -517.0339027790563\n",
      "    val_loss       : -473.0808741165606\n",
      "    val_log_likelihood: 805.9653867737981\n",
      "    val_log_marginal: 484.1367103473712\n",
      "Train Epoch: 207 [512/17352 (3%)] Loss: -481.473816\n",
      "Train Epoch: 207 [10074/17352 (58%)] Loss: -573.190957\n",
      "Train Epoch: 207 [17124/17352 (99%)] Loss: -568.527907\n",
      "    epoch          : 207\n",
      "    loss           : -513.3278448251253\n",
      "    val_loss       : -484.2082636439623\n",
      "    val_log_likelihood: 818.4958462162609\n",
      "    val_log_marginal: 518.4028468012654\n",
      "Train Epoch: 208 [512/17352 (3%)] Loss: -453.655640\n",
      "Train Epoch: 208 [9958/17352 (57%)] Loss: -568.429010\n",
      "Train Epoch: 208 [16878/17352 (97%)] Loss: -605.012445\n",
      "    epoch          : 208\n",
      "    loss           : -539.748717224706\n",
      "    val_loss       : -556.8132974216271\n",
      "    val_log_likelihood: 841.0814487833652\n",
      "    val_log_marginal: 565.6681904263643\n",
      "Train Epoch: 209 [512/17352 (3%)] Loss: -511.254730\n",
      "Train Epoch: 209 [10294/17352 (59%)] Loss: -633.309098\n",
      "Train Epoch: 209 [16988/17352 (98%)] Loss: -472.268493\n",
      "    epoch          : 209\n",
      "    loss           : -535.1962307714404\n",
      "    val_loss       : -498.9593746564642\n",
      "    val_log_likelihood: 820.3014411256937\n",
      "    val_log_marginal: 512.2630744620737\n",
      "Train Epoch: 210 [512/17352 (3%)] Loss: -501.574921\n",
      "Train Epoch: 210 [10145/17352 (58%)] Loss: -629.130261\n",
      "Train Epoch: 210 [16878/17352 (97%)] Loss: -610.964894\n",
      "    epoch          : 210\n",
      "    loss           : -526.8500876671874\n",
      "    val_loss       : -525.2532621237154\n",
      "    val_log_likelihood: 836.9287463035673\n",
      "    val_log_marginal: 534.923597926183\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch210.pth ...\n",
      "Train Epoch: 211 [512/17352 (3%)] Loss: -527.442993\n",
      "Train Epoch: 211 [10369/17352 (60%)] Loss: -613.848282\n",
      "Train Epoch: 211 [17064/17352 (98%)] Loss: -592.936234\n",
      "    epoch          : 211\n",
      "    loss           : -551.6515567148095\n",
      "    val_loss       : -480.23000059744305\n",
      "    val_log_likelihood: 833.3914564640455\n",
      "    val_log_marginal: 491.0325067582803\n",
      "Train Epoch: 212 [512/17352 (3%)] Loss: -487.464264\n",
      "Train Epoch: 212 [10602/17352 (61%)] Loss: -511.286372\n",
      "Train Epoch: 212 [16878/17352 (97%)] Loss: -601.861462\n",
      "    epoch          : 212\n",
      "    loss           : -508.75982946423494\n",
      "    val_loss       : -473.07265371768733\n",
      "    val_log_likelihood: 818.744049898516\n",
      "    val_log_marginal: 482.38848761375897\n",
      "Train Epoch: 213 [512/17352 (3%)] Loss: -489.830109\n",
      "Train Epoch: 213 [11048/17352 (64%)] Loss: -465.503023\n",
      "Train Epoch: 213 [17253/17352 (99%)] Loss: -607.995084\n",
      "    epoch          : 213\n",
      "    loss           : -534.7957242871644\n",
      "    val_loss       : -524.855224158476\n",
      "    val_log_likelihood: 834.6276002947664\n",
      "    val_log_marginal: 543.468775905746\n",
      "Train Epoch: 214 [512/17352 (3%)] Loss: -522.914368\n",
      "Train Epoch: 214 [10892/17352 (63%)] Loss: -390.159674\n",
      "Train Epoch: 214 [17133/17352 (99%)] Loss: -509.450135\n",
      "    epoch          : 214\n",
      "    loss           : -534.7978244588073\n",
      "    val_loss       : -549.9307048283573\n",
      "    val_log_likelihood: 848.0795884200845\n",
      "    val_log_marginal: 565.1794496044066\n",
      "Train Epoch: 215 [512/17352 (3%)] Loss: -496.660980\n",
      "Train Epoch: 215 [10143/17352 (58%)] Loss: -536.476279\n",
      "Train Epoch: 215 [16934/17352 (98%)] Loss: -513.625694\n",
      "    epoch          : 215\n",
      "    loss           : -553.4868639953917\n",
      "    val_loss       : -568.7874539345174\n",
      "    val_log_likelihood: 855.8452407732326\n",
      "    val_log_marginal: 577.0110650448504\n",
      "Train Epoch: 216 [512/17352 (3%)] Loss: -573.623047\n",
      "Train Epoch: 216 [10197/17352 (59%)] Loss: -424.586496\n",
      "Train Epoch: 216 [17253/17352 (99%)] Loss: -513.690832\n",
      "    epoch          : 216\n",
      "    loss           : -542.8653145919801\n",
      "    val_loss       : -497.5356629979977\n",
      "    val_log_likelihood: 850.8304005607388\n",
      "    val_log_marginal: 508.41259683054585\n",
      "Train Epoch: 217 [512/17352 (3%)] Loss: -501.956787\n",
      "Train Epoch: 217 [10303/17352 (59%)] Loss: -517.057827\n",
      "Train Epoch: 217 [17108/17352 (99%)] Loss: -574.984049\n",
      "    epoch          : 217\n",
      "    loss           : -421.5921376194138\n",
      "    val_loss       : -406.83677411996314\n",
      "    val_log_likelihood: 783.6559776022773\n",
      "    val_log_marginal: 424.2102000628798\n",
      "Train Epoch: 218 [512/17352 (3%)] Loss: -396.540649\n",
      "Train Epoch: 218 [10448/17352 (60%)] Loss: -312.965054\n",
      "Train Epoch: 218 [17108/17352 (99%)] Loss: -455.955891\n",
      "    epoch          : 218\n",
      "    loss           : -452.5534814266656\n",
      "    val_loss       : -461.11417536343856\n",
      "    val_log_likelihood: 797.4486581955018\n",
      "    val_log_marginal: 472.6556653474101\n",
      "Train Epoch: 219 [512/17352 (3%)] Loss: -486.568024\n",
      "Train Epoch: 219 [10568/17352 (61%)] Loss: -541.918348\n",
      "Train Epoch: 219 [17133/17352 (99%)] Loss: -545.953223\n",
      "    epoch          : 219\n",
      "    loss           : -526.9711381615546\n",
      "    val_loss       : -550.8901777693244\n",
      "    val_log_likelihood: 849.7341775769479\n",
      "    val_log_marginal: 557.493815547165\n",
      "Train Epoch: 220 [512/17352 (3%)] Loss: -561.417480\n",
      "Train Epoch: 220 [10101/17352 (58%)] Loss: -567.858801\n",
      "Train Epoch: 220 [17049/17352 (98%)] Loss: -654.436188\n",
      "    epoch          : 220\n",
      "    loss           : -568.588167958089\n",
      "    val_loss       : -569.957241185532\n",
      "    val_log_likelihood: 859.9950692672395\n",
      "    val_log_marginal: 581.9823439324897\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch220.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 221 [512/17352 (3%)] Loss: -572.154907\n",
      "Train Epoch: 221 [10210/17352 (59%)] Loss: -471.452251\n",
      "Train Epoch: 221 [17277/17352 (100%)] Loss: -583.108270\n",
      "    epoch          : 221\n",
      "    loss           : -539.3485727112393\n",
      "    val_loss       : -504.22196407288027\n",
      "    val_log_likelihood: 831.497928597208\n",
      "    val_log_marginal: 528.4288242647787\n",
      "Train Epoch: 222 [512/17352 (3%)] Loss: -441.278534\n",
      "Train Epoch: 222 [10376/17352 (60%)] Loss: -590.967769\n",
      "Train Epoch: 222 [16882/17352 (97%)] Loss: -519.688904\n",
      "    epoch          : 222\n",
      "    loss           : -500.30730468115064\n",
      "    val_loss       : -522.6034122179174\n",
      "    val_log_likelihood: 838.0224051289074\n",
      "    val_log_marginal: 537.8564208292626\n",
      "Train Epoch: 223 [512/17352 (3%)] Loss: -437.150146\n",
      "Train Epoch: 223 [10186/17352 (59%)] Loss: -606.461702\n",
      "Train Epoch: 223 [17253/17352 (99%)] Loss: -622.749709\n",
      "    epoch          : 223\n",
      "    loss           : -506.7154517927887\n",
      "    val_loss       : -510.2430617682308\n",
      "    val_log_likelihood: 835.3636150536096\n",
      "    val_log_marginal: 531.9530395784562\n",
      "Train Epoch: 224 [512/17352 (3%)] Loss: -549.626709\n",
      "Train Epoch: 224 [10269/17352 (59%)] Loss: -550.600740\n",
      "Train Epoch: 224 [16883/17352 (97%)] Loss: -640.243021\n",
      "    epoch          : 224\n",
      "    loss           : -544.2867829411657\n",
      "    val_loss       : -570.3490134742912\n",
      "    val_log_likelihood: 869.8697626639765\n",
      "    val_log_marginal: 588.0639831653998\n",
      "Train Epoch: 225 [512/17352 (3%)] Loss: -592.459595\n",
      "Train Epoch: 225 [9801/17352 (56%)] Loss: -578.703481\n",
      "Train Epoch: 225 [16887/17352 (97%)] Loss: -537.214489\n",
      "    epoch          : 225\n",
      "    loss           : -537.3071884740406\n",
      "    val_loss       : -550.5665942633112\n",
      "    val_log_likelihood: 852.957558364677\n",
      "    val_log_marginal: 561.0173446759102\n",
      "Train Epoch: 226 [512/17352 (3%)] Loss: -540.023743\n",
      "Train Epoch: 226 [10702/17352 (62%)] Loss: -565.195499\n",
      "Train Epoch: 226 [17108/17352 (99%)] Loss: -632.250834\n",
      "    epoch          : 226\n",
      "    loss           : -560.5422411511978\n",
      "    val_loss       : -557.9397510616955\n",
      "    val_log_likelihood: 856.0105637244467\n",
      "    val_log_marginal: 567.3281556722741\n",
      "Train Epoch: 227 [512/17352 (3%)] Loss: -556.193970\n",
      "Train Epoch: 227 [10374/17352 (60%)] Loss: -577.206773\n",
      "Train Epoch: 227 [16988/17352 (98%)] Loss: -625.011230\n",
      "    epoch          : 227\n",
      "    loss           : -559.0547396669098\n",
      "    val_loss       : -563.8165948221064\n",
      "    val_log_likelihood: 865.6348454770567\n",
      "    val_log_marginal: 573.9143792123065\n",
      "Train Epoch: 228 [512/17352 (3%)] Loss: -429.356628\n",
      "Train Epoch: 228 [10079/17352 (58%)] Loss: -605.626998\n",
      "Train Epoch: 228 [16939/17352 (98%)] Loss: -635.136753\n",
      "    epoch          : 228\n",
      "    loss           : -563.7313535994174\n",
      "    val_loss       : -565.5031241465534\n",
      "    val_log_likelihood: 874.5480479723393\n",
      "    val_log_marginal: 584.6141892953221\n",
      "Train Epoch: 229 [512/17352 (3%)] Loss: -430.900024\n",
      "Train Epoch: 229 [10357/17352 (60%)] Loss: -603.890232\n",
      "Train Epoch: 229 [16922/17352 (98%)] Loss: -573.220819\n",
      "    epoch          : 229\n",
      "    loss           : -553.2961913287196\n",
      "    val_loss       : -564.5837954438433\n",
      "    val_log_likelihood: 885.3150281605762\n",
      "    val_log_marginal: 577.2375511033437\n",
      "Train Epoch: 230 [512/17352 (3%)] Loss: -577.408813\n",
      "Train Epoch: 230 [10401/17352 (60%)] Loss: -496.175461\n",
      "Train Epoch: 230 [16923/17352 (98%)] Loss: -639.592926\n",
      "    epoch          : 230\n",
      "    loss           : -580.0629051910169\n",
      "    val_loss       : -597.1318099648829\n",
      "    val_log_likelihood: 889.2176447846542\n",
      "    val_log_marginal: 603.0718237520191\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch230.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 231 [512/17352 (3%)] Loss: -593.458191\n",
      "Train Epoch: 231 [9894/17352 (57%)] Loss: -551.225954\n",
      "Train Epoch: 231 [16934/17352 (98%)] Loss: -517.290647\n",
      "    epoch          : 231\n",
      "    loss           : -592.4767741132758\n",
      "    val_loss       : -598.633411902363\n",
      "    val_log_likelihood: 892.5048093945582\n",
      "    val_log_marginal: 603.817448310286\n",
      "Train Epoch: 232 [512/17352 (3%)] Loss: -563.467529\n",
      "Train Epoch: 232 [9870/17352 (57%)] Loss: -485.473288\n",
      "Train Epoch: 232 [16887/17352 (97%)] Loss: -680.961569\n",
      "    epoch          : 232\n",
      "    loss           : -593.3582139083468\n",
      "    val_loss       : -595.7747494783883\n",
      "    val_log_likelihood: 895.1431116703575\n",
      "    val_log_marginal: 607.0229902590318\n",
      "Train Epoch: 233 [512/17352 (3%)] Loss: -572.022827\n",
      "Train Epoch: 233 [10372/17352 (60%)] Loss: -663.138696\n",
      "Train Epoch: 233 [16887/17352 (97%)] Loss: -603.723348\n",
      "    epoch          : 233\n",
      "    loss           : -584.2908457860248\n",
      "    val_loss       : -603.2812752112455\n",
      "    val_log_likelihood: 900.3506572369187\n",
      "    val_log_marginal: 607.6496799644456\n",
      "Train Epoch: 234 [512/17352 (3%)] Loss: -618.452515\n",
      "Train Epoch: 234 [10357/17352 (60%)] Loss: -470.940266\n",
      "Train Epoch: 234 [17133/17352 (99%)] Loss: -427.234448\n",
      "    epoch          : 234\n",
      "    loss           : -585.975838811194\n",
      "    val_loss       : -556.9022906152932\n",
      "    val_log_likelihood: 878.757300872846\n",
      "    val_log_marginal: 565.9929740157692\n",
      "Train Epoch: 235 [512/17352 (3%)] Loss: -524.411621\n",
      "Train Epoch: 235 [10083/17352 (58%)] Loss: -612.868436\n",
      "Train Epoch: 235 [16957/17352 (98%)] Loss: -579.650498\n",
      "    epoch          : 235\n",
      "    loss           : -573.6558099770988\n",
      "    val_loss       : -567.4982780200601\n",
      "    val_log_likelihood: 886.4265757102019\n",
      "    val_log_marginal: 579.1145868466169\n",
      "Train Epoch: 236 [512/17352 (3%)] Loss: -577.501953\n",
      "Train Epoch: 236 [9930/17352 (57%)] Loss: -565.022830\n",
      "Train Epoch: 236 [17090/17352 (98%)] Loss: -549.908398\n",
      "    epoch          : 236\n",
      "    loss           : -598.0003081841749\n",
      "    val_loss       : -593.9106584170619\n",
      "    val_log_likelihood: 908.1367499442839\n",
      "    val_log_marginal: 605.9271340439954\n",
      "Train Epoch: 237 [512/17352 (3%)] Loss: -570.597961\n",
      "Train Epoch: 237 [10314/17352 (59%)] Loss: -699.648374\n",
      "Train Epoch: 237 [16939/17352 (98%)] Loss: -452.701882\n",
      "    epoch          : 237\n",
      "    loss           : -599.4875623990596\n",
      "    val_loss       : -593.8073461417356\n",
      "    val_log_likelihood: 904.8357298334118\n",
      "    val_log_marginal: 604.6812018276797\n",
      "Train Epoch: 238 [512/17352 (3%)] Loss: -604.463867\n",
      "Train Epoch: 238 [10190/17352 (59%)] Loss: -522.342601\n",
      "Train Epoch: 238 [17126/17352 (99%)] Loss: -678.841209\n",
      "    epoch          : 238\n",
      "    loss           : -600.6550870461022\n",
      "    val_loss       : -607.1779679827031\n",
      "    val_log_likelihood: 910.6946676669039\n",
      "    val_log_marginal: 613.5397918923032\n",
      "Train Epoch: 239 [512/17352 (3%)] Loss: -620.925354\n",
      "Train Epoch: 239 [10551/17352 (61%)] Loss: -690.227527\n",
      "Train Epoch: 239 [16872/17352 (97%)] Loss: -638.354986\n",
      "    epoch          : 239\n",
      "    loss           : -596.2297817453716\n",
      "    val_loss       : -590.047347512292\n",
      "    val_log_likelihood: 906.4587194173672\n",
      "    val_log_marginal: 594.4159991633666\n",
      "Train Epoch: 240 [512/17352 (3%)] Loss: -592.150513\n",
      "Train Epoch: 240 [10874/17352 (63%)] Loss: -414.982673\n",
      "Train Epoch: 240 [16988/17352 (98%)] Loss: -567.464041\n",
      "    epoch          : 240\n",
      "    loss           : -582.1527657822377\n",
      "    val_loss       : -585.5003768202095\n",
      "    val_log_likelihood: 890.5818098870999\n",
      "    val_log_marginal: 592.3385315637557\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch240.pth ...\n",
      "Train Epoch: 241 [512/17352 (3%)] Loss: -536.404297\n",
      "Train Epoch: 241 [10019/17352 (58%)] Loss: -616.476279\n",
      "Train Epoch: 241 [17108/17352 (99%)] Loss: -352.439886\n",
      "    epoch          : 241\n",
      "    loss           : -597.3559867717738\n",
      "    val_loss       : -574.969860092363\n",
      "    val_log_likelihood: 902.0229987964585\n",
      "    val_log_marginal: 587.0892865394344\n",
      "Train Epoch: 242 [512/17352 (3%)] Loss: -590.311218\n",
      "Train Epoch: 242 [10398/17352 (60%)] Loss: -342.366552\n",
      "Train Epoch: 242 [16882/17352 (97%)] Loss: -603.456473\n",
      "    epoch          : 242\n",
      "    loss           : -600.9676416696282\n",
      "    val_loss       : -618.4884195960473\n",
      "    val_log_likelihood: 918.8318393367433\n",
      "    val_log_marginal: 628.3595994650947\n",
      "Train Epoch: 243 [512/17352 (3%)] Loss: -639.195312\n",
      "Train Epoch: 243 [10455/17352 (60%)] Loss: -644.052294\n",
      "Train Epoch: 243 [17101/17352 (99%)] Loss: -502.714844\n",
      "    epoch          : 243\n",
      "    loss           : -596.0556892447393\n",
      "    val_loss       : -546.1782268868778\n",
      "    val_log_likelihood: 909.3453994226086\n",
      "    val_log_marginal: 553.4464667111093\n",
      "Train Epoch: 244 [512/17352 (3%)] Loss: -556.662109\n",
      "Train Epoch: 244 [10369/17352 (60%)] Loss: -392.491079\n",
      "Train Epoch: 244 [16922/17352 (98%)] Loss: -515.539844\n",
      "    epoch          : 244\n",
      "    loss           : -556.7149419046387\n",
      "    val_loss       : -538.1827037075959\n",
      "    val_log_likelihood: 897.5331260085826\n",
      "    val_log_marginal: 552.337182053253\n",
      "Train Epoch: 245 [512/17352 (3%)] Loss: -545.580566\n",
      "Train Epoch: 245 [10125/17352 (58%)] Loss: -578.528073\n",
      "Train Epoch: 245 [16992/17352 (98%)] Loss: -656.875473\n",
      "    epoch          : 245\n",
      "    loss           : -581.6326667206672\n",
      "    val_loss       : -604.7413188924631\n",
      "    val_log_likelihood: 926.6478876597762\n",
      "    val_log_marginal: 615.0377033763832\n",
      "Train Epoch: 246 [512/17352 (3%)] Loss: -613.763428\n",
      "Train Epoch: 246 [10278/17352 (59%)] Loss: -589.369271\n",
      "Train Epoch: 246 [17106/17352 (99%)] Loss: -551.850100\n",
      "    epoch          : 246\n",
      "    loss           : -511.8668393656282\n",
      "    val_loss       : -372.89796802781166\n",
      "    val_log_likelihood: 819.6163141897435\n",
      "    val_log_marginal: 376.30395773810835\n",
      "Train Epoch: 247 [512/17352 (3%)] Loss: -214.326447\n",
      "Train Epoch: 247 [10475/17352 (60%)] Loss: -476.589056\n",
      "Train Epoch: 247 [16887/17352 (97%)] Loss: -4.586173\n",
      "    epoch          : 247\n",
      "    loss           : -411.4068411315946\n",
      "    val_loss       : -154.59476130180107\n",
      "    val_log_likelihood: 779.5784651743905\n",
      "    val_log_marginal: 165.21120640086366\n",
      "Train Epoch: 248 [512/17352 (3%)] Loss: 7.873534\n",
      "Train Epoch: 248 [9910/17352 (57%)] Loss: -521.915613\n",
      "Train Epoch: 248 [17126/17352 (99%)] Loss: -389.187970\n",
      "    epoch          : 248\n",
      "    loss           : -432.48252791775593\n",
      "    val_loss       : -547.6160523016854\n",
      "    val_log_likelihood: 887.9193877338888\n",
      "    val_log_marginal: 555.7866512454382\n",
      "Train Epoch: 249 [512/17352 (3%)] Loss: -550.667480\n",
      "Train Epoch: 249 [10319/17352 (59%)] Loss: -660.781535\n",
      "Train Epoch: 249 [16923/17352 (98%)] Loss: -589.622141\n",
      "    epoch          : 249\n",
      "    loss           : -578.465938257139\n",
      "    val_loss       : -470.56975185681364\n",
      "    val_log_likelihood: 905.4161119849725\n",
      "    val_log_marginal: 494.45287038746085\n",
      "Train Epoch: 250 [512/17352 (3%)] Loss: -455.327118\n",
      "Train Epoch: 250 [10567/17352 (61%)] Loss: -505.743605\n",
      "Train Epoch: 250 [16958/17352 (98%)] Loss: -674.995744\n",
      "    epoch          : 250\n",
      "    loss           : -585.8597720423145\n",
      "    val_loss       : -629.0014756510636\n",
      "    val_log_likelihood: 926.9435617901006\n",
      "    val_log_marginal: 635.8313319613401\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch250.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 251 [512/17352 (3%)] Loss: -632.590210\n",
      "Train Epoch: 251 [10520/17352 (61%)] Loss: -516.578221\n",
      "Train Epoch: 251 [17126/17352 (99%)] Loss: -471.929202\n",
      "    epoch          : 251\n",
      "    loss           : -598.9219335187246\n",
      "    val_loss       : -603.3352261892395\n",
      "    val_log_likelihood: 926.716337002937\n",
      "    val_log_marginal: 622.3154826556073\n",
      "Train Epoch: 252 [512/17352 (3%)] Loss: -577.059326\n",
      "Train Epoch: 252 [10647/17352 (61%)] Loss: -690.268610\n",
      "Train Epoch: 252 [16934/17352 (98%)] Loss: -684.956771\n",
      "    epoch          : 252\n",
      "    loss           : -603.6710891786497\n",
      "    val_loss       : -540.7217579557064\n",
      "    val_log_likelihood: 881.756170101519\n",
      "    val_log_marginal: 552.0294828572344\n",
      "Train Epoch: 253 [512/17352 (3%)] Loss: -552.852112\n",
      "Train Epoch: 253 [10166/17352 (59%)] Loss: -690.561484\n",
      "Train Epoch: 253 [17143/17352 (99%)] Loss: -484.128146\n",
      "    epoch          : 253\n",
      "    loss           : -618.5169849442075\n",
      "    val_loss       : -634.8278325726043\n",
      "    val_log_likelihood: 934.511651241706\n",
      "    val_log_marginal: 641.178919815304\n",
      "Train Epoch: 254 [512/17352 (3%)] Loss: -634.246338\n",
      "Train Epoch: 254 [10740/17352 (62%)] Loss: -623.378441\n",
      "Train Epoch: 254 [17106/17352 (99%)] Loss: -590.151823\n",
      "    epoch          : 254\n",
      "    loss           : -624.3202959884056\n",
      "    val_loss       : -612.768876809593\n",
      "    val_log_likelihood: 934.3150119664849\n",
      "    val_log_marginal: 627.4433972282242\n",
      "Train Epoch: 255 [512/17352 (3%)] Loss: -579.962646\n",
      "Train Epoch: 255 [10267/17352 (59%)] Loss: -531.087613\n",
      "Train Epoch: 255 [16883/17352 (97%)] Loss: -611.840533\n",
      "    epoch          : 255\n",
      "    loss           : -638.4708982057963\n",
      "    val_loss       : -617.3555653480953\n",
      "    val_log_likelihood: 937.9138782411205\n",
      "    val_log_marginal: 630.4338085238899\n",
      "Train Epoch: 256 [512/17352 (3%)] Loss: -599.244202\n",
      "Train Epoch: 256 [10509/17352 (61%)] Loss: -679.135029\n",
      "Train Epoch: 256 [16988/17352 (98%)] Loss: -546.751628\n",
      "    epoch          : 256\n",
      "    loss           : -609.0293792610106\n",
      "    val_loss       : -554.2476306976466\n",
      "    val_log_likelihood: 931.066392275305\n",
      "    val_log_marginal: 567.0975513334133\n",
      "Train Epoch: 257 [512/17352 (3%)] Loss: -555.057251\n",
      "Train Epoch: 257 [10752/17352 (62%)] Loss: -617.971094\n",
      "Train Epoch: 257 [17090/17352 (98%)] Loss: -565.497261\n",
      "    epoch          : 257\n",
      "    loss           : -613.4785830342493\n",
      "    val_loss       : -615.3381215539592\n",
      "    val_log_likelihood: 941.8419606171876\n",
      "    val_log_marginal: 626.7899227864528\n",
      "Train Epoch: 258 [512/17352 (3%)] Loss: -624.292419\n",
      "Train Epoch: 258 [10298/17352 (59%)] Loss: -502.105095\n",
      "Train Epoch: 258 [17064/17352 (98%)] Loss: -461.735047\n",
      "    epoch          : 258\n",
      "    loss           : -614.6789286692006\n",
      "    val_loss       : -609.5015652858348\n",
      "    val_log_likelihood: 943.4799277393942\n",
      "    val_log_marginal: 618.7736225092851\n",
      "Train Epoch: 259 [512/17352 (3%)] Loss: -581.560791\n",
      "Train Epoch: 259 [10621/17352 (61%)] Loss: -649.095209\n",
      "Train Epoch: 259 [17049/17352 (98%)] Loss: -654.199827\n",
      "    epoch          : 259\n",
      "    loss           : -609.1500886841935\n",
      "    val_loss       : -612.8799845155806\n",
      "    val_log_likelihood: 938.3030113495264\n",
      "    val_log_marginal: 624.5761661347469\n",
      "Train Epoch: 260 [512/17352 (3%)] Loss: -622.228394\n",
      "Train Epoch: 260 [10116/17352 (58%)] Loss: -703.795854\n",
      "Train Epoch: 260 [17124/17352 (99%)] Loss: -662.422660\n",
      "    epoch          : 260\n",
      "    loss           : -615.2527387194976\n",
      "    val_loss       : -585.0911780611829\n",
      "    val_log_likelihood: 931.4415688430827\n",
      "    val_log_marginal: 595.6020925123094\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch260.pth ...\n",
      "Train Epoch: 261 [512/17352 (3%)] Loss: -585.967712\n",
      "Train Epoch: 261 [10317/17352 (59%)] Loss: -529.378102\n",
      "Train Epoch: 261 [17044/17352 (98%)] Loss: -647.712329\n",
      "    epoch          : 261\n",
      "    loss           : -579.9720971407228\n",
      "    val_loss       : -603.916115518351\n",
      "    val_log_likelihood: 935.5132897532935\n",
      "    val_log_marginal: 614.1849113102385\n",
      "Train Epoch: 262 [512/17352 (3%)] Loss: -610.052917\n",
      "Train Epoch: 262 [10254/17352 (59%)] Loss: -729.250997\n",
      "Train Epoch: 262 [16923/17352 (98%)] Loss: -655.529426\n",
      "    epoch          : 262\n",
      "    loss           : -637.3771777528323\n",
      "    val_loss       : -649.9667223311375\n",
      "    val_log_likelihood: 957.8730587820431\n",
      "    val_log_marginal: 661.9275075256783\n",
      "Train Epoch: 263 [512/17352 (3%)] Loss: -664.752563\n",
      "Train Epoch: 263 [10271/17352 (59%)] Loss: -661.686849\n",
      "Train Epoch: 263 [16872/17352 (97%)] Loss: -668.136501\n",
      "    epoch          : 263\n",
      "    loss           : -624.2311237164831\n",
      "    val_loss       : -627.8543712545996\n",
      "    val_log_likelihood: 955.6458856000814\n",
      "    val_log_marginal: 643.9128485738772\n",
      "Train Epoch: 264 [512/17352 (3%)] Loss: -638.847290\n",
      "Train Epoch: 264 [10508/17352 (61%)] Loss: -729.410127\n",
      "Train Epoch: 264 [16883/17352 (97%)] Loss: -640.121702\n",
      "    epoch          : 264\n",
      "    loss           : -634.4200114851675\n",
      "    val_loss       : -642.9750427190997\n",
      "    val_log_likelihood: 968.5759550293332\n",
      "    val_log_marginal: 654.0772231458607\n",
      "Train Epoch: 265 [512/17352 (3%)] Loss: -662.925171\n",
      "Train Epoch: 265 [10719/17352 (62%)] Loss: -601.395877\n",
      "Train Epoch: 265 [16878/17352 (97%)] Loss: -611.351690\n",
      "    epoch          : 265\n",
      "    loss           : -614.1227706695684\n",
      "    val_loss       : -635.1287257600711\n",
      "    val_log_likelihood: 956.1971665001764\n",
      "    val_log_marginal: 642.9543286686755\n",
      "Train Epoch: 266 [512/17352 (3%)] Loss: -613.734375\n",
      "Train Epoch: 266 [10539/17352 (61%)] Loss: -719.526677\n",
      "Train Epoch: 266 [16957/17352 (98%)] Loss: -675.550286\n",
      "    epoch          : 266\n",
      "    loss           : -610.0943907327509\n",
      "    val_loss       : -606.9777463768544\n",
      "    val_log_likelihood: 960.3094811656264\n",
      "    val_log_marginal: 640.6108117684311\n",
      "Train Epoch: 267 [512/17352 (3%)] Loss: -650.381958\n",
      "Train Epoch: 267 [10031/17352 (58%)] Loss: -594.636087\n",
      "Train Epoch: 267 [16872/17352 (97%)] Loss: -397.440603\n",
      "    epoch          : 267\n",
      "    loss           : -599.4642558085245\n",
      "    val_loss       : -603.0944868214627\n",
      "    val_log_likelihood: 941.628069831879\n",
      "    val_log_marginal: 612.9707171104069\n",
      "Train Epoch: 268 [512/17352 (3%)] Loss: -594.442810\n",
      "Train Epoch: 268 [10177/17352 (59%)] Loss: -657.899931\n",
      "Train Epoch: 268 [16957/17352 (98%)] Loss: -611.298995\n",
      "    epoch          : 268\n",
      "    loss           : -629.0406486493573\n",
      "    val_loss       : -653.8035973131902\n",
      "    val_log_likelihood: 970.7418039851063\n",
      "    val_log_marginal: 664.6839046976814\n",
      "Train Epoch: 269 [512/17352 (3%)] Loss: -652.582581\n",
      "Train Epoch: 269 [9954/17352 (57%)] Loss: -745.063693\n",
      "Train Epoch: 269 [17016/17352 (98%)] Loss: -635.540234\n",
      "    epoch          : 269\n",
      "    loss           : -646.0514006901307\n",
      "    val_loss       : -620.2353938054409\n",
      "    val_log_likelihood: 957.9946954068878\n",
      "    val_log_marginal: 632.9153608892976\n",
      "Train Epoch: 270 [512/17352 (3%)] Loss: -568.648193\n",
      "Train Epoch: 270 [10302/17352 (59%)] Loss: -607.277691\n",
      "Train Epoch: 270 [17335/17352 (100%)] Loss: -589.331978\n",
      "    epoch          : 270\n",
      "    loss           : -638.592976030766\n",
      "    val_loss       : -545.9846144346184\n",
      "    val_log_likelihood: 922.3017109135997\n",
      "    val_log_marginal: 555.4332387130046\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch270.pth ...\n",
      "Train Epoch: 271 [512/17352 (3%)] Loss: -560.064087\n",
      "Train Epoch: 271 [9906/17352 (57%)] Loss: -661.184789\n",
      "Train Epoch: 271 [17153/17352 (99%)] Loss: -600.365916\n",
      "    epoch          : 271\n",
      "    loss           : -585.73685819561\n",
      "    val_loss       : -570.9249434091724\n",
      "    val_log_likelihood: 932.1477121985869\n",
      "    val_log_marginal: 588.1158547646775\n",
      "Train Epoch: 272 [512/17352 (3%)] Loss: -575.296936\n",
      "Train Epoch: 272 [10544/17352 (61%)] Loss: -501.641553\n",
      "Train Epoch: 272 [16992/17352 (98%)] Loss: -664.680434\n",
      "    epoch          : 272\n",
      "    loss           : -589.0915271126098\n",
      "    val_loss       : -612.9337459678386\n",
      "    val_log_likelihood: 948.0775742007759\n",
      "    val_log_marginal: 620.6104537374214\n",
      "Train Epoch: 273 [512/17352 (3%)] Loss: -612.574463\n",
      "Train Epoch: 273 [9992/17352 (58%)] Loss: -469.417166\n",
      "Train Epoch: 273 [17106/17352 (99%)] Loss: -509.295146\n",
      "    epoch          : 273\n",
      "    loss           : -575.4762796721504\n",
      "    val_loss       : -582.7241833677308\n",
      "    val_log_likelihood: 941.0356494538297\n",
      "    val_log_marginal: 595.2351848809265\n",
      "Train Epoch: 274 [512/17352 (3%)] Loss: -553.776978\n",
      "Train Epoch: 274 [10426/17352 (60%)] Loss: -621.796596\n",
      "Train Epoch: 274 [17101/17352 (99%)] Loss: -709.169038\n",
      "    epoch          : 274\n",
      "    loss           : -624.2575476288779\n",
      "    val_loss       : -602.7494061943706\n",
      "    val_log_likelihood: 947.8939912965741\n",
      "    val_log_marginal: 616.191596946743\n",
      "Train Epoch: 275 [512/17352 (3%)] Loss: -621.889343\n",
      "Train Epoch: 275 [10172/17352 (59%)] Loss: -593.908306\n",
      "Train Epoch: 275 [17108/17352 (99%)] Loss: -552.280734\n",
      "    epoch          : 275\n",
      "    loss           : -637.2142372519285\n",
      "    val_loss       : -645.1296563008012\n",
      "    val_log_likelihood: 975.3131403702184\n",
      "    val_log_marginal: 649.3313160363737\n",
      "Train Epoch: 276 [512/17352 (3%)] Loss: -660.290527\n",
      "Train Epoch: 276 [10025/17352 (58%)] Loss: -633.722310\n",
      "Train Epoch: 276 [16988/17352 (98%)] Loss: -618.781576\n",
      "    epoch          : 276\n",
      "    loss           : -652.7375232428833\n",
      "    val_loss       : -653.6347913739352\n",
      "    val_log_likelihood: 985.0122427597155\n",
      "    val_log_marginal: 662.3848144275682\n",
      "Train Epoch: 277 [512/17352 (3%)] Loss: -653.438538\n",
      "Train Epoch: 277 [10670/17352 (61%)] Loss: -661.899801\n",
      "Train Epoch: 277 [16887/17352 (97%)] Loss: -658.291911\n",
      "    epoch          : 277\n",
      "    loss           : -604.8053508522701\n",
      "    val_loss       : -597.7475698409089\n",
      "    val_log_likelihood: 984.6923271659173\n",
      "    val_log_marginal: 606.5460288699343\n",
      "Train Epoch: 278 [512/17352 (3%)] Loss: -602.342224\n",
      "Train Epoch: 278 [9736/17352 (56%)] Loss: -575.924862\n",
      "Train Epoch: 278 [17106/17352 (99%)] Loss: -575.454373\n",
      "    epoch          : 278\n",
      "    loss           : -574.1464216406459\n",
      "    val_loss       : -600.9666886789576\n",
      "    val_log_likelihood: 955.0485138854323\n",
      "    val_log_marginal: 607.1911568912911\n",
      "Train Epoch: 279 [512/17352 (3%)] Loss: -554.415039\n",
      "Train Epoch: 279 [10149/17352 (58%)] Loss: -514.396255\n",
      "Train Epoch: 279 [17016/17352 (98%)] Loss: -360.716003\n",
      "    epoch          : 279\n",
      "    loss           : -489.0644912713362\n",
      "    val_loss       : -412.82145222805235\n",
      "    val_log_likelihood: 892.6735594665669\n",
      "    val_log_marginal: 429.6135342442817\n",
      "Train Epoch: 280 [512/17352 (3%)] Loss: -373.191986\n",
      "Train Epoch: 280 [10437/17352 (60%)] Loss: -657.482114\n",
      "Train Epoch: 280 [16957/17352 (98%)] Loss: -635.177583\n",
      "    epoch          : 280\n",
      "    loss           : -556.2873124137632\n",
      "    val_loss       : -636.7625302659721\n",
      "    val_log_likelihood: 953.7624655138089\n",
      "    val_log_marginal: 641.2730690169811\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch280.pth ...\n",
      "Train Epoch: 281 [512/17352 (3%)] Loss: -636.596741\n",
      "Train Epoch: 281 [10467/17352 (60%)] Loss: -626.949037\n",
      "Train Epoch: 281 [16992/17352 (98%)] Loss: -517.264642\n",
      "    epoch          : 281\n",
      "    loss           : -645.4953662291314\n",
      "    val_loss       : -665.4562098400816\n",
      "    val_log_likelihood: 981.1303436233287\n",
      "    val_log_marginal: 676.2327736821227\n",
      "Train Epoch: 282 [512/17352 (3%)] Loss: -683.184204\n",
      "Train Epoch: 282 [10052/17352 (58%)] Loss: -729.623617\n",
      "Train Epoch: 282 [16922/17352 (98%)] Loss: -557.809612\n",
      "    epoch          : 282\n",
      "    loss           : -676.4938760733182\n",
      "    val_loss       : -670.3632942903729\n",
      "    val_log_likelihood: 988.9301915664189\n",
      "    val_log_marginal: 683.7147138894326\n",
      "Train Epoch: 283 [512/17352 (3%)] Loss: -545.960205\n",
      "Train Epoch: 283 [10129/17352 (58%)] Loss: -718.849143\n",
      "Train Epoch: 283 [17263/17352 (99%)] Loss: -590.232263\n",
      "    epoch          : 283\n",
      "    loss           : -679.8796715583504\n",
      "    val_loss       : -661.8292755659779\n",
      "    val_log_likelihood: 989.9255968808171\n",
      "    val_log_marginal: 673.8774246166304\n",
      "Train Epoch: 284 [512/17352 (3%)] Loss: -676.129395\n",
      "Train Epoch: 284 [10038/17352 (58%)] Loss: -456.494019\n",
      "Train Epoch: 284 [16882/17352 (97%)] Loss: -656.007626\n",
      "    epoch          : 284\n",
      "    loss           : -677.5820164354072\n",
      "    val_loss       : -686.0211575009064\n",
      "    val_log_likelihood: 1003.2821172454038\n",
      "    val_log_marginal: 695.5129929195551\n",
      "Train Epoch: 285 [512/17352 (3%)] Loss: -698.467163\n",
      "Train Epoch: 285 [10583/17352 (61%)] Loss: -707.735122\n",
      "Train Epoch: 285 [17335/17352 (100%)] Loss: -659.140762\n",
      "    epoch          : 285\n",
      "    loss           : -672.7919591360063\n",
      "    val_loss       : -622.9007727442961\n",
      "    val_log_likelihood: 979.793223802343\n",
      "    val_log_marginal: 633.8671720886082\n",
      "Train Epoch: 286 [512/17352 (3%)] Loss: -641.298096\n",
      "Train Epoch: 286 [10419/17352 (60%)] Loss: -502.167165\n",
      "Train Epoch: 286 [17126/17352 (99%)] Loss: -636.693170\n",
      "    epoch          : 286\n",
      "    loss           : -629.0558636854975\n",
      "    val_loss       : -591.9610764402238\n",
      "    val_log_likelihood: 950.2094750232012\n",
      "    val_log_marginal: 604.8489950557152\n",
      "Train Epoch: 287 [512/17352 (3%)] Loss: -583.728577\n",
      "Train Epoch: 287 [10164/17352 (59%)] Loss: -558.588432\n",
      "Train Epoch: 287 [17153/17352 (99%)] Loss: -622.507492\n",
      "    epoch          : 287\n",
      "    loss           : -642.1439935304595\n",
      "    val_loss       : -627.5719866755564\n",
      "    val_log_likelihood: 986.9128136015023\n",
      "    val_log_marginal: 651.1203351434267\n",
      "Train Epoch: 288 [512/17352 (3%)] Loss: -383.134155\n",
      "Train Epoch: 288 [11016/17352 (63%)] Loss: -760.947185\n",
      "Train Epoch: 288 [17153/17352 (99%)] Loss: -601.235207\n",
      "    epoch          : 288\n",
      "    loss           : -645.4397664965784\n",
      "    val_loss       : -650.2603207185828\n",
      "    val_log_likelihood: 991.1577173963321\n",
      "    val_log_marginal: 661.1951275172488\n",
      "Train Epoch: 289 [512/17352 (3%)] Loss: -624.150879\n",
      "Train Epoch: 289 [10397/17352 (60%)] Loss: -648.041533\n",
      "Train Epoch: 289 [16992/17352 (98%)] Loss: -204.441681\n",
      "    epoch          : 289\n",
      "    loss           : -628.6853980558514\n",
      "    val_loss       : 59.09057107516249\n",
      "    val_log_likelihood: 1002.4175952692912\n",
      "    val_log_marginal: -52.70526206821635\n",
      "Train Epoch: 290 [512/17352 (3%)] Loss: 57.249905\n",
      "Train Epoch: 290 [10155/17352 (59%)] Loss: -525.373025\n",
      "Train Epoch: 290 [17049/17352 (98%)] Loss: -528.649816\n",
      "    epoch          : 290\n",
      "    loss           : -277.6653939441945\n",
      "    val_loss       : -456.723941549872\n",
      "    val_log_likelihood: 884.7987138272041\n",
      "    val_log_marginal: 479.3902956121951\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch290.pth ...\n",
      "Train Epoch: 291 [512/17352 (3%)] Loss: -320.222900\n",
      "Train Epoch: 291 [10756/17352 (62%)] Loss: -658.233668\n",
      "Train Epoch: 291 [17101/17352 (99%)] Loss: -702.517132\n",
      "    epoch          : 291\n",
      "    loss           : -593.8626447329123\n",
      "    val_loss       : -623.8010074901867\n",
      "    val_log_likelihood: 965.5404803003953\n",
      "    val_log_marginal: 647.9540270261197\n",
      "Train Epoch: 292 [512/17352 (3%)] Loss: -632.417603\n",
      "Train Epoch: 292 [9759/17352 (56%)] Loss: -675.736482\n",
      "Train Epoch: 292 [16872/17352 (97%)] Loss: -674.073360\n",
      "    epoch          : 292\n",
      "    loss           : -646.7610588199444\n",
      "    val_loss       : -666.9880605333761\n",
      "    val_log_likelihood: 993.2924855452119\n",
      "    val_log_marginal: 683.7741275905759\n",
      "Train Epoch: 293 [512/17352 (3%)] Loss: -633.271179\n",
      "Train Epoch: 293 [10661/17352 (61%)] Loss: -788.040148\n",
      "Train Epoch: 293 [17101/17352 (99%)] Loss: -739.556357\n",
      "    epoch          : 293\n",
      "    loss           : -671.5009198498744\n",
      "    val_loss       : -664.3058038346043\n",
      "    val_log_likelihood: 996.0312817702087\n",
      "    val_log_marginal: 684.2007613683818\n",
      "Train Epoch: 294 [512/17352 (3%)] Loss: -691.724548\n",
      "Train Epoch: 294 [10236/17352 (59%)] Loss: -577.950102\n",
      "Train Epoch: 294 [17126/17352 (99%)] Loss: -551.882407\n",
      "    epoch          : 294\n",
      "    loss           : -669.2220987168079\n",
      "    val_loss       : -688.9474819603956\n",
      "    val_log_likelihood: 1008.3915037107666\n",
      "    val_log_marginal: 699.1062235602571\n",
      "Train Epoch: 295 [512/17352 (3%)] Loss: -564.915161\n",
      "Train Epoch: 295 [10241/17352 (59%)] Loss: -744.154383\n",
      "Train Epoch: 295 [17044/17352 (98%)] Loss: -732.733378\n",
      "    epoch          : 295\n",
      "    loss           : -680.4435259784565\n",
      "    val_loss       : -678.960505238249\n",
      "    val_log_likelihood: 999.8265634298688\n",
      "    val_log_marginal: 684.0645642110816\n",
      "Train Epoch: 296 [512/17352 (3%)] Loss: -683.400452\n",
      "Train Epoch: 296 [10697/17352 (62%)] Loss: -594.177070\n",
      "Train Epoch: 296 [17263/17352 (99%)] Loss: -688.163953\n",
      "    epoch          : 296\n",
      "    loss           : -641.4612727237619\n",
      "    val_loss       : -646.4516054345364\n",
      "    val_log_likelihood: 995.5786593660368\n",
      "    val_log_marginal: 658.8508072496537\n",
      "Train Epoch: 297 [512/17352 (3%)] Loss: -659.835938\n",
      "Train Epoch: 297 [9818/17352 (57%)] Loss: -733.790729\n",
      "Train Epoch: 297 [16887/17352 (97%)] Loss: -702.019983\n",
      "    epoch          : 297\n",
      "    loss           : -677.9983798511532\n",
      "    val_loss       : -680.217348653859\n",
      "    val_log_likelihood: 1018.6054258160895\n",
      "    val_log_marginal: 701.0999503074556\n",
      "Train Epoch: 298 [512/17352 (3%)] Loss: -701.659546\n",
      "Train Epoch: 298 [10405/17352 (60%)] Loss: -701.232443\n",
      "Train Epoch: 298 [16872/17352 (97%)] Loss: -641.989690\n",
      "    epoch          : 298\n",
      "    loss           : -683.5368773605559\n",
      "    val_loss       : -692.8926142123848\n",
      "    val_log_likelihood: 1023.359920315084\n",
      "    val_log_marginal: 706.6974427462928\n",
      "Train Epoch: 299 [512/17352 (3%)] Loss: -710.917725\n",
      "Train Epoch: 299 [10282/17352 (59%)] Loss: -687.890152\n",
      "Train Epoch: 299 [17044/17352 (98%)] Loss: -532.547245\n",
      "    epoch          : 299\n",
      "    loss           : -690.7606059049751\n",
      "    val_loss       : -674.1856080937812\n",
      "    val_log_likelihood: 1016.5886477287896\n",
      "    val_log_marginal: 691.7017527269484\n",
      "Train Epoch: 300 [512/17352 (3%)] Loss: -662.382812\n",
      "Train Epoch: 300 [10566/17352 (61%)] Loss: -710.354396\n",
      "Train Epoch: 300 [17126/17352 (99%)] Loss: -662.364905\n",
      "    epoch          : 300\n",
      "    loss           : -675.8491435317466\n",
      "    val_loss       : -572.81250422815\n",
      "    val_log_likelihood: 950.1817552960769\n",
      "    val_log_marginal: 590.1918843045048\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch300.pth ...\n",
      "Train Epoch: 301 [512/17352 (3%)] Loss: -602.102112\n",
      "Train Epoch: 301 [10632/17352 (61%)] Loss: -663.058315\n",
      "Train Epoch: 301 [16872/17352 (97%)] Loss: -746.294643\n",
      "    epoch          : 301\n",
      "    loss           : -683.017484698203\n",
      "    val_loss       : -689.4312470843895\n",
      "    val_log_likelihood: 1023.305646270803\n",
      "    val_log_marginal: 695.8241291749662\n",
      "Train Epoch: 302 [512/17352 (3%)] Loss: -698.635742\n",
      "Train Epoch: 302 [9796/17352 (56%)] Loss: -578.265212\n",
      "Train Epoch: 302 [16882/17352 (97%)] Loss: -514.247268\n",
      "    epoch          : 302\n",
      "    loss           : -680.5731056716749\n",
      "    val_loss       : -685.3171403363585\n",
      "    val_log_likelihood: 1018.9584793074132\n",
      "    val_log_marginal: 696.072128658387\n",
      "Train Epoch: 303 [512/17352 (3%)] Loss: -701.489075\n",
      "Train Epoch: 303 [10128/17352 (58%)] Loss: -661.982143\n",
      "Train Epoch: 303 [17253/17352 (99%)] Loss: -670.516481\n",
      "    epoch          : 303\n",
      "    loss           : -659.598850336752\n",
      "    val_loss       : -586.092071663776\n",
      "    val_log_likelihood: 969.5428915427782\n",
      "    val_log_marginal: 600.4696581462736\n",
      "Train Epoch: 304 [512/17352 (3%)] Loss: -605.912781\n",
      "Train Epoch: 304 [10068/17352 (58%)] Loss: -628.321484\n",
      "Train Epoch: 304 [17101/17352 (99%)] Loss: -757.179430\n",
      "    epoch          : 304\n",
      "    loss           : -641.2920585298532\n",
      "    val_loss       : -676.6504815607765\n",
      "    val_log_likelihood: 1011.3781508715293\n",
      "    val_log_marginal: 683.2992226026355\n",
      "Train Epoch: 305 [512/17352 (3%)] Loss: -694.473633\n",
      "Train Epoch: 305 [10492/17352 (60%)] Loss: -589.855405\n",
      "Train Epoch: 305 [16934/17352 (98%)] Loss: -751.380546\n",
      "    epoch          : 305\n",
      "    loss           : -691.6765247702036\n",
      "    val_loss       : -702.6672278569229\n",
      "    val_log_likelihood: 1032.427344780408\n",
      "    val_log_marginal: 718.1825150322936\n",
      "Train Epoch: 306 [512/17352 (3%)] Loss: -720.127197\n",
      "Train Epoch: 306 [10772/17352 (62%)] Loss: -696.187449\n",
      "Train Epoch: 306 [16887/17352 (97%)] Loss: -802.334242\n",
      "    epoch          : 306\n",
      "    loss           : -712.4637702009552\n",
      "    val_loss       : -704.5986839198976\n",
      "    val_log_likelihood: 1038.2920175030767\n",
      "    val_log_marginal: 716.7644313027131\n",
      "Train Epoch: 307 [512/17352 (3%)] Loss: -719.299622\n",
      "Train Epoch: 307 [10393/17352 (60%)] Loss: -585.232955\n",
      "Train Epoch: 307 [17044/17352 (98%)] Loss: -832.976128\n",
      "    epoch          : 307\n",
      "    loss           : -714.3353166978719\n",
      "    val_loss       : -701.08970051523\n",
      "    val_log_likelihood: 1035.0413615905481\n",
      "    val_log_marginal: 710.6258871159021\n",
      "Train Epoch: 308 [512/17352 (3%)] Loss: -704.643127\n",
      "Train Epoch: 308 [10427/17352 (60%)] Loss: -750.976326\n",
      "Train Epoch: 308 [16887/17352 (97%)] Loss: -751.622367\n",
      "    epoch          : 308\n",
      "    loss           : -713.5633564567652\n",
      "    val_loss       : -716.3885928134126\n",
      "    val_log_likelihood: 1050.7284927018393\n",
      "    val_log_marginal: 728.8808561836165\n",
      "Train Epoch: 309 [512/17352 (3%)] Loss: -736.541626\n",
      "Train Epoch: 309 [10421/17352 (60%)] Loss: -573.579994\n",
      "Train Epoch: 309 [16992/17352 (98%)] Loss: -215.733808\n",
      "    epoch          : 309\n",
      "    loss           : -677.4483701419008\n",
      "    val_loss       : -635.6667912713632\n",
      "    val_log_likelihood: 996.9245209533502\n",
      "    val_log_marginal: 642.8694888172826\n",
      "Train Epoch: 310 [512/17352 (3%)] Loss: -579.363159\n",
      "Train Epoch: 310 [10877/17352 (63%)] Loss: -754.206649\n",
      "Train Epoch: 310 [17044/17352 (98%)] Loss: -544.302766\n",
      "    epoch          : 310\n",
      "    loss           : -621.3210458753109\n",
      "    val_loss       : -641.7318432482283\n",
      "    val_log_likelihood: 1006.2299554443708\n",
      "    val_log_marginal: 657.0986504260921\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch310.pth ...\n",
      "Train Epoch: 311 [512/17352 (3%)] Loss: -639.242493\n",
      "Train Epoch: 311 [10144/17352 (58%)] Loss: -648.565005\n",
      "Train Epoch: 311 [16957/17352 (98%)] Loss: -725.078997\n",
      "    epoch          : 311\n",
      "    loss           : -661.6468781507349\n",
      "    val_loss       : -631.6568793937449\n",
      "    val_log_likelihood: 1012.9192292540602\n",
      "    val_log_marginal: 642.0391196503605\n",
      "Train Epoch: 312 [512/17352 (3%)] Loss: -624.929688\n",
      "Train Epoch: 312 [10546/17352 (61%)] Loss: -624.316014\n",
      "Train Epoch: 312 [16939/17352 (98%)] Loss: -615.747904\n",
      "    epoch          : 312\n",
      "    loss           : -661.3969796567727\n",
      "    val_loss       : -685.8069589960464\n",
      "    val_log_likelihood: 1033.1519268590343\n",
      "    val_log_marginal: 704.6492989926334\n",
      "Train Epoch: 313 [512/17352 (3%)] Loss: -702.482544\n",
      "Train Epoch: 313 [10297/17352 (59%)] Loss: -664.509868\n",
      "Train Epoch: 313 [17064/17352 (98%)] Loss: -780.573542\n",
      "    epoch          : 313\n",
      "    loss           : -691.8125816628742\n",
      "    val_loss       : -690.9945593332532\n",
      "    val_log_likelihood: 1039.6229715347215\n",
      "    val_log_marginal: 705.3171278200348\n",
      "Train Epoch: 314 [512/17352 (3%)] Loss: -702.922852\n",
      "Train Epoch: 314 [10501/17352 (61%)] Loss: -705.723692\n",
      "Train Epoch: 314 [16958/17352 (98%)] Loss: -111.409895\n",
      "    epoch          : 314\n",
      "    loss           : -644.480325407987\n",
      "    val_loss       : -105.37845386199344\n",
      "    val_log_likelihood: 982.8319904005353\n",
      "    val_log_marginal: 113.1798925679358\n",
      "Train Epoch: 315 [512/17352 (3%)] Loss: -137.276855\n",
      "Train Epoch: 315 [10258/17352 (59%)] Loss: -316.065168\n",
      "Train Epoch: 315 [16957/17352 (98%)] Loss: -209.756033\n",
      "    epoch          : 315\n",
      "    loss           : -388.94388695378433\n",
      "    val_loss       : -402.8950981623697\n",
      "    val_log_likelihood: 921.1046591171529\n",
      "    val_log_marginal: 428.1261516381316\n",
      "Train Epoch: 316 [512/17352 (3%)] Loss: -373.491882\n",
      "Train Epoch: 316 [10239/17352 (59%)] Loss: -666.464510\n",
      "Train Epoch: 316 [16958/17352 (98%)] Loss: -715.759688\n",
      "    epoch          : 316\n",
      "    loss           : -602.4888742524091\n",
      "    val_loss       : -671.0597972412206\n",
      "    val_log_likelihood: 1015.4961087355404\n",
      "    val_log_marginal: 682.6334918792802\n",
      "Train Epoch: 317 [512/17352 (3%)] Loss: -666.193298\n",
      "Train Epoch: 317 [9880/17352 (57%)] Loss: -675.446962\n",
      "Train Epoch: 317 [17277/17352 (100%)] Loss: -713.254240\n",
      "    epoch          : 317\n",
      "    loss           : -664.3355084611649\n",
      "    val_loss       : -653.77822021543\n",
      "    val_log_likelihood: 1013.4331374430028\n",
      "    val_log_marginal: 664.6756089538462\n",
      "Train Epoch: 318 [512/17352 (3%)] Loss: -527.479187\n",
      "Train Epoch: 318 [10724/17352 (62%)] Loss: -675.260437\n",
      "Train Epoch: 318 [17124/17352 (99%)] Loss: -647.652394\n",
      "    epoch          : 318\n",
      "    loss           : -669.788573157241\n",
      "    val_loss       : -673.0054120306697\n",
      "    val_log_likelihood: 1023.031155664885\n",
      "    val_log_marginal: 691.0923048160831\n",
      "Train Epoch: 319 [512/17352 (3%)] Loss: -305.122223\n",
      "Train Epoch: 319 [10289/17352 (59%)] Loss: -727.504209\n",
      "Train Epoch: 319 [17253/17352 (99%)] Loss: -695.703850\n",
      "    epoch          : 319\n",
      "    loss           : -702.3256157372256\n",
      "    val_loss       : -693.1616412766531\n",
      "    val_log_likelihood: 1038.7164524347208\n",
      "    val_log_marginal: 712.4073266894125\n",
      "Train Epoch: 320 [512/17352 (3%)] Loss: -727.042969\n",
      "Train Epoch: 320 [10463/17352 (60%)] Loss: -783.542354\n",
      "Train Epoch: 320 [17101/17352 (99%)] Loss: -737.536932\n",
      "    epoch          : 320\n",
      "    loss           : -713.7452532275967\n",
      "    val_loss       : -709.4489125267296\n",
      "    val_log_likelihood: 1052.9182402017373\n",
      "    val_log_marginal: 727.8864527198684\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch320.pth ...\n",
      "Train Epoch: 321 [512/17352 (3%)] Loss: -723.953979\n",
      "Train Epoch: 321 [10107/17352 (58%)] Loss: -773.830051\n",
      "Train Epoch: 321 [17049/17352 (98%)] Loss: -626.023536\n",
      "    epoch          : 321\n",
      "    loss           : -690.7404150262233\n",
      "    val_loss       : -505.30107552431303\n",
      "    val_log_likelihood: 1033.3384002767093\n",
      "    val_log_marginal: 517.2042113893317\n",
      "Train Epoch: 322 [512/17352 (3%)] Loss: -544.513733\n",
      "Train Epoch: 322 [9948/17352 (57%)] Loss: -520.562363\n",
      "Train Epoch: 322 [16883/17352 (97%)] Loss: -690.435407\n",
      "    epoch          : 322\n",
      "    loss           : -678.2383465322545\n",
      "    val_loss       : -722.9381620279694\n",
      "    val_log_likelihood: 1061.0726969811637\n",
      "    val_log_marginal: 734.7147551041468\n",
      "Train Epoch: 323 [512/17352 (3%)] Loss: -596.178345\n",
      "Train Epoch: 323 [10340/17352 (60%)] Loss: -577.968750\n",
      "Train Epoch: 323 [16988/17352 (98%)] Loss: -773.755053\n",
      "    epoch          : 323\n",
      "    loss           : -700.1412293978381\n",
      "    val_loss       : -679.5973127033116\n",
      "    val_log_likelihood: 1045.4727606808474\n",
      "    val_log_marginal: 685.0812622767457\n",
      "Train Epoch: 324 [512/17352 (3%)] Loss: -581.743958\n",
      "Train Epoch: 324 [10502/17352 (61%)] Loss: -732.246514\n",
      "Train Epoch: 324 [17126/17352 (99%)] Loss: -573.595869\n",
      "    epoch          : 324\n",
      "    loss           : -669.9195668465638\n",
      "    val_loss       : -616.2898363888586\n",
      "    val_log_likelihood: 1055.2066743736825\n",
      "    val_log_marginal: 626.909124136427\n",
      "Train Epoch: 325 [512/17352 (3%)] Loss: -623.624512\n",
      "Train Epoch: 325 [10127/17352 (58%)] Loss: -629.855149\n",
      "Train Epoch: 325 [16922/17352 (98%)] Loss: -229.055057\n",
      "    epoch          : 325\n",
      "    loss           : -653.439344429762\n",
      "    val_loss       : -455.0701440661821\n",
      "    val_log_likelihood: 1032.9876452559488\n",
      "    val_log_marginal: 469.0230397541418\n",
      "Train Epoch: 326 [512/17352 (3%)] Loss: -457.454102\n",
      "Train Epoch: 326 [10085/17352 (58%)] Loss: -803.104192\n",
      "Train Epoch: 326 [16878/17352 (97%)] Loss: -573.241753\n",
      "    epoch          : 326\n",
      "    loss           : -659.7126864578065\n",
      "    val_loss       : -708.7422446678196\n",
      "    val_log_likelihood: 1057.9608100697883\n",
      "    val_log_marginal: 722.3059489480823\n",
      "Train Epoch: 327 [512/17352 (3%)] Loss: -729.584717\n",
      "Train Epoch: 327 [10801/17352 (62%)] Loss: -788.714557\n",
      "Train Epoch: 327 [17101/17352 (99%)] Loss: -677.223518\n",
      "    epoch          : 327\n",
      "    loss           : -691.1002709362085\n",
      "    val_loss       : -673.0235902469614\n",
      "    val_log_likelihood: 1032.853029465573\n",
      "    val_log_marginal: 680.1237165907556\n",
      "Train Epoch: 328 [512/17352 (3%)] Loss: -697.599731\n",
      "Train Epoch: 328 [10233/17352 (59%)] Loss: -805.872806\n",
      "Train Epoch: 328 [17253/17352 (99%)] Loss: -768.132037\n",
      "    epoch          : 328\n",
      "    loss           : -708.3393153398789\n",
      "    val_loss       : -723.1683943833792\n",
      "    val_log_likelihood: 1066.026846500377\n",
      "    val_log_marginal: 733.4620621572359\n",
      "Train Epoch: 329 [512/17352 (3%)] Loss: -734.748657\n",
      "Train Epoch: 329 [10438/17352 (60%)] Loss: -760.634217\n",
      "Train Epoch: 329 [17335/17352 (100%)] Loss: -650.706552\n",
      "    epoch          : 329\n",
      "    loss           : -712.5604984096879\n",
      "    val_loss       : -693.3718496185519\n",
      "    val_log_likelihood: 1047.7044480744535\n",
      "    val_log_marginal: 705.8705449111087\n",
      "Train Epoch: 330 [512/17352 (3%)] Loss: -723.921997\n",
      "Train Epoch: 330 [10455/17352 (60%)] Loss: -761.794740\n",
      "Train Epoch: 330 [17253/17352 (99%)] Loss: -653.689556\n",
      "    epoch          : 330\n",
      "    loss           : -715.267399149701\n",
      "    val_loss       : -718.3863005528915\n",
      "    val_log_likelihood: 1065.082371725844\n",
      "    val_log_marginal: 735.4883645404806\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch330.pth ...\n",
      "Train Epoch: 331 [512/17352 (3%)] Loss: -736.224854\n",
      "Train Epoch: 331 [10495/17352 (60%)] Loss: -739.287380\n",
      "Train Epoch: 331 [17126/17352 (99%)] Loss: -757.048734\n",
      "    epoch          : 331\n",
      "    loss           : -681.3108067999867\n",
      "    val_loss       : -631.3543963546826\n",
      "    val_log_likelihood: 1004.9629520616787\n",
      "    val_log_marginal: 646.9151595998878\n",
      "Train Epoch: 332 [512/17352 (3%)] Loss: -678.755493\n",
      "Train Epoch: 332 [10284/17352 (59%)] Loss: -681.329432\n",
      "Train Epoch: 332 [17106/17352 (99%)] Loss: -753.279994\n",
      "    epoch          : 332\n",
      "    loss           : -699.9910581186311\n",
      "    val_loss       : -670.7378426822168\n",
      "    val_log_likelihood: 1034.402206900258\n",
      "    val_log_marginal: 687.091652632466\n",
      "Train Epoch: 333 [512/17352 (3%)] Loss: -688.612122\n",
      "Train Epoch: 333 [10087/17352 (58%)] Loss: -759.493603\n",
      "Train Epoch: 333 [16939/17352 (98%)] Loss: -798.395858\n",
      "    epoch          : 333\n",
      "    loss           : -710.75062492453\n",
      "    val_loss       : -695.2811399694057\n",
      "    val_log_likelihood: 1065.4660436932102\n",
      "    val_log_marginal: 717.618037149866\n",
      "Train Epoch: 334 [512/17352 (3%)] Loss: -718.317383\n",
      "Train Epoch: 334 [10502/17352 (61%)] Loss: -515.139205\n",
      "Train Epoch: 334 [17133/17352 (99%)] Loss: -580.910362\n",
      "    epoch          : 334\n",
      "    loss           : -693.8567815948858\n",
      "    val_loss       : -696.0673493231685\n",
      "    val_log_likelihood: 1054.4362794253282\n",
      "    val_log_marginal: 712.5235597717314\n",
      "Train Epoch: 335 [512/17352 (3%)] Loss: -737.068054\n",
      "Train Epoch: 335 [10513/17352 (61%)] Loss: -622.572844\n",
      "Train Epoch: 335 [17263/17352 (99%)] Loss: -569.507065\n",
      "    epoch          : 335\n",
      "    loss           : -726.4844060757491\n",
      "    val_loss       : -738.1639687399555\n",
      "    val_log_likelihood: 1074.162960383206\n",
      "    val_log_marginal: 744.3992538687959\n",
      "Train Epoch: 336 [512/17352 (3%)] Loss: -702.417725\n",
      "Train Epoch: 336 [10530/17352 (61%)] Loss: -782.324227\n",
      "Train Epoch: 336 [17044/17352 (98%)] Loss: -861.946832\n",
      "    epoch          : 336\n",
      "    loss           : -747.5204251025928\n",
      "    val_loss       : -746.0606946195512\n",
      "    val_log_likelihood: 1087.1021229100547\n",
      "    val_log_marginal: 753.433723673256\n",
      "Train Epoch: 337 [512/17352 (3%)] Loss: -753.898682\n",
      "Train Epoch: 337 [9952/17352 (57%)] Loss: -763.886600\n",
      "Train Epoch: 337 [16878/17352 (97%)] Loss: -730.008743\n",
      "    epoch          : 337\n",
      "    loss           : -735.9184612311368\n",
      "    val_loss       : -732.4739843266306\n",
      "    val_log_likelihood: 1075.7918885828867\n",
      "    val_log_marginal: 742.5392982845607\n",
      "Train Epoch: 338 [512/17352 (3%)] Loss: -738.495789\n",
      "Train Epoch: 338 [10473/17352 (60%)] Loss: -770.333587\n",
      "Train Epoch: 338 [16883/17352 (97%)] Loss: -656.717521\n",
      "    epoch          : 338\n",
      "    loss           : -733.5382084389312\n",
      "    val_loss       : -685.668862638237\n",
      "    val_log_likelihood: 1055.7461134734347\n",
      "    val_log_marginal: 695.902773457862\n",
      "Train Epoch: 339 [512/17352 (3%)] Loss: -720.063721\n",
      "Train Epoch: 339 [10416/17352 (60%)] Loss: -718.444135\n",
      "Train Epoch: 339 [16958/17352 (98%)] Loss: -516.557292\n",
      "    epoch          : 339\n",
      "    loss           : -592.0651438029229\n",
      "    val_loss       : -409.89700144816254\n",
      "    val_log_likelihood: 1016.4120988918966\n",
      "    val_log_marginal: 425.7345071801315\n",
      "Train Epoch: 340 [512/17352 (3%)] Loss: -468.763794\n",
      "Train Epoch: 340 [10686/17352 (62%)] Loss: -578.081270\n",
      "Train Epoch: 340 [17049/17352 (98%)] Loss: -687.179688\n",
      "    epoch          : 340\n",
      "    loss           : -617.7751808023303\n",
      "    val_loss       : -595.5860505807682\n",
      "    val_log_likelihood: 1016.6500054163887\n",
      "    val_log_marginal: 604.3302718447537\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch340.pth ...\n",
      "Train Epoch: 341 [512/17352 (3%)] Loss: -570.051575\n",
      "Train Epoch: 341 [10177/17352 (59%)] Loss: -756.084666\n",
      "Train Epoch: 341 [17064/17352 (98%)] Loss: -667.671235\n",
      "    epoch          : 341\n",
      "    loss           : -671.6925053867384\n",
      "    val_loss       : -722.4183121698827\n",
      "    val_log_likelihood: 1065.1571773306569\n",
      "    val_log_marginal: 731.2340465222578\n",
      "Train Epoch: 342 [512/17352 (3%)] Loss: -730.102905\n",
      "Train Epoch: 342 [10929/17352 (63%)] Loss: -835.813257\n",
      "Train Epoch: 342 [17108/17352 (99%)] Loss: -712.665022\n",
      "    epoch          : 342\n",
      "    loss           : -732.3690569832518\n",
      "    val_loss       : -728.3143499273764\n",
      "    val_log_likelihood: 1084.552507135705\n",
      "    val_log_marginal: 736.2570286385597\n",
      "Train Epoch: 343 [512/17352 (3%)] Loss: -744.626770\n",
      "Train Epoch: 343 [9757/17352 (56%)] Loss: -536.361077\n",
      "Train Epoch: 343 [16992/17352 (98%)] Loss: -600.677527\n",
      "    epoch          : 343\n",
      "    loss           : -690.6521117038435\n",
      "    val_loss       : -603.4280638497056\n",
      "    val_log_likelihood: 1023.7779212410657\n",
      "    val_log_marginal: 611.0595534280724\n",
      "Train Epoch: 344 [512/17352 (3%)] Loss: -589.000854\n",
      "Train Epoch: 344 [9737/17352 (56%)] Loss: -733.977026\n",
      "Train Epoch: 344 [16883/17352 (97%)] Loss: -555.670152\n",
      "    epoch          : 344\n",
      "    loss           : -689.9219651297542\n",
      "    val_loss       : -671.0541001783392\n",
      "    val_log_likelihood: 1052.5391927111561\n",
      "    val_log_marginal: 705.1472224867379\n",
      "Train Epoch: 345 [512/17352 (3%)] Loss: -722.735962\n",
      "Train Epoch: 345 [9745/17352 (56%)] Loss: -750.631847\n",
      "Train Epoch: 345 [16934/17352 (98%)] Loss: -700.186709\n",
      "    epoch          : 345\n",
      "    loss           : -657.2109981516588\n",
      "    val_loss       : -699.0757075765664\n",
      "    val_log_likelihood: 1060.4879849825447\n",
      "    val_log_marginal: 720.8228300575894\n",
      "Train Epoch: 346 [512/17352 (3%)] Loss: -545.959290\n",
      "Train Epoch: 346 [10351/17352 (60%)] Loss: -616.855948\n",
      "Train Epoch: 346 [17143/17352 (99%)] Loss: -682.545294\n",
      "    epoch          : 346\n",
      "    loss           : -714.186548458207\n",
      "    val_loss       : -717.2409653536196\n",
      "    val_log_likelihood: 1078.970754505477\n",
      "    val_log_marginal: 733.2880271825613\n",
      "Train Epoch: 347 [512/17352 (3%)] Loss: -730.333069\n",
      "Train Epoch: 347 [10614/17352 (61%)] Loss: -724.294238\n",
      "Train Epoch: 347 [17126/17352 (99%)] Loss: -796.201660\n",
      "    epoch          : 347\n",
      "    loss           : -744.814320821673\n",
      "    val_loss       : -736.9540714440946\n",
      "    val_log_likelihood: 1085.036175639191\n",
      "    val_log_marginal: 748.793810380712\n",
      "Train Epoch: 348 [512/17352 (3%)] Loss: -611.152832\n",
      "Train Epoch: 348 [10105/17352 (58%)] Loss: -713.419792\n",
      "Train Epoch: 348 [16988/17352 (98%)] Loss: -826.717287\n",
      "    epoch          : 348\n",
      "    loss           : -733.6277372914778\n",
      "    val_loss       : -704.3732785407498\n",
      "    val_log_likelihood: 1077.294519333276\n",
      "    val_log_marginal: 723.514714172097\n",
      "Train Epoch: 349 [512/17352 (3%)] Loss: -722.391846\n",
      "Train Epoch: 349 [10399/17352 (60%)] Loss: -753.113839\n",
      "Train Epoch: 349 [16882/17352 (97%)] Loss: -577.064651\n",
      "    epoch          : 349\n",
      "    loss           : -735.239198724077\n",
      "    val_loss       : -732.8676447311719\n",
      "    val_log_likelihood: 1086.4795839461956\n",
      "    val_log_marginal: 745.0701220992155\n",
      "Train Epoch: 350 [512/17352 (3%)] Loss: -756.411255\n",
      "Train Epoch: 350 [10436/17352 (60%)] Loss: -682.591765\n",
      "Train Epoch: 350 [17143/17352 (99%)] Loss: -620.152390\n",
      "    epoch          : 350\n",
      "    loss           : -733.4437634363101\n",
      "    val_loss       : -708.7384411756881\n",
      "    val_log_likelihood: 1092.907297152827\n",
      "    val_log_marginal: 728.35961895972\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch350.pth ...\n",
      "Train Epoch: 351 [512/17352 (3%)] Loss: -732.089355\n",
      "Train Epoch: 351 [10409/17352 (60%)] Loss: -801.233359\n",
      "Train Epoch: 351 [17143/17352 (99%)] Loss: -569.611283\n",
      "    epoch          : 351\n",
      "    loss           : -696.4716176619\n",
      "    val_loss       : -551.7813933705429\n",
      "    val_log_likelihood: 1049.1036734028928\n",
      "    val_log_marginal: 565.9164141736222\n",
      "Train Epoch: 352 [512/17352 (3%)] Loss: -525.364624\n",
      "Train Epoch: 352 [10535/17352 (61%)] Loss: -130.857791\n",
      "Train Epoch: 352 [16992/17352 (98%)] Loss: 7.691839\n",
      "    epoch          : 352\n",
      "    loss           : -81.51331693705464\n",
      "    val_loss       : -148.07978795546174\n",
      "    val_log_likelihood: 823.9307152753378\n",
      "    val_log_marginal: 170.55490882558192\n",
      "Train Epoch: 353 [512/17352 (3%)] Loss: -127.415665\n",
      "Train Epoch: 353 [10200/17352 (59%)] Loss: -294.572653\n",
      "Train Epoch: 353 [16922/17352 (98%)] Loss: -702.450442\n",
      "    epoch          : 353\n",
      "    loss           : -498.6757964948117\n",
      "    val_loss       : -635.4486758546467\n",
      "    val_log_likelihood: 1007.4986424963572\n",
      "    val_log_marginal: 655.0452938814663\n",
      "Train Epoch: 354 [512/17352 (3%)] Loss: -649.440552\n",
      "Train Epoch: 354 [10398/17352 (60%)] Loss: -716.733268\n",
      "Train Epoch: 354 [16922/17352 (98%)] Loss: -803.155854\n",
      "    epoch          : 354\n",
      "    loss           : -686.6499969218513\n",
      "    val_loss       : -735.506848657021\n",
      "    val_log_likelihood: 1066.9314832455236\n",
      "    val_log_marginal: 745.1751718172601\n",
      "Train Epoch: 355 [512/17352 (3%)] Loss: -758.162781\n",
      "Train Epoch: 355 [10855/17352 (63%)] Loss: -822.368750\n",
      "Train Epoch: 355 [17153/17352 (99%)] Loss: -721.639529\n",
      "    epoch          : 355\n",
      "    loss           : -733.1794818019456\n",
      "    val_loss       : -738.4883206760638\n",
      "    val_log_likelihood: 1078.9100700243391\n",
      "    val_log_marginal: 748.5744370359058\n",
      "Train Epoch: 356 [512/17352 (3%)] Loss: -764.764465\n",
      "Train Epoch: 356 [10383/17352 (60%)] Loss: -637.933736\n",
      "Train Epoch: 356 [17106/17352 (99%)] Loss: -793.144158\n",
      "    epoch          : 356\n",
      "    loss           : -748.210745056242\n",
      "    val_loss       : -743.5636823449423\n",
      "    val_log_likelihood: 1087.0521072924635\n",
      "    val_log_marginal: 754.7869115231878\n",
      "Train Epoch: 357 [512/17352 (3%)] Loss: -763.926514\n",
      "Train Epoch: 357 [10062/17352 (58%)] Loss: -843.259782\n",
      "Train Epoch: 357 [16872/17352 (97%)] Loss: -713.007022\n",
      "    epoch          : 357\n",
      "    loss           : -757.7829655533366\n",
      "    val_loss       : -766.8414838442015\n",
      "    val_log_likelihood: 1109.5181165816728\n",
      "    val_log_marginal: 780.1907499969169\n",
      "Train Epoch: 358 [512/17352 (3%)] Loss: -793.507935\n",
      "Train Epoch: 358 [9885/17352 (57%)] Loss: -809.785675\n",
      "Train Epoch: 358 [16934/17352 (98%)] Loss: -724.334689\n",
      "    epoch          : 358\n",
      "    loss           : -760.2940956643182\n",
      "    val_loss       : -764.4158604896625\n",
      "    val_log_likelihood: 1109.1919464054788\n",
      "    val_log_marginal: 776.2602509568354\n",
      "Train Epoch: 359 [512/17352 (3%)] Loss: -784.525696\n",
      "Train Epoch: 359 [9627/17352 (55%)] Loss: -755.943736\n",
      "Train Epoch: 359 [17143/17352 (99%)] Loss: -831.545276\n",
      "    epoch          : 359\n",
      "    loss           : -770.7812133623935\n",
      "    val_loss       : -759.6345344697256\n",
      "    val_log_likelihood: 1111.8975909769208\n",
      "    val_log_marginal: 770.5872162819854\n",
      "Train Epoch: 360 [512/17352 (3%)] Loss: -783.154053\n",
      "Train Epoch: 360 [10773/17352 (62%)] Loss: -861.805851\n",
      "Train Epoch: 360 [16992/17352 (98%)] Loss: -829.427421\n",
      "    epoch          : 360\n",
      "    loss           : -772.2350632037306\n",
      "    val_loss       : -774.9226966536573\n",
      "    val_log_likelihood: 1120.7935858656156\n",
      "    val_log_marginal: 784.06063004072\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch360.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 361 [512/17352 (3%)] Loss: -781.242371\n",
      "Train Epoch: 361 [10326/17352 (60%)] Loss: -794.048258\n",
      "Train Epoch: 361 [17049/17352 (98%)] Loss: -558.332922\n",
      "    epoch          : 361\n",
      "    loss           : -744.5801752909506\n",
      "    val_loss       : -757.9692564086537\n",
      "    val_log_likelihood: 1106.8723578329739\n",
      "    val_log_marginal: 766.473245854387\n",
      "Train Epoch: 362 [512/17352 (3%)] Loss: -774.978027\n",
      "Train Epoch: 362 [10858/17352 (63%)] Loss: -579.229321\n",
      "Train Epoch: 362 [16923/17352 (98%)] Loss: -812.509658\n",
      "    epoch          : 362\n",
      "    loss           : -752.8413859034666\n",
      "    val_loss       : -777.4930017744322\n",
      "    val_log_likelihood: 1124.7074385017784\n",
      "    val_log_marginal: 784.5711435924887\n",
      "Train Epoch: 363 [512/17352 (3%)] Loss: -796.910278\n",
      "Train Epoch: 363 [10376/17352 (60%)] Loss: -842.628938\n",
      "Train Epoch: 363 [16939/17352 (98%)] Loss: -775.774227\n",
      "    epoch          : 363\n",
      "    loss           : -763.2708327090977\n",
      "    val_loss       : -770.7502621484997\n",
      "    val_log_likelihood: 1129.0096866317178\n",
      "    val_log_marginal: 783.1353793096396\n",
      "Train Epoch: 364 [512/17352 (3%)] Loss: -642.950012\n",
      "Train Epoch: 364 [10454/17352 (60%)] Loss: -854.952128\n",
      "Train Epoch: 364 [16923/17352 (98%)] Loss: -740.113188\n",
      "    epoch          : 364\n",
      "    loss           : -772.830141897549\n",
      "    val_loss       : -770.055974058593\n",
      "    val_log_likelihood: 1132.8091887545527\n",
      "    val_log_marginal: 779.9438930079288\n",
      "Train Epoch: 365 [512/17352 (3%)] Loss: -783.215820\n",
      "Train Epoch: 365 [10024/17352 (58%)] Loss: -820.216543\n",
      "Train Epoch: 365 [17335/17352 (100%)] Loss: -841.105959\n",
      "    epoch          : 365\n",
      "    loss           : -777.6982621837523\n",
      "    val_loss       : -752.7897660725935\n",
      "    val_log_likelihood: 1119.109984085804\n",
      "    val_log_marginal: 766.276577069519\n",
      "Train Epoch: 366 [512/17352 (3%)] Loss: -770.056885\n",
      "Train Epoch: 366 [10683/17352 (62%)] Loss: -804.526253\n",
      "Train Epoch: 366 [17064/17352 (98%)] Loss: -856.028718\n",
      "    epoch          : 366\n",
      "    loss           : -753.4593611821426\n",
      "    val_loss       : -736.7989207376123\n",
      "    val_log_likelihood: 1119.0551435610294\n",
      "    val_log_marginal: 759.0504114845913\n",
      "Train Epoch: 367 [512/17352 (3%)] Loss: -778.665588\n",
      "Train Epoch: 367 [10419/17352 (60%)] Loss: -690.544744\n",
      "Train Epoch: 367 [17277/17352 (100%)] Loss: -795.079332\n",
      "    epoch          : 367\n",
      "    loss           : -757.88618170212\n",
      "    val_loss       : -726.6388029340598\n",
      "    val_log_likelihood: 1105.432503756513\n",
      "    val_log_marginal: 739.2411029588055\n",
      "Train Epoch: 368 [512/17352 (3%)] Loss: -746.343140\n",
      "Train Epoch: 368 [10463/17352 (60%)] Loss: -859.352300\n",
      "Train Epoch: 368 [17277/17352 (100%)] Loss: -671.241166\n",
      "    epoch          : 368\n",
      "    loss           : -750.8140037163082\n",
      "    val_loss       : -679.9590823931245\n",
      "    val_log_likelihood: 1112.8478966056482\n",
      "    val_log_marginal: 697.651736604996\n",
      "Train Epoch: 369 [512/17352 (3%)] Loss: -683.563660\n",
      "Train Epoch: 369 [9803/17352 (56%)] Loss: -628.928322\n",
      "Train Epoch: 369 [16922/17352 (98%)] Loss: -609.159502\n",
      "    epoch          : 369\n",
      "    loss           : -665.3043881629089\n",
      "    val_loss       : -572.2899930665237\n",
      "    val_log_likelihood: 1076.4847599443824\n",
      "    val_log_marginal: 588.4515863877522\n",
      "Train Epoch: 370 [512/17352 (3%)] Loss: -592.681091\n",
      "Train Epoch: 370 [10636/17352 (61%)] Loss: -674.371899\n",
      "Train Epoch: 370 [17277/17352 (100%)] Loss: -683.656960\n",
      "    epoch          : 370\n",
      "    loss           : -700.3597548577205\n",
      "    val_loss       : -651.2516685935548\n",
      "    val_log_likelihood: 1058.5851826484718\n",
      "    val_log_marginal: 664.107830109059\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch370.pth ...\n",
      "Train Epoch: 371 [512/17352 (3%)] Loss: -606.135254\n",
      "Train Epoch: 371 [10494/17352 (60%)] Loss: -817.228643\n",
      "Train Epoch: 371 [17044/17352 (98%)] Loss: -683.314892\n",
      "    epoch          : 371\n",
      "    loss           : -731.7699022300396\n",
      "    val_loss       : -635.3967005989632\n",
      "    val_log_likelihood: 1061.4650124864545\n",
      "    val_log_marginal: 654.6161231142269\n",
      "Train Epoch: 372 [512/17352 (3%)] Loss: -641.217529\n",
      "Train Epoch: 372 [10169/17352 (59%)] Loss: -622.492956\n",
      "Train Epoch: 372 [17016/17352 (98%)] Loss: -788.046732\n",
      "    epoch          : 372\n",
      "    loss           : -711.9659428151009\n",
      "    val_loss       : -735.9733382192071\n",
      "    val_log_likelihood: 1100.5076249619815\n",
      "    val_log_marginal: 748.9439492536928\n",
      "Train Epoch: 373 [512/17352 (3%)] Loss: -753.214478\n",
      "Train Epoch: 373 [10047/17352 (58%)] Loss: -697.026914\n",
      "Train Epoch: 373 [16882/17352 (97%)] Loss: -737.999684\n",
      "    epoch          : 373\n",
      "    loss           : -726.4367697352953\n",
      "    val_loss       : -742.2380743494153\n",
      "    val_log_likelihood: 1115.6825788080482\n",
      "    val_log_marginal: 763.6267892071054\n",
      "Train Epoch: 374 [512/17352 (3%)] Loss: -781.723877\n",
      "Train Epoch: 374 [10759/17352 (62%)] Loss: -582.435798\n",
      "Train Epoch: 374 [17124/17352 (99%)] Loss: -742.822087\n",
      "    epoch          : 374\n",
      "    loss           : -734.429181383017\n",
      "    val_loss       : -685.3779102360104\n",
      "    val_log_likelihood: 1073.3781419848178\n",
      "    val_log_marginal: 693.4568565722642\n",
      "Train Epoch: 375 [512/17352 (3%)] Loss: -708.106018\n",
      "Train Epoch: 375 [10569/17352 (61%)] Loss: -828.497579\n",
      "Train Epoch: 375 [17253/17352 (99%)] Loss: -743.612737\n",
      "    epoch          : 375\n",
      "    loss           : -739.1088278662882\n",
      "    val_loss       : -734.6593561777154\n",
      "    val_log_likelihood: 1112.4638018816343\n",
      "    val_log_marginal: 751.4340542128355\n",
      "Train Epoch: 376 [512/17352 (3%)] Loss: -738.795532\n",
      "Train Epoch: 376 [10468/17352 (60%)] Loss: -895.587836\n",
      "Train Epoch: 376 [17106/17352 (99%)] Loss: -840.111343\n",
      "    epoch          : 376\n",
      "    loss           : -787.4543024401945\n",
      "    val_loss       : -796.4575648267236\n",
      "    val_log_likelihood: 1141.8312882653295\n",
      "    val_log_marginal: 802.8075737949738\n",
      "Train Epoch: 377 [512/17352 (3%)] Loss: -807.546143\n",
      "Train Epoch: 377 [9998/17352 (58%)] Loss: -750.398552\n",
      "Train Epoch: 377 [16957/17352 (98%)] Loss: -838.453768\n",
      "    epoch          : 377\n",
      "    loss           : -775.3010715471409\n",
      "    val_loss       : -694.2891186946681\n",
      "    val_log_likelihood: 1073.7552076737454\n",
      "    val_log_marginal: 701.7299300049154\n",
      "Train Epoch: 378 [512/17352 (3%)] Loss: -695.105225\n",
      "Train Epoch: 378 [9933/17352 (57%)] Loss: -701.666304\n",
      "Train Epoch: 378 [16934/17352 (98%)] Loss: -800.588227\n",
      "    epoch          : 378\n",
      "    loss           : -724.1927174832936\n",
      "    val_loss       : -739.0747758052603\n",
      "    val_log_likelihood: 1116.8472664171813\n",
      "    val_log_marginal: 745.9461855316397\n",
      "Train Epoch: 379 [512/17352 (3%)] Loss: -741.980408\n",
      "Train Epoch: 379 [9263/17352 (53%)] Loss: -795.333794\n",
      "Train Epoch: 379 [16958/17352 (98%)] Loss: -703.809170\n",
      "    epoch          : 379\n",
      "    loss           : -768.7898447499887\n",
      "    val_loss       : -752.7313305938459\n",
      "    val_log_likelihood: 1114.8699304673607\n",
      "    val_log_marginal: 762.406004987809\n",
      "Train Epoch: 380 [512/17352 (3%)] Loss: -771.891846\n",
      "Train Epoch: 380 [10499/17352 (61%)] Loss: -861.902124\n",
      "Train Epoch: 380 [17153/17352 (99%)] Loss: -677.678395\n",
      "    epoch          : 380\n",
      "    loss           : -774.5520279636479\n",
      "    val_loss       : -774.259583514476\n",
      "    val_log_likelihood: 1140.3122668641213\n",
      "    val_log_marginal: 791.19946413059\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch380.pth ...\n",
      "Train Epoch: 381 [512/17352 (3%)] Loss: -796.644775\n",
      "Train Epoch: 381 [10270/17352 (59%)] Loss: -837.212287\n",
      "Train Epoch: 381 [17090/17352 (98%)] Loss: -752.161226\n",
      "    epoch          : 381\n",
      "    loss           : -778.1023286703085\n",
      "    val_loss       : -775.146049350728\n",
      "    val_log_likelihood: 1137.7015890796163\n",
      "    val_log_marginal: 784.2100438401686\n",
      "Train Epoch: 382 [512/17352 (3%)] Loss: -784.650635\n",
      "Train Epoch: 382 [10684/17352 (62%)] Loss: -893.410239\n",
      "Train Epoch: 382 [17090/17352 (98%)] Loss: -832.169378\n",
      "    epoch          : 382\n",
      "    loss           : -800.2870444804857\n",
      "    val_loss       : -791.3967678094741\n",
      "    val_log_likelihood: 1149.7937850619135\n",
      "    val_log_marginal: 800.7448580483264\n",
      "Train Epoch: 383 [512/17352 (3%)] Loss: -802.785278\n",
      "Train Epoch: 383 [10611/17352 (61%)] Loss: -678.409151\n",
      "Train Epoch: 383 [16923/17352 (98%)] Loss: -856.794020\n",
      "    epoch          : 383\n",
      "    loss           : -771.6096031926361\n",
      "    val_loss       : -782.4119721326181\n",
      "    val_log_likelihood: 1149.6877485792184\n",
      "    val_log_marginal: 795.4345731958122\n",
      "Train Epoch: 384 [512/17352 (3%)] Loss: -804.128418\n",
      "Train Epoch: 384 [10410/17352 (60%)] Loss: -625.045673\n",
      "Train Epoch: 384 [16887/17352 (97%)] Loss: -721.654188\n",
      "    epoch          : 384\n",
      "    loss           : -772.1018821698111\n",
      "    val_loss       : -797.7889881497757\n",
      "    val_log_likelihood: 1150.2123191209248\n",
      "    val_log_marginal: 802.724886229276\n",
      "Train Epoch: 385 [512/17352 (3%)] Loss: -814.395874\n",
      "Train Epoch: 385 [9800/17352 (56%)] Loss: -690.500172\n",
      "Train Epoch: 385 [16878/17352 (97%)] Loss: -772.302502\n",
      "    epoch          : 385\n",
      "    loss           : -771.313325887058\n",
      "    val_loss       : -797.8143473989933\n",
      "    val_log_likelihood: 1159.149211787335\n",
      "    val_log_marginal: 808.4869437970245\n",
      "Train Epoch: 386 [512/17352 (3%)] Loss: -812.457092\n",
      "Train Epoch: 386 [10274/17352 (59%)] Loss: -711.644028\n",
      "Train Epoch: 386 [16957/17352 (98%)] Loss: -701.324963\n",
      "    epoch          : 386\n",
      "    loss           : -794.9520782647136\n",
      "    val_loss       : -741.8681904397655\n",
      "    val_log_likelihood: 1163.3722026036974\n",
      "    val_log_marginal: 752.4818299186537\n",
      "Train Epoch: 387 [512/17352 (3%)] Loss: -712.654419\n",
      "Train Epoch: 387 [9998/17352 (58%)] Loss: -803.841330\n",
      "Train Epoch: 387 [16882/17352 (97%)] Loss: -744.443196\n",
      "    epoch          : 387\n",
      "    loss           : -757.5013759093554\n",
      "    val_loss       : -736.6418868308368\n",
      "    val_log_likelihood: 1151.2853733557129\n",
      "    val_log_marginal: 752.5548206163685\n",
      "Train Epoch: 388 [512/17352 (3%)] Loss: -752.933899\n",
      "Train Epoch: 388 [10133/17352 (58%)] Loss: -706.234554\n",
      "Train Epoch: 388 [17335/17352 (100%)] Loss: -653.202975\n",
      "    epoch          : 388\n",
      "    loss           : -710.3994473192835\n",
      "    val_loss       : -278.2332617051723\n",
      "    val_log_likelihood: 1078.664312162077\n",
      "    val_log_marginal: 292.7863335856699\n",
      "Train Epoch: 389 [512/17352 (3%)] Loss: -344.024414\n",
      "Train Epoch: 389 [10477/17352 (60%)] Loss: -514.455815\n",
      "Train Epoch: 389 [17277/17352 (100%)] Loss: -588.728024\n",
      "    epoch          : 389\n",
      "    loss           : -643.5019339334021\n",
      "    val_loss       : -716.7557379422764\n",
      "    val_log_likelihood: 1104.3056904443326\n",
      "    val_log_marginal: 726.6315720076698\n",
      "Train Epoch: 390 [512/17352 (3%)] Loss: -721.523804\n",
      "Train Epoch: 390 [10484/17352 (60%)] Loss: -656.509178\n",
      "Train Epoch: 390 [17335/17352 (100%)] Loss: -814.033203\n",
      "    epoch          : 390\n",
      "    loss           : -767.784547547331\n",
      "    val_loss       : -709.6294110931046\n",
      "    val_log_likelihood: 1118.5303872231075\n",
      "    val_log_marginal: 726.3311287675161\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch390.pth ...\n",
      "Train Epoch: 391 [512/17352 (3%)] Loss: -728.112915\n",
      "Train Epoch: 391 [9814/17352 (57%)] Loss: -846.879464\n",
      "Train Epoch: 391 [16957/17352 (98%)] Loss: -766.511924\n",
      "    epoch          : 391\n",
      "    loss           : -753.3095651281507\n",
      "    val_loss       : -781.2097396228379\n",
      "    val_log_likelihood: 1152.305218327886\n",
      "    val_log_marginal: 804.3522523405684\n",
      "Train Epoch: 392 [512/17352 (3%)] Loss: -759.514221\n",
      "Train Epoch: 392 [10216/17352 (59%)] Loss: -900.939833\n",
      "Train Epoch: 392 [17106/17352 (99%)] Loss: -743.701910\n",
      "    epoch          : 392\n",
      "    loss           : -768.3243914967642\n",
      "    val_loss       : -749.9105305775673\n",
      "    val_log_likelihood: 1145.1836891445314\n",
      "    val_log_marginal: 757.7667835910861\n",
      "Train Epoch: 393 [512/17352 (3%)] Loss: -746.106567\n",
      "Train Epoch: 393 [9968/17352 (57%)] Loss: -685.869083\n",
      "Train Epoch: 393 [17263/17352 (99%)] Loss: -751.152301\n",
      "    epoch          : 393\n",
      "    loss           : -719.927167475318\n",
      "    val_loss       : -756.7517401430563\n",
      "    val_log_likelihood: 1141.3219465121092\n",
      "    val_log_marginal: 763.308427240367\n",
      "Train Epoch: 394 [512/17352 (3%)] Loss: -784.675903\n",
      "Train Epoch: 394 [10325/17352 (60%)] Loss: -641.648043\n",
      "Train Epoch: 394 [16883/17352 (97%)] Loss: -649.871550\n",
      "    epoch          : 394\n",
      "    loss           : -761.242010577013\n",
      "    val_loss       : -738.4078969672338\n",
      "    val_log_likelihood: 1162.5682235507186\n",
      "    val_log_marginal: 748.9673397367656\n",
      "Train Epoch: 395 [512/17352 (3%)] Loss: -772.536621\n",
      "Train Epoch: 395 [10330/17352 (60%)] Loss: -762.445114\n",
      "Train Epoch: 395 [17253/17352 (99%)] Loss: -665.495586\n",
      "    epoch          : 395\n",
      "    loss           : -706.3067013638633\n",
      "    val_loss       : -450.7993893464563\n",
      "    val_log_likelihood: 1078.8989588719533\n",
      "    val_log_marginal: 460.85763246682546\n",
      "Train Epoch: 396 [512/17352 (3%)] Loss: -412.484680\n",
      "Train Epoch: 396 [10499/17352 (61%)] Loss: -826.095612\n",
      "Train Epoch: 396 [17090/17352 (98%)] Loss: -706.720186\n",
      "    epoch          : 396\n",
      "    loss           : -681.0429629154886\n",
      "    val_loss       : -748.9937710592708\n",
      "    val_log_likelihood: 1131.1597349381907\n",
      "    val_log_marginal: 763.7411750101147\n",
      "Train Epoch: 397 [512/17352 (3%)] Loss: -772.039917\n",
      "Train Epoch: 397 [10370/17352 (60%)] Loss: -682.807962\n",
      "Train Epoch: 397 [16883/17352 (97%)] Loss: -648.555444\n",
      "    epoch          : 397\n",
      "    loss           : -770.6849002781933\n",
      "    val_loss       : -785.8219384393157\n",
      "    val_log_likelihood: 1159.8664284648737\n",
      "    val_log_marginal: 801.9938768417585\n",
      "Train Epoch: 398 [512/17352 (3%)] Loss: -824.926270\n",
      "Train Epoch: 398 [10470/17352 (60%)] Loss: -824.620230\n",
      "Train Epoch: 398 [16939/17352 (98%)] Loss: -705.832314\n",
      "    epoch          : 398\n",
      "    loss           : -781.0812337200149\n",
      "    val_loss       : -787.292527749313\n",
      "    val_log_likelihood: 1165.0782978034974\n",
      "    val_log_marginal: 813.3971008634893\n",
      "Train Epoch: 399 [512/17352 (3%)] Loss: -818.841309\n",
      "Train Epoch: 399 [10427/17352 (60%)] Loss: -874.854635\n",
      "Train Epoch: 399 [16934/17352 (98%)] Loss: -698.937692\n",
      "    epoch          : 399\n",
      "    loss           : -787.1124660850339\n",
      "    val_loss       : -794.7664402062729\n",
      "    val_log_likelihood: 1162.2625895581314\n",
      "    val_log_marginal: 811.1009008835126\n",
      "Train Epoch: 400 [512/17352 (3%)] Loss: -825.551514\n",
      "Train Epoch: 400 [10234/17352 (59%)] Loss: -645.541599\n",
      "Train Epoch: 400 [16958/17352 (98%)] Loss: -848.803906\n",
      "    epoch          : 400\n",
      "    loss           : -792.2663069494976\n",
      "    val_loss       : -796.4053637373894\n",
      "    val_log_likelihood: 1163.3504848365517\n",
      "    val_log_marginal: 805.8792024830921\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch400.pth ...\n",
      "Train Epoch: 401 [512/17352 (3%)] Loss: -656.212585\n",
      "Train Epoch: 401 [10677/17352 (62%)] Loss: -576.094124\n",
      "Train Epoch: 401 [16887/17352 (97%)] Loss: -789.798730\n",
      "    epoch          : 401\n",
      "    loss           : -771.3097394036495\n",
      "    val_loss       : -774.8487076951884\n",
      "    val_log_likelihood: 1172.6803636173631\n",
      "    val_log_marginal: 785.1775592809646\n",
      "Train Epoch: 402 [512/17352 (3%)] Loss: -795.900696\n",
      "Train Epoch: 402 [10714/17352 (62%)] Loss: -731.574416\n",
      "Train Epoch: 402 [17153/17352 (99%)] Loss: -542.642900\n",
      "    epoch          : 402\n",
      "    loss           : -692.19501299877\n",
      "    val_loss       : -732.5967288404051\n",
      "    val_log_likelihood: 1126.5983829785516\n",
      "    val_log_marginal: 738.4584434808054\n",
      "Train Epoch: 403 [512/17352 (3%)] Loss: -728.068726\n",
      "Train Epoch: 403 [9700/17352 (56%)] Loss: -627.805264\n",
      "Train Epoch: 403 [16882/17352 (97%)] Loss: -685.804523\n",
      "    epoch          : 403\n",
      "    loss           : -713.4362819144578\n",
      "    val_loss       : -750.2683633989653\n",
      "    val_log_likelihood: 1135.5166085307494\n",
      "    val_log_marginal: 762.8040720095145\n",
      "Train Epoch: 404 [512/17352 (3%)] Loss: -771.934753\n",
      "Train Epoch: 404 [10041/17352 (58%)] Loss: -718.376042\n",
      "Train Epoch: 404 [16992/17352 (98%)] Loss: -733.452225\n",
      "    epoch          : 404\n",
      "    loss           : -740.404917563723\n",
      "    val_loss       : -659.9158077431682\n",
      "    val_log_likelihood: 1061.9719048808226\n",
      "    val_log_marginal: 682.9632949876755\n",
      "Train Epoch: 405 [512/17352 (3%)] Loss: -727.685547\n",
      "Train Epoch: 405 [10485/17352 (60%)] Loss: -804.329183\n",
      "Train Epoch: 405 [17335/17352 (100%)] Loss: -860.230135\n",
      "    epoch          : 405\n",
      "    loss           : -767.7444682370175\n",
      "    val_loss       : -787.185382889228\n",
      "    val_log_likelihood: 1167.7032362314392\n",
      "    val_log_marginal: 799.0738058590445\n",
      "Train Epoch: 406 [512/17352 (3%)] Loss: -811.882690\n",
      "Train Epoch: 406 [10415/17352 (60%)] Loss: -772.681250\n",
      "Train Epoch: 406 [17335/17352 (100%)] Loss: -749.947443\n",
      "    epoch          : 406\n",
      "    loss           : -788.6417169601752\n",
      "    val_loss       : -620.7668352781023\n",
      "    val_log_likelihood: 1118.8145239118508\n",
      "    val_log_marginal: 624.1143056397453\n",
      "Train Epoch: 407 [512/17352 (3%)] Loss: -623.952637\n",
      "Train Epoch: 407 [10276/17352 (59%)] Loss: -878.475095\n",
      "Train Epoch: 407 [16883/17352 (97%)] Loss: -851.685393\n",
      "    epoch          : 407\n",
      "    loss           : -769.7009875667819\n",
      "    val_loss       : -629.3124159850644\n",
      "    val_log_likelihood: 1084.0653738315496\n",
      "    val_log_marginal: 639.6536302809452\n",
      "Train Epoch: 408 [512/17352 (3%)] Loss: -687.101868\n",
      "Train Epoch: 408 [10392/17352 (60%)] Loss: -775.679771\n",
      "Train Epoch: 408 [16878/17352 (97%)] Loss: -696.189683\n",
      "    epoch          : 408\n",
      "    loss           : -744.4014926195989\n",
      "    val_loss       : -814.0249769597868\n",
      "    val_log_likelihood: 1170.315486952757\n",
      "    val_log_marginal: 822.2693206508194\n",
      "Train Epoch: 409 [512/17352 (3%)] Loss: -849.350464\n",
      "Train Epoch: 409 [10566/17352 (61%)] Loss: -814.815662\n",
      "Train Epoch: 409 [16992/17352 (98%)] Loss: -744.929725\n",
      "    epoch          : 409\n",
      "    loss           : -810.8815515394551\n",
      "    val_loss       : -780.0647051804266\n",
      "    val_log_likelihood: 1184.7503336687512\n",
      "    val_log_marginal: 797.162525564332\n",
      "Train Epoch: 410 [512/17352 (3%)] Loss: -806.370483\n",
      "Train Epoch: 410 [10601/17352 (61%)] Loss: -942.494792\n",
      "Train Epoch: 410 [16934/17352 (98%)] Loss: -754.446849\n",
      "    epoch          : 410\n",
      "    loss           : -813.1290894762012\n",
      "    val_loss       : -818.1395898499464\n",
      "    val_log_likelihood: 1193.542015726849\n",
      "    val_log_marginal: 836.042360625896\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch410.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 411 [512/17352 (3%)] Loss: -613.677979\n",
      "Train Epoch: 411 [10601/17352 (61%)] Loss: -848.368899\n",
      "Train Epoch: 411 [17335/17352 (100%)] Loss: -870.026367\n",
      "    epoch          : 411\n",
      "    loss           : -836.8591459336152\n",
      "    val_loss       : -834.1972102137111\n",
      "    val_log_likelihood: 1204.0763127269802\n",
      "    val_log_marginal: 847.4379537985765\n",
      "Train Epoch: 412 [512/17352 (3%)] Loss: -865.039795\n",
      "Train Epoch: 412 [10282/17352 (59%)] Loss: -905.193643\n",
      "Train Epoch: 412 [16934/17352 (98%)] Loss: -772.141580\n",
      "    epoch          : 412\n",
      "    loss           : -831.4872796271433\n",
      "    val_loss       : -812.4856954227874\n",
      "    val_log_likelihood: 1196.5454948137262\n",
      "    val_log_marginal: 831.6558029375483\n",
      "Train Epoch: 413 [512/17352 (3%)] Loss: -772.015930\n",
      "Train Epoch: 413 [10313/17352 (59%)] Loss: -814.029194\n",
      "Train Epoch: 413 [17153/17352 (99%)] Loss: -677.859887\n",
      "    epoch          : 413\n",
      "    loss           : -805.1068309525646\n",
      "    val_loss       : -796.8826418478704\n",
      "    val_log_likelihood: 1175.4051656437612\n",
      "    val_log_marginal: 808.4086621001026\n",
      "Train Epoch: 414 [512/17352 (3%)] Loss: -649.582520\n",
      "Train Epoch: 414 [10716/17352 (62%)] Loss: -706.570275\n",
      "Train Epoch: 414 [17106/17352 (99%)] Loss: -772.998651\n",
      "    epoch          : 414\n",
      "    loss           : -823.636679998645\n",
      "    val_loss       : -816.0581789975979\n",
      "    val_log_likelihood: 1204.249208973139\n",
      "    val_log_marginal: 824.5795456064143\n",
      "Train Epoch: 415 [512/17352 (3%)] Loss: -834.416382\n",
      "Train Epoch: 415 [10407/17352 (60%)] Loss: -815.661902\n",
      "Train Epoch: 415 [17277/17352 (100%)] Loss: -894.740480\n",
      "    epoch          : 415\n",
      "    loss           : -824.2887799831475\n",
      "    val_loss       : -808.5174439653936\n",
      "    val_log_likelihood: 1201.3999210433903\n",
      "    val_log_marginal: 819.0587778302223\n",
      "Train Epoch: 416 [512/17352 (3%)] Loss: -784.707153\n",
      "Train Epoch: 416 [10601/17352 (61%)] Loss: -723.236953\n",
      "Train Epoch: 416 [17263/17352 (99%)] Loss: -917.750254\n",
      "    epoch          : 416\n",
      "    loss           : -818.0736714688159\n",
      "    val_loss       : -829.0051990346877\n",
      "    val_log_likelihood: 1211.0040603132793\n",
      "    val_log_marginal: 839.0135694095044\n",
      "Train Epoch: 417 [512/17352 (3%)] Loss: -852.311646\n",
      "Train Epoch: 417 [10238/17352 (59%)] Loss: -785.270236\n",
      "Train Epoch: 417 [16872/17352 (97%)] Loss: -730.115063\n",
      "    epoch          : 417\n",
      "    loss           : -816.6159621486877\n",
      "    val_loss       : -824.5494694444014\n",
      "    val_log_likelihood: 1202.334300335411\n",
      "    val_log_marginal: 836.2166139301257\n",
      "Train Epoch: 418 [512/17352 (3%)] Loss: -849.183533\n",
      "Train Epoch: 418 [10277/17352 (59%)] Loss: -840.966198\n",
      "Train Epoch: 418 [17263/17352 (99%)] Loss: -650.986774\n",
      "    epoch          : 418\n",
      "    loss           : -760.1290632348707\n",
      "    val_loss       : -629.2064168229912\n",
      "    val_log_likelihood: 1084.593620465506\n",
      "    val_log_marginal: 645.3169981131537\n",
      "Train Epoch: 419 [512/17352 (3%)] Loss: -646.223389\n",
      "Train Epoch: 419 [10610/17352 (61%)] Loss: -848.066456\n",
      "Train Epoch: 419 [17049/17352 (98%)] Loss: -636.662769\n",
      "    epoch          : 419\n",
      "    loss           : -766.5339973587894\n",
      "    val_loss       : -751.1933808432522\n",
      "    val_log_likelihood: 1166.870333164661\n",
      "    val_log_marginal: 775.611720830737\n",
      "Train Epoch: 420 [512/17352 (3%)] Loss: -775.311768\n",
      "Train Epoch: 420 [10477/17352 (60%)] Loss: -813.794364\n",
      "Train Epoch: 420 [17263/17352 (99%)] Loss: -757.243107\n",
      "    epoch          : 420\n",
      "    loss           : -801.2466637880723\n",
      "    val_loss       : -549.966815161343\n",
      "    val_log_likelihood: 1072.4792375333398\n",
      "    val_log_marginal: 558.4466073134163\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch420.pth ...\n",
      "Train Epoch: 421 [512/17352 (3%)] Loss: -411.227295\n",
      "Train Epoch: 421 [10763/17352 (62%)] Loss: -715.266211\n",
      "Train Epoch: 421 [16922/17352 (98%)] Loss: -576.518460\n",
      "    epoch          : 421\n",
      "    loss           : -654.2434004361982\n",
      "    val_loss       : -620.713288908088\n",
      "    val_log_likelihood: 1147.2315354469702\n",
      "    val_log_marginal: 639.8218851992293\n",
      "Train Epoch: 422 [512/17352 (3%)] Loss: -569.911743\n",
      "Train Epoch: 422 [10336/17352 (60%)] Loss: -729.937858\n",
      "Train Epoch: 422 [16878/17352 (97%)] Loss: -687.039885\n",
      "    epoch          : 422\n",
      "    loss           : -645.0288157689259\n",
      "    val_loss       : -660.438558766651\n",
      "    val_log_likelihood: 1150.6369623998644\n",
      "    val_log_marginal: 683.8597769333412\n",
      "Train Epoch: 423 [512/17352 (3%)] Loss: -684.746582\n",
      "Train Epoch: 423 [10522/17352 (61%)] Loss: -839.976165\n",
      "Train Epoch: 423 [16872/17352 (97%)] Loss: -787.608212\n",
      "    epoch          : 423\n",
      "    loss           : -640.132765477985\n",
      "    val_loss       : -696.8967329085423\n",
      "    val_log_likelihood: 1125.2096217001877\n",
      "    val_log_marginal: 717.3521582668991\n",
      "Train Epoch: 424 [512/17352 (3%)] Loss: -666.999084\n",
      "Train Epoch: 424 [10361/17352 (60%)] Loss: -736.889104\n",
      "Train Epoch: 424 [17263/17352 (99%)] Loss: -383.167292\n",
      "    epoch          : 424\n",
      "    loss           : -587.844367867987\n",
      "    val_loss       : -215.7279144714177\n",
      "    val_log_likelihood: 1101.8784142298175\n",
      "    val_log_marginal: 245.84759582200766\n",
      "Train Epoch: 425 [512/17352 (3%)] Loss: -286.988647\n",
      "Train Epoch: 425 [10876/17352 (63%)] Loss: -608.319378\n",
      "Train Epoch: 425 [17153/17352 (99%)] Loss: -712.966924\n",
      "    epoch          : 425\n",
      "    loss           : -650.9606464988013\n",
      "    val_loss       : -737.1888987631997\n",
      "    val_log_likelihood: 1157.7326026209435\n",
      "    val_log_marginal: 754.4611624025541\n",
      "Train Epoch: 426 [512/17352 (3%)] Loss: -766.727051\n",
      "Train Epoch: 426 [10212/17352 (59%)] Loss: -881.131449\n",
      "Train Epoch: 426 [17263/17352 (99%)] Loss: -805.914578\n",
      "    epoch          : 426\n",
      "    loss           : -766.2905290909382\n",
      "    val_loss       : -744.9559936356223\n",
      "    val_log_likelihood: 1179.6045557668137\n",
      "    val_log_marginal: 783.5293314263226\n",
      "Train Epoch: 427 [512/17352 (3%)] Loss: -802.866333\n",
      "Train Epoch: 427 [9962/17352 (57%)] Loss: -829.279699\n",
      "Train Epoch: 427 [16922/17352 (98%)] Loss: -805.751302\n",
      "    epoch          : 427\n",
      "    loss           : -821.3680091861376\n",
      "    val_loss       : -844.4191965637896\n",
      "    val_log_likelihood: 1204.3319315198166\n",
      "    val_log_marginal: 854.475090893395\n",
      "Train Epoch: 428 [512/17352 (3%)] Loss: -872.174194\n",
      "Train Epoch: 428 [10549/17352 (61%)] Loss: -902.327269\n",
      "Train Epoch: 428 [16988/17352 (98%)] Loss: -905.020336\n",
      "    epoch          : 428\n",
      "    loss           : -842.6579827466215\n",
      "    val_loss       : -855.2601132026077\n",
      "    val_log_likelihood: 1216.449347181499\n",
      "    val_log_marginal: 863.9538694794159\n",
      "Train Epoch: 429 [512/17352 (3%)] Loss: -878.451233\n",
      "Train Epoch: 429 [10405/17352 (60%)] Loss: -760.136308\n",
      "Train Epoch: 429 [17108/17352 (99%)] Loss: -907.009400\n",
      "    epoch          : 429\n",
      "    loss           : -847.5439824445557\n",
      "    val_loss       : -846.375222224643\n",
      "    val_log_likelihood: 1216.0533496007206\n",
      "    val_log_marginal: 856.3379192810095\n",
      "Train Epoch: 430 [512/17352 (3%)] Loss: -869.350525\n",
      "Train Epoch: 430 [10405/17352 (60%)] Loss: -933.722005\n",
      "Train Epoch: 430 [16872/17352 (97%)] Loss: -792.455816\n",
      "    epoch          : 430\n",
      "    loss           : -849.1915088181546\n",
      "    val_loss       : -838.5784442580875\n",
      "    val_log_likelihood: 1214.2987161937576\n",
      "    val_log_marginal: 842.6194543044309\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch430.pth ...\n",
      "Train Epoch: 431 [512/17352 (3%)] Loss: -726.075378\n",
      "Train Epoch: 431 [10304/17352 (59%)] Loss: -757.564101\n",
      "Train Epoch: 431 [16883/17352 (97%)] Loss: -875.267284\n",
      "    epoch          : 431\n",
      "    loss           : -831.4258598119568\n",
      "    val_loss       : -834.0552638515978\n",
      "    val_log_likelihood: 1213.806649063668\n",
      "    val_log_marginal: 840.6239155591418\n",
      "Train Epoch: 432 [512/17352 (3%)] Loss: -862.561157\n",
      "Train Epoch: 432 [10442/17352 (60%)] Loss: -649.247370\n",
      "Train Epoch: 432 [17133/17352 (99%)] Loss: -809.224669\n",
      "    epoch          : 432\n",
      "    loss           : -785.6879664977926\n",
      "    val_loss       : -744.9584655488354\n",
      "    val_log_likelihood: 1182.3515513131758\n",
      "    val_log_marginal: 777.7916713961846\n",
      "Train Epoch: 433 [512/17352 (3%)] Loss: -335.786621\n",
      "Train Epoch: 433 [10938/17352 (63%)] Loss: -893.379388\n",
      "Train Epoch: 433 [17126/17352 (99%)] Loss: -641.313250\n",
      "    epoch          : 433\n",
      "    loss           : -730.3382251451374\n",
      "    val_loss       : -675.2622236281559\n",
      "    val_log_likelihood: 1115.1127036944356\n",
      "    val_log_marginal: 707.4208333899168\n",
      "Train Epoch: 434 [512/17352 (3%)] Loss: -712.026733\n",
      "Train Epoch: 434 [10798/17352 (62%)] Loss: -786.179786\n",
      "Train Epoch: 434 [17153/17352 (99%)] Loss: -672.495228\n",
      "    epoch          : 434\n",
      "    loss           : -789.1197255404481\n",
      "    val_loss       : -814.873178171377\n",
      "    val_log_likelihood: 1194.0568549573177\n",
      "    val_log_marginal: 830.7999594585052\n",
      "Train Epoch: 435 [512/17352 (3%)] Loss: -781.136230\n",
      "Train Epoch: 435 [10288/17352 (59%)] Loss: -813.354009\n",
      "Train Epoch: 435 [16923/17352 (98%)] Loss: -615.173253\n",
      "    epoch          : 435\n",
      "    loss           : -809.2872223176248\n",
      "    val_loss       : -841.1353676826645\n",
      "    val_log_likelihood: 1214.4147121706897\n",
      "    val_log_marginal: 854.2433746182722\n",
      "Train Epoch: 436 [512/17352 (3%)] Loss: -873.606445\n",
      "Train Epoch: 436 [10167/17352 (59%)] Loss: -840.738374\n",
      "Train Epoch: 436 [16957/17352 (98%)] Loss: -815.382040\n",
      "    epoch          : 436\n",
      "    loss           : -824.8378007009617\n",
      "    val_loss       : -808.1440851651455\n",
      "    val_log_likelihood: 1201.3469686790902\n",
      "    val_log_marginal: 820.3470352207992\n",
      "Train Epoch: 437 [512/17352 (3%)] Loss: -774.229858\n",
      "Train Epoch: 437 [9777/17352 (56%)] Loss: -747.935695\n",
      "Train Epoch: 437 [16992/17352 (98%)] Loss: -866.768529\n",
      "    epoch          : 437\n",
      "    loss           : -821.1850469154577\n",
      "    val_loss       : -829.3715062898688\n",
      "    val_log_likelihood: 1221.4031463883878\n",
      "    val_log_marginal: 845.102505578117\n",
      "Train Epoch: 438 [512/17352 (3%)] Loss: -869.487427\n",
      "Train Epoch: 438 [9976/17352 (57%)] Loss: -809.108029\n",
      "Train Epoch: 438 [17263/17352 (99%)] Loss: -917.601453\n",
      "    epoch          : 438\n",
      "    loss           : -851.8416000715977\n",
      "    val_loss       : -825.5245667687971\n",
      "    val_log_likelihood: 1216.9876792035382\n",
      "    val_log_marginal: 835.769693739679\n",
      "Train Epoch: 439 [512/17352 (3%)] Loss: -851.953430\n",
      "Train Epoch: 439 [10236/17352 (59%)] Loss: -856.456171\n",
      "Train Epoch: 439 [17153/17352 (99%)] Loss: -744.257639\n",
      "    epoch          : 439\n",
      "    loss           : -832.9940843461299\n",
      "    val_loss       : -859.0092965913196\n",
      "    val_log_likelihood: 1232.403960785178\n",
      "    val_log_marginal: 865.804775306077\n",
      "Train Epoch: 440 [512/17352 (3%)] Loss: -881.989746\n",
      "Train Epoch: 440 [10060/17352 (58%)] Loss: -847.670455\n",
      "Train Epoch: 440 [16988/17352 (98%)] Loss: -860.828540\n",
      "    epoch          : 440\n",
      "    loss           : -813.0616890074132\n",
      "    val_loss       : -817.9057129520945\n",
      "    val_log_likelihood: 1221.8624298519353\n",
      "    val_log_marginal: 824.2294762487112\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch440.pth ...\n",
      "Train Epoch: 441 [512/17352 (3%)] Loss: -834.685425\n",
      "Train Epoch: 441 [9809/17352 (57%)] Loss: -807.670267\n",
      "Train Epoch: 441 [17108/17352 (99%)] Loss: -627.735863\n",
      "    epoch          : 441\n",
      "    loss           : -809.5932261702227\n",
      "    val_loss       : -801.5255396708686\n",
      "    val_log_likelihood: 1206.6498282413918\n",
      "    val_log_marginal: 812.1803863429556\n",
      "Train Epoch: 442 [512/17352 (3%)] Loss: -831.130676\n",
      "Train Epoch: 442 [9993/17352 (58%)] Loss: -783.028665\n",
      "Train Epoch: 442 [17108/17352 (99%)] Loss: -808.033482\n",
      "    epoch          : 442\n",
      "    loss           : -806.3907035449423\n",
      "    val_loss       : -772.9728325022965\n",
      "    val_log_likelihood: 1217.2862176408908\n",
      "    val_log_marginal: 777.203775196356\n",
      "Train Epoch: 443 [512/17352 (3%)] Loss: -792.319336\n",
      "Train Epoch: 443 [10610/17352 (61%)] Loss: -707.843183\n",
      "Train Epoch: 443 [17108/17352 (99%)] Loss: -870.804742\n",
      "    epoch          : 443\n",
      "    loss           : -769.8761517923616\n",
      "    val_loss       : -752.1125439484482\n",
      "    val_log_likelihood: 1207.3049453226017\n",
      "    val_log_marginal: 773.9517915050723\n",
      "Train Epoch: 444 [512/17352 (3%)] Loss: -776.811279\n",
      "Train Epoch: 444 [9974/17352 (57%)] Loss: -905.921278\n",
      "Train Epoch: 444 [16882/17352 (97%)] Loss: -712.430996\n",
      "    epoch          : 444\n",
      "    loss           : -792.3598309878075\n",
      "    val_loss       : -823.5080537521009\n",
      "    val_log_likelihood: 1215.874834238439\n",
      "    val_log_marginal: 835.7445355428838\n",
      "Train Epoch: 445 [512/17352 (3%)] Loss: -856.545532\n",
      "Train Epoch: 445 [9898/17352 (57%)] Loss: -923.352261\n",
      "Train Epoch: 445 [17016/17352 (98%)] Loss: -795.235828\n",
      "    epoch          : 445\n",
      "    loss           : -795.8358772313311\n",
      "    val_loss       : -818.1027535430311\n",
      "    val_log_likelihood: 1216.60983293261\n",
      "    val_log_marginal: 825.3274497964741\n",
      "Train Epoch: 446 [512/17352 (3%)] Loss: -775.524658\n",
      "Train Epoch: 446 [10616/17352 (61%)] Loss: -921.708212\n",
      "Train Epoch: 446 [17101/17352 (99%)] Loss: -754.650448\n",
      "    epoch          : 446\n",
      "    loss           : -833.3748526664846\n",
      "    val_loss       : -776.9741505241282\n",
      "    val_log_likelihood: 1186.735246146665\n",
      "    val_log_marginal: 784.6422223367134\n",
      "Train Epoch: 447 [512/17352 (3%)] Loss: -821.187988\n",
      "Train Epoch: 447 [10588/17352 (61%)] Loss: -711.656452\n",
      "Train Epoch: 447 [17101/17352 (99%)] Loss: -862.554721\n",
      "    epoch          : 447\n",
      "    loss           : -848.3479704454488\n",
      "    val_loss       : -825.1639191924895\n",
      "    val_log_likelihood: 1242.5995248088163\n",
      "    val_log_marginal: 836.9840255423243\n",
      "Train Epoch: 448 [512/17352 (3%)] Loss: -854.972412\n",
      "Train Epoch: 448 [10489/17352 (60%)] Loss: -924.060174\n",
      "Train Epoch: 448 [16883/17352 (97%)] Loss: -882.537405\n",
      "    epoch          : 448\n",
      "    loss           : -844.5189765832866\n",
      "    val_loss       : -846.2992453199641\n",
      "    val_log_likelihood: 1230.3610026219715\n",
      "    val_log_marginal: 855.4906752367905\n",
      "Train Epoch: 449 [512/17352 (3%)] Loss: -728.636963\n",
      "Train Epoch: 449 [10225/17352 (59%)] Loss: -816.764536\n",
      "Train Epoch: 449 [17133/17352 (99%)] Loss: -699.576939\n",
      "    epoch          : 449\n",
      "    loss           : -837.4291864606485\n",
      "    val_loss       : -814.6930250052538\n",
      "    val_log_likelihood: 1241.967179441207\n",
      "    val_log_marginal: 831.8062170138867\n",
      "Train Epoch: 450 [512/17352 (3%)] Loss: -627.390808\n",
      "Train Epoch: 450 [10495/17352 (60%)] Loss: -865.945253\n",
      "Train Epoch: 450 [17133/17352 (99%)] Loss: -531.351382\n",
      "    epoch          : 450\n",
      "    loss           : -816.571129662406\n",
      "    val_loss       : -725.2638166821367\n",
      "    val_log_likelihood: 1180.3575845924531\n",
      "    val_log_marginal: 733.0014766138119\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch450.pth ...\n",
      "Train Epoch: 451 [512/17352 (3%)] Loss: -632.411011\n",
      "Train Epoch: 451 [10153/17352 (59%)] Loss: -651.390054\n",
      "Train Epoch: 451 [17133/17352 (99%)] Loss: -804.114372\n",
      "    epoch          : 451\n",
      "    loss           : -778.7251383982936\n",
      "    val_loss       : -668.2654540372939\n",
      "    val_log_likelihood: 1184.986779992611\n",
      "    val_log_marginal: 678.6716181986902\n",
      "Train Epoch: 452 [512/17352 (3%)] Loss: -682.096436\n",
      "Train Epoch: 452 [10520/17352 (61%)] Loss: -897.384223\n",
      "Train Epoch: 452 [17277/17352 (100%)] Loss: -630.562632\n",
      "    epoch          : 452\n",
      "    loss           : -795.8356916731851\n",
      "    val_loss       : -620.392727883655\n",
      "    val_log_likelihood: 1184.6551016045344\n",
      "    val_log_marginal: 635.6108896455665\n",
      "Train Epoch: 453 [512/17352 (3%)] Loss: -648.192993\n",
      "Train Epoch: 453 [10099/17352 (58%)] Loss: -851.963680\n",
      "Train Epoch: 453 [17253/17352 (99%)] Loss: -690.298790\n",
      "    epoch          : 453\n",
      "    loss           : -766.760370673542\n",
      "    val_loss       : -820.0589124428985\n",
      "    val_log_likelihood: 1218.7807845274226\n",
      "    val_log_marginal: 826.0444365063485\n",
      "Train Epoch: 454 [512/17352 (3%)] Loss: -589.794373\n",
      "Train Epoch: 454 [9942/17352 (57%)] Loss: -890.173017\n",
      "Train Epoch: 454 [17263/17352 (99%)] Loss: -732.043952\n",
      "    epoch          : 454\n",
      "    loss           : -859.9620786319098\n",
      "    val_loss       : -846.9073626643844\n",
      "    val_log_likelihood: 1235.4198422773552\n",
      "    val_log_marginal: 855.4986709531562\n",
      "Train Epoch: 455 [512/17352 (3%)] Loss: -857.086792\n",
      "Train Epoch: 455 [10498/17352 (61%)] Loss: -958.284731\n",
      "Train Epoch: 455 [16988/17352 (98%)] Loss: -808.068391\n",
      "    epoch          : 455\n",
      "    loss           : -877.0406186247513\n",
      "    val_loss       : -875.4324888929841\n",
      "    val_log_likelihood: 1264.7207285067836\n",
      "    val_log_marginal: 897.2172997631213\n",
      "Train Epoch: 456 [512/17352 (3%)] Loss: -912.963989\n",
      "Train Epoch: 456 [10288/17352 (59%)] Loss: -912.724609\n",
      "Train Epoch: 456 [17126/17352 (99%)] Loss: -888.178790\n",
      "    epoch          : 456\n",
      "    loss           : -866.4683715712055\n",
      "    val_loss       : -852.2114324774457\n",
      "    val_log_likelihood: 1255.8724800363009\n",
      "    val_log_marginal: 861.282422419739\n",
      "Train Epoch: 457 [512/17352 (3%)] Loss: -888.137146\n",
      "Train Epoch: 457 [10053/17352 (58%)] Loss: -952.766930\n",
      "Train Epoch: 457 [16923/17352 (98%)] Loss: -849.401615\n",
      "    epoch          : 457\n",
      "    loss           : -876.8056516065055\n",
      "    val_loss       : -890.6086183855848\n",
      "    val_log_likelihood: 1271.336415902605\n",
      "    val_log_marginal: 901.2895583176021\n",
      "Train Epoch: 458 [512/17352 (3%)] Loss: -679.119629\n",
      "Train Epoch: 458 [10557/17352 (61%)] Loss: -884.738235\n",
      "Train Epoch: 458 [16878/17352 (97%)] Loss: -916.578379\n",
      "    epoch          : 458\n",
      "    loss           : -864.7687341642426\n",
      "    val_loss       : -882.6956459299694\n",
      "    val_log_likelihood: 1268.620614895489\n",
      "    val_log_marginal: 891.37654470052\n",
      "Train Epoch: 459 [512/17352 (3%)] Loss: -864.514648\n",
      "Train Epoch: 459 [10479/17352 (60%)] Loss: -846.741100\n",
      "Train Epoch: 459 [17049/17352 (98%)] Loss: -898.549658\n",
      "    epoch          : 459\n",
      "    loss           : -860.8965429099695\n",
      "    val_loss       : -859.6742846403629\n",
      "    val_log_likelihood: 1258.9532845784054\n",
      "    val_log_marginal: 873.6210191924678\n",
      "Train Epoch: 460 [512/17352 (3%)] Loss: -899.095825\n",
      "Train Epoch: 460 [10250/17352 (59%)] Loss: -721.257327\n",
      "Train Epoch: 460 [16883/17352 (97%)] Loss: -937.373771\n",
      "    epoch          : 460\n",
      "    loss           : -822.0790625245389\n",
      "    val_loss       : -816.5391217841914\n",
      "    val_log_likelihood: 1248.4042595171697\n",
      "    val_log_marginal: 829.2412058100242\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch460.pth ...\n",
      "Train Epoch: 461 [512/17352 (3%)] Loss: -841.375244\n",
      "Train Epoch: 461 [10883/17352 (63%)] Loss: -428.749845\n",
      "Train Epoch: 461 [17090/17352 (98%)] Loss: -863.594963\n",
      "    epoch          : 461\n",
      "    loss           : -801.109846876365\n",
      "    val_loss       : -663.2540406191514\n",
      "    val_log_likelihood: 1107.4770920287378\n",
      "    val_log_marginal: 673.5129307066226\n",
      "Train Epoch: 462 [512/17352 (3%)] Loss: -703.922607\n",
      "Train Epoch: 462 [10405/17352 (60%)] Loss: -883.905117\n",
      "Train Epoch: 462 [17101/17352 (99%)] Loss: -614.203387\n",
      "    epoch          : 462\n",
      "    loss           : -774.240218853065\n",
      "    val_loss       : -756.9844206112147\n",
      "    val_log_likelihood: 1235.780777124877\n",
      "    val_log_marginal: 767.5794219195442\n",
      "Train Epoch: 463 [512/17352 (3%)] Loss: -791.052368\n",
      "Train Epoch: 463 [10198/17352 (59%)] Loss: -599.288579\n",
      "Train Epoch: 463 [17108/17352 (99%)] Loss: -404.461582\n",
      "    epoch          : 463\n",
      "    loss           : -749.7386475872687\n",
      "    val_loss       : -557.6598151975063\n",
      "    val_log_likelihood: 1192.3162499608618\n",
      "    val_log_marginal: 567.6340039187345\n",
      "Train Epoch: 464 [512/17352 (3%)] Loss: -566.106995\n",
      "Train Epoch: 464 [10878/17352 (63%)] Loss: -866.954053\n",
      "Train Epoch: 464 [17049/17352 (98%)] Loss: -819.290819\n",
      "    epoch          : 464\n",
      "    loss           : -752.1589610144531\n",
      "    val_loss       : -844.2419299447874\n",
      "    val_log_likelihood: 1243.6598565321087\n",
      "    val_log_marginal: 852.8280849999237\n",
      "Train Epoch: 465 [512/17352 (3%)] Loss: -868.362732\n",
      "Train Epoch: 465 [10413/17352 (60%)] Loss: -825.528112\n",
      "Train Epoch: 465 [16923/17352 (98%)] Loss: -787.014254\n",
      "    epoch          : 465\n",
      "    loss           : -863.5659139221086\n",
      "    val_loss       : -847.8869629141377\n",
      "    val_log_likelihood: 1250.5780050023995\n",
      "    val_log_marginal: 862.8457239785903\n",
      "Train Epoch: 466 [512/17352 (3%)] Loss: -875.043579\n",
      "Train Epoch: 466 [10929/17352 (63%)] Loss: -927.103030\n",
      "Train Epoch: 466 [17133/17352 (99%)] Loss: -932.205523\n",
      "    epoch          : 466\n",
      "    loss           : -854.0295650149204\n",
      "    val_loss       : -889.4014009185545\n",
      "    val_log_likelihood: 1271.9531401128434\n",
      "    val_log_marginal: 900.6179171097367\n",
      "Train Epoch: 467 [512/17352 (3%)] Loss: -928.759644\n",
      "Train Epoch: 467 [9923/17352 (57%)] Loss: -860.706380\n",
      "Train Epoch: 467 [16882/17352 (97%)] Loss: -940.511047\n",
      "    epoch          : 467\n",
      "    loss           : -891.2166077742041\n",
      "    val_loss       : -880.0699631875774\n",
      "    val_log_likelihood: 1267.4616130865857\n",
      "    val_log_marginal: 888.1316204609279\n",
      "Train Epoch: 468 [512/17352 (3%)] Loss: -905.519531\n",
      "Train Epoch: 468 [10522/17352 (61%)] Loss: -898.457826\n",
      "Train Epoch: 468 [17044/17352 (98%)] Loss: -928.200771\n",
      "    epoch          : 468\n",
      "    loss           : -883.1703827158465\n",
      "    val_loss       : -877.0588130038216\n",
      "    val_log_likelihood: 1273.046876131153\n",
      "    val_log_marginal: 885.1139519947073\n",
      "Train Epoch: 469 [512/17352 (3%)] Loss: -895.337158\n",
      "Train Epoch: 469 [10332/17352 (60%)] Loss: -909.179688\n",
      "Train Epoch: 469 [17106/17352 (99%)] Loss: -846.383557\n",
      "    epoch          : 469\n",
      "    loss           : -870.3049305786807\n",
      "    val_loss       : -842.4711745692705\n",
      "    val_log_likelihood: 1255.782388507547\n",
      "    val_log_marginal: 854.025280888515\n",
      "Train Epoch: 470 [512/17352 (3%)] Loss: -852.688110\n",
      "Train Epoch: 470 [9994/17352 (58%)] Loss: -919.108750\n",
      "Train Epoch: 470 [17064/17352 (98%)] Loss: -876.394773\n",
      "    epoch          : 470\n",
      "    loss           : -842.659305714543\n",
      "    val_loss       : -793.7409984387776\n",
      "    val_log_likelihood: 1235.199914230252\n",
      "    val_log_marginal: 827.7721789926295\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch470.pth ...\n",
      "Train Epoch: 471 [512/17352 (3%)] Loss: -862.843323\n",
      "Train Epoch: 471 [9981/17352 (58%)] Loss: -885.643169\n",
      "Train Epoch: 471 [16923/17352 (98%)] Loss: -832.970182\n",
      "    epoch          : 471\n",
      "    loss           : -773.5248741127004\n",
      "    val_loss       : -793.6878287536018\n",
      "    val_log_likelihood: 1227.1145588321085\n",
      "    val_log_marginal: 822.0767741341535\n",
      "Train Epoch: 472 [512/17352 (3%)] Loss: -845.643921\n",
      "Train Epoch: 472 [10269/17352 (59%)] Loss: -681.871572\n",
      "Train Epoch: 472 [16992/17352 (98%)] Loss: 372.104744\n",
      "    epoch          : 472\n",
      "    loss           : -372.052081366774\n",
      "    val_loss       : 2103.9352753398607\n",
      "    val_log_likelihood: 673.7784404142457\n",
      "    val_log_marginal: -2103.654609061141\n",
      "Train Epoch: 473 [512/17352 (3%)] Loss: 1915.333984\n",
      "Train Epoch: 473 [10487/17352 (60%)] Loss: -316.581883\n",
      "Train Epoch: 473 [17090/17352 (98%)] Loss: -621.263292\n",
      "    epoch          : 473\n",
      "    loss           : -222.27623068838085\n",
      "    val_loss       : -329.2047360322956\n",
      "    val_log_likelihood: 949.0918401589953\n",
      "    val_log_marginal: 340.84405941846904\n",
      "Train Epoch: 474 [512/17352 (3%)] Loss: -244.516388\n",
      "Train Epoch: 474 [10510/17352 (61%)] Loss: -647.332015\n",
      "Train Epoch: 474 [16887/17352 (97%)] Loss: -836.169643\n",
      "    epoch          : 474\n",
      "    loss           : -651.065792879968\n",
      "    val_loss       : -798.7386900210389\n",
      "    val_log_likelihood: 1171.5320769694597\n",
      "    val_log_marginal: 807.9349049245857\n",
      "Train Epoch: 475 [512/17352 (3%)] Loss: -829.415771\n",
      "Train Epoch: 475 [10617/17352 (61%)] Loss: -775.200820\n",
      "Train Epoch: 475 [16958/17352 (98%)] Loss: -880.200205\n",
      "    epoch          : 475\n",
      "    loss           : -824.9266411115219\n",
      "    val_loss       : -824.3243452972841\n",
      "    val_log_likelihood: 1199.9675947934027\n",
      "    val_log_marginal: 838.2978485095167\n",
      "Train Epoch: 476 [512/17352 (3%)] Loss: -732.690063\n",
      "Train Epoch: 476 [10686/17352 (62%)] Loss: -888.164323\n",
      "Train Epoch: 476 [17263/17352 (99%)] Loss: -897.442077\n",
      "    epoch          : 476\n",
      "    loss           : -847.6834711579503\n",
      "    val_loss       : -862.4903763858434\n",
      "    val_log_likelihood: 1242.1924623364778\n",
      "    val_log_marginal: 872.0701678698832\n",
      "Train Epoch: 477 [512/17352 (3%)] Loss: -838.661499\n",
      "Train Epoch: 477 [9952/17352 (57%)] Loss: -822.826705\n",
      "Train Epoch: 477 [16882/17352 (97%)] Loss: -929.661919\n",
      "    epoch          : 477\n",
      "    loss           : -870.9748941471697\n",
      "    val_loss       : -880.7610774081164\n",
      "    val_log_likelihood: 1257.3919486368104\n",
      "    val_log_marginal: 890.7541192223799\n",
      "Train Epoch: 478 [512/17352 (3%)] Loss: -913.283691\n",
      "Train Epoch: 478 [10521/17352 (61%)] Loss: -845.964570\n",
      "Train Epoch: 478 [17335/17352 (100%)] Loss: -941.714612\n",
      "    epoch          : 478\n",
      "    loss           : -878.2808252070428\n",
      "    val_loss       : -869.0692872539572\n",
      "    val_log_likelihood: 1260.0820747036555\n",
      "    val_log_marginal: 877.3460405488016\n",
      "Train Epoch: 479 [512/17352 (3%)] Loss: -899.619385\n",
      "Train Epoch: 479 [10564/17352 (61%)] Loss: -983.270325\n",
      "Train Epoch: 479 [16922/17352 (98%)] Loss: -913.327887\n",
      "    epoch          : 479\n",
      "    loss           : -885.096927024397\n",
      "    val_loss       : -890.5588048277136\n",
      "    val_log_likelihood: 1273.085834506952\n",
      "    val_log_marginal: 895.1899309513122\n",
      "Train Epoch: 480 [512/17352 (3%)] Loss: -914.347412\n",
      "Train Epoch: 480 [9655/17352 (56%)] Loss: -774.381579\n",
      "Train Epoch: 480 [17143/17352 (99%)] Loss: -979.526693\n",
      "    epoch          : 480\n",
      "    loss           : -877.5267920936186\n",
      "    val_loss       : -882.6972646641638\n",
      "    val_log_likelihood: 1275.4330770118843\n",
      "    val_log_marginal: 889.1739300061793\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch480.pth ...\n",
      "Train Epoch: 481 [512/17352 (3%)] Loss: -916.271973\n",
      "Train Epoch: 481 [10514/17352 (61%)] Loss: -864.890191\n",
      "Train Epoch: 481 [16922/17352 (98%)] Loss: -888.077381\n",
      "    epoch          : 481\n",
      "    loss           : -890.6549577139768\n",
      "    val_loss       : -908.4238409798547\n",
      "    val_log_likelihood: 1294.125168373955\n",
      "    val_log_marginal: 918.4977097304653\n",
      "Train Epoch: 482 [512/17352 (3%)] Loss: -944.231201\n",
      "Train Epoch: 482 [10685/17352 (62%)] Loss: -872.733122\n",
      "Train Epoch: 482 [16882/17352 (97%)] Loss: -751.915647\n",
      "    epoch          : 482\n",
      "    loss           : -905.3506625928394\n",
      "    val_loss       : -908.0595642363766\n",
      "    val_log_likelihood: 1295.1192889115353\n",
      "    val_log_marginal: 913.4288137737406\n",
      "Train Epoch: 483 [512/17352 (3%)] Loss: -840.388184\n",
      "Train Epoch: 483 [10702/17352 (62%)] Loss: -993.154731\n",
      "Train Epoch: 483 [16992/17352 (98%)] Loss: -990.510838\n",
      "    epoch          : 483\n",
      "    loss           : -903.8123660642129\n",
      "    val_loss       : -904.3387177052995\n",
      "    val_log_likelihood: 1300.5124055103477\n",
      "    val_log_marginal: 917.262523499084\n",
      "Train Epoch: 484 [512/17352 (3%)] Loss: -932.635193\n",
      "Train Epoch: 484 [10228/17352 (59%)] Loss: -907.136600\n",
      "Train Epoch: 484 [17335/17352 (100%)] Loss: -790.560579\n",
      "    epoch          : 484\n",
      "    loss           : -909.5843803429877\n",
      "    val_loss       : -890.9890007433396\n",
      "    val_log_likelihood: 1302.9194101485084\n",
      "    val_log_marginal: 898.4349239654264\n",
      "Train Epoch: 485 [512/17352 (3%)] Loss: -919.572632\n",
      "Train Epoch: 485 [10322/17352 (59%)] Loss: -1014.491102\n",
      "Train Epoch: 485 [17335/17352 (100%)] Loss: -1009.099576\n",
      "    epoch          : 485\n",
      "    loss           : -917.0027381431456\n",
      "    val_loss       : -901.2849773715767\n",
      "    val_log_likelihood: 1301.1193963586654\n",
      "    val_log_marginal: 913.240026597172\n",
      "Train Epoch: 486 [512/17352 (3%)] Loss: -924.716980\n",
      "Train Epoch: 486 [10101/17352 (58%)] Loss: -933.392914\n",
      "Train Epoch: 486 [17126/17352 (99%)] Loss: -872.150514\n",
      "    epoch          : 486\n",
      "    loss           : -915.4023438818298\n",
      "    val_loss       : -915.8498806349603\n",
      "    val_log_likelihood: 1311.518589044011\n",
      "    val_log_marginal: 922.1036966937123\n",
      "Train Epoch: 487 [512/17352 (3%)] Loss: -944.232727\n",
      "Train Epoch: 487 [10357/17352 (60%)] Loss: -862.053757\n",
      "Train Epoch: 487 [17106/17352 (99%)] Loss: -972.806516\n",
      "    epoch          : 487\n",
      "    loss           : -885.7990788985521\n",
      "    val_loss       : -809.7504748237569\n",
      "    val_log_likelihood: 1268.0592980650079\n",
      "    val_log_marginal: 824.8811353503564\n",
      "Train Epoch: 488 [512/17352 (3%)] Loss: -798.189636\n",
      "Train Epoch: 488 [10408/17352 (60%)] Loss: -872.740954\n",
      "Train Epoch: 488 [17263/17352 (99%)] Loss: -921.332049\n",
      "    epoch          : 488\n",
      "    loss           : -875.2987907867787\n",
      "    val_loss       : -875.3610561381684\n",
      "    val_log_likelihood: 1285.1735457842872\n",
      "    val_log_marginal: 882.788719015347\n",
      "Train Epoch: 489 [512/17352 (3%)] Loss: -907.025330\n",
      "Train Epoch: 489 [10246/17352 (59%)] Loss: -912.124256\n",
      "Train Epoch: 489 [17153/17352 (99%)] Loss: -999.866888\n",
      "    epoch          : 489\n",
      "    loss           : -901.1634512193385\n",
      "    val_loss       : -890.088688537719\n",
      "    val_log_likelihood: 1309.7614200600024\n",
      "    val_log_marginal: 901.6588300109778\n",
      "Train Epoch: 490 [512/17352 (3%)] Loss: -916.147522\n",
      "Train Epoch: 490 [10775/17352 (62%)] Loss: -884.964236\n",
      "Train Epoch: 490 [17153/17352 (99%)] Loss: -1004.916233\n",
      "    epoch          : 490\n",
      "    loss           : -916.1507688474455\n",
      "    val_loss       : -920.7878573826815\n",
      "    val_log_likelihood: 1322.1600617655865\n",
      "    val_log_marginal: 928.9937737211109\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch490.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 491 [512/17352 (3%)] Loss: -952.730347\n",
      "Train Epoch: 491 [10261/17352 (59%)] Loss: -879.803603\n",
      "Train Epoch: 491 [16957/17352 (98%)] Loss: -775.220021\n",
      "    epoch          : 491\n",
      "    loss           : -908.2017004773851\n",
      "    val_loss       : -923.8607216879101\n",
      "    val_log_likelihood: 1321.4332076486553\n",
      "    val_log_marginal: 928.0373469530094\n",
      "Train Epoch: 492 [512/17352 (3%)] Loss: -944.065186\n",
      "Train Epoch: 492 [10235/17352 (59%)] Loss: -786.592789\n",
      "Train Epoch: 492 [17124/17352 (99%)] Loss: -717.635616\n",
      "    epoch          : 492\n",
      "    loss           : -866.788827162686\n",
      "    val_loss       : -842.4408289700029\n",
      "    val_log_likelihood: 1265.6735853006685\n",
      "    val_log_marginal: 848.4978040433739\n",
      "Train Epoch: 493 [512/17352 (3%)] Loss: -867.318542\n",
      "Train Epoch: 493 [10806/17352 (62%)] Loss: -751.172648\n",
      "Train Epoch: 493 [16872/17352 (97%)] Loss: -977.128997\n",
      "    epoch          : 493\n",
      "    loss           : -874.784672474221\n",
      "    val_loss       : -906.892365300983\n",
      "    val_log_likelihood: 1308.4116290939826\n",
      "    val_log_marginal: 921.1798590563743\n",
      "Train Epoch: 494 [512/17352 (3%)] Loss: -955.312866\n",
      "Train Epoch: 494 [9845/17352 (57%)] Loss: -1022.908293\n",
      "Train Epoch: 494 [16958/17352 (98%)] Loss: -979.815116\n",
      "    epoch          : 494\n",
      "    loss           : -919.3703920116715\n",
      "    val_loss       : -914.6828247070075\n",
      "    val_log_likelihood: 1319.0987677229823\n",
      "    val_log_marginal: 932.0789873434143\n",
      "Train Epoch: 495 [512/17352 (3%)] Loss: -946.590576\n",
      "Train Epoch: 495 [10637/17352 (61%)] Loss: -999.568251\n",
      "Train Epoch: 495 [16887/17352 (97%)] Loss: -958.390075\n",
      "    epoch          : 495\n",
      "    loss           : -929.3117448262008\n",
      "    val_loss       : -935.0518572710413\n",
      "    val_log_likelihood: 1339.4514274690664\n",
      "    val_log_marginal: 952.1862129798275\n",
      "Train Epoch: 496 [512/17352 (3%)] Loss: -939.715393\n",
      "Train Epoch: 496 [9704/17352 (56%)] Loss: -970.230818\n",
      "Train Epoch: 496 [16939/17352 (98%)] Loss: -778.213505\n",
      "    epoch          : 496\n",
      "    loss           : -908.2125297125518\n",
      "    val_loss       : -873.4070363963247\n",
      "    val_log_likelihood: 1309.6325642861882\n",
      "    val_log_marginal: 882.8579168250741\n",
      "Train Epoch: 497 [512/17352 (3%)] Loss: -886.825928\n",
      "Train Epoch: 497 [10796/17352 (62%)] Loss: -762.220833\n",
      "Train Epoch: 497 [17253/17352 (99%)] Loss: -574.986618\n",
      "    epoch          : 497\n",
      "    loss           : -849.1967975620045\n",
      "    val_loss       : -426.35159463088513\n",
      "    val_log_likelihood: 1265.6475618382817\n",
      "    val_log_marginal: 432.77186441863665\n",
      "Train Epoch: 498 [512/17352 (3%)] Loss: -420.248444\n",
      "Train Epoch: 498 [9986/17352 (58%)] Loss: -727.499298\n",
      "Train Epoch: 498 [17253/17352 (99%)] Loss: -922.807809\n",
      "    epoch          : 498\n",
      "    loss           : -671.9958580324019\n",
      "    val_loss       : -687.4677230217355\n",
      "    val_log_likelihood: 1238.2237718868305\n",
      "    val_log_marginal: 698.2715105392324\n",
      "Train Epoch: 499 [512/17352 (3%)] Loss: -708.176880\n",
      "Train Epoch: 499 [10148/17352 (58%)] Loss: -886.575304\n",
      "Train Epoch: 499 [16883/17352 (97%)] Loss: -516.345728\n",
      "    epoch          : 499\n",
      "    loss           : -825.734383990335\n",
      "    val_loss       : -660.4540672897031\n",
      "    val_log_likelihood: 1291.6226404912638\n",
      "    val_log_marginal: 679.6498316517053\n",
      "Train Epoch: 500 [512/17352 (3%)] Loss: -732.986328\n",
      "Train Epoch: 500 [10211/17352 (59%)] Loss: -720.277257\n",
      "Train Epoch: 500 [17153/17352 (99%)] Loss: -838.620878\n",
      "    epoch          : 500\n",
      "    loss           : -686.8478766020417\n",
      "    val_loss       : -769.1084847930631\n",
      "    val_log_likelihood: 1271.4370925451092\n",
      "    val_log_marginal: 780.448814688855\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch500.pth ...\n",
      "Train Epoch: 501 [512/17352 (3%)] Loss: -773.606445\n",
      "Train Epoch: 501 [10986/17352 (63%)] Loss: -878.752418\n",
      "Train Epoch: 501 [17049/17352 (98%)] Loss: -862.059896\n",
      "    epoch          : 501\n",
      "    loss           : -852.1636617839581\n",
      "    val_loss       : -884.9629398303601\n",
      "    val_log_likelihood: 1296.8854925590504\n",
      "    val_log_marginal: 896.5758457748109\n",
      "Train Epoch: 502 [512/17352 (3%)] Loss: -909.795227\n",
      "Train Epoch: 502 [10856/17352 (63%)] Loss: -987.323338\n",
      "Train Epoch: 502 [17126/17352 (99%)] Loss: -916.319060\n",
      "    epoch          : 502\n",
      "    loss           : -903.1346190966603\n",
      "    val_loss       : -898.7407789106353\n",
      "    val_log_likelihood: 1310.0562512327238\n",
      "    val_log_marginal: 910.30770265474\n",
      "Train Epoch: 503 [512/17352 (3%)] Loss: -922.623108\n",
      "Train Epoch: 503 [10515/17352 (61%)] Loss: -1033.819878\n",
      "Train Epoch: 503 [17277/17352 (100%)] Loss: -868.106143\n",
      "    epoch          : 503\n",
      "    loss           : -888.8359475163671\n",
      "    val_loss       : -673.6094875610121\n",
      "    val_log_likelihood: 1201.9726452459372\n",
      "    val_log_marginal: 683.1769406821466\n",
      "Train Epoch: 504 [512/17352 (3%)] Loss: -791.044678\n",
      "Train Epoch: 504 [10500/17352 (61%)] Loss: -838.836234\n",
      "Train Epoch: 504 [17016/17352 (98%)] Loss: -943.139104\n",
      "    epoch          : 504\n",
      "    loss           : -848.5693987296827\n",
      "    val_loss       : -861.4571563323319\n",
      "    val_log_likelihood: 1297.490773947223\n",
      "    val_log_marginal: 871.1465607948205\n",
      "Train Epoch: 505 [512/17352 (3%)] Loss: -877.857056\n",
      "Train Epoch: 505 [10281/17352 (59%)] Loss: -934.933647\n",
      "Train Epoch: 505 [16988/17352 (98%)] Loss: -810.198415\n",
      "    epoch          : 505\n",
      "    loss           : -910.4429067674263\n",
      "    val_loss       : -927.2419217902628\n",
      "    val_log_likelihood: 1331.9786662946776\n",
      "    val_log_marginal: 937.4317581187973\n",
      "Train Epoch: 506 [512/17352 (3%)] Loss: -918.303284\n",
      "Train Epoch: 506 [10348/17352 (60%)] Loss: -983.680310\n",
      "Train Epoch: 506 [17049/17352 (98%)] Loss: -940.289971\n",
      "    epoch          : 506\n",
      "    loss           : -935.1588169115173\n",
      "    val_loss       : -922.4774726310353\n",
      "    val_log_likelihood: 1331.1735088894625\n",
      "    val_log_marginal: 931.1163628604796\n",
      "Train Epoch: 507 [512/17352 (3%)] Loss: -939.004700\n",
      "Train Epoch: 507 [10487/17352 (60%)] Loss: -1001.008777\n",
      "Train Epoch: 507 [17044/17352 (98%)] Loss: -741.250822\n",
      "    epoch          : 507\n",
      "    loss           : -910.5213017382807\n",
      "    val_loss       : -867.1161466767308\n",
      "    val_log_likelihood: 1296.9584881043975\n",
      "    val_log_marginal: 871.726095149918\n",
      "Train Epoch: 508 [512/17352 (3%)] Loss: -880.605103\n",
      "Train Epoch: 508 [10231/17352 (59%)] Loss: -981.545224\n",
      "Train Epoch: 508 [16887/17352 (97%)] Loss: -979.977906\n",
      "    epoch          : 508\n",
      "    loss           : -884.6285267751414\n",
      "    val_loss       : -920.9009606263357\n",
      "    val_log_likelihood: 1331.187071940956\n",
      "    val_log_marginal: 930.9803023195055\n",
      "Train Epoch: 509 [512/17352 (3%)] Loss: -959.887756\n",
      "Train Epoch: 509 [10180/17352 (59%)] Loss: -895.288999\n",
      "Train Epoch: 509 [16882/17352 (97%)] Loss: -875.853896\n",
      "    epoch          : 509\n",
      "    loss           : -892.0797215374631\n",
      "    val_loss       : -933.4166165446387\n",
      "    val_log_likelihood: 1336.882709942958\n",
      "    val_log_marginal: 941.4057260291862\n",
      "Train Epoch: 510 [512/17352 (3%)] Loss: -965.895874\n",
      "Train Epoch: 510 [10372/17352 (60%)] Loss: -957.320508\n",
      "Train Epoch: 510 [16887/17352 (97%)] Loss: -911.455476\n",
      "    epoch          : 510\n",
      "    loss           : -879.0765253965111\n",
      "    val_loss       : -868.5100037184521\n",
      "    val_log_likelihood: 1310.0828847790706\n",
      "    val_log_marginal: 891.0974912448635\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch510.pth ...\n",
      "Train Epoch: 511 [512/17352 (3%)] Loss: -830.100525\n",
      "Train Epoch: 511 [10710/17352 (62%)] Loss: -768.185282\n",
      "Train Epoch: 511 [16992/17352 (98%)] Loss: -969.614726\n",
      "    epoch          : 511\n",
      "    loss           : -873.5294649686521\n",
      "    val_loss       : -924.6432525107483\n",
      "    val_log_likelihood: 1335.4030158768035\n",
      "    val_log_marginal: 932.5012634975827\n",
      "Train Epoch: 512 [512/17352 (3%)] Loss: -955.861694\n",
      "Train Epoch: 512 [10306/17352 (59%)] Loss: -818.871389\n",
      "Train Epoch: 512 [16878/17352 (97%)] Loss: -1045.451714\n",
      "    epoch          : 512\n",
      "    loss           : -920.8475986016205\n",
      "    val_loss       : -940.3612971354702\n",
      "    val_log_likelihood: 1351.0833359455778\n",
      "    val_log_marginal: 949.4935700847203\n",
      "Train Epoch: 513 [512/17352 (3%)] Loss: -982.942200\n",
      "Train Epoch: 513 [10486/17352 (60%)] Loss: -858.423796\n",
      "Train Epoch: 513 [16934/17352 (98%)] Loss: -921.521291\n",
      "    epoch          : 513\n",
      "    loss           : -916.6292790390249\n",
      "    val_loss       : -913.0785546744395\n",
      "    val_log_likelihood: 1342.0135588276787\n",
      "    val_log_marginal: 938.2329672781217\n",
      "Train Epoch: 514 [512/17352 (3%)] Loss: -965.562561\n",
      "Train Epoch: 514 [10247/17352 (59%)] Loss: -1014.147207\n",
      "Train Epoch: 514 [16923/17352 (98%)] Loss: -982.278542\n",
      "    epoch          : 514\n",
      "    loss           : -915.0125188136407\n",
      "    val_loss       : -908.2504880194234\n",
      "    val_log_likelihood: 1334.7336695107708\n",
      "    val_log_marginal: 928.9603756711921\n",
      "Train Epoch: 515 [512/17352 (3%)] Loss: -942.850952\n",
      "Train Epoch: 515 [10633/17352 (61%)] Loss: -1019.565902\n",
      "Train Epoch: 515 [17101/17352 (99%)] Loss: -934.851648\n",
      "    epoch          : 515\n",
      "    loss           : -931.2071322526269\n",
      "    val_loss       : -881.8091313503902\n",
      "    val_log_likelihood: 1317.9805769457396\n",
      "    val_log_marginal: 904.1423327623087\n",
      "Train Epoch: 516 [512/17352 (3%)] Loss: -930.220093\n",
      "Train Epoch: 516 [11013/17352 (63%)] Loss: -982.924269\n",
      "Train Epoch: 516 [17143/17352 (99%)] Loss: -996.151398\n",
      "    epoch          : 516\n",
      "    loss           : -923.820827280159\n",
      "    val_loss       : -915.0727265824601\n",
      "    val_log_likelihood: 1347.4118884274853\n",
      "    val_log_marginal: 939.8145458312752\n",
      "Train Epoch: 517 [512/17352 (3%)] Loss: -953.334717\n",
      "Train Epoch: 517 [10359/17352 (60%)] Loss: -1011.296621\n",
      "Train Epoch: 517 [17016/17352 (98%)] Loss: -733.314475\n",
      "    epoch          : 517\n",
      "    loss           : -905.9550766864612\n",
      "    val_loss       : -897.1338665687864\n",
      "    val_log_likelihood: 1331.4340256794087\n",
      "    val_log_marginal: 912.9210773332477\n",
      "Train Epoch: 518 [512/17352 (3%)] Loss: -922.986084\n",
      "Train Epoch: 518 [10150/17352 (58%)] Loss: -1027.196329\n",
      "Train Epoch: 518 [16923/17352 (98%)] Loss: -874.125000\n",
      "    epoch          : 518\n",
      "    loss           : -918.5657341885673\n",
      "    val_loss       : -927.5368712459518\n",
      "    val_log_likelihood: 1350.4357422722883\n",
      "    val_log_marginal: 935.0397935879095\n",
      "Train Epoch: 519 [512/17352 (3%)] Loss: -899.730103\n",
      "Train Epoch: 519 [9896/17352 (57%)] Loss: -910.808628\n",
      "Train Epoch: 519 [16887/17352 (97%)] Loss: -893.061384\n",
      "    epoch          : 519\n",
      "    loss           : -915.8807851358048\n",
      "    val_loss       : -920.2839573479761\n",
      "    val_log_likelihood: 1345.5811031806397\n",
      "    val_log_marginal: 927.6521081745611\n",
      "Train Epoch: 520 [512/17352 (3%)] Loss: -954.638062\n",
      "Train Epoch: 520 [10552/17352 (61%)] Loss: -1041.609675\n",
      "Train Epoch: 520 [17106/17352 (99%)] Loss: -1018.284375\n",
      "    epoch          : 520\n",
      "    loss           : -939.0845529710641\n",
      "    val_loss       : -952.5051802257702\n",
      "    val_log_likelihood: 1363.885998598549\n",
      "    val_log_marginal: 957.3758481277456\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch520.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 521 [512/17352 (3%)] Loss: -986.329224\n",
      "Train Epoch: 521 [9888/17352 (57%)] Loss: -965.761763\n",
      "Train Epoch: 521 [16934/17352 (98%)] Loss: -797.208073\n",
      "    epoch          : 521\n",
      "    loss           : -840.608566076477\n",
      "    val_loss       : -839.1807372206026\n",
      "    val_log_likelihood: 1317.7652633157004\n",
      "    val_log_marginal: 848.0537746440168\n",
      "Train Epoch: 522 [512/17352 (3%)] Loss: -732.117737\n",
      "Train Epoch: 522 [10304/17352 (59%)] Loss: -760.663665\n",
      "Train Epoch: 522 [16958/17352 (98%)] Loss: -734.019531\n",
      "    epoch          : 522\n",
      "    loss           : -726.2852030822199\n",
      "    val_loss       : -822.0084875368948\n",
      "    val_log_likelihood: 1269.0248025182905\n",
      "    val_log_marginal: 830.6318427519432\n",
      "Train Epoch: 523 [512/17352 (3%)] Loss: -851.307495\n",
      "Train Epoch: 523 [10123/17352 (58%)] Loss: -807.431416\n",
      "Train Epoch: 523 [17133/17352 (99%)] Loss: -876.035365\n",
      "    epoch          : 523\n",
      "    loss           : -832.2007414259991\n",
      "    val_loss       : -617.0849517828718\n",
      "    val_log_likelihood: 1123.2402983686345\n",
      "    val_log_marginal: 633.5016406834754\n",
      "Train Epoch: 524 [512/17352 (3%)] Loss: -639.513672\n",
      "Train Epoch: 524 [9963/17352 (57%)] Loss: -670.464521\n",
      "Train Epoch: 524 [17016/17352 (98%)] Loss: -811.244858\n",
      "    epoch          : 524\n",
      "    loss           : -817.1423918329674\n",
      "    val_loss       : -676.4087427569805\n",
      "    val_log_likelihood: 1288.6653546485604\n",
      "    val_log_marginal: 694.6549345621722\n",
      "Train Epoch: 525 [512/17352 (3%)] Loss: -733.352966\n",
      "Train Epoch: 525 [10513/17352 (61%)] Loss: -730.409238\n",
      "Train Epoch: 525 [17335/17352 (100%)] Loss: -794.598547\n",
      "    epoch          : 525\n",
      "    loss           : -821.9542686998727\n",
      "    val_loss       : -826.7419951653327\n",
      "    val_log_likelihood: 1298.6435310231102\n",
      "    val_log_marginal: 838.2670692270019\n",
      "Train Epoch: 526 [512/17352 (3%)] Loss: -836.765015\n",
      "Train Epoch: 526 [10302/17352 (59%)] Loss: -980.287452\n",
      "Train Epoch: 526 [16957/17352 (98%)] Loss: -961.112239\n",
      "    epoch          : 526\n",
      "    loss           : -919.6032654452454\n",
      "    val_loss       : -942.4098651418385\n",
      "    val_log_likelihood: 1350.1211955126746\n",
      "    val_log_marginal: 950.0867254921508\n",
      "Train Epoch: 527 [512/17352 (3%)] Loss: -976.594971\n",
      "Train Epoch: 527 [9538/17352 (55%)] Loss: -893.669034\n",
      "Train Epoch: 527 [16922/17352 (98%)] Loss: -993.011393\n",
      "    epoch          : 527\n",
      "    loss           : -951.5159055739933\n",
      "    val_loss       : -965.0501693598578\n",
      "    val_log_likelihood: 1365.4377410467287\n",
      "    val_log_marginal: 974.8977644943141\n",
      "Train Epoch: 528 [512/17352 (3%)] Loss: -1000.448853\n",
      "Train Epoch: 528 [10542/17352 (61%)] Loss: -1012.075061\n",
      "Train Epoch: 528 [16992/17352 (98%)] Loss: -968.467415\n",
      "    epoch          : 528\n",
      "    loss           : -912.9186796122209\n",
      "    val_loss       : -906.2580236452774\n",
      "    val_log_likelihood: 1331.5182579173627\n",
      "    val_log_marginal: 920.350349684629\n",
      "Train Epoch: 529 [512/17352 (3%)] Loss: -923.962585\n",
      "Train Epoch: 529 [10886/17352 (63%)] Loss: -902.894878\n",
      "Train Epoch: 529 [17016/17352 (98%)] Loss: -968.148698\n",
      "    epoch          : 529\n",
      "    loss           : -937.6518781286796\n",
      "    val_loss       : -913.4796653835558\n",
      "    val_log_likelihood: 1348.8343333880307\n",
      "    val_log_marginal: 921.7332636020691\n",
      "Train Epoch: 530 [512/17352 (3%)] Loss: -941.024536\n",
      "Train Epoch: 530 [10457/17352 (60%)] Loss: -839.633298\n",
      "Train Epoch: 530 [17133/17352 (99%)] Loss: -1005.243680\n",
      "    epoch          : 530\n",
      "    loss           : -937.09229007061\n",
      "    val_loss       : -849.0276767077836\n",
      "    val_log_likelihood: 1320.5088404843111\n",
      "    val_log_marginal: 855.2401685168123\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch530.pth ...\n",
      "Train Epoch: 531 [512/17352 (3%)] Loss: -878.619263\n",
      "Train Epoch: 531 [10417/17352 (60%)] Loss: -902.283333\n",
      "Train Epoch: 531 [16922/17352 (98%)] Loss: -1024.796156\n",
      "    epoch          : 531\n",
      "    loss           : -939.9844631232905\n",
      "    val_loss       : -946.8173490706807\n",
      "    val_log_likelihood: 1367.8360918286285\n",
      "    val_log_marginal: 959.0737700772922\n",
      "Train Epoch: 532 [512/17352 (3%)] Loss: -836.635864\n",
      "Train Epoch: 532 [10253/17352 (59%)] Loss: -891.524987\n",
      "Train Epoch: 532 [17153/17352 (99%)] Loss: -960.899544\n",
      "    epoch          : 532\n",
      "    loss           : -929.7781356254216\n",
      "    val_loss       : -909.451743282406\n",
      "    val_log_likelihood: 1354.5954930090616\n",
      "    val_log_marginal: 937.2829110261227\n",
      "Train Epoch: 533 [512/17352 (3%)] Loss: -964.508179\n",
      "Train Epoch: 533 [10216/17352 (59%)] Loss: -747.814818\n",
      "Train Epoch: 533 [17133/17352 (99%)] Loss: -871.887295\n",
      "    epoch          : 533\n",
      "    loss           : -928.6721263253683\n",
      "    val_loss       : -898.2452469884925\n",
      "    val_log_likelihood: 1340.2766239377577\n",
      "    val_log_marginal: 922.0957121651284\n",
      "Train Epoch: 534 [512/17352 (3%)] Loss: -954.592285\n",
      "Train Epoch: 534 [10733/17352 (62%)] Loss: -974.668078\n",
      "Train Epoch: 534 [17016/17352 (98%)] Loss: -1007.658596\n",
      "    epoch          : 534\n",
      "    loss           : -934.821747888418\n",
      "    val_loss       : -943.1301151363856\n",
      "    val_log_likelihood: 1370.2563017607881\n",
      "    val_log_marginal: 958.3714600721595\n",
      "Train Epoch: 535 [512/17352 (3%)] Loss: -922.253784\n",
      "Train Epoch: 535 [10533/17352 (61%)] Loss: -1051.317364\n",
      "Train Epoch: 535 [17263/17352 (99%)] Loss: -889.435677\n",
      "    epoch          : 535\n",
      "    loss           : -918.6843289320747\n",
      "    val_loss       : -918.0458558521124\n",
      "    val_log_likelihood: 1364.33063076666\n",
      "    val_log_marginal: 934.0418364593561\n",
      "Train Epoch: 536 [512/17352 (3%)] Loss: -954.555115\n",
      "Train Epoch: 536 [10811/17352 (62%)] Loss: -741.062650\n",
      "Train Epoch: 536 [16878/17352 (97%)] Loss: -760.038469\n",
      "    epoch          : 536\n",
      "    loss           : -902.4339576807907\n",
      "    val_loss       : -890.9023881862119\n",
      "    val_log_likelihood: 1344.966524303538\n",
      "    val_log_marginal: 903.0893917938072\n",
      "Train Epoch: 537 [512/17352 (3%)] Loss: -921.079834\n",
      "Train Epoch: 537 [10499/17352 (61%)] Loss: -876.871862\n",
      "Train Epoch: 537 [16887/17352 (97%)] Loss: -844.264918\n",
      "    epoch          : 537\n",
      "    loss           : -920.1924509708973\n",
      "    val_loss       : -895.1553171178437\n",
      "    val_log_likelihood: 1372.8669766644703\n",
      "    val_log_marginal: 927.4243684084548\n",
      "Train Epoch: 538 [512/17352 (3%)] Loss: -945.937988\n",
      "Train Epoch: 538 [10349/17352 (60%)] Loss: -851.140587\n",
      "Train Epoch: 538 [17124/17352 (99%)] Loss: -733.247020\n",
      "    epoch          : 538\n",
      "    loss           : -718.2322260181718\n",
      "    val_loss       : -307.26465371495425\n",
      "    val_log_likelihood: 1315.1057329486564\n",
      "    val_log_marginal: 316.81197073809\n",
      "Train Epoch: 539 [512/17352 (3%)] Loss: -340.439392\n",
      "Train Epoch: 539 [10544/17352 (61%)] Loss: -510.700066\n",
      "Train Epoch: 539 [17133/17352 (99%)] Loss: -753.707950\n",
      "    epoch          : 539\n",
      "    loss           : -657.3638913129214\n",
      "    val_loss       : -558.1929205449356\n",
      "    val_log_likelihood: 1235.1494953407177\n",
      "    val_log_marginal: 578.1903483322238\n",
      "Train Epoch: 540 [512/17352 (3%)] Loss: -637.270874\n",
      "Train Epoch: 540 [10310/17352 (59%)] Loss: -920.837500\n",
      "Train Epoch: 540 [17153/17352 (99%)] Loss: -647.288626\n",
      "    epoch          : 540\n",
      "    loss           : -690.4786696266142\n",
      "    val_loss       : -696.1489719224812\n",
      "    val_log_likelihood: 1253.066466559787\n",
      "    val_log_marginal: 712.0537047143681\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch540.pth ...\n",
      "Train Epoch: 541 [512/17352 (3%)] Loss: -687.479004\n",
      "Train Epoch: 541 [10125/17352 (58%)] Loss: -946.212071\n",
      "Train Epoch: 541 [16957/17352 (98%)] Loss: -920.425859\n",
      "    epoch          : 541\n",
      "    loss           : -864.783357500758\n",
      "    val_loss       : -899.0861083248228\n",
      "    val_log_likelihood: 1330.788848999633\n",
      "    val_log_marginal: 924.0330988592233\n",
      "Train Epoch: 542 [512/17352 (3%)] Loss: -952.482849\n",
      "Train Epoch: 542 [9959/17352 (57%)] Loss: -965.884195\n",
      "Train Epoch: 542 [16934/17352 (98%)] Loss: -964.173927\n",
      "    epoch          : 542\n",
      "    loss           : -929.9137023329849\n",
      "    val_loss       : -958.6563209130261\n",
      "    val_log_likelihood: 1365.2749168436137\n",
      "    val_log_marginal: 974.4295483707298\n",
      "Train Epoch: 543 [512/17352 (3%)] Loss: -986.482300\n",
      "Train Epoch: 543 [10589/17352 (61%)] Loss: -1000.668099\n",
      "Train Epoch: 543 [16923/17352 (98%)] Loss: -952.589862\n",
      "    epoch          : 543\n",
      "    loss           : -963.7508758230123\n",
      "    val_loss       : -972.4710360108514\n",
      "    val_log_likelihood: 1382.4408784568018\n",
      "    val_log_marginal: 988.2796628909689\n",
      "Train Epoch: 544 [512/17352 (3%)] Loss: -1007.851929\n",
      "Train Epoch: 544 [10178/17352 (59%)] Loss: -1013.813060\n",
      "Train Epoch: 544 [17143/17352 (99%)] Loss: -1065.310771\n",
      "    epoch          : 544\n",
      "    loss           : -974.1582831441834\n",
      "    val_loss       : -962.987564733138\n",
      "    val_log_likelihood: 1380.0143655723768\n",
      "    val_log_marginal: 974.5623883291304\n",
      "Train Epoch: 545 [512/17352 (3%)] Loss: -998.823669\n",
      "Train Epoch: 545 [10794/17352 (62%)] Loss: -1017.549586\n",
      "Train Epoch: 545 [17090/17352 (98%)] Loss: -1061.629891\n",
      "    epoch          : 545\n",
      "    loss           : -977.3888943144683\n",
      "    val_loss       : -976.9636706183401\n",
      "    val_log_likelihood: 1395.9215924644186\n",
      "    val_log_marginal: 986.8492122291938\n",
      "Train Epoch: 546 [512/17352 (3%)] Loss: -1014.482422\n",
      "Train Epoch: 546 [10340/17352 (60%)] Loss: -867.282446\n",
      "Train Epoch: 546 [17101/17352 (99%)] Loss: -874.149767\n",
      "    epoch          : 546\n",
      "    loss           : -981.1835649705883\n",
      "    val_loss       : -965.7379004303939\n",
      "    val_log_likelihood: 1393.6489313014608\n",
      "    val_log_marginal: 973.483705612836\n",
      "Train Epoch: 547 [512/17352 (3%)] Loss: -995.845886\n",
      "Train Epoch: 547 [10879/17352 (63%)] Loss: -799.025120\n",
      "Train Epoch: 547 [16992/17352 (98%)] Loss: -904.188696\n",
      "    epoch          : 547\n",
      "    loss           : -959.1334863811987\n",
      "    val_loss       : -947.2313997319119\n",
      "    val_log_likelihood: 1379.2823131144517\n",
      "    val_log_marginal: 957.8053199444986\n",
      "Train Epoch: 548 [512/17352 (3%)] Loss: -969.981262\n",
      "Train Epoch: 548 [10447/17352 (60%)] Loss: -980.690832\n",
      "Train Epoch: 548 [17126/17352 (99%)] Loss: -1045.809197\n",
      "    epoch          : 548\n",
      "    loss           : -952.8003529465144\n",
      "    val_loss       : -937.9831892994172\n",
      "    val_log_likelihood: 1372.7353841187019\n",
      "    val_log_marginal: 945.7111073386023\n",
      "Train Epoch: 549 [512/17352 (3%)] Loss: -965.877930\n",
      "Train Epoch: 549 [10391/17352 (60%)] Loss: -949.462722\n",
      "Train Epoch: 549 [16934/17352 (98%)] Loss: -964.421584\n",
      "    epoch          : 549\n",
      "    loss           : -904.7669259608282\n",
      "    val_loss       : -887.5013048073338\n",
      "    val_log_likelihood: 1338.4717769027468\n",
      "    val_log_marginal: 911.8374607247736\n",
      "Train Epoch: 550 [512/17352 (3%)] Loss: -938.051270\n",
      "Train Epoch: 550 [10382/17352 (60%)] Loss: -958.951795\n",
      "Train Epoch: 550 [17101/17352 (99%)] Loss: -801.955394\n",
      "    epoch          : 550\n",
      "    loss           : -932.5705582343769\n",
      "    val_loss       : -947.4493666799842\n",
      "    val_log_likelihood: 1372.5688483237443\n",
      "    val_log_marginal: 956.1851193688575\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch550.pth ...\n",
      "Train Epoch: 551 [512/17352 (3%)] Loss: -986.113098\n",
      "Train Epoch: 551 [10175/17352 (59%)] Loss: -915.955966\n",
      "Train Epoch: 551 [17153/17352 (99%)] Loss: -1044.302192\n",
      "    epoch          : 551\n",
      "    loss           : -952.9389572882637\n",
      "    val_loss       : -902.1093905294271\n",
      "    val_log_likelihood: 1360.1634008052752\n",
      "    val_log_marginal: 910.7668783057334\n",
      "Train Epoch: 552 [512/17352 (3%)] Loss: -787.135498\n",
      "Train Epoch: 552 [10337/17352 (60%)] Loss: -720.352587\n",
      "Train Epoch: 552 [17153/17352 (99%)] Loss: -865.799314\n",
      "    epoch          : 552\n",
      "    loss           : -923.094451428263\n",
      "    val_loss       : -788.2209966211623\n",
      "    val_log_likelihood: 1372.2523916175307\n",
      "    val_log_marginal: 806.9798398796011\n",
      "Train Epoch: 553 [512/17352 (3%)] Loss: -701.263306\n",
      "Train Epoch: 553 [10636/17352 (61%)] Loss: -906.228705\n",
      "Train Epoch: 553 [16882/17352 (97%)] Loss: -796.257812\n",
      "    epoch          : 553\n",
      "    loss           : -928.6918469055533\n",
      "    val_loss       : -949.9063302440509\n",
      "    val_log_likelihood: 1383.6683367846354\n",
      "    val_log_marginal: 957.8391972050885\n",
      "Train Epoch: 554 [512/17352 (3%)] Loss: -974.663574\n",
      "Train Epoch: 554 [10306/17352 (59%)] Loss: -914.132177\n",
      "Train Epoch: 554 [17108/17352 (99%)] Loss: -863.563895\n",
      "    epoch          : 554\n",
      "    loss           : -906.2593466908677\n",
      "    val_loss       : -845.911507065747\n",
      "    val_log_likelihood: 1310.4594533699515\n",
      "    val_log_marginal: 856.3820503881869\n",
      "Train Epoch: 555 [512/17352 (3%)] Loss: -876.120422\n",
      "Train Epoch: 555 [10465/17352 (60%)] Loss: -862.642407\n",
      "Train Epoch: 555 [17253/17352 (99%)] Loss: -894.295501\n",
      "    epoch          : 555\n",
      "    loss           : -886.8994251558164\n",
      "    val_loss       : -833.5190913731986\n",
      "    val_log_likelihood: 1299.537411147295\n",
      "    val_log_marginal: 855.550300399382\n",
      "Train Epoch: 556 [512/17352 (3%)] Loss: -858.765076\n",
      "Train Epoch: 556 [10027/17352 (58%)] Loss: -736.750576\n",
      "Train Epoch: 556 [17133/17352 (99%)] Loss: -862.723086\n",
      "    epoch          : 556\n",
      "    loss           : -909.4111902563029\n",
      "    val_loss       : -890.2836262031135\n",
      "    val_log_likelihood: 1332.2248471998792\n",
      "    val_log_marginal: 902.0602528351086\n",
      "Train Epoch: 557 [512/17352 (3%)] Loss: -927.635864\n",
      "Train Epoch: 557 [10282/17352 (59%)] Loss: -856.941883\n",
      "Train Epoch: 557 [17133/17352 (99%)] Loss: -874.123369\n",
      "    epoch          : 557\n",
      "    loss           : -927.963324583676\n",
      "    val_loss       : -892.2268939828864\n",
      "    val_log_likelihood: 1364.1358712495746\n",
      "    val_log_marginal: 911.0879893819547\n",
      "Train Epoch: 558 [512/17352 (3%)] Loss: -915.255615\n",
      "Train Epoch: 558 [10400/17352 (60%)] Loss: -832.346851\n",
      "Train Epoch: 558 [17126/17352 (99%)] Loss: -1041.849699\n",
      "    epoch          : 558\n",
      "    loss           : -940.7639274907172\n",
      "    val_loss       : -946.7957517219807\n",
      "    val_log_likelihood: 1389.8233629274641\n",
      "    val_log_marginal: 963.1242361276579\n",
      "Train Epoch: 559 [512/17352 (3%)] Loss: -994.452759\n",
      "Train Epoch: 559 [10234/17352 (59%)] Loss: -844.583333\n",
      "Train Epoch: 559 [17101/17352 (99%)] Loss: -1033.901932\n",
      "    epoch          : 559\n",
      "    loss           : -970.3347668393321\n",
      "    val_loss       : -968.634667337552\n",
      "    val_log_likelihood: 1398.496834220405\n",
      "    val_log_marginal: 985.5474775033281\n",
      "Train Epoch: 560 [512/17352 (3%)] Loss: -1018.127258\n",
      "Train Epoch: 560 [10123/17352 (58%)] Loss: -855.053470\n",
      "Train Epoch: 560 [16882/17352 (97%)] Loss: -1015.943557\n",
      "    epoch          : 560\n",
      "    loss           : -982.518905035794\n",
      "    val_loss       : -974.4583862315615\n",
      "    val_log_likelihood: 1404.4504047095238\n",
      "    val_log_marginal: 978.872393257183\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch560.pth ...\n",
      "Train Epoch: 561 [512/17352 (3%)] Loss: -861.601135\n",
      "Train Epoch: 561 [10177/17352 (59%)] Loss: -987.140874\n",
      "Train Epoch: 561 [17126/17352 (99%)] Loss: -279.135045\n",
      "    epoch          : 561\n",
      "    loss           : -872.7559889375084\n",
      "    val_loss       : -299.66070502843024\n",
      "    val_log_likelihood: 1355.2735269311834\n",
      "    val_log_marginal: 313.49292629933467\n",
      "Train Epoch: 562 [512/17352 (3%)] Loss: -359.234741\n",
      "Train Epoch: 562 [10076/17352 (58%)] Loss: -804.917325\n",
      "Train Epoch: 562 [17106/17352 (99%)] Loss: -580.250158\n",
      "    epoch          : 562\n",
      "    loss           : -673.2947117090426\n",
      "    val_loss       : -333.8324127359323\n",
      "    val_log_likelihood: 1296.740666199757\n",
      "    val_log_marginal: 344.2431884044127\n",
      "Train Epoch: 563 [512/17352 (3%)] Loss: -398.770752\n",
      "Train Epoch: 563 [9574/17352 (55%)] Loss: -795.653386\n",
      "Train Epoch: 563 [17064/17352 (98%)] Loss: -809.004006\n",
      "    epoch          : 563\n",
      "    loss           : -754.2262243021335\n",
      "    val_loss       : -851.4631335652603\n",
      "    val_log_likelihood: 1341.0674305563907\n",
      "    val_log_marginal: 872.5016495097912\n",
      "Train Epoch: 564 [512/17352 (3%)] Loss: -877.388306\n",
      "Train Epoch: 564 [10013/17352 (58%)] Loss: -921.239857\n",
      "Train Epoch: 564 [16878/17352 (97%)] Loss: -869.781250\n",
      "    epoch          : 564\n",
      "    loss           : -900.1244760944969\n",
      "    val_loss       : -965.199724089508\n",
      "    val_log_likelihood: 1380.3714760384767\n",
      "    val_log_marginal: 973.0678048846711\n",
      "Train Epoch: 565 [512/17352 (3%)] Loss: -851.489563\n",
      "Train Epoch: 565 [9705/17352 (56%)] Loss: -826.171256\n",
      "Train Epoch: 565 [17133/17352 (99%)] Loss: -958.231306\n",
      "    epoch          : 565\n",
      "    loss           : -961.2051092728219\n",
      "    val_loss       : -953.4109397034451\n",
      "    val_log_likelihood: 1376.2424465551524\n",
      "    val_log_marginal: 964.5544463926075\n",
      "Train Epoch: 566 [512/17352 (3%)] Loss: -992.424194\n",
      "Train Epoch: 566 [10296/17352 (59%)] Loss: -961.827340\n",
      "Train Epoch: 566 [17133/17352 (99%)] Loss: -859.654605\n",
      "    epoch          : 566\n",
      "    loss           : -927.4504650213837\n",
      "    val_loss       : -956.4338310183426\n",
      "    val_log_likelihood: 1375.5786401147677\n",
      "    val_log_marginal: 959.8987640262801\n",
      "Train Epoch: 567 [512/17352 (3%)] Loss: -989.094055\n",
      "Train Epoch: 567 [10614/17352 (61%)] Loss: -878.317135\n",
      "Train Epoch: 567 [16887/17352 (97%)] Loss: -1113.313766\n",
      "    epoch          : 567\n",
      "    loss           : -990.4359396176851\n",
      "    val_loss       : -1003.0600002639002\n",
      "    val_log_likelihood: 1418.37691772574\n",
      "    val_log_marginal: 1014.5465387646918\n",
      "Train Epoch: 568 [512/17352 (3%)] Loss: -902.230713\n",
      "Train Epoch: 568 [10034/17352 (58%)] Loss: -959.334263\n",
      "Train Epoch: 568 [16934/17352 (98%)] Loss: -939.427015\n",
      "    epoch          : 568\n",
      "    loss           : -981.0572820868792\n",
      "    val_loss       : -973.5197101985764\n",
      "    val_log_likelihood: 1419.8682059995706\n",
      "    val_log_marginal: 1010.4949681863367\n",
      "Train Epoch: 569 [512/17352 (3%)] Loss: -1035.515015\n",
      "Train Epoch: 569 [10130/17352 (58%)] Loss: -967.835103\n",
      "Train Epoch: 569 [17124/17352 (99%)] Loss: -1058.980013\n",
      "    epoch          : 569\n",
      "    loss           : -979.6785134713249\n",
      "    val_loss       : -966.3245736862751\n",
      "    val_log_likelihood: 1403.699964420092\n",
      "    val_log_marginal: 984.2743532361653\n",
      "Train Epoch: 570 [512/17352 (3%)] Loss: -952.509705\n",
      "Train Epoch: 570 [10537/17352 (61%)] Loss: -728.191522\n",
      "Train Epoch: 570 [16934/17352 (98%)] Loss: -993.808633\n",
      "    epoch          : 570\n",
      "    loss           : -996.2172937914478\n",
      "    val_loss       : -1005.9843789222599\n",
      "    val_log_likelihood: 1429.772878983462\n",
      "    val_log_marginal: 1016.6749688134349\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch570.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 571 [512/17352 (3%)] Loss: -1037.275635\n",
      "Train Epoch: 571 [10643/17352 (61%)] Loss: -863.891597\n",
      "Train Epoch: 571 [17253/17352 (99%)] Loss: -1044.840665\n",
      "    epoch          : 571\n",
      "    loss           : -973.8365310697717\n",
      "    val_loss       : -953.3782246830834\n",
      "    val_log_likelihood: 1410.3668002375834\n",
      "    val_log_marginal: 963.848638357984\n",
      "Train Epoch: 572 [512/17352 (3%)] Loss: -992.197144\n",
      "Train Epoch: 572 [10089/17352 (58%)] Loss: -853.158581\n",
      "Train Epoch: 572 [16878/17352 (97%)] Loss: -930.890305\n",
      "    epoch          : 572\n",
      "    loss           : -972.9914315568357\n",
      "    val_loss       : -999.8225826349602\n",
      "    val_log_likelihood: 1425.0426862397728\n",
      "    val_log_marginal: 1004.3252891068661\n",
      "Train Epoch: 573 [512/17352 (3%)] Loss: -1029.107666\n",
      "Train Epoch: 573 [10108/17352 (58%)] Loss: -1018.871003\n",
      "Train Epoch: 573 [16988/17352 (98%)] Loss: -942.196172\n",
      "    epoch          : 573\n",
      "    loss           : -982.6196657686593\n",
      "    val_loss       : -999.2558968437631\n",
      "    val_log_likelihood: 1430.9332812503508\n",
      "    val_log_marginal: 1011.4991898686093\n",
      "Train Epoch: 574 [512/17352 (3%)] Loss: -1029.174561\n",
      "Train Epoch: 574 [10719/17352 (62%)] Loss: -949.062407\n",
      "Train Epoch: 574 [17153/17352 (99%)] Loss: -1059.107500\n",
      "    epoch          : 574\n",
      "    loss           : -989.1869507178089\n",
      "    val_loss       : -973.9148821503668\n",
      "    val_log_likelihood: 1429.1679544853866\n",
      "    val_log_marginal: 984.692646340174\n",
      "Train Epoch: 575 [512/17352 (3%)] Loss: -1005.810425\n",
      "Train Epoch: 575 [10480/17352 (60%)] Loss: -1087.257495\n",
      "Train Epoch: 575 [17049/17352 (98%)] Loss: -1013.866770\n",
      "    epoch          : 575\n",
      "    loss           : -968.7784184284905\n",
      "    val_loss       : -992.6520390955961\n",
      "    val_log_likelihood: 1431.8634744610392\n",
      "    val_log_marginal: 1003.1667572070162\n",
      "Train Epoch: 576 [512/17352 (3%)] Loss: -966.759155\n",
      "Train Epoch: 576 [10263/17352 (59%)] Loss: -1002.265348\n",
      "Train Epoch: 576 [16882/17352 (97%)] Loss: -738.500897\n",
      "    epoch          : 576\n",
      "    loss           : -909.6454853464217\n",
      "    val_loss       : -953.1152994116682\n",
      "    val_log_likelihood: 1395.5819386508012\n",
      "    val_log_marginal: 960.7859091839952\n",
      "Train Epoch: 577 [512/17352 (3%)] Loss: -983.370667\n",
      "Train Epoch: 577 [10071/17352 (58%)] Loss: -950.819760\n",
      "Train Epoch: 577 [17016/17352 (98%)] Loss: -981.309320\n",
      "    epoch          : 577\n",
      "    loss           : -932.2823872900364\n",
      "    val_loss       : -980.0949553812094\n",
      "    val_log_likelihood: 1403.4055253715371\n",
      "    val_log_marginal: 990.3708086636439\n",
      "Train Epoch: 578 [512/17352 (3%)] Loss: -1009.983521\n",
      "Train Epoch: 578 [10395/17352 (60%)] Loss: -1097.082423\n",
      "Train Epoch: 578 [16878/17352 (97%)] Loss: -1070.270930\n",
      "    epoch          : 578\n",
      "    loss           : -989.1928275791752\n",
      "    val_loss       : -1010.9192778201007\n",
      "    val_log_likelihood: 1427.1593976945107\n",
      "    val_log_marginal: 1015.1932320010156\n",
      "Train Epoch: 579 [512/17352 (3%)] Loss: -999.323730\n",
      "Train Epoch: 579 [9914/17352 (57%)] Loss: -1001.429802\n",
      "Train Epoch: 579 [16923/17352 (98%)] Loss: -941.153085\n",
      "    epoch          : 579\n",
      "    loss           : -984.9732917599866\n",
      "    val_loss       : -979.7146989790757\n",
      "    val_log_likelihood: 1423.3816042898343\n",
      "    val_log_marginal: 988.5037846202201\n",
      "Train Epoch: 580 [512/17352 (3%)] Loss: -1013.603333\n",
      "Train Epoch: 580 [10056/17352 (58%)] Loss: -1003.969378\n",
      "Train Epoch: 580 [17277/17352 (100%)] Loss: -895.577927\n",
      "    epoch          : 580\n",
      "    loss           : -1004.3235163002945\n",
      "    val_loss       : -887.0884616931755\n",
      "    val_log_likelihood: 1428.02062605078\n",
      "    val_log_marginal: 896.6551657904891\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch580.pth ...\n",
      "Train Epoch: 581 [512/17352 (3%)] Loss: -925.110229\n",
      "Train Epoch: 581 [10186/17352 (59%)] Loss: -1032.759898\n",
      "Train Epoch: 581 [17253/17352 (99%)] Loss: -975.288999\n",
      "    epoch          : 581\n",
      "    loss           : -961.5306938821539\n",
      "    val_loss       : -915.8893533324219\n",
      "    val_log_likelihood: 1382.1474624396665\n",
      "    val_log_marginal: 920.6562423678863\n",
      "Train Epoch: 582 [512/17352 (3%)] Loss: -731.753418\n",
      "Train Epoch: 582 [10245/17352 (59%)] Loss: -852.004899\n",
      "Train Epoch: 582 [16934/17352 (98%)] Loss: -889.870460\n",
      "    epoch          : 582\n",
      "    loss           : -933.87486282475\n",
      "    val_loss       : -962.0171434960556\n",
      "    val_log_likelihood: 1404.7327609413026\n",
      "    val_log_marginal: 970.6691650033563\n",
      "Train Epoch: 583 [512/17352 (3%)] Loss: -989.954956\n",
      "Train Epoch: 583 [10739/17352 (62%)] Loss: -901.500000\n",
      "Train Epoch: 583 [17049/17352 (98%)] Loss: -850.563140\n",
      "    epoch          : 583\n",
      "    loss           : -954.1875590211349\n",
      "    val_loss       : -957.2125557799619\n",
      "    val_log_likelihood: 1408.9639361585491\n",
      "    val_log_marginal: 970.4135535687022\n",
      "Train Epoch: 584 [512/17352 (3%)] Loss: -693.063477\n",
      "Train Epoch: 584 [10187/17352 (59%)] Loss: -953.408755\n",
      "Train Epoch: 584 [17101/17352 (99%)] Loss: -760.642674\n",
      "    epoch          : 584\n",
      "    loss           : -939.0393693903192\n",
      "    val_loss       : -955.139273386457\n",
      "    val_log_likelihood: 1410.30242802908\n",
      "    val_log_marginal: 978.4432711437402\n",
      "Train Epoch: 585 [512/17352 (3%)] Loss: -994.415894\n",
      "Train Epoch: 585 [10514/17352 (61%)] Loss: -1033.750130\n",
      "Train Epoch: 585 [16988/17352 (98%)] Loss: -1071.979854\n",
      "    epoch          : 585\n",
      "    loss           : -987.3050432091311\n",
      "    val_loss       : -990.5958956077568\n",
      "    val_log_likelihood: 1438.1287526574163\n",
      "    val_log_marginal: 1016.3126546082426\n",
      "Train Epoch: 586 [512/17352 (3%)] Loss: -1040.931641\n",
      "Train Epoch: 586 [10255/17352 (59%)] Loss: -835.870864\n",
      "Train Epoch: 586 [17263/17352 (99%)] Loss: -1020.841016\n",
      "    epoch          : 586\n",
      "    loss           : -975.7527373705085\n",
      "    val_loss       : -928.9370566721203\n",
      "    val_log_likelihood: 1404.7065366369848\n",
      "    val_log_marginal: 952.1914299042135\n",
      "Train Epoch: 587 [512/17352 (3%)] Loss: -993.635864\n",
      "Train Epoch: 587 [10158/17352 (59%)] Loss: -980.749828\n",
      "Train Epoch: 587 [17124/17352 (99%)] Loss: -1066.860759\n",
      "    epoch          : 587\n",
      "    loss           : -999.3720701684392\n",
      "    val_loss       : -965.0634291829957\n",
      "    val_log_likelihood: 1430.7637467910447\n",
      "    val_log_marginal: 972.6075947158163\n",
      "Train Epoch: 588 [512/17352 (3%)] Loss: -941.754211\n",
      "Train Epoch: 588 [10370/17352 (60%)] Loss: -1037.814315\n",
      "Train Epoch: 588 [17143/17352 (99%)] Loss: -967.092291\n",
      "    epoch          : 588\n",
      "    loss           : -1003.3214017605708\n",
      "    val_loss       : -1004.3829197857959\n",
      "    val_log_likelihood: 1449.8009021707662\n",
      "    val_log_marginal: 1016.1219350037759\n",
      "Train Epoch: 589 [512/17352 (3%)] Loss: -982.725891\n",
      "Train Epoch: 589 [10250/17352 (59%)] Loss: -951.741477\n",
      "Train Epoch: 589 [16923/17352 (98%)] Loss: -1036.386259\n",
      "    epoch          : 589\n",
      "    loss           : -995.0837551553366\n",
      "    val_loss       : -978.9607294441157\n",
      "    val_log_likelihood: 1429.9619171908932\n",
      "    val_log_marginal: 994.8358926875932\n",
      "Train Epoch: 590 [512/17352 (3%)] Loss: -1017.466858\n",
      "Train Epoch: 590 [10695/17352 (62%)] Loss: -833.137995\n",
      "Train Epoch: 590 [17044/17352 (98%)] Loss: -1005.153865\n",
      "    epoch          : 590\n",
      "    loss           : -941.8694877120644\n",
      "    val_loss       : -966.317380781728\n",
      "    val_log_likelihood: 1422.676216731319\n",
      "    val_log_marginal: 988.7549636126485\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch590.pth ...\n",
      "Train Epoch: 591 [512/17352 (3%)] Loss: -856.332581\n",
      "Train Epoch: 591 [10157/17352 (59%)] Loss: -1047.092960\n",
      "Train Epoch: 591 [17064/17352 (98%)] Loss: -985.666031\n",
      "    epoch          : 591\n",
      "    loss           : -944.2414219048895\n",
      "    val_loss       : -911.285613413939\n",
      "    val_log_likelihood: 1388.1379918299492\n",
      "    val_log_marginal: 928.7228600532294\n",
      "Train Epoch: 592 [512/17352 (3%)] Loss: -953.969727\n",
      "Train Epoch: 592 [10442/17352 (60%)] Loss: -862.410410\n",
      "Train Epoch: 592 [16988/17352 (98%)] Loss: -944.887708\n",
      "    epoch          : 592\n",
      "    loss           : -927.0685604574427\n",
      "    val_loss       : -883.465787515491\n",
      "    val_log_likelihood: 1354.847794898961\n",
      "    val_log_marginal: 893.9591136463333\n",
      "Train Epoch: 593 [512/17352 (3%)] Loss: -877.675354\n",
      "Train Epoch: 593 [10156/17352 (59%)] Loss: -839.915023\n",
      "Train Epoch: 593 [17101/17352 (99%)] Loss: -850.655230\n",
      "    epoch          : 593\n",
      "    loss           : -915.2975386386137\n",
      "    val_loss       : -861.5999400224819\n",
      "    val_log_likelihood: 1338.3859410723358\n",
      "    val_log_marginal: 881.6999963443487\n",
      "Train Epoch: 594 [512/17352 (3%)] Loss: -887.592102\n",
      "Train Epoch: 594 [10511/17352 (61%)] Loss: -963.778776\n",
      "Train Epoch: 594 [16957/17352 (98%)] Loss: -792.808566\n",
      "    epoch          : 594\n",
      "    loss           : -941.2029312573671\n",
      "    val_loss       : -997.6194261949979\n",
      "    val_log_likelihood: 1422.6380452124563\n",
      "    val_log_marginal: 1003.0958432168036\n",
      "Train Epoch: 595 [512/17352 (3%)] Loss: -1031.884399\n",
      "Train Epoch: 595 [9978/17352 (58%)] Loss: -926.661198\n",
      "Train Epoch: 595 [17124/17352 (99%)] Loss: 730.899340\n",
      "    epoch          : 595\n",
      "    loss           : -938.2315284277076\n",
      "    val_loss       : -381.8799257623574\n",
      "    val_log_likelihood: 1347.684376980062\n",
      "    val_log_marginal: 399.24715795687933\n",
      "Train Epoch: 596 [512/17352 (3%)] Loss: -422.099152\n",
      "Train Epoch: 596 [10448/17352 (60%)] Loss: -958.588350\n",
      "Train Epoch: 596 [17143/17352 (99%)] Loss: -852.322273\n",
      "    epoch          : 596\n",
      "    loss           : -878.261880866337\n",
      "    val_loss       : -948.3046147631765\n",
      "    val_log_likelihood: 1388.5798183293925\n",
      "    val_log_marginal: 954.083947150563\n",
      "Train Epoch: 597 [512/17352 (3%)] Loss: -982.944946\n",
      "Train Epoch: 597 [9970/17352 (57%)] Loss: -985.279609\n",
      "Train Epoch: 597 [16934/17352 (98%)] Loss: -798.795833\n",
      "    epoch          : 597\n",
      "    loss           : -926.2228401376741\n",
      "    val_loss       : -941.1583081068376\n",
      "    val_log_likelihood: 1409.5269246679998\n",
      "    val_log_marginal: 966.5588414185135\n",
      "Train Epoch: 598 [512/17352 (3%)] Loss: -976.930237\n",
      "Train Epoch: 598 [10217/17352 (59%)] Loss: -1005.956649\n",
      "Train Epoch: 598 [17153/17352 (99%)] Loss: -946.742075\n",
      "    epoch          : 598\n",
      "    loss           : -965.7123754092289\n",
      "    val_loss       : -971.2258578165435\n",
      "    val_log_likelihood: 1411.6541941530363\n",
      "    val_log_marginal: 980.1586606133958\n",
      "Train Epoch: 599 [512/17352 (3%)] Loss: -995.852600\n",
      "Train Epoch: 599 [10019/17352 (58%)] Loss: -968.762277\n",
      "Train Epoch: 599 [16887/17352 (97%)] Loss: -983.837022\n",
      "    epoch          : 599\n",
      "    loss           : -985.3532550374629\n",
      "    val_loss       : -997.9158242507324\n",
      "    val_log_likelihood: 1439.110469730688\n",
      "    val_log_marginal: 1020.6546577928995\n",
      "Train Epoch: 600 [512/17352 (3%)] Loss: -1042.204834\n",
      "Train Epoch: 600 [9963/17352 (57%)] Loss: -1065.660174\n",
      "Train Epoch: 600 [16882/17352 (97%)] Loss: -898.844985\n",
      "    epoch          : 600\n",
      "    loss           : -951.3892472193644\n",
      "    val_loss       : -813.6446766118636\n",
      "    val_log_likelihood: 1413.2609114349661\n",
      "    val_log_marginal: 819.8953200703808\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch600.pth ...\n",
      "Train Epoch: 601 [512/17352 (3%)] Loss: -892.858765\n",
      "Train Epoch: 601 [10115/17352 (58%)] Loss: -816.997309\n",
      "Train Epoch: 601 [16878/17352 (97%)] Loss: -286.152105\n",
      "    epoch          : 601\n",
      "    loss           : -822.1231634817071\n",
      "    val_loss       : -846.0373540261429\n",
      "    val_log_likelihood: 1382.8378098949047\n",
      "    val_log_marginal: 912.4460015167589\n",
      "Train Epoch: 602 [512/17352 (3%)] Loss: -924.255981\n",
      "Train Epoch: 602 [10619/17352 (61%)] Loss: -741.180585\n",
      "Train Epoch: 602 [17153/17352 (99%)] Loss: -633.795556\n",
      "    epoch          : 602\n",
      "    loss           : -899.1814034895818\n",
      "    val_loss       : -788.0130066691873\n",
      "    val_log_likelihood: 1398.0159015832228\n",
      "    val_log_marginal: 827.3887907383304\n",
      "Train Epoch: 603 [512/17352 (3%)] Loss: -849.111694\n",
      "Train Epoch: 603 [10185/17352 (59%)] Loss: -957.977532\n",
      "Train Epoch: 603 [16958/17352 (98%)] Loss: -808.435104\n",
      "    epoch          : 603\n",
      "    loss           : -456.31322376739706\n",
      "    val_loss       : -497.7900841874693\n",
      "    val_log_likelihood: 1293.2292694919906\n",
      "    val_log_marginal: 830.2833227272705\n",
      "Train Epoch: 604 [512/17352 (3%)] Loss: -848.594421\n",
      "Train Epoch: 604 [9783/17352 (56%)] Loss: -474.682301\n",
      "Train Epoch: 604 [16923/17352 (98%)] Loss: -666.719149\n",
      "    epoch          : 604\n",
      "    loss           : -104.82149361357133\n",
      "    val_loss       : -432.12427724868905\n",
      "    val_log_likelihood: 1188.637806111193\n",
      "    val_log_marginal: 593.441069849727\n",
      "Train Epoch: 605 [512/17352 (3%)] Loss: -609.641724\n",
      "Train Epoch: 605 [10797/17352 (62%)] Loss: 366.078292\n",
      "Train Epoch: 605 [16988/17352 (98%)] Loss: -740.074767\n",
      "    epoch          : 605\n",
      "    loss           : -390.6965766347771\n",
      "    val_loss       : -618.5313890970841\n",
      "    val_log_likelihood: 1338.726482362068\n",
      "    val_log_marginal: 872.269154743048\n",
      "Train Epoch: 606 [512/17352 (3%)] Loss: -896.550171\n",
      "Train Epoch: 606 [10099/17352 (58%)] Loss: -1019.899583\n",
      "Train Epoch: 606 [17253/17352 (99%)] Loss: -897.597561\n",
      "    epoch          : 606\n",
      "    loss           : 380.2232529700115\n",
      "    val_loss       : -414.83984550468915\n",
      "    val_log_likelihood: 1321.3497061172507\n",
      "    val_log_marginal: 789.1028528028784\n",
      "Train Epoch: 607 [512/17352 (3%)] Loss: -822.245300\n",
      "Train Epoch: 607 [10142/17352 (58%)] Loss: -880.290650\n",
      "Train Epoch: 607 [16992/17352 (98%)] Loss: -909.576801\n",
      "    epoch          : 607\n",
      "    loss           : -405.6688099955616\n",
      "    val_loss       : -602.9725112028418\n",
      "    val_log_likelihood: 1301.7964350190582\n",
      "    val_log_marginal: 787.653602754814\n",
      "Train Epoch: 608 [512/17352 (3%)] Loss: -793.517334\n",
      "Train Epoch: 608 [10110/17352 (58%)] Loss: 900.952691\n",
      "Train Epoch: 608 [17126/17352 (99%)] Loss: -803.510562\n",
      "    epoch          : 608\n",
      "    loss           : -713.4133265762501\n",
      "    val_loss       : -791.2955817304367\n",
      "    val_log_likelihood: 1379.90762871119\n",
      "    val_log_marginal: 941.7197618618628\n",
      "Train Epoch: 609 [512/17352 (3%)] Loss: -814.162903\n",
      "Train Epoch: 609 [10602/17352 (61%)] Loss: -930.731864\n",
      "Train Epoch: 609 [17253/17352 (99%)] Loss: -780.847039\n",
      "    epoch          : 609\n",
      "    loss           : -758.7304949495937\n",
      "    val_loss       : -718.2446035649202\n",
      "    val_log_likelihood: 1402.1362033015378\n",
      "    val_log_marginal: 953.0299847411907\n",
      "Train Epoch: 610 [512/17352 (3%)] Loss: -975.070435\n",
      "Train Epoch: 610 [10099/17352 (58%)] Loss: 10008.164474\n",
      "Train Epoch: 610 [17044/17352 (98%)] Loss: -1012.309251\n",
      "    epoch          : 610\n",
      "    loss           : -533.9919110995658\n",
      "    val_loss       : -674.80790252085\n",
      "    val_log_likelihood: 1381.5816205650947\n",
      "    val_log_marginal: 942.0991230157048\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch610.pth ...\n",
      "Train Epoch: 611 [512/17352 (3%)] Loss: -967.808411\n",
      "Train Epoch: 611 [10261/17352 (59%)] Loss: -931.185369\n",
      "Train Epoch: 611 [16882/17352 (97%)] Loss: -1008.842601\n",
      "    epoch          : 611\n",
      "    loss           : -585.4638883148652\n",
      "    val_loss       : -575.8150402865303\n",
      "    val_log_likelihood: 1409.1406208401675\n",
      "    val_log_marginal: 993.144503784935\n",
      "Train Epoch: 612 [512/17352 (3%)] Loss: -1021.156311\n",
      "Train Epoch: 612 [10374/17352 (60%)] Loss: -32.950363\n",
      "Train Epoch: 612 [17153/17352 (99%)] Loss: -1048.540396\n",
      "    epoch          : 612\n",
      "    loss           : -715.4133757421642\n",
      "    val_loss       : -588.0205631850413\n",
      "    val_log_likelihood: 1391.493154809652\n",
      "    val_log_marginal: 959.4243755856493\n",
      "Train Epoch: 613 [512/17352 (3%)] Loss: -971.359863\n",
      "Train Epoch: 613 [10214/17352 (59%)] Loss: -1010.784235\n",
      "Train Epoch: 613 [16992/17352 (98%)] Loss: 205.755797\n",
      "    epoch          : 613\n",
      "    loss           : -662.7265477536776\n",
      "    val_loss       : -816.5593207279301\n",
      "    val_log_likelihood: 1397.5142055162337\n",
      "    val_log_marginal: 984.958203906908\n",
      "Train Epoch: 614 [512/17352 (3%)] Loss: -1017.558472\n",
      "Train Epoch: 614 [10227/17352 (59%)] Loss: 409.539326\n",
      "Train Epoch: 614 [16872/17352 (97%)] Loss: 305.072049\n",
      "    epoch          : 614\n",
      "    loss           : -776.1145016147377\n",
      "    val_loss       : -734.8629265679945\n",
      "    val_log_likelihood: 1384.1590400319315\n",
      "    val_log_marginal: 967.0161407578761\n",
      "Train Epoch: 615 [512/17352 (3%)] Loss: 242.134705\n",
      "Train Epoch: 615 [10664/17352 (61%)] Loss: -903.251399\n",
      "Train Epoch: 615 [16992/17352 (98%)] Loss: -885.738477\n",
      "    epoch          : 615\n",
      "    loss           : -591.9275724559511\n",
      "    val_loss       : -648.6607023143785\n",
      "    val_log_likelihood: 1327.0027686457702\n",
      "    val_log_marginal: 902.117960189221\n",
      "Train Epoch: 616 [512/17352 (3%)] Loss: -912.726074\n",
      "Train Epoch: 616 [10378/17352 (60%)] Loss: -920.608621\n",
      "Train Epoch: 616 [17253/17352 (99%)] Loss: 152.602915\n",
      "    epoch          : 616\n",
      "    loss           : -519.5122252798053\n",
      "    val_loss       : -551.4059272401598\n",
      "    val_log_likelihood: 1362.729887571003\n",
      "    val_log_marginal: 747.1147745222648\n",
      "Train Epoch: 617 [512/17352 (3%)] Loss: -772.441162\n",
      "Train Epoch: 617 [10788/17352 (62%)] Loss: -817.106520\n",
      "Train Epoch: 617 [17277/17352 (100%)] Loss: -515.676339\n",
      "    epoch          : 617\n",
      "    loss           : -724.0109815294427\n",
      "    val_loss       : -647.9038244609883\n",
      "    val_log_likelihood: 1365.729437996453\n",
      "    val_log_marginal: 814.140516395202\n",
      "Train Epoch: 618 [512/17352 (3%)] Loss: -861.965881\n",
      "Train Epoch: 618 [11030/17352 (64%)] Loss: -1000.659382\n",
      "Train Epoch: 618 [17253/17352 (99%)] Loss: -905.804816\n",
      "    epoch          : 618\n",
      "    loss           : -813.2526176950827\n",
      "    val_loss       : -750.3430072788468\n",
      "    val_log_likelihood: 1368.717601681988\n",
      "    val_log_marginal: 944.9575538256452\n",
      "Train Epoch: 619 [512/17352 (3%)] Loss: -959.863708\n",
      "Train Epoch: 619 [10414/17352 (60%)] Loss: -726.233804\n",
      "Train Epoch: 619 [17277/17352 (100%)] Loss: -815.388951\n",
      "    epoch          : 619\n",
      "    loss           : -635.5216160593021\n",
      "    val_loss       : -643.8144860396327\n",
      "    val_log_likelihood: 1332.9437066954142\n",
      "    val_log_marginal: 787.2059391439009\n",
      "Train Epoch: 620 [512/17352 (3%)] Loss: -833.815674\n",
      "Train Epoch: 620 [10215/17352 (59%)] Loss: -967.635203\n",
      "Train Epoch: 620 [17143/17352 (99%)] Loss: -740.100962\n",
      "    epoch          : 620\n",
      "    loss           : -748.574353516939\n",
      "    val_loss       : -177.02371042958458\n",
      "    val_log_likelihood: 1369.1929301638243\n",
      "    val_log_marginal: 460.1798141833071\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch620.pth ...\n",
      "Train Epoch: 621 [512/17352 (3%)] Loss: -485.994171\n",
      "Train Epoch: 621 [10604/17352 (61%)] Loss: -804.718357\n",
      "Train Epoch: 621 [17090/17352 (98%)] Loss: -692.756975\n",
      "    epoch          : 621\n",
      "    loss           : -348.74022726803156\n",
      "    val_loss       : 3884.10415592183\n",
      "    val_log_likelihood: 751.8137025056049\n",
      "    val_log_marginal: -3413.2839266835963\n",
      "Train Epoch: 622 [512/17352 (3%)] Loss: 3517.501465\n",
      "Train Epoch: 622 [9922/17352 (57%)] Loss: -502.167500\n",
      "Train Epoch: 622 [16934/17352 (98%)] Loss: -283.309477\n",
      "    epoch          : 622\n",
      "    loss           : 264.92861889442827\n",
      "    val_loss       : -524.4793734760083\n",
      "    val_log_likelihood: 1179.1302537617298\n",
      "    val_log_marginal: 613.0234792295432\n",
      "Train Epoch: 623 [512/17352 (3%)] Loss: -641.459351\n",
      "Train Epoch: 623 [10351/17352 (60%)] Loss: -750.267195\n",
      "Train Epoch: 623 [17126/17352 (99%)] Loss: -945.865312\n",
      "    epoch          : 623\n",
      "    loss           : -648.3378341082805\n",
      "    val_loss       : -679.4291767508973\n",
      "    val_log_likelihood: 1278.5023057709736\n",
      "    val_log_marginal: 860.5100540184905\n",
      "Train Epoch: 624 [512/17352 (3%)] Loss: -871.976624\n",
      "Train Epoch: 624 [10513/17352 (61%)] Loss: -1008.248095\n",
      "Train Epoch: 624 [16988/17352 (98%)] Loss: -103.044397\n",
      "    epoch          : 624\n",
      "    loss           : -724.0173600383552\n",
      "    val_loss       : -737.8208255899397\n",
      "    val_log_likelihood: 1328.936092328742\n",
      "    val_log_marginal: 941.0177891011732\n",
      "Train Epoch: 625 [512/17352 (3%)] Loss: 114.018799\n",
      "Train Epoch: 625 [10571/17352 (61%)] Loss: -849.297442\n",
      "Train Epoch: 625 [16988/17352 (98%)] Loss: -856.557028\n",
      "    epoch          : 625\n",
      "    loss           : -848.1547572279912\n",
      "    val_loss       : -826.5212736544166\n",
      "    val_log_likelihood: 1330.6615605995848\n",
      "    val_log_marginal: 944.6771804645584\n",
      "Train Epoch: 626 [512/17352 (3%)] Loss: -971.169434\n",
      "Train Epoch: 626 [9955/17352 (57%)] Loss: -916.579951\n",
      "Train Epoch: 626 [16934/17352 (98%)] Loss: -1013.711555\n",
      "    epoch          : 626\n",
      "    loss           : -876.7385474456656\n",
      "    val_loss       : -781.1976830518527\n",
      "    val_log_likelihood: 1348.5454922522608\n",
      "    val_log_marginal: 972.2625718493634\n",
      "Train Epoch: 627 [512/17352 (3%)] Loss: -995.099670\n",
      "Train Epoch: 627 [10005/17352 (58%)] Loss: -850.634615\n",
      "Train Epoch: 627 [17101/17352 (99%)] Loss: -853.143167\n",
      "    epoch          : 627\n",
      "    loss           : -818.8327333869704\n",
      "    val_loss       : -810.5077050576962\n",
      "    val_log_likelihood: 1356.5389515784257\n",
      "    val_log_marginal: 977.6884135154185\n",
      "Train Epoch: 628 [512/17352 (3%)] Loss: -999.104065\n",
      "Train Epoch: 628 [9768/17352 (56%)] Loss: -959.764881\n",
      "Train Epoch: 628 [17090/17352 (98%)] Loss: -1009.460782\n",
      "    epoch          : 628\n",
      "    loss           : -884.2609512298319\n",
      "    val_loss       : -794.5248720543844\n",
      "    val_log_likelihood: 1361.187367570899\n",
      "    val_log_marginal: 984.763523671441\n",
      "Train Epoch: 629 [512/17352 (3%)] Loss: -1013.804077\n",
      "Train Epoch: 629 [10547/17352 (61%)] Loss: -989.482955\n",
      "Train Epoch: 629 [17126/17352 (99%)] Loss: -980.097356\n",
      "    epoch          : 629\n",
      "    loss           : -876.4928288843278\n",
      "    val_loss       : -843.589016692559\n",
      "    val_log_likelihood: 1361.2048336982557\n",
      "    val_log_marginal: 985.7894254111607\n",
      "Train Epoch: 630 [512/17352 (3%)] Loss: -1011.090271\n",
      "Train Epoch: 630 [10667/17352 (61%)] Loss: -842.802061\n",
      "Train Epoch: 630 [17108/17352 (99%)] Loss: -660.339247\n",
      "    epoch          : 630\n",
      "    loss           : -687.6056720006536\n",
      "    val_loss       : -704.687591168256\n",
      "    val_log_likelihood: 1280.1736325189702\n",
      "    val_log_marginal: 785.4907399221163\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch630.pth ...\n",
      "Train Epoch: 631 [512/17352 (3%)] Loss: -844.485962\n",
      "Train Epoch: 631 [10336/17352 (60%)] Loss: -915.445587\n",
      "Train Epoch: 631 [16992/17352 (98%)] Loss: -999.688356\n",
      "    epoch          : 631\n",
      "    loss           : -800.0065011730854\n",
      "    val_loss       : -702.2951607514415\n",
      "    val_log_likelihood: 1309.283237791905\n",
      "    val_log_marginal: 913.6095434634854\n",
      "Train Epoch: 632 [512/17352 (3%)] Loss: -781.115845\n",
      "Train Epoch: 632 [10389/17352 (60%)] Loss: -984.267907\n",
      "Train Epoch: 632 [16922/17352 (98%)] Loss: -10.547564\n",
      "    epoch          : 632\n",
      "    loss           : -830.7733126585359\n",
      "    val_loss       : -820.5046604476937\n",
      "    val_log_likelihood: 1355.6484783354929\n",
      "    val_log_marginal: 983.419181916595\n",
      "Train Epoch: 633 [512/17352 (3%)] Loss: -1008.742615\n",
      "Train Epoch: 633 [10099/17352 (58%)] Loss: -972.671186\n",
      "Train Epoch: 633 [16958/17352 (98%)] Loss: -1015.632198\n",
      "    epoch          : 633\n",
      "    loss           : -930.7739240606902\n",
      "    val_loss       : -803.2123456497918\n",
      "    val_log_likelihood: 1363.075417143062\n",
      "    val_log_marginal: 989.7374973354107\n",
      "Train Epoch: 634 [512/17352 (3%)] Loss: -1010.200867\n",
      "Train Epoch: 634 [10402/17352 (60%)] Loss: -91.208504\n",
      "Train Epoch: 634 [16878/17352 (97%)] Loss: 5.431756\n",
      "    epoch          : 634\n",
      "    loss           : -913.0657199577893\n",
      "    val_loss       : -784.8810450305717\n",
      "    val_log_likelihood: 1359.5581166634317\n",
      "    val_log_marginal: 979.7901620403691\n",
      "Train Epoch: 635 [512/17352 (3%)] Loss: -875.284302\n",
      "Train Epoch: 635 [10687/17352 (62%)] Loss: -938.827070\n",
      "Train Epoch: 635 [17108/17352 (99%)] Loss: -670.512485\n",
      "    epoch          : 635\n",
      "    loss           : -747.6649592415728\n",
      "    val_loss       : -693.1996329647212\n",
      "    val_log_likelihood: 1260.7479671249191\n",
      "    val_log_marginal: 846.5573032834866\n",
      "Train Epoch: 636 [512/17352 (3%)] Loss: -870.537537\n",
      "Train Epoch: 636 [10080/17352 (58%)] Loss: -876.640698\n",
      "Train Epoch: 636 [16878/17352 (97%)] Loss: -956.620091\n",
      "    epoch          : 636\n",
      "    loss           : -569.3440545811254\n",
      "    val_loss       : -802.9136609804327\n",
      "    val_log_likelihood: 1315.7217646987406\n",
      "    val_log_marginal: 930.3337025041276\n",
      "Train Epoch: 637 [512/17352 (3%)] Loss: -957.556152\n",
      "Train Epoch: 637 [10418/17352 (60%)] Loss: -998.997820\n",
      "Train Epoch: 637 [16923/17352 (98%)] Loss: -255.357658\n",
      "    epoch          : 637\n",
      "    loss           : -755.6291380500411\n",
      "    val_loss       : -862.9450084255586\n",
      "    val_log_likelihood: 1354.6271138611885\n",
      "    val_log_marginal: 986.3455878767102\n",
      "Train Epoch: 638 [512/17352 (3%)] Loss: -1011.024780\n",
      "Train Epoch: 638 [10277/17352 (59%)] Loss: -942.415972\n",
      "Train Epoch: 638 [16887/17352 (97%)] Loss: -960.934710\n",
      "    epoch          : 638\n",
      "    loss           : -883.5981317537409\n",
      "    val_loss       : -887.0114292057075\n",
      "    val_log_likelihood: 1360.365742924026\n",
      "    val_log_marginal: 993.696765969308\n",
      "Train Epoch: 639 [512/17352 (3%)] Loss: -1028.039062\n",
      "Train Epoch: 639 [10613/17352 (61%)] Loss: -1024.559399\n",
      "Train Epoch: 639 [16957/17352 (98%)] Loss: -996.262311\n",
      "    epoch          : 639\n",
      "    loss           : -948.3063003413445\n",
      "    val_loss       : -977.8490622782126\n",
      "    val_log_likelihood: 1369.4413998678422\n",
      "    val_log_marginal: 1001.5296230433421\n",
      "Train Epoch: 640 [512/17352 (3%)] Loss: -894.430969\n",
      "Train Epoch: 640 [10273/17352 (59%)] Loss: -1017.489905\n",
      "Train Epoch: 640 [17016/17352 (98%)] Loss: -1023.930625\n",
      "    epoch          : 640\n",
      "    loss           : -898.0695754395172\n",
      "    val_loss       : -866.944861367352\n",
      "    val_log_likelihood: 1361.3403040436622\n",
      "    val_log_marginal: 989.7797798509334\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch640.pth ...\n",
      "Train Epoch: 641 [512/17352 (3%)] Loss: -1013.410461\n",
      "Train Epoch: 641 [10203/17352 (59%)] Loss: -972.659770\n",
      "Train Epoch: 641 [17049/17352 (98%)] Loss: -1039.046240\n",
      "    epoch          : 641\n",
      "    loss           : -864.6301607577276\n",
      "    val_loss       : -928.9249752729899\n",
      "    val_log_likelihood: 1362.0787047112665\n",
      "    val_log_marginal: 994.3038588488579\n",
      "Train Epoch: 642 [512/17352 (3%)] Loss: -1025.441895\n",
      "Train Epoch: 642 [10438/17352 (60%)] Loss: -1019.101299\n",
      "Train Epoch: 642 [17049/17352 (98%)] Loss: -912.562240\n",
      "    epoch          : 642\n",
      "    loss           : -831.231349501386\n",
      "    val_loss       : -824.3840599125018\n",
      "    val_log_likelihood: 1332.4434994975954\n",
      "    val_log_marginal: 946.8242205210619\n",
      "Train Epoch: 643 [512/17352 (3%)] Loss: -442.615631\n",
      "Train Epoch: 643 [10737/17352 (62%)] Loss: -909.048698\n",
      "Train Epoch: 643 [17108/17352 (99%)] Loss: -1025.973138\n",
      "    epoch          : 643\n",
      "    loss           : -897.4588318968097\n",
      "    val_loss       : -897.7200128110579\n",
      "    val_log_likelihood: 1355.2878877010312\n",
      "    val_log_marginal: 976.6541784421158\n",
      "Train Epoch: 644 [512/17352 (3%)] Loss: -411.080566\n",
      "Train Epoch: 644 [10023/17352 (58%)] Loss: -944.923958\n",
      "Train Epoch: 644 [17090/17352 (98%)] Loss: -1050.783178\n",
      "    epoch          : 644\n",
      "    loss           : -917.9963336087206\n",
      "    val_loss       : -918.730122327471\n",
      "    val_log_likelihood: 1336.5233960445157\n",
      "    val_log_marginal: 946.6329801025737\n",
      "Train Epoch: 645 [512/17352 (3%)] Loss: -949.632446\n",
      "Train Epoch: 645 [9922/17352 (57%)] Loss: -913.168888\n",
      "Train Epoch: 645 [17143/17352 (99%)] Loss: -997.934896\n",
      "    epoch          : 645\n",
      "    loss           : -865.3133107591432\n",
      "    val_loss       : -961.1837738891995\n",
      "    val_log_likelihood: 1365.0582409235037\n",
      "    val_log_marginal: 989.8396779359936\n",
      "Train Epoch: 646 [512/17352 (3%)] Loss: -1013.482727\n",
      "Train Epoch: 646 [10145/17352 (58%)] Loss: -953.804756\n",
      "Train Epoch: 646 [16958/17352 (98%)] Loss: -1036.892891\n",
      "    epoch          : 646\n",
      "    loss           : -931.1773812879372\n",
      "    val_loss       : -911.2888938746937\n",
      "    val_log_likelihood: 1364.3031313026472\n",
      "    val_log_marginal: 991.8187019096782\n",
      "Train Epoch: 647 [512/17352 (3%)] Loss: -1019.291443\n",
      "Train Epoch: 647 [9860/17352 (57%)] Loss: -956.457893\n",
      "Train Epoch: 647 [16878/17352 (97%)] Loss: -907.727936\n",
      "    epoch          : 647\n",
      "    loss           : -909.300913232873\n",
      "    val_loss       : -881.5880905151695\n",
      "    val_log_likelihood: 1363.9190136327961\n",
      "    val_log_marginal: 990.475971350958\n",
      "Train Epoch: 648 [512/17352 (3%)] Loss: -1014.967041\n",
      "Train Epoch: 648 [10416/17352 (60%)] Loss: -308.624162\n",
      "Train Epoch: 648 [16958/17352 (98%)] Loss: -989.519245\n",
      "    epoch          : 648\n",
      "    loss           : -849.4343978259659\n",
      "    val_loss       : -859.0640736757407\n",
      "    val_log_likelihood: 1349.1305219638616\n",
      "    val_log_marginal: 971.2072012115636\n",
      "Train Epoch: 649 [512/17352 (3%)] Loss: -990.265076\n",
      "Train Epoch: 649 [10109/17352 (58%)] Loss: -889.808941\n",
      "Train Epoch: 649 [17153/17352 (99%)] Loss: -1092.055437\n",
      "    epoch          : 649\n",
      "    loss           : -880.1777578834534\n",
      "    val_loss       : -906.2891773571811\n",
      "    val_log_likelihood: 1346.809238050587\n",
      "    val_log_marginal: 967.6423541664775\n",
      "Train Epoch: 650 [512/17352 (3%)] Loss: -1002.099182\n",
      "Train Epoch: 650 [10763/17352 (62%)] Loss: -985.705660\n",
      "Train Epoch: 650 [17064/17352 (98%)] Loss: -881.362764\n",
      "    epoch          : 650\n",
      "    loss           : -780.4552436923798\n",
      "    val_loss       : -853.2744417412271\n",
      "    val_log_likelihood: 1319.5691863657082\n",
      "    val_log_marginal: 919.1839564700389\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch650.pth ...\n",
      "Train Epoch: 651 [512/17352 (3%)] Loss: -942.597412\n",
      "Train Epoch: 651 [10930/17352 (63%)] Loss: -853.085417\n",
      "Train Epoch: 651 [17064/17352 (98%)] Loss: -1033.840291\n",
      "    epoch          : 651\n",
      "    loss           : -899.6560289052622\n",
      "    val_loss       : -933.8493095852767\n",
      "    val_log_likelihood: 1364.5375340484827\n",
      "    val_log_marginal: 994.6112301502634\n",
      "Train Epoch: 652 [512/17352 (3%)] Loss: -1028.364990\n",
      "Train Epoch: 652 [10470/17352 (60%)] Loss: -912.962731\n",
      "Train Epoch: 652 [17126/17352 (99%)] Loss: -991.724905\n",
      "    epoch          : 652\n",
      "    loss           : -886.0635335368225\n",
      "    val_loss       : -893.1441768016359\n",
      "    val_log_likelihood: 1352.386517719088\n",
      "    val_log_marginal: 967.5002776510765\n",
      "Train Epoch: 653 [512/17352 (3%)] Loss: -999.997681\n",
      "Train Epoch: 653 [10076/17352 (58%)] Loss: -1019.318023\n",
      "Train Epoch: 653 [17277/17352 (100%)] Loss: -1031.810830\n",
      "    epoch          : 653\n",
      "    loss           : -902.960278823701\n",
      "    val_loss       : -899.5757382307964\n",
      "    val_log_likelihood: 1367.9513899892054\n",
      "    val_log_marginal: 998.9549154601885\n",
      "Train Epoch: 654 [512/17352 (3%)] Loss: -1026.327637\n",
      "Train Epoch: 654 [10010/17352 (58%)] Loss: -1104.769748\n",
      "Train Epoch: 654 [17108/17352 (99%)] Loss: -1051.635313\n",
      "    epoch          : 654\n",
      "    loss           : -962.9362756443646\n",
      "    val_loss       : -943.008492505904\n",
      "    val_log_likelihood: 1372.2179616963317\n",
      "    val_log_marginal: 1003.1473237727897\n",
      "Train Epoch: 655 [512/17352 (3%)] Loss: -707.350403\n",
      "Train Epoch: 655 [10347/17352 (60%)] Loss: -993.770912\n",
      "Train Epoch: 655 [17101/17352 (99%)] Loss: -966.840058\n",
      "    epoch          : 655\n",
      "    loss           : -970.6589330257771\n",
      "    val_loss       : -948.5947438084899\n",
      "    val_log_likelihood: 1378.479597155901\n",
      "    val_log_marginal: 1007.6870985580435\n",
      "Train Epoch: 656 [512/17352 (3%)] Loss: -1033.943848\n",
      "Train Epoch: 656 [10402/17352 (60%)] Loss: -1062.302057\n",
      "Train Epoch: 656 [17143/17352 (99%)] Loss: -905.889205\n",
      "    epoch          : 656\n",
      "    loss           : -954.0109892180513\n",
      "    val_loss       : -941.2627206049693\n",
      "    val_log_likelihood: 1379.0218615882573\n",
      "    val_log_marginal: 1010.2123304705165\n",
      "Train Epoch: 657 [512/17352 (3%)] Loss: -1042.344238\n",
      "Train Epoch: 657 [10238/17352 (59%)] Loss: -955.591233\n",
      "Train Epoch: 657 [16922/17352 (98%)] Loss: -863.018242\n",
      "    epoch          : 657\n",
      "    loss           : -871.4711721747226\n",
      "    val_loss       : -962.8095640831609\n",
      "    val_log_likelihood: 1374.6323988479332\n",
      "    val_log_marginal: 992.6745009036639\n",
      "Train Epoch: 658 [512/17352 (3%)] Loss: -713.321655\n",
      "Train Epoch: 658 [10281/17352 (59%)] Loss: -1016.463328\n",
      "Train Epoch: 658 [16992/17352 (98%)] Loss: -524.454799\n",
      "    epoch          : 658\n",
      "    loss           : -907.9544183057475\n",
      "    val_loss       : -910.3170192742706\n",
      "    val_log_likelihood: 1345.80265467383\n",
      "    val_log_marginal: 957.3012251673972\n",
      "Train Epoch: 659 [512/17352 (3%)] Loss: -391.501892\n",
      "Train Epoch: 659 [10644/17352 (61%)] Loss: -964.592448\n",
      "Train Epoch: 659 [16882/17352 (97%)] Loss: -980.039679\n",
      "    epoch          : 659\n",
      "    loss           : -945.1463290626945\n",
      "    val_loss       : -944.5156783627934\n",
      "    val_log_likelihood: 1381.6169333709254\n",
      "    val_log_marginal: 1011.2344650986281\n",
      "Train Epoch: 660 [512/17352 (3%)] Loss: -1035.611816\n",
      "Train Epoch: 660 [10103/17352 (58%)] Loss: -799.242619\n",
      "Train Epoch: 660 [16922/17352 (98%)] Loss: -1112.482530\n",
      "    epoch          : 660\n",
      "    loss           : -969.7086519786592\n",
      "    val_loss       : -962.105068568981\n",
      "    val_log_likelihood: 1387.3137222351268\n",
      "    val_log_marginal: 1012.77824258268\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch660.pth ...\n",
      "Train Epoch: 661 [512/17352 (3%)] Loss: -1036.738892\n",
      "Train Epoch: 661 [10662/17352 (61%)] Loss: -1122.719083\n",
      "Train Epoch: 661 [17049/17352 (98%)] Loss: -1035.897410\n",
      "    epoch          : 661\n",
      "    loss           : -951.4864556967522\n",
      "    val_loss       : -907.9741643521523\n",
      "    val_log_likelihood: 1373.8191256047412\n",
      "    val_log_marginal: 988.6568202314942\n",
      "Train Epoch: 662 [512/17352 (3%)] Loss: -1021.319336\n",
      "Train Epoch: 662 [9941/17352 (57%)] Loss: -1034.680777\n",
      "Train Epoch: 662 [16887/17352 (97%)] Loss: -940.194602\n",
      "    epoch          : 662\n",
      "    loss           : -954.8454664140864\n",
      "    val_loss       : -974.1197110501676\n",
      "    val_log_likelihood: 1375.6021856819257\n",
      "    val_log_marginal: 993.4672492620331\n",
      "Train Epoch: 663 [512/17352 (3%)] Loss: -1028.817871\n",
      "Train Epoch: 663 [10506/17352 (61%)] Loss: -801.603800\n",
      "Train Epoch: 663 [16939/17352 (98%)] Loss: -1053.451301\n",
      "    epoch          : 663\n",
      "    loss           : -953.5458723429847\n",
      "    val_loss       : -983.1243011858888\n",
      "    val_log_likelihood: 1387.809695255384\n",
      "    val_log_marginal: 1014.8243178173244\n",
      "Train Epoch: 664 [512/17352 (3%)] Loss: -1047.116211\n",
      "Train Epoch: 664 [10324/17352 (59%)] Loss: -867.020027\n",
      "Train Epoch: 664 [17044/17352 (98%)] Loss: -1061.714888\n",
      "    epoch          : 664\n",
      "    loss           : -953.9187733872285\n",
      "    val_loss       : -919.4545435841595\n",
      "    val_log_likelihood: 1374.787577287845\n",
      "    val_log_marginal: 996.8831450220137\n",
      "Train Epoch: 665 [512/17352 (3%)] Loss: -1020.889587\n",
      "Train Epoch: 665 [10658/17352 (61%)] Loss: -990.115805\n",
      "Train Epoch: 665 [16934/17352 (98%)] Loss: -771.273893\n",
      "    epoch          : 665\n",
      "    loss           : -931.4258284632489\n",
      "    val_loss       : -961.6309392997413\n",
      "    val_log_likelihood: 1365.5793590465798\n",
      "    val_log_marginal: 975.5961305771444\n",
      "Train Epoch: 666 [512/17352 (3%)] Loss: -988.422852\n",
      "Train Epoch: 666 [10273/17352 (59%)] Loss: -1018.058103\n",
      "Train Epoch: 666 [17126/17352 (99%)] Loss: -866.266157\n",
      "    epoch          : 666\n",
      "    loss           : -924.6857228434908\n",
      "    val_loss       : -935.4720642555394\n",
      "    val_log_likelihood: 1379.7698170777774\n",
      "    val_log_marginal: 978.3493699846182\n",
      "Train Epoch: 667 [512/17352 (3%)] Loss: -1005.960266\n",
      "Train Epoch: 667 [10273/17352 (59%)] Loss: -902.832031\n",
      "Train Epoch: 667 [17101/17352 (99%)] Loss: -1053.717297\n",
      "    epoch          : 667\n",
      "    loss           : -957.2158900685187\n",
      "    val_loss       : -978.5344446048887\n",
      "    val_log_likelihood: 1381.1242530787322\n",
      "    val_log_marginal: 1001.8164864193176\n",
      "Train Epoch: 668 [512/17352 (3%)] Loss: -1029.032959\n",
      "Train Epoch: 668 [10884/17352 (63%)] Loss: -666.640192\n",
      "Train Epoch: 668 [16882/17352 (97%)] Loss: -934.738997\n",
      "    epoch          : 668\n",
      "    loss           : -913.3462568577988\n",
      "    val_loss       : -894.0225716190216\n",
      "    val_log_likelihood: 1351.08564486317\n",
      "    val_log_marginal: 950.4290015279418\n",
      "Train Epoch: 669 [512/17352 (3%)] Loss: -981.472900\n",
      "Train Epoch: 669 [10380/17352 (60%)] Loss: -1024.028493\n",
      "Train Epoch: 669 [16957/17352 (98%)] Loss: -885.736244\n",
      "    epoch          : 669\n",
      "    loss           : -944.3808481179019\n",
      "    val_loss       : -987.5419607778291\n",
      "    val_log_likelihood: 1386.3340466403042\n",
      "    val_log_marginal: 1017.1679877740835\n",
      "Train Epoch: 670 [512/17352 (3%)] Loss: -1041.193359\n",
      "Train Epoch: 670 [10107/17352 (58%)] Loss: -918.395701\n",
      "Train Epoch: 670 [16939/17352 (98%)] Loss: -945.030641\n",
      "    epoch          : 670\n",
      "    loss           : -959.9611982736699\n",
      "    val_loss       : -930.3180850722929\n",
      "    val_log_likelihood: 1376.8880070389903\n",
      "    val_log_marginal: 997.2628176250793\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch670.pth ...\n",
      "Train Epoch: 671 [512/17352 (3%)] Loss: -767.718140\n",
      "Train Epoch: 671 [10368/17352 (60%)] Loss: -953.845266\n",
      "Train Epoch: 671 [17049/17352 (98%)] Loss: -1010.899667\n",
      "    epoch          : 671\n",
      "    loss           : -916.9557261866911\n",
      "    val_loss       : -909.8950975134427\n",
      "    val_log_likelihood: 1374.8439103429412\n",
      "    val_log_marginal: 984.2684752322945\n",
      "Train Epoch: 672 [512/17352 (3%)] Loss: -866.765259\n",
      "Train Epoch: 672 [9913/17352 (57%)] Loss: -1032.839098\n",
      "Train Epoch: 672 [17016/17352 (98%)] Loss: -868.375801\n",
      "    epoch          : 672\n",
      "    loss           : -890.4787095422009\n",
      "    val_loss       : -885.8675311696888\n",
      "    val_log_likelihood: 1362.5778823149346\n",
      "    val_log_marginal: 972.2984149277154\n",
      "Train Epoch: 673 [512/17352 (3%)] Loss: -989.094360\n",
      "Train Epoch: 673 [9986/17352 (58%)] Loss: -956.643541\n",
      "Train Epoch: 673 [17277/17352 (100%)] Loss: -1021.418782\n",
      "    epoch          : 673\n",
      "    loss           : -972.6103980091478\n",
      "    val_loss       : -962.5439358120295\n",
      "    val_log_likelihood: 1388.9230417410681\n",
      "    val_log_marginal: 991.2692613388831\n",
      "Train Epoch: 674 [512/17352 (3%)] Loss: -1016.143188\n",
      "Train Epoch: 674 [10794/17352 (62%)] Loss: -809.716003\n",
      "Train Epoch: 674 [17044/17352 (98%)] Loss: -967.604380\n",
      "    epoch          : 674\n",
      "    loss           : -1001.8085109354599\n",
      "    val_loss       : -970.6364488671246\n",
      "    val_log_likelihood: 1394.3844360515031\n",
      "    val_log_marginal: 1018.106493416831\n",
      "Train Epoch: 675 [512/17352 (3%)] Loss: -868.427429\n",
      "Train Epoch: 675 [10072/17352 (58%)] Loss: -977.667005\n",
      "Train Epoch: 675 [16883/17352 (97%)] Loss: -1041.573153\n",
      "    epoch          : 675\n",
      "    loss           : -1004.6349363908666\n",
      "    val_loss       : -983.5473467978081\n",
      "    val_log_likelihood: 1402.8979266316478\n",
      "    val_log_marginal: 1031.8685563240883\n",
      "Train Epoch: 676 [512/17352 (3%)] Loss: -1059.499023\n",
      "Train Epoch: 676 [10273/17352 (59%)] Loss: -843.327257\n",
      "Train Epoch: 676 [17049/17352 (98%)] Loss: -997.418448\n",
      "    epoch          : 676\n",
      "    loss           : -998.4368193078427\n",
      "    val_loss       : -1011.0152590866875\n",
      "    val_log_likelihood: 1403.7508641119719\n",
      "    val_log_marginal: 1031.8649804616261\n",
      "Train Epoch: 677 [512/17352 (3%)] Loss: -1053.953613\n",
      "Train Epoch: 677 [10450/17352 (60%)] Loss: -983.223958\n",
      "Train Epoch: 677 [16934/17352 (98%)] Loss: -978.163462\n",
      "    epoch          : 677\n",
      "    loss           : -943.8414741432687\n",
      "    val_loss       : -1011.2555534160382\n",
      "    val_log_likelihood: 1398.2716376081355\n",
      "    val_log_marginal: 1022.4097691950317\n",
      "Train Epoch: 678 [512/17352 (3%)] Loss: -1045.154785\n",
      "Train Epoch: 678 [9447/17352 (54%)] Loss: -1008.355009\n",
      "Train Epoch: 678 [16957/17352 (98%)] Loss: -883.621337\n",
      "    epoch          : 678\n",
      "    loss           : -936.49400176926\n",
      "    val_loss       : -957.1430860044246\n",
      "    val_log_likelihood: 1391.1828593991293\n",
      "    val_log_marginal: 1013.4536105726518\n",
      "Train Epoch: 679 [512/17352 (3%)] Loss: -788.935303\n",
      "Train Epoch: 679 [10296/17352 (59%)] Loss: -1004.929688\n",
      "Train Epoch: 679 [16934/17352 (98%)] Loss: -1092.546308\n",
      "    epoch          : 679\n",
      "    loss           : -943.0746519860203\n",
      "    val_loss       : -992.209310793611\n",
      "    val_log_likelihood: 1402.7253810763764\n",
      "    val_log_marginal: 1019.9073878793002\n",
      "Train Epoch: 680 [512/17352 (3%)] Loss: -1042.871948\n",
      "Train Epoch: 680 [10317/17352 (59%)] Loss: -1046.255116\n",
      "Train Epoch: 680 [17106/17352 (99%)] Loss: -966.061603\n",
      "    epoch          : 680\n",
      "    loss           : -982.6491806007778\n",
      "    val_loss       : -993.4317156550547\n",
      "    val_log_likelihood: 1405.8996304618254\n",
      "    val_log_marginal: 1031.5635810558053\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch680.pth ...\n",
      "Train Epoch: 681 [512/17352 (3%)] Loss: -1054.086304\n",
      "Train Epoch: 681 [10122/17352 (58%)] Loss: -983.949945\n",
      "Train Epoch: 681 [16883/17352 (97%)] Loss: -1004.716425\n",
      "    epoch          : 681\n",
      "    loss           : -961.1951538720529\n",
      "    val_loss       : -972.7237099710421\n",
      "    val_log_likelihood: 1402.4602276403466\n",
      "    val_log_marginal: 1014.9034359026971\n",
      "Train Epoch: 682 [512/17352 (3%)] Loss: -1039.366211\n",
      "Train Epoch: 682 [10167/17352 (59%)] Loss: -1031.960315\n",
      "Train Epoch: 682 [17335/17352 (100%)] Loss: -974.099229\n",
      "    epoch          : 682\n",
      "    loss           : -992.6199834963779\n",
      "    val_loss       : -972.6223329893077\n",
      "    val_log_likelihood: 1409.560353455173\n",
      "    val_log_marginal: 997.2781247969715\n",
      "Train Epoch: 683 [512/17352 (3%)] Loss: -632.362488\n",
      "Train Epoch: 683 [9967/17352 (57%)] Loss: -1017.245265\n",
      "Train Epoch: 683 [17153/17352 (99%)] Loss: -702.969543\n",
      "    epoch          : 683\n",
      "    loss           : -890.3254537775885\n",
      "    val_loss       : -907.7269243044384\n",
      "    val_log_likelihood: 1393.4944608059382\n",
      "    val_log_marginal: 950.6051194470233\n",
      "Train Epoch: 684 [512/17352 (3%)] Loss: -973.600281\n",
      "Train Epoch: 684 [10039/17352 (58%)] Loss: -824.260549\n",
      "Train Epoch: 684 [16882/17352 (97%)] Loss: -990.757996\n",
      "    epoch          : 684\n",
      "    loss           : -938.1972848132725\n",
      "    val_loss       : -987.395087842824\n",
      "    val_log_likelihood: 1403.14227427789\n",
      "    val_log_marginal: 1007.9216089353679\n",
      "Train Epoch: 685 [512/17352 (3%)] Loss: -1024.924194\n",
      "Train Epoch: 685 [10734/17352 (62%)] Loss: -971.503439\n",
      "Train Epoch: 685 [16992/17352 (98%)] Loss: -1077.391377\n",
      "    epoch          : 685\n",
      "    loss           : -956.1273820842254\n",
      "    val_loss       : -918.4046132497905\n",
      "    val_log_likelihood: 1405.1087936206304\n",
      "    val_log_marginal: 1021.9243473977787\n",
      "Train Epoch: 686 [512/17352 (3%)] Loss: -1056.544067\n",
      "Train Epoch: 686 [10401/17352 (60%)] Loss: -1121.627604\n",
      "Train Epoch: 686 [16922/17352 (98%)] Loss: -909.091146\n",
      "    epoch          : 686\n",
      "    loss           : -939.0215433876232\n",
      "    val_loss       : -906.5815179483026\n",
      "    val_log_likelihood: 1396.4656527481548\n",
      "    val_log_marginal: 996.1352053120673\n",
      "Train Epoch: 687 [512/17352 (3%)] Loss: -1014.609558\n",
      "Train Epoch: 687 [10882/17352 (63%)] Loss: -1026.499674\n",
      "Train Epoch: 687 [17263/17352 (99%)] Loss: -1061.818854\n",
      "    epoch          : 687\n",
      "    loss           : -977.2797157771286\n",
      "    val_loss       : -956.511192663357\n",
      "    val_log_likelihood: 1390.9073981156382\n",
      "    val_log_marginal: 987.2142749566488\n",
      "Train Epoch: 688 [512/17352 (3%)] Loss: -1021.996216\n",
      "Train Epoch: 688 [9785/17352 (56%)] Loss: -1057.459014\n",
      "Train Epoch: 688 [17044/17352 (98%)] Loss: -1091.715359\n",
      "    epoch          : 688\n",
      "    loss           : -980.1521393946559\n",
      "    val_loss       : -943.2134985538613\n",
      "    val_log_likelihood: 1409.648805725047\n",
      "    val_log_marginal: 1013.494505157667\n",
      "Train Epoch: 689 [512/17352 (3%)] Loss: -900.494385\n",
      "Train Epoch: 689 [9886/17352 (57%)] Loss: -1098.010705\n",
      "Train Epoch: 689 [17153/17352 (99%)] Loss: -1000.088170\n",
      "    epoch          : 689\n",
      "    loss           : -988.552367149767\n",
      "    val_loss       : -964.5181009575167\n",
      "    val_log_likelihood: 1415.1489926497145\n",
      "    val_log_marginal: 1030.9758813719961\n",
      "Train Epoch: 690 [512/17352 (3%)] Loss: -1056.255615\n",
      "Train Epoch: 690 [10365/17352 (60%)] Loss: -1122.583442\n",
      "Train Epoch: 690 [16882/17352 (97%)] Loss: -917.213442\n",
      "    epoch          : 690\n",
      "    loss           : -999.2606223301971\n",
      "    val_loss       : -1001.1393298571003\n",
      "    val_log_likelihood: 1418.4942815478948\n",
      "    val_log_marginal: 1032.133600584272\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch690.pth ...\n",
      "Train Epoch: 691 [512/17352 (3%)] Loss: -1056.848877\n",
      "Train Epoch: 691 [10804/17352 (62%)] Loss: -790.859639\n",
      "Train Epoch: 691 [17049/17352 (98%)] Loss: -970.250798\n",
      "    epoch          : 691\n",
      "    loss           : -1024.569128064188\n",
      "    val_loss       : -1008.7951791964033\n",
      "    val_log_likelihood: 1414.8435264470636\n",
      "    val_log_marginal: 1023.1340728337092\n",
      "Train Epoch: 692 [512/17352 (3%)] Loss: -1049.467041\n",
      "Train Epoch: 692 [10335/17352 (60%)] Loss: -934.837022\n",
      "Train Epoch: 692 [17253/17352 (99%)] Loss: -1062.161988\n",
      "    epoch          : 692\n",
      "    loss           : -1024.2674662533275\n",
      "    val_loss       : -950.5195920139165\n",
      "    val_log_likelihood: 1403.2819311770877\n",
      "    val_log_marginal: 987.1442762108345\n",
      "Train Epoch: 693 [512/17352 (3%)] Loss: -1021.524658\n",
      "Train Epoch: 693 [10528/17352 (61%)] Loss: -914.758333\n",
      "Train Epoch: 693 [16992/17352 (98%)] Loss: -1082.824873\n",
      "    epoch          : 693\n",
      "    loss           : -998.6890247531207\n",
      "    val_loss       : -991.8145748070808\n",
      "    val_log_likelihood: 1421.8451084736748\n",
      "    val_log_marginal: 1028.3705559553157\n",
      "Train Epoch: 694 [512/17352 (3%)] Loss: -1056.801514\n",
      "Train Epoch: 694 [10416/17352 (60%)] Loss: -1085.271519\n",
      "Train Epoch: 694 [17335/17352 (100%)] Loss: -885.041957\n",
      "    epoch          : 694\n",
      "    loss           : -995.9804683887435\n",
      "    val_loss       : -942.8709265490555\n",
      "    val_log_likelihood: 1405.7486119398802\n",
      "    val_log_marginal: 998.2121243658597\n",
      "Train Epoch: 695 [512/17352 (3%)] Loss: -1034.484619\n",
      "Train Epoch: 695 [10587/17352 (61%)] Loss: -1101.377136\n",
      "Train Epoch: 695 [16923/17352 (98%)] Loss: -1093.676352\n",
      "    epoch          : 695\n",
      "    loss           : -1010.2235969811145\n",
      "    val_loss       : -1007.8546290520342\n",
      "    val_log_likelihood: 1428.8237965156338\n",
      "    val_log_marginal: 1046.9033033047658\n",
      "Train Epoch: 696 [512/17352 (3%)] Loss: -1073.144775\n",
      "Train Epoch: 696 [10522/17352 (61%)] Loss: -911.484323\n",
      "Train Epoch: 696 [17016/17352 (98%)] Loss: -951.179723\n",
      "    epoch          : 696\n",
      "    loss           : -921.7128980252444\n",
      "    val_loss       : -851.4354446586497\n",
      "    val_log_likelihood: 1329.2291725585158\n",
      "    val_log_marginal: 893.616413189589\n",
      "Train Epoch: 697 [512/17352 (3%)] Loss: -900.339233\n",
      "Train Epoch: 697 [10321/17352 (59%)] Loss: -860.918414\n",
      "Train Epoch: 697 [16958/17352 (98%)] Loss: -1040.201888\n",
      "    epoch          : 697\n",
      "    loss           : -948.6017680113391\n",
      "    val_loss       : -1005.1318090319816\n",
      "    val_log_likelihood: 1417.0073171685494\n",
      "    val_log_marginal: 1023.6516499668197\n",
      "Train Epoch: 698 [512/17352 (3%)] Loss: -1057.322632\n",
      "Train Epoch: 698 [10518/17352 (61%)] Loss: -1095.051872\n",
      "Train Epoch: 698 [16922/17352 (98%)] Loss: -996.073153\n",
      "    epoch          : 698\n",
      "    loss           : -1018.8808438839872\n",
      "    val_loss       : -1029.1369042257436\n",
      "    val_log_likelihood: 1430.3395895378487\n",
      "    val_log_marginal: 1048.6439233967396\n",
      "Train Epoch: 699 [512/17352 (3%)] Loss: -1079.902710\n",
      "Train Epoch: 699 [10594/17352 (61%)] Loss: -929.990676\n",
      "Train Epoch: 699 [17049/17352 (98%)] Loss: -1070.670332\n",
      "    epoch          : 699\n",
      "    loss           : -922.3527211949739\n",
      "    val_loss       : -958.0578516810754\n",
      "    val_log_likelihood: 1407.1029726414997\n",
      "    val_log_marginal: 982.4091473206948\n",
      "Train Epoch: 700 [512/17352 (3%)] Loss: -1014.703247\n",
      "Train Epoch: 700 [10296/17352 (59%)] Loss: -984.486111\n",
      "Train Epoch: 700 [17335/17352 (100%)] Loss: -1049.256649\n",
      "    epoch          : 700\n",
      "    loss           : -966.7264325532884\n",
      "    val_loss       : -827.7649633477862\n",
      "    val_log_likelihood: 1417.167228313419\n",
      "    val_log_marginal: 932.5976227322747\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch700.pth ...\n",
      "Train Epoch: 701 [512/17352 (3%)] Loss: -973.804871\n",
      "Train Epoch: 701 [10154/17352 (59%)] Loss: -1005.847656\n",
      "Train Epoch: 701 [16958/17352 (98%)] Loss: -1067.917354\n",
      "    epoch          : 701\n",
      "    loss           : -979.1555393530402\n",
      "    val_loss       : -957.2411702959981\n",
      "    val_log_likelihood: 1426.081968783828\n",
      "    val_log_marginal: 1011.9174951191078\n",
      "Train Epoch: 702 [512/17352 (3%)] Loss: -1052.687256\n",
      "Train Epoch: 702 [9817/17352 (57%)] Loss: -883.674365\n",
      "Train Epoch: 702 [16934/17352 (98%)] Loss: -1079.516818\n",
      "    epoch          : 702\n",
      "    loss           : -1010.5060376384474\n",
      "    val_loss       : -1034.625854343322\n",
      "    val_log_likelihood: 1433.926478201488\n",
      "    val_log_marginal: 1041.8940010932063\n",
      "Train Epoch: 703 [512/17352 (3%)] Loss: -1068.036621\n",
      "Train Epoch: 703 [10214/17352 (59%)] Loss: -1106.329395\n",
      "Train Epoch: 703 [17335/17352 (100%)] Loss: -1067.359505\n",
      "    epoch          : 703\n",
      "    loss           : -1020.4531967964892\n",
      "    val_loss       : -1018.6250665441265\n",
      "    val_log_likelihood: 1434.883501749839\n",
      "    val_log_marginal: 1030.9257578671072\n",
      "Train Epoch: 704 [512/17352 (3%)] Loss: -933.762329\n",
      "Train Epoch: 704 [10472/17352 (60%)] Loss: -926.876031\n",
      "Train Epoch: 704 [17101/17352 (99%)] Loss: -1031.631981\n",
      "    epoch          : 704\n",
      "    loss           : -891.1656693182291\n",
      "    val_loss       : -637.1956965109331\n",
      "    val_log_likelihood: 1415.5728956622845\n",
      "    val_log_marginal: 682.4765164642168\n",
      "Train Epoch: 705 [512/17352 (3%)] Loss: -602.042664\n",
      "Train Epoch: 705 [10657/17352 (61%)] Loss: -1071.017563\n",
      "Train Epoch: 705 [17108/17352 (99%)] Loss: -1082.985306\n",
      "    epoch          : 705\n",
      "    loss           : -939.7974677550551\n",
      "    val_loss       : -872.5531781522092\n",
      "    val_log_likelihood: 1410.6425608085058\n",
      "    val_log_marginal: 1006.2225970441946\n",
      "Train Epoch: 706 [512/17352 (3%)] Loss: -1047.589844\n",
      "Train Epoch: 706 [9940/17352 (57%)] Loss: -1101.145479\n",
      "Train Epoch: 706 [16872/17352 (97%)] Loss: -1084.441783\n",
      "    epoch          : 706\n",
      "    loss           : -911.380091699311\n",
      "    val_loss       : -997.2684954803204\n",
      "    val_log_likelihood: 1418.3796834203379\n",
      "    val_log_marginal: 1023.438687809885\n",
      "Train Epoch: 707 [512/17352 (3%)] Loss: -1051.657959\n",
      "Train Epoch: 707 [10189/17352 (59%)] Loss: -1002.327100\n",
      "Train Epoch: 707 [16934/17352 (98%)] Loss: -767.441825\n",
      "    epoch          : 707\n",
      "    loss           : -1021.8674243812223\n",
      "    val_loss       : -996.8434918921497\n",
      "    val_log_likelihood: 1439.6323773113772\n",
      "    val_log_marginal: 1050.6580523566654\n",
      "Train Epoch: 708 [512/17352 (3%)] Loss: -1075.367310\n",
      "Train Epoch: 708 [10019/17352 (58%)] Loss: -1078.448560\n",
      "Train Epoch: 708 [16872/17352 (97%)] Loss: -928.508224\n",
      "    epoch          : 708\n",
      "    loss           : -966.887413285865\n",
      "    val_loss       : -1007.3741548514828\n",
      "    val_log_likelihood: 1441.2324711660483\n",
      "    val_log_marginal: 1037.1182852716836\n",
      "Train Epoch: 709 [512/17352 (3%)] Loss: -1063.897705\n",
      "Train Epoch: 709 [10227/17352 (59%)] Loss: -1071.035883\n",
      "Train Epoch: 709 [17133/17352 (99%)] Loss: -1090.678750\n",
      "    epoch          : 709\n",
      "    loss           : -764.7567131535494\n",
      "    val_loss       : -911.0935367378509\n",
      "    val_log_likelihood: 1400.607542835922\n",
      "    val_log_marginal: 980.7217359099366\n",
      "Train Epoch: 710 [512/17352 (3%)] Loss: -994.132446\n",
      "Train Epoch: 710 [10580/17352 (61%)] Loss: -1129.686632\n",
      "Train Epoch: 710 [16878/17352 (97%)] Loss: -1109.242131\n",
      "    epoch          : 710\n",
      "    loss           : -1009.1030616203728\n",
      "    val_loss       : -952.7869162384576\n",
      "    val_log_likelihood: 1434.7545678085503\n",
      "    val_log_marginal: 1042.446867381517\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch710.pth ...\n",
      "Train Epoch: 711 [512/17352 (3%)] Loss: -1068.204834\n",
      "Train Epoch: 711 [10223/17352 (59%)] Loss: -1059.159389\n",
      "Train Epoch: 711 [17126/17352 (99%)] Loss: -901.912380\n",
      "    epoch          : 711\n",
      "    loss           : -988.7494391131065\n",
      "    val_loss       : -1029.5299488892545\n",
      "    val_log_likelihood: 1439.3508668006486\n",
      "    val_log_marginal: 1048.4908156946478\n",
      "Train Epoch: 712 [512/17352 (3%)] Loss: -1074.847900\n",
      "Train Epoch: 712 [10080/17352 (58%)] Loss: -1122.372713\n",
      "Train Epoch: 712 [16922/17352 (98%)] Loss: -713.952649\n",
      "    epoch          : 712\n",
      "    loss           : -1004.0585242837183\n",
      "    val_loss       : -1009.5545590917616\n",
      "    val_log_likelihood: 1434.7463312760535\n",
      "    val_log_marginal: 1043.5001349460338\n",
      "Train Epoch: 713 [512/17352 (3%)] Loss: -1076.111084\n",
      "Train Epoch: 713 [10247/17352 (59%)] Loss: -1040.281678\n",
      "Train Epoch: 713 [17090/17352 (98%)] Loss: -923.752110\n",
      "    epoch          : 713\n",
      "    loss           : -15.623372362608189\n",
      "    val_loss       : -646.7064440635153\n",
      "    val_log_likelihood: 1366.1851414966497\n",
      "    val_log_marginal: 931.8584948717078\n",
      "Train Epoch: 714 [512/17352 (3%)] Loss: -962.061401\n",
      "Train Epoch: 714 [10013/17352 (58%)] Loss: -1022.186427\n",
      "Train Epoch: 714 [17153/17352 (99%)] Loss: -945.296053\n",
      "    epoch          : 714\n",
      "    loss           : -713.0460299048046\n",
      "    val_loss       : -925.5873332471206\n",
      "    val_log_likelihood: 1387.7668756954743\n",
      "    val_log_marginal: 959.890445280726\n",
      "Train Epoch: 715 [512/17352 (3%)] Loss: -989.496643\n",
      "Train Epoch: 715 [10312/17352 (59%)] Loss: -976.198177\n",
      "Train Epoch: 715 [16922/17352 (98%)] Loss: -1091.074702\n",
      "    epoch          : 715\n",
      "    loss           : -1002.3651256626459\n",
      "    val_loss       : -958.2591827007624\n",
      "    val_log_likelihood: 1426.6793736487186\n",
      "    val_log_marginal: 1043.34734224378\n",
      "Train Epoch: 716 [512/17352 (3%)] Loss: -1076.586182\n",
      "Train Epoch: 716 [10236/17352 (59%)] Loss: -1023.601906\n",
      "Train Epoch: 716 [16934/17352 (98%)] Loss: -1163.842351\n",
      "    epoch          : 716\n",
      "    loss           : -996.8848206215315\n",
      "    val_loss       : -962.5822112080359\n",
      "    val_log_likelihood: 1433.4742103717583\n",
      "    val_log_marginal: 1051.2345133658712\n",
      "Train Epoch: 717 [512/17352 (3%)] Loss: -1076.124268\n",
      "Train Epoch: 717 [10239/17352 (59%)] Loss: 548.881225\n",
      "Train Epoch: 717 [16878/17352 (97%)] Loss: -1127.564024\n",
      "    epoch          : 717\n",
      "    loss           : -987.5482247556668\n",
      "    val_loss       : -994.3510069146926\n",
      "    val_log_likelihood: 1438.1461060896272\n",
      "    val_log_marginal: 1059.4593404173738\n",
      "Train Epoch: 718 [512/17352 (3%)] Loss: -596.767639\n",
      "Train Epoch: 718 [10158/17352 (59%)] Loss: -929.232282\n",
      "Train Epoch: 718 [16922/17352 (98%)] Loss: -1115.498730\n",
      "    epoch          : 718\n",
      "    loss           : -932.8962199512505\n",
      "    val_loss       : -948.2400023363604\n",
      "    val_log_likelihood: 1423.2100280809477\n",
      "    val_log_marginal: 1039.5090871860737\n",
      "Train Epoch: 719 [512/17352 (3%)] Loss: -1070.383057\n",
      "Train Epoch: 719 [10481/17352 (60%)] Loss: -447.816964\n",
      "Train Epoch: 719 [17263/17352 (99%)] Loss: -1057.434432\n",
      "    epoch          : 719\n",
      "    loss           : -885.563051823805\n",
      "    val_loss       : -909.617593186621\n",
      "    val_log_likelihood: 1417.9789181441172\n",
      "    val_log_marginal: 1011.2256309182274\n",
      "Train Epoch: 720 [512/17352 (3%)] Loss: 934.129395\n",
      "Train Epoch: 720 [10657/17352 (61%)] Loss: -831.143462\n",
      "Train Epoch: 720 [17101/17352 (99%)] Loss: -996.069626\n",
      "    epoch          : 720\n",
      "    loss           : -884.9773975507046\n",
      "    val_loss       : -937.0476378684644\n",
      "    val_log_likelihood: 1421.180969446008\n",
      "    val_log_marginal: 982.563247287871\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch720.pth ...\n",
      "Train Epoch: 721 [512/17352 (3%)] Loss: -998.121704\n",
      "Train Epoch: 721 [10523/17352 (61%)] Loss: -924.849001\n",
      "Train Epoch: 721 [17064/17352 (98%)] Loss: -492.229531\n",
      "    epoch          : 721\n",
      "    loss           : -790.5055454632624\n",
      "    val_loss       : -677.9549540214525\n",
      "    val_log_likelihood: 1361.358155108859\n",
      "    val_log_marginal: 738.2627754919044\n",
      "Train Epoch: 722 [512/17352 (3%)] Loss: 850.604797\n",
      "Train Epoch: 722 [10255/17352 (59%)] Loss: -719.410156\n",
      "Train Epoch: 722 [17253/17352 (99%)] Loss: -769.144976\n",
      "    epoch          : 722\n",
      "    loss           : -712.3087336252631\n",
      "    val_loss       : -500.6589629223366\n",
      "    val_log_likelihood: 1370.576547125182\n",
      "    val_log_marginal: 549.2978015349148\n",
      "Train Epoch: 723 [512/17352 (3%)] Loss: -603.648010\n",
      "Train Epoch: 723 [10383/17352 (60%)] Loss: -902.322746\n",
      "Train Epoch: 723 [16922/17352 (98%)] Loss: -1004.331301\n",
      "    epoch          : 723\n",
      "    loss           : -789.2791664888432\n",
      "    val_loss       : -861.8267150145224\n",
      "    val_log_likelihood: 1392.2956660234827\n",
      "    val_log_marginal: 911.4544966199621\n",
      "Train Epoch: 724 [512/17352 (3%)] Loss: -971.481567\n",
      "Train Epoch: 724 [10388/17352 (60%)] Loss: -725.051744\n",
      "Train Epoch: 724 [17106/17352 (99%)] Loss: -788.610496\n",
      "    epoch          : 724\n",
      "    loss           : -851.6563574042935\n",
      "    val_loss       : -689.0760046632114\n",
      "    val_log_likelihood: 1414.7224761426573\n",
      "    val_log_marginal: 735.6519520666815\n",
      "Train Epoch: 725 [512/17352 (3%)] Loss: -790.553223\n",
      "Train Epoch: 725 [9818/17352 (57%)] Loss: -675.187209\n",
      "Train Epoch: 725 [17277/17352 (100%)] Loss: -842.160759\n",
      "    epoch          : 725\n",
      "    loss           : -656.9075234937551\n",
      "    val_loss       : -89.39330316030924\n",
      "    val_log_likelihood: 1331.0322977236135\n",
      "    val_log_marginal: 127.44507331764811\n",
      "Train Epoch: 726 [512/17352 (3%)] Loss: -182.771423\n",
      "Train Epoch: 726 [10089/17352 (58%)] Loss: -832.905738\n",
      "Train Epoch: 726 [17016/17352 (98%)] Loss: -1027.703204\n",
      "    epoch          : 726\n",
      "    loss           : -773.3180622541512\n",
      "    val_loss       : -929.2985885067606\n",
      "    val_log_likelihood: 1399.033627998592\n",
      "    val_log_marginal: 957.8068019519274\n",
      "Train Epoch: 727 [512/17352 (3%)] Loss: -988.378113\n",
      "Train Epoch: 727 [10241/17352 (59%)] Loss: -533.453671\n",
      "Train Epoch: 727 [16958/17352 (98%)] Loss: -1021.921464\n",
      "    epoch          : 727\n",
      "    loss           : -910.3302443861195\n",
      "    val_loss       : -1011.2346959716816\n",
      "    val_log_likelihood: 1419.1706728645252\n",
      "    val_log_marginal: 1038.5813934666944\n",
      "Train Epoch: 728 [512/17352 (3%)] Loss: -1068.960571\n",
      "Train Epoch: 728 [10457/17352 (60%)] Loss: -1079.497574\n",
      "Train Epoch: 728 [17044/17352 (98%)] Loss: -1084.506250\n",
      "    epoch          : 728\n",
      "    loss           : -976.0856947160743\n",
      "    val_loss       : -959.1346107175143\n",
      "    val_log_likelihood: 1425.9542671587674\n",
      "    val_log_marginal: 1046.6698034918245\n",
      "Train Epoch: 729 [512/17352 (3%)] Loss: -1076.062622\n",
      "Train Epoch: 729 [9988/17352 (58%)] Loss: -1141.135200\n",
      "Train Epoch: 729 [17277/17352 (100%)] Loss: -1084.296019\n",
      "    epoch          : 729\n",
      "    loss           : -1014.0138617715512\n",
      "    val_loss       : -993.6280330876209\n",
      "    val_log_likelihood: 1432.9527613235616\n",
      "    val_log_marginal: 1055.6769915581706\n",
      "Train Epoch: 730 [512/17352 (3%)] Loss: -1084.160400\n",
      "Train Epoch: 730 [10535/17352 (61%)] Loss: -1081.962891\n",
      "Train Epoch: 730 [17253/17352 (99%)] Loss: -980.711194\n",
      "    epoch          : 730\n",
      "    loss           : -908.4811200699709\n",
      "    val_loss       : -914.1035774822886\n",
      "    val_log_likelihood: 1413.816690463405\n",
      "    val_log_marginal: 1021.562264279797\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch730.pth ...\n",
      "Train Epoch: 731 [512/17352 (3%)] Loss: -1053.284668\n",
      "Train Epoch: 731 [10529/17352 (61%)] Loss: -105.574871\n",
      "Train Epoch: 731 [17124/17352 (99%)] Loss: -18.360149\n",
      "    epoch          : 731\n",
      "    loss           : -216.64508110799997\n",
      "    val_loss       : -437.5015741396983\n",
      "    val_log_likelihood: 1162.2471496381588\n",
      "    val_log_marginal: 564.4902744730097\n",
      "Train Epoch: 732 [512/17352 (3%)] Loss: 234.281738\n",
      "Train Epoch: 732 [10218/17352 (59%)] Loss: -789.624657\n",
      "Train Epoch: 732 [16882/17352 (97%)] Loss: -1057.538750\n",
      "    epoch          : 732\n",
      "    loss           : -753.2565054229169\n",
      "    val_loss       : -922.3744038724423\n",
      "    val_log_likelihood: 1374.427753465925\n",
      "    val_log_marginal: 984.3403002706128\n",
      "Train Epoch: 733 [512/17352 (3%)] Loss: -1022.489807\n",
      "Train Epoch: 733 [10615/17352 (61%)] Loss: -1052.066235\n",
      "Train Epoch: 733 [16882/17352 (97%)] Loss: -1003.887336\n",
      "    epoch          : 733\n",
      "    loss           : -886.4244938496914\n",
      "    val_loss       : -959.9738662145804\n",
      "    val_log_likelihood: 1403.4185804578124\n",
      "    val_log_marginal: 1027.9580623120312\n",
      "Train Epoch: 734 [512/17352 (3%)] Loss: -1059.610107\n",
      "Train Epoch: 734 [10091/17352 (58%)] Loss: -902.872984\n",
      "Train Epoch: 734 [16872/17352 (97%)] Loss: -1060.913160\n",
      "    epoch          : 734\n",
      "    loss           : -979.9523082062681\n",
      "    val_loss       : -979.854048949852\n",
      "    val_log_likelihood: 1411.4591038431145\n",
      "    val_log_marginal: 1040.234579765159\n",
      "Train Epoch: 735 [512/17352 (3%)] Loss: -643.607483\n",
      "Train Epoch: 735 [10537/17352 (61%)] Loss: -889.724113\n",
      "Train Epoch: 735 [17016/17352 (98%)] Loss: -662.705763\n",
      "    epoch          : 735\n",
      "    loss           : -877.4629733469002\n",
      "    val_loss       : -942.7463732443813\n",
      "    val_log_likelihood: 1403.7960125409834\n",
      "    val_log_marginal: 984.2471562775028\n",
      "Train Epoch: 736 [512/17352 (3%)] Loss: -1013.946350\n",
      "Train Epoch: 736 [10365/17352 (60%)] Loss: -973.527902\n",
      "Train Epoch: 736 [17124/17352 (99%)] Loss: -993.854514\n",
      "    epoch          : 736\n",
      "    loss           : -965.9215282441176\n",
      "    val_loss       : -964.9615502495348\n",
      "    val_log_likelihood: 1413.8855376666095\n",
      "    val_log_marginal: 1002.0331889746567\n",
      "Train Epoch: 737 [512/17352 (3%)] Loss: -1030.594116\n",
      "Train Epoch: 737 [10143/17352 (58%)] Loss: -1085.010937\n",
      "Train Epoch: 737 [17126/17352 (99%)] Loss: -1067.569401\n",
      "    epoch          : 737\n",
      "    loss           : -1006.3685541900535\n",
      "    val_loss       : -1019.0857666944179\n",
      "    val_log_likelihood: 1425.0326013274869\n",
      "    val_log_marginal: 1032.0532384928722\n",
      "Train Epoch: 738 [512/17352 (3%)] Loss: -1068.025757\n",
      "Train Epoch: 738 [10074/17352 (58%)] Loss: -1118.103277\n",
      "Train Epoch: 738 [17263/17352 (99%)] Loss: -964.826746\n",
      "    epoch          : 738\n",
      "    loss           : -1001.1231889445809\n",
      "    val_loss       : -934.759016501121\n",
      "    val_log_likelihood: 1426.8357830107082\n",
      "    val_log_marginal: 1034.498963621761\n",
      "Train Epoch: 739 [512/17352 (3%)] Loss: -1064.132935\n",
      "Train Epoch: 739 [10342/17352 (60%)] Loss: -1030.100414\n",
      "Train Epoch: 739 [16872/17352 (97%)] Loss: -1033.168174\n",
      "    epoch          : 739\n",
      "    loss           : -1023.9289171240383\n",
      "    val_loss       : -1038.0935629957062\n",
      "    val_log_likelihood: 1434.4436887006643\n",
      "    val_log_marginal: 1058.4662447323924\n",
      "Train Epoch: 740 [512/17352 (3%)] Loss: -1087.670410\n",
      "Train Epoch: 740 [10597/17352 (61%)] Loss: -998.270450\n",
      "Train Epoch: 740 [17049/17352 (98%)] Loss: -1086.094271\n",
      "    epoch          : 740\n",
      "    loss           : -1042.1502041515434\n",
      "    val_loss       : -974.649896738329\n",
      "    val_log_likelihood: 1438.1921240412612\n",
      "    val_log_marginal: 1061.254618564476\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch740.pth ...\n",
      "Train Epoch: 741 [512/17352 (3%)] Loss: -1091.738403\n",
      "Train Epoch: 741 [10835/17352 (62%)] Loss: -1101.443605\n",
      "Train Epoch: 741 [17153/17352 (99%)] Loss: -1027.692429\n",
      "    epoch          : 741\n",
      "    loss           : -1029.8087217062982\n",
      "    val_loss       : -1029.1148673706684\n",
      "    val_log_likelihood: 1436.9823039960713\n",
      "    val_log_marginal: 1055.8029911796718\n",
      "Train Epoch: 742 [512/17352 (3%)] Loss: -1085.441406\n",
      "Train Epoch: 742 [10181/17352 (59%)] Loss: -915.239583\n",
      "Train Epoch: 742 [16934/17352 (98%)] Loss: -410.343359\n",
      "    epoch          : 742\n",
      "    loss           : -960.6404301468452\n",
      "    val_loss       : -1022.1254927186519\n",
      "    val_log_likelihood: 1435.9476991232982\n",
      "    val_log_marginal: 1045.0239036577757\n",
      "Train Epoch: 743 [512/17352 (3%)] Loss: -837.496643\n",
      "Train Epoch: 743 [10420/17352 (60%)] Loss: -921.297494\n",
      "Train Epoch: 743 [16939/17352 (98%)] Loss: -624.035756\n",
      "    epoch          : 743\n",
      "    loss           : -911.441279792081\n",
      "    val_loss       : -568.2063896472104\n",
      "    val_log_likelihood: 1396.7449419563702\n",
      "    val_log_marginal: 632.1433920517343\n",
      "Train Epoch: 744 [512/17352 (3%)] Loss: -649.329041\n",
      "Train Epoch: 744 [10221/17352 (59%)] Loss: -868.436159\n",
      "Train Epoch: 744 [17277/17352 (100%)] Loss: -1029.407558\n",
      "    epoch          : 744\n",
      "    loss           : -783.6724228585417\n",
      "    val_loss       : -667.4886565445112\n",
      "    val_log_likelihood: 1352.9047348727393\n",
      "    val_log_marginal: 809.482720345572\n",
      "Train Epoch: 745 [512/17352 (3%)] Loss: -877.801636\n",
      "Train Epoch: 745 [10519/17352 (61%)] Loss: -911.994454\n",
      "Train Epoch: 745 [16878/17352 (97%)] Loss: 175.580494\n",
      "    epoch          : 745\n",
      "    loss           : -654.4678749180105\n",
      "    val_loss       : -423.3588724549312\n",
      "    val_log_likelihood: 1377.863555228918\n",
      "    val_log_marginal: 458.5210408960538\n",
      "Train Epoch: 746 [512/17352 (3%)] Loss: -342.587402\n",
      "Train Epoch: 746 [10628/17352 (61%)] Loss: -835.648674\n",
      "Train Epoch: 746 [17044/17352 (98%)] Loss: -655.493722\n",
      "    epoch          : 746\n",
      "    loss           : -778.3438533828524\n",
      "    val_loss       : -826.2495683612134\n",
      "    val_log_likelihood: 1407.0417435851666\n",
      "    val_log_marginal: 957.9031972977917\n",
      "Train Epoch: 747 [512/17352 (3%)] Loss: -973.497925\n",
      "Train Epoch: 747 [9999/17352 (58%)] Loss: -1058.609446\n",
      "Train Epoch: 747 [17263/17352 (99%)] Loss: -1099.682741\n",
      "    epoch          : 747\n",
      "    loss           : -966.2108917421332\n",
      "    val_loss       : -1009.2928055839559\n",
      "    val_log_likelihood: 1428.516078696582\n",
      "    val_log_marginal: 1031.4311809624796\n",
      "Train Epoch: 748 [512/17352 (3%)] Loss: -1063.660034\n",
      "Train Epoch: 748 [10435/17352 (60%)] Loss: -1115.760417\n",
      "Train Epoch: 748 [16922/17352 (98%)] Loss: -1089.948487\n",
      "    epoch          : 748\n",
      "    loss           : -1010.1223766472763\n",
      "    val_loss       : -1021.8747744659129\n",
      "    val_log_likelihood: 1432.5788844536378\n",
      "    val_log_marginal: 1051.6995286569102\n",
      "Train Epoch: 749 [512/17352 (3%)] Loss: -1075.676514\n",
      "Train Epoch: 749 [10645/17352 (61%)] Loss: -943.744121\n",
      "Train Epoch: 749 [17263/17352 (99%)] Loss: -1130.956341\n",
      "    epoch          : 749\n",
      "    loss           : -1024.6248041889507\n",
      "    val_loss       : -910.4046324345262\n",
      "    val_log_likelihood: 1436.8907747724677\n",
      "    val_log_marginal: 968.2682914898925\n",
      "Train Epoch: 750 [512/17352 (3%)] Loss: -859.516113\n",
      "Train Epoch: 750 [10032/17352 (58%)] Loss: -1082.162973\n",
      "Train Epoch: 750 [16958/17352 (98%)] Loss: -992.825179\n",
      "    epoch          : 750\n",
      "    loss           : -1000.4354722417751\n",
      "    val_loss       : -1031.566333161333\n",
      "    val_log_likelihood: 1438.8337499874508\n",
      "    val_log_marginal: 1056.1845575890568\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch750.pth ...\n",
      "Train Epoch: 751 [512/17352 (3%)] Loss: -857.137329\n",
      "Train Epoch: 751 [10801/17352 (62%)] Loss: -1123.327527\n",
      "Train Epoch: 751 [17101/17352 (99%)] Loss: -982.825597\n",
      "    epoch          : 751\n",
      "    loss           : -1005.2700280868205\n",
      "    val_loss       : -1001.2138430230573\n",
      "    val_log_likelihood: 1440.440045218075\n",
      "    val_log_marginal: 1049.71816908668\n",
      "Train Epoch: 752 [512/17352 (3%)] Loss: -1077.759399\n",
      "Train Epoch: 752 [10935/17352 (63%)] Loss: -898.839015\n",
      "Train Epoch: 752 [16988/17352 (98%)] Loss: -1092.394944\n",
      "    epoch          : 752\n",
      "    loss           : -863.4082229414873\n",
      "    val_loss       : -947.3753582994116\n",
      "    val_log_likelihood: 1414.522960289452\n",
      "    val_log_marginal: 1017.3691578523244\n",
      "Train Epoch: 753 [512/17352 (3%)] Loss: -1037.266724\n",
      "Train Epoch: 753 [10209/17352 (59%)] Loss: -948.012238\n",
      "Train Epoch: 753 [16939/17352 (98%)] Loss: -940.538099\n",
      "    epoch          : 753\n",
      "    loss           : -870.6318278448108\n",
      "    val_loss       : -939.1089399200447\n",
      "    val_log_likelihood: 1384.9577402708542\n",
      "    val_log_marginal: 987.4731720373704\n",
      "Train Epoch: 754 [512/17352 (3%)] Loss: -1011.613647\n",
      "Train Epoch: 754 [10666/17352 (61%)] Loss: -873.855780\n",
      "Train Epoch: 754 [16939/17352 (98%)] Loss: -1062.235896\n",
      "    epoch          : 754\n",
      "    loss           : -970.47309778397\n",
      "    val_loss       : -983.468256963113\n",
      "    val_log_likelihood: 1435.266887145782\n",
      "    val_log_marginal: 1047.3425461653937\n",
      "Train Epoch: 755 [512/17352 (3%)] Loss: -1078.755615\n",
      "Train Epoch: 755 [10038/17352 (58%)] Loss: -1099.980330\n",
      "Train Epoch: 755 [17049/17352 (98%)] Loss: -864.955966\n",
      "    epoch          : 755\n",
      "    loss           : -847.3746805710983\n",
      "    val_loss       : -926.6843463193602\n",
      "    val_log_likelihood: 1374.6668775726764\n",
      "    val_log_marginal: 963.6609749859902\n",
      "Train Epoch: 756 [512/17352 (3%)] Loss: -991.690674\n",
      "Train Epoch: 756 [10274/17352 (59%)] Loss: -751.559690\n",
      "Train Epoch: 756 [16957/17352 (98%)] Loss: -964.646549\n",
      "    epoch          : 756\n",
      "    loss           : -521.566771759269\n",
      "    val_loss       : -819.012226027854\n",
      "    val_log_likelihood: 1325.8450432369907\n",
      "    val_log_marginal: 868.6612503703797\n",
      "Train Epoch: 757 [512/17352 (3%)] Loss: -941.053833\n",
      "Train Epoch: 757 [10437/17352 (60%)] Loss: -1027.788747\n",
      "Train Epoch: 757 [16872/17352 (97%)] Loss: -713.892253\n",
      "    epoch          : 757\n",
      "    loss           : -923.9154689167445\n",
      "    val_loss       : -980.4207113305382\n",
      "    val_log_likelihood: 1424.7858169450235\n",
      "    val_log_marginal: 1044.2359959726805\n",
      "Train Epoch: 758 [512/17352 (3%)] Loss: -1076.187378\n",
      "Train Epoch: 758 [10366/17352 (60%)] Loss: -1073.388802\n",
      "Train Epoch: 758 [16988/17352 (98%)] Loss: -1091.023259\n",
      "    epoch          : 758\n",
      "    loss           : -1006.5477694122459\n",
      "    val_loss       : -1031.0598272058412\n",
      "    val_log_likelihood: 1432.37324802044\n",
      "    val_log_marginal: 1055.540488639074\n",
      "Train Epoch: 759 [512/17352 (3%)] Loss: -1089.612793\n",
      "Train Epoch: 759 [10307/17352 (59%)] Loss: -1112.012449\n",
      "Train Epoch: 759 [17277/17352 (100%)] Loss: -1111.393084\n",
      "    epoch          : 759\n",
      "    loss           : -970.6011454527733\n",
      "    val_loss       : -962.6073849665335\n",
      "    val_log_likelihood: 1430.5782840103996\n",
      "    val_log_marginal: 1046.340416401373\n",
      "Train Epoch: 760 [512/17352 (3%)] Loss: -817.999878\n",
      "Train Epoch: 760 [10492/17352 (60%)] Loss: -1097.986458\n",
      "Train Epoch: 760 [17335/17352 (100%)] Loss: -1101.823297\n",
      "    epoch          : 760\n",
      "    loss           : -1018.2804166656249\n",
      "    val_loss       : -1027.9328756742937\n",
      "    val_log_likelihood: 1436.887617748807\n",
      "    val_log_marginal: 1045.744291735755\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch760.pth ...\n",
      "Train Epoch: 761 [512/17352 (3%)] Loss: -1080.606567\n",
      "Train Epoch: 761 [10484/17352 (60%)] Loss: 149.996240\n",
      "Train Epoch: 761 [17108/17352 (99%)] Loss: -1091.594300\n",
      "    epoch          : 761\n",
      "    loss           : -992.3166907022933\n",
      "    val_loss       : -915.9951173512856\n",
      "    val_log_likelihood: 1428.9320761985662\n",
      "    val_log_marginal: 1037.437863044277\n",
      "Train Epoch: 762 [512/17352 (3%)] Loss: -632.480530\n",
      "Train Epoch: 762 [10781/17352 (62%)] Loss: -960.063447\n",
      "Train Epoch: 762 [17153/17352 (99%)] Loss: -1091.796159\n",
      "    epoch          : 762\n",
      "    loss           : -1022.6647666893089\n",
      "    val_loss       : -971.7076130621914\n",
      "    val_log_likelihood: 1437.3560675524493\n",
      "    val_log_marginal: 1044.9493922764832\n",
      "Train Epoch: 763 [512/17352 (3%)] Loss: -835.874023\n",
      "Train Epoch: 763 [10393/17352 (60%)] Loss: -1085.349544\n",
      "Train Epoch: 763 [17133/17352 (99%)] Loss: -1174.163646\n",
      "    epoch          : 763\n",
      "    loss           : -1015.4780551260758\n",
      "    val_loss       : -1025.1601427669705\n",
      "    val_log_likelihood: 1441.2524006117594\n",
      "    val_log_marginal: 1055.941532864248\n",
      "Train Epoch: 764 [512/17352 (3%)] Loss: -1083.276367\n",
      "Train Epoch: 764 [10186/17352 (59%)] Loss: -1092.068021\n",
      "Train Epoch: 764 [17126/17352 (99%)] Loss: -1088.143697\n",
      "    epoch          : 764\n",
      "    loss           : -1009.4291812634893\n",
      "    val_loss       : -1020.970574868437\n",
      "    val_log_likelihood: 1441.1520937565206\n",
      "    val_log_marginal: 1054.353007605135\n",
      "Train Epoch: 765 [512/17352 (3%)] Loss: -1080.950684\n",
      "Train Epoch: 765 [9943/17352 (57%)] Loss: -1047.242273\n",
      "Train Epoch: 765 [16939/17352 (98%)] Loss: -1072.156721\n",
      "    epoch          : 765\n",
      "    loss           : -986.0171169132122\n",
      "    val_loss       : -994.724749229325\n",
      "    val_log_likelihood: 1432.6951177148787\n",
      "    val_log_marginal: 1035.566459981741\n",
      "Train Epoch: 766 [512/17352 (3%)] Loss: -1063.559692\n",
      "Train Epoch: 766 [10157/17352 (59%)] Loss: -934.765561\n",
      "Train Epoch: 766 [17016/17352 (98%)] Loss: -259.921559\n",
      "    epoch          : 766\n",
      "    loss           : -967.6584368052359\n",
      "    val_loss       : -990.3182970521117\n",
      "    val_log_likelihood: 1443.682804772627\n",
      "    val_log_marginal: 1059.8375152095207\n",
      "Train Epoch: 767 [512/17352 (3%)] Loss: -1084.276855\n",
      "Train Epoch: 767 [9867/17352 (57%)] Loss: -1071.405619\n",
      "Train Epoch: 767 [17153/17352 (99%)] Loss: -926.663924\n",
      "    epoch          : 767\n",
      "    loss           : -1018.9510676219357\n",
      "    val_loss       : -962.1670162027929\n",
      "    val_log_likelihood: 1445.988453384871\n",
      "    val_log_marginal: 1057.4098946422496\n",
      "Train Epoch: 768 [512/17352 (3%)] Loss: -1085.618774\n",
      "Train Epoch: 768 [10270/17352 (59%)] Loss: -731.965949\n",
      "Train Epoch: 768 [16988/17352 (98%)] Loss: -1076.331282\n",
      "    epoch          : 768\n",
      "    loss           : -968.9403271551297\n",
      "    val_loss       : -990.9096025634187\n",
      "    val_log_likelihood: 1423.3379522686416\n",
      "    val_log_marginal: 1022.8207183560294\n",
      "Train Epoch: 769 [512/17352 (3%)] Loss: -1044.588867\n",
      "Train Epoch: 769 [10592/17352 (61%)] Loss: -1113.852475\n",
      "Train Epoch: 769 [17016/17352 (98%)] Loss: -988.790179\n",
      "    epoch          : 769\n",
      "    loss           : -1015.7043399580389\n",
      "    val_loss       : -1012.3873473240662\n",
      "    val_log_likelihood: 1450.7278406138605\n",
      "    val_log_marginal: 1061.2570312799999\n",
      "Train Epoch: 770 [512/17352 (3%)] Loss: -910.442383\n",
      "Train Epoch: 770 [10647/17352 (61%)] Loss: -933.860807\n",
      "Train Epoch: 770 [17253/17352 (99%)] Loss: -1111.790292\n",
      "    epoch          : 770\n",
      "    loss           : -1024.500369939349\n",
      "    val_loss       : -1023.8739667933107\n",
      "    val_log_likelihood: 1447.889704756239\n",
      "    val_log_marginal: 1050.1705206614474\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch770.pth ...\n",
      "Train Epoch: 771 [512/17352 (3%)] Loss: -1081.228149\n",
      "Train Epoch: 771 [10368/17352 (60%)] Loss: -1128.882580\n",
      "Train Epoch: 771 [17049/17352 (98%)] Loss: -958.909940\n",
      "    epoch          : 771\n",
      "    loss           : -1007.3821374774845\n",
      "    val_loss       : -1055.3260223683894\n",
      "    val_log_likelihood: 1454.3753090605676\n",
      "    val_log_marginal: 1069.4305781381752\n",
      "Train Epoch: 772 [512/17352 (3%)] Loss: -1091.080444\n",
      "Train Epoch: 772 [9950/17352 (57%)] Loss: -1150.800999\n",
      "Train Epoch: 772 [17016/17352 (98%)] Loss: -946.821995\n",
      "    epoch          : 772\n",
      "    loss           : -1036.4575645220277\n",
      "    val_loss       : -1006.2201870922707\n",
      "    val_log_likelihood: 1458.251142598722\n",
      "    val_log_marginal: 1068.4001276762076\n",
      "Train Epoch: 773 [512/17352 (3%)] Loss: -1101.457031\n",
      "Train Epoch: 773 [10677/17352 (62%)] Loss: -1020.419040\n",
      "Train Epoch: 773 [17277/17352 (100%)] Loss: -872.075322\n",
      "    epoch          : 773\n",
      "    loss           : -941.3918897762245\n",
      "    val_loss       : -947.081864281836\n",
      "    val_log_likelihood: 1442.712798310265\n",
      "    val_log_marginal: 1014.782566844362\n",
      "Train Epoch: 774 [512/17352 (3%)] Loss: -1042.459229\n",
      "Train Epoch: 774 [10350/17352 (60%)] Loss: -1029.889228\n",
      "Train Epoch: 774 [17277/17352 (100%)] Loss: -1047.009542\n",
      "    epoch          : 774\n",
      "    loss           : -859.4082522350294\n",
      "    val_loss       : -931.2265458109381\n",
      "    val_log_likelihood: 1434.4366752409705\n",
      "    val_log_marginal: 992.0938965037396\n",
      "Train Epoch: 775 [512/17352 (3%)] Loss: 552.548950\n",
      "Train Epoch: 775 [10070/17352 (58%)] Loss: -1077.428510\n",
      "Train Epoch: 775 [16923/17352 (98%)] Loss: -825.683765\n",
      "    epoch          : 775\n",
      "    loss           : -917.7499278481702\n",
      "    val_loss       : -984.7751045652979\n",
      "    val_log_likelihood: 1428.1701569355773\n",
      "    val_log_marginal: 1024.447347422542\n",
      "Train Epoch: 776 [512/17352 (3%)] Loss: -1050.780273\n",
      "Train Epoch: 776 [10352/17352 (60%)] Loss: -1134.901463\n",
      "Train Epoch: 776 [17263/17352 (99%)] Loss: -1176.781850\n",
      "    epoch          : 776\n",
      "    loss           : -1014.8928609571325\n",
      "    val_loss       : -990.525471140469\n",
      "    val_log_likelihood: 1449.0910230743339\n",
      "    val_log_marginal: 1054.0182226943323\n",
      "Train Epoch: 777 [512/17352 (3%)] Loss: -1088.067627\n",
      "Train Epoch: 777 [10571/17352 (61%)] Loss: -933.956855\n",
      "Train Epoch: 777 [16872/17352 (97%)] Loss: -934.692808\n",
      "    epoch          : 777\n",
      "    loss           : -1044.7798302682056\n",
      "    val_loss       : -1009.1786903671469\n",
      "    val_log_likelihood: 1458.6547976866275\n",
      "    val_log_marginal: 1071.516063940709\n",
      "Train Epoch: 778 [512/17352 (3%)] Loss: -1095.191284\n",
      "Train Epoch: 778 [10505/17352 (61%)] Loss: -1108.992384\n",
      "Train Epoch: 778 [16988/17352 (98%)] Loss: -1099.597236\n",
      "    epoch          : 778\n",
      "    loss           : -1026.9473178349983\n",
      "    val_loss       : -1022.4656127366511\n",
      "    val_log_likelihood: 1460.621754639671\n",
      "    val_log_marginal: 1074.0849386019306\n",
      "Train Epoch: 779 [512/17352 (3%)] Loss: -1106.659912\n",
      "Train Epoch: 779 [10061/17352 (58%)] Loss: -1120.409707\n",
      "Train Epoch: 779 [16883/17352 (97%)] Loss: -952.539190\n",
      "    epoch          : 779\n",
      "    loss           : -1011.3018062202107\n",
      "    val_loss       : -1006.1903619502312\n",
      "    val_log_likelihood: 1455.8600423680648\n",
      "    val_log_marginal: 1055.5286680785734\n",
      "Train Epoch: 780 [512/17352 (3%)] Loss: -1081.238525\n",
      "Train Epoch: 780 [10531/17352 (61%)] Loss: -648.625103\n",
      "Train Epoch: 780 [17263/17352 (99%)] Loss: -744.699374\n",
      "    epoch          : 780\n",
      "    loss           : -950.5074218464667\n",
      "    val_loss       : -791.3659053777459\n",
      "    val_log_likelihood: 1428.9083276676306\n",
      "    val_log_marginal: 824.8563792403068\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch780.pth ...\n",
      "Train Epoch: 781 [512/17352 (3%)] Loss: -699.312012\n",
      "Train Epoch: 781 [10444/17352 (60%)] Loss: -903.828835\n",
      "Train Epoch: 781 [16922/17352 (98%)] Loss: -443.931858\n",
      "    epoch          : 781\n",
      "    loss           : -920.0858125415899\n",
      "    val_loss       : -815.3168119651078\n",
      "    val_log_likelihood: 1425.290230420618\n",
      "    val_log_marginal: 844.6908782651336\n",
      "Train Epoch: 782 [512/17352 (3%)] Loss: -842.016235\n",
      "Train Epoch: 782 [10284/17352 (59%)] Loss: -1080.402693\n",
      "Train Epoch: 782 [16882/17352 (97%)] Loss: -1044.732232\n",
      "    epoch          : 782\n",
      "    loss           : -865.587101002694\n",
      "    val_loss       : -889.400338983807\n",
      "    val_log_likelihood: 1419.11854654044\n",
      "    val_log_marginal: 1022.4670010985553\n",
      "Train Epoch: 783 [512/17352 (3%)] Loss: -1054.675049\n",
      "Train Epoch: 783 [10314/17352 (59%)] Loss: -1031.011234\n",
      "Train Epoch: 783 [17253/17352 (99%)] Loss: -1005.200521\n",
      "    epoch          : 783\n",
      "    loss           : -1004.9360610378151\n",
      "    val_loss       : -949.5544976776141\n",
      "    val_log_likelihood: 1437.2260006768474\n",
      "    val_log_marginal: 1020.9900557380846\n",
      "Train Epoch: 784 [512/17352 (3%)] Loss: -1056.133423\n",
      "Train Epoch: 784 [10366/17352 (60%)] Loss: 1036.198938\n",
      "Train Epoch: 784 [17335/17352 (100%)] Loss: -1023.903846\n",
      "    epoch          : 784\n",
      "    loss           : -954.2760363580112\n",
      "    val_loss       : -967.6863966899712\n",
      "    val_log_likelihood: 1442.2284453749164\n",
      "    val_log_marginal: 1045.6879507214878\n",
      "Train Epoch: 785 [512/17352 (3%)] Loss: -1069.359619\n",
      "Train Epoch: 785 [10889/17352 (63%)] Loss: -1129.997872\n",
      "Train Epoch: 785 [16939/17352 (98%)] Loss: -1091.118542\n",
      "    epoch          : 785\n",
      "    loss           : -1013.2504447640168\n",
      "    val_loss       : -1007.2202184520668\n",
      "    val_log_likelihood: 1457.3881775514453\n",
      "    val_log_marginal: 1070.0614345514005\n",
      "Train Epoch: 786 [512/17352 (3%)] Loss: -1095.712891\n",
      "Train Epoch: 786 [10563/17352 (61%)] Loss: -1146.535185\n",
      "Train Epoch: 786 [17126/17352 (99%)] Loss: -1162.486674\n",
      "    epoch          : 786\n",
      "    loss           : -1018.8809963475896\n",
      "    val_loss       : -1010.7897440284008\n",
      "    val_log_likelihood: 1451.754486212346\n",
      "    val_log_marginal: 1052.6418993305324\n",
      "Train Epoch: 787 [512/17352 (3%)] Loss: -1075.763672\n",
      "Train Epoch: 787 [10095/17352 (58%)] Loss: -1075.272500\n",
      "Train Epoch: 787 [17153/17352 (99%)] Loss: -1010.098586\n",
      "    epoch          : 787\n",
      "    loss           : -1005.803763378475\n",
      "    val_loss       : -1009.9519424209934\n",
      "    val_log_likelihood: 1449.878739445826\n",
      "    val_log_marginal: 1043.693046025979\n",
      "Train Epoch: 788 [512/17352 (3%)] Loss: -1074.269165\n",
      "Train Epoch: 788 [10373/17352 (60%)] Loss: -1120.492941\n",
      "Train Epoch: 788 [17016/17352 (98%)] Loss: -1016.988786\n",
      "    epoch          : 788\n",
      "    loss           : -1030.1170884755354\n",
      "    val_loss       : -1024.0186662083024\n",
      "    val_log_likelihood: 1450.4259725270897\n",
      "    val_log_marginal: 1059.2012914575007\n",
      "Train Epoch: 789 [512/17352 (3%)] Loss: -1093.337646\n",
      "Train Epoch: 789 [10276/17352 (59%)] Loss: -761.078125\n",
      "Train Epoch: 789 [17277/17352 (100%)] Loss: -1080.122201\n",
      "    epoch          : 789\n",
      "    loss           : -1022.9114881694819\n",
      "    val_loss       : -923.5392865210858\n",
      "    val_log_likelihood: 1403.204825507833\n",
      "    val_log_marginal: 981.3541115393617\n",
      "Train Epoch: 790 [512/17352 (3%)] Loss: -988.727722\n",
      "Train Epoch: 790 [10474/17352 (60%)] Loss: -1141.845612\n",
      "Train Epoch: 790 [16922/17352 (98%)] Loss: -945.261626\n",
      "    epoch          : 790\n",
      "    loss           : -1035.1408919572352\n",
      "    val_loss       : -973.2256184057657\n",
      "    val_log_likelihood: 1459.750175037134\n",
      "    val_log_marginal: 1070.3658390791386\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch790.pth ...\n",
      "Train Epoch: 791 [512/17352 (3%)] Loss: -1103.359863\n",
      "Train Epoch: 791 [10589/17352 (61%)] Loss: -1105.026042\n",
      "Train Epoch: 791 [17133/17352 (99%)] Loss: -1126.313770\n",
      "    epoch          : 791\n",
      "    loss           : -1028.3640284451385\n",
      "    val_loss       : -971.4796902560495\n",
      "    val_log_likelihood: 1441.164084203013\n",
      "    val_log_marginal: 1017.8009071538241\n",
      "Train Epoch: 792 [512/17352 (3%)] Loss: -893.890625\n",
      "Train Epoch: 792 [10031/17352 (58%)] Loss: -1108.942812\n",
      "Train Epoch: 792 [17101/17352 (99%)] Loss: -950.054765\n",
      "    epoch          : 792\n",
      "    loss           : -1039.2141230260115\n",
      "    val_loss       : -986.0902132140199\n",
      "    val_log_likelihood: 1459.6259549548852\n",
      "    val_log_marginal: 1008.4736338298695\n",
      "Train Epoch: 793 [512/17352 (3%)] Loss: -1029.633179\n",
      "Train Epoch: 793 [10652/17352 (61%)] Loss: -1092.169492\n",
      "Train Epoch: 793 [17253/17352 (99%)] Loss: -732.755934\n",
      "    epoch          : 793\n",
      "    loss           : -938.5989652089226\n",
      "    val_loss       : -790.5690549600549\n",
      "    val_log_likelihood: 1405.5076637365316\n",
      "    val_log_marginal: 825.6854170710385\n",
      "Train Epoch: 794 [512/17352 (3%)] Loss: -548.027588\n",
      "Train Epoch: 794 [10361/17352 (60%)] Loss: -826.374402\n",
      "Train Epoch: 794 [16923/17352 (98%)] Loss: -1115.964715\n",
      "    epoch          : 794\n",
      "    loss           : -920.799963237164\n",
      "    val_loss       : -1022.1388074300637\n",
      "    val_log_likelihood: 1440.3063210393793\n",
      "    val_log_marginal: 1044.8059871977441\n",
      "Train Epoch: 795 [512/17352 (3%)] Loss: -1071.877563\n",
      "Train Epoch: 795 [10840/17352 (62%)] Loss: -1001.841829\n",
      "Train Epoch: 795 [17253/17352 (99%)] Loss: -1089.418958\n",
      "    epoch          : 795\n",
      "    loss           : -993.2466521813396\n",
      "    val_loss       : -887.549146370028\n",
      "    val_log_likelihood: 1387.5397877067655\n",
      "    val_log_marginal: 947.7425387657765\n",
      "Train Epoch: 796 [512/17352 (3%)] Loss: -635.600464\n",
      "Train Epoch: 796 [10139/17352 (58%)] Loss: -1085.759703\n",
      "Train Epoch: 796 [16887/17352 (97%)] Loss: -929.847112\n",
      "    epoch          : 796\n",
      "    loss           : -920.230156763276\n",
      "    val_loss       : -798.9776886779019\n",
      "    val_log_likelihood: 1400.2908772487658\n",
      "    val_log_marginal: 926.6677429848435\n",
      "Train Epoch: 797 [512/17352 (3%)] Loss: -958.835815\n",
      "Train Epoch: 797 [10269/17352 (59%)] Loss: -863.104302\n",
      "Train Epoch: 797 [16887/17352 (97%)] Loss: -1037.508323\n",
      "    epoch          : 797\n",
      "    loss           : -822.4410182226005\n",
      "    val_loss       : -841.1823554624563\n",
      "    val_log_likelihood: 1357.5241578335279\n",
      "    val_log_marginal: 939.3320301122084\n",
      "Train Epoch: 798 [512/17352 (3%)] Loss: -962.824341\n",
      "Train Epoch: 798 [10157/17352 (59%)] Loss: -1060.198339\n",
      "Train Epoch: 798 [17253/17352 (99%)] Loss: -1073.089462\n",
      "    epoch          : 798\n",
      "    loss           : -942.450060614668\n",
      "    val_loss       : -1040.7280969548929\n",
      "    val_log_likelihood: 1440.9414132886798\n",
      "    val_log_marginal: 1041.5507746032488\n",
      "Train Epoch: 799 [512/17352 (3%)] Loss: -1075.627930\n",
      "Train Epoch: 799 [10111/17352 (58%)] Loss: -1034.249885\n",
      "Train Epoch: 799 [17253/17352 (99%)] Loss: -872.994292\n",
      "    epoch          : 799\n",
      "    loss           : -1012.1233652382929\n",
      "    val_loss       : -963.7801298483791\n",
      "    val_log_likelihood: 1447.1161730633678\n",
      "    val_log_marginal: 1016.2095795127073\n",
      "Train Epoch: 800 [512/17352 (3%)] Loss: -1049.514160\n",
      "Train Epoch: 800 [10237/17352 (59%)] Loss: -863.373870\n",
      "Train Epoch: 800 [17263/17352 (99%)] Loss: -986.349838\n",
      "    epoch          : 800\n",
      "    loss           : -945.7752933671024\n",
      "    val_loss       : -886.1442740065446\n",
      "    val_log_likelihood: 1424.140593776933\n",
      "    val_log_marginal: 976.8174985186549\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch800.pth ...\n",
      "Train Epoch: 801 [512/17352 (3%)] Loss: -994.042908\n",
      "Train Epoch: 801 [10245/17352 (59%)] Loss: -1077.981941\n",
      "Train Epoch: 801 [17143/17352 (99%)] Loss: -989.667287\n",
      "    epoch          : 801\n",
      "    loss           : -1026.2981031872614\n",
      "    val_loss       : -1018.3150266916447\n",
      "    val_log_likelihood: 1454.2819605386744\n",
      "    val_log_marginal: 1065.3516525767993\n",
      "Train Epoch: 802 [512/17352 (3%)] Loss: -1092.999756\n",
      "Train Epoch: 802 [10152/17352 (59%)] Loss: -1101.898698\n",
      "Train Epoch: 802 [16934/17352 (98%)] Loss: -1195.090352\n",
      "    epoch          : 802\n",
      "    loss           : -1043.2947501614838\n",
      "    val_loss       : -1051.5153200339496\n",
      "    val_log_likelihood: 1465.3293802553617\n",
      "    val_log_marginal: 1083.8921442475119\n",
      "Train Epoch: 803 [512/17352 (3%)] Loss: -1117.682739\n",
      "Train Epoch: 803 [10336/17352 (60%)] Loss: -802.537153\n",
      "Train Epoch: 803 [17124/17352 (99%)] Loss: -1137.692686\n",
      "    epoch          : 803\n",
      "    loss           : -1036.468638124647\n",
      "    val_loss       : -1054.6701407742755\n",
      "    val_log_likelihood: 1464.3163158854463\n",
      "    val_log_marginal: 1071.6343557072055\n",
      "Train Epoch: 804 [512/17352 (3%)] Loss: -1099.205322\n",
      "Train Epoch: 804 [10146/17352 (58%)] Loss: -1112.961370\n",
      "Train Epoch: 804 [17253/17352 (99%)] Loss: -755.327579\n",
      "    epoch          : 804\n",
      "    loss           : -993.7588305841176\n",
      "    val_loss       : -885.8894442885169\n",
      "    val_log_likelihood: 1433.6012615488191\n",
      "    val_log_marginal: 923.6008637711639\n",
      "Train Epoch: 805 [512/17352 (3%)] Loss: -959.097900\n",
      "Train Epoch: 805 [10070/17352 (58%)] Loss: -1110.475685\n",
      "Train Epoch: 805 [17253/17352 (99%)] Loss: -1110.114003\n",
      "    epoch          : 805\n",
      "    loss           : -1023.3506428536804\n",
      "    val_loss       : -1012.0556802307052\n",
      "    val_log_likelihood: 1467.441301521495\n",
      "    val_log_marginal: 1067.4243398610683\n",
      "Train Epoch: 806 [512/17352 (3%)] Loss: -954.471985\n",
      "Train Epoch: 806 [9900/17352 (57%)] Loss: -1108.595034\n",
      "Train Epoch: 806 [16882/17352 (97%)] Loss: -1125.559884\n",
      "    epoch          : 806\n",
      "    loss           : -1051.6606800703332\n",
      "    val_loss       : -1051.994606478501\n",
      "    val_log_likelihood: 1459.2729579549634\n",
      "    val_log_marginal: 1063.748759212407\n",
      "Train Epoch: 807 [512/17352 (3%)] Loss: -1098.664551\n",
      "Train Epoch: 807 [10746/17352 (62%)] Loss: -940.754483\n",
      "Train Epoch: 807 [17049/17352 (98%)] Loss: -1011.325081\n",
      "    epoch          : 807\n",
      "    loss           : -1007.7133525908773\n",
      "    val_loss       : -1000.3587726649473\n",
      "    val_log_likelihood: 1444.997018992384\n",
      "    val_log_marginal: 1042.29750430617\n",
      "Train Epoch: 808 [512/17352 (3%)] Loss: -1064.786621\n",
      "Train Epoch: 808 [10794/17352 (62%)] Loss: -1033.005272\n",
      "Train Epoch: 808 [16923/17352 (98%)] Loss: -1096.849117\n",
      "    epoch          : 808\n",
      "    loss           : -976.547736997444\n",
      "    val_loss       : -911.75693236092\n",
      "    val_log_likelihood: 1438.0539390214733\n",
      "    val_log_marginal: 1041.758617949447\n",
      "Train Epoch: 809 [512/17352 (3%)] Loss: -1058.579834\n",
      "Train Epoch: 809 [10381/17352 (60%)] Loss: -1013.685718\n",
      "Train Epoch: 809 [16934/17352 (98%)] Loss: -1065.428554\n",
      "    epoch          : 809\n",
      "    loss           : -1001.7147892505361\n",
      "    val_loss       : -965.1451015330697\n",
      "    val_log_likelihood: 1446.3041210478839\n",
      "    val_log_marginal: 1011.9135815283165\n",
      "Train Epoch: 810 [512/17352 (3%)] Loss: -1027.743042\n",
      "Train Epoch: 810 [10433/17352 (60%)] Loss: -1035.610723\n",
      "Train Epoch: 810 [16878/17352 (97%)] Loss: -870.901861\n",
      "    epoch          : 810\n",
      "    loss           : -978.5953965697405\n",
      "    val_loss       : -968.2044014115985\n",
      "    val_log_likelihood: 1455.3897141746995\n",
      "    val_log_marginal: 996.2000440008951\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch810.pth ...\n",
      "Train Epoch: 811 [512/17352 (3%)] Loss: -1019.737793\n",
      "Train Epoch: 811 [10138/17352 (58%)] Loss: -1093.313257\n",
      "Train Epoch: 811 [16922/17352 (98%)] Loss: -1053.683245\n",
      "    epoch          : 811\n",
      "    loss           : -923.3398069007376\n",
      "    val_loss       : -936.4889555318117\n",
      "    val_log_likelihood: 1443.9946121523942\n",
      "    val_log_marginal: 970.6573503415194\n",
      "Train Epoch: 812 [512/17352 (3%)] Loss: -999.949097\n",
      "Train Epoch: 812 [10859/17352 (63%)] Loss: -1051.240032\n",
      "Train Epoch: 812 [16934/17352 (98%)] Loss: -1069.714933\n",
      "    epoch          : 812\n",
      "    loss           : -925.058627941423\n",
      "    val_loss       : -968.6054315299205\n",
      "    val_log_likelihood: 1453.6671539561053\n",
      "    val_log_marginal: 1054.9630937369047\n",
      "Train Epoch: 813 [512/17352 (3%)] Loss: -659.595642\n",
      "Train Epoch: 813 [10299/17352 (59%)] Loss: -949.339331\n",
      "Train Epoch: 813 [17124/17352 (99%)] Loss: -714.671612\n",
      "    epoch          : 813\n",
      "    loss           : -939.7839479634313\n",
      "    val_loss       : -899.2693230162513\n",
      "    val_log_likelihood: 1401.674697336112\n",
      "    val_log_marginal: 954.4773417843459\n",
      "Train Epoch: 814 [512/17352 (3%)] Loss: -328.757751\n",
      "Train Epoch: 814 [10165/17352 (59%)] Loss: -973.927964\n",
      "Train Epoch: 814 [17044/17352 (98%)] Loss: -993.465598\n",
      "    epoch          : 814\n",
      "    loss           : -961.8947308608077\n",
      "    val_loss       : -1007.0152980264173\n",
      "    val_log_likelihood: 1453.7803368747682\n",
      "    val_log_marginal: 1051.9183267979097\n",
      "Train Epoch: 815 [512/17352 (3%)] Loss: -1077.096680\n",
      "Train Epoch: 815 [10214/17352 (59%)] Loss: -1081.319767\n",
      "Train Epoch: 815 [16878/17352 (97%)] Loss: -941.323535\n",
      "    epoch          : 815\n",
      "    loss           : -951.3272534492671\n",
      "    val_loss       : -926.8032390057743\n",
      "    val_log_likelihood: 1455.5826585363232\n",
      "    val_log_marginal: 1065.8926618812964\n",
      "Train Epoch: 816 [512/17352 (3%)] Loss: -1090.225708\n",
      "Train Epoch: 816 [10773/17352 (62%)] Loss: -1096.450982\n",
      "Train Epoch: 816 [16922/17352 (98%)] Loss: -976.965759\n",
      "    epoch          : 816\n",
      "    loss           : -1045.552013863228\n",
      "    val_loss       : -1007.7094467460755\n",
      "    val_log_likelihood: 1469.4883626596088\n",
      "    val_log_marginal: 1083.1624586258604\n",
      "Train Epoch: 817 [512/17352 (3%)] Loss: -1106.196289\n",
      "Train Epoch: 817 [10719/17352 (62%)] Loss: -1027.283076\n",
      "Train Epoch: 817 [16939/17352 (98%)] Loss: -1139.407519\n",
      "    epoch          : 817\n",
      "    loss           : -1049.4096467015777\n",
      "    val_loss       : -1034.877949196829\n",
      "    val_log_likelihood: 1475.6858086785708\n",
      "    val_log_marginal: 1075.562815319905\n",
      "Train Epoch: 818 [512/17352 (3%)] Loss: -931.066406\n",
      "Train Epoch: 818 [9911/17352 (57%)] Loss: -1099.697187\n",
      "Train Epoch: 818 [17153/17352 (99%)] Loss: -1062.627539\n",
      "    epoch          : 818\n",
      "    loss           : -965.8146022803637\n",
      "    val_loss       : -942.4441820574285\n",
      "    val_log_likelihood: 1459.0666028521155\n",
      "    val_log_marginal: 976.1976012492612\n",
      "Train Epoch: 819 [512/17352 (3%)] Loss: -996.570679\n",
      "Train Epoch: 819 [10602/17352 (61%)] Loss: -953.915520\n",
      "Train Epoch: 819 [16988/17352 (98%)] Loss: -1058.536692\n",
      "    epoch          : 819\n",
      "    loss           : -1014.8794820992206\n",
      "    val_loss       : -1044.679415884795\n",
      "    val_log_likelihood: 1472.7561375976245\n",
      "    val_log_marginal: 1066.1407140994825\n",
      "Train Epoch: 820 [512/17352 (3%)] Loss: -1106.127930\n",
      "Train Epoch: 820 [10426/17352 (60%)] Loss: -915.495411\n",
      "Train Epoch: 820 [17153/17352 (99%)] Loss: -790.457488\n",
      "    epoch          : 820\n",
      "    loss           : -1022.3641324126035\n",
      "    val_loss       : -1023.3121563541442\n",
      "    val_log_likelihood: 1470.0263607713648\n",
      "    val_log_marginal: 1057.443060749864\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch820.pth ...\n",
      "Train Epoch: 821 [512/17352 (3%)] Loss: -958.440857\n",
      "Train Epoch: 821 [10519/17352 (61%)] Loss: -896.082611\n",
      "Train Epoch: 821 [17108/17352 (99%)] Loss: -941.567774\n",
      "    epoch          : 821\n",
      "    loss           : -949.6595851788509\n",
      "    val_loss       : -931.46730813174\n",
      "    val_log_likelihood: 1459.840832170112\n",
      "    val_log_marginal: 940.1227231827861\n",
      "Train Epoch: 822 [512/17352 (3%)] Loss: -949.294739\n",
      "Train Epoch: 822 [10555/17352 (61%)] Loss: -1003.587103\n",
      "Train Epoch: 822 [17049/17352 (98%)] Loss: -889.039315\n",
      "    epoch          : 822\n",
      "    loss           : -972.0123383753848\n",
      "    val_loss       : -911.4177945023393\n",
      "    val_log_likelihood: 1449.3681381198016\n",
      "    val_log_marginal: 1007.5857689026071\n",
      "Train Epoch: 823 [512/17352 (3%)] Loss: -1032.927246\n",
      "Train Epoch: 823 [10099/17352 (58%)] Loss: -996.640625\n",
      "Train Epoch: 823 [17263/17352 (99%)] Loss: -1091.187240\n",
      "    epoch          : 823\n",
      "    loss           : -962.9191174395415\n",
      "    val_loss       : -961.5282708258555\n",
      "    val_log_likelihood: 1464.4789361120233\n",
      "    val_log_marginal: 1054.2184611316259\n",
      "Train Epoch: 824 [512/17352 (3%)] Loss: -1092.236084\n",
      "Train Epoch: 824 [9983/17352 (58%)] Loss: -1176.140951\n",
      "Train Epoch: 824 [17049/17352 (98%)] Loss: -816.799306\n",
      "    epoch          : 824\n",
      "    loss           : -1056.1481226115297\n",
      "    val_loss       : -1075.4055481575888\n",
      "    val_log_likelihood: 1480.6335798843359\n",
      "    val_log_marginal: 1085.7838252959575\n",
      "Train Epoch: 825 [512/17352 (3%)] Loss: -1115.262451\n",
      "Train Epoch: 825 [10280/17352 (59%)] Loss: -1174.366677\n",
      "Train Epoch: 825 [16988/17352 (98%)] Loss: -1024.071417\n",
      "    epoch          : 825\n",
      "    loss           : -1047.4952618090063\n",
      "    val_loss       : -1025.7048518238867\n",
      "    val_log_likelihood: 1478.177291373341\n",
      "    val_log_marginal: 1078.147642732915\n",
      "Train Epoch: 826 [512/17352 (3%)] Loss: -1098.309937\n",
      "Train Epoch: 826 [10763/17352 (62%)] Loss: -1052.407096\n",
      "Train Epoch: 826 [17335/17352 (100%)] Loss: -843.958871\n",
      "    epoch          : 826\n",
      "    loss           : -1022.044770737407\n",
      "    val_loss       : -572.4592257305721\n",
      "    val_log_likelihood: 1469.116711388913\n",
      "    val_log_marginal: 646.6722382602882\n",
      "Train Epoch: 827 [512/17352 (3%)] Loss: -648.920532\n",
      "Train Epoch: 827 [9881/17352 (57%)] Loss: -1094.492032\n",
      "Train Epoch: 827 [17108/17352 (99%)] Loss: -720.564531\n",
      "    epoch          : 827\n",
      "    loss           : -959.3723371193463\n",
      "    val_loss       : -979.1171780695627\n",
      "    val_log_likelihood: 1436.6357979692623\n",
      "    val_log_marginal: 1001.3317649962795\n",
      "Train Epoch: 828 [512/17352 (3%)] Loss: -1039.770386\n",
      "Train Epoch: 828 [9976/17352 (57%)] Loss: -1041.135735\n",
      "Train Epoch: 828 [17106/17352 (99%)] Loss: -889.407346\n",
      "    epoch          : 828\n",
      "    loss           : -913.9280536050055\n",
      "    val_loss       : -925.4792040546621\n",
      "    val_log_likelihood: 1446.4382942870425\n",
      "    val_log_marginal: 956.4277716128325\n",
      "Train Epoch: 829 [512/17352 (3%)] Loss: -966.117065\n",
      "Train Epoch: 829 [10289/17352 (59%)] Loss: -950.738986\n",
      "Train Epoch: 829 [16923/17352 (98%)] Loss: -1017.086627\n",
      "    epoch          : 829\n",
      "    loss           : -995.5751169452783\n",
      "    val_loss       : -996.4807756002924\n",
      "    val_log_likelihood: 1477.1926447403062\n",
      "    val_log_marginal: 1071.4942949898598\n",
      "Train Epoch: 830 [512/17352 (3%)] Loss: -1110.216187\n",
      "Train Epoch: 830 [10334/17352 (60%)] Loss: -921.192169\n",
      "Train Epoch: 830 [17108/17352 (99%)] Loss: -839.352642\n",
      "    epoch          : 830\n",
      "    loss           : -750.5556607350267\n",
      "    val_loss       : -910.3751344471514\n",
      "    val_log_likelihood: 1421.799874236491\n",
      "    val_log_marginal: 994.1283820719215\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch830.pth ...\n",
      "Train Epoch: 831 [512/17352 (3%)] Loss: -1007.158325\n",
      "Train Epoch: 831 [10268/17352 (59%)] Loss: -1003.071920\n",
      "Train Epoch: 831 [17253/17352 (99%)] Loss: -1001.097656\n",
      "    epoch          : 831\n",
      "    loss           : -999.0497206220825\n",
      "    val_loss       : -998.0397211680227\n",
      "    val_log_likelihood: 1467.9967394280188\n",
      "    val_log_marginal: 1071.7959067766049\n",
      "Train Epoch: 832 [512/17352 (3%)] Loss: -1104.859863\n",
      "Train Epoch: 832 [10577/17352 (61%)] Loss: -927.282191\n",
      "Train Epoch: 832 [16934/17352 (98%)] Loss: -1159.682836\n",
      "    epoch          : 832\n",
      "    loss           : -988.3182821092181\n",
      "    val_loss       : -1018.081206180713\n",
      "    val_log_likelihood: 1477.8615525372331\n",
      "    val_log_marginal: 1065.7579732080665\n",
      "Train Epoch: 833 [512/17352 (3%)] Loss: -1096.512939\n",
      "Train Epoch: 833 [10692/17352 (62%)] Loss: -1041.014372\n",
      "Train Epoch: 833 [16934/17352 (98%)] Loss: -942.854578\n",
      "    epoch          : 833\n",
      "    loss           : -992.4274295905113\n",
      "    val_loss       : -982.9104870989887\n",
      "    val_log_likelihood: 1476.0829252438823\n",
      "    val_log_marginal: 1059.1873316596536\n",
      "Train Epoch: 834 [512/17352 (3%)] Loss: -1087.640869\n",
      "Train Epoch: 834 [10322/17352 (59%)] Loss: -1091.452938\n",
      "Train Epoch: 834 [17064/17352 (98%)] Loss: -749.873355\n",
      "    epoch          : 834\n",
      "    loss           : -1008.308004053111\n",
      "    val_loss       : -783.2177543933307\n",
      "    val_log_likelihood: 1472.6146077237465\n",
      "    val_log_marginal: 804.3533764350655\n",
      "Train Epoch: 835 [512/17352 (3%)] Loss: -811.597961\n",
      "Train Epoch: 835 [10110/17352 (58%)] Loss: -1141.417952\n",
      "Train Epoch: 835 [17016/17352 (98%)] Loss: -679.836582\n",
      "    epoch          : 835\n",
      "    loss           : -951.9097810595209\n",
      "    val_loss       : -981.3227694557761\n",
      "    val_log_likelihood: 1471.3313812859244\n",
      "    val_log_marginal: 1022.3370531961226\n",
      "Train Epoch: 836 [512/17352 (3%)] Loss: -1038.620239\n",
      "Train Epoch: 836 [10258/17352 (59%)] Loss: -1036.340803\n",
      "Train Epoch: 836 [16878/17352 (97%)] Loss: -975.085208\n",
      "    epoch          : 836\n",
      "    loss           : -943.7029001952955\n",
      "    val_loss       : -933.3594516103358\n",
      "    val_log_likelihood: 1473.2950787286723\n",
      "    val_log_marginal: 983.8825296229662\n",
      "Train Epoch: 837 [512/17352 (3%)] Loss: -978.454834\n",
      "Train Epoch: 837 [10024/17352 (58%)] Loss: -977.353286\n",
      "Train Epoch: 837 [17108/17352 (99%)] Loss: -1089.515032\n",
      "    epoch          : 837\n",
      "    loss           : -997.5873850313657\n",
      "    val_loss       : -990.8003879504633\n",
      "    val_log_likelihood: 1477.5190143509615\n",
      "    val_log_marginal: 1035.2086592674227\n",
      "Train Epoch: 838 [512/17352 (3%)] Loss: -1053.682861\n",
      "Train Epoch: 838 [10349/17352 (60%)] Loss: -953.643924\n",
      "Train Epoch: 838 [16988/17352 (98%)] Loss: -1127.671494\n",
      "    epoch          : 838\n",
      "    loss           : -1002.4590629405296\n",
      "    val_loss       : -1055.305901123829\n",
      "    val_log_likelihood: 1486.3538749532993\n",
      "    val_log_marginal: 1078.6838477931026\n",
      "Train Epoch: 839 [512/17352 (3%)] Loss: -1106.895752\n",
      "Train Epoch: 839 [10184/17352 (59%)] Loss: -1093.055871\n",
      "Train Epoch: 839 [16939/17352 (98%)] Loss: -1058.006319\n",
      "    epoch          : 839\n",
      "    loss           : -1073.7148531781836\n",
      "    val_loss       : -1073.5212384394745\n",
      "    val_log_likelihood: 1489.6523743812086\n",
      "    val_log_marginal: 1097.278832498617\n",
      "Train Epoch: 840 [512/17352 (3%)] Loss: -1124.379639\n",
      "Train Epoch: 840 [10261/17352 (59%)] Loss: -1155.862896\n",
      "Train Epoch: 840 [17090/17352 (98%)] Loss: -1129.863940\n",
      "    epoch          : 840\n",
      "    loss           : -1072.026181773362\n",
      "    val_loss       : -1079.382676449435\n",
      "    val_log_likelihood: 1494.1518288180694\n",
      "    val_log_marginal: 1097.802543579691\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch840.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 841 [512/17352 (3%)] Loss: -1124.994385\n",
      "Train Epoch: 841 [10298/17352 (59%)] Loss: -1131.643697\n",
      "Train Epoch: 841 [16923/17352 (98%)] Loss: -1096.629215\n",
      "    epoch          : 841\n",
      "    loss           : -1041.3627072730437\n",
      "    val_loss       : -1030.139852567865\n",
      "    val_log_likelihood: 1498.1978161315476\n",
      "    val_log_marginal: 1049.581150758811\n",
      "Train Epoch: 842 [512/17352 (3%)] Loss: -1072.581543\n",
      "Train Epoch: 842 [10482/17352 (60%)] Loss: -1062.802517\n",
      "Train Epoch: 842 [16887/17352 (97%)] Loss: -953.744534\n",
      "    epoch          : 842\n",
      "    loss           : -1053.0029481814634\n",
      "    val_loss       : -1089.5372461698496\n",
      "    val_log_likelihood: 1499.0889410540951\n",
      "    val_log_marginal: 1096.7906428410479\n",
      "Train Epoch: 843 [512/17352 (3%)] Loss: -1122.035278\n",
      "Train Epoch: 843 [10752/17352 (62%)] Loss: -963.974723\n",
      "Train Epoch: 843 [16887/17352 (97%)] Loss: -1095.534590\n",
      "    epoch          : 843\n",
      "    loss           : -1055.9969752469044\n",
      "    val_loss       : -1078.579641040327\n",
      "    val_log_likelihood: 1497.2367203089102\n",
      "    val_log_marginal: 1099.877182414238\n",
      "Train Epoch: 844 [512/17352 (3%)] Loss: -1130.004150\n",
      "Train Epoch: 844 [10322/17352 (59%)] Loss: -1040.520399\n",
      "Train Epoch: 844 [17277/17352 (100%)] Loss: -969.841584\n",
      "    epoch          : 844\n",
      "    loss           : -1043.4610116108895\n",
      "    val_loss       : -1013.5564785570491\n",
      "    val_log_likelihood: 1501.3826004934965\n",
      "    val_log_marginal: 1102.5728573038373\n",
      "Train Epoch: 845 [512/17352 (3%)] Loss: -1130.368164\n",
      "Train Epoch: 845 [10703/17352 (62%)] Loss: -950.732809\n",
      "Train Epoch: 845 [17064/17352 (98%)] Loss: -988.641406\n",
      "    epoch          : 845\n",
      "    loss           : -960.1522992678413\n",
      "    val_loss       : -792.3495398521638\n",
      "    val_log_likelihood: 1478.7229775219628\n",
      "    val_log_marginal: 865.7056762447165\n",
      "Train Epoch: 846 [512/17352 (3%)] Loss: -904.309937\n",
      "Train Epoch: 846 [10202/17352 (59%)] Loss: -859.888737\n",
      "Train Epoch: 846 [17064/17352 (98%)] Loss: -874.797664\n",
      "    epoch          : 846\n",
      "    loss           : -788.5819256078515\n",
      "    val_loss       : -795.1911653952922\n",
      "    val_log_likelihood: 1385.9419255944088\n",
      "    val_log_marginal: 902.5985961220439\n",
      "Train Epoch: 847 [512/17352 (3%)] Loss: -875.085815\n",
      "Train Epoch: 847 [9786/17352 (56%)] Loss: -424.625150\n",
      "Train Epoch: 847 [17124/17352 (99%)] Loss: -753.996541\n",
      "    epoch          : 847\n",
      "    loss           : -859.2013755101499\n",
      "    val_loss       : -995.810916285225\n",
      "    val_log_likelihood: 1444.6861781573577\n",
      "    val_log_marginal: 1026.538968971206\n",
      "Train Epoch: 848 [512/17352 (3%)] Loss: -1056.146362\n",
      "Train Epoch: 848 [10278/17352 (59%)] Loss: -888.380122\n",
      "Train Epoch: 848 [16872/17352 (97%)] Loss: -703.189856\n",
      "    epoch          : 848\n",
      "    loss           : -863.8503219532431\n",
      "    val_loss       : -855.4938688272164\n",
      "    val_log_likelihood: 1464.148218753237\n",
      "    val_log_marginal: 876.9674831055055\n",
      "Train Epoch: 849 [512/17352 (3%)] Loss: -208.070160\n",
      "Train Epoch: 849 [10376/17352 (60%)] Loss: -737.994715\n",
      "Train Epoch: 849 [17277/17352 (100%)] Loss: -639.674466\n",
      "    epoch          : 849\n",
      "    loss           : -717.1118723604814\n",
      "    val_loss       : -95.40418247064655\n",
      "    val_log_likelihood: 1354.0553879527347\n",
      "    val_log_marginal: 193.3578249325754\n",
      "Train Epoch: 850 [512/17352 (3%)] Loss: -318.726807\n",
      "Train Epoch: 850 [10542/17352 (61%)] Loss: -839.586961\n",
      "Train Epoch: 850 [16922/17352 (98%)] Loss: -916.157468\n",
      "    epoch          : 850\n",
      "    loss           : -796.9377950294522\n",
      "    val_loss       : -942.2675426686437\n",
      "    val_log_likelihood: 1454.0727902700921\n",
      "    val_log_marginal: 1044.0962364728666\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch850.pth ...\n",
      "Train Epoch: 851 [512/17352 (3%)] Loss: -902.717041\n",
      "Train Epoch: 851 [10456/17352 (60%)] Loss: -1045.411272\n",
      "Train Epoch: 851 [17277/17352 (100%)] Loss: -1147.460366\n",
      "    epoch          : 851\n",
      "    loss           : -1028.28561857276\n",
      "    val_loss       : -1028.9701883970256\n",
      "    val_log_likelihood: 1470.0842173059127\n",
      "    val_log_marginal: 1065.6864043764012\n",
      "Train Epoch: 852 [512/17352 (3%)] Loss: -1096.000977\n",
      "Train Epoch: 852 [10245/17352 (59%)] Loss: -1192.546908\n",
      "Train Epoch: 852 [17090/17352 (98%)] Loss: -1196.162543\n",
      "    epoch          : 852\n",
      "    loss           : -1046.4721724100893\n",
      "    val_loss       : -1056.4543061544564\n",
      "    val_log_likelihood: 1483.305822679523\n",
      "    val_log_marginal: 1083.2365748843915\n",
      "Train Epoch: 853 [512/17352 (3%)] Loss: -1107.327148\n",
      "Train Epoch: 853 [10054/17352 (58%)] Loss: -1125.825755\n",
      "Train Epoch: 853 [16887/17352 (97%)] Loss: -1042.396260\n",
      "    epoch          : 853\n",
      "    loss           : -1071.1127533774516\n",
      "    val_loss       : -1067.9701796784125\n",
      "    val_log_likelihood: 1491.9423238521015\n",
      "    val_log_marginal: 1101.3881560646166\n",
      "Train Epoch: 854 [512/17352 (3%)] Loss: -1137.398804\n",
      "Train Epoch: 854 [10591/17352 (61%)] Loss: -1149.546584\n",
      "Train Epoch: 854 [17143/17352 (99%)] Loss: -1045.097144\n",
      "    epoch          : 854\n",
      "    loss           : -1082.7936678589117\n",
      "    val_loss       : -1075.7898665391688\n",
      "    val_log_likelihood: 1497.7409680431074\n",
      "    val_log_marginal: 1104.7512679580611\n",
      "Train Epoch: 855 [512/17352 (3%)] Loss: -1132.458740\n",
      "Train Epoch: 855 [10175/17352 (59%)] Loss: -1132.068861\n",
      "Train Epoch: 855 [17044/17352 (98%)] Loss: -1082.830450\n",
      "    epoch          : 855\n",
      "    loss           : -1094.2597722411501\n",
      "    val_loss       : -1085.713566030085\n",
      "    val_log_likelihood: 1504.3149555918396\n",
      "    val_log_marginal: 1111.2685081414852\n",
      "Train Epoch: 856 [512/17352 (3%)] Loss: -1145.889282\n",
      "Train Epoch: 856 [10802/17352 (62%)] Loss: -1214.570362\n",
      "Train Epoch: 856 [16872/17352 (97%)] Loss: -1128.642123\n",
      "    epoch          : 856\n",
      "    loss           : -1013.4470068470073\n",
      "    val_loss       : -1034.9285393863813\n",
      "    val_log_likelihood: 1498.0968050767049\n",
      "    val_log_marginal: 1101.3124989479693\n",
      "Train Epoch: 857 [512/17352 (3%)] Loss: -1128.463501\n",
      "Train Epoch: 857 [10471/17352 (60%)] Loss: -990.209181\n",
      "Train Epoch: 857 [17133/17352 (99%)] Loss: -1107.244081\n",
      "    epoch          : 857\n",
      "    loss           : -1025.3384517628092\n",
      "    val_loss       : -1036.0898463501217\n",
      "    val_log_likelihood: 1475.955698212269\n",
      "    val_log_marginal: 1063.932021084997\n",
      "Train Epoch: 858 [512/17352 (3%)] Loss: -1087.677979\n",
      "Train Epoch: 858 [10143/17352 (58%)] Loss: -1119.754055\n",
      "Train Epoch: 858 [16923/17352 (98%)] Loss: -1142.657292\n",
      "    epoch          : 858\n",
      "    loss           : -1072.6862504518265\n",
      "    val_loss       : -1037.386196743061\n",
      "    val_log_likelihood: 1506.083917084944\n",
      "    val_log_marginal: 1106.707031159611\n",
      "Train Epoch: 859 [512/17352 (3%)] Loss: -1136.580078\n",
      "Train Epoch: 859 [10651/17352 (61%)] Loss: -1056.610764\n",
      "Train Epoch: 859 [17108/17352 (99%)] Loss: -1099.441840\n",
      "    epoch          : 859\n",
      "    loss           : -1077.840614479024\n",
      "    val_loss       : -1062.5282216765067\n",
      "    val_log_likelihood: 1506.5986540852523\n",
      "    val_log_marginal: 1106.973233654147\n",
      "Train Epoch: 860 [512/17352 (3%)] Loss: -1139.304443\n",
      "Train Epoch: 860 [10480/17352 (60%)] Loss: -989.913577\n",
      "Train Epoch: 860 [17153/17352 (99%)] Loss: -1120.961560\n",
      "    epoch          : 860\n",
      "    loss           : -1098.6061187556495\n",
      "    val_loss       : -1081.348216987898\n",
      "    val_log_likelihood: 1512.257853451341\n",
      "    val_log_marginal: 1111.5258691723652\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch860.pth ...\n",
      "Train Epoch: 861 [512/17352 (3%)] Loss: -1145.867310\n",
      "Train Epoch: 861 [10717/17352 (62%)] Loss: -1124.432506\n",
      "Train Epoch: 861 [17143/17352 (99%)] Loss: -1066.302370\n",
      "    epoch          : 861\n",
      "    loss           : -995.0276280715277\n",
      "    val_loss       : -967.5009056767708\n",
      "    val_log_likelihood: 1482.4211812326043\n",
      "    val_log_marginal: 1011.81430792967\n",
      "Train Epoch: 862 [512/17352 (3%)] Loss: -1033.323608\n",
      "Train Epoch: 862 [10589/17352 (61%)] Loss: -1099.987763\n",
      "Train Epoch: 862 [17335/17352 (100%)] Loss: -1133.608899\n",
      "    epoch          : 862\n",
      "    loss           : -997.2088719034133\n",
      "    val_loss       : -1025.689843971847\n",
      "    val_log_likelihood: 1468.138257443794\n",
      "    val_log_marginal: 1040.276365449557\n",
      "Train Epoch: 863 [512/17352 (3%)] Loss: -1052.072754\n",
      "Train Epoch: 863 [9968/17352 (57%)] Loss: -987.827917\n",
      "Train Epoch: 863 [16988/17352 (98%)] Loss: -1134.532249\n",
      "    epoch          : 863\n",
      "    loss           : -1019.9792576795844\n",
      "    val_loss       : -1053.9907130761578\n",
      "    val_log_likelihood: 1502.426976616576\n",
      "    val_log_marginal: 1096.8285248119896\n",
      "Train Epoch: 864 [512/17352 (3%)] Loss: -1126.228394\n",
      "Train Epoch: 864 [10208/17352 (59%)] Loss: -1144.107267\n",
      "Train Epoch: 864 [17153/17352 (99%)] Loss: -695.487366\n",
      "    epoch          : 864\n",
      "    loss           : -1068.5721647712892\n",
      "    val_loss       : -1039.9442158538627\n",
      "    val_log_likelihood: 1503.7854054061333\n",
      "    val_log_marginal: 1093.3565020000176\n",
      "Train Epoch: 865 [512/17352 (3%)] Loss: -1118.835327\n",
      "Train Epoch: 865 [10476/17352 (60%)] Loss: -883.310522\n",
      "Train Epoch: 865 [17143/17352 (99%)] Loss: -1156.339583\n",
      "    epoch          : 865\n",
      "    loss           : -1063.0151849850997\n",
      "    val_loss       : -1088.9165836665027\n",
      "    val_log_likelihood: 1509.8009728319375\n",
      "    val_log_marginal: 1105.0231584777805\n",
      "Train Epoch: 866 [512/17352 (3%)] Loss: -1003.698975\n",
      "Train Epoch: 866 [10316/17352 (59%)] Loss: -848.828582\n",
      "Train Epoch: 866 [17049/17352 (98%)] Loss: -1222.283849\n",
      "    epoch          : 866\n",
      "    loss           : -1087.796204822971\n",
      "    val_loss       : -1044.5528116667815\n",
      "    val_log_likelihood: 1508.1853460015561\n",
      "    val_log_marginal: 1100.744256409684\n",
      "Train Epoch: 867 [512/17352 (3%)] Loss: -1129.276733\n",
      "Train Epoch: 867 [10113/17352 (58%)] Loss: -1114.655774\n",
      "Train Epoch: 867 [16934/17352 (98%)] Loss: -1111.585584\n",
      "    epoch          : 867\n",
      "    loss           : -1022.594911755361\n",
      "    val_loss       : -1068.2456611681155\n",
      "    val_log_likelihood: 1495.2486722170304\n",
      "    val_log_marginal: 1090.5845155248433\n",
      "Train Epoch: 868 [512/17352 (3%)] Loss: -941.997681\n",
      "Train Epoch: 868 [9878/17352 (57%)] Loss: -734.771441\n",
      "Train Epoch: 868 [17016/17352 (98%)] Loss: -1081.059327\n",
      "    epoch          : 868\n",
      "    loss           : -1071.1443473039278\n",
      "    val_loss       : -1024.2713649795517\n",
      "    val_log_likelihood: 1499.6901383521683\n",
      "    val_log_marginal: 1088.9655045361942\n",
      "Train Epoch: 869 [512/17352 (3%)] Loss: -1120.572144\n",
      "Train Epoch: 869 [10106/17352 (58%)] Loss: -595.676361\n",
      "Train Epoch: 869 [16922/17352 (98%)] Loss: -1178.787093\n",
      "    epoch          : 869\n",
      "    loss           : -1078.0854932456161\n",
      "    val_loss       : -1065.1133994312634\n",
      "    val_log_likelihood: 1516.060484116606\n",
      "    val_log_marginal: 1117.23247622184\n",
      "Train Epoch: 870 [512/17352 (3%)] Loss: -1148.574951\n",
      "Train Epoch: 870 [10110/17352 (58%)] Loss: -1187.139609\n",
      "Train Epoch: 870 [16887/17352 (97%)] Loss: -1151.387628\n",
      "    epoch          : 870\n",
      "    loss           : -1074.2188508983088\n",
      "    val_loss       : -1078.1303082119584\n",
      "    val_log_likelihood: 1519.64153035551\n",
      "    val_log_marginal: 1119.0106794658539\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch870.pth ...\n",
      "Train Epoch: 871 [512/17352 (3%)] Loss: -1149.309570\n",
      "Train Epoch: 871 [9994/17352 (58%)] Loss: -1065.480263\n",
      "Train Epoch: 871 [17049/17352 (98%)] Loss: -1147.067708\n",
      "    epoch          : 871\n",
      "    loss           : -1112.6275235870455\n",
      "    val_loss       : -1088.3940002213635\n",
      "    val_log_likelihood: 1519.5943257674598\n",
      "    val_log_marginal: 1117.1664593067812\n",
      "Train Epoch: 872 [512/17352 (3%)] Loss: -1153.411133\n",
      "Train Epoch: 872 [10555/17352 (61%)] Loss: -1155.117733\n",
      "Train Epoch: 872 [17133/17352 (99%)] Loss: -855.106352\n",
      "    epoch          : 872\n",
      "    loss           : -1104.2586699304018\n",
      "    val_loss       : -1072.2348778808264\n",
      "    val_log_likelihood: 1520.3620194023106\n",
      "    val_log_marginal: 1113.4315369615756\n",
      "Train Epoch: 873 [512/17352 (3%)] Loss: -1145.152588\n",
      "Train Epoch: 873 [9938/17352 (57%)] Loss: -1180.906782\n",
      "Train Epoch: 873 [17143/17352 (99%)] Loss: -1163.061119\n",
      "    epoch          : 873\n",
      "    loss           : -1091.1336466591276\n",
      "    val_loss       : -1049.019005580291\n",
      "    val_log_likelihood: 1496.8967255857244\n",
      "    val_log_marginal: 1074.1974797173777\n",
      "Train Epoch: 874 [512/17352 (3%)] Loss: -1108.739746\n",
      "Train Epoch: 874 [10339/17352 (60%)] Loss: -1128.800208\n",
      "Train Epoch: 874 [17335/17352 (100%)] Loss: -968.203795\n",
      "    epoch          : 874\n",
      "    loss           : -1001.2407954311799\n",
      "    val_loss       : -1031.2412584588092\n",
      "    val_log_likelihood: 1485.82054063963\n",
      "    val_log_marginal: 1060.8437682895537\n",
      "Train Epoch: 875 [512/17352 (3%)] Loss: -1103.918213\n",
      "Train Epoch: 875 [9965/17352 (57%)] Loss: -810.507347\n",
      "Train Epoch: 875 [17044/17352 (98%)] Loss: -863.356250\n",
      "    epoch          : 875\n",
      "    loss           : -769.1550676155198\n",
      "    val_loss       : -870.9464459225019\n",
      "    val_log_likelihood: 1399.56025731665\n",
      "    val_log_marginal: 916.955164789439\n",
      "Train Epoch: 876 [512/17352 (3%)] Loss: -802.859497\n",
      "Train Epoch: 876 [10630/17352 (61%)] Loss: -1048.606445\n",
      "Train Epoch: 876 [16992/17352 (98%)] Loss: -752.018724\n",
      "    epoch          : 876\n",
      "    loss           : -922.726644742586\n",
      "    val_loss       : -1040.5915502146288\n",
      "    val_log_likelihood: 1483.9058364455746\n",
      "    val_log_marginal: 1062.2858727555285\n",
      "Train Epoch: 877 [512/17352 (3%)] Loss: -1088.051514\n",
      "Train Epoch: 877 [9965/17352 (57%)] Loss: -1048.495290\n",
      "Train Epoch: 877 [16939/17352 (98%)] Loss: -980.310460\n",
      "    epoch          : 877\n",
      "    loss           : -1036.2180664437842\n",
      "    val_loss       : -1068.7914826949468\n",
      "    val_log_likelihood: 1502.5981199998375\n",
      "    val_log_marginal: 1093.1006138027133\n",
      "Train Epoch: 878 [512/17352 (3%)] Loss: -954.384338\n",
      "Train Epoch: 878 [10388/17352 (60%)] Loss: -900.756449\n",
      "Train Epoch: 878 [17335/17352 (100%)] Loss: -1133.129632\n",
      "    epoch          : 878\n",
      "    loss           : -1063.535076098008\n",
      "    val_loss       : -1013.6548876487639\n",
      "    val_log_likelihood: 1491.5307654330795\n",
      "    val_log_marginal: 1078.7887719130333\n",
      "Train Epoch: 879 [512/17352 (3%)] Loss: -951.178589\n",
      "Train Epoch: 879 [9933/17352 (57%)] Loss: -1157.390449\n",
      "Train Epoch: 879 [17044/17352 (98%)] Loss: -1079.109512\n",
      "    epoch          : 879\n",
      "    loss           : -1074.9719038763217\n",
      "    val_loss       : -1089.0074246348609\n",
      "    val_log_likelihood: 1516.0327933964231\n",
      "    val_log_marginal: 1114.0413460909858\n",
      "Train Epoch: 880 [512/17352 (3%)] Loss: -1142.459229\n",
      "Train Epoch: 880 [9906/17352 (57%)] Loss: -1130.239636\n",
      "Train Epoch: 880 [16934/17352 (98%)] Loss: -991.164971\n",
      "    epoch          : 880\n",
      "    loss           : -1008.6158481210167\n",
      "    val_loss       : -1044.8971493904307\n",
      "    val_log_likelihood: 1509.4768061903053\n",
      "    val_log_marginal: 1067.9595925357194\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch880.pth ...\n",
      "Train Epoch: 881 [512/17352 (3%)] Loss: -1092.279541\n",
      "Train Epoch: 881 [10248/17352 (59%)] Loss: -1051.666992\n",
      "Train Epoch: 881 [16922/17352 (98%)] Loss: -840.158867\n",
      "    epoch          : 881\n",
      "    loss           : -840.6791242273732\n",
      "    val_loss       : -988.6592063700825\n",
      "    val_log_likelihood: 1473.0787272027708\n",
      "    val_log_marginal: 995.5025116562974\n",
      "Train Epoch: 882 [512/17352 (3%)] Loss: -1038.796997\n",
      "Train Epoch: 882 [10288/17352 (59%)] Loss: -514.569758\n",
      "Train Epoch: 882 [16923/17352 (98%)] Loss: -835.381461\n",
      "    epoch          : 882\n",
      "    loss           : -797.9373783183654\n",
      "    val_loss       : -875.3501767503965\n",
      "    val_log_likelihood: 1439.7348094678146\n",
      "    val_log_marginal: 924.6187124870409\n",
      "Train Epoch: 883 [512/17352 (3%)] Loss: -933.360291\n",
      "Train Epoch: 883 [10080/17352 (58%)] Loss: -922.146640\n",
      "Train Epoch: 883 [17106/17352 (99%)] Loss: -1142.325190\n",
      "    epoch          : 883\n",
      "    loss           : -937.3156494082579\n",
      "    val_loss       : -1025.8682197484472\n",
      "    val_log_likelihood: 1490.2014451867499\n",
      "    val_log_marginal: 1062.798755757902\n",
      "Train Epoch: 884 [512/17352 (3%)] Loss: -1091.178467\n",
      "Train Epoch: 884 [10325/17352 (60%)] Loss: -1137.551115\n",
      "Train Epoch: 884 [17101/17352 (99%)] Loss: -1190.719944\n",
      "    epoch          : 884\n",
      "    loss           : -1077.0984793891746\n",
      "    val_loss       : -1096.5533063678495\n",
      "    val_log_likelihood: 1503.1408949419276\n",
      "    val_log_marginal: 1102.0644529633066\n",
      "Train Epoch: 885 [512/17352 (3%)] Loss: -979.932007\n",
      "Train Epoch: 885 [10457/17352 (60%)] Loss: -1152.411042\n",
      "Train Epoch: 885 [17253/17352 (99%)] Loss: -1048.522797\n",
      "    epoch          : 885\n",
      "    loss           : -1090.1554721569728\n",
      "    val_loss       : -1078.6305611421144\n",
      "    val_log_likelihood: 1514.5506143787545\n",
      "    val_log_marginal: 1100.3453839006236\n",
      "Train Epoch: 886 [512/17352 (3%)] Loss: -1133.275391\n",
      "Train Epoch: 886 [10617/17352 (61%)] Loss: -1161.520049\n",
      "Train Epoch: 886 [16957/17352 (98%)] Loss: -1110.804895\n",
      "    epoch          : 886\n",
      "    loss           : -1052.1754045678085\n",
      "    val_loss       : -1043.7933702351174\n",
      "    val_log_likelihood: 1514.0138030507296\n",
      "    val_log_marginal: 1094.8364826504494\n",
      "Train Epoch: 887 [512/17352 (3%)] Loss: -1128.917969\n",
      "Train Epoch: 887 [10027/17352 (58%)] Loss: -1057.663309\n",
      "Train Epoch: 887 [16958/17352 (98%)] Loss: -1130.390365\n",
      "    epoch          : 887\n",
      "    loss           : -1036.7629720398427\n",
      "    val_loss       : -1021.814630045188\n",
      "    val_log_likelihood: 1514.7385549150647\n",
      "    val_log_marginal: 1111.1936247550302\n",
      "Train Epoch: 888 [512/17352 (3%)] Loss: -1141.054077\n",
      "Train Epoch: 888 [10372/17352 (60%)] Loss: -1078.709019\n",
      "Train Epoch: 888 [16882/17352 (97%)] Loss: -1141.309636\n",
      "    epoch          : 888\n",
      "    loss           : -1084.791995877817\n",
      "    val_loss       : -1083.2730492773255\n",
      "    val_log_likelihood: 1521.249922685414\n",
      "    val_log_marginal: 1120.9903472864055\n",
      "Train Epoch: 889 [512/17352 (3%)] Loss: -1152.793091\n",
      "Train Epoch: 889 [9843/17352 (57%)] Loss: -1143.908333\n",
      "Train Epoch: 889 [17253/17352 (99%)] Loss: -1022.406541\n",
      "    epoch          : 889\n",
      "    loss           : -1102.7520445890677\n",
      "    val_loss       : -1093.9840897787603\n",
      "    val_log_likelihood: 1518.020330462159\n",
      "    val_log_marginal: 1110.0568021196652\n",
      "Train Epoch: 890 [512/17352 (3%)] Loss: -1137.441284\n",
      "Train Epoch: 890 [10965/17352 (63%)] Loss: -1016.200135\n",
      "Train Epoch: 890 [17143/17352 (99%)] Loss: -1164.843353\n",
      "    epoch          : 890\n",
      "    loss           : -1107.3077556003636\n",
      "    val_loss       : -1102.1318604799603\n",
      "    val_log_likelihood: 1528.5678357651875\n",
      "    val_log_marginal: 1113.465473776742\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch890.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 891 [512/17352 (3%)] Loss: -1140.020752\n",
      "Train Epoch: 891 [10787/17352 (62%)] Loss: -1113.832761\n",
      "Train Epoch: 891 [17106/17352 (99%)] Loss: -1205.382037\n",
      "    epoch          : 891\n",
      "    loss           : -1101.9824237582038\n",
      "    val_loss       : -971.0334876306713\n",
      "    val_log_likelihood: 1529.1832747991436\n",
      "    val_log_marginal: 1119.409795681885\n",
      "Train Epoch: 892 [512/17352 (3%)] Loss: -1152.329468\n",
      "Train Epoch: 892 [9973/17352 (57%)] Loss: -1137.465495\n",
      "Train Epoch: 892 [17143/17352 (99%)] Loss: -1135.496074\n",
      "    epoch          : 892\n",
      "    loss           : -1062.2075862458923\n",
      "    val_loss       : -1064.9651518023102\n",
      "    val_log_likelihood: 1515.6275004273216\n",
      "    val_log_marginal: 1103.0961053263957\n",
      "Train Epoch: 893 [512/17352 (3%)] Loss: -1138.156128\n",
      "Train Epoch: 893 [10935/17352 (63%)] Loss: -1149.644661\n",
      "Train Epoch: 893 [16958/17352 (98%)] Loss: -1066.808507\n",
      "    epoch          : 893\n",
      "    loss           : -1089.9778751969277\n",
      "    val_loss       : -1082.1514384359186\n",
      "    val_log_likelihood: 1520.0455534100472\n",
      "    val_log_marginal: 1110.3826070530229\n",
      "Train Epoch: 894 [512/17352 (3%)] Loss: -993.972839\n",
      "Train Epoch: 894 [9955/17352 (57%)] Loss: -1105.950138\n",
      "Train Epoch: 894 [16923/17352 (98%)] Loss: -1071.350649\n",
      "    epoch          : 894\n",
      "    loss           : -1087.8872704873172\n",
      "    val_loss       : -1028.5171736182704\n",
      "    val_log_likelihood: 1515.0494540454376\n",
      "    val_log_marginal: 1095.3975713076286\n",
      "Train Epoch: 895 [512/17352 (3%)] Loss: -1116.949585\n",
      "Train Epoch: 895 [9874/17352 (57%)] Loss: -1095.446417\n",
      "Train Epoch: 895 [16872/17352 (97%)] Loss: -1153.926227\n",
      "    epoch          : 895\n",
      "    loss           : -1087.7611689626358\n",
      "    val_loss       : -1054.5608884259004\n",
      "    val_log_likelihood: 1530.1967403029628\n",
      "    val_log_marginal: 1118.0404762153305\n",
      "Train Epoch: 896 [512/17352 (3%)] Loss: -1146.246460\n",
      "Train Epoch: 896 [9583/17352 (55%)] Loss: -1172.441456\n",
      "Train Epoch: 896 [16934/17352 (98%)] Loss: -817.593183\n",
      "    epoch          : 896\n",
      "    loss           : -1099.3505876564636\n",
      "    val_loss       : -1051.7446124080034\n",
      "    val_log_likelihood: 1534.3674518056039\n",
      "    val_log_marginal: 1124.405334984209\n",
      "Train Epoch: 897 [512/17352 (3%)] Loss: -1153.093506\n",
      "Train Epoch: 897 [10716/17352 (62%)] Loss: -1175.697547\n",
      "Train Epoch: 897 [17143/17352 (99%)] Loss: -1225.010794\n",
      "    epoch          : 897\n",
      "    loss           : -1100.0556572415246\n",
      "    val_loss       : -1104.2740336871395\n",
      "    val_log_likelihood: 1533.5178390019387\n",
      "    val_log_marginal: 1118.8249266781547\n",
      "Train Epoch: 898 [512/17352 (3%)] Loss: -1144.926514\n",
      "Train Epoch: 898 [10926/17352 (63%)] Loss: -1163.705890\n",
      "Train Epoch: 898 [17263/17352 (99%)] Loss: -1150.778646\n",
      "    epoch          : 898\n",
      "    loss           : -1114.0604200023988\n",
      "    val_loss       : -1015.0304108334329\n",
      "    val_log_likelihood: 1526.704706938304\n",
      "    val_log_marginal: 1084.1342337673336\n",
      "Train Epoch: 899 [512/17352 (3%)] Loss: -1126.867554\n",
      "Train Epoch: 899 [10930/17352 (63%)] Loss: -834.701181\n",
      "Train Epoch: 899 [17153/17352 (99%)] Loss: -249.176175\n",
      "    epoch          : 899\n",
      "    loss           : -912.6312022184857\n",
      "    val_loss       : -412.26639216394284\n",
      "    val_log_likelihood: 1408.7774886391228\n",
      "    val_log_marginal: 435.21523460752763\n",
      "Train Epoch: 900 [512/17352 (3%)] Loss: -466.593079\n",
      "Train Epoch: 900 [10471/17352 (60%)] Loss: -970.053488\n",
      "Train Epoch: 900 [16882/17352 (97%)] Loss: -304.129805\n",
      "    epoch          : 900\n",
      "    loss           : -787.7827593906962\n",
      "    val_loss       : -245.9797659963805\n",
      "    val_log_likelihood: 1427.9071090998912\n",
      "    val_log_marginal: 298.0139823232361\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch900.pth ...\n",
      "Train Epoch: 901 [512/17352 (3%)] Loss: -334.961304\n",
      "Train Epoch: 901 [9558/17352 (55%)] Loss: -742.533620\n",
      "Train Epoch: 901 [17153/17352 (99%)] Loss: -714.449126\n",
      "    epoch          : 901\n",
      "    loss           : -583.0477206845957\n",
      "    val_loss       : -718.864929272214\n",
      "    val_log_likelihood: 1375.0438211990893\n",
      "    val_log_marginal: 772.828655217884\n",
      "Train Epoch: 902 [512/17352 (3%)] Loss: -876.467957\n",
      "Train Epoch: 902 [10481/17352 (60%)] Loss: -997.344326\n",
      "Train Epoch: 902 [16887/17352 (97%)] Loss: -1053.695823\n",
      "    epoch          : 902\n",
      "    loss           : -921.1745734908129\n",
      "    val_loss       : -1055.609572031223\n",
      "    val_log_likelihood: 1481.0180254449574\n",
      "    val_log_marginal: 1076.7323247479019\n",
      "Train Epoch: 903 [512/17352 (3%)] Loss: -1107.790894\n",
      "Train Epoch: 903 [10866/17352 (63%)] Loss: -1221.313966\n",
      "Train Epoch: 903 [17106/17352 (99%)] Loss: -996.211947\n",
      "    epoch          : 903\n",
      "    loss           : -1079.8518413846714\n",
      "    val_loss       : -1061.5086673408741\n",
      "    val_log_likelihood: 1492.004879687626\n",
      "    val_log_marginal: 1080.4203572327608\n",
      "Train Epoch: 904 [512/17352 (3%)] Loss: -1115.076172\n",
      "Train Epoch: 904 [10619/17352 (61%)] Loss: -1152.404894\n",
      "Train Epoch: 904 [16878/17352 (97%)] Loss: -1054.802354\n",
      "    epoch          : 904\n",
      "    loss           : -1089.255640156308\n",
      "    val_loss       : -1101.4778420532969\n",
      "    val_log_likelihood: 1509.7150070504183\n",
      "    val_log_marginal: 1115.5888359456396\n",
      "Train Epoch: 905 [512/17352 (3%)] Loss: -1151.255249\n",
      "Train Epoch: 905 [10818/17352 (62%)] Loss: -872.128450\n",
      "Train Epoch: 905 [16878/17352 (97%)] Loss: -908.117956\n",
      "    epoch          : 905\n",
      "    loss           : -1065.0711700834552\n",
      "    val_loss       : -1090.6753736889157\n",
      "    val_log_likelihood: 1517.1224939700721\n",
      "    val_log_marginal: 1117.3548639668293\n",
      "Train Epoch: 906 [512/17352 (3%)] Loss: -1148.256958\n",
      "Train Epoch: 906 [10215/17352 (59%)] Loss: -994.409614\n",
      "Train Epoch: 906 [17253/17352 (99%)] Loss: -953.302257\n",
      "    epoch          : 906\n",
      "    loss           : -1067.9769374784871\n",
      "    val_loss       : -1075.726774812099\n",
      "    val_log_likelihood: 1519.8920741710724\n",
      "    val_log_marginal: 1087.0788659697573\n",
      "Train Epoch: 907 [512/17352 (3%)] Loss: -1119.195923\n",
      "Train Epoch: 907 [9973/17352 (57%)] Loss: -923.114583\n",
      "Train Epoch: 907 [17133/17352 (99%)] Loss: -1007.554868\n",
      "    epoch          : 907\n",
      "    loss           : -1082.1098102796666\n",
      "    val_loss       : -1035.5925573338013\n",
      "    val_log_likelihood: 1526.7822540751974\n",
      "    val_log_marginal: 1120.5008958171738\n",
      "Train Epoch: 908 [512/17352 (3%)] Loss: -1147.817871\n",
      "Train Epoch: 908 [10384/17352 (60%)] Loss: -873.607479\n",
      "Train Epoch: 908 [17124/17352 (99%)] Loss: -999.908307\n",
      "    epoch          : 908\n",
      "    loss           : -1071.4477652402263\n",
      "    val_loss       : -1076.495904436066\n",
      "    val_log_likelihood: 1534.2123112882255\n",
      "    val_log_marginal: 1116.7101193091598\n",
      "Train Epoch: 909 [512/17352 (3%)] Loss: -1148.772339\n",
      "Train Epoch: 909 [10099/17352 (58%)] Loss: -1228.984049\n",
      "Train Epoch: 909 [16878/17352 (97%)] Loss: -1058.053757\n",
      "    epoch          : 909\n",
      "    loss           : -1072.1308570416816\n",
      "    val_loss       : -984.2927998061431\n",
      "    val_log_likelihood: 1528.614173087031\n",
      "    val_log_marginal: 1103.5490096672147\n",
      "Train Epoch: 910 [512/17352 (3%)] Loss: -1130.365479\n",
      "Train Epoch: 910 [10669/17352 (61%)] Loss: -915.466509\n",
      "Train Epoch: 910 [17153/17352 (99%)] Loss: -1095.577593\n",
      "    epoch          : 910\n",
      "    loss           : -1051.3405597008166\n",
      "    val_loss       : -976.4843265810568\n",
      "    val_log_likelihood: 1494.1514544540298\n",
      "    val_log_marginal: 985.5578144857201\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch910.pth ...\n",
      "Train Epoch: 911 [512/17352 (3%)] Loss: -1018.202637\n",
      "Train Epoch: 911 [9939/17352 (57%)] Loss: -1111.210708\n",
      "Train Epoch: 911 [16988/17352 (98%)] Loss: -854.182246\n",
      "    epoch          : 911\n",
      "    loss           : -968.1883552562973\n",
      "    val_loss       : -976.681416991663\n",
      "    val_log_likelihood: 1500.1808776582443\n",
      "    val_log_marginal: 1029.3624741605145\n",
      "Train Epoch: 912 [512/17352 (3%)] Loss: -1024.609985\n",
      "Train Epoch: 912 [10480/17352 (60%)] Loss: -1043.134272\n",
      "Train Epoch: 912 [17106/17352 (99%)] Loss: -870.447710\n",
      "    epoch          : 912\n",
      "    loss           : -1027.4294333046194\n",
      "    val_loss       : -1068.3935221565825\n",
      "    val_log_likelihood: 1519.4288513745905\n",
      "    val_log_marginal: 1087.1275286630969\n",
      "Train Epoch: 913 [512/17352 (3%)] Loss: -1113.228760\n",
      "Train Epoch: 913 [10130/17352 (58%)] Loss: -1150.236056\n",
      "Train Epoch: 913 [16872/17352 (97%)] Loss: -1180.847533\n",
      "    epoch          : 913\n",
      "    loss           : -1085.9761444663836\n",
      "    val_loss       : -1087.4979224090835\n",
      "    val_log_likelihood: 1534.3203816139896\n",
      "    val_log_marginal: 1111.3183705296176\n",
      "Train Epoch: 914 [512/17352 (3%)] Loss: -1136.414062\n",
      "Train Epoch: 914 [11182/17352 (64%)] Loss: -1249.184835\n",
      "Train Epoch: 914 [16958/17352 (98%)] Loss: -1015.901684\n",
      "    epoch          : 914\n",
      "    loss           : -1085.584160409392\n",
      "    val_loss       : -1054.7208525231158\n",
      "    val_log_likelihood: 1527.942580693851\n",
      "    val_log_marginal: 1117.7660904413701\n",
      "Train Epoch: 915 [512/17352 (3%)] Loss: -1155.298828\n",
      "Train Epoch: 915 [10425/17352 (60%)] Loss: -939.967805\n",
      "Train Epoch: 915 [17153/17352 (99%)] Loss: -1028.571232\n",
      "    epoch          : 915\n",
      "    loss           : -1041.8650011881618\n",
      "    val_loss       : -981.8772839866455\n",
      "    val_log_likelihood: 1446.0861044775875\n",
      "    val_log_marginal: 995.7877154005197\n",
      "Train Epoch: 916 [512/17352 (3%)] Loss: -1047.689941\n",
      "Train Epoch: 916 [10679/17352 (62%)] Loss: -984.625672\n",
      "Train Epoch: 916 [17263/17352 (99%)] Loss: -1105.172905\n",
      "    epoch          : 916\n",
      "    loss           : -1072.7603662184627\n",
      "    val_loss       : -1039.4472102686884\n",
      "    val_log_likelihood: 1530.273613211674\n",
      "    val_log_marginal: 1097.9108275995009\n",
      "Train Epoch: 917 [512/17352 (3%)] Loss: -1130.582764\n",
      "Train Epoch: 917 [9874/17352 (57%)] Loss: -1112.429002\n",
      "Train Epoch: 917 [16957/17352 (98%)] Loss: -1148.687002\n",
      "    epoch          : 917\n",
      "    loss           : -1077.495680778254\n",
      "    val_loss       : -1027.8755277033154\n",
      "    val_log_likelihood: 1523.7102758805365\n",
      "    val_log_marginal: 1102.559363755223\n",
      "Train Epoch: 918 [512/17352 (3%)] Loss: -1120.992310\n",
      "Train Epoch: 918 [10145/17352 (58%)] Loss: -1104.092442\n",
      "Train Epoch: 918 [16883/17352 (97%)] Loss: -1024.974229\n",
      "    epoch          : 918\n",
      "    loss           : -1010.903897277902\n",
      "    val_loss       : -1078.4562296778477\n",
      "    val_log_likelihood: 1529.1173543854131\n",
      "    val_log_marginal: 1105.2211986615466\n",
      "Train Epoch: 919 [512/17352 (3%)] Loss: -1139.905273\n",
      "Train Epoch: 919 [10597/17352 (61%)] Loss: -1054.439008\n",
      "Train Epoch: 919 [17101/17352 (99%)] Loss: -1004.406319\n",
      "    epoch          : 919\n",
      "    loss           : -1020.1125406189292\n",
      "    val_loss       : -1029.5102144058021\n",
      "    val_log_likelihood: 1509.6755043859325\n",
      "    val_log_marginal: 1058.8010760754955\n",
      "Train Epoch: 920 [512/17352 (3%)] Loss: -1091.699341\n",
      "Train Epoch: 920 [10241/17352 (59%)] Loss: -874.222174\n",
      "Train Epoch: 920 [17108/17352 (99%)] Loss: -991.316007\n",
      "    epoch          : 920\n",
      "    loss           : -1051.9889731189194\n",
      "    val_loss       : -1084.9626298486319\n",
      "    val_log_likelihood: 1518.607250633216\n",
      "    val_log_marginal: 1095.2996802922935\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch920.pth ...\n",
      "Train Epoch: 921 [512/17352 (3%)] Loss: -1126.365479\n",
      "Train Epoch: 921 [10261/17352 (59%)] Loss: -1118.248111\n",
      "Train Epoch: 921 [16883/17352 (97%)] Loss: -1039.969722\n",
      "    epoch          : 921\n",
      "    loss           : -1057.4470855616935\n",
      "    val_loss       : -1060.017521932657\n",
      "    val_log_likelihood: 1531.19097682839\n",
      "    val_log_marginal: 1109.3755973496764\n",
      "Train Epoch: 922 [512/17352 (3%)] Loss: -1133.930786\n",
      "Train Epoch: 922 [10216/17352 (59%)] Loss: -739.118122\n",
      "Train Epoch: 922 [16883/17352 (97%)] Loss: -1128.546639\n",
      "    epoch          : 922\n",
      "    loss           : -1064.641010610907\n",
      "    val_loss       : -1027.6080403369901\n",
      "    val_log_likelihood: 1502.1351858736953\n",
      "    val_log_marginal: 1068.5114971820287\n",
      "Train Epoch: 923 [512/17352 (3%)] Loss: -1061.848022\n",
      "Train Epoch: 923 [10520/17352 (61%)] Loss: -988.098412\n",
      "Train Epoch: 923 [17064/17352 (98%)] Loss: -1112.258757\n",
      "    epoch          : 923\n",
      "    loss           : -1087.5865665080844\n",
      "    val_loss       : -1089.201992002065\n",
      "    val_log_likelihood: 1534.5287396357567\n",
      "    val_log_marginal: 1121.6010714560286\n",
      "Train Epoch: 924 [512/17352 (3%)] Loss: -1138.102051\n",
      "Train Epoch: 924 [10001/17352 (58%)] Loss: -1161.047314\n",
      "Train Epoch: 924 [17143/17352 (99%)] Loss: -967.066089\n",
      "    epoch          : 924\n",
      "    loss           : -1055.0320007075534\n",
      "    val_loss       : -1062.6747746342744\n",
      "    val_log_likelihood: 1530.6659370947073\n",
      "    val_log_marginal: 1103.2681058063554\n",
      "Train Epoch: 925 [512/17352 (3%)] Loss: -991.380249\n",
      "Train Epoch: 925 [10551/17352 (61%)] Loss: -1025.959645\n",
      "Train Epoch: 925 [17335/17352 (100%)] Loss: -1161.538854\n",
      "    epoch          : 925\n",
      "    loss           : -1054.412055324766\n",
      "    val_loss       : -861.7937348284775\n",
      "    val_log_likelihood: 1472.106044772878\n",
      "    val_log_marginal: 1005.7762103964923\n",
      "Train Epoch: 926 [512/17352 (3%)] Loss: -884.079590\n",
      "Train Epoch: 926 [10208/17352 (59%)] Loss: -1129.634960\n",
      "Train Epoch: 926 [17016/17352 (98%)] Loss: -1125.025568\n",
      "    epoch          : 926\n",
      "    loss           : -1078.6693937741259\n",
      "    val_loss       : -1088.122546432494\n",
      "    val_log_likelihood: 1541.7645565786888\n",
      "    val_log_marginal: 1129.3551835368585\n",
      "Train Epoch: 927 [512/17352 (3%)] Loss: -1151.208740\n",
      "Train Epoch: 927 [10235/17352 (59%)] Loss: -1239.593099\n",
      "Train Epoch: 927 [16883/17352 (97%)] Loss: -1224.934095\n",
      "    epoch          : 927\n",
      "    loss           : -1120.444740758081\n",
      "    val_loss       : -1117.6576166680477\n",
      "    val_log_likelihood: 1547.6593380251627\n",
      "    val_log_marginal: 1138.7925591841708\n",
      "Train Epoch: 928 [512/17352 (3%)] Loss: -1168.281860\n",
      "Train Epoch: 928 [10407/17352 (60%)] Loss: -1136.033933\n",
      "Train Epoch: 928 [17064/17352 (98%)] Loss: -1017.918023\n",
      "    epoch          : 928\n",
      "    loss           : -930.8386687418747\n",
      "    val_loss       : -914.4619065192677\n",
      "    val_log_likelihood: 1458.8540612144159\n",
      "    val_log_marginal: 999.4271721967534\n",
      "Train Epoch: 929 [512/17352 (3%)] Loss: -1033.543213\n",
      "Train Epoch: 929 [10260/17352 (59%)] Loss: -471.846654\n",
      "Train Epoch: 929 [17108/17352 (99%)] Loss: -523.586851\n",
      "    epoch          : 929\n",
      "    loss           : -903.9752639960025\n",
      "    val_loss       : -920.2126717836452\n",
      "    val_log_likelihood: 1471.5600100489876\n",
      "    val_log_marginal: 1017.384961206998\n",
      "Train Epoch: 930 [512/17352 (3%)] Loss: -901.769348\n",
      "Train Epoch: 930 [10294/17352 (59%)] Loss: -1129.442605\n",
      "Train Epoch: 930 [16887/17352 (97%)] Loss: -1021.415956\n",
      "    epoch          : 930\n",
      "    loss           : -965.8372955732808\n",
      "    val_loss       : -1046.1346526588088\n",
      "    val_log_likelihood: 1512.71330074861\n",
      "    val_log_marginal: 1092.156529941905\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch930.pth ...\n",
      "Train Epoch: 931 [512/17352 (3%)] Loss: -1125.783691\n",
      "Train Epoch: 931 [10433/17352 (60%)] Loss: -1140.018522\n",
      "Train Epoch: 931 [17044/17352 (98%)] Loss: -1073.662295\n",
      "    epoch          : 931\n",
      "    loss           : -985.5103590274384\n",
      "    val_loss       : -1036.9762624481011\n",
      "    val_log_likelihood: 1522.5984226584424\n",
      "    val_log_marginal: 1106.6062193531488\n",
      "Train Epoch: 932 [512/17352 (3%)] Loss: -1142.816284\n",
      "Train Epoch: 932 [10779/17352 (62%)] Loss: -1185.980964\n",
      "Train Epoch: 932 [17253/17352 (99%)] Loss: -1178.410625\n",
      "    epoch          : 932\n",
      "    loss           : -1098.1299772460056\n",
      "    val_loss       : -1110.966132057371\n",
      "    val_log_likelihood: 1541.577399842236\n",
      "    val_log_marginal: 1130.4140893083838\n",
      "Train Epoch: 933 [512/17352 (3%)] Loss: -1161.558350\n",
      "Train Epoch: 933 [10508/17352 (61%)] Loss: -1224.588832\n",
      "Train Epoch: 933 [17143/17352 (99%)] Loss: -1203.270198\n",
      "    epoch          : 933\n",
      "    loss           : -1123.2281426586646\n",
      "    val_loss       : -1022.2818749612661\n",
      "    val_log_likelihood: 1535.3586820020907\n",
      "    val_log_marginal: 1097.5026146447403\n",
      "Train Epoch: 934 [512/17352 (3%)] Loss: -1127.225464\n",
      "Train Epoch: 934 [10440/17352 (60%)] Loss: -917.730842\n",
      "Train Epoch: 934 [17153/17352 (99%)] Loss: -928.567181\n",
      "    epoch          : 934\n",
      "    loss           : -1049.7428036440176\n",
      "    val_loss       : -893.6845480384819\n",
      "    val_log_likelihood: 1526.0540437331197\n",
      "    val_log_marginal: 915.2052783293902\n",
      "Train Epoch: 935 [512/17352 (3%)] Loss: -768.647522\n",
      "Train Epoch: 935 [10480/17352 (60%)] Loss: -1175.238939\n",
      "Train Epoch: 935 [17124/17352 (99%)] Loss: -1092.639055\n",
      "    epoch          : 935\n",
      "    loss           : -958.5105792193011\n",
      "    val_loss       : -870.2873181578469\n",
      "    val_log_likelihood: 1500.0555531168459\n",
      "    val_log_marginal: 933.9566216179738\n",
      "Train Epoch: 936 [512/17352 (3%)] Loss: -983.809998\n",
      "Train Epoch: 936 [10700/17352 (62%)] Loss: -1055.363594\n",
      "Train Epoch: 936 [16882/17352 (97%)] Loss: -962.251736\n",
      "    epoch          : 936\n",
      "    loss           : -977.0192884617868\n",
      "    val_loss       : -997.8693855371138\n",
      "    val_log_likelihood: 1529.437490774242\n",
      "    val_log_marginal: 1064.5707524750828\n",
      "Train Epoch: 937 [512/17352 (3%)] Loss: -1091.863037\n",
      "Train Epoch: 937 [11051/17352 (64%)] Loss: -981.016599\n",
      "Train Epoch: 937 [17335/17352 (100%)] Loss: -1133.626284\n",
      "    epoch          : 937\n",
      "    loss           : -1071.8544953446\n",
      "    val_loss       : -1041.1380340154128\n",
      "    val_log_likelihood: 1513.2883741249054\n",
      "    val_log_marginal: 1066.505632139629\n",
      "Train Epoch: 938 [512/17352 (3%)] Loss: 93.678131\n",
      "Train Epoch: 938 [10102/17352 (58%)] Loss: -1080.818921\n",
      "Train Epoch: 938 [17253/17352 (99%)] Loss: -861.376850\n",
      "    epoch          : 938\n",
      "    loss           : -827.5136043103994\n",
      "    val_loss       : -840.4125444543987\n",
      "    val_log_likelihood: 1443.5307856521806\n",
      "    val_log_marginal: 876.6165060304112\n",
      "Train Epoch: 939 [512/17352 (3%)] Loss: -841.817017\n",
      "Train Epoch: 939 [10820/17352 (62%)] Loss: -1006.995536\n",
      "Train Epoch: 939 [16957/17352 (98%)] Loss: -733.479102\n",
      "    epoch          : 939\n",
      "    loss           : -932.6858203129406\n",
      "    val_loss       : -837.9448035938829\n",
      "    val_log_likelihood: 1434.9911637109124\n",
      "    val_log_marginal: 859.1801310682876\n",
      "Train Epoch: 940 [512/17352 (3%)] Loss: -860.762878\n",
      "Train Epoch: 940 [10373/17352 (60%)] Loss: -1099.406112\n",
      "Train Epoch: 940 [16992/17352 (98%)] Loss: -1065.004086\n",
      "    epoch          : 940\n",
      "    loss           : -1001.7770677040498\n",
      "    val_loss       : -1068.1384908028238\n",
      "    val_log_likelihood: 1502.3938833275745\n",
      "    val_log_marginal: 1087.860945193877\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch940.pth ...\n",
      "Train Epoch: 941 [512/17352 (3%)] Loss: -1122.086060\n",
      "Train Epoch: 941 [10303/17352 (59%)] Loss: 564.227584\n",
      "Train Epoch: 941 [17153/17352 (99%)] Loss: -1193.738567\n",
      "    epoch          : 941\n",
      "    loss           : -1026.9690535857144\n",
      "    val_loss       : -1062.8217956614276\n",
      "    val_log_likelihood: 1518.780462680724\n",
      "    val_log_marginal: 1087.6774356415815\n",
      "Train Epoch: 942 [512/17352 (3%)] Loss: -1120.288818\n",
      "Train Epoch: 942 [9774/17352 (56%)] Loss: -1111.553020\n",
      "Train Epoch: 942 [16887/17352 (97%)] Loss: -587.542325\n",
      "    epoch          : 942\n",
      "    loss           : -924.5195148937742\n",
      "    val_loss       : -800.4866762344743\n",
      "    val_log_likelihood: 1520.984159862426\n",
      "    val_log_marginal: 829.2799471885198\n",
      "Train Epoch: 943 [512/17352 (3%)] Loss: -922.030396\n",
      "Train Epoch: 943 [10564/17352 (61%)] Loss: -555.117537\n",
      "Train Epoch: 943 [17335/17352 (100%)] Loss: -980.372253\n",
      "    epoch          : 943\n",
      "    loss           : -785.8926243284031\n",
      "    val_loss       : -972.2293817945723\n",
      "    val_log_likelihood: 1454.0701630335802\n",
      "    val_log_marginal: 996.9764018994094\n",
      "Train Epoch: 944 [512/17352 (3%)] Loss: -793.872314\n",
      "Train Epoch: 944 [10158/17352 (59%)] Loss: -1147.642117\n",
      "Train Epoch: 944 [17044/17352 (98%)] Loss: -964.524073\n",
      "    epoch          : 944\n",
      "    loss           : -1013.2803349457765\n",
      "    val_loss       : -1080.5269584360444\n",
      "    val_log_likelihood: 1521.0074854590844\n",
      "    val_log_marginal: 1100.3619613017793\n",
      "Train Epoch: 945 [512/17352 (3%)] Loss: -1125.121948\n",
      "Train Epoch: 945 [9961/17352 (57%)] Loss: -1048.157330\n",
      "Train Epoch: 945 [17253/17352 (99%)] Loss: -1139.121899\n",
      "    epoch          : 945\n",
      "    loss           : -1080.18861367456\n",
      "    val_loss       : -1092.1707758598893\n",
      "    val_log_likelihood: 1520.198207300748\n",
      "    val_log_marginal: 1106.396691316576\n",
      "Train Epoch: 946 [512/17352 (3%)] Loss: -1128.717529\n",
      "Train Epoch: 946 [10283/17352 (59%)] Loss: -1166.664826\n",
      "Train Epoch: 946 [16939/17352 (98%)] Loss: -1013.035586\n",
      "    epoch          : 946\n",
      "    loss           : -1099.3227327520588\n",
      "    val_loss       : -1073.0741897446728\n",
      "    val_log_likelihood: 1513.9775238933887\n",
      "    val_log_marginal: 1104.9009556733313\n",
      "Train Epoch: 947 [512/17352 (3%)] Loss: -1136.923096\n",
      "Train Epoch: 947 [10331/17352 (60%)] Loss: -1181.850571\n",
      "Train Epoch: 947 [16882/17352 (97%)] Loss: -1021.763307\n",
      "    epoch          : 947\n",
      "    loss           : -1086.7866070250443\n",
      "    val_loss       : -1042.1007619476559\n",
      "    val_log_likelihood: 1540.310473250491\n",
      "    val_log_marginal: 1127.8431363055813\n",
      "Train Epoch: 948 [512/17352 (3%)] Loss: -1157.671021\n",
      "Train Epoch: 948 [10097/17352 (58%)] Loss: -1039.315414\n",
      "Train Epoch: 948 [16878/17352 (97%)] Loss: -1176.247853\n",
      "    epoch          : 948\n",
      "    loss           : -1116.0437837390032\n",
      "    val_loss       : -1111.6025503058845\n",
      "    val_log_likelihood: 1547.9119822160353\n",
      "    val_log_marginal: 1145.6602263439092\n",
      "Train Epoch: 949 [512/17352 (3%)] Loss: -1169.091064\n",
      "Train Epoch: 949 [10069/17352 (58%)] Loss: -1111.184398\n",
      "Train Epoch: 949 [16882/17352 (97%)] Loss: -1019.657366\n",
      "    epoch          : 949\n",
      "    loss           : -1100.7123780083302\n",
      "    val_loss       : -1078.979772926766\n",
      "    val_log_likelihood: 1547.3386787073177\n",
      "    val_log_marginal: 1105.5322785079384\n",
      "Train Epoch: 950 [512/17352 (3%)] Loss: -1132.403564\n",
      "Train Epoch: 950 [10326/17352 (60%)] Loss: -1149.316740\n",
      "Train Epoch: 950 [17263/17352 (99%)] Loss: -903.330479\n",
      "    epoch          : 950\n",
      "    loss           : -1081.3217506416622\n",
      "    val_loss       : -841.0476211213875\n",
      "    val_log_likelihood: 1529.6189003023092\n",
      "    val_log_marginal: 863.4075419684762\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch950.pth ...\n",
      "Train Epoch: 951 [512/17352 (3%)] Loss: -917.030212\n",
      "Train Epoch: 951 [10066/17352 (58%)] Loss: -852.934200\n",
      "Train Epoch: 951 [17126/17352 (99%)] Loss: -369.576594\n",
      "    epoch          : 951\n",
      "    loss           : -804.3571608433006\n",
      "    val_loss       : -880.853774309672\n",
      "    val_log_likelihood: 1460.2990881325675\n",
      "    val_log_marginal: 912.1602217548964\n",
      "Train Epoch: 952 [512/17352 (3%)] Loss: -930.910767\n",
      "Train Epoch: 952 [10043/17352 (58%)] Loss: -1004.861979\n",
      "Train Epoch: 952 [17153/17352 (99%)] Loss: -1033.841797\n",
      "    epoch          : 952\n",
      "    loss           : -943.0318361501434\n",
      "    val_loss       : -773.725891450053\n",
      "    val_log_likelihood: 1460.8429960336723\n",
      "    val_log_marginal: 835.3899718976677\n",
      "Train Epoch: 953 [512/17352 (3%)] Loss: -835.312988\n",
      "Train Epoch: 953 [10186/17352 (59%)] Loss: -922.946721\n",
      "Train Epoch: 953 [17044/17352 (98%)] Loss: -1043.860243\n",
      "    epoch          : 953\n",
      "    loss           : -905.8360721831984\n",
      "    val_loss       : -1000.6752658731574\n",
      "    val_log_likelihood: 1483.1797322484313\n",
      "    val_log_marginal: 1016.4567688661211\n",
      "Train Epoch: 954 [512/17352 (3%)] Loss: -1030.445068\n",
      "Train Epoch: 954 [10737/17352 (62%)] Loss: -1062.649260\n",
      "Train Epoch: 954 [16934/17352 (98%)] Loss: -985.803407\n",
      "    epoch          : 954\n",
      "    loss           : -1054.0263292119205\n",
      "    val_loss       : -1083.6198236063253\n",
      "    val_log_likelihood: 1529.8161173830335\n",
      "    val_log_marginal: 1113.3886280783474\n",
      "Train Epoch: 955 [512/17352 (3%)] Loss: -1147.342896\n",
      "Train Epoch: 955 [9804/17352 (57%)] Loss: -1156.726792\n",
      "Train Epoch: 955 [17106/17352 (99%)] Loss: -1010.812035\n",
      "    epoch          : 955\n",
      "    loss           : -1073.642862811342\n",
      "    val_loss       : -965.1574430338385\n",
      "    val_log_likelihood: 1499.753295985898\n",
      "    val_log_marginal: 1077.024591601473\n",
      "Train Epoch: 956 [512/17352 (3%)] Loss: -1091.213013\n",
      "Train Epoch: 956 [10678/17352 (62%)] Loss: -1228.229744\n",
      "Train Epoch: 956 [17126/17352 (99%)] Loss: -1192.056551\n",
      "    epoch          : 956\n",
      "    loss           : -1096.1356596254402\n",
      "    val_loss       : -1093.1537124046158\n",
      "    val_log_likelihood: 1532.4116979732419\n",
      "    val_log_marginal: 1124.6265056919397\n",
      "Train Epoch: 957 [512/17352 (3%)] Loss: -1148.151855\n",
      "Train Epoch: 957 [10247/17352 (59%)] Loss: -1146.888551\n",
      "Train Epoch: 957 [16958/17352 (98%)] Loss: -1135.391755\n",
      "    epoch          : 957\n",
      "    loss           : -1109.5143440277134\n",
      "    val_loss       : -1015.3662138325416\n",
      "    val_log_likelihood: 1540.1628530037885\n",
      "    val_log_marginal: 1057.5556150591633\n",
      "Train Epoch: 958 [512/17352 (3%)] Loss: -1074.904419\n",
      "Train Epoch: 958 [10297/17352 (59%)] Loss: -884.532899\n",
      "Train Epoch: 958 [16939/17352 (98%)] Loss: -1224.964627\n",
      "    epoch          : 958\n",
      "    loss           : -1096.0199153308647\n",
      "    val_loss       : -1129.0475598070611\n",
      "    val_log_likelihood: 1549.6753508221116\n",
      "    val_log_marginal: 1139.644557882227\n",
      "Train Epoch: 959 [512/17352 (3%)] Loss: -1025.410645\n",
      "Train Epoch: 959 [10138/17352 (58%)] Loss: -1067.710901\n",
      "Train Epoch: 959 [16887/17352 (97%)] Loss: -1160.432708\n",
      "    epoch          : 959\n",
      "    loss           : -1111.498842475707\n",
      "    val_loss       : -1113.761663483831\n",
      "    val_log_likelihood: 1554.351059410925\n",
      "    val_log_marginal: 1144.7879074524028\n",
      "Train Epoch: 960 [512/17352 (3%)] Loss: -1176.568970\n",
      "Train Epoch: 960 [10738/17352 (62%)] Loss: -1094.664773\n",
      "Train Epoch: 960 [16878/17352 (97%)] Loss: -1188.649201\n",
      "    epoch          : 960\n",
      "    loss           : -1110.5469860287885\n",
      "    val_loss       : -1118.3570740962807\n",
      "    val_log_likelihood: 1553.0165445774603\n",
      "    val_log_marginal: 1140.5098960454159\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch960.pth ...\n",
      "Train Epoch: 961 [512/17352 (3%)] Loss: -1175.284302\n",
      "Train Epoch: 961 [10494/17352 (60%)] Loss: -1179.432776\n",
      "Train Epoch: 961 [16887/17352 (97%)] Loss: -975.019139\n",
      "    epoch          : 961\n",
      "    loss           : -1116.299081063812\n",
      "    val_loss       : -1065.5626976060796\n",
      "    val_log_likelihood: 1551.589203955031\n",
      "    val_log_marginal: 1090.4569745771173\n",
      "Train Epoch: 962 [512/17352 (3%)] Loss: -1120.649780\n",
      "Train Epoch: 962 [9930/17352 (57%)] Loss: -1041.517226\n",
      "Train Epoch: 962 [17263/17352 (99%)] Loss: -1095.923351\n",
      "    epoch          : 962\n",
      "    loss           : -1092.1387140820882\n",
      "    val_loss       : -1105.8901066656074\n",
      "    val_log_likelihood: 1554.5429677311754\n",
      "    val_log_marginal: 1128.9393059247489\n",
      "Train Epoch: 963 [512/17352 (3%)] Loss: -1151.215088\n",
      "Train Epoch: 963 [10789/17352 (62%)] Loss: -1192.853343\n",
      "Train Epoch: 963 [16958/17352 (98%)] Loss: -1103.487964\n",
      "    epoch          : 963\n",
      "    loss           : -1120.4165871991806\n",
      "    val_loss       : -1134.0071361024623\n",
      "    val_log_likelihood: 1563.7445697288565\n",
      "    val_log_marginal: 1149.588571217313\n",
      "Train Epoch: 964 [512/17352 (3%)] Loss: -1172.208618\n",
      "Train Epoch: 964 [10558/17352 (61%)] Loss: -868.517774\n",
      "Train Epoch: 964 [17108/17352 (99%)] Loss: -1052.494965\n",
      "    epoch          : 964\n",
      "    loss           : -1080.912222000988\n",
      "    val_loss       : -1027.999912427552\n",
      "    val_log_likelihood: 1531.097172481546\n",
      "    val_log_marginal: 1045.2359785332485\n",
      "Train Epoch: 965 [512/17352 (3%)] Loss: -934.755615\n",
      "Train Epoch: 965 [10286/17352 (59%)] Loss: -1148.573679\n",
      "Train Epoch: 965 [17263/17352 (99%)] Loss: -1166.547005\n",
      "    epoch          : 965\n",
      "    loss           : -1048.4722696367642\n",
      "    val_loss       : -1020.5067484445156\n",
      "    val_log_likelihood: 1521.4057273379603\n",
      "    val_log_marginal: 1069.8445151175686\n",
      "Train Epoch: 966 [512/17352 (3%)] Loss: -1100.290649\n",
      "Train Epoch: 966 [10191/17352 (59%)] Loss: -1170.061589\n",
      "Train Epoch: 966 [17126/17352 (99%)] Loss: -1013.655242\n",
      "    epoch          : 966\n",
      "    loss           : -1108.4134111047993\n",
      "    val_loss       : -1113.1270716875476\n",
      "    val_log_likelihood: 1558.5383381069475\n",
      "    val_log_marginal: 1133.9348243476668\n",
      "Train Epoch: 967 [512/17352 (3%)] Loss: -1051.123779\n",
      "Train Epoch: 967 [9982/17352 (58%)] Loss: -1159.240579\n",
      "Train Epoch: 967 [17126/17352 (99%)] Loss: -1182.189647\n",
      "    epoch          : 967\n",
      "    loss           : -1114.852262379308\n",
      "    val_loss       : -1109.7405345017164\n",
      "    val_log_likelihood: 1559.461556600789\n",
      "    val_log_marginal: 1136.3112138301126\n",
      "Train Epoch: 968 [512/17352 (3%)] Loss: -1169.003296\n",
      "Train Epoch: 968 [10039/17352 (58%)] Loss: -947.682904\n",
      "Train Epoch: 968 [17253/17352 (99%)] Loss: -1184.535547\n",
      "    epoch          : 968\n",
      "    loss           : -1124.8376897563728\n",
      "    val_loss       : -1105.0700685129193\n",
      "    val_log_likelihood: 1560.635810670016\n",
      "    val_log_marginal: 1132.406460888602\n",
      "Train Epoch: 969 [512/17352 (3%)] Loss: -1015.496277\n",
      "Train Epoch: 969 [10684/17352 (62%)] Loss: -1186.761273\n",
      "Train Epoch: 969 [16878/17352 (97%)] Loss: -1214.341755\n",
      "    epoch          : 969\n",
      "    loss           : -1110.7767595669625\n",
      "    val_loss       : -1115.4668924358991\n",
      "    val_log_likelihood: 1557.8647731153778\n",
      "    val_log_marginal: 1128.974715975971\n",
      "Train Epoch: 970 [512/17352 (3%)] Loss: -1013.596497\n",
      "Train Epoch: 970 [10165/17352 (59%)] Loss: -1206.875625\n",
      "Train Epoch: 970 [17124/17352 (99%)] Loss: -1074.777314\n",
      "    epoch          : 970\n",
      "    loss           : -1111.5368896008927\n",
      "    val_loss       : -1111.8890953389741\n",
      "    val_log_likelihood: 1558.1288222277708\n",
      "    val_log_marginal: 1129.954359494918\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch970.pth ...\n",
      "Train Epoch: 971 [512/17352 (3%)] Loss: -1155.868042\n",
      "Train Epoch: 971 [10449/17352 (60%)] Loss: -1190.303750\n",
      "Train Epoch: 971 [16872/17352 (97%)] Loss: -1070.661037\n",
      "    epoch          : 971\n",
      "    loss           : -1044.4786764949786\n",
      "    val_loss       : -1006.7019040122059\n",
      "    val_log_likelihood: 1544.8095947162665\n",
      "    val_log_marginal: 1022.2389514679384\n",
      "Train Epoch: 972 [512/17352 (3%)] Loss: -1057.738770\n",
      "Train Epoch: 972 [10793/17352 (62%)] Loss: -1195.219258\n",
      "Train Epoch: 972 [17277/17352 (100%)] Loss: -1115.721897\n",
      "    epoch          : 972\n",
      "    loss           : -1059.9571470964177\n",
      "    val_loss       : -819.0966767297049\n",
      "    val_log_likelihood: 1510.3405849246776\n",
      "    val_log_marginal: 855.3566235842584\n",
      "Train Epoch: 973 [512/17352 (3%)] Loss: -891.805542\n",
      "Train Epoch: 973 [10840/17352 (62%)] Loss: -1147.577911\n",
      "Train Epoch: 973 [17126/17352 (99%)] Loss: -1142.344452\n",
      "    epoch          : 973\n",
      "    loss           : -1030.004965236268\n",
      "    val_loss       : -1083.0292624009635\n",
      "    val_log_likelihood: 1553.0819887159523\n",
      "    val_log_marginal: 1111.634137794049\n",
      "Train Epoch: 974 [512/17352 (3%)] Loss: -1144.631470\n",
      "Train Epoch: 974 [10587/17352 (61%)] Loss: -1131.303077\n",
      "Train Epoch: 974 [16882/17352 (97%)] Loss: -1181.439640\n",
      "    epoch          : 974\n",
      "    loss           : -1106.6942843668994\n",
      "    val_loss       : -1124.4511189009695\n",
      "    val_log_likelihood: 1565.580631972888\n",
      "    val_log_marginal: 1145.6137815048248\n",
      "Train Epoch: 975 [512/17352 (3%)] Loss: -1164.498779\n",
      "Train Epoch: 975 [10463/17352 (60%)] Loss: -1130.460565\n",
      "Train Epoch: 975 [17263/17352 (99%)] Loss: -1134.979523\n",
      "    epoch          : 975\n",
      "    loss           : -1093.2572303915192\n",
      "    val_loss       : -884.532110843805\n",
      "    val_log_likelihood: 1541.6732188104393\n",
      "    val_log_marginal: 994.2181519747706\n",
      "Train Epoch: 976 [512/17352 (3%)] Loss: -1018.124878\n",
      "Train Epoch: 976 [10230/17352 (59%)] Loss: -985.730578\n",
      "Train Epoch: 976 [17335/17352 (100%)] Loss: -1029.446631\n",
      "    epoch          : 976\n",
      "    loss           : -1077.7591522578034\n",
      "    val_loss       : -1067.0134386294053\n",
      "    val_log_likelihood: 1560.4005590787121\n",
      "    val_log_marginal: 1116.978756122899\n",
      "Train Epoch: 977 [512/17352 (3%)] Loss: -1142.255005\n",
      "Train Epoch: 977 [10253/17352 (59%)] Loss: -1054.232232\n",
      "Train Epoch: 977 [16872/17352 (97%)] Loss: -1183.388271\n",
      "    epoch          : 977\n",
      "    loss           : -1060.6128398102742\n",
      "    val_loss       : -1080.3760001076503\n",
      "    val_log_likelihood: 1565.4221337430579\n",
      "    val_log_marginal: 1147.4369441544613\n",
      "Train Epoch: 978 [512/17352 (3%)] Loss: -1182.112183\n",
      "Train Epoch: 978 [10332/17352 (60%)] Loss: -1189.108228\n",
      "Train Epoch: 978 [16878/17352 (97%)] Loss: -1025.643167\n",
      "    epoch          : 978\n",
      "    loss           : -1052.7514732560717\n",
      "    val_loss       : -1023.7655442318224\n",
      "    val_log_likelihood: 1530.5421733110672\n",
      "    val_log_marginal: 1091.2582316619555\n",
      "Train Epoch: 979 [512/17352 (3%)] Loss: -975.609680\n",
      "Train Epoch: 979 [10073/17352 (58%)] Loss: -1208.742433\n",
      "Train Epoch: 979 [17044/17352 (98%)] Loss: -1156.805312\n",
      "    epoch          : 979\n",
      "    loss           : -981.0289686223109\n",
      "    val_loss       : -1110.2181187102087\n",
      "    val_log_likelihood: 1553.153760811575\n",
      "    val_log_marginal: 1130.5903191803795\n",
      "Train Epoch: 980 [512/17352 (3%)] Loss: -1036.458740\n",
      "Train Epoch: 980 [10636/17352 (61%)] Loss: -1185.799889\n",
      "Train Epoch: 980 [16988/17352 (98%)] Loss: -1168.600188\n",
      "    epoch          : 980\n",
      "    loss           : -1110.7753130007259\n",
      "    val_loss       : -1114.1629362188044\n",
      "    val_log_likelihood: 1568.9681165885445\n",
      "    val_log_marginal: 1149.896502853698\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch980.pth ...\n",
      "Train Epoch: 981 [512/17352 (3%)] Loss: -1186.150635\n",
      "Train Epoch: 981 [10778/17352 (62%)] Loss: -1185.096294\n",
      "Train Epoch: 981 [16882/17352 (97%)] Loss: -1110.002146\n",
      "    epoch          : 981\n",
      "    loss           : -1068.8020148920539\n",
      "    val_loss       : -1111.521864625374\n",
      "    val_log_likelihood: 1565.033215456558\n",
      "    val_log_marginal: 1140.1059802922841\n",
      "Train Epoch: 982 [512/17352 (3%)] Loss: -1165.709717\n",
      "Train Epoch: 982 [10199/17352 (59%)] Loss: -1168.226493\n",
      "Train Epoch: 982 [17253/17352 (99%)] Loss: -1079.467720\n",
      "    epoch          : 982\n",
      "    loss           : -1098.6072063005136\n",
      "    val_loss       : -977.9217845759968\n",
      "    val_log_likelihood: 1548.3246130400382\n",
      "    val_log_marginal: 997.7314502304604\n",
      "Train Epoch: 983 [512/17352 (3%)] Loss: -1039.217285\n",
      "Train Epoch: 983 [10137/17352 (58%)] Loss: -1151.298058\n",
      "Train Epoch: 983 [17133/17352 (99%)] Loss: -989.265524\n",
      "    epoch          : 983\n",
      "    loss           : -1067.7856573020308\n",
      "    val_loss       : -1086.25829220417\n",
      "    val_log_likelihood: 1554.9728172132884\n",
      "    val_log_marginal: 1106.3845913588939\n",
      "Train Epoch: 984 [512/17352 (3%)] Loss: -1139.329956\n",
      "Train Epoch: 984 [10743/17352 (62%)] Loss: -958.803728\n",
      "Train Epoch: 984 [17044/17352 (98%)] Loss: -1202.309954\n",
      "    epoch          : 984\n",
      "    loss           : -1107.8322405707404\n",
      "    val_loss       : -1132.1743082550552\n",
      "    val_log_likelihood: 1569.5184891164188\n",
      "    val_log_marginal: 1145.0542217871593\n",
      "Train Epoch: 985 [512/17352 (3%)] Loss: -1031.232422\n",
      "Train Epoch: 985 [10818/17352 (62%)] Loss: -1120.730400\n",
      "Train Epoch: 985 [17153/17352 (99%)] Loss: -1130.890982\n",
      "    epoch          : 985\n",
      "    loss           : -1124.1697501357505\n",
      "    val_loss       : -1140.5592339746418\n",
      "    val_log_likelihood: 1572.7164238982118\n",
      "    val_log_marginal: 1152.5008635990364\n",
      "Train Epoch: 986 [512/17352 (3%)] Loss: -1182.764648\n",
      "Train Epoch: 986 [9956/17352 (57%)] Loss: -1158.104324\n",
      "Train Epoch: 986 [16922/17352 (98%)] Loss: -1079.065957\n",
      "    epoch          : 986\n",
      "    loss           : -1114.6014025733018\n",
      "    val_loss       : -1080.0611481262852\n",
      "    val_log_likelihood: 1573.9575893433594\n",
      "    val_log_marginal: 1104.0744875986081\n",
      "Train Epoch: 987 [512/17352 (3%)] Loss: -1129.401611\n",
      "Train Epoch: 987 [10460/17352 (60%)] Loss: -1111.023438\n",
      "Train Epoch: 987 [17277/17352 (100%)] Loss: -1259.216363\n",
      "    epoch          : 987\n",
      "    loss           : -1109.391697375881\n",
      "    val_loss       : -1076.8069829668414\n",
      "    val_log_likelihood: 1556.8345192128393\n",
      "    val_log_marginal: 1119.7762440274353\n",
      "Train Epoch: 988 [512/17352 (3%)] Loss: -1002.725586\n",
      "Train Epoch: 988 [9868/17352 (57%)] Loss: -1040.479009\n",
      "Train Epoch: 988 [17277/17352 (100%)] Loss: -1177.058018\n",
      "    epoch          : 988\n",
      "    loss           : -1111.425094047155\n",
      "    val_loss       : -1010.1538822337512\n",
      "    val_log_likelihood: 1562.0659170445003\n",
      "    val_log_marginal: 1068.7223813902287\n",
      "Train Epoch: 989 [512/17352 (3%)] Loss: -1094.214111\n",
      "Train Epoch: 989 [10621/17352 (61%)] Loss: -1171.182181\n",
      "Train Epoch: 989 [17277/17352 (100%)] Loss: -1035.960153\n",
      "    epoch          : 989\n",
      "    loss           : -1016.0440389592098\n",
      "    val_loss       : -1026.1532242543237\n",
      "    val_log_likelihood: 1524.795121487736\n",
      "    val_log_marginal: 1061.1839466587182\n",
      "Train Epoch: 990 [512/17352 (3%)] Loss: -1066.744873\n",
      "Train Epoch: 990 [10508/17352 (61%)] Loss: -1007.216146\n",
      "Train Epoch: 990 [16923/17352 (98%)] Loss: -896.242282\n",
      "    epoch          : 990\n",
      "    loss           : -1021.2649316725426\n",
      "    val_loss       : -797.0037000037672\n",
      "    val_log_likelihood: 1519.7373860469168\n",
      "    val_log_marginal: 842.1121553040005\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch990.pth ...\n",
      "Train Epoch: 991 [512/17352 (3%)] Loss: -883.403198\n",
      "Train Epoch: 991 [10518/17352 (61%)] Loss: -452.410206\n",
      "Train Epoch: 991 [16887/17352 (97%)] Loss: -962.849143\n",
      "    epoch          : 991\n",
      "    loss           : -855.3406244257555\n",
      "    val_loss       : -942.8123927541927\n",
      "    val_log_likelihood: 1478.0385348430898\n",
      "    val_log_marginal: 967.5744507564382\n",
      "Train Epoch: 992 [512/17352 (3%)] Loss: -800.156311\n",
      "Train Epoch: 992 [10486/17352 (60%)] Loss: -982.186244\n",
      "Train Epoch: 992 [17124/17352 (99%)] Loss: -865.373828\n",
      "    epoch          : 992\n",
      "    loss           : -983.608906794365\n",
      "    val_loss       : -862.0284950813483\n",
      "    val_log_likelihood: 1529.020046780371\n",
      "    val_log_marginal: 893.9324375401166\n",
      "Train Epoch: 993 [512/17352 (3%)] Loss: -497.831604\n",
      "Train Epoch: 993 [10754/17352 (62%)] Loss: -959.595245\n",
      "Train Epoch: 993 [17143/17352 (99%)] Loss: -1157.531032\n",
      "    epoch          : 993\n",
      "    loss           : -1025.4022451793924\n",
      "    val_loss       : -1066.0258101910704\n",
      "    val_log_likelihood: 1555.3742566017804\n",
      "    val_log_marginal: 1116.6731963239174\n",
      "Train Epoch: 994 [512/17352 (3%)] Loss: -417.387817\n",
      "Train Epoch: 994 [10446/17352 (60%)] Loss: -1180.878860\n",
      "Train Epoch: 994 [17133/17352 (99%)] Loss: -1209.562727\n",
      "    epoch          : 994\n",
      "    loss           : -1084.5296407193523\n",
      "    val_loss       : -1111.0394615743119\n",
      "    val_log_likelihood: 1563.295799551255\n",
      "    val_log_marginal: 1138.7738392958968\n",
      "Train Epoch: 995 [512/17352 (3%)] Loss: -1174.669556\n",
      "Train Epoch: 995 [9990/17352 (58%)] Loss: -1185.475457\n",
      "Train Epoch: 995 [17143/17352 (99%)] Loss: -1036.921352\n",
      "    epoch          : 995\n",
      "    loss           : -1130.5449264323593\n",
      "    val_loss       : -1058.4675192866875\n",
      "    val_log_likelihood: 1540.5036683096978\n",
      "    val_log_marginal: 1104.9341918238947\n",
      "Train Epoch: 996 [512/17352 (3%)] Loss: -1130.498291\n",
      "Train Epoch: 996 [10921/17352 (63%)] Loss: -1234.932128\n",
      "Train Epoch: 996 [17143/17352 (99%)] Loss: -1046.299087\n",
      "    epoch          : 996\n",
      "    loss           : -1110.4509885078548\n",
      "    val_loss       : -1110.63212803486\n",
      "    val_log_likelihood: 1561.882193526415\n",
      "    val_log_marginal: 1136.4519544684167\n",
      "Train Epoch: 997 [512/17352 (3%)] Loss: -1164.733643\n",
      "Train Epoch: 997 [10495/17352 (60%)] Loss: -1103.508672\n",
      "Train Epoch: 997 [16934/17352 (98%)] Loss: -1163.568308\n",
      "    epoch          : 997\n",
      "    loss           : -1112.958506727713\n",
      "    val_loss       : -1138.9705845769465\n",
      "    val_log_likelihood: 1577.6344709864738\n",
      "    val_log_marginal: 1156.8802773935138\n",
      "Train Epoch: 998 [512/17352 (3%)] Loss: -1183.355713\n",
      "Train Epoch: 998 [10510/17352 (61%)] Loss: -1088.782437\n",
      "Train Epoch: 998 [17106/17352 (99%)] Loss: -1073.560918\n",
      "    epoch          : 998\n",
      "    loss           : -1123.8926929181796\n",
      "    val_loss       : -1034.074865483397\n",
      "    val_log_likelihood: 1556.1269805891181\n",
      "    val_log_marginal: 1054.3906408727998\n",
      "Train Epoch: 999 [512/17352 (3%)] Loss: -1086.854980\n",
      "Train Epoch: 999 [10741/17352 (62%)] Loss: -1067.616146\n",
      "Train Epoch: 999 [16957/17352 (98%)] Loss: -1037.254710\n",
      "    epoch          : 999\n",
      "    loss           : -1098.3182530897104\n",
      "    val_loss       : -1114.7586838953018\n",
      "    val_log_likelihood: 1577.3947217645807\n",
      "    val_log_marginal: 1143.505835401093\n",
      "Train Epoch: 1000 [512/17352 (3%)] Loss: -1177.471558\n",
      "Train Epoch: 1000 [10518/17352 (61%)] Loss: -1111.365451\n",
      "Train Epoch: 1000 [16988/17352 (98%)] Loss: -1143.686379\n",
      "    epoch          : 1000\n",
      "    loss           : -1110.6492031691946\n",
      "    val_loss       : -1108.0475130815241\n",
      "    val_log_likelihood: 1571.2322512760925\n",
      "    val_log_marginal: 1142.8647375695211\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1000.pth ...\n",
      "Train Epoch: 1001 [512/17352 (3%)] Loss: -1168.949463\n",
      "Train Epoch: 1001 [10501/17352 (61%)] Loss: -1133.356971\n",
      "Train Epoch: 1001 [16887/17352 (97%)] Loss: -1005.503497\n",
      "    epoch          : 1001\n",
      "    loss           : -1101.4460034701913\n",
      "    val_loss       : -1058.1042238825412\n",
      "    val_log_likelihood: 1551.3975228907\n",
      "    val_log_marginal: 1073.9343137437106\n",
      "Train Epoch: 1002 [512/17352 (3%)] Loss: -1002.764832\n",
      "Train Epoch: 1002 [10668/17352 (61%)] Loss: -1146.538071\n",
      "Train Epoch: 1002 [17044/17352 (98%)] Loss: -986.770688\n",
      "    epoch          : 1002\n",
      "    loss           : -1083.0792517077123\n",
      "    val_loss       : -1083.2645943685852\n",
      "    val_log_likelihood: 1556.4161976895762\n",
      "    val_log_marginal: 1117.5727909275279\n",
      "Train Epoch: 1003 [512/17352 (3%)] Loss: -1036.185303\n",
      "Train Epoch: 1003 [9967/17352 (57%)] Loss: -1142.792089\n",
      "Train Epoch: 1003 [16988/17352 (98%)] Loss: -893.588802\n",
      "    epoch          : 1003\n",
      "    loss           : -1047.0370368664446\n",
      "    val_loss       : -1005.543156645876\n",
      "    val_log_likelihood: 1559.4580282968768\n",
      "    val_log_marginal: 1022.0804980243964\n",
      "Train Epoch: 1004 [512/17352 (3%)] Loss: -1053.242065\n",
      "Train Epoch: 1004 [10638/17352 (61%)] Loss: -1181.103965\n",
      "Train Epoch: 1004 [16957/17352 (98%)] Loss: -973.536719\n",
      "    epoch          : 1004\n",
      "    loss           : -1048.9092625479116\n",
      "    val_loss       : -1045.7452928138657\n",
      "    val_log_likelihood: 1537.7509508218773\n",
      "    val_log_marginal: 1067.859749272217\n",
      "Train Epoch: 1005 [512/17352 (3%)] Loss: -1115.923096\n",
      "Train Epoch: 1005 [9973/17352 (57%)] Loss: -1052.442503\n",
      "Train Epoch: 1005 [17133/17352 (99%)] Loss: -1000.632721\n",
      "    epoch          : 1005\n",
      "    loss           : -1037.149383282593\n",
      "    val_loss       : -792.962600757811\n",
      "    val_log_likelihood: 1544.0082992377768\n",
      "    val_log_marginal: 821.778958440952\n",
      "Train Epoch: 1006 [512/17352 (3%)] Loss: -859.428406\n",
      "Train Epoch: 1006 [10142/17352 (58%)] Loss: -869.236585\n",
      "Train Epoch: 1006 [17143/17352 (99%)] Loss: -952.354301\n",
      "    epoch          : 1006\n",
      "    loss           : -970.903972294089\n",
      "    val_loss       : -1019.4716211711898\n",
      "    val_log_likelihood: 1538.824248393557\n",
      "    val_log_marginal: 1067.457945100643\n",
      "Train Epoch: 1007 [512/17352 (3%)] Loss: -1097.906616\n",
      "Train Epoch: 1007 [10270/17352 (59%)] Loss: -1150.824202\n",
      "Train Epoch: 1007 [17263/17352 (99%)] Loss: -1229.379449\n",
      "    epoch          : 1007\n",
      "    loss           : -1089.0567737410859\n",
      "    val_loss       : -1060.3233244260646\n",
      "    val_log_likelihood: 1556.3760936147178\n",
      "    val_log_marginal: 1100.8101614990023\n",
      "Train Epoch: 1008 [512/17352 (3%)] Loss: -756.054810\n",
      "Train Epoch: 1008 [10426/17352 (60%)] Loss: -1088.835594\n",
      "Train Epoch: 1008 [16958/17352 (98%)] Loss: -1159.277724\n",
      "    epoch          : 1008\n",
      "    loss           : -1095.667390390287\n",
      "    val_loss       : -1079.0251617984252\n",
      "    val_log_likelihood: 1558.3676230984972\n",
      "    val_log_marginal: 1092.3501853272317\n",
      "Train Epoch: 1009 [512/17352 (3%)] Loss: -1116.791748\n",
      "Train Epoch: 1009 [10344/17352 (60%)] Loss: -912.239172\n",
      "Train Epoch: 1009 [17153/17352 (99%)] Loss: -1124.923005\n",
      "    epoch          : 1009\n",
      "    loss           : -1045.1958280669685\n",
      "    val_loss       : -1018.589785545385\n",
      "    val_log_likelihood: 1550.9533230922864\n",
      "    val_log_marginal: 1036.1935132803012\n",
      "Train Epoch: 1010 [512/17352 (3%)] Loss: -1049.299072\n",
      "Train Epoch: 1010 [10992/17352 (63%)] Loss: -1063.801432\n",
      "Train Epoch: 1010 [17253/17352 (99%)] Loss: -1235.919715\n",
      "    epoch          : 1010\n",
      "    loss           : -1127.066127908798\n",
      "    val_loss       : -1144.3790249956692\n",
      "    val_log_likelihood: 1578.7465464316072\n",
      "    val_log_marginal: 1158.0214878800539\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1010.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1011 [512/17352 (3%)] Loss: -1077.118896\n",
      "Train Epoch: 1011 [10622/17352 (61%)] Loss: -1191.623047\n",
      "Train Epoch: 1011 [16934/17352 (98%)] Loss: -910.456541\n",
      "    epoch          : 1011\n",
      "    loss           : -1047.97652765007\n",
      "    val_loss       : -848.3695647772435\n",
      "    val_log_likelihood: 1562.3836100646506\n",
      "    val_log_marginal: 863.490378440167\n",
      "Train Epoch: 1012 [512/17352 (3%)] Loss: -865.474976\n",
      "Train Epoch: 1012 [10042/17352 (58%)] Loss: -1047.892318\n",
      "Train Epoch: 1012 [16923/17352 (98%)] Loss: -946.727590\n",
      "    epoch          : 1012\n",
      "    loss           : -1039.5912194043758\n",
      "    val_loss       : -890.5952778538311\n",
      "    val_log_likelihood: 1564.6572786311792\n",
      "    val_log_marginal: 916.3260819451299\n",
      "Train Epoch: 1013 [512/17352 (3%)] Loss: -931.886963\n",
      "Train Epoch: 1013 [10109/17352 (58%)] Loss: -900.004138\n",
      "Train Epoch: 1013 [16883/17352 (97%)] Loss: -1104.313534\n",
      "    epoch          : 1013\n",
      "    loss           : -1017.6906172180761\n",
      "    val_loss       : -1086.9118986760548\n",
      "    val_log_likelihood: 1555.2098571510933\n",
      "    val_log_marginal: 1097.0973357235057\n",
      "Train Epoch: 1014 [512/17352 (3%)] Loss: -1133.205078\n",
      "Train Epoch: 1014 [10213/17352 (59%)] Loss: -932.815341\n",
      "Train Epoch: 1014 [16988/17352 (98%)] Loss: -23.710736\n",
      "    epoch          : 1014\n",
      "    loss           : -442.97359446726983\n",
      "    val_loss       : 30.697497558078293\n",
      "    val_log_likelihood: 1043.1503183653676\n",
      "    val_log_marginal: 81.24488776844012\n",
      "Train Epoch: 1015 [512/17352 (3%)] Loss: -12.633055\n",
      "Train Epoch: 1015 [10197/17352 (59%)] Loss: -294.160994\n",
      "Train Epoch: 1015 [16872/17352 (97%)] Loss: -738.934253\n",
      "    epoch          : 1015\n",
      "    loss           : -661.4176953987791\n",
      "    val_loss       : -864.9781417620918\n",
      "    val_log_likelihood: 1466.0003921238863\n",
      "    val_log_marginal: 923.1491881231425\n",
      "Train Epoch: 1016 [512/17352 (3%)] Loss: -949.249634\n",
      "Train Epoch: 1016 [9989/17352 (58%)] Loss: -1049.042978\n",
      "Train Epoch: 1016 [16883/17352 (97%)] Loss: -1155.730934\n",
      "    epoch          : 1016\n",
      "    loss           : -1002.6779295488976\n",
      "    val_loss       : -1023.7141824868121\n",
      "    val_log_likelihood: 1517.930882098104\n",
      "    val_log_marginal: 1073.2057074736842\n",
      "Train Epoch: 1017 [512/17352 (3%)] Loss: -940.032227\n",
      "Train Epoch: 1017 [10372/17352 (60%)] Loss: -961.995632\n",
      "Train Epoch: 1017 [16988/17352 (98%)] Loss: -1041.830174\n",
      "    epoch          : 1017\n",
      "    loss           : -1088.2584261677716\n",
      "    val_loss       : -1108.2284766602863\n",
      "    val_log_likelihood: 1548.344299865492\n",
      "    val_log_marginal: 1130.7581432462318\n",
      "Train Epoch: 1018 [512/17352 (3%)] Loss: -1160.317383\n",
      "Train Epoch: 1018 [10066/17352 (58%)] Loss: -1100.776302\n",
      "Train Epoch: 1018 [17016/17352 (98%)] Loss: -916.864384\n",
      "    epoch          : 1018\n",
      "    loss           : -1111.3738732625318\n",
      "    val_loss       : -992.031056487717\n",
      "    val_log_likelihood: 1558.5737123294352\n",
      "    val_log_marginal: 1017.0787863109771\n",
      "Train Epoch: 1019 [512/17352 (3%)] Loss: -1038.050537\n",
      "Train Epoch: 1019 [10187/17352 (59%)] Loss: -1095.994234\n",
      "Train Epoch: 1019 [17153/17352 (99%)] Loss: -1174.809635\n",
      "    epoch          : 1019\n",
      "    loss           : -1093.6204390936557\n",
      "    val_loss       : -1076.4006529103362\n",
      "    val_log_likelihood: 1548.0204299921002\n",
      "    val_log_marginal: 1102.505695136058\n",
      "Train Epoch: 1020 [512/17352 (3%)] Loss: -1155.555176\n",
      "Train Epoch: 1020 [10256/17352 (59%)] Loss: -1199.645067\n",
      "Train Epoch: 1020 [16934/17352 (98%)] Loss: -1139.600017\n",
      "    epoch          : 1020\n",
      "    loss           : -1091.1564777576061\n",
      "    val_loss       : -1118.516030593985\n",
      "    val_log_likelihood: 1562.5145456507241\n",
      "    val_log_marginal: 1139.4471998070774\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1020.pth ...\n",
      "Train Epoch: 1021 [512/17352 (3%)] Loss: -1165.963257\n",
      "Train Epoch: 1021 [10293/17352 (59%)] Loss: -1106.586285\n",
      "Train Epoch: 1021 [16939/17352 (98%)] Loss: -1260.827148\n",
      "    epoch          : 1021\n",
      "    loss           : -1123.9756331099786\n",
      "    val_loss       : -1129.2780960195028\n",
      "    val_log_likelihood: 1569.124192631862\n",
      "    val_log_marginal: 1147.3289164726914\n",
      "Train Epoch: 1022 [512/17352 (3%)] Loss: -1172.483276\n",
      "Train Epoch: 1022 [10076/17352 (58%)] Loss: -1171.233822\n",
      "Train Epoch: 1022 [17049/17352 (98%)] Loss: -1194.388542\n",
      "    epoch          : 1022\n",
      "    loss           : -1147.6334635906949\n",
      "    val_loss       : -1148.24872502771\n",
      "    val_log_likelihood: 1581.3037463766407\n",
      "    val_log_marginal: 1162.7754869204034\n",
      "Train Epoch: 1023 [512/17352 (3%)] Loss: -1186.249146\n",
      "Train Epoch: 1023 [10420/17352 (60%)] Loss: -1203.359686\n",
      "Train Epoch: 1023 [17277/17352 (100%)] Loss: -972.637871\n",
      "    epoch          : 1023\n",
      "    loss           : -1150.877650416006\n",
      "    val_loss       : -1126.1436592598675\n",
      "    val_log_likelihood: 1578.0775136729699\n",
      "    val_log_marginal: 1148.9169391096782\n",
      "Train Epoch: 1024 [512/17352 (3%)] Loss: -1176.520996\n",
      "Train Epoch: 1024 [10589/17352 (61%)] Loss: -1195.348998\n",
      "Train Epoch: 1024 [16922/17352 (98%)] Loss: -1149.763415\n",
      "    epoch          : 1024\n",
      "    loss           : -1134.7411946136453\n",
      "    val_loss       : -1161.719383817649\n",
      "    val_log_likelihood: 1591.73600698242\n",
      "    val_log_marginal: 1171.2843104621986\n",
      "Train Epoch: 1025 [512/17352 (3%)] Loss: -1201.694580\n",
      "Train Epoch: 1025 [10886/17352 (63%)] Loss: -1165.511062\n",
      "Train Epoch: 1025 [16988/17352 (98%)] Loss: -1142.615294\n",
      "    epoch          : 1025\n",
      "    loss           : -1101.0845131198955\n",
      "    val_loss       : -1138.8278849232013\n",
      "    val_log_likelihood: 1587.1415905080803\n",
      "    val_log_marginal: 1164.9600990982185\n",
      "Train Epoch: 1026 [512/17352 (3%)] Loss: -1201.465576\n",
      "Train Epoch: 1026 [10255/17352 (59%)] Loss: -1190.778030\n",
      "Train Epoch: 1026 [17108/17352 (99%)] Loss: -1136.451705\n",
      "    epoch          : 1026\n",
      "    loss           : -1151.9266943547007\n",
      "    val_loss       : -1120.6917038148958\n",
      "    val_log_likelihood: 1592.6099207282143\n",
      "    val_log_marginal: 1159.0719612790367\n",
      "Train Epoch: 1027 [512/17352 (3%)] Loss: -1181.999512\n",
      "Train Epoch: 1027 [10149/17352 (58%)] Loss: -1029.313944\n",
      "Train Epoch: 1027 [16939/17352 (98%)] Loss: -972.810215\n",
      "    epoch          : 1027\n",
      "    loss           : -1087.4248463980693\n",
      "    val_loss       : -1074.9684477363878\n",
      "    val_log_likelihood: 1564.8683737178878\n",
      "    val_log_marginal: 1116.068208672885\n",
      "Train Epoch: 1028 [512/17352 (3%)] Loss: -1149.983521\n",
      "Train Epoch: 1028 [10393/17352 (60%)] Loss: -1152.487707\n",
      "Train Epoch: 1028 [16882/17352 (97%)] Loss: -1132.213021\n",
      "    epoch          : 1028\n",
      "    loss           : -1125.7686236494756\n",
      "    val_loss       : -1117.8300188631067\n",
      "    val_log_likelihood: 1583.8823003426103\n",
      "    val_log_marginal: 1137.9017860021738\n",
      "Train Epoch: 1029 [512/17352 (3%)] Loss: -1164.136963\n",
      "Train Epoch: 1029 [10309/17352 (59%)] Loss: -1040.726151\n",
      "Train Epoch: 1029 [17090/17352 (98%)] Loss: -1205.301667\n",
      "    epoch          : 1029\n",
      "    loss           : -1138.9017680176219\n",
      "    val_loss       : -1141.6029843822093\n",
      "    val_log_likelihood: 1584.8207603756389\n",
      "    val_log_marginal: 1149.868713109689\n",
      "Train Epoch: 1030 [512/17352 (3%)] Loss: -1184.259644\n",
      "Train Epoch: 1030 [10152/17352 (59%)] Loss: -1152.739315\n",
      "Train Epoch: 1030 [16958/17352 (98%)] Loss: -1106.888494\n",
      "    epoch          : 1030\n",
      "    loss           : -1131.038666318562\n",
      "    val_loss       : -1143.529878193725\n",
      "    val_log_likelihood: 1592.0256575755857\n",
      "    val_log_marginal: 1161.9432267676523\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1030.pth ...\n",
      "Train Epoch: 1031 [512/17352 (3%)] Loss: -1196.954712\n",
      "Train Epoch: 1031 [10461/17352 (60%)] Loss: -1082.699667\n",
      "Train Epoch: 1031 [17106/17352 (99%)] Loss: -1185.211836\n",
      "    epoch          : 1031\n",
      "    loss           : -1137.614497773296\n",
      "    val_loss       : -1122.0841318624052\n",
      "    val_log_likelihood: 1582.6303227321084\n",
      "    val_log_marginal: 1144.286100398832\n",
      "Train Epoch: 1032 [512/17352 (3%)] Loss: -1162.006714\n",
      "Train Epoch: 1032 [10016/17352 (58%)] Loss: -1097.288474\n",
      "Train Epoch: 1032 [16882/17352 (97%)] Loss: -1127.463925\n",
      "    epoch          : 1032\n",
      "    loss           : -1129.4384195919788\n",
      "    val_loss       : -1159.5117185150643\n",
      "    val_log_likelihood: 1594.6303692263834\n",
      "    val_log_marginal: 1167.2712443048001\n",
      "Train Epoch: 1033 [512/17352 (3%)] Loss: -1200.767212\n",
      "Train Epoch: 1033 [10053/17352 (58%)] Loss: -1115.291933\n",
      "Train Epoch: 1033 [16882/17352 (97%)] Loss: -1183.166269\n",
      "    epoch          : 1033\n",
      "    loss           : -1125.238393056493\n",
      "    val_loss       : -1126.3932911479553\n",
      "    val_log_likelihood: 1582.4858283393621\n",
      "    val_log_marginal: 1150.5136966747475\n",
      "Train Epoch: 1034 [512/17352 (3%)] Loss: -1191.073120\n",
      "Train Epoch: 1034 [9508/17352 (55%)] Loss: -177.192040\n",
      "Train Epoch: 1034 [17101/17352 (99%)] Loss: -1236.509761\n",
      "    epoch          : 1034\n",
      "    loss           : -1090.715414077651\n",
      "    val_loss       : -1130.59031622155\n",
      "    val_log_likelihood: 1581.9467441625093\n",
      "    val_log_marginal: 1145.2480766880894\n",
      "Train Epoch: 1035 [512/17352 (3%)] Loss: -1169.687378\n",
      "Train Epoch: 1035 [10488/17352 (60%)] Loss: -1270.654318\n",
      "Train Epoch: 1035 [17124/17352 (99%)] Loss: -1268.138997\n",
      "    epoch          : 1035\n",
      "    loss           : -1134.673168485727\n",
      "    val_loss       : -1110.765620052014\n",
      "    val_log_likelihood: 1589.4417010780971\n",
      "    val_log_marginal: 1150.536397054488\n",
      "Train Epoch: 1036 [512/17352 (3%)] Loss: -1181.795044\n",
      "Train Epoch: 1036 [9912/17352 (57%)] Loss: -1125.035317\n",
      "Train Epoch: 1036 [17124/17352 (99%)] Loss: -1113.227906\n",
      "    epoch          : 1036\n",
      "    loss           : -1079.0107752741255\n",
      "    val_loss       : -630.8737859254245\n",
      "    val_log_likelihood: 1552.6859227007592\n",
      "    val_log_marginal: 649.4934978854478\n",
      "Train Epoch: 1037 [512/17352 (3%)] Loss: -736.475464\n",
      "Train Epoch: 1037 [9915/17352 (57%)] Loss: -1066.968197\n",
      "Train Epoch: 1037 [16934/17352 (98%)] Loss: -805.878455\n",
      "    epoch          : 1037\n",
      "    loss           : -816.6937144594037\n",
      "    val_loss       : -659.4893751286637\n",
      "    val_log_likelihood: 1325.9934254736886\n",
      "    val_log_marginal: 676.2449023862795\n",
      "Train Epoch: 1038 [512/17352 (3%)] Loss: -725.034485\n",
      "Train Epoch: 1038 [10032/17352 (58%)] Loss: -1044.890831\n",
      "Train Epoch: 1038 [16992/17352 (98%)] Loss: -1153.802300\n",
      "    epoch          : 1038\n",
      "    loss           : -997.7341767262677\n",
      "    val_loss       : -1101.770127945055\n",
      "    val_log_likelihood: 1558.878822501497\n",
      "    val_log_marginal: 1109.6576282104281\n",
      "Train Epoch: 1039 [512/17352 (3%)] Loss: -987.828857\n",
      "Train Epoch: 1039 [10823/17352 (62%)] Loss: -1108.522972\n",
      "Train Epoch: 1039 [17044/17352 (98%)] Loss: -1158.518382\n",
      "    epoch          : 1039\n",
      "    loss           : -1081.5634447286511\n",
      "    val_loss       : -1145.6285139376473\n",
      "    val_log_likelihood: 1571.2978663591787\n",
      "    val_log_marginal: 1150.6438817870635\n",
      "Train Epoch: 1040 [512/17352 (3%)] Loss: -1180.359863\n",
      "Train Epoch: 1040 [10127/17352 (58%)] Loss: -1184.292704\n",
      "Train Epoch: 1040 [17064/17352 (98%)] Loss: -1065.929079\n",
      "    epoch          : 1040\n",
      "    loss           : -1128.3615683475334\n",
      "    val_loss       : -1120.0400732243118\n",
      "    val_log_likelihood: 1569.1944118625815\n",
      "    val_log_marginal: 1140.8151191107831\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1040.pth ...\n",
      "Train Epoch: 1041 [512/17352 (3%)] Loss: -1173.683472\n",
      "Train Epoch: 1041 [10556/17352 (61%)] Loss: -1005.753842\n",
      "Train Epoch: 1041 [17335/17352 (100%)] Loss: -960.431771\n",
      "    epoch          : 1041\n",
      "    loss           : -1143.152556244331\n",
      "    val_loss       : -1094.1132704463585\n",
      "    val_log_likelihood: 1565.9131686683822\n",
      "    val_log_marginal: 1136.8110010190155\n",
      "Train Epoch: 1042 [512/17352 (3%)] Loss: -1173.140259\n",
      "Train Epoch: 1042 [10805/17352 (62%)] Loss: -1037.707074\n",
      "Train Epoch: 1042 [16939/17352 (98%)] Loss: -1219.610247\n",
      "    epoch          : 1042\n",
      "    loss           : -1128.6765131596676\n",
      "    val_loss       : -1062.754729507922\n",
      "    val_log_likelihood: 1574.6577909885439\n",
      "    val_log_marginal: 1143.7991884262065\n",
      "Train Epoch: 1043 [512/17352 (3%)] Loss: -1168.213623\n",
      "Train Epoch: 1043 [10626/17352 (61%)] Loss: -1266.877604\n",
      "Train Epoch: 1043 [17263/17352 (99%)] Loss: -1206.285029\n",
      "    epoch          : 1043\n",
      "    loss           : -1123.7022212044908\n",
      "    val_loss       : -1119.3561891453644\n",
      "    val_log_likelihood: 1583.0075521304695\n",
      "    val_log_marginal: 1150.030516623961\n",
      "Train Epoch: 1044 [512/17352 (3%)] Loss: -1038.852295\n",
      "Train Epoch: 1044 [10055/17352 (58%)] Loss: -1223.669383\n",
      "Train Epoch: 1044 [16878/17352 (97%)] Loss: -1071.525000\n",
      "    epoch          : 1044\n",
      "    loss           : -1104.034771636943\n",
      "    val_loss       : -1082.1271651101833\n",
      "    val_log_likelihood: 1574.5573853959027\n",
      "    val_log_marginal: 1097.866538715983\n",
      "Train Epoch: 1045 [512/17352 (3%)] Loss: -1129.383545\n",
      "Train Epoch: 1045 [10465/17352 (60%)] Loss: -1018.583731\n",
      "Train Epoch: 1045 [16939/17352 (98%)] Loss: -1153.992960\n",
      "    epoch          : 1045\n",
      "    loss           : -1090.7488753143798\n",
      "    val_loss       : -1119.8262158177108\n",
      "    val_log_likelihood: 1590.8396724269169\n",
      "    val_log_marginal: 1158.8156734705176\n",
      "Train Epoch: 1046 [512/17352 (3%)] Loss: -1195.014160\n",
      "Train Epoch: 1046 [10439/17352 (60%)] Loss: -1182.872820\n",
      "Train Epoch: 1046 [16872/17352 (97%)] Loss: -1056.532780\n",
      "    epoch          : 1046\n",
      "    loss           : -1136.2372892743736\n",
      "    val_loss       : -1132.7512486333997\n",
      "    val_log_likelihood: 1586.1823516656998\n",
      "    val_log_marginal: 1154.8621675153265\n",
      "Train Epoch: 1047 [512/17352 (3%)] Loss: -1182.791138\n",
      "Train Epoch: 1047 [10436/17352 (60%)] Loss: -1169.147677\n",
      "Train Epoch: 1047 [17153/17352 (99%)] Loss: -1139.867580\n",
      "    epoch          : 1047\n",
      "    loss           : -1107.8487636163263\n",
      "    val_loss       : -1115.5148368223076\n",
      "    val_log_likelihood: 1582.295276722987\n",
      "    val_log_marginal: 1140.8172748889076\n",
      "Train Epoch: 1048 [512/17352 (3%)] Loss: -1168.887939\n",
      "Train Epoch: 1048 [10909/17352 (63%)] Loss: -1195.989583\n",
      "Train Epoch: 1048 [17101/17352 (99%)] Loss: -1083.717091\n",
      "    epoch          : 1048\n",
      "    loss           : -1148.2894418029184\n",
      "    val_loss       : -1099.3497183496027\n",
      "    val_log_likelihood: 1597.0733470664784\n",
      "    val_log_marginal: 1140.6882771277246\n",
      "Train Epoch: 1049 [512/17352 (3%)] Loss: -1168.399658\n",
      "Train Epoch: 1049 [10846/17352 (63%)] Loss: -1127.688291\n",
      "Train Epoch: 1049 [17277/17352 (100%)] Loss: -927.418037\n",
      "    epoch          : 1049\n",
      "    loss           : -1093.7462810743696\n",
      "    val_loss       : -737.7999071287263\n",
      "    val_log_likelihood: 1567.5545397754663\n",
      "    val_log_marginal: 749.3699594620056\n",
      "Train Epoch: 1050 [512/17352 (3%)] Loss: -655.890625\n",
      "Train Epoch: 1050 [10436/17352 (60%)] Loss: -1037.494703\n",
      "Train Epoch: 1050 [17153/17352 (99%)] Loss: -911.352261\n",
      "    epoch          : 1050\n",
      "    loss           : -851.1285165943491\n",
      "    val_loss       : -990.3803509659285\n",
      "    val_log_likelihood: 1540.3304533255446\n",
      "    val_log_marginal: 1028.532141201992\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1050.pth ...\n",
      "Train Epoch: 1051 [512/17352 (3%)] Loss: -1074.730469\n",
      "Train Epoch: 1051 [10550/17352 (61%)] Loss: -887.302823\n",
      "Train Epoch: 1051 [16992/17352 (98%)] Loss: -1178.121203\n",
      "    epoch          : 1051\n",
      "    loss           : -1006.6181358404485\n",
      "    val_loss       : -1047.398198391792\n",
      "    val_log_likelihood: 1558.1785166993693\n",
      "    val_log_marginal: 1106.990386232679\n",
      "Train Epoch: 1052 [512/17352 (3%)] Loss: -1130.774170\n",
      "Train Epoch: 1052 [10090/17352 (58%)] Loss: -1258.060981\n",
      "Train Epoch: 1052 [16988/17352 (98%)] Loss: -1125.091682\n",
      "    epoch          : 1052\n",
      "    loss           : -1103.8997922452115\n",
      "    val_loss       : -1130.0241464952962\n",
      "    val_log_likelihood: 1570.324967722846\n",
      "    val_log_marginal: 1137.725484661454\n",
      "Train Epoch: 1053 [512/17352 (3%)] Loss: -646.418884\n",
      "Train Epoch: 1053 [10483/17352 (60%)] Loss: -1018.517944\n",
      "Train Epoch: 1053 [17090/17352 (98%)] Loss: -1166.322095\n",
      "    epoch          : 1053\n",
      "    loss           : -1054.9964946298492\n",
      "    val_loss       : -1058.0385250336265\n",
      "    val_log_likelihood: 1536.151168740614\n",
      "    val_log_marginal: 1071.6249783447652\n",
      "Train Epoch: 1054 [512/17352 (3%)] Loss: -1087.013184\n",
      "Train Epoch: 1054 [9690/17352 (56%)] Loss: -1268.064670\n",
      "Train Epoch: 1054 [16992/17352 (98%)] Loss: -1107.258278\n",
      "    epoch          : 1054\n",
      "    loss           : -1132.1529202474471\n",
      "    val_loss       : -1143.3234074708478\n",
      "    val_log_likelihood: 1585.3989782476824\n",
      "    val_log_marginal: 1157.262434978224\n",
      "Train Epoch: 1055 [512/17352 (3%)] Loss: -1190.659546\n",
      "Train Epoch: 1055 [10291/17352 (59%)] Loss: 1818.758304\n",
      "Train Epoch: 1055 [17143/17352 (99%)] Loss: -928.575581\n",
      "    epoch          : 1055\n",
      "    loss           : -807.9193721793354\n",
      "    val_loss       : -958.6161079881485\n",
      "    val_log_likelihood: 1453.9511727992215\n",
      "    val_log_marginal: 968.771074530384\n",
      "Train Epoch: 1056 [512/17352 (3%)] Loss: -803.417847\n",
      "Train Epoch: 1056 [11100/17352 (64%)] Loss: -1015.094156\n",
      "Train Epoch: 1056 [17253/17352 (99%)] Loss: -1170.893550\n",
      "    epoch          : 1056\n",
      "    loss           : -1045.1703884854228\n",
      "    val_loss       : -1120.9006636000313\n",
      "    val_log_likelihood: 1559.1860490305933\n",
      "    val_log_marginal: 1133.5764542434292\n",
      "Train Epoch: 1057 [512/17352 (3%)] Loss: -1159.709717\n",
      "Train Epoch: 1057 [10320/17352 (59%)] Loss: -1124.318173\n",
      "Train Epoch: 1057 [17335/17352 (100%)] Loss: -1218.163071\n",
      "    epoch          : 1057\n",
      "    loss           : -1144.0014304729975\n",
      "    val_loss       : -1096.2120555665072\n",
      "    val_log_likelihood: 1574.8180439890625\n",
      "    val_log_marginal: 1131.1066905567238\n",
      "Train Epoch: 1058 [512/17352 (3%)] Loss: -1161.532471\n",
      "Train Epoch: 1058 [10594/17352 (61%)] Loss: -1234.223936\n",
      "Train Epoch: 1058 [17044/17352 (98%)] Loss: -1189.913372\n",
      "    epoch          : 1058\n",
      "    loss           : -1130.6259978040105\n",
      "    val_loss       : -1124.8841119701237\n",
      "    val_log_likelihood: 1589.7994153763884\n",
      "    val_log_marginal: 1152.347651894434\n",
      "Train Epoch: 1059 [512/17352 (3%)] Loss: -1056.678345\n",
      "Train Epoch: 1059 [10758/17352 (62%)] Loss: -1235.987104\n",
      "Train Epoch: 1059 [16958/17352 (98%)] Loss: -1212.428924\n",
      "    epoch          : 1059\n",
      "    loss           : -1134.0288028480368\n",
      "    val_loss       : -1156.1400603188779\n",
      "    val_log_likelihood: 1591.8703189454802\n",
      "    val_log_marginal: 1171.0011948117744\n",
      "Train Epoch: 1060 [512/17352 (3%)] Loss: -1205.335205\n",
      "Train Epoch: 1060 [10608/17352 (61%)] Loss: -1047.505780\n",
      "Train Epoch: 1060 [17277/17352 (100%)] Loss: -1121.827795\n",
      "    epoch          : 1060\n",
      "    loss           : -1136.5379829252447\n",
      "    val_loss       : -1121.4411207051935\n",
      "    val_log_likelihood: 1595.1827416634808\n",
      "    val_log_marginal: 1149.2159816082249\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1060.pth ...\n",
      "Train Epoch: 1061 [512/17352 (3%)] Loss: -1180.445190\n",
      "Train Epoch: 1061 [10144/17352 (58%)] Loss: -1104.684050\n",
      "Train Epoch: 1061 [17143/17352 (99%)] Loss: -1037.475397\n",
      "    epoch          : 1061\n",
      "    loss           : -1121.7867570484505\n",
      "    val_loss       : -1087.4061060603758\n",
      "    val_log_likelihood: 1599.7572184922624\n",
      "    val_log_marginal: 1110.8222157451162\n",
      "Train Epoch: 1062 [512/17352 (3%)] Loss: -1021.986450\n",
      "Train Epoch: 1062 [10682/17352 (62%)] Loss: -924.663024\n",
      "Train Epoch: 1062 [16939/17352 (98%)] Loss: -1018.322917\n",
      "    epoch          : 1062\n",
      "    loss           : -996.8682148191857\n",
      "    val_loss       : -1102.4252836827975\n",
      "    val_log_likelihood: 1571.3495327290925\n",
      "    val_log_marginal: 1126.7749041674651\n",
      "Train Epoch: 1063 [512/17352 (3%)] Loss: -1155.202515\n",
      "Train Epoch: 1063 [10540/17352 (61%)] Loss: -1217.636179\n",
      "Train Epoch: 1063 [17101/17352 (99%)] Loss: -1058.272378\n",
      "    epoch          : 1063\n",
      "    loss           : -1089.2127865425223\n",
      "    val_loss       : -990.0809199866745\n",
      "    val_log_likelihood: 1507.9807782039345\n",
      "    val_log_marginal: 1026.824940097645\n",
      "Train Epoch: 1064 [512/17352 (3%)] Loss: -1039.270508\n",
      "Train Epoch: 1064 [10451/17352 (60%)] Loss: -1154.686555\n",
      "Train Epoch: 1064 [17106/17352 (99%)] Loss: -1146.944066\n",
      "    epoch          : 1064\n",
      "    loss           : -1084.9527506873962\n",
      "    val_loss       : -1081.129704944785\n",
      "    val_log_likelihood: 1570.5167168822447\n",
      "    val_log_marginal: 1125.7269020432861\n",
      "Train Epoch: 1065 [512/17352 (3%)] Loss: -1173.376221\n",
      "Train Epoch: 1065 [10255/17352 (59%)] Loss: -1199.024898\n",
      "Train Epoch: 1065 [17153/17352 (99%)] Loss: -1101.807018\n",
      "    epoch          : 1065\n",
      "    loss           : -1099.028683945439\n",
      "    val_loss       : -1025.9198603550735\n",
      "    val_log_likelihood: 1527.2958757122794\n",
      "    val_log_marginal: 1047.5564459386337\n",
      "Train Epoch: 1066 [512/17352 (3%)] Loss: -910.561157\n",
      "Train Epoch: 1066 [10456/17352 (60%)] Loss: -1096.004710\n",
      "Train Epoch: 1066 [17263/17352 (99%)] Loss: -1222.004388\n",
      "    epoch          : 1066\n",
      "    loss           : -1112.6465912229535\n",
      "    val_loss       : -1139.7580712076854\n",
      "    val_log_likelihood: 1587.3059072795593\n",
      "    val_log_marginal: 1157.479273135699\n",
      "Train Epoch: 1067 [512/17352 (3%)] Loss: -1061.893921\n",
      "Train Epoch: 1067 [10632/17352 (61%)] Loss: -1135.332147\n",
      "Train Epoch: 1067 [16883/17352 (97%)] Loss: -1060.455144\n",
      "    epoch          : 1067\n",
      "    loss           : -1158.931269387876\n",
      "    val_loss       : -1116.7417876469372\n",
      "    val_log_likelihood: 1587.7102620910287\n",
      "    val_log_marginal: 1160.927714528801\n",
      "Train Epoch: 1068 [512/17352 (3%)] Loss: -1190.690430\n",
      "Train Epoch: 1068 [10326/17352 (60%)] Loss: -1273.598090\n",
      "Train Epoch: 1068 [17016/17352 (98%)] Loss: -1156.370364\n",
      "    epoch          : 1068\n",
      "    loss           : -1149.1356797851781\n",
      "    val_loss       : -1155.1593273297476\n",
      "    val_log_likelihood: 1593.560903825072\n",
      "    val_log_marginal: 1166.2527792035105\n",
      "Train Epoch: 1069 [512/17352 (3%)] Loss: -1190.016235\n",
      "Train Epoch: 1069 [10560/17352 (61%)] Loss: -1249.005833\n",
      "Train Epoch: 1069 [17335/17352 (100%)] Loss: -1075.518502\n",
      "    epoch          : 1069\n",
      "    loss           : -1170.9827443891188\n",
      "    val_loss       : -1099.0457749610305\n",
      "    val_log_likelihood: 1600.8297153303338\n",
      "    val_log_marginal: 1144.6999281739718\n",
      "Train Epoch: 1070 [512/17352 (3%)] Loss: -1171.906006\n",
      "Train Epoch: 1070 [10455/17352 (60%)] Loss: -1251.807927\n",
      "Train Epoch: 1070 [17044/17352 (98%)] Loss: -1111.651884\n",
      "    epoch          : 1070\n",
      "    loss           : -1133.809499804041\n",
      "    val_loss       : -1155.952877407008\n",
      "    val_log_likelihood: 1603.0204969555723\n",
      "    val_log_marginal: 1166.906987978784\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1070.pth ...\n",
      "Train Epoch: 1071 [512/17352 (3%)] Loss: -1189.091797\n",
      "Train Epoch: 1071 [10485/17352 (60%)] Loss: -1051.486626\n",
      "Train Epoch: 1071 [17101/17352 (99%)] Loss: -812.639769\n",
      "    epoch          : 1071\n",
      "    loss           : -1107.9096811605643\n",
      "    val_loss       : -1054.540866357967\n",
      "    val_log_likelihood: 1592.0564872549915\n",
      "    val_log_marginal: 1078.9021810745146\n",
      "Train Epoch: 1072 [512/17352 (3%)] Loss: -995.766235\n",
      "Train Epoch: 1072 [9756/17352 (56%)] Loss: -1066.769301\n",
      "Train Epoch: 1072 [16957/17352 (98%)] Loss: -1167.812500\n",
      "    epoch          : 1072\n",
      "    loss           : -1018.6641535458003\n",
      "    val_loss       : -1113.8977785009276\n",
      "    val_log_likelihood: 1582.9244923658973\n",
      "    val_log_marginal: 1131.2101166694126\n",
      "Train Epoch: 1073 [512/17352 (3%)] Loss: -1173.091064\n",
      "Train Epoch: 1073 [10014/17352 (58%)] Loss: -1152.102440\n",
      "Train Epoch: 1073 [16923/17352 (98%)] Loss: -1062.656453\n",
      "    epoch          : 1073\n",
      "    loss           : -1064.1413970918836\n",
      "    val_loss       : -1138.74891090699\n",
      "    val_log_likelihood: 1590.3544648188424\n",
      "    val_log_marginal: 1155.0619175076097\n",
      "Train Epoch: 1074 [512/17352 (3%)] Loss: -1189.738525\n",
      "Train Epoch: 1074 [10463/17352 (60%)] Loss: -1096.293880\n",
      "Train Epoch: 1074 [16882/17352 (97%)] Loss: -1103.375436\n",
      "    epoch          : 1074\n",
      "    loss           : -1137.4990003509047\n",
      "    val_loss       : -1146.2353551295876\n",
      "    val_log_likelihood: 1600.502839457522\n",
      "    val_log_marginal: 1174.2588246073308\n",
      "Train Epoch: 1075 [512/17352 (3%)] Loss: -1100.195801\n",
      "Train Epoch: 1075 [9767/17352 (56%)] Loss: -1255.722180\n",
      "Train Epoch: 1075 [16882/17352 (97%)] Loss: -1284.288628\n",
      "    epoch          : 1075\n",
      "    loss           : -1138.1066107047961\n",
      "    val_loss       : -1161.9215023953805\n",
      "    val_log_likelihood: 1609.9189327160423\n",
      "    val_log_marginal: 1184.6662013047826\n",
      "Train Epoch: 1076 [512/17352 (3%)] Loss: -1208.107178\n",
      "Train Epoch: 1076 [10567/17352 (61%)] Loss: -1235.456329\n",
      "Train Epoch: 1076 [17108/17352 (99%)] Loss: -1304.918843\n",
      "    epoch          : 1076\n",
      "    loss           : -1164.3228948239082\n",
      "    val_loss       : -1086.3677631979192\n",
      "    val_log_likelihood: 1567.083726235263\n",
      "    val_log_marginal: 1118.3399322161313\n",
      "Train Epoch: 1077 [512/17352 (3%)] Loss: -1148.524414\n",
      "Train Epoch: 1077 [10296/17352 (59%)] Loss: -1147.358686\n",
      "Train Epoch: 1077 [16883/17352 (97%)] Loss: -978.710701\n",
      "    epoch          : 1077\n",
      "    loss           : -1083.2248898949128\n",
      "    val_loss       : -1134.4543721289936\n",
      "    val_log_likelihood: 1583.185701495335\n",
      "    val_log_marginal: 1151.435847104388\n",
      "Train Epoch: 1078 [512/17352 (3%)] Loss: -1188.952881\n",
      "Train Epoch: 1078 [10085/17352 (58%)] Loss: -1101.797772\n",
      "Train Epoch: 1078 [16872/17352 (97%)] Loss: -1149.030060\n",
      "    epoch          : 1078\n",
      "    loss           : -1116.9662279565325\n",
      "    val_loss       : -1114.1528774347382\n",
      "    val_log_likelihood: 1590.987768439898\n",
      "    val_log_marginal: 1140.595734697501\n",
      "Train Epoch: 1079 [512/17352 (3%)] Loss: -1178.049927\n",
      "Train Epoch: 1079 [10094/17352 (58%)] Loss: -965.408958\n",
      "Train Epoch: 1079 [16922/17352 (98%)] Loss: -1130.092891\n",
      "    epoch          : 1079\n",
      "    loss           : -1111.6181723605052\n",
      "    val_loss       : -1154.1108409857234\n",
      "    val_log_likelihood: 1600.5861976051547\n",
      "    val_log_marginal: 1161.691392972865\n",
      "Train Epoch: 1080 [512/17352 (3%)] Loss: -1185.134277\n",
      "Train Epoch: 1080 [10416/17352 (60%)] Loss: -1008.082544\n",
      "Train Epoch: 1080 [17153/17352 (99%)] Loss: -1103.840236\n",
      "    epoch          : 1080\n",
      "    loss           : -1119.3103585483689\n",
      "    val_loss       : -1109.7159576916174\n",
      "    val_log_likelihood: 1596.486455037248\n",
      "    val_log_marginal: 1158.9708635211664\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1080.pth ...\n",
      "Train Epoch: 1081 [512/17352 (3%)] Loss: -1183.490845\n",
      "Train Epoch: 1081 [10699/17352 (62%)] Loss: -1025.712252\n",
      "Train Epoch: 1081 [17263/17352 (99%)] Loss: -1199.407181\n",
      "    epoch          : 1081\n",
      "    loss           : -1137.4363024647253\n",
      "    val_loss       : -1061.3389963643517\n",
      "    val_log_likelihood: 1593.5348308619746\n",
      "    val_log_marginal: 1085.844429848336\n",
      "Train Epoch: 1082 [512/17352 (3%)] Loss: -1110.095581\n",
      "Train Epoch: 1082 [10446/17352 (60%)] Loss: -1050.417473\n",
      "Train Epoch: 1082 [16923/17352 (98%)] Loss: -1208.099085\n",
      "    epoch          : 1082\n",
      "    loss           : -1111.3332248546615\n",
      "    val_loss       : -1139.8982050087536\n",
      "    val_log_likelihood: 1602.6217037187548\n",
      "    val_log_marginal: 1155.8712295906844\n",
      "Train Epoch: 1083 [512/17352 (3%)] Loss: -1184.149414\n",
      "Train Epoch: 1083 [10089/17352 (58%)] Loss: -585.628746\n",
      "Train Epoch: 1083 [16957/17352 (98%)] Loss: -1131.076693\n",
      "    epoch          : 1083\n",
      "    loss           : -1120.6459870927094\n",
      "    val_loss       : -1148.4646282191761\n",
      "    val_log_likelihood: 1602.4032087486526\n",
      "    val_log_marginal: 1169.071338654873\n",
      "Train Epoch: 1084 [512/17352 (3%)] Loss: -1198.621460\n",
      "Train Epoch: 1084 [9878/17352 (57%)] Loss: -1218.478318\n",
      "Train Epoch: 1084 [17143/17352 (99%)] Loss: -1247.061484\n",
      "    epoch          : 1084\n",
      "    loss           : -1150.9529613853522\n",
      "    val_loss       : -1135.2104454949126\n",
      "    val_log_likelihood: 1607.7078601241922\n",
      "    val_log_marginal: 1177.9816273133647\n",
      "Train Epoch: 1085 [512/17352 (3%)] Loss: -1211.652222\n",
      "Train Epoch: 1085 [10379/17352 (60%)] Loss: -1220.548659\n",
      "Train Epoch: 1085 [16878/17352 (97%)] Loss: -1240.513465\n",
      "    epoch          : 1085\n",
      "    loss           : -1146.299290805043\n",
      "    val_loss       : -1160.2309452785319\n",
      "    val_log_likelihood: 1609.2463140817597\n",
      "    val_log_marginal: 1179.2537566300923\n",
      "Train Epoch: 1086 [512/17352 (3%)] Loss: -1204.263062\n",
      "Train Epoch: 1086 [10502/17352 (61%)] Loss: -1118.940383\n",
      "Train Epoch: 1086 [17064/17352 (98%)] Loss: -1088.736657\n",
      "    epoch          : 1086\n",
      "    loss           : -1125.158290377043\n",
      "    val_loss       : -1089.816711112286\n",
      "    val_log_likelihood: 1570.421349869029\n",
      "    val_log_marginal: 1111.4159481194108\n",
      "Train Epoch: 1087 [512/17352 (3%)] Loss: -1150.478760\n",
      "Train Epoch: 1087 [10495/17352 (60%)] Loss: -1140.467237\n",
      "Train Epoch: 1087 [17143/17352 (99%)] Loss: -1192.108302\n",
      "    epoch          : 1087\n",
      "    loss           : -1134.6692850988202\n",
      "    val_loss       : -1149.0453509981737\n",
      "    val_log_likelihood: 1607.5865648495292\n",
      "    val_log_marginal: 1164.1496203804368\n",
      "Train Epoch: 1088 [512/17352 (3%)] Loss: -1183.501587\n",
      "Train Epoch: 1088 [10779/17352 (62%)] Loss: -1133.049913\n",
      "Train Epoch: 1088 [16992/17352 (98%)] Loss: -1193.849740\n",
      "    epoch          : 1088\n",
      "    loss           : -1142.6374668802748\n",
      "    val_loss       : -1075.8900530158942\n",
      "    val_log_likelihood: 1591.6307313835714\n",
      "    val_log_marginal: 1139.5833699004702\n",
      "Train Epoch: 1089 [512/17352 (3%)] Loss: -1169.883545\n",
      "Train Epoch: 1089 [10286/17352 (59%)] Loss: -1184.350625\n",
      "Train Epoch: 1089 [16958/17352 (98%)] Loss: -1139.035731\n",
      "    epoch          : 1089\n",
      "    loss           : -1130.0557523302505\n",
      "    val_loss       : -1148.6705081600937\n",
      "    val_log_likelihood: 1615.034848228053\n",
      "    val_log_marginal: 1180.8077741375748\n",
      "Train Epoch: 1090 [512/17352 (3%)] Loss: -1206.426758\n",
      "Train Epoch: 1090 [10894/17352 (63%)] Loss: -1067.501444\n",
      "Train Epoch: 1090 [17263/17352 (99%)] Loss: -1210.502326\n",
      "    epoch          : 1090\n",
      "    loss           : -1151.1008363224842\n",
      "    val_loss       : -1095.6756726444878\n",
      "    val_log_likelihood: 1610.7266071069246\n",
      "    val_log_marginal: 1107.4494618300666\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1090.pth ...\n",
      "Train Epoch: 1091 [512/17352 (3%)] Loss: -1132.954346\n",
      "Train Epoch: 1091 [10629/17352 (61%)] Loss: -1259.977376\n",
      "Train Epoch: 1091 [16882/17352 (97%)] Loss: -938.941982\n",
      "    epoch          : 1091\n",
      "    loss           : -1120.2562524069235\n",
      "    val_loss       : -1107.048944984797\n",
      "    val_log_likelihood: 1599.5547441548374\n",
      "    val_log_marginal: 1121.5068543699501\n",
      "Train Epoch: 1092 [512/17352 (3%)] Loss: -1148.065186\n",
      "Train Epoch: 1092 [9852/17352 (57%)] Loss: -1100.854372\n",
      "Train Epoch: 1092 [16988/17352 (98%)] Loss: -1020.396847\n",
      "    epoch          : 1092\n",
      "    loss           : -1080.4700608654166\n",
      "    val_loss       : -1127.9054119640332\n",
      "    val_log_likelihood: 1606.835259278092\n",
      "    val_log_marginal: 1153.1554116295504\n",
      "Train Epoch: 1093 [512/17352 (3%)] Loss: -1180.238892\n",
      "Train Epoch: 1093 [10449/17352 (60%)] Loss: -1152.211648\n",
      "Train Epoch: 1093 [17133/17352 (99%)] Loss: -1129.172706\n",
      "    epoch          : 1093\n",
      "    loss           : -1097.2578793331363\n",
      "    val_loss       : -1061.339413983635\n",
      "    val_log_likelihood: 1596.351171535696\n",
      "    val_log_marginal: 1098.616525557628\n",
      "Train Epoch: 1094 [512/17352 (3%)] Loss: -1132.901123\n",
      "Train Epoch: 1094 [10021/17352 (58%)] Loss: -1126.911118\n",
      "Train Epoch: 1094 [16957/17352 (98%)] Loss: -1150.241146\n",
      "    epoch          : 1094\n",
      "    loss           : -1093.5180617550118\n",
      "    val_loss       : -1087.7201387644755\n",
      "    val_log_likelihood: 1587.9254015279162\n",
      "    val_log_marginal: 1111.1875784626754\n",
      "Train Epoch: 1095 [512/17352 (3%)] Loss: -1157.520508\n",
      "Train Epoch: 1095 [10577/17352 (61%)] Loss: -1186.276549\n",
      "Train Epoch: 1095 [17153/17352 (99%)] Loss: -989.250343\n",
      "    epoch          : 1095\n",
      "    loss           : -1106.9450327659972\n",
      "    val_loss       : -994.4047234237305\n",
      "    val_log_likelihood: 1587.767416502088\n",
      "    val_log_marginal: 1009.1723232710671\n",
      "Train Epoch: 1096 [512/17352 (3%)] Loss: -1041.137695\n",
      "Train Epoch: 1096 [10469/17352 (60%)] Loss: -1049.980198\n",
      "Train Epoch: 1096 [17253/17352 (99%)] Loss: -1184.769622\n",
      "    epoch          : 1096\n",
      "    loss           : -1141.0055485716277\n",
      "    val_loss       : -1093.322806245588\n",
      "    val_log_likelihood: 1613.4055720936535\n",
      "    val_log_marginal: 1113.0414662211358\n",
      "Train Epoch: 1097 [512/17352 (3%)] Loss: -1133.922363\n",
      "Train Epoch: 1097 [10136/17352 (58%)] Loss: -1230.834746\n",
      "Train Epoch: 1097 [17090/17352 (98%)] Loss: -975.364608\n",
      "    epoch          : 1097\n",
      "    loss           : -1089.084417268437\n",
      "    val_loss       : -1124.7689275680477\n",
      "    val_log_likelihood: 1598.3762210268778\n",
      "    val_log_marginal: 1134.3322364595156\n",
      "Train Epoch: 1098 [512/17352 (3%)] Loss: -1158.241943\n",
      "Train Epoch: 1098 [10123/17352 (58%)] Loss: -1129.242890\n",
      "Train Epoch: 1098 [17133/17352 (99%)] Loss: -1104.437391\n",
      "    epoch          : 1098\n",
      "    loss           : -1042.716346167935\n",
      "    val_loss       : -1073.3721705252883\n",
      "    val_log_likelihood: 1591.4778554992504\n",
      "    val_log_marginal: 1105.1457481823072\n",
      "Train Epoch: 1099 [512/17352 (3%)] Loss: -1133.143433\n",
      "Train Epoch: 1099 [10761/17352 (62%)] Loss: -1094.397446\n",
      "Train Epoch: 1099 [16878/17352 (97%)] Loss: -1183.364399\n",
      "    epoch          : 1099\n",
      "    loss           : -1038.515175372383\n",
      "    val_loss       : -1118.1220368250965\n",
      "    val_log_likelihood: 1578.3481206188742\n",
      "    val_log_marginal: 1132.6853371736565\n",
      "Train Epoch: 1100 [512/17352 (3%)] Loss: -1152.671875\n",
      "Train Epoch: 1100 [10684/17352 (62%)] Loss: -1152.802284\n",
      "Train Epoch: 1100 [17106/17352 (99%)] Loss: -1107.324132\n",
      "    epoch          : 1100\n",
      "    loss           : -1119.9144908718365\n",
      "    val_loss       : -1001.7525953523294\n",
      "    val_log_likelihood: 1509.3003165708005\n",
      "    val_log_marginal: 1027.4631565645439\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1100.pth ...\n",
      "Train Epoch: 1101 [512/17352 (3%)] Loss: -1071.776978\n",
      "Train Epoch: 1101 [10154/17352 (59%)] Loss: -1226.319868\n",
      "Train Epoch: 1101 [16923/17352 (98%)] Loss: -1200.083333\n",
      "    epoch          : 1101\n",
      "    loss           : -1101.3534539571651\n",
      "    val_loss       : -1094.8308042087804\n",
      "    val_log_likelihood: 1610.6945202043091\n",
      "    val_log_marginal: 1160.5183955772454\n",
      "Train Epoch: 1102 [512/17352 (3%)] Loss: -1183.380005\n",
      "Train Epoch: 1102 [10051/17352 (58%)] Loss: -1029.948432\n",
      "Train Epoch: 1102 [17106/17352 (99%)] Loss: -1130.527848\n",
      "    epoch          : 1102\n",
      "    loss           : -1110.444860196527\n",
      "    val_loss       : -1053.8917271091457\n",
      "    val_log_likelihood: 1593.9978770824328\n",
      "    val_log_marginal: 1102.750390381778\n",
      "Train Epoch: 1103 [512/17352 (3%)] Loss: -1144.128906\n",
      "Train Epoch: 1103 [10582/17352 (61%)] Loss: -1016.046766\n",
      "Train Epoch: 1103 [16992/17352 (98%)] Loss: -1183.662580\n",
      "    epoch          : 1103\n",
      "    loss           : -1110.7986363916568\n",
      "    val_loss       : -1154.0836279847877\n",
      "    val_log_likelihood: 1608.4008431638108\n",
      "    val_log_marginal: 1168.2104479858974\n",
      "Train Epoch: 1104 [512/17352 (3%)] Loss: -1196.748657\n",
      "Train Epoch: 1104 [10641/17352 (61%)] Loss: -1121.327691\n",
      "Train Epoch: 1104 [17101/17352 (99%)] Loss: -960.413128\n",
      "    epoch          : 1104\n",
      "    loss           : -1139.3018744244519\n",
      "    val_loss       : -1067.90102440207\n",
      "    val_log_likelihood: 1594.9833840304523\n",
      "    val_log_marginal: 1112.5222641953624\n",
      "Train Epoch: 1105 [512/17352 (3%)] Loss: -1149.942871\n",
      "Train Epoch: 1105 [10384/17352 (60%)] Loss: -1060.639306\n",
      "Train Epoch: 1105 [17124/17352 (99%)] Loss: -1141.955323\n",
      "    epoch          : 1105\n",
      "    loss           : -1129.109258209129\n",
      "    val_loss       : -1154.3789643847854\n",
      "    val_log_likelihood: 1613.911991932413\n",
      "    val_log_marginal: 1170.6868342472967\n",
      "Train Epoch: 1106 [512/17352 (3%)] Loss: -1203.440918\n",
      "Train Epoch: 1106 [10602/17352 (61%)] Loss: -1122.919442\n",
      "Train Epoch: 1106 [17101/17352 (99%)] Loss: -1180.073273\n",
      "    epoch          : 1106\n",
      "    loss           : -1156.691664162289\n",
      "    val_loss       : -1155.0076900259367\n",
      "    val_log_likelihood: 1616.1445696917324\n",
      "    val_log_marginal: 1175.6165128682355\n",
      "Train Epoch: 1107 [512/17352 (3%)] Loss: -1206.351807\n",
      "Train Epoch: 1107 [9957/17352 (57%)] Loss: -1130.647321\n",
      "Train Epoch: 1107 [17064/17352 (98%)] Loss: -1055.312294\n",
      "    epoch          : 1107\n",
      "    loss           : -1125.7445930695205\n",
      "    val_loss       : -1092.0485174393918\n",
      "    val_log_likelihood: 1573.126100151671\n",
      "    val_log_marginal: 1105.300860727666\n",
      "Train Epoch: 1108 [512/17352 (3%)] Loss: -1113.025879\n",
      "Train Epoch: 1108 [11029/17352 (64%)] Loss: -1237.370479\n",
      "Train Epoch: 1108 [17143/17352 (99%)] Loss: -523.388368\n",
      "    epoch          : 1108\n",
      "    loss           : -1058.556180651404\n",
      "    val_loss       : -966.7856666686552\n",
      "    val_log_likelihood: 1583.3964025281314\n",
      "    val_log_marginal: 984.9604045882446\n",
      "Train Epoch: 1109 [512/17352 (3%)] Loss: -1000.135437\n",
      "Train Epoch: 1109 [9984/17352 (58%)] Loss: -149.342059\n",
      "Train Epoch: 1109 [16939/17352 (98%)] Loss: -814.787196\n",
      "    epoch          : 1109\n",
      "    loss           : -668.1729501764123\n",
      "    val_loss       : -698.4567400528936\n",
      "    val_log_likelihood: 1533.1741780634152\n",
      "    val_log_marginal: 752.9347751331325\n",
      "Train Epoch: 1110 [512/17352 (3%)] Loss: -645.635376\n",
      "Train Epoch: 1110 [10313/17352 (59%)] Loss: -724.356930\n",
      "Train Epoch: 1110 [17153/17352 (99%)] Loss: -223.922002\n",
      "    epoch          : 1110\n",
      "    loss           : -288.58215278464866\n",
      "    val_loss       : 500.07075551979926\n",
      "    val_log_likelihood: 912.0681962251741\n",
      "    val_log_marginal: -457.1149683781956\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1110.pth ...\n",
      "Train Epoch: 1111 [512/17352 (3%)] Loss: 595.674683\n",
      "Train Epoch: 1111 [10466/17352 (60%)] Loss: -765.042377\n",
      "Train Epoch: 1111 [16934/17352 (98%)] Loss: 570.803906\n",
      "    epoch          : 1111\n",
      "    loss           : -550.2202950144762\n",
      "    val_loss       : -409.8029722984301\n",
      "    val_log_likelihood: 1438.932449343143\n",
      "    val_log_marginal: 446.3064294669613\n",
      "Train Epoch: 1112 [512/17352 (3%)] Loss: -447.501923\n",
      "Train Epoch: 1112 [10943/17352 (63%)] Loss: -559.686790\n",
      "Train Epoch: 1112 [17153/17352 (99%)] Loss: -969.787555\n",
      "    epoch          : 1112\n",
      "    loss           : -827.3287535075335\n",
      "    val_loss       : -760.7738930867691\n",
      "    val_log_likelihood: 1501.071875703157\n",
      "    val_log_marginal: 789.428682756651\n",
      "Train Epoch: 1113 [512/17352 (3%)] Loss: -783.507935\n",
      "Train Epoch: 1113 [10784/17352 (62%)] Loss: -904.700758\n",
      "Train Epoch: 1113 [17016/17352 (98%)] Loss: -1012.300260\n",
      "    epoch          : 1113\n",
      "    loss           : -974.7137728074558\n",
      "    val_loss       : -1095.4536406609975\n",
      "    val_log_likelihood: 1552.4809477269762\n",
      "    val_log_marginal: 1131.172781685979\n",
      "Train Epoch: 1114 [512/17352 (3%)] Loss: -1165.895996\n",
      "Train Epoch: 1114 [10535/17352 (61%)] Loss: -1119.506944\n",
      "Train Epoch: 1114 [16958/17352 (98%)] Loss: -957.110232\n",
      "    epoch          : 1114\n",
      "    loss           : -1125.9856068590432\n",
      "    val_loss       : -1128.5665265794503\n",
      "    val_log_likelihood: 1573.6565507593752\n",
      "    val_log_marginal: 1159.1492831708522\n",
      "Train Epoch: 1115 [512/17352 (3%)] Loss: -1080.655884\n",
      "Train Epoch: 1115 [10834/17352 (62%)] Loss: -1047.560753\n",
      "Train Epoch: 1115 [17277/17352 (100%)] Loss: -1212.245825\n",
      "    epoch          : 1115\n",
      "    loss           : -1149.5351509950958\n",
      "    val_loss       : -1167.4988900781232\n",
      "    val_log_likelihood: 1592.4841229925094\n",
      "    val_log_marginal: 1176.517038689831\n",
      "Train Epoch: 1116 [512/17352 (3%)] Loss: -1208.879517\n",
      "Train Epoch: 1116 [10176/17352 (59%)] Loss: -1128.924977\n",
      "Train Epoch: 1116 [16872/17352 (97%)] Loss: -1239.987342\n",
      "    epoch          : 1116\n",
      "    loss           : -1157.953560120425\n",
      "    val_loss       : -1170.5018720755534\n",
      "    val_log_likelihood: 1599.7815459783485\n",
      "    val_log_marginal: 1180.799798809019\n",
      "Train Epoch: 1117 [512/17352 (3%)] Loss: -1213.222290\n",
      "Train Epoch: 1117 [9905/17352 (57%)] Loss: -1127.793586\n",
      "Train Epoch: 1117 [16883/17352 (97%)] Loss: -1004.669271\n",
      "    epoch          : 1117\n",
      "    loss           : -1167.9149576428752\n",
      "    val_loss       : -1173.800866011676\n",
      "    val_log_likelihood: 1608.807145907149\n",
      "    val_log_marginal: 1185.7097476773\n",
      "Train Epoch: 1118 [512/17352 (3%)] Loss: -1216.581299\n",
      "Train Epoch: 1118 [10378/17352 (60%)] Loss: -1177.635554\n",
      "Train Epoch: 1118 [17106/17352 (99%)] Loss: -1246.844016\n",
      "    epoch          : 1118\n",
      "    loss           : -1168.3960518321899\n",
      "    val_loss       : -1129.317635627768\n",
      "    val_log_likelihood: 1604.2376007389162\n",
      "    val_log_marginal: 1167.4730870458854\n",
      "Train Epoch: 1119 [512/17352 (3%)] Loss: -1195.407471\n",
      "Train Epoch: 1119 [9964/17352 (57%)] Loss: -1233.407744\n",
      "Train Epoch: 1119 [17044/17352 (98%)] Loss: -1143.811231\n",
      "    epoch          : 1119\n",
      "    loss           : -1132.904616972981\n",
      "    val_loss       : -1153.44056339523\n",
      "    val_log_likelihood: 1608.5007004160684\n",
      "    val_log_marginal: 1174.2928939169942\n",
      "Train Epoch: 1120 [512/17352 (3%)] Loss: -1205.113281\n",
      "Train Epoch: 1120 [10538/17352 (61%)] Loss: -1085.256920\n",
      "Train Epoch: 1120 [17263/17352 (99%)] Loss: -1165.898849\n",
      "    epoch          : 1120\n",
      "    loss           : -1180.1061241197283\n",
      "    val_loss       : -1133.3340504345392\n",
      "    val_log_likelihood: 1611.2734494513004\n",
      "    val_log_marginal: 1178.238040326164\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1120.pth ...\n",
      "Train Epoch: 1121 [512/17352 (3%)] Loss: -1208.570068\n",
      "Train Epoch: 1121 [10542/17352 (61%)] Loss: -1260.950665\n",
      "Train Epoch: 1121 [17124/17352 (99%)] Loss: -1012.092925\n",
      "    epoch          : 1121\n",
      "    loss           : -1147.1836527265532\n",
      "    val_loss       : -1099.272883493548\n",
      "    val_log_likelihood: 1595.0503082622624\n",
      "    val_log_marginal: 1147.3796422417915\n",
      "Train Epoch: 1122 [512/17352 (3%)] Loss: -1175.016602\n",
      "Train Epoch: 1122 [10664/17352 (61%)] Loss: -1256.806598\n",
      "Train Epoch: 1122 [16934/17352 (98%)] Loss: -930.951686\n",
      "    epoch          : 1122\n",
      "    loss           : -1108.2935532960178\n",
      "    val_loss       : -1126.0664124096759\n",
      "    val_log_likelihood: 1590.238911019369\n",
      "    val_log_marginal: 1146.9418124450347\n",
      "Train Epoch: 1123 [512/17352 (3%)] Loss: -1033.465576\n",
      "Train Epoch: 1123 [10180/17352 (59%)] Loss: -1076.419954\n",
      "Train Epoch: 1123 [17277/17352 (100%)] Loss: -1110.073312\n",
      "    epoch          : 1123\n",
      "    loss           : -1145.0477931931637\n",
      "    val_loss       : -1168.4047967468216\n",
      "    val_log_likelihood: 1613.6764314832699\n",
      "    val_log_marginal: 1176.2343985862371\n",
      "Train Epoch: 1124 [512/17352 (3%)] Loss: -1208.793213\n",
      "Train Epoch: 1124 [9973/17352 (57%)] Loss: -1212.603053\n",
      "Train Epoch: 1124 [16883/17352 (97%)] Loss: -1253.615600\n",
      "    epoch          : 1124\n",
      "    loss           : -1135.3555760111785\n",
      "    val_loss       : -1132.8470944820222\n",
      "    val_log_likelihood: 1606.7502687270455\n",
      "    val_log_marginal: 1169.9025032717186\n",
      "Train Epoch: 1125 [512/17352 (3%)] Loss: -1206.740479\n",
      "Train Epoch: 1125 [9838/17352 (57%)] Loss: -1202.843061\n",
      "Train Epoch: 1125 [17106/17352 (99%)] Loss: -1235.303536\n",
      "    epoch          : 1125\n",
      "    loss           : -1162.8108029348753\n",
      "    val_loss       : -1154.5095314533592\n",
      "    val_log_likelihood: 1612.6296011927404\n",
      "    val_log_marginal: 1173.3556839575845\n",
      "Train Epoch: 1126 [512/17352 (3%)] Loss: -1196.640137\n",
      "Train Epoch: 1126 [10535/17352 (61%)] Loss: -1063.759592\n",
      "Train Epoch: 1126 [16992/17352 (98%)] Loss: -1221.046482\n",
      "    epoch          : 1126\n",
      "    loss           : -1143.0097008257753\n",
      "    val_loss       : -1155.4006043437955\n",
      "    val_log_likelihood: 1621.5844862080705\n",
      "    val_log_marginal: 1170.7836023199984\n",
      "Train Epoch: 1127 [512/17352 (3%)] Loss: -1190.671387\n",
      "Train Epoch: 1127 [10469/17352 (60%)] Loss: -1122.391183\n",
      "Train Epoch: 1127 [16988/17352 (98%)] Loss: -1207.525726\n",
      "    epoch          : 1127\n",
      "    loss           : -1145.482076272904\n",
      "    val_loss       : -1083.6975720519756\n",
      "    val_log_likelihood: 1618.5197451193653\n",
      "    val_log_marginal: 1099.4265903873843\n",
      "Train Epoch: 1128 [512/17352 (3%)] Loss: -1012.713989\n",
      "Train Epoch: 1128 [10825/17352 (62%)] Loss: -1102.382118\n",
      "Train Epoch: 1128 [17108/17352 (99%)] Loss: -1162.614085\n",
      "    epoch          : 1128\n",
      "    loss           : -1137.1329583303375\n",
      "    val_loss       : -1171.6996963766621\n",
      "    val_log_likelihood: 1621.9580483695825\n",
      "    val_log_marginal: 1181.2714829376748\n",
      "Train Epoch: 1129 [512/17352 (3%)] Loss: -1207.520996\n",
      "Train Epoch: 1129 [10216/17352 (59%)] Loss: -823.283430\n",
      "Train Epoch: 1129 [16887/17352 (97%)] Loss: -981.821461\n",
      "    epoch          : 1129\n",
      "    loss           : -1094.3255378447934\n",
      "    val_loss       : -1131.5113752090092\n",
      "    val_log_likelihood: 1611.994626101489\n",
      "    val_log_marginal: 1153.887009855582\n",
      "Train Epoch: 1130 [512/17352 (3%)] Loss: -1189.728027\n",
      "Train Epoch: 1130 [10237/17352 (59%)] Loss: -968.256250\n",
      "Train Epoch: 1130 [17016/17352 (98%)] Loss: -1131.856962\n",
      "    epoch          : 1130\n",
      "    loss           : -1145.2024696226938\n",
      "    val_loss       : -1119.9345609596785\n",
      "    val_log_likelihood: 1617.3855605676395\n",
      "    val_log_marginal: 1143.3148583898342\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1130.pth ...\n",
      "Train Epoch: 1131 [512/17352 (3%)] Loss: -1158.172974\n",
      "Train Epoch: 1131 [10457/17352 (60%)] Loss: -1218.348063\n",
      "Train Epoch: 1131 [17133/17352 (99%)] Loss: -1059.841642\n",
      "    epoch          : 1131\n",
      "    loss           : -1037.5604965934858\n",
      "    val_loss       : -989.6274304312884\n",
      "    val_log_likelihood: 1545.0844190205357\n",
      "    val_log_marginal: 1021.986024492998\n",
      "Train Epoch: 1132 [512/17352 (3%)] Loss: -1081.748291\n",
      "Train Epoch: 1132 [10508/17352 (61%)] Loss: -1256.202633\n",
      "Train Epoch: 1132 [16887/17352 (97%)] Loss: -1141.628430\n",
      "    epoch          : 1132\n",
      "    loss           : -1098.257561585452\n",
      "    val_loss       : -1135.6083574382415\n",
      "    val_log_likelihood: 1612.1480957990152\n",
      "    val_log_marginal: 1181.4148028855996\n",
      "Train Epoch: 1133 [512/17352 (3%)] Loss: -1063.188599\n",
      "Train Epoch: 1133 [10341/17352 (60%)] Loss: -1295.618070\n",
      "Train Epoch: 1133 [17064/17352 (98%)] Loss: -1204.819777\n",
      "    epoch          : 1133\n",
      "    loss           : -1164.3191123137308\n",
      "    val_loss       : -1150.1600381435412\n",
      "    val_log_likelihood: 1615.903832042554\n",
      "    val_log_marginal: 1180.3936651641009\n",
      "Train Epoch: 1134 [512/17352 (3%)] Loss: -1208.661865\n",
      "Train Epoch: 1134 [10120/17352 (58%)] Loss: -1099.614768\n",
      "Train Epoch: 1134 [17049/17352 (98%)] Loss: -979.957639\n",
      "    epoch          : 1134\n",
      "    loss           : -1141.677766936253\n",
      "    val_loss       : -1094.192565055479\n",
      "    val_log_likelihood: 1609.4748030228156\n",
      "    val_log_marginal: 1099.2867769514824\n",
      "Train Epoch: 1135 [512/17352 (3%)] Loss: -1129.013550\n",
      "Train Epoch: 1135 [10500/17352 (61%)] Loss: -1132.106470\n",
      "Train Epoch: 1135 [17335/17352 (100%)] Loss: -951.026712\n",
      "    epoch          : 1135\n",
      "    loss           : -1089.6907645548545\n",
      "    val_loss       : -1067.3637801737889\n",
      "    val_log_likelihood: 1594.3704063198936\n",
      "    val_log_marginal: 1119.745398072989\n",
      "Train Epoch: 1136 [512/17352 (3%)] Loss: -1035.198364\n",
      "Train Epoch: 1136 [10431/17352 (60%)] Loss: -1211.494401\n",
      "Train Epoch: 1136 [16922/17352 (98%)] Loss: -1129.464190\n",
      "    epoch          : 1136\n",
      "    loss           : -1124.8876486847093\n",
      "    val_loss       : -1108.897195660154\n",
      "    val_log_likelihood: 1609.7865697207703\n",
      "    val_log_marginal: 1166.2022422852635\n",
      "Train Epoch: 1137 [512/17352 (3%)] Loss: -1213.642090\n",
      "Train Epoch: 1137 [10704/17352 (62%)] Loss: -1178.580266\n",
      "Train Epoch: 1137 [16883/17352 (97%)] Loss: -1002.018038\n",
      "    epoch          : 1137\n",
      "    loss           : -1111.2085560036412\n",
      "    val_loss       : -998.3543524342067\n",
      "    val_log_likelihood: 1595.7386308903322\n",
      "    val_log_marginal: 1031.8230206214105\n",
      "Train Epoch: 1138 [512/17352 (3%)] Loss: -906.124023\n",
      "Train Epoch: 1138 [10721/17352 (62%)] Loss: -1241.356329\n",
      "Train Epoch: 1138 [17133/17352 (99%)] Loss: -1043.300885\n",
      "    epoch          : 1138\n",
      "    loss           : -1084.9369778831838\n",
      "    val_loss       : -1069.6553544637995\n",
      "    val_log_likelihood: 1565.283005477783\n",
      "    val_log_marginal: 1072.1248681114337\n",
      "Train Epoch: 1139 [512/17352 (3%)] Loss: -1085.082886\n",
      "Train Epoch: 1139 [10259/17352 (59%)] Loss: -1148.326195\n",
      "Train Epoch: 1139 [17335/17352 (100%)] Loss: -1254.711637\n",
      "    epoch          : 1139\n",
      "    loss           : -1100.353882709954\n",
      "    val_loss       : -976.2790077283421\n",
      "    val_log_likelihood: 1504.2963312270374\n",
      "    val_log_marginal: 1003.4668740659537\n",
      "Train Epoch: 1140 [512/17352 (3%)] Loss: -1036.733154\n",
      "Train Epoch: 1140 [10680/17352 (62%)] Loss: -1232.833360\n",
      "Train Epoch: 1140 [17263/17352 (99%)] Loss: -985.773320\n",
      "    epoch          : 1140\n",
      "    loss           : -1126.5739876692712\n",
      "    val_loss       : -981.4448451028821\n",
      "    val_log_likelihood: 1519.0412421734413\n",
      "    val_log_marginal: 1022.3375121812476\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1140.pth ...\n",
      "Train Epoch: 1141 [512/17352 (3%)] Loss: -1054.655029\n",
      "Train Epoch: 1141 [9971/17352 (57%)] Loss: -1214.988795\n",
      "Train Epoch: 1141 [17253/17352 (99%)] Loss: -1255.393085\n",
      "    epoch          : 1141\n",
      "    loss           : -1075.9681869773328\n",
      "    val_loss       : -1123.0602174172109\n",
      "    val_log_likelihood: 1599.729385719161\n",
      "    val_log_marginal: 1152.5052730980826\n",
      "Train Epoch: 1142 [512/17352 (3%)] Loss: -1188.928833\n",
      "Train Epoch: 1142 [10427/17352 (60%)] Loss: -772.137593\n",
      "Train Epoch: 1142 [16939/17352 (98%)] Loss: -1044.871043\n",
      "    epoch          : 1142\n",
      "    loss           : -1081.4075144299518\n",
      "    val_loss       : -1146.3051768451526\n",
      "    val_log_likelihood: 1602.7980808306522\n",
      "    val_log_marginal: 1165.314688787195\n",
      "Train Epoch: 1143 [512/17352 (3%)] Loss: -1198.350342\n",
      "Train Epoch: 1143 [9849/17352 (57%)] Loss: -1199.887753\n",
      "Train Epoch: 1143 [17016/17352 (98%)] Loss: -1183.122718\n",
      "    epoch          : 1143\n",
      "    loss           : -1158.911789261452\n",
      "    val_loss       : -1168.8874565264541\n",
      "    val_log_likelihood: 1622.4218309925368\n",
      "    val_log_marginal: 1189.4348968201464\n",
      "Train Epoch: 1144 [512/17352 (3%)] Loss: -1079.027710\n",
      "Train Epoch: 1144 [10473/17352 (60%)] Loss: -1136.933808\n",
      "Train Epoch: 1144 [17263/17352 (99%)] Loss: -873.744699\n",
      "    epoch          : 1144\n",
      "    loss           : -1136.168572134023\n",
      "    val_loss       : -1122.8729713666712\n",
      "    val_log_likelihood: 1610.7770801151557\n",
      "    val_log_marginal: 1134.9204982959052\n",
      "Train Epoch: 1145 [512/17352 (3%)] Loss: -1170.339844\n",
      "Train Epoch: 1145 [10517/17352 (61%)] Loss: -956.186827\n",
      "Train Epoch: 1145 [16922/17352 (98%)] Loss: -1200.997759\n",
      "    epoch          : 1145\n",
      "    loss           : -1144.530610733226\n",
      "    val_loss       : -1172.5022735777563\n",
      "    val_log_likelihood: 1622.2299958683966\n",
      "    val_log_marginal: 1185.6599205265738\n",
      "Train Epoch: 1146 [512/17352 (3%)] Loss: -1224.550537\n",
      "Train Epoch: 1146 [10198/17352 (59%)] Loss: -1072.539752\n",
      "Train Epoch: 1146 [16883/17352 (97%)] Loss: -1225.885290\n",
      "    epoch          : 1146\n",
      "    loss           : -1137.5990834494537\n",
      "    val_loss       : -1101.695918093723\n",
      "    val_log_likelihood: 1620.4980399166932\n",
      "    val_log_marginal: 1150.6674055817418\n",
      "Train Epoch: 1147 [512/17352 (3%)] Loss: -1184.184692\n",
      "Train Epoch: 1147 [10314/17352 (59%)] Loss: -1171.328244\n",
      "Train Epoch: 1147 [16939/17352 (98%)] Loss: -1089.132302\n",
      "    epoch          : 1147\n",
      "    loss           : -1062.2716925700763\n",
      "    val_loss       : -1119.930957227498\n",
      "    val_log_likelihood: 1611.8546841922887\n",
      "    val_log_marginal: 1131.7964776438685\n",
      "Train Epoch: 1148 [512/17352 (3%)] Loss: -1168.013916\n",
      "Train Epoch: 1148 [10228/17352 (59%)] Loss: -1119.170759\n",
      "Train Epoch: 1148 [17263/17352 (99%)] Loss: -601.108350\n",
      "    epoch          : 1148\n",
      "    loss           : -1125.9632490514505\n",
      "    val_loss       : -1141.186968941626\n",
      "    val_log_likelihood: 1617.5089516239368\n",
      "    val_log_marginal: 1160.9344307274566\n",
      "Train Epoch: 1149 [512/17352 (3%)] Loss: -1194.437012\n",
      "Train Epoch: 1149 [10967/17352 (63%)] Loss: -1242.452570\n",
      "Train Epoch: 1149 [17253/17352 (99%)] Loss: -1087.465052\n",
      "    epoch          : 1149\n",
      "    loss           : -1167.3437228921587\n",
      "    val_loss       : -1071.466552103247\n",
      "    val_log_likelihood: 1557.2783718490357\n",
      "    val_log_marginal: 1082.4784862406768\n",
      "Train Epoch: 1150 [512/17352 (3%)] Loss: -1064.661377\n",
      "Train Epoch: 1150 [10668/17352 (61%)] Loss: -1148.027995\n",
      "Train Epoch: 1150 [16934/17352 (98%)] Loss: -583.665961\n",
      "    epoch          : 1150\n",
      "    loss           : -1077.612249689607\n",
      "    val_loss       : -1016.0569377763102\n",
      "    val_log_likelihood: 1623.4878656071112\n",
      "    val_log_marginal: 1052.8158370258598\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1150.pth ...\n",
      "Train Epoch: 1151 [512/17352 (3%)] Loss: -1082.529419\n",
      "Train Epoch: 1151 [9652/17352 (56%)] Loss: -1167.011949\n",
      "Train Epoch: 1151 [17108/17352 (99%)] Loss: -1135.353057\n",
      "    epoch          : 1151\n",
      "    loss           : -1073.8379776219656\n",
      "    val_loss       : -949.4435603434856\n",
      "    val_log_likelihood: 1591.5802296127229\n",
      "    val_log_marginal: 963.7006060433009\n",
      "Train Epoch: 1152 [512/17352 (3%)] Loss: -919.121826\n",
      "Train Epoch: 1152 [9865/17352 (57%)] Loss: -1097.890625\n",
      "Train Epoch: 1152 [16878/17352 (97%)] Loss: -1120.702951\n",
      "    epoch          : 1152\n",
      "    loss           : -1118.2047842004563\n",
      "    val_loss       : -1170.6112709921708\n",
      "    val_log_likelihood: 1627.3784861959198\n",
      "    val_log_marginal: 1183.5353089305129\n",
      "Train Epoch: 1153 [512/17352 (3%)] Loss: -1220.057495\n",
      "Train Epoch: 1153 [10300/17352 (59%)] Loss: -1121.118086\n",
      "Train Epoch: 1153 [17064/17352 (98%)] Loss: -1044.331115\n",
      "    epoch          : 1153\n",
      "    loss           : -1113.637382458546\n",
      "    val_loss       : -1107.6586833775139\n",
      "    val_log_likelihood: 1611.683986469519\n",
      "    val_log_marginal: 1123.8897270353693\n",
      "Train Epoch: 1154 [512/17352 (3%)] Loss: -1005.411987\n",
      "Train Epoch: 1154 [10048/17352 (58%)] Loss: -1173.909341\n",
      "Train Epoch: 1154 [16922/17352 (98%)] Loss: -1314.949227\n",
      "    epoch          : 1154\n",
      "    loss           : -1131.2274726909889\n",
      "    val_loss       : -1115.1583379376857\n",
      "    val_log_likelihood: 1587.518825202717\n",
      "    val_log_marginal: 1130.3197641651793\n",
      "Train Epoch: 1155 [512/17352 (3%)] Loss: -1162.139038\n",
      "Train Epoch: 1155 [10253/17352 (59%)] Loss: -1156.415878\n",
      "Train Epoch: 1155 [17335/17352 (100%)] Loss: -1197.575457\n",
      "    epoch          : 1155\n",
      "    loss           : -1099.7684865092388\n",
      "    val_loss       : -1036.8750238192272\n",
      "    val_log_likelihood: 1540.763862440226\n",
      "    val_log_marginal: 1052.38488597773\n",
      "Train Epoch: 1156 [512/17352 (3%)] Loss: -1101.656738\n",
      "Train Epoch: 1156 [10567/17352 (61%)] Loss: -1045.245963\n",
      "Train Epoch: 1156 [17263/17352 (99%)] Loss: -867.171411\n",
      "    epoch          : 1156\n",
      "    loss           : -1118.4602794040975\n",
      "    val_loss       : -1083.4629881425287\n",
      "    val_log_likelihood: 1572.0200324382402\n",
      "    val_log_marginal: 1107.048829510912\n",
      "Train Epoch: 1157 [512/17352 (3%)] Loss: -1125.851440\n",
      "Train Epoch: 1157 [9797/17352 (56%)] Loss: -1168.924622\n",
      "Train Epoch: 1157 [17108/17352 (99%)] Loss: -1140.762709\n",
      "    epoch          : 1157\n",
      "    loss           : -1146.1508936159512\n",
      "    val_loss       : -1159.6312718630595\n",
      "    val_log_likelihood: 1617.126093176384\n",
      "    val_log_marginal: 1179.9218766111505\n",
      "Train Epoch: 1158 [512/17352 (3%)] Loss: -1204.716064\n",
      "Train Epoch: 1158 [10419/17352 (60%)] Loss: -1090.297130\n",
      "Train Epoch: 1158 [17133/17352 (99%)] Loss: -1201.334347\n",
      "    epoch          : 1158\n",
      "    loss           : -1167.21997351165\n",
      "    val_loss       : -1159.1375019988373\n",
      "    val_log_likelihood: 1628.6103344995004\n",
      "    val_log_marginal: 1192.1334167362725\n",
      "Train Epoch: 1159 [512/17352 (3%)] Loss: -1225.511597\n",
      "Train Epoch: 1159 [10163/17352 (59%)] Loss: -1149.489955\n",
      "Train Epoch: 1159 [17263/17352 (99%)] Loss: -1179.152699\n",
      "    epoch          : 1159\n",
      "    loss           : -1140.6519462204385\n",
      "    val_loss       : -993.9123335955815\n",
      "    val_log_likelihood: 1530.4011774959697\n",
      "    val_log_marginal: 1035.5600980834406\n",
      "Train Epoch: 1160 [512/17352 (3%)] Loss: 84.635437\n",
      "Train Epoch: 1160 [10763/17352 (62%)] Loss: -1044.826502\n",
      "Train Epoch: 1160 [16992/17352 (98%)] Loss: -742.516398\n",
      "    epoch          : 1160\n",
      "    loss           : -1031.2462223710636\n",
      "    val_loss       : -836.9611520879884\n",
      "    val_log_likelihood: 1422.7880704011038\n",
      "    val_log_marginal: 901.0853368241607\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1160.pth ...\n",
      "Train Epoch: 1161 [512/17352 (3%)] Loss: -937.101746\n",
      "Train Epoch: 1161 [10214/17352 (59%)] Loss: -838.343133\n",
      "Train Epoch: 1161 [16934/17352 (98%)] Loss: -1051.806526\n",
      "    epoch          : 1161\n",
      "    loss           : -835.5524631867193\n",
      "    val_loss       : -983.4329464060467\n",
      "    val_log_likelihood: 1512.9264576764865\n",
      "    val_log_marginal: 1064.2034263979858\n",
      "Train Epoch: 1162 [512/17352 (3%)] Loss: -1107.707642\n",
      "Train Epoch: 1162 [9910/17352 (57%)] Loss: -988.777803\n",
      "Train Epoch: 1162 [17016/17352 (98%)] Loss: -1003.772993\n",
      "    epoch          : 1162\n",
      "    loss           : -953.9389456151713\n",
      "    val_loss       : -1017.4097918120287\n",
      "    val_log_likelihood: 1494.920133975299\n",
      "    val_log_marginal: 1049.529558132874\n",
      "Train Epoch: 1163 [512/17352 (3%)] Loss: -1086.359253\n",
      "Train Epoch: 1163 [9553/17352 (55%)] Loss: -1150.236788\n",
      "Train Epoch: 1163 [16939/17352 (98%)] Loss: -1030.584543\n",
      "    epoch          : 1163\n",
      "    loss           : -1084.3038629020991\n",
      "    val_loss       : -1143.5828528056682\n",
      "    val_log_likelihood: 1585.0982633289789\n",
      "    val_log_marginal: 1166.2698434228569\n",
      "Train Epoch: 1164 [512/17352 (3%)] Loss: -1203.342163\n",
      "Train Epoch: 1164 [10515/17352 (61%)] Loss: -1220.233421\n",
      "Train Epoch: 1164 [17253/17352 (99%)] Loss: -1243.165292\n",
      "    epoch          : 1164\n",
      "    loss           : -1164.7911653608662\n",
      "    val_loss       : -1156.5719916644455\n",
      "    val_log_likelihood: 1606.1801395840619\n",
      "    val_log_marginal: 1188.726927376029\n",
      "Train Epoch: 1165 [512/17352 (3%)] Loss: -1088.937256\n",
      "Train Epoch: 1165 [10306/17352 (59%)] Loss: -1169.213235\n",
      "Train Epoch: 1165 [17090/17352 (98%)] Loss: -1148.035469\n",
      "    epoch          : 1165\n",
      "    loss           : -1162.8880990027246\n",
      "    val_loss       : -1181.9646035585706\n",
      "    val_log_likelihood: 1619.3555218531492\n",
      "    val_log_marginal: 1197.7287112412707\n",
      "Train Epoch: 1166 [512/17352 (3%)] Loss: -1233.867188\n",
      "Train Epoch: 1166 [10695/17352 (62%)] Loss: -1214.581858\n",
      "Train Epoch: 1166 [17016/17352 (98%)] Loss: -1149.462998\n",
      "    epoch          : 1166\n",
      "    loss           : -1118.3067014033422\n",
      "    val_loss       : -1093.2430933681685\n",
      "    val_log_likelihood: 1581.829369219535\n",
      "    val_log_marginal: 1137.2768584159858\n",
      "Train Epoch: 1167 [512/17352 (3%)] Loss: -1165.373535\n",
      "Train Epoch: 1167 [10514/17352 (61%)] Loss: -1256.192581\n",
      "Train Epoch: 1167 [16923/17352 (98%)] Loss: -1123.709928\n",
      "    epoch          : 1167\n",
      "    loss           : -1135.4626219254192\n",
      "    val_loss       : -1128.7920360910489\n",
      "    val_log_likelihood: 1600.4101709273268\n",
      "    val_log_marginal: 1165.8139421610438\n",
      "Train Epoch: 1168 [512/17352 (3%)] Loss: -1193.979248\n",
      "Train Epoch: 1168 [10290/17352 (59%)] Loss: -1011.888820\n",
      "Train Epoch: 1168 [16882/17352 (97%)] Loss: -910.608960\n",
      "    epoch          : 1168\n",
      "    loss           : -1123.6584705218186\n",
      "    val_loss       : -1105.8998523035639\n",
      "    val_log_likelihood: 1614.8460461230982\n",
      "    val_log_marginal: 1154.7766414015498\n",
      "Train Epoch: 1169 [512/17352 (3%)] Loss: -1187.240479\n",
      "Train Epoch: 1169 [10066/17352 (58%)] Loss: -1222.228945\n",
      "Train Epoch: 1169 [17143/17352 (99%)] Loss: -1065.571338\n",
      "    epoch          : 1169\n",
      "    loss           : -1115.948389632176\n",
      "    val_loss       : -1061.875814078032\n",
      "    val_log_likelihood: 1572.2549572237692\n",
      "    val_log_marginal: 1102.2705584993842\n",
      "Train Epoch: 1170 [512/17352 (3%)] Loss: -1032.664795\n",
      "Train Epoch: 1170 [10470/17352 (60%)] Loss: -940.228996\n",
      "Train Epoch: 1170 [17126/17352 (99%)] Loss: -896.873866\n",
      "    epoch          : 1170\n",
      "    loss           : -1099.5106938277402\n",
      "    val_loss       : -1100.134605019834\n",
      "    val_log_likelihood: 1605.0040532068329\n",
      "    val_log_marginal: 1155.3014932208353\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1170.pth ...\n",
      "Train Epoch: 1171 [512/17352 (3%)] Loss: -1183.620117\n",
      "Train Epoch: 1171 [10512/17352 (61%)] Loss: -1047.323950\n",
      "Train Epoch: 1171 [16992/17352 (98%)] Loss: -1238.586472\n",
      "    epoch          : 1171\n",
      "    loss           : -1101.7212428212626\n",
      "    val_loss       : -1143.470606223325\n",
      "    val_log_likelihood: 1592.2490696365767\n",
      "    val_log_marginal: 1159.1886869974019\n",
      "Train Epoch: 1172 [512/17352 (3%)] Loss: -1190.500244\n",
      "Train Epoch: 1172 [10514/17352 (61%)] Loss: -1164.572680\n",
      "Train Epoch: 1172 [16882/17352 (97%)] Loss: -1057.468686\n",
      "    epoch          : 1172\n",
      "    loss           : -1155.7047119087758\n",
      "    val_loss       : -1176.2771493338662\n",
      "    val_log_likelihood: 1612.9109359995966\n",
      "    val_log_marginal: 1186.5017093221034\n",
      "Train Epoch: 1173 [512/17352 (3%)] Loss: -1219.535645\n",
      "Train Epoch: 1173 [10742/17352 (62%)] Loss: -1237.657620\n",
      "Train Epoch: 1173 [17133/17352 (99%)] Loss: -1289.182506\n",
      "    epoch          : 1173\n",
      "    loss           : -1162.969515866571\n",
      "    val_loss       : -1130.5008654041253\n",
      "    val_log_likelihood: 1600.984123811512\n",
      "    val_log_marginal: 1165.6310966118165\n",
      "Train Epoch: 1174 [512/17352 (3%)] Loss: -1183.741821\n",
      "Train Epoch: 1174 [10417/17352 (60%)] Loss: -1235.078601\n",
      "Train Epoch: 1174 [17277/17352 (100%)] Loss: -1307.391276\n",
      "    epoch          : 1174\n",
      "    loss           : -1191.4215153208381\n",
      "    val_loss       : -1178.5783502854824\n",
      "    val_log_likelihood: 1631.8219746616219\n",
      "    val_log_marginal: 1202.4843738619113\n",
      "Train Epoch: 1175 [512/17352 (3%)] Loss: -1231.585938\n",
      "Train Epoch: 1175 [9965/17352 (57%)] Loss: -1173.174403\n",
      "Train Epoch: 1175 [16957/17352 (98%)] Loss: -1187.596749\n",
      "    epoch          : 1175\n",
      "    loss           : -1188.5652196269116\n",
      "    val_loss       : -1153.0134851665644\n",
      "    val_log_likelihood: 1635.1991897324813\n",
      "    val_log_marginal: 1206.6162614594843\n",
      "Train Epoch: 1176 [512/17352 (3%)] Loss: -810.153625\n",
      "Train Epoch: 1176 [10087/17352 (58%)] Loss: -1219.637292\n",
      "Train Epoch: 1176 [17090/17352 (98%)] Loss: -468.338525\n",
      "    epoch          : 1176\n",
      "    loss           : -1073.1990887549516\n",
      "    val_loss       : -879.7127777048408\n",
      "    val_log_likelihood: 1589.5480233079466\n",
      "    val_log_marginal: 905.6963085601378\n",
      "Train Epoch: 1177 [512/17352 (3%)] Loss: -938.944580\n",
      "Train Epoch: 1177 [10100/17352 (58%)] Loss: -1199.039099\n",
      "Train Epoch: 1177 [16872/17352 (97%)] Loss: -748.179997\n",
      "    epoch          : 1177\n",
      "    loss           : -1050.5569467909556\n",
      "    val_loss       : -1075.8292045645635\n",
      "    val_log_likelihood: 1598.752580746205\n",
      "    val_log_marginal: 1126.3945770147932\n",
      "Train Epoch: 1178 [512/17352 (3%)] Loss: -1157.378784\n",
      "Train Epoch: 1178 [10394/17352 (60%)] Loss: -1293.775853\n",
      "Train Epoch: 1178 [17253/17352 (99%)] Loss: -1058.061262\n",
      "    epoch          : 1178\n",
      "    loss           : -1135.1780181815645\n",
      "    val_loss       : -891.1960112868755\n",
      "    val_log_likelihood: 1592.9145302869738\n",
      "    val_log_marginal: 904.7531986204332\n",
      "Train Epoch: 1179 [512/17352 (3%)] Loss: -939.154724\n",
      "Train Epoch: 1179 [10423/17352 (60%)] Loss: -1117.598410\n",
      "Train Epoch: 1179 [16988/17352 (98%)] Loss: -1111.915612\n",
      "    epoch          : 1179\n",
      "    loss           : -1063.0491970043454\n",
      "    val_loss       : -1098.0568277385694\n",
      "    val_log_likelihood: 1584.4873517892731\n",
      "    val_log_marginal: 1130.7546700246542\n",
      "Train Epoch: 1180 [512/17352 (3%)] Loss: -1149.861450\n",
      "Train Epoch: 1180 [10940/17352 (63%)] Loss: -1251.355319\n",
      "Train Epoch: 1180 [16878/17352 (97%)] Loss: -1142.942370\n",
      "    epoch          : 1180\n",
      "    loss           : -1153.4261389657083\n",
      "    val_loss       : -1185.9480857561261\n",
      "    val_log_likelihood: 1634.8997649618022\n",
      "    val_log_marginal: 1205.0299309349552\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1180.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1181 [512/17352 (3%)] Loss: -1233.071045\n",
      "Train Epoch: 1181 [10084/17352 (58%)] Loss: -1125.000689\n",
      "Train Epoch: 1181 [16958/17352 (98%)] Loss: -1162.828364\n",
      "    epoch          : 1181\n",
      "    loss           : -1131.896583393471\n",
      "    val_loss       : -1141.52518676682\n",
      "    val_log_likelihood: 1622.4772548259969\n",
      "    val_log_marginal: 1167.8800129359588\n",
      "Train Epoch: 1182 [512/17352 (3%)] Loss: -1200.127930\n",
      "Train Epoch: 1182 [10734/17352 (62%)] Loss: -1128.746835\n",
      "Train Epoch: 1182 [17335/17352 (100%)] Loss: -1184.257396\n",
      "    epoch          : 1182\n",
      "    loss           : -1129.1340452423399\n",
      "    val_loss       : -680.3137221982514\n",
      "    val_log_likelihood: 1446.668977129589\n",
      "    val_log_marginal: 705.5487364479708\n",
      "Train Epoch: 1183 [512/17352 (3%)] Loss: -710.128235\n",
      "Train Epoch: 1183 [10405/17352 (60%)] Loss: -805.469066\n",
      "Train Epoch: 1183 [17090/17352 (98%)] Loss: -1057.644912\n",
      "    epoch          : 1183\n",
      "    loss           : -942.1321314780159\n",
      "    val_loss       : -1072.271897354507\n",
      "    val_log_likelihood: 1562.9144769146524\n",
      "    val_log_marginal: 1090.5183170211503\n",
      "Train Epoch: 1184 [512/17352 (3%)] Loss: -1106.899170\n",
      "Train Epoch: 1184 [10144/17352 (58%)] Loss: -1094.951899\n",
      "Train Epoch: 1184 [16887/17352 (97%)] Loss: -893.189540\n",
      "    epoch          : 1184\n",
      "    loss           : -1013.884993239283\n",
      "    val_loss       : -935.2910705808987\n",
      "    val_log_likelihood: 1519.4556790570005\n",
      "    val_log_marginal: 965.3956505780282\n",
      "Train Epoch: 1185 [512/17352 (3%)] Loss: -993.227661\n",
      "Train Epoch: 1185 [10825/17352 (62%)] Loss: -1100.827195\n",
      "Train Epoch: 1185 [17277/17352 (100%)] Loss: -1193.769937\n",
      "    epoch          : 1185\n",
      "    loss           : -1069.5834388616574\n",
      "    val_loss       : -1073.3887051557017\n",
      "    val_log_likelihood: 1591.305146469889\n",
      "    val_log_marginal: 1132.1239244105377\n",
      "Train Epoch: 1186 [512/17352 (3%)] Loss: -1036.464355\n",
      "Train Epoch: 1186 [9983/17352 (58%)] Loss: -1210.362017\n",
      "Train Epoch: 1186 [16883/17352 (97%)] Loss: -1121.338371\n",
      "    epoch          : 1186\n",
      "    loss           : -1164.5831081472145\n",
      "    val_loss       : -1161.8780930251849\n",
      "    val_log_likelihood: 1620.2728741656508\n",
      "    val_log_marginal: 1199.0368697231622\n",
      "Train Epoch: 1187 [512/17352 (3%)] Loss: -1233.019775\n",
      "Train Epoch: 1187 [10555/17352 (61%)] Loss: -870.058602\n",
      "Train Epoch: 1187 [17090/17352 (98%)] Loss: -1026.393648\n",
      "    epoch          : 1187\n",
      "    loss           : -1162.7544678506567\n",
      "    val_loss       : -1086.799529854272\n",
      "    val_log_likelihood: 1618.350464349449\n",
      "    val_log_marginal: 1107.8034997346067\n",
      "Train Epoch: 1188 [512/17352 (3%)] Loss: -992.743286\n",
      "Train Epoch: 1188 [10277/17352 (59%)] Loss: -1056.730380\n",
      "Train Epoch: 1188 [17126/17352 (99%)] Loss: -1030.902327\n",
      "    epoch          : 1188\n",
      "    loss           : -945.877905439942\n",
      "    val_loss       : 102.48861043290694\n",
      "    val_log_likelihood: 1467.2528727404795\n",
      "    val_log_marginal: -49.07928652554414\n",
      "Train Epoch: 1189 [512/17352 (3%)] Loss: -77.552536\n",
      "Train Epoch: 1189 [10159/17352 (59%)] Loss: -300.000069\n",
      "Train Epoch: 1189 [16882/17352 (97%)] Loss: -56.487766\n",
      "    epoch          : 1189\n",
      "    loss           : -462.5546114994207\n",
      "    val_loss       : -423.51613285399577\n",
      "    val_log_likelihood: 1342.9537146499515\n",
      "    val_log_marginal: 444.90801068777074\n",
      "Train Epoch: 1190 [512/17352 (3%)] Loss: -560.237427\n",
      "Train Epoch: 1190 [10103/17352 (58%)] Loss: 1293.236056\n",
      "Train Epoch: 1190 [17064/17352 (98%)] Loss: -852.169057\n",
      "    epoch          : 1190\n",
      "    loss           : -337.32462733784035\n",
      "    val_loss       : -617.633438696005\n",
      "    val_log_likelihood: 1417.9477487779168\n",
      "    val_log_marginal: 656.840905816399\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1190.pth ...\n",
      "Train Epoch: 1191 [512/17352 (3%)] Loss: -633.073486\n",
      "Train Epoch: 1191 [10424/17352 (60%)] Loss: -1032.491293\n",
      "Train Epoch: 1191 [16923/17352 (98%)] Loss: -1126.795416\n",
      "    epoch          : 1191\n",
      "    loss           : -1007.2271563901935\n",
      "    val_loss       : -1116.2742338544633\n",
      "    val_log_likelihood: 1563.9331835021364\n",
      "    val_log_marginal: 1141.4805847390844\n",
      "Train Epoch: 1192 [512/17352 (3%)] Loss: -1161.602661\n",
      "Train Epoch: 1192 [10307/17352 (59%)] Loss: -1229.249298\n",
      "Train Epoch: 1192 [17016/17352 (98%)] Loss: -1220.761198\n",
      "    epoch          : 1192\n",
      "    loss           : -1164.30701444125\n",
      "    val_loss       : -1168.7666442412028\n",
      "    val_log_likelihood: 1594.3338448449842\n",
      "    val_log_marginal: 1180.0802464919307\n",
      "Train Epoch: 1193 [512/17352 (3%)] Loss: -1210.323364\n",
      "Train Epoch: 1193 [10248/17352 (59%)] Loss: -1230.913854\n",
      "Train Epoch: 1193 [16939/17352 (98%)] Loss: -1085.313228\n",
      "    epoch          : 1193\n",
      "    loss           : -1164.0993739773967\n",
      "    val_loss       : -1149.746159515397\n",
      "    val_log_likelihood: 1595.8949005289112\n",
      "    val_log_marginal: 1171.816970588982\n",
      "Train Epoch: 1194 [512/17352 (3%)] Loss: -1201.197021\n",
      "Train Epoch: 1194 [10202/17352 (59%)] Loss: -1100.197646\n",
      "Train Epoch: 1194 [17277/17352 (100%)] Loss: -1047.396505\n",
      "    epoch          : 1194\n",
      "    loss           : -1156.2689710750506\n",
      "    val_loss       : -1120.027785772636\n",
      "    val_log_likelihood: 1588.3001414685657\n",
      "    val_log_marginal: 1133.037270915881\n",
      "Train Epoch: 1195 [512/17352 (3%)] Loss: -1160.970947\n",
      "Train Epoch: 1195 [10564/17352 (61%)] Loss: -1224.545703\n",
      "Train Epoch: 1195 [16988/17352 (98%)] Loss: -1221.663808\n",
      "    epoch          : 1195\n",
      "    loss           : -1148.9575808587965\n",
      "    val_loss       : -1162.0717752424707\n",
      "    val_log_likelihood: 1617.8212623018578\n",
      "    val_log_marginal: 1180.7782117165154\n",
      "Train Epoch: 1196 [512/17352 (3%)] Loss: -1205.879272\n",
      "Train Epoch: 1196 [10679/17352 (62%)] Loss: -1061.599798\n",
      "Train Epoch: 1196 [16957/17352 (98%)] Loss: -1265.719766\n",
      "    epoch          : 1196\n",
      "    loss           : -1169.1034866058246\n",
      "    val_loss       : -1166.8008093463804\n",
      "    val_log_likelihood: 1623.7970955495534\n",
      "    val_log_marginal: 1197.4742690513174\n",
      "Train Epoch: 1197 [512/17352 (3%)] Loss: -1225.259277\n",
      "Train Epoch: 1197 [10653/17352 (61%)] Loss: -1200.109533\n",
      "Train Epoch: 1197 [16872/17352 (97%)] Loss: -1177.980142\n",
      "    epoch          : 1197\n",
      "    loss           : -1176.6032727263507\n",
      "    val_loss       : -1179.502082351956\n",
      "    val_log_likelihood: 1629.4207944410339\n",
      "    val_log_marginal: 1202.6053192888448\n",
      "Train Epoch: 1198 [512/17352 (3%)] Loss: -1076.610962\n",
      "Train Epoch: 1198 [10313/17352 (59%)] Loss: -1138.080558\n",
      "Train Epoch: 1198 [16934/17352 (98%)] Loss: -1291.633247\n",
      "    epoch          : 1198\n",
      "    loss           : -1192.5471734126513\n",
      "    val_loss       : -1194.5197146827757\n",
      "    val_log_likelihood: 1637.1406067168014\n",
      "    val_log_marginal: 1210.4750261489196\n",
      "Train Epoch: 1199 [512/17352 (3%)] Loss: -1245.806152\n",
      "Train Epoch: 1199 [10402/17352 (60%)] Loss: -1258.652917\n",
      "Train Epoch: 1199 [16872/17352 (97%)] Loss: -1106.456148\n",
      "    epoch          : 1199\n",
      "    loss           : -1179.6842230740065\n",
      "    val_loss       : -1192.7743792139038\n",
      "    val_log_likelihood: 1639.8235508235446\n",
      "    val_log_marginal: 1205.8947125033976\n",
      "Train Epoch: 1200 [512/17352 (3%)] Loss: -1240.440430\n",
      "Train Epoch: 1200 [10795/17352 (62%)] Loss: -1140.941406\n",
      "Train Epoch: 1200 [17277/17352 (100%)] Loss: -1165.208070\n",
      "    epoch          : 1200\n",
      "    loss           : -1186.1579215959669\n",
      "    val_loss       : -1083.617726278146\n",
      "    val_log_likelihood: 1581.9495896498922\n",
      "    val_log_marginal: 1118.5812377535965\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0505_180806/checkpoint-epoch1200.pth ...\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:categorical_bpl] *",
   "language": "python",
   "name": "conda-env-categorical_bpl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
