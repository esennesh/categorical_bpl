{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/categorical_bpl\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = collections.namedtuple('Args', 'config resume device')\n",
    "config = ConfigParser.from_args(Args(config='omniglot_config.json', resume=None, device=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = config.get_logger('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = pyro.optim.StepLR({\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'optim_args': {\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": 0,\n",
    "        \"amsgrad\": True\n",
    "    },\n",
    "    \"step_size\": 400,\n",
    "    \"gamma\": 0.1,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, [], optimizer, config=config,\n",
    "                  data_loader=data_loader,\n",
    "                  valid_data_loader=valid_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [512/17352 (3%)] Loss: 1802.379150\n",
      "Train Epoch: 1 [10099/17352 (58%)] Loss: 1021.206687\n",
      "Train Epoch: 1 [17143/17352 (99%)] Loss: 948.891772\n",
      "    epoch          : 1\n",
      "    loss           : 1130.2835686776448\n",
      "    val_loss       : 957.4353819375941\n",
      "Train Epoch: 2 [512/17352 (3%)] Loss: 940.922180\n",
      "Train Epoch: 2 [10201/17352 (59%)] Loss: 915.099315\n",
      "Train Epoch: 2 [16934/17352 (98%)] Loss: 896.869462\n",
      "    epoch          : 2\n",
      "    loss           : 888.6258302270719\n",
      "    val_loss       : 844.6804248069985\n",
      "Train Epoch: 3 [512/17352 (3%)] Loss: 814.329468\n",
      "Train Epoch: 3 [10495/17352 (60%)] Loss: 783.363467\n",
      "Train Epoch: 3 [16882/17352 (97%)] Loss: 775.518790\n",
      "    epoch          : 3\n",
      "    loss           : 806.8475524359661\n",
      "    val_loss       : 786.1656532180142\n",
      "Train Epoch: 4 [512/17352 (3%)] Loss: 799.465942\n",
      "Train Epoch: 4 [10126/17352 (58%)] Loss: 809.949618\n",
      "Train Epoch: 4 [17106/17352 (99%)] Loss: 747.410057\n",
      "    epoch          : 4\n",
      "    loss           : 777.4439155074801\n",
      "    val_loss       : 760.4387201790774\n",
      "Train Epoch: 5 [512/17352 (3%)] Loss: 747.680298\n",
      "Train Epoch: 5 [10604/17352 (61%)] Loss: 699.792511\n",
      "Train Epoch: 5 [17253/17352 (99%)] Loss: 726.300000\n",
      "    epoch          : 5\n",
      "    loss           : 722.9712580773892\n",
      "    val_loss       : 717.7813655630482\n",
      "Train Epoch: 6 [512/17352 (3%)] Loss: 708.588013\n",
      "Train Epoch: 6 [10845/17352 (62%)] Loss: 693.963528\n",
      "Train Epoch: 6 [16939/17352 (98%)] Loss: 678.147797\n",
      "    epoch          : 6\n",
      "    loss           : 696.6745969814093\n",
      "    val_loss       : 688.6434649718818\n",
      "Train Epoch: 7 [512/17352 (3%)] Loss: 674.894653\n",
      "Train Epoch: 7 [10106/17352 (58%)] Loss: 672.011416\n",
      "Train Epoch: 7 [17101/17352 (99%)] Loss: 662.493737\n",
      "    epoch          : 7\n",
      "    loss           : 670.1538067501239\n",
      "    val_loss       : 663.0983325028744\n",
      "Train Epoch: 8 [512/17352 (3%)] Loss: 655.664307\n",
      "Train Epoch: 8 [9923/17352 (57%)] Loss: 649.371373\n",
      "Train Epoch: 8 [17090/17352 (98%)] Loss: 643.183220\n",
      "    epoch          : 8\n",
      "    loss           : 645.7237826584986\n",
      "    val_loss       : 643.5687964204254\n",
      "Train Epoch: 9 [512/17352 (3%)] Loss: 637.057434\n",
      "Train Epoch: 9 [10075/17352 (58%)] Loss: 638.663890\n",
      "Train Epoch: 9 [16922/17352 (98%)] Loss: 621.981961\n",
      "    epoch          : 9\n",
      "    loss           : 628.9354502703533\n",
      "    val_loss       : 618.9459469565447\n",
      "Train Epoch: 10 [512/17352 (3%)] Loss: 613.850342\n",
      "Train Epoch: 10 [10024/17352 (58%)] Loss: 604.173653\n",
      "Train Epoch: 10 [17101/17352 (99%)] Loss: 588.011727\n",
      "    epoch          : 10\n",
      "    loss           : 609.5359064806424\n",
      "    val_loss       : 607.9236364209286\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch10.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 11 [512/17352 (3%)] Loss: 604.932129\n",
      "Train Epoch: 11 [10505/17352 (61%)] Loss: 590.016623\n",
      "Train Epoch: 11 [16988/17352 (98%)] Loss: 576.900086\n",
      "    epoch          : 11\n",
      "    loss           : 590.1300692522757\n",
      "    val_loss       : 589.5776862751679\n",
      "Train Epoch: 12 [512/17352 (3%)] Loss: 585.793335\n",
      "Train Epoch: 12 [10471/17352 (60%)] Loss: 582.753215\n",
      "Train Epoch: 12 [17124/17352 (99%)] Loss: 571.851413\n",
      "    epoch          : 12\n",
      "    loss           : 573.6553653511519\n",
      "    val_loss       : 573.5248293221684\n",
      "Train Epoch: 13 [512/17352 (3%)] Loss: 568.480957\n",
      "Train Epoch: 13 [10698/17352 (62%)] Loss: 555.650298\n",
      "Train Epoch: 13 [16882/17352 (97%)] Loss: 550.699845\n",
      "    epoch          : 13\n",
      "    loss           : 557.2734349904107\n",
      "    val_loss       : 552.3620672581604\n",
      "Train Epoch: 14 [512/17352 (3%)] Loss: 548.597717\n",
      "Train Epoch: 14 [9923/17352 (57%)] Loss: 538.744463\n",
      "Train Epoch: 14 [17090/17352 (98%)] Loss: 525.904902\n",
      "    epoch          : 14\n",
      "    loss           : 540.3910354236529\n",
      "    val_loss       : 534.4467602510086\n",
      "Train Epoch: 15 [512/17352 (3%)] Loss: 529.695068\n",
      "Train Epoch: 15 [10423/17352 (60%)] Loss: 524.450048\n",
      "Train Epoch: 15 [16883/17352 (97%)] Loss: 524.648566\n",
      "    epoch          : 15\n",
      "    loss           : 527.6344307019383\n",
      "    val_loss       : 531.2690099439926\n",
      "Train Epoch: 16 [512/17352 (3%)] Loss: 524.772766\n",
      "Train Epoch: 16 [10546/17352 (61%)] Loss: 516.393693\n",
      "Train Epoch: 16 [16958/17352 (98%)] Loss: 511.717115\n",
      "    epoch          : 16\n",
      "    loss           : 515.9964385528799\n",
      "    val_loss       : 511.84721899611446\n",
      "Train Epoch: 17 [512/17352 (3%)] Loss: 504.473938\n",
      "Train Epoch: 17 [10013/17352 (58%)] Loss: 494.439884\n",
      "Train Epoch: 17 [17133/17352 (99%)] Loss: 487.657918\n",
      "    epoch          : 17\n",
      "    loss           : 491.89957938050395\n",
      "    val_loss       : 490.87200549860535\n",
      "Train Epoch: 18 [512/17352 (3%)] Loss: 486.749451\n",
      "Train Epoch: 18 [10279/17352 (59%)] Loss: 469.005000\n",
      "Train Epoch: 18 [17253/17352 (99%)] Loss: 480.712869\n",
      "    epoch          : 18\n",
      "    loss           : 475.86764317516\n",
      "    val_loss       : 474.9163419249034\n",
      "Train Epoch: 19 [512/17352 (3%)] Loss: 468.603943\n",
      "Train Epoch: 19 [10017/17352 (58%)] Loss: 478.102137\n",
      "Train Epoch: 19 [16882/17352 (97%)] Loss: 483.755982\n",
      "    epoch          : 19\n",
      "    loss           : 461.33018999835485\n",
      "    val_loss       : 459.33320812298524\n",
      "Train Epoch: 20 [512/17352 (3%)] Loss: 453.733826\n",
      "Train Epoch: 20 [10208/17352 (59%)] Loss: 448.000765\n",
      "Train Epoch: 20 [17124/17352 (99%)] Loss: 441.813472\n",
      "    epoch          : 20\n",
      "    loss           : 444.7394647024897\n",
      "    val_loss       : 438.6785050273939\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch20.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 21 [512/17352 (3%)] Loss: 432.491821\n",
      "Train Epoch: 21 [10214/17352 (59%)] Loss: 423.827998\n",
      "Train Epoch: 21 [16883/17352 (97%)] Loss: 429.555968\n",
      "    epoch          : 21\n",
      "    loss           : 428.07533400373256\n",
      "    val_loss       : 421.9770339260473\n",
      "Train Epoch: 22 [512/17352 (3%)] Loss: 417.701569\n",
      "Train Epoch: 22 [10683/17352 (62%)] Loss: 400.902360\n",
      "Train Epoch: 22 [17277/17352 (100%)] Loss: 411.027083\n",
      "    epoch          : 22\n",
      "    loss           : 410.9770700212871\n",
      "    val_loss       : 416.21821122564523\n",
      "Train Epoch: 23 [512/17352 (3%)] Loss: 411.457581\n",
      "Train Epoch: 23 [10082/17352 (58%)] Loss: 394.043264\n",
      "Train Epoch: 23 [17090/17352 (98%)] Loss: 388.349834\n",
      "    epoch          : 23\n",
      "    loss           : 396.21753393772144\n",
      "    val_loss       : 393.21160714862515\n",
      "Train Epoch: 24 [512/17352 (3%)] Loss: 387.102142\n",
      "Train Epoch: 24 [10471/17352 (60%)] Loss: 372.373576\n",
      "Train Epoch: 24 [17133/17352 (99%)] Loss: 372.059667\n",
      "    epoch          : 24\n",
      "    loss           : 383.68632916017265\n",
      "    val_loss       : 378.5571344562731\n",
      "Train Epoch: 25 [512/17352 (3%)] Loss: 372.771149\n",
      "Train Epoch: 25 [9961/17352 (57%)] Loss: 365.735624\n",
      "Train Epoch: 25 [17153/17352 (99%)] Loss: 371.962865\n",
      "    epoch          : 25\n",
      "    loss           : 368.7663782449692\n",
      "    val_loss       : 366.3556231126268\n",
      "Train Epoch: 26 [512/17352 (3%)] Loss: 360.880035\n",
      "Train Epoch: 26 [10381/17352 (60%)] Loss: 366.022129\n",
      "Train Epoch: 26 [17016/17352 (98%)] Loss: 334.424368\n",
      "    epoch          : 26\n",
      "    loss           : 352.13622474184643\n",
      "    val_loss       : 356.53907215283954\n",
      "Train Epoch: 27 [512/17352 (3%)] Loss: 352.461700\n",
      "Train Epoch: 27 [10126/17352 (58%)] Loss: 325.989710\n",
      "Train Epoch: 27 [17335/17352 (100%)] Loss: 325.745901\n",
      "    epoch          : 27\n",
      "    loss           : 336.8522757391388\n",
      "    val_loss       : 336.077470256853\n",
      "Train Epoch: 28 [512/17352 (3%)] Loss: 329.586426\n",
      "Train Epoch: 28 [9837/17352 (57%)] Loss: 325.347760\n",
      "Train Epoch: 28 [16957/17352 (98%)] Loss: 323.380986\n",
      "    epoch          : 28\n",
      "    loss           : 326.92527541261296\n",
      "    val_loss       : 316.91613211247113\n",
      "Train Epoch: 29 [512/17352 (3%)] Loss: 309.495148\n",
      "Train Epoch: 29 [10350/17352 (60%)] Loss: 295.672274\n",
      "Train Epoch: 29 [17106/17352 (99%)] Loss: 312.633101\n",
      "    epoch          : 29\n",
      "    loss           : 308.1196296941179\n",
      "    val_loss       : 302.3288157285847\n",
      "Train Epoch: 30 [512/17352 (3%)] Loss: 299.125458\n",
      "Train Epoch: 30 [10445/17352 (60%)] Loss: 276.174320\n",
      "Train Epoch: 30 [16958/17352 (98%)] Loss: 302.142681\n",
      "    epoch          : 30\n",
      "    loss           : 293.2970358327374\n",
      "    val_loss       : 286.85375873450107\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch30.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 31 [512/17352 (3%)] Loss: 285.046875\n",
      "Train Epoch: 31 [10278/17352 (59%)] Loss: 259.802719\n",
      "Train Epoch: 31 [17049/17352 (98%)] Loss: 266.530811\n",
      "    epoch          : 31\n",
      "    loss           : 279.00865990757296\n",
      "    val_loss       : 272.93972189854304\n",
      "Train Epoch: 32 [512/17352 (3%)] Loss: 269.307343\n",
      "Train Epoch: 32 [10059/17352 (58%)] Loss: 244.867384\n",
      "Train Epoch: 32 [16878/17352 (97%)] Loss: 277.158268\n",
      "    epoch          : 32\n",
      "    loss           : 265.6253377354071\n",
      "    val_loss       : 262.38137793274984\n",
      "Train Epoch: 33 [512/17352 (3%)] Loss: 257.699554\n",
      "Train Epoch: 33 [10249/17352 (59%)] Loss: 258.646615\n",
      "Train Epoch: 33 [17044/17352 (98%)] Loss: 244.681658\n",
      "    epoch          : 33\n",
      "    loss           : 254.11679117694803\n",
      "    val_loss       : 252.26049258806603\n",
      "Train Epoch: 34 [512/17352 (3%)] Loss: 249.916580\n",
      "Train Epoch: 34 [10501/17352 (61%)] Loss: 227.272643\n",
      "Train Epoch: 34 [17106/17352 (99%)] Loss: 227.990368\n",
      "    epoch          : 34\n",
      "    loss           : 256.2088765220183\n",
      "    val_loss       : 264.3111008492701\n",
      "Train Epoch: 35 [512/17352 (3%)] Loss: 253.807312\n",
      "Train Epoch: 35 [10019/17352 (58%)] Loss: 257.236057\n",
      "Train Epoch: 35 [17108/17352 (99%)] Loss: 225.679283\n",
      "    epoch          : 35\n",
      "    loss           : 233.8081264344257\n",
      "    val_loss       : 225.82760519312714\n",
      "Train Epoch: 36 [512/17352 (3%)] Loss: 218.966461\n",
      "Train Epoch: 36 [10179/17352 (59%)] Loss: 201.840354\n",
      "Train Epoch: 36 [16872/17352 (97%)] Loss: 189.130939\n",
      "    epoch          : 36\n",
      "    loss           : 213.4047689998231\n",
      "    val_loss       : 210.70763471942928\n",
      "Train Epoch: 37 [512/17352 (3%)] Loss: 198.977631\n",
      "Train Epoch: 37 [10071/17352 (58%)] Loss: 197.871341\n",
      "Train Epoch: 37 [16992/17352 (98%)] Loss: 230.830985\n",
      "    epoch          : 37\n",
      "    loss           : 203.58102955972015\n",
      "    val_loss       : 203.83091309751615\n",
      "Train Epoch: 38 [512/17352 (3%)] Loss: 196.051483\n",
      "Train Epoch: 38 [10664/17352 (61%)] Loss: 178.164534\n",
      "Train Epoch: 38 [17090/17352 (98%)] Loss: 195.901263\n",
      "    epoch          : 38\n",
      "    loss           : 197.3807163911791\n",
      "    val_loss       : 201.87829985290716\n",
      "Train Epoch: 39 [512/17352 (3%)] Loss: 191.213760\n",
      "Train Epoch: 39 [10453/17352 (60%)] Loss: 186.804175\n",
      "Train Epoch: 39 [16878/17352 (97%)] Loss: 228.455175\n",
      "    epoch          : 39\n",
      "    loss           : 193.20195008553682\n",
      "    val_loss       : 193.5725741740178\n",
      "Train Epoch: 40 [512/17352 (3%)] Loss: 182.735153\n",
      "Train Epoch: 40 [11332/17352 (65%)] Loss: 168.541172\n",
      "Train Epoch: 40 [17108/17352 (99%)] Loss: 128.578668\n",
      "    epoch          : 40\n",
      "    loss           : 171.80299694493274\n",
      "    val_loss       : 165.7380494997965\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch40.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 41 [512/17352 (3%)] Loss: 195.495972\n",
      "Train Epoch: 41 [9954/17352 (57%)] Loss: 159.731297\n",
      "Train Epoch: 41 [16992/17352 (98%)] Loss: 155.480120\n",
      "    epoch          : 41\n",
      "    loss           : 157.7722763187254\n",
      "    val_loss       : 159.24915298949153\n",
      "Train Epoch: 42 [512/17352 (3%)] Loss: 147.803894\n",
      "Train Epoch: 42 [10019/17352 (58%)] Loss: 123.881888\n",
      "Train Epoch: 42 [17108/17352 (99%)] Loss: 146.032775\n",
      "    epoch          : 42\n",
      "    loss           : 147.38347819925792\n",
      "    val_loss       : 145.14729682186507\n",
      "Train Epoch: 43 [512/17352 (3%)] Loss: 168.358612\n",
      "Train Epoch: 43 [10846/17352 (63%)] Loss: 85.961337\n",
      "Train Epoch: 43 [16923/17352 (98%)] Loss: 133.193964\n",
      "    epoch          : 43\n",
      "    loss           : 137.43661897037904\n",
      "    val_loss       : 137.72975889158667\n",
      "Train Epoch: 44 [512/17352 (3%)] Loss: 128.096985\n",
      "Train Epoch: 44 [10042/17352 (58%)] Loss: 128.955491\n",
      "Train Epoch: 44 [17124/17352 (99%)] Loss: 112.585690\n",
      "    epoch          : 44\n",
      "    loss           : 128.11454158642601\n",
      "    val_loss       : 129.5270816258877\n",
      "Train Epoch: 45 [512/17352 (3%)] Loss: 120.712494\n",
      "Train Epoch: 45 [10340/17352 (60%)] Loss: 158.868733\n",
      "Train Epoch: 45 [16939/17352 (98%)] Loss: 116.415499\n",
      "    epoch          : 45\n",
      "    loss           : 118.19850113962966\n",
      "    val_loss       : 115.1702036952747\n",
      "Train Epoch: 46 [512/17352 (3%)] Loss: 109.901756\n",
      "Train Epoch: 46 [10496/17352 (60%)] Loss: 103.580428\n",
      "Train Epoch: 46 [16882/17352 (97%)] Loss: 89.827441\n",
      "    epoch          : 46\n",
      "    loss           : 111.0010201674308\n",
      "    val_loss       : 110.73803195392257\n",
      "Train Epoch: 47 [512/17352 (3%)] Loss: 97.201797\n",
      "Train Epoch: 47 [9996/17352 (58%)] Loss: 118.580122\n",
      "Train Epoch: 47 [17253/17352 (99%)] Loss: 47.448707\n",
      "    epoch          : 47\n",
      "    loss           : 106.27404487631036\n",
      "    val_loss       : 226.9336528531438\n",
      "Train Epoch: 48 [512/17352 (3%)] Loss: 216.328552\n",
      "Train Epoch: 48 [9828/17352 (57%)] Loss: 79.137076\n",
      "Train Epoch: 48 [17153/17352 (99%)] Loss: 73.919586\n",
      "    epoch          : 48\n",
      "    loss           : 113.39352803301077\n",
      "    val_loss       : 112.17528196864043\n",
      "Train Epoch: 49 [512/17352 (3%)] Loss: 99.609985\n",
      "Train Epoch: 49 [10377/17352 (60%)] Loss: 59.570336\n",
      "Train Epoch: 49 [17124/17352 (99%)] Loss: 61.382071\n",
      "    epoch          : 49\n",
      "    loss           : 87.78851053919777\n",
      "    val_loss       : 93.55223808349318\n",
      "Train Epoch: 50 [512/17352 (3%)] Loss: 87.065880\n",
      "Train Epoch: 50 [10342/17352 (60%)] Loss: 93.529057\n",
      "Train Epoch: 50 [17044/17352 (98%)] Loss: 52.071750\n",
      "    epoch          : 50\n",
      "    loss           : 78.64194136747902\n",
      "    val_loss       : 77.26511306903363\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch50.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 51 [512/17352 (3%)] Loss: 71.638947\n",
      "Train Epoch: 51 [10206/17352 (59%)] Loss: 84.847073\n",
      "Train Epoch: 51 [17143/17352 (99%)] Loss: 113.618832\n",
      "    epoch          : 51\n",
      "    loss           : 68.3570922182931\n",
      "    val_loss       : 78.22397113194577\n",
      "Train Epoch: 52 [512/17352 (3%)] Loss: 65.200928\n",
      "Train Epoch: 52 [10466/17352 (60%)] Loss: -7.194530\n",
      "Train Epoch: 52 [16992/17352 (98%)] Loss: 56.870584\n",
      "    epoch          : 52\n",
      "    loss           : 59.47905826165031\n",
      "    val_loss       : 57.587045587224445\n",
      "Train Epoch: 53 [512/17352 (3%)] Loss: 44.978142\n",
      "Train Epoch: 53 [10513/17352 (61%)] Loss: 79.622036\n",
      "Train Epoch: 53 [17044/17352 (98%)] Loss: -15.585844\n",
      "    epoch          : 53\n",
      "    loss           : 51.102132454671384\n",
      "    val_loss       : 57.41132747036302\n",
      "Train Epoch: 54 [512/17352 (3%)] Loss: 47.579834\n",
      "Train Epoch: 54 [10426/17352 (60%)] Loss: 7.426939\n",
      "Train Epoch: 54 [17263/17352 (99%)] Loss: 19.324832\n",
      "    epoch          : 54\n",
      "    loss           : 45.958079491836436\n",
      "    val_loss       : 65.5381364733012\n",
      "Train Epoch: 55 [512/17352 (3%)] Loss: 46.347183\n",
      "Train Epoch: 55 [10258/17352 (59%)] Loss: 42.707758\n",
      "Train Epoch: 55 [17044/17352 (98%)] Loss: 260.790967\n",
      "    epoch          : 55\n",
      "    loss           : 81.53937955758137\n",
      "    val_loss       : 175.86971544339974\n",
      "Train Epoch: 56 [512/17352 (3%)] Loss: 146.242264\n",
      "Train Epoch: 56 [10540/17352 (61%)] Loss: 96.219649\n",
      "Train Epoch: 56 [16934/17352 (98%)] Loss: 80.836661\n",
      "    epoch          : 56\n",
      "    loss           : 80.70245105268799\n",
      "    val_loss       : 71.98339900567493\n",
      "Train Epoch: 57 [512/17352 (3%)] Loss: 118.979416\n",
      "Train Epoch: 57 [10381/17352 (60%)] Loss: 39.269004\n",
      "Train Epoch: 57 [16872/17352 (97%)] Loss: 25.085324\n",
      "    epoch          : 57\n",
      "    loss           : 47.20680811673186\n",
      "    val_loss       : 44.661458386562\n",
      "Train Epoch: 58 [512/17352 (3%)] Loss: 25.170948\n",
      "Train Epoch: 58 [10275/17352 (59%)] Loss: -26.797842\n",
      "Train Epoch: 58 [16957/17352 (98%)] Loss: 145.890493\n",
      "    epoch          : 58\n",
      "    loss           : 46.56869875358853\n",
      "    val_loss       : 189.43535734726998\n",
      "Train Epoch: 59 [512/17352 (3%)] Loss: 174.204147\n",
      "Train Epoch: 59 [10936/17352 (63%)] Loss: 1.235176\n",
      "Train Epoch: 59 [17106/17352 (99%)] Loss: 16.790196\n",
      "    epoch          : 59\n",
      "    loss           : 47.27824892174552\n",
      "    val_loss       : 32.970553811275366\n",
      "Train Epoch: 60 [512/17352 (3%)] Loss: 13.304888\n",
      "Train Epoch: 60 [10653/17352 (61%)] Loss: 78.156737\n",
      "Train Epoch: 60 [17126/17352 (99%)] Loss: -5.419732\n",
      "    epoch          : 60\n",
      "    loss           : 19.04269190204817\n",
      "    val_loss       : 20.13432741794655\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch60.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 61 [512/17352 (3%)] Loss: 7.577806\n",
      "Train Epoch: 61 [10228/17352 (59%)] Loss: 11.794427\n",
      "Train Epoch: 61 [17090/17352 (98%)] Loss: 29.010155\n",
      "    epoch          : 61\n",
      "    loss           : 12.62372371848395\n",
      "    val_loss       : 13.84830497199224\n",
      "Train Epoch: 62 [512/17352 (3%)] Loss: 5.130922\n",
      "Train Epoch: 62 [10442/17352 (60%)] Loss: -26.622605\n",
      "Train Epoch: 62 [16922/17352 (98%)] Loss: -77.278227\n",
      "    epoch          : 62\n",
      "    loss           : 4.494409331960206\n",
      "    val_loss       : 6.978403228195869\n",
      "Train Epoch: 63 [512/17352 (3%)] Loss: -9.452686\n",
      "Train Epoch: 63 [10351/17352 (60%)] Loss: 30.417534\n",
      "Train Epoch: 63 [16887/17352 (97%)] Loss: 25.979326\n",
      "    epoch          : 63\n",
      "    loss           : 0.020364819533620272\n",
      "    val_loss       : 3.739466349108127\n",
      "Train Epoch: 64 [512/17352 (3%)] Loss: -13.484208\n",
      "Train Epoch: 64 [10296/17352 (59%)] Loss: 28.941596\n",
      "Train Epoch: 64 [16988/17352 (98%)] Loss: -43.187539\n",
      "    epoch          : 64\n",
      "    loss           : -5.663828961150608\n",
      "    val_loss       : 1.9078065258483143\n",
      "Train Epoch: 65 [512/17352 (3%)] Loss: -18.794058\n",
      "Train Epoch: 65 [10386/17352 (60%)] Loss: -32.113615\n",
      "Train Epoch: 65 [16882/17352 (97%)] Loss: 17.231219\n",
      "    epoch          : 65\n",
      "    loss           : -12.050629301442301\n",
      "    val_loss       : -8.215499322610375\n",
      "Train Epoch: 66 [512/17352 (3%)] Loss: -28.562647\n",
      "Train Epoch: 66 [10600/17352 (61%)] Loss: -13.026783\n",
      "Train Epoch: 66 [16934/17352 (98%)] Loss: -11.304358\n",
      "    epoch          : 66\n",
      "    loss           : -16.518045377647532\n",
      "    val_loss       : -13.969431450681435\n",
      "Train Epoch: 67 [512/17352 (3%)] Loss: -40.351696\n",
      "Train Epoch: 67 [10579/17352 (61%)] Loss: -50.395603\n",
      "Train Epoch: 67 [16883/17352 (97%)] Loss: -7.772563\n",
      "    epoch          : 67\n",
      "    loss           : -23.639455811740316\n",
      "    val_loss       : -14.268246821472763\n",
      "Train Epoch: 68 [512/17352 (3%)] Loss: -31.507519\n",
      "Train Epoch: 68 [10600/17352 (61%)] Loss: -14.194680\n",
      "Train Epoch: 68 [17335/17352 (100%)] Loss: 64.111416\n",
      "    epoch          : 68\n",
      "    loss           : -29.534735327233864\n",
      "    val_loss       : -4.825781232650908\n",
      "Train Epoch: 69 [512/17352 (3%)] Loss: -22.650965\n",
      "Train Epoch: 69 [10219/17352 (59%)] Loss: 38.875285\n",
      "Train Epoch: 69 [16882/17352 (97%)] Loss: -9.317343\n",
      "    epoch          : 69\n",
      "    loss           : -30.63330395558873\n",
      "    val_loss       : -29.82122621237972\n",
      "Train Epoch: 70 [512/17352 (3%)] Loss: -45.975891\n",
      "Train Epoch: 70 [10199/17352 (59%)] Loss: -118.171750\n",
      "Train Epoch: 70 [17016/17352 (98%)] Loss: 34.351399\n",
      "    epoch          : 70\n",
      "    loss           : -34.16341839963959\n",
      "    val_loss       : -24.295518324227388\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch70.pth ...\n",
      "Train Epoch: 71 [512/17352 (3%)] Loss: -51.393036\n",
      "Train Epoch: 71 [10347/17352 (60%)] Loss: -51.594096\n",
      "Train Epoch: 71 [17064/17352 (98%)] Loss: -113.636277\n",
      "    epoch          : 71\n",
      "    loss           : -37.994826447694194\n",
      "    val_loss       : -17.54944639703898\n",
      "Train Epoch: 72 [512/17352 (3%)] Loss: 47.979977\n",
      "Train Epoch: 72 [10560/17352 (61%)] Loss: -110.661594\n",
      "Train Epoch: 72 [16958/17352 (98%)] Loss: -101.396159\n",
      "    epoch          : 72\n",
      "    loss           : -32.70220082291416\n",
      "    val_loss       : -33.9428534395166\n",
      "Train Epoch: 73 [512/17352 (3%)] Loss: -53.515423\n",
      "Train Epoch: 73 [10448/17352 (60%)] Loss: -50.238183\n",
      "Train Epoch: 73 [16878/17352 (97%)] Loss: -89.883853\n",
      "    epoch          : 73\n",
      "    loss           : -47.674329116475114\n",
      "    val_loss       : -42.72844092791144\n",
      "Train Epoch: 74 [512/17352 (3%)] Loss: -68.119095\n",
      "Train Epoch: 74 [10236/17352 (59%)] Loss: -91.561579\n",
      "Train Epoch: 74 [17133/17352 (99%)] Loss: -24.584076\n",
      "    epoch          : 74\n",
      "    loss           : -54.509412256586224\n",
      "    val_loss       : -37.62298991935709\n",
      "Train Epoch: 75 [512/17352 (3%)] Loss: -58.876637\n",
      "Train Epoch: 75 [10225/17352 (59%)] Loss: -11.016932\n",
      "Train Epoch: 75 [17106/17352 (99%)] Loss: -38.713489\n",
      "    epoch          : 75\n",
      "    loss           : -54.68353747885646\n",
      "    val_loss       : -39.8940884120559\n",
      "Train Epoch: 76 [512/17352 (3%)] Loss: -71.244637\n",
      "Train Epoch: 76 [10187/17352 (59%)] Loss: -87.443963\n",
      "Train Epoch: 76 [17126/17352 (99%)] Loss: -89.533535\n",
      "    epoch          : 76\n",
      "    loss           : -60.623425957178476\n",
      "    val_loss       : -55.917662163359466\n",
      "Train Epoch: 77 [512/17352 (3%)] Loss: -86.380959\n",
      "Train Epoch: 77 [9658/17352 (56%)] Loss: -55.721911\n",
      "Train Epoch: 77 [17049/17352 (98%)] Loss: -164.404984\n",
      "    epoch          : 77\n",
      "    loss           : -65.03882463794534\n",
      "    val_loss       : -55.37140047833004\n",
      "Train Epoch: 78 [512/17352 (3%)] Loss: -75.537415\n",
      "Train Epoch: 78 [10121/17352 (58%)] Loss: -37.917697\n",
      "Train Epoch: 78 [16883/17352 (97%)] Loss: -26.117608\n",
      "    epoch          : 78\n",
      "    loss           : -65.42521558668267\n",
      "    val_loss       : -34.797160864311145\n",
      "Train Epoch: 79 [512/17352 (3%)] Loss: -52.903522\n",
      "Train Epoch: 79 [10750/17352 (62%)] Loss: -93.158675\n",
      "Train Epoch: 79 [17064/17352 (98%)] Loss: -61.188279\n",
      "    epoch          : 79\n",
      "    loss           : -61.78950975224674\n",
      "    val_loss       : -55.79193917566393\n",
      "Train Epoch: 80 [512/17352 (3%)] Loss: -81.026146\n",
      "Train Epoch: 80 [10576/17352 (61%)] Loss: -101.784367\n",
      "Train Epoch: 80 [16923/17352 (98%)] Loss: -165.181831\n",
      "    epoch          : 80\n",
      "    loss           : -76.65623558181845\n",
      "    val_loss       : -77.88243417883245\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch80.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 81 [512/17352 (3%)] Loss: -88.937279\n",
      "Train Epoch: 81 [10310/17352 (59%)] Loss: -100.587109\n",
      "Train Epoch: 81 [16939/17352 (98%)] Loss: -69.718732\n",
      "    epoch          : 81\n",
      "    loss           : -80.81059946441108\n",
      "    val_loss       : -76.47443743101746\n",
      "Train Epoch: 82 [512/17352 (3%)] Loss: -102.129745\n",
      "Train Epoch: 82 [10735/17352 (62%)] Loss: -69.187117\n",
      "Train Epoch: 82 [17126/17352 (99%)] Loss: -110.091812\n",
      "    epoch          : 82\n",
      "    loss           : -77.791624359849\n",
      "    val_loss       : -64.5470234924746\n",
      "Train Epoch: 83 [512/17352 (3%)] Loss: 13.588706\n",
      "Train Epoch: 83 [10308/17352 (59%)] Loss: 36.279790\n",
      "Train Epoch: 83 [17101/17352 (99%)] Loss: 25.486282\n",
      "    epoch          : 83\n",
      "    loss           : -68.31428045555332\n",
      "    val_loss       : -64.7609264964646\n",
      "Train Epoch: 84 [512/17352 (3%)] Loss: -103.112190\n",
      "Train Epoch: 84 [10450/17352 (60%)] Loss: -120.571475\n",
      "Train Epoch: 84 [17090/17352 (98%)] Loss: -112.881127\n",
      "    epoch          : 84\n",
      "    loss           : -84.70502518531316\n",
      "    val_loss       : -83.23064549503975\n",
      "Train Epoch: 85 [512/17352 (3%)] Loss: -106.222397\n",
      "Train Epoch: 85 [10580/17352 (61%)] Loss: -157.390834\n",
      "Train Epoch: 85 [16934/17352 (98%)] Loss: -83.347246\n",
      "    epoch          : 85\n",
      "    loss           : -92.77574600594683\n",
      "    val_loss       : -88.54537977118372\n",
      "Train Epoch: 86 [512/17352 (3%)] Loss: -106.049774\n",
      "Train Epoch: 86 [10356/17352 (60%)] Loss: -159.351404\n",
      "Train Epoch: 86 [16958/17352 (98%)] Loss: -45.703013\n",
      "    epoch          : 86\n",
      "    loss           : -99.38148158014357\n",
      "    val_loss       : -97.98426437007215\n",
      "Train Epoch: 87 [512/17352 (3%)] Loss: -115.178497\n",
      "Train Epoch: 87 [9552/17352 (55%)] Loss: -79.906052\n",
      "Train Epoch: 87 [17277/17352 (100%)] Loss: -104.564072\n",
      "    epoch          : 87\n",
      "    loss           : -106.85033343795884\n",
      "    val_loss       : -94.6968296697621\n",
      "Train Epoch: 88 [512/17352 (3%)] Loss: -119.210373\n",
      "Train Epoch: 88 [10237/17352 (59%)] Loss: -131.875718\n",
      "Train Epoch: 88 [17133/17352 (99%)] Loss: -127.570805\n",
      "    epoch          : 88\n",
      "    loss           : -94.28565348072344\n",
      "    val_loss       : -64.42764243763489\n",
      "Train Epoch: 89 [512/17352 (3%)] Loss: 6.546134\n",
      "Train Epoch: 89 [10502/17352 (61%)] Loss: -54.735216\n",
      "Train Epoch: 89 [17277/17352 (100%)] Loss: -36.719527\n",
      "    epoch          : 89\n",
      "    loss           : -87.90341450905429\n",
      "    val_loss       : -87.21394485218713\n",
      "Train Epoch: 90 [512/17352 (3%)] Loss: -108.801193\n",
      "Train Epoch: 90 [10128/17352 (58%)] Loss: -92.212147\n",
      "Train Epoch: 90 [16882/17352 (97%)] Loss: 172.690916\n",
      "    epoch          : 90\n",
      "    loss           : -92.28607488577997\n",
      "    val_loss       : 62.10357708079353\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch90.pth ...\n",
      "Train Epoch: 91 [512/17352 (3%)] Loss: 142.086914\n",
      "Train Epoch: 91 [10432/17352 (60%)] Loss: -3.546789\n",
      "Train Epoch: 91 [16992/17352 (98%)] Loss: -163.434424\n",
      "    epoch          : 91\n",
      "    loss           : -78.98033664471724\n",
      "    val_loss       : -93.16535091160733\n",
      "Train Epoch: 92 [512/17352 (3%)] Loss: -114.480965\n",
      "Train Epoch: 92 [10117/17352 (58%)] Loss: -155.283074\n",
      "Train Epoch: 92 [16957/17352 (98%)] Loss: -169.715908\n",
      "    epoch          : 92\n",
      "    loss           : -118.25381819841458\n",
      "    val_loss       : -121.0609192735542\n",
      "Train Epoch: 93 [512/17352 (3%)] Loss: -137.612869\n",
      "Train Epoch: 93 [10302/17352 (59%)] Loss: -7.805339\n",
      "Train Epoch: 93 [16883/17352 (97%)] Loss: -107.359630\n",
      "    epoch          : 93\n",
      "    loss           : -125.63852084249643\n",
      "    val_loss       : -106.66945946125811\n",
      "Train Epoch: 94 [512/17352 (3%)] Loss: -145.854065\n",
      "Train Epoch: 94 [10564/17352 (61%)] Loss: -191.127848\n",
      "Train Epoch: 94 [17263/17352 (99%)] Loss: 23.969119\n",
      "    epoch          : 94\n",
      "    loss           : -111.46022222573386\n",
      "    val_loss       : 292.96190305626914\n",
      "Train Epoch: 95 [512/17352 (3%)] Loss: 196.662247\n",
      "Train Epoch: 95 [10041/17352 (58%)] Loss: -85.734196\n",
      "Train Epoch: 95 [17108/17352 (99%)] Loss: -132.337459\n",
      "    epoch          : 95\n",
      "    loss           : -68.3357392960811\n",
      "    val_loss       : -96.83482298437924\n",
      "Train Epoch: 96 [512/17352 (3%)] Loss: -113.473900\n",
      "Train Epoch: 96 [9972/17352 (57%)] Loss: -46.925330\n",
      "Train Epoch: 96 [16992/17352 (98%)] Loss: -129.651238\n",
      "    epoch          : 96\n",
      "    loss           : -117.84954533068726\n",
      "    val_loss       : -77.94017545650563\n",
      "Train Epoch: 97 [512/17352 (3%)] Loss: -97.017281\n",
      "Train Epoch: 97 [10105/17352 (58%)] Loss: -150.517122\n",
      "Train Epoch: 97 [16887/17352 (97%)] Loss: -96.908108\n",
      "    epoch          : 97\n",
      "    loss           : -120.96562241091895\n",
      "    val_loss       : -130.4565308415199\n",
      "Train Epoch: 98 [512/17352 (3%)] Loss: -164.837372\n",
      "Train Epoch: 98 [9917/17352 (57%)] Loss: -120.298053\n",
      "Train Epoch: 98 [17124/17352 (99%)] Loss: -206.429589\n",
      "    epoch          : 98\n",
      "    loss           : -135.58932476592986\n",
      "    val_loss       : -116.9403716816942\n",
      "Train Epoch: 99 [512/17352 (3%)] Loss: -145.554794\n",
      "Train Epoch: 99 [10290/17352 (59%)] Loss: -118.421838\n",
      "Train Epoch: 99 [17153/17352 (99%)] Loss: -145.480729\n",
      "    epoch          : 99\n",
      "    loss           : -143.81849184632165\n",
      "    val_loss       : -125.15836874161276\n",
      "Train Epoch: 100 [512/17352 (3%)] Loss: -163.803833\n",
      "Train Epoch: 100 [10489/17352 (60%)] Loss: -122.566104\n",
      "Train Epoch: 100 [16882/17352 (97%)] Loss: -275.584838\n",
      "    epoch          : 100\n",
      "    loss           : -140.35308980109818\n",
      "    val_loss       : -137.04437435811045\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch100.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 101 [512/17352 (3%)] Loss: -175.029938\n",
      "Train Epoch: 101 [10045/17352 (58%)] Loss: -216.741084\n",
      "Train Epoch: 101 [17133/17352 (99%)] Loss: -106.227947\n",
      "    epoch          : 101\n",
      "    loss           : -144.89438902796894\n",
      "    val_loss       : -92.28897674469782\n",
      "Train Epoch: 102 [512/17352 (3%)] Loss: -138.965607\n",
      "Train Epoch: 102 [10204/17352 (59%)] Loss: -180.096498\n",
      "Train Epoch: 102 [16922/17352 (98%)] Loss: -14.366370\n",
      "    epoch          : 102\n",
      "    loss           : -150.8603253956001\n",
      "    val_loss       : -153.5359401236853\n",
      "Train Epoch: 103 [512/17352 (3%)] Loss: -203.814957\n",
      "Train Epoch: 103 [10283/17352 (59%)] Loss: -187.885417\n",
      "Train Epoch: 103 [17253/17352 (99%)] Loss: -237.794991\n",
      "    epoch          : 103\n",
      "    loss           : -173.51197197604787\n",
      "    val_loss       : -161.09218112360745\n",
      "Train Epoch: 104 [512/17352 (3%)] Loss: -68.841164\n",
      "Train Epoch: 104 [10375/17352 (60%)] Loss: -295.683802\n",
      "Train Epoch: 104 [16957/17352 (98%)] Loss: -216.287554\n",
      "    epoch          : 104\n",
      "    loss           : -178.4844391655041\n",
      "    val_loss       : -175.58328166339788\n",
      "Train Epoch: 105 [512/17352 (3%)] Loss: -204.652161\n",
      "Train Epoch: 105 [9795/17352 (56%)] Loss: -137.944347\n",
      "Train Epoch: 105 [16939/17352 (98%)] Loss: -87.599002\n",
      "    epoch          : 105\n",
      "    loss           : -179.7783407717392\n",
      "    val_loss       : -172.65260363883218\n",
      "Train Epoch: 106 [512/17352 (3%)] Loss: -206.628326\n",
      "Train Epoch: 106 [9996/17352 (58%)] Loss: -134.790737\n",
      "Train Epoch: 106 [16882/17352 (97%)] Loss: -111.013343\n",
      "    epoch          : 106\n",
      "    loss           : -194.25370885025458\n",
      "    val_loss       : -176.9371418620565\n",
      "Train Epoch: 107 [512/17352 (3%)] Loss: -232.147888\n",
      "Train Epoch: 107 [11138/17352 (64%)] Loss: -251.809539\n",
      "Train Epoch: 107 [17090/17352 (98%)] Loss: -160.631504\n",
      "    epoch          : 107\n",
      "    loss           : -207.3459044742772\n",
      "    val_loss       : -187.55789734390137\n",
      "Train Epoch: 108 [512/17352 (3%)] Loss: -228.307770\n",
      "Train Epoch: 108 [10014/17352 (58%)] Loss: -244.309395\n",
      "Train Epoch: 108 [17049/17352 (98%)] Loss: -212.652825\n",
      "    epoch          : 108\n",
      "    loss           : -203.73694701707566\n",
      "    val_loss       : -200.46481275326462\n",
      "Train Epoch: 109 [512/17352 (3%)] Loss: -242.087372\n",
      "Train Epoch: 109 [10265/17352 (59%)] Loss: -182.469846\n",
      "Train Epoch: 109 [16957/17352 (98%)] Loss: -228.833034\n",
      "    epoch          : 109\n",
      "    loss           : -215.16109926615508\n",
      "    val_loss       : -198.2991667459061\n",
      "Train Epoch: 110 [512/17352 (3%)] Loss: -224.284439\n",
      "Train Epoch: 110 [10267/17352 (59%)] Loss: -240.905441\n",
      "Train Epoch: 110 [16883/17352 (97%)] Loss: -197.343301\n",
      "    epoch          : 110\n",
      "    loss           : -207.9416994009954\n",
      "    val_loss       : -198.07241713172525\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch110.pth ...\n",
      "Train Epoch: 111 [512/17352 (3%)] Loss: -218.943237\n",
      "Train Epoch: 111 [10186/17352 (59%)] Loss: -290.713907\n",
      "Train Epoch: 111 [17064/17352 (98%)] Loss: -266.514475\n",
      "    epoch          : 111\n",
      "    loss           : -202.59003498779984\n",
      "    val_loss       : -193.82006561871776\n",
      "Train Epoch: 112 [512/17352 (3%)] Loss: -223.570663\n",
      "Train Epoch: 112 [10597/17352 (61%)] Loss: -333.082656\n",
      "Train Epoch: 112 [16882/17352 (97%)] Loss: -238.669414\n",
      "    epoch          : 112\n",
      "    loss           : -193.75905169088358\n",
      "    val_loss       : -192.47186273130745\n",
      "Train Epoch: 113 [512/17352 (3%)] Loss: -262.128784\n",
      "Train Epoch: 113 [10500/17352 (61%)] Loss: -277.290153\n",
      "Train Epoch: 113 [16872/17352 (97%)] Loss: -304.981976\n",
      "    epoch          : 113\n",
      "    loss           : -213.64857749433517\n",
      "    val_loss       : -188.10468320211078\n",
      "Train Epoch: 114 [512/17352 (3%)] Loss: -58.950539\n",
      "Train Epoch: 114 [10987/17352 (63%)] Loss: -323.483290\n",
      "Train Epoch: 114 [17277/17352 (100%)] Loss: -262.837913\n",
      "    epoch          : 114\n",
      "    loss           : -218.54532532058167\n",
      "    val_loss       : -197.14609100234696\n",
      "Train Epoch: 115 [512/17352 (3%)] Loss: -257.638763\n",
      "Train Epoch: 115 [10584/17352 (61%)] Loss: -202.491667\n",
      "Train Epoch: 115 [17124/17352 (99%)] Loss: -302.799977\n",
      "    epoch          : 115\n",
      "    loss           : -243.37057098098313\n",
      "    val_loss       : -184.52721476675026\n",
      "Train Epoch: 116 [512/17352 (3%)] Loss: -223.375214\n",
      "Train Epoch: 116 [10583/17352 (61%)] Loss: -130.277034\n",
      "Train Epoch: 116 [17101/17352 (99%)] Loss: -129.569696\n",
      "    epoch          : 116\n",
      "    loss           : -245.57504648481722\n",
      "    val_loss       : -240.63183617811538\n",
      "Train Epoch: 117 [512/17352 (3%)] Loss: -287.750458\n",
      "Train Epoch: 117 [10383/17352 (60%)] Loss: -191.786786\n",
      "Train Epoch: 117 [16988/17352 (98%)] Loss: -216.114035\n",
      "    epoch          : 117\n",
      "    loss           : -262.07985493238937\n",
      "    val_loss       : -242.45397320360564\n",
      "Train Epoch: 118 [512/17352 (3%)] Loss: -144.507309\n",
      "Train Epoch: 118 [9609/17352 (55%)] Loss: -208.542315\n",
      "Train Epoch: 118 [17106/17352 (99%)] Loss: -216.834397\n",
      "    epoch          : 118\n",
      "    loss           : -266.65504101540853\n",
      "    val_loss       : -254.812837433342\n",
      "Train Epoch: 119 [512/17352 (3%)] Loss: -297.719910\n",
      "Train Epoch: 119 [10627/17352 (61%)] Loss: -309.332308\n",
      "Train Epoch: 119 [17124/17352 (99%)] Loss: -326.801176\n",
      "    epoch          : 119\n",
      "    loss           : -275.86853821602244\n",
      "    val_loss       : -251.37701138414948\n",
      "Train Epoch: 120 [512/17352 (3%)] Loss: -302.187531\n",
      "Train Epoch: 120 [10084/17352 (58%)] Loss: -219.082473\n",
      "Train Epoch: 120 [17263/17352 (99%)] Loss: -233.994640\n",
      "    epoch          : 120\n",
      "    loss           : -279.95906550168047\n",
      "    val_loss       : -255.00016106014408\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch120.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 121 [512/17352 (3%)] Loss: -311.052185\n",
      "Train Epoch: 121 [10547/17352 (61%)] Loss: -261.325242\n",
      "Train Epoch: 121 [17106/17352 (99%)] Loss: -132.508837\n",
      "    epoch          : 121\n",
      "    loss           : -287.30760384407864\n",
      "    val_loss       : -251.19900017065737\n",
      "Train Epoch: 122 [512/17352 (3%)] Loss: -310.856903\n",
      "Train Epoch: 122 [10102/17352 (58%)] Loss: -309.050990\n",
      "Train Epoch: 122 [17049/17352 (98%)] Loss: -142.843834\n",
      "    epoch          : 122\n",
      "    loss           : -277.97843985470604\n",
      "    val_loss       : -267.38970786964614\n",
      "Train Epoch: 123 [512/17352 (3%)] Loss: -300.903534\n",
      "Train Epoch: 123 [10467/17352 (60%)] Loss: -393.927938\n",
      "Train Epoch: 123 [17153/17352 (99%)] Loss: -292.056221\n",
      "    epoch          : 123\n",
      "    loss           : -278.3028643557393\n",
      "    val_loss       : -216.3122101049524\n",
      "Train Epoch: 124 [512/17352 (3%)] Loss: -104.942543\n",
      "Train Epoch: 124 [10588/17352 (61%)] Loss: -243.610153\n",
      "Train Epoch: 124 [17064/17352 (98%)] Loss: -369.061592\n",
      "    epoch          : 124\n",
      "    loss           : -252.0222052658925\n",
      "    val_loss       : -231.30077850211558\n",
      "Train Epoch: 125 [512/17352 (3%)] Loss: -287.415771\n",
      "Train Epoch: 125 [10622/17352 (61%)] Loss: -274.869613\n",
      "Train Epoch: 125 [16992/17352 (98%)] Loss: -209.561328\n",
      "    epoch          : 125\n",
      "    loss           : -220.2878148921914\n",
      "    val_loss       : -227.1497134643643\n",
      "Train Epoch: 126 [512/17352 (3%)] Loss: -283.578949\n",
      "Train Epoch: 126 [10638/17352 (61%)] Loss: -170.420676\n",
      "Train Epoch: 126 [17277/17352 (100%)] Loss: -60.334921\n",
      "    epoch          : 126\n",
      "    loss           : -215.76299715614508\n",
      "    val_loss       : -177.17110754822792\n",
      "Train Epoch: 127 [512/17352 (3%)] Loss: -221.928223\n",
      "Train Epoch: 127 [9923/17352 (57%)] Loss: -119.337839\n",
      "Train Epoch: 127 [17106/17352 (99%)] Loss: -302.862763\n",
      "    epoch          : 127\n",
      "    loss           : -223.7927458351116\n",
      "    val_loss       : -202.15262233829858\n",
      "Train Epoch: 128 [512/17352 (3%)] Loss: -273.652313\n",
      "Train Epoch: 128 [10884/17352 (63%)] Loss: -367.110173\n",
      "Train Epoch: 128 [17263/17352 (99%)] Loss: -253.965644\n",
      "    epoch          : 128\n",
      "    loss           : -290.27635696263445\n",
      "    val_loss       : -273.71044128757677\n",
      "Train Epoch: 129 [512/17352 (3%)] Loss: -331.611267\n",
      "Train Epoch: 129 [10493/17352 (60%)] Loss: -420.971349\n",
      "Train Epoch: 129 [16934/17352 (98%)] Loss: -203.382445\n",
      "    epoch          : 129\n",
      "    loss           : -303.7075765902476\n",
      "    val_loss       : -269.31625479132725\n",
      "Train Epoch: 130 [512/17352 (3%)] Loss: -340.192474\n",
      "Train Epoch: 130 [10664/17352 (61%)] Loss: -250.174089\n",
      "Train Epoch: 130 [16878/17352 (97%)] Loss: -129.335424\n",
      "    epoch          : 130\n",
      "    loss           : -301.7142953942688\n",
      "    val_loss       : -271.4019922452829\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch130.pth ...\n",
      "Train Epoch: 131 [512/17352 (3%)] Loss: -343.312927\n",
      "Train Epoch: 131 [10830/17352 (62%)] Loss: -422.259128\n",
      "Train Epoch: 131 [16887/17352 (97%)] Loss: -368.568343\n",
      "    epoch          : 131\n",
      "    loss           : -307.4964566817294\n",
      "    val_loss       : -300.72028815807977\n",
      "Train Epoch: 132 [512/17352 (3%)] Loss: -360.805420\n",
      "Train Epoch: 132 [10063/17352 (58%)] Loss: -363.609468\n",
      "Train Epoch: 132 [16934/17352 (98%)] Loss: -377.493797\n",
      "    epoch          : 132\n",
      "    loss           : -333.8655616629111\n",
      "    val_loss       : -314.92304217743043\n",
      "Train Epoch: 133 [512/17352 (3%)] Loss: -374.712311\n",
      "Train Epoch: 133 [9784/17352 (56%)] Loss: -400.524427\n",
      "Train Epoch: 133 [17133/17352 (99%)] Loss: -300.760579\n",
      "    epoch          : 133\n",
      "    loss           : -342.3650177471481\n",
      "    val_loss       : -315.6849130727732\n",
      "Train Epoch: 134 [512/17352 (3%)] Loss: -342.960693\n",
      "Train Epoch: 134 [10259/17352 (59%)] Loss: -402.864964\n",
      "Train Epoch: 134 [16934/17352 (98%)] Loss: -252.720142\n",
      "    epoch          : 134\n",
      "    loss           : -346.91812265465694\n",
      "    val_loss       : -324.1431909135687\n",
      "Train Epoch: 135 [512/17352 (3%)] Loss: -373.601654\n",
      "Train Epoch: 135 [9925/17352 (57%)] Loss: -442.217018\n",
      "Train Epoch: 135 [16872/17352 (97%)] Loss: -268.731097\n",
      "    epoch          : 135\n",
      "    loss           : -336.0367925915934\n",
      "    val_loss       : -318.7405654749023\n",
      "Train Epoch: 136 [512/17352 (3%)] Loss: -388.328400\n",
      "Train Epoch: 136 [9998/17352 (58%)] Loss: -420.042511\n",
      "Train Epoch: 136 [16934/17352 (98%)] Loss: -405.142330\n",
      "    epoch          : 136\n",
      "    loss           : -338.53377572798985\n",
      "    val_loss       : -313.21263390852044\n",
      "Train Epoch: 137 [512/17352 (3%)] Loss: -384.633087\n",
      "Train Epoch: 137 [10678/17352 (62%)] Loss: -356.050300\n",
      "Train Epoch: 137 [17049/17352 (98%)] Loss: -119.479749\n",
      "    epoch          : 137\n",
      "    loss           : -293.58853257641164\n",
      "    val_loss       : -239.11243742686835\n",
      "Train Epoch: 138 [512/17352 (3%)] Loss: -317.714844\n",
      "Train Epoch: 138 [9817/17352 (57%)] Loss: -360.357865\n",
      "Train Epoch: 138 [16872/17352 (97%)] Loss: -301.474225\n",
      "    epoch          : 138\n",
      "    loss           : -281.29154598444796\n",
      "    val_loss       : -285.04687830691654\n",
      "Train Epoch: 139 [512/17352 (3%)] Loss: -353.892334\n",
      "Train Epoch: 139 [10544/17352 (61%)] Loss: -297.934918\n",
      "Train Epoch: 139 [16934/17352 (98%)] Loss: -357.105924\n",
      "    epoch          : 139\n",
      "    loss           : -340.6955462323513\n",
      "    val_loss       : -335.56170040629\n",
      "Train Epoch: 140 [512/17352 (3%)] Loss: -398.546021\n",
      "Train Epoch: 140 [10308/17352 (59%)] Loss: -353.444352\n",
      "Train Epoch: 140 [17016/17352 (98%)] Loss: -405.599689\n",
      "    epoch          : 140\n",
      "    loss           : -349.6812106977435\n",
      "    val_loss       : -303.5867357069357\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch140.pth ...\n",
      "Train Epoch: 141 [512/17352 (3%)] Loss: -380.562347\n",
      "Train Epoch: 141 [10495/17352 (60%)] Loss: -264.631798\n",
      "Train Epoch: 141 [17101/17352 (99%)] Loss: -405.412395\n",
      "    epoch          : 141\n",
      "    loss           : -356.9216229352286\n",
      "    val_loss       : -328.7084303063803\n",
      "Train Epoch: 142 [512/17352 (3%)] Loss: -400.341919\n",
      "Train Epoch: 142 [10165/17352 (59%)] Loss: -425.254038\n",
      "Train Epoch: 142 [17335/17352 (100%)] Loss: -417.462969\n",
      "    epoch          : 142\n",
      "    loss           : -367.124625020612\n",
      "    val_loss       : -309.7215023934483\n",
      "Train Epoch: 143 [512/17352 (3%)] Loss: -391.333679\n",
      "Train Epoch: 143 [9954/17352 (57%)] Loss: -359.956007\n",
      "Train Epoch: 143 [16883/17352 (97%)] Loss: -315.241081\n",
      "    epoch          : 143\n",
      "    loss           : -374.2741795360249\n",
      "    val_loss       : -344.55550148591084\n",
      "Train Epoch: 144 [512/17352 (3%)] Loss: -422.472931\n",
      "Train Epoch: 144 [10007/17352 (58%)] Loss: -386.260653\n",
      "Train Epoch: 144 [16939/17352 (98%)] Loss: -442.739096\n",
      "    epoch          : 144\n",
      "    loss           : -382.45631120792837\n",
      "    val_loss       : -352.849088170388\n",
      "Train Epoch: 145 [512/17352 (3%)] Loss: -419.807709\n",
      "Train Epoch: 145 [10829/17352 (62%)] Loss: -401.904818\n",
      "Train Epoch: 145 [16934/17352 (98%)] Loss: -449.719195\n",
      "    epoch          : 145\n",
      "    loss           : -382.79147656560616\n",
      "    val_loss       : -355.1689588348185\n",
      "Train Epoch: 146 [512/17352 (3%)] Loss: -429.519165\n",
      "Train Epoch: 146 [9763/17352 (56%)] Loss: -320.329575\n",
      "Train Epoch: 146 [17143/17352 (99%)] Loss: -410.843376\n",
      "    epoch          : 146\n",
      "    loss           : -392.81521660397374\n",
      "    val_loss       : -347.17390662689877\n",
      "Train Epoch: 147 [512/17352 (3%)] Loss: -408.325928\n",
      "Train Epoch: 147 [9752/17352 (56%)] Loss: -257.748879\n",
      "Train Epoch: 147 [17277/17352 (100%)] Loss: -453.954354\n",
      "    epoch          : 147\n",
      "    loss           : -381.17293602484847\n",
      "    val_loss       : -318.77434197399475\n",
      "Train Epoch: 148 [512/17352 (3%)] Loss: -401.257568\n",
      "Train Epoch: 148 [10415/17352 (60%)] Loss: -280.230338\n",
      "Train Epoch: 148 [17064/17352 (98%)] Loss: -367.135130\n",
      "    epoch          : 148\n",
      "    loss           : -380.5562885560523\n",
      "    val_loss       : -351.33750757960934\n",
      "Train Epoch: 149 [512/17352 (3%)] Loss: -428.536774\n",
      "Train Epoch: 149 [10259/17352 (59%)] Loss: -238.964987\n",
      "Train Epoch: 149 [17090/17352 (98%)] Loss: -165.817153\n",
      "    epoch          : 149\n",
      "    loss           : -371.5795405302022\n",
      "    val_loss       : -303.99592042028644\n",
      "Train Epoch: 150 [512/17352 (3%)] Loss: -408.219849\n",
      "Train Epoch: 150 [10206/17352 (59%)] Loss: -194.188563\n",
      "Train Epoch: 150 [17335/17352 (100%)] Loss: -338.726366\n",
      "    epoch          : 150\n",
      "    loss           : -235.27974365355504\n",
      "    val_loss       : 179.76830145786823\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch150.pth ...\n",
      "Train Epoch: 151 [512/17352 (3%)] Loss: 33.498619\n",
      "Train Epoch: 151 [10460/17352 (60%)] Loss: -301.147693\n",
      "Train Epoch: 151 [17126/17352 (99%)] Loss: -367.467415\n",
      "    epoch          : 151\n",
      "    loss           : -290.91868682595174\n",
      "    val_loss       : -292.1443311474623\n",
      "Train Epoch: 152 [512/17352 (3%)] Loss: -257.505066\n",
      "Train Epoch: 152 [9996/17352 (58%)] Loss: -439.077363\n",
      "Train Epoch: 152 [16887/17352 (97%)] Loss: -50.534297\n",
      "    epoch          : 152\n",
      "    loss           : -350.4371509523557\n",
      "    val_loss       : -342.3595564218574\n",
      "Train Epoch: 153 [512/17352 (3%)] Loss: -415.617096\n",
      "Train Epoch: 153 [10819/17352 (62%)] Loss: -232.487179\n",
      "Train Epoch: 153 [16882/17352 (97%)] Loss: -414.234874\n",
      "    epoch          : 153\n",
      "    loss           : -378.50690286928\n",
      "    val_loss       : -355.58343046275013\n",
      "Train Epoch: 154 [512/17352 (3%)] Loss: -435.784851\n",
      "Train Epoch: 154 [9859/17352 (57%)] Loss: -440.708570\n",
      "Train Epoch: 154 [17277/17352 (100%)] Loss: -291.864833\n",
      "    epoch          : 154\n",
      "    loss           : -409.55142669352864\n",
      "    val_loss       : -370.55198227114323\n",
      "Train Epoch: 155 [512/17352 (3%)] Loss: -446.505219\n",
      "Train Epoch: 155 [10285/17352 (59%)] Loss: -492.711551\n",
      "Train Epoch: 155 [16922/17352 (98%)] Loss: -451.444961\n",
      "    epoch          : 155\n",
      "    loss           : -418.7204064642107\n",
      "    val_loss       : -372.54484304878804\n",
      "Train Epoch: 156 [512/17352 (3%)] Loss: -465.240936\n",
      "Train Epoch: 156 [9978/17352 (58%)] Loss: -413.173493\n",
      "Train Epoch: 156 [17126/17352 (99%)] Loss: -475.657457\n",
      "    epoch          : 156\n",
      "    loss           : -418.0709518531354\n",
      "    val_loss       : -384.46544100019526\n",
      "Train Epoch: 157 [512/17352 (3%)] Loss: -463.763519\n",
      "Train Epoch: 157 [10065/17352 (58%)] Loss: -495.846923\n",
      "Train Epoch: 157 [17106/17352 (99%)] Loss: -334.531944\n",
      "    epoch          : 157\n",
      "    loss           : -409.37581609304294\n",
      "    val_loss       : -361.7199504890899\n",
      "Train Epoch: 158 [512/17352 (3%)] Loss: -410.165405\n",
      "Train Epoch: 158 [10478/17352 (60%)] Loss: -385.518759\n",
      "Train Epoch: 158 [16992/17352 (98%)] Loss: -462.532580\n",
      "    epoch          : 158\n",
      "    loss           : -400.814268466703\n",
      "    val_loss       : -374.3821927892565\n",
      "Train Epoch: 159 [512/17352 (3%)] Loss: -443.633728\n",
      "Train Epoch: 159 [10692/17352 (62%)] Loss: -317.445312\n",
      "Train Epoch: 159 [16882/17352 (97%)] Loss: -329.089962\n",
      "    epoch          : 159\n",
      "    loss           : -407.59175952183267\n",
      "    val_loss       : -386.06493131550144\n",
      "Train Epoch: 160 [512/17352 (3%)] Loss: -466.698669\n",
      "Train Epoch: 160 [10456/17352 (60%)] Loss: -473.220336\n",
      "Train Epoch: 160 [16922/17352 (98%)] Loss: -424.113557\n",
      "    epoch          : 160\n",
      "    loss           : -425.0942353434926\n",
      "    val_loss       : -385.0105400179681\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch160.pth ...\n",
      "Train Epoch: 161 [512/17352 (3%)] Loss: -472.345337\n",
      "Train Epoch: 161 [10241/17352 (59%)] Loss: -264.303501\n",
      "Train Epoch: 161 [17335/17352 (100%)] Loss: -376.198698\n",
      "    epoch          : 161\n",
      "    loss           : -424.93354907342876\n",
      "    val_loss       : -271.74576556405464\n",
      "Train Epoch: 162 [512/17352 (3%)] Loss: -340.986115\n",
      "Train Epoch: 162 [10748/17352 (62%)] Loss: -174.527151\n",
      "Train Epoch: 162 [17101/17352 (99%)] Loss: 201.271944\n",
      "    epoch          : 162\n",
      "    loss           : -214.96141797021764\n",
      "    val_loss       : -136.2828233052139\n",
      "Train Epoch: 163 [512/17352 (3%)] Loss: -217.564331\n",
      "Train Epoch: 163 [10390/17352 (60%)] Loss: -304.672103\n",
      "Train Epoch: 163 [16957/17352 (98%)] Loss: -420.211295\n",
      "    epoch          : 163\n",
      "    loss           : -281.45092437369624\n",
      "    val_loss       : -333.10854058532425\n",
      "Train Epoch: 164 [512/17352 (3%)] Loss: -372.234039\n",
      "Train Epoch: 164 [10267/17352 (59%)] Loss: -478.101064\n",
      "Train Epoch: 164 [16872/17352 (97%)] Loss: -459.118682\n",
      "    epoch          : 164\n",
      "    loss           : -406.1844731014826\n",
      "    val_loss       : -375.2060560662294\n",
      "Train Epoch: 165 [512/17352 (3%)] Loss: -454.906433\n",
      "Train Epoch: 165 [10586/17352 (61%)] Loss: -359.008689\n",
      "Train Epoch: 165 [17016/17352 (98%)] Loss: -344.420637\n",
      "    epoch          : 165\n",
      "    loss           : -423.4433511285761\n",
      "    val_loss       : -388.56620214896566\n",
      "Train Epoch: 166 [512/17352 (3%)] Loss: -463.423889\n",
      "Train Epoch: 166 [10916/17352 (63%)] Loss: -487.582522\n",
      "Train Epoch: 166 [17253/17352 (99%)] Loss: -383.014648\n",
      "    epoch          : 166\n",
      "    loss           : -449.9000088898281\n",
      "    val_loss       : -389.5509206932609\n",
      "Train Epoch: 167 [512/17352 (3%)] Loss: -485.926666\n",
      "Train Epoch: 167 [9931/17352 (57%)] Loss: -466.487479\n",
      "Train Epoch: 167 [16878/17352 (97%)] Loss: -522.778006\n",
      "    epoch          : 167\n",
      "    loss           : -452.44066804873387\n",
      "    val_loss       : -390.8754458181781\n",
      "Train Epoch: 168 [512/17352 (3%)] Loss: -506.736084\n",
      "Train Epoch: 168 [9889/17352 (57%)] Loss: -494.074552\n",
      "Train Epoch: 168 [16923/17352 (98%)] Loss: -490.549544\n",
      "    epoch          : 168\n",
      "    loss           : -457.963916868786\n",
      "    val_loss       : -408.9021032770742\n",
      "Train Epoch: 169 [512/17352 (3%)] Loss: -503.834076\n",
      "Train Epoch: 169 [10058/17352 (58%)] Loss: -428.324667\n",
      "Train Epoch: 169 [17253/17352 (99%)] Loss: -563.851213\n",
      "    epoch          : 169\n",
      "    loss           : -463.94328036320707\n",
      "    val_loss       : -391.5298548398498\n",
      "Train Epoch: 170 [512/17352 (3%)] Loss: -468.224152\n",
      "Train Epoch: 170 [10027/17352 (58%)] Loss: -355.396676\n",
      "Train Epoch: 170 [17143/17352 (99%)] Loss: -450.102311\n",
      "    epoch          : 170\n",
      "    loss           : -405.88824217435996\n",
      "    val_loss       : -306.11908158284956\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch170.pth ...\n",
      "Train Epoch: 171 [512/17352 (3%)] Loss: -404.064087\n",
      "Train Epoch: 171 [10251/17352 (59%)] Loss: -354.179256\n",
      "Train Epoch: 171 [16923/17352 (98%)] Loss: -528.836771\n",
      "    epoch          : 171\n",
      "    loss           : -414.10412400426463\n",
      "    val_loss       : -398.2413367297745\n",
      "Train Epoch: 172 [512/17352 (3%)] Loss: -469.797791\n",
      "Train Epoch: 172 [10478/17352 (60%)] Loss: -540.410015\n",
      "Train Epoch: 172 [16887/17352 (97%)] Loss: -383.848546\n",
      "    epoch          : 172\n",
      "    loss           : -446.10269380452394\n",
      "    val_loss       : -410.4208085348598\n",
      "Train Epoch: 173 [512/17352 (3%)] Loss: -503.801056\n",
      "Train Epoch: 173 [10101/17352 (58%)] Loss: -509.915643\n",
      "Train Epoch: 173 [17064/17352 (98%)] Loss: -504.660781\n",
      "    epoch          : 173\n",
      "    loss           : -459.98238785262805\n",
      "    val_loss       : -381.1966294260635\n",
      "Train Epoch: 174 [512/17352 (3%)] Loss: -507.949097\n",
      "Train Epoch: 174 [10377/17352 (60%)] Loss: -449.947115\n",
      "Train Epoch: 174 [16923/17352 (98%)] Loss: -403.264024\n",
      "    epoch          : 174\n",
      "    loss           : -446.42726911335194\n",
      "    val_loss       : -404.4810982729224\n",
      "Train Epoch: 175 [512/17352 (3%)] Loss: -506.619446\n",
      "Train Epoch: 175 [10460/17352 (60%)] Loss: -524.436501\n",
      "Train Epoch: 175 [16883/17352 (97%)] Loss: -501.927353\n",
      "    epoch          : 175\n",
      "    loss           : -474.5049390153607\n",
      "    val_loss       : -433.7217879466343\n",
      "Train Epoch: 176 [512/17352 (3%)] Loss: -530.391113\n",
      "Train Epoch: 176 [9954/17352 (57%)] Loss: -556.749446\n",
      "Train Epoch: 176 [16922/17352 (98%)] Loss: -570.812878\n",
      "    epoch          : 176\n",
      "    loss           : -484.7135923698\n",
      "    val_loss       : -430.34646106872736\n",
      "Train Epoch: 177 [512/17352 (3%)] Loss: -513.676270\n",
      "Train Epoch: 177 [10029/17352 (58%)] Loss: -533.506927\n",
      "Train Epoch: 177 [16957/17352 (98%)] Loss: -477.426965\n",
      "    epoch          : 177\n",
      "    loss           : -475.48970413144525\n",
      "    val_loss       : -428.34453057119555\n",
      "Train Epoch: 178 [512/17352 (3%)] Loss: -516.583618\n",
      "Train Epoch: 178 [10321/17352 (59%)] Loss: -517.477387\n",
      "Train Epoch: 178 [16882/17352 (97%)] Loss: -537.637031\n",
      "    epoch          : 178\n",
      "    loss           : -485.9206523077577\n",
      "    val_loss       : -439.4182239299245\n",
      "Train Epoch: 179 [512/17352 (3%)] Loss: -520.409912\n",
      "Train Epoch: 179 [10256/17352 (59%)] Loss: -521.567858\n",
      "Train Epoch: 179 [16957/17352 (98%)] Loss: -426.958283\n",
      "    epoch          : 179\n",
      "    loss           : -481.6651854425711\n",
      "    val_loss       : -415.3867705854633\n",
      "Train Epoch: 180 [512/17352 (3%)] Loss: -501.352722\n",
      "Train Epoch: 180 [9939/17352 (57%)] Loss: -454.851878\n",
      "Train Epoch: 180 [16957/17352 (98%)] Loss: -433.016753\n",
      "    epoch          : 180\n",
      "    loss           : -478.3708156926474\n",
      "    val_loss       : -430.34433740336556\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch180.pth ...\n",
      "Train Epoch: 181 [512/17352 (3%)] Loss: -515.798157\n",
      "Train Epoch: 181 [10110/17352 (58%)] Loss: -408.708283\n",
      "Train Epoch: 181 [16887/17352 (97%)] Loss: -469.567495\n",
      "    epoch          : 181\n",
      "    loss           : -493.2608913995247\n",
      "    val_loss       : -463.71143786894214\n",
      "Train Epoch: 182 [512/17352 (3%)] Loss: -552.415527\n",
      "Train Epoch: 182 [10242/17352 (59%)] Loss: -493.819068\n",
      "Train Epoch: 182 [17143/17352 (99%)] Loss: -464.602214\n",
      "    epoch          : 182\n",
      "    loss           : -489.2389397544339\n",
      "    val_loss       : -415.0151692648932\n",
      "Train Epoch: 183 [512/17352 (3%)] Loss: -504.743195\n",
      "Train Epoch: 183 [10575/17352 (61%)] Loss: -431.292448\n",
      "Train Epoch: 183 [16887/17352 (97%)] Loss: -405.015573\n",
      "    epoch          : 183\n",
      "    loss           : -487.04838278665045\n",
      "    val_loss       : -452.41807391209824\n",
      "Train Epoch: 184 [512/17352 (3%)] Loss: -552.704346\n",
      "Train Epoch: 184 [10068/17352 (58%)] Loss: -444.789028\n",
      "Train Epoch: 184 [16872/17352 (97%)] Loss: -325.870626\n",
      "    epoch          : 184\n",
      "    loss           : -492.9233685700629\n",
      "    val_loss       : -441.0608008625701\n",
      "Train Epoch: 185 [512/17352 (3%)] Loss: -555.472290\n",
      "Train Epoch: 185 [10332/17352 (60%)] Loss: -472.981839\n",
      "Train Epoch: 185 [16934/17352 (98%)] Loss: -342.283467\n",
      "    epoch          : 185\n",
      "    loss           : -491.4839912470507\n",
      "    val_loss       : -434.80158257291134\n",
      "Train Epoch: 186 [512/17352 (3%)] Loss: -536.094788\n",
      "Train Epoch: 186 [10530/17352 (61%)] Loss: -308.849762\n",
      "Train Epoch: 186 [16988/17352 (98%)] Loss: -326.382426\n",
      "    epoch          : 186\n",
      "    loss           : -437.3227164788275\n",
      "    val_loss       : -425.4625372573223\n",
      "Train Epoch: 187 [512/17352 (3%)] Loss: -529.923706\n",
      "Train Epoch: 187 [10269/17352 (59%)] Loss: -546.876670\n",
      "Train Epoch: 187 [17106/17352 (99%)] Loss: -569.469510\n",
      "    epoch          : 187\n",
      "    loss           : -481.2714134583619\n",
      "    val_loss       : -403.58996138599167\n",
      "Train Epoch: 188 [512/17352 (3%)] Loss: -474.724426\n",
      "Train Epoch: 188 [10339/17352 (60%)] Loss: -501.580208\n",
      "Train Epoch: 188 [16957/17352 (98%)] Loss: -510.540971\n",
      "    epoch          : 188\n",
      "    loss           : -460.25683842034493\n",
      "    val_loss       : -427.0712725664186\n",
      "Train Epoch: 189 [512/17352 (3%)] Loss: -508.047058\n",
      "Train Epoch: 189 [10787/17352 (62%)] Loss: -592.874281\n",
      "Train Epoch: 189 [17101/17352 (99%)] Loss: -417.307335\n",
      "    epoch          : 189\n",
      "    loss           : -484.6783478549027\n",
      "    val_loss       : -442.2117255488542\n",
      "Train Epoch: 190 [512/17352 (3%)] Loss: -552.221313\n",
      "Train Epoch: 190 [10496/17352 (60%)] Loss: -611.312900\n",
      "Train Epoch: 190 [16939/17352 (98%)] Loss: -578.468115\n",
      "    epoch          : 190\n",
      "    loss           : -504.5010934083879\n",
      "    val_loss       : -444.8711114669618\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch190.pth ...\n",
      "Train Epoch: 191 [512/17352 (3%)] Loss: -544.285889\n",
      "Train Epoch: 191 [9889/17352 (57%)] Loss: -434.469582\n",
      "Train Epoch: 191 [16934/17352 (98%)] Loss: -571.020521\n",
      "    epoch          : 191\n",
      "    loss           : -508.25047414800247\n",
      "    val_loss       : -455.81864443915174\n",
      "Train Epoch: 192 [512/17352 (3%)] Loss: -559.280884\n",
      "Train Epoch: 192 [10627/17352 (61%)] Loss: -454.675912\n",
      "Train Epoch: 192 [16922/17352 (98%)] Loss: -560.419549\n",
      "    epoch          : 192\n",
      "    loss           : -522.413279475181\n",
      "    val_loss       : -466.38008002822147\n",
      "Train Epoch: 193 [512/17352 (3%)] Loss: -571.653870\n",
      "Train Epoch: 193 [10433/17352 (60%)] Loss: -446.828016\n",
      "Train Epoch: 193 [17090/17352 (98%)] Loss: -363.984188\n",
      "    epoch          : 193\n",
      "    loss           : -527.5345080132427\n",
      "    val_loss       : -440.99747702358707\n",
      "Train Epoch: 194 [512/17352 (3%)] Loss: -551.658081\n",
      "Train Epoch: 194 [10458/17352 (60%)] Loss: -564.333598\n",
      "Train Epoch: 194 [17143/17352 (99%)] Loss: -340.028409\n",
      "    epoch          : 194\n",
      "    loss           : -509.8632694987024\n",
      "    val_loss       : -436.11046387566535\n",
      "Train Epoch: 195 [512/17352 (3%)] Loss: -534.191467\n",
      "Train Epoch: 195 [10403/17352 (60%)] Loss: -542.912395\n",
      "Train Epoch: 195 [16958/17352 (98%)] Loss: -362.710200\n",
      "    epoch          : 195\n",
      "    loss           : -454.53145917623993\n",
      "    val_loss       : -382.221385909731\n",
      "Train Epoch: 196 [512/17352 (3%)] Loss: -516.351685\n",
      "Train Epoch: 196 [10655/17352 (61%)] Loss: -369.967685\n",
      "Train Epoch: 196 [16872/17352 (97%)] Loss: -348.520336\n",
      "    epoch          : 196\n",
      "    loss           : -433.76768739731637\n",
      "    val_loss       : -381.77927850595063\n",
      "Train Epoch: 197 [512/17352 (3%)] Loss: -499.337097\n",
      "Train Epoch: 197 [10200/17352 (59%)] Loss: -497.825579\n",
      "Train Epoch: 197 [17126/17352 (99%)] Loss: -283.136582\n",
      "    epoch          : 197\n",
      "    loss           : -436.5357706891668\n",
      "    val_loss       : -391.3336532590698\n",
      "Train Epoch: 198 [512/17352 (3%)] Loss: -473.458893\n",
      "Train Epoch: 198 [9744/17352 (56%)] Loss: -481.369245\n",
      "Train Epoch: 198 [16872/17352 (97%)] Loss: -640.694878\n",
      "    epoch          : 198\n",
      "    loss           : -470.6796730686391\n",
      "    val_loss       : -443.1328766951298\n",
      "Train Epoch: 199 [512/17352 (3%)] Loss: -506.121429\n",
      "Train Epoch: 199 [10271/17352 (59%)] Loss: -406.981901\n",
      "Train Epoch: 199 [17064/17352 (98%)] Loss: -409.779082\n",
      "    epoch          : 199\n",
      "    loss           : -505.32070620805905\n",
      "    val_loss       : -478.0720969688596\n",
      "Train Epoch: 200 [512/17352 (3%)] Loss: -575.176758\n",
      "Train Epoch: 200 [10976/17352 (63%)] Loss: -591.902253\n",
      "Train Epoch: 200 [17277/17352 (100%)] Loss: -554.794715\n",
      "    epoch          : 200\n",
      "    loss           : -525.8176070017839\n",
      "    val_loss       : -463.7243261620222\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch200.pth ...\n",
      "Train Epoch: 201 [512/17352 (3%)] Loss: -555.757080\n",
      "Train Epoch: 201 [10175/17352 (59%)] Loss: -461.678950\n",
      "Train Epoch: 201 [17090/17352 (98%)] Loss: -590.885328\n",
      "    epoch          : 201\n",
      "    loss           : -525.7663342135853\n",
      "    val_loss       : -470.97104267262506\n",
      "Train Epoch: 202 [512/17352 (3%)] Loss: -579.883179\n",
      "Train Epoch: 202 [10121/17352 (58%)] Loss: -547.388359\n",
      "Train Epoch: 202 [16958/17352 (98%)] Loss: -391.091806\n",
      "    epoch          : 202\n",
      "    loss           : -534.5400756850765\n",
      "    val_loss       : -485.0921132994763\n",
      "Train Epoch: 203 [512/17352 (3%)] Loss: -410.749084\n",
      "Train Epoch: 203 [10175/17352 (59%)] Loss: -610.134302\n",
      "Train Epoch: 203 [16988/17352 (98%)] Loss: -499.083984\n",
      "    epoch          : 203\n",
      "    loss           : -548.7830771809729\n",
      "    val_loss       : -492.23681157816515\n",
      "Train Epoch: 204 [512/17352 (3%)] Loss: -585.797668\n",
      "Train Epoch: 204 [10222/17352 (59%)] Loss: -583.803028\n",
      "Train Epoch: 204 [16882/17352 (97%)] Loss: -408.439478\n",
      "    epoch          : 204\n",
      "    loss           : -544.3261693201248\n",
      "    val_loss       : -449.89014307895286\n",
      "Train Epoch: 205 [512/17352 (3%)] Loss: -545.928345\n",
      "Train Epoch: 205 [9964/17352 (57%)] Loss: -495.233629\n",
      "Train Epoch: 205 [17090/17352 (98%)] Loss: -545.936572\n",
      "    epoch          : 205\n",
      "    loss           : -520.9296288319954\n",
      "    val_loss       : -457.45524515440667\n",
      "Train Epoch: 206 [512/17352 (3%)] Loss: -361.906921\n",
      "Train Epoch: 206 [10783/17352 (62%)] Loss: -382.333468\n",
      "Train Epoch: 206 [17064/17352 (98%)] Loss: -426.081477\n",
      "    epoch          : 206\n",
      "    loss           : -544.6883967855471\n",
      "    val_loss       : -477.9044530935869\n",
      "Train Epoch: 207 [512/17352 (3%)] Loss: -607.169434\n",
      "Train Epoch: 207 [10255/17352 (59%)] Loss: -523.056961\n",
      "Train Epoch: 207 [16922/17352 (98%)] Loss: -645.324455\n",
      "    epoch          : 207\n",
      "    loss           : -553.042253405671\n",
      "    val_loss       : -481.496089838785\n",
      "Train Epoch: 208 [512/17352 (3%)] Loss: -591.493713\n",
      "Train Epoch: 208 [10585/17352 (61%)] Loss: -608.347983\n",
      "Train Epoch: 208 [16887/17352 (97%)] Loss: -378.021419\n",
      "    epoch          : 208\n",
      "    loss           : -546.8553591949877\n",
      "    val_loss       : -475.06779257161054\n",
      "Train Epoch: 209 [512/17352 (3%)] Loss: -581.899597\n",
      "Train Epoch: 209 [10478/17352 (60%)] Loss: -491.495648\n",
      "Train Epoch: 209 [17263/17352 (99%)] Loss: -466.608962\n",
      "    epoch          : 209\n",
      "    loss           : -540.2280988165339\n",
      "    val_loss       : -452.5590138569337\n",
      "Train Epoch: 210 [512/17352 (3%)] Loss: -535.483154\n",
      "Train Epoch: 210 [9814/17352 (57%)] Loss: -537.134792\n",
      "Train Epoch: 210 [17126/17352 (99%)] Loss: -432.554487\n",
      "    epoch          : 210\n",
      "    loss           : -538.9889074069996\n",
      "    val_loss       : -473.735793114319\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch210.pth ...\n",
      "Train Epoch: 211 [512/17352 (3%)] Loss: -598.680908\n",
      "Train Epoch: 211 [10323/17352 (59%)] Loss: -616.739219\n",
      "Train Epoch: 211 [17263/17352 (99%)] Loss: -443.767533\n",
      "    epoch          : 211\n",
      "    loss           : -558.2658627850393\n",
      "    val_loss       : -429.8269834248946\n",
      "Train Epoch: 212 [512/17352 (3%)] Loss: -553.372070\n",
      "Train Epoch: 212 [10328/17352 (60%)] Loss: -647.114407\n",
      "Train Epoch: 212 [16922/17352 (98%)] Loss: -484.417178\n",
      "    epoch          : 212\n",
      "    loss           : -546.3380974472968\n",
      "    val_loss       : -474.74579638428315\n",
      "Train Epoch: 213 [512/17352 (3%)] Loss: -403.156494\n",
      "Train Epoch: 213 [9663/17352 (56%)] Loss: -628.104167\n",
      "Train Epoch: 213 [17049/17352 (98%)] Loss: -470.023529\n",
      "    epoch          : 213\n",
      "    loss           : -547.3617472711875\n",
      "    val_loss       : -471.5560280473323\n",
      "Train Epoch: 214 [512/17352 (3%)] Loss: -590.639526\n",
      "Train Epoch: 214 [10476/17352 (60%)] Loss: -602.571766\n",
      "Train Epoch: 214 [17044/17352 (98%)] Loss: -658.185101\n",
      "    epoch          : 214\n",
      "    loss           : -558.4678761685153\n",
      "    val_loss       : -454.10161702714794\n",
      "Train Epoch: 215 [512/17352 (3%)] Loss: -576.627625\n",
      "Train Epoch: 215 [9954/17352 (57%)] Loss: -633.430171\n",
      "Train Epoch: 215 [16882/17352 (97%)] Loss: -469.824269\n",
      "    epoch          : 215\n",
      "    loss           : -545.9284378041069\n",
      "    val_loss       : -473.5607734175899\n",
      "Train Epoch: 216 [512/17352 (3%)] Loss: -571.363892\n",
      "Train Epoch: 216 [10072/17352 (58%)] Loss: -430.583728\n",
      "Train Epoch: 216 [17090/17352 (98%)] Loss: -370.709245\n",
      "    epoch          : 216\n",
      "    loss           : -514.3046614470704\n",
      "    val_loss       : -452.2067417230029\n",
      "Train Epoch: 217 [512/17352 (3%)] Loss: -575.795593\n",
      "Train Epoch: 217 [10259/17352 (59%)] Loss: -553.990052\n",
      "Train Epoch: 217 [16958/17352 (98%)] Loss: -508.509017\n",
      "    epoch          : 217\n",
      "    loss           : -467.00399197095334\n",
      "    val_loss       : -422.8250416940214\n",
      "Train Epoch: 218 [512/17352 (3%)] Loss: -545.976807\n",
      "Train Epoch: 218 [10023/17352 (58%)] Loss: -417.574738\n",
      "Train Epoch: 218 [17253/17352 (99%)] Loss: -515.677691\n",
      "    epoch          : 218\n",
      "    loss           : -532.930269072974\n",
      "    val_loss       : -465.7882868776915\n",
      "Train Epoch: 219 [512/17352 (3%)] Loss: -604.309448\n",
      "Train Epoch: 219 [10470/17352 (60%)] Loss: -633.060914\n",
      "Train Epoch: 219 [16872/17352 (97%)] Loss: -626.907035\n",
      "    epoch          : 219\n",
      "    loss           : -563.4022495752477\n",
      "    val_loss       : -483.54293552323117\n",
      "Train Epoch: 220 [512/17352 (3%)] Loss: -605.911865\n",
      "Train Epoch: 220 [10193/17352 (59%)] Loss: -548.895519\n",
      "Train Epoch: 220 [16934/17352 (98%)] Loss: -600.569348\n",
      "    epoch          : 220\n",
      "    loss           : -552.3757499925687\n",
      "    val_loss       : -423.5121253793362\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch220.pth ...\n",
      "Train Epoch: 221 [512/17352 (3%)] Loss: -555.610229\n",
      "Train Epoch: 221 [10298/17352 (59%)] Loss: -510.864720\n",
      "Train Epoch: 221 [16957/17352 (98%)] Loss: -536.898901\n",
      "    epoch          : 221\n",
      "    loss           : -449.0672256372512\n",
      "    val_loss       : -327.4536112959083\n",
      "Train Epoch: 222 [512/17352 (3%)] Loss: -462.663330\n",
      "Train Epoch: 222 [10672/17352 (62%)] Loss: -618.980142\n",
      "Train Epoch: 222 [17124/17352 (99%)] Loss: -572.288802\n",
      "    epoch          : 222\n",
      "    loss           : -475.9310715471752\n",
      "    val_loss       : -406.16809322216847\n",
      "Train Epoch: 223 [512/17352 (3%)] Loss: -319.500000\n",
      "Train Epoch: 223 [10024/17352 (58%)] Loss: -548.044012\n",
      "Train Epoch: 223 [16882/17352 (97%)] Loss: -445.652863\n",
      "    epoch          : 223\n",
      "    loss           : -530.8870511516625\n",
      "    val_loss       : -482.00194778619453\n",
      "Train Epoch: 224 [512/17352 (3%)] Loss: -626.621582\n",
      "Train Epoch: 224 [10112/17352 (58%)] Loss: -637.670886\n",
      "Train Epoch: 224 [17049/17352 (98%)] Loss: -629.390232\n",
      "    epoch          : 224\n",
      "    loss           : -569.0043709649074\n",
      "    val_loss       : -487.8395458038297\n",
      "Train Epoch: 225 [512/17352 (3%)] Loss: -587.390320\n",
      "Train Epoch: 225 [10500/17352 (61%)] Loss: -556.049637\n",
      "Train Epoch: 225 [16882/17352 (97%)] Loss: -539.895905\n",
      "    epoch          : 225\n",
      "    loss           : -566.1054836724605\n",
      "    val_loss       : -482.3416803116367\n",
      "Train Epoch: 226 [512/17352 (3%)] Loss: -597.079468\n",
      "Train Epoch: 226 [9894/17352 (57%)] Loss: -502.939967\n",
      "Train Epoch: 226 [16883/17352 (97%)] Loss: -649.720521\n",
      "    epoch          : 226\n",
      "    loss           : -565.5708298652614\n",
      "    val_loss       : -493.79547383389416\n",
      "Train Epoch: 227 [512/17352 (3%)] Loss: -607.575684\n",
      "Train Epoch: 227 [9963/17352 (57%)] Loss: -586.827779\n",
      "Train Epoch: 227 [16878/17352 (97%)] Loss: -650.437368\n",
      "    epoch          : 227\n",
      "    loss           : -566.3322596827954\n",
      "    val_loss       : -481.3414070507205\n",
      "Train Epoch: 228 [512/17352 (3%)] Loss: -424.898376\n",
      "Train Epoch: 228 [10632/17352 (61%)] Loss: -670.915492\n",
      "Train Epoch: 228 [17016/17352 (98%)] Loss: -324.262896\n",
      "    epoch          : 228\n",
      "    loss           : -512.0814522212943\n",
      "    val_loss       : -458.77405014878104\n",
      "Train Epoch: 229 [512/17352 (3%)] Loss: -571.558594\n",
      "Train Epoch: 229 [9658/17352 (56%)] Loss: 24.396700\n",
      "Train Epoch: 229 [16887/17352 (97%)] Loss: -296.235959\n",
      "    epoch          : 229\n",
      "    loss           : -323.2453940701345\n",
      "    val_loss       : -298.48387627552165\n",
      "Train Epoch: 230 [512/17352 (3%)] Loss: -472.246460\n",
      "Train Epoch: 230 [10187/17352 (59%)] Loss: -402.920380\n",
      "Train Epoch: 230 [16872/17352 (97%)] Loss: -576.573705\n",
      "    epoch          : 230\n",
      "    loss           : -476.88299944358613\n",
      "    val_loss       : -458.96153346753624\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch230.pth ...\n",
      "Train Epoch: 231 [512/17352 (3%)] Loss: -605.282532\n",
      "Train Epoch: 231 [9882/17352 (57%)] Loss: -580.120620\n",
      "Train Epoch: 231 [17263/17352 (99%)] Loss: -423.219460\n",
      "    epoch          : 231\n",
      "    loss           : -560.0218559327324\n",
      "    val_loss       : -500.10994987344344\n",
      "Train Epoch: 232 [512/17352 (3%)] Loss: -629.046631\n",
      "Train Epoch: 232 [10543/17352 (61%)] Loss: -670.986104\n",
      "Train Epoch: 232 [16923/17352 (98%)] Loss: -505.687852\n",
      "    epoch          : 232\n",
      "    loss           : -557.9772330233587\n",
      "    val_loss       : -475.60939324138474\n",
      "Train Epoch: 233 [512/17352 (3%)] Loss: -583.455200\n",
      "Train Epoch: 233 [10362/17352 (60%)] Loss: -641.314953\n",
      "Train Epoch: 233 [17106/17352 (99%)] Loss: -584.619042\n",
      "    epoch          : 233\n",
      "    loss           : -566.9925884969563\n",
      "    val_loss       : -469.82787530610113\n",
      "Train Epoch: 234 [512/17352 (3%)] Loss: -596.399353\n",
      "Train Epoch: 234 [10339/17352 (60%)] Loss: -515.841180\n",
      "Train Epoch: 234 [16882/17352 (97%)] Loss: -603.014015\n",
      "    epoch          : 234\n",
      "    loss           : -579.7234953453165\n",
      "    val_loss       : -497.9269634934612\n",
      "Train Epoch: 235 [512/17352 (3%)] Loss: -640.813354\n",
      "Train Epoch: 235 [10188/17352 (59%)] Loss: -676.169146\n",
      "Train Epoch: 235 [17106/17352 (99%)] Loss: -488.702922\n",
      "    epoch          : 235\n",
      "    loss           : -597.1621678462532\n",
      "    val_loss       : -515.2351383506292\n",
      "Train Epoch: 236 [512/17352 (3%)] Loss: -640.755859\n",
      "Train Epoch: 236 [10692/17352 (62%)] Loss: -617.617874\n",
      "Train Epoch: 236 [17049/17352 (98%)] Loss: -721.773926\n",
      "    epoch          : 236\n",
      "    loss           : -609.2288489674256\n",
      "    val_loss       : -528.6428432849298\n",
      "Train Epoch: 237 [512/17352 (3%)] Loss: -661.480164\n",
      "Train Epoch: 237 [10278/17352 (59%)] Loss: -578.615513\n",
      "Train Epoch: 237 [17124/17352 (99%)] Loss: -499.055281\n",
      "    epoch          : 237\n",
      "    loss           : -615.3964270586553\n",
      "    val_loss       : -524.7794638893163\n",
      "Train Epoch: 238 [512/17352 (3%)] Loss: -663.673401\n",
      "Train Epoch: 238 [9760/17352 (56%)] Loss: -556.973682\n",
      "Train Epoch: 238 [17064/17352 (98%)] Loss: -520.277664\n",
      "    epoch          : 238\n",
      "    loss           : -592.135038811199\n",
      "    val_loss       : -513.7074137592288\n",
      "Train Epoch: 239 [512/17352 (3%)] Loss: -455.110321\n",
      "Train Epoch: 239 [10508/17352 (61%)] Loss: -641.990697\n",
      "Train Epoch: 239 [16958/17352 (98%)] Loss: -662.865625\n",
      "    epoch          : 239\n",
      "    loss           : -607.7830282476459\n",
      "    val_loss       : -526.7295340213238\n",
      "Train Epoch: 240 [512/17352 (3%)] Loss: -661.802124\n",
      "Train Epoch: 240 [10644/17352 (61%)] Loss: -488.053977\n",
      "Train Epoch: 240 [16939/17352 (98%)] Loss: -547.696205\n",
      "    epoch          : 240\n",
      "    loss           : -624.3629097539182\n",
      "    val_loss       : -539.923227802513\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch240.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 241 [512/17352 (3%)] Loss: -655.980835\n",
      "Train Epoch: 241 [10254/17352 (59%)] Loss: -568.698180\n",
      "Train Epoch: 241 [17335/17352 (100%)] Loss: -593.034708\n",
      "    epoch          : 241\n",
      "    loss           : -629.9422732166272\n",
      "    val_loss       : -528.8015875676069\n",
      "Train Epoch: 242 [512/17352 (3%)] Loss: -662.965942\n",
      "Train Epoch: 242 [10109/17352 (58%)] Loss: -664.141248\n",
      "Train Epoch: 242 [17126/17352 (99%)] Loss: -651.741510\n",
      "    epoch          : 242\n",
      "    loss           : -623.3895461078467\n",
      "    val_loss       : -504.5509024145305\n",
      "Train Epoch: 243 [512/17352 (3%)] Loss: -659.428162\n",
      "Train Epoch: 243 [10195/17352 (59%)] Loss: -647.188156\n",
      "Train Epoch: 243 [16957/17352 (98%)] Loss: -723.456265\n",
      "    epoch          : 243\n",
      "    loss           : -608.4657931337612\n",
      "    val_loss       : -534.594239351709\n",
      "Train Epoch: 244 [512/17352 (3%)] Loss: -657.484741\n",
      "Train Epoch: 244 [10223/17352 (59%)] Loss: -683.989466\n",
      "Train Epoch: 244 [17044/17352 (98%)] Loss: -561.205181\n",
      "    epoch          : 244\n",
      "    loss           : -614.0212313112977\n",
      "    val_loss       : -532.4364736183027\n",
      "Train Epoch: 245 [512/17352 (3%)] Loss: -646.587708\n",
      "Train Epoch: 245 [10025/17352 (58%)] Loss: -549.235937\n",
      "Train Epoch: 245 [17153/17352 (99%)] Loss: -547.655986\n",
      "    epoch          : 245\n",
      "    loss           : -595.7193525016064\n",
      "    val_loss       : -462.532958037955\n",
      "Train Epoch: 246 [512/17352 (3%)] Loss: -593.226501\n",
      "Train Epoch: 246 [10713/17352 (62%)] Loss: -514.406362\n",
      "Train Epoch: 246 [17277/17352 (100%)] Loss: 404.069444\n",
      "    epoch          : 246\n",
      "    loss           : -451.73333025979304\n",
      "    val_loss       : 1703.0781455857489\n",
      "Train Epoch: 247 [512/17352 (3%)] Loss: 1201.528320\n",
      "Train Epoch: 247 [10154/17352 (59%)] Loss: 1246.375258\n",
      "Train Epoch: 247 [16992/17352 (98%)] Loss: -17.562834\n",
      "    epoch          : 247\n",
      "    loss           : 182.993247184462\n",
      "    val_loss       : -198.4899898758178\n",
      "Train Epoch: 248 [512/17352 (3%)] Loss: -393.305786\n",
      "Train Epoch: 248 [10135/17352 (58%)] Loss: -377.361657\n",
      "Train Epoch: 248 [16878/17352 (97%)] Loss: -532.349237\n",
      "    epoch          : 248\n",
      "    loss           : -405.95801293501916\n",
      "    val_loss       : -416.19148134291373\n",
      "Train Epoch: 249 [512/17352 (3%)] Loss: -560.579468\n",
      "Train Epoch: 249 [10168/17352 (59%)] Loss: -664.159201\n",
      "Train Epoch: 249 [17124/17352 (99%)] Loss: -614.561193\n",
      "    epoch          : 249\n",
      "    loss           : -554.7996289728337\n",
      "    val_loss       : -483.0419440081314\n",
      "Train Epoch: 250 [512/17352 (3%)] Loss: -608.365723\n",
      "Train Epoch: 250 [9955/17352 (57%)] Loss: -380.145464\n",
      "Train Epoch: 250 [16923/17352 (98%)] Loss: -674.530870\n",
      "    epoch          : 250\n",
      "    loss           : -581.7384106878515\n",
      "    val_loss       : -517.7712896495708\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch250.pth ...\n",
      "Train Epoch: 251 [512/17352 (3%)] Loss: -645.279236\n",
      "Train Epoch: 251 [10297/17352 (59%)] Loss: -662.124288\n",
      "Train Epoch: 251 [17133/17352 (99%)] Loss: -408.328965\n",
      "    epoch          : 251\n",
      "    loss           : -594.5290104842289\n",
      "    val_loss       : -522.5051643458976\n",
      "Train Epoch: 252 [512/17352 (3%)] Loss: -647.858765\n",
      "Train Epoch: 252 [10185/17352 (59%)] Loss: -677.453852\n",
      "Train Epoch: 252 [17101/17352 (99%)] Loss: -462.234861\n",
      "    epoch          : 252\n",
      "    loss           : -614.3970908455534\n",
      "    val_loss       : -516.7197595497762\n",
      "Train Epoch: 253 [512/17352 (3%)] Loss: -672.246826\n",
      "Train Epoch: 253 [10284/17352 (59%)] Loss: -428.947009\n",
      "Train Epoch: 253 [17143/17352 (99%)] Loss: -727.384332\n",
      "    epoch          : 253\n",
      "    loss           : -614.6785346739173\n",
      "    val_loss       : -534.5774653181481\n",
      "Train Epoch: 254 [512/17352 (3%)] Loss: -673.568909\n",
      "Train Epoch: 254 [10250/17352 (59%)] Loss: -669.345306\n",
      "Train Epoch: 254 [17277/17352 (100%)] Loss: -489.155727\n",
      "    epoch          : 254\n",
      "    loss           : -626.5507194251395\n",
      "    val_loss       : -544.1131541018854\n",
      "Train Epoch: 255 [512/17352 (3%)] Loss: -672.311035\n",
      "Train Epoch: 255 [9752/17352 (56%)] Loss: -552.685481\n",
      "Train Epoch: 255 [17153/17352 (99%)] Loss: -545.064030\n",
      "    epoch          : 255\n",
      "    loss           : -635.4116215998549\n",
      "    val_loss       : -543.7746119606182\n",
      "Train Epoch: 256 [512/17352 (3%)] Loss: -680.714600\n",
      "Train Epoch: 256 [10331/17352 (60%)] Loss: -704.999604\n",
      "Train Epoch: 256 [17263/17352 (99%)] Loss: -641.372243\n",
      "    epoch          : 256\n",
      "    loss           : -634.2365538347858\n",
      "    val_loss       : -536.7127784792156\n",
      "Train Epoch: 257 [512/17352 (3%)] Loss: -654.369385\n",
      "Train Epoch: 257 [10370/17352 (60%)] Loss: -574.513457\n",
      "Train Epoch: 257 [17253/17352 (99%)] Loss: -706.072970\n",
      "    epoch          : 257\n",
      "    loss           : -635.1026021720699\n",
      "    val_loss       : -551.1440183236492\n",
      "Train Epoch: 258 [512/17352 (3%)] Loss: -687.294434\n",
      "Train Epoch: 258 [9682/17352 (56%)] Loss: -621.269326\n",
      "Train Epoch: 258 [17153/17352 (99%)] Loss: -582.530273\n",
      "    epoch          : 258\n",
      "    loss           : -645.5101500389322\n",
      "    val_loss       : -539.515104341269\n",
      "Train Epoch: 259 [512/17352 (3%)] Loss: -688.371826\n",
      "Train Epoch: 259 [10476/17352 (60%)] Loss: -703.183802\n",
      "Train Epoch: 259 [17263/17352 (99%)] Loss: -688.668416\n",
      "    epoch          : 259\n",
      "    loss           : -643.6017803831925\n",
      "    val_loss       : -546.3494036192966\n",
      "Train Epoch: 260 [512/17352 (3%)] Loss: -513.418762\n",
      "Train Epoch: 260 [10290/17352 (59%)] Loss: -616.338371\n",
      "Train Epoch: 260 [16883/17352 (97%)] Loss: -643.041295\n",
      "    epoch          : 260\n",
      "    loss           : -648.5152136714129\n",
      "    val_loss       : -544.2309443482671\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch260.pth ...\n",
      "Train Epoch: 261 [512/17352 (3%)] Loss: -705.506653\n",
      "Train Epoch: 261 [10627/17352 (61%)] Loss: -706.287447\n",
      "Train Epoch: 261 [16988/17352 (98%)] Loss: -483.613786\n",
      "    epoch          : 261\n",
      "    loss           : -622.7021914452464\n",
      "    val_loss       : -508.27707699444323\n",
      "Train Epoch: 262 [512/17352 (3%)] Loss: -610.139404\n",
      "Train Epoch: 262 [10446/17352 (60%)] Loss: -580.038370\n",
      "Train Epoch: 262 [17108/17352 (99%)] Loss: -734.821353\n",
      "    epoch          : 262\n",
      "    loss           : -631.1830232118903\n",
      "    val_loss       : -515.4337624750613\n",
      "Train Epoch: 263 [512/17352 (3%)] Loss: -678.197205\n",
      "Train Epoch: 263 [9854/17352 (57%)] Loss: -688.843686\n",
      "Train Epoch: 263 [16957/17352 (98%)] Loss: -594.025825\n",
      "    epoch          : 263\n",
      "    loss           : -632.3742773734219\n",
      "    val_loss       : -549.6371236286576\n",
      "Train Epoch: 264 [512/17352 (3%)] Loss: -698.450195\n",
      "Train Epoch: 264 [9551/17352 (55%)] Loss: -715.322188\n",
      "Train Epoch: 264 [17124/17352 (99%)] Loss: -625.685010\n",
      "    epoch          : 264\n",
      "    loss           : -653.2534675973385\n",
      "    val_loss       : -540.766876193713\n",
      "Train Epoch: 265 [512/17352 (3%)] Loss: -491.298676\n",
      "Train Epoch: 265 [10398/17352 (60%)] Loss: -593.108854\n",
      "Train Epoch: 265 [16922/17352 (98%)] Loss: -554.456422\n",
      "    epoch          : 265\n",
      "    loss           : -644.7552993806795\n",
      "    val_loss       : -534.9857671630588\n",
      "Train Epoch: 266 [512/17352 (3%)] Loss: -688.668518\n",
      "Train Epoch: 266 [10039/17352 (58%)] Loss: -584.009955\n",
      "Train Epoch: 266 [16934/17352 (98%)] Loss: -733.778718\n",
      "    epoch          : 266\n",
      "    loss           : -649.0033597183365\n",
      "    val_loss       : -538.2116007212032\n",
      "Train Epoch: 267 [512/17352 (3%)] Loss: -690.973511\n",
      "Train Epoch: 267 [10035/17352 (58%)] Loss: -768.998155\n",
      "Train Epoch: 267 [16882/17352 (97%)] Loss: -672.332939\n",
      "    epoch          : 267\n",
      "    loss           : -655.2793065798819\n",
      "    val_loss       : -553.5468115131473\n",
      "Train Epoch: 268 [512/17352 (3%)] Loss: -671.593994\n",
      "Train Epoch: 268 [10917/17352 (63%)] Loss: -640.129386\n",
      "Train Epoch: 268 [16883/17352 (97%)] Loss: -597.536198\n",
      "    epoch          : 268\n",
      "    loss           : -656.6698550579752\n",
      "    val_loss       : -541.7031064533937\n",
      "Train Epoch: 269 [512/17352 (3%)] Loss: -703.058105\n",
      "Train Epoch: 269 [10010/17352 (58%)] Loss: -699.218399\n",
      "Train Epoch: 269 [17126/17352 (99%)] Loss: -733.400997\n",
      "    epoch          : 269\n",
      "    loss           : -652.0369047031029\n",
      "    val_loss       : -524.9354931266378\n",
      "Train Epoch: 270 [512/17352 (3%)] Loss: -658.976074\n",
      "Train Epoch: 270 [10162/17352 (59%)] Loss: -717.639990\n",
      "Train Epoch: 270 [16992/17352 (98%)] Loss: -718.801440\n",
      "    epoch          : 270\n",
      "    loss           : -641.7144769774239\n",
      "    val_loss       : -539.2467322571489\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch270.pth ...\n",
      "Train Epoch: 271 [512/17352 (3%)] Loss: -513.094727\n",
      "Train Epoch: 271 [10020/17352 (58%)] Loss: -533.662541\n",
      "Train Epoch: 271 [16872/17352 (97%)] Loss: -633.023298\n",
      "    epoch          : 271\n",
      "    loss           : -656.0644840618959\n",
      "    val_loss       : -552.2550552577736\n",
      "Train Epoch: 272 [512/17352 (3%)] Loss: -695.550110\n",
      "Train Epoch: 272 [10906/17352 (63%)] Loss: -723.748183\n",
      "Train Epoch: 272 [16887/17352 (97%)] Loss: -595.726755\n",
      "    epoch          : 272\n",
      "    loss           : -662.2504826190205\n",
      "    val_loss       : -555.6086504564132\n",
      "Train Epoch: 273 [512/17352 (3%)] Loss: -712.441406\n",
      "Train Epoch: 273 [10551/17352 (61%)] Loss: -585.158854\n",
      "Train Epoch: 273 [17253/17352 (99%)] Loss: -680.409223\n",
      "    epoch          : 273\n",
      "    loss           : -648.49148065515\n",
      "    val_loss       : -495.39002215554086\n",
      "Train Epoch: 274 [512/17352 (3%)] Loss: -679.812683\n",
      "Train Epoch: 274 [10637/17352 (61%)] Loss: -584.646528\n",
      "Train Epoch: 274 [16988/17352 (98%)] Loss: -679.664852\n",
      "    epoch          : 274\n",
      "    loss           : -642.8965119431917\n",
      "    val_loss       : -535.8708728606646\n",
      "Train Epoch: 275 [512/17352 (3%)] Loss: -714.868530\n",
      "Train Epoch: 275 [10549/17352 (61%)] Loss: -580.029221\n",
      "Train Epoch: 275 [17277/17352 (100%)] Loss: -709.987760\n",
      "    epoch          : 275\n",
      "    loss           : -664.8020345774396\n",
      "    val_loss       : -544.7400885633423\n",
      "Train Epoch: 276 [512/17352 (3%)] Loss: -717.207886\n",
      "Train Epoch: 276 [10433/17352 (60%)] Loss: -516.089521\n",
      "Train Epoch: 276 [16923/17352 (98%)] Loss: -624.004675\n",
      "    epoch          : 276\n",
      "    loss           : -666.6633828660565\n",
      "    val_loss       : -564.0209556533813\n",
      "Train Epoch: 277 [512/17352 (3%)] Loss: -717.241760\n",
      "Train Epoch: 277 [10544/17352 (61%)] Loss: -689.710543\n",
      "Train Epoch: 277 [16922/17352 (98%)] Loss: -758.596288\n",
      "    epoch          : 277\n",
      "    loss           : -678.1507823258623\n",
      "    val_loss       : -580.0100638005729\n",
      "Train Epoch: 278 [512/17352 (3%)] Loss: -722.612183\n",
      "Train Epoch: 278 [10191/17352 (59%)] Loss: -754.475597\n",
      "Train Epoch: 278 [16958/17352 (98%)] Loss: -699.049116\n",
      "    epoch          : 278\n",
      "    loss           : -676.4435413205687\n",
      "    val_loss       : -557.7481334182538\n",
      "Train Epoch: 279 [512/17352 (3%)] Loss: -735.416260\n",
      "Train Epoch: 279 [10266/17352 (59%)] Loss: -619.374868\n",
      "Train Epoch: 279 [17108/17352 (99%)] Loss: -511.937911\n",
      "    epoch          : 279\n",
      "    loss           : -669.9454161824332\n",
      "    val_loss       : -526.9408264612349\n",
      "Train Epoch: 280 [512/17352 (3%)] Loss: -687.766235\n",
      "Train Epoch: 280 [10202/17352 (59%)] Loss: -771.787921\n",
      "Train Epoch: 280 [17335/17352 (100%)] Loss: -731.384884\n",
      "    epoch          : 280\n",
      "    loss           : -670.8051135573334\n",
      "    val_loss       : -549.6646372714808\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch280.pth ...\n",
      "Train Epoch: 281 [512/17352 (3%)] Loss: -716.343994\n",
      "Train Epoch: 281 [10359/17352 (60%)] Loss: -715.093266\n",
      "Train Epoch: 281 [16992/17352 (98%)] Loss: -739.129122\n",
      "    epoch          : 281\n",
      "    loss           : -663.6517450411612\n",
      "    val_loss       : -558.5718672516226\n",
      "Train Epoch: 282 [512/17352 (3%)] Loss: -708.363892\n",
      "Train Epoch: 282 [10344/17352 (60%)] Loss: -739.431904\n",
      "Train Epoch: 282 [17049/17352 (98%)] Loss: -775.983505\n",
      "    epoch          : 282\n",
      "    loss           : -675.8793472106065\n",
      "    val_loss       : -555.2769790798538\n",
      "Train Epoch: 283 [512/17352 (3%)] Loss: -716.135864\n",
      "Train Epoch: 283 [10423/17352 (60%)] Loss: -738.494733\n",
      "Train Epoch: 283 [17106/17352 (99%)] Loss: -742.872559\n",
      "    epoch          : 283\n",
      "    loss           : -665.1052336628433\n",
      "    val_loss       : -479.6696986166533\n",
      "Train Epoch: 284 [512/17352 (3%)] Loss: -651.770142\n",
      "Train Epoch: 284 [10584/17352 (61%)] Loss: -745.731311\n",
      "Train Epoch: 284 [16872/17352 (97%)] Loss: -501.927734\n",
      "    epoch          : 284\n",
      "    loss           : -605.5780039788872\n",
      "    val_loss       : -449.0326847056639\n",
      "Train Epoch: 285 [512/17352 (3%)] Loss: -593.330994\n",
      "Train Epoch: 285 [10304/17352 (59%)] Loss: -572.090186\n",
      "Train Epoch: 285 [17133/17352 (99%)] Loss: -674.096037\n",
      "    epoch          : 285\n",
      "    loss           : -576.2991453549265\n",
      "    val_loss       : -324.2888663039003\n",
      "Train Epoch: 286 [512/17352 (3%)] Loss: -538.995239\n",
      "Train Epoch: 286 [10384/17352 (60%)] Loss: -485.857390\n",
      "Train Epoch: 286 [16922/17352 (98%)] Loss: -678.960554\n",
      "    epoch          : 286\n",
      "    loss           : -548.0740744843821\n",
      "    val_loss       : -463.8167872897111\n",
      "Train Epoch: 287 [512/17352 (3%)] Loss: -662.742798\n",
      "Train Epoch: 287 [10472/17352 (60%)] Loss: -707.322346\n",
      "Train Epoch: 287 [16934/17352 (98%)] Loss: -636.667105\n",
      "    epoch          : 287\n",
      "    loss           : -610.8199751696599\n",
      "    val_loss       : -514.1129441685804\n",
      "Train Epoch: 288 [512/17352 (3%)] Loss: -690.772949\n",
      "Train Epoch: 288 [9745/17352 (56%)] Loss: -611.855995\n",
      "Train Epoch: 288 [17106/17352 (99%)] Loss: -731.347602\n",
      "    epoch          : 288\n",
      "    loss           : -639.1397439136078\n",
      "    val_loss       : -535.0243036555886\n",
      "Train Epoch: 289 [512/17352 (3%)] Loss: -520.691040\n",
      "Train Epoch: 289 [10195/17352 (59%)] Loss: -490.179435\n",
      "Train Epoch: 289 [17049/17352 (98%)] Loss: -666.587910\n",
      "    epoch          : 289\n",
      "    loss           : -662.2561148225955\n",
      "    val_loss       : -551.4988468663043\n",
      "Train Epoch: 290 [512/17352 (3%)] Loss: -724.227478\n",
      "Train Epoch: 290 [10330/17352 (60%)] Loss: -711.220247\n",
      "Train Epoch: 290 [16922/17352 (98%)] Loss: -608.615582\n",
      "    epoch          : 290\n",
      "    loss           : -685.2156828074625\n",
      "    val_loss       : -549.2563548930085\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch290.pth ...\n",
      "Train Epoch: 291 [512/17352 (3%)] Loss: -737.600281\n",
      "Train Epoch: 291 [10286/17352 (59%)] Loss: -745.039375\n",
      "Train Epoch: 291 [17153/17352 (99%)] Loss: -732.909113\n",
      "    epoch          : 291\n",
      "    loss           : -691.3958619027328\n",
      "    val_loss       : -551.0177156430183\n",
      "Train Epoch: 292 [512/17352 (3%)] Loss: -721.500122\n",
      "Train Epoch: 292 [9887/17352 (57%)] Loss: -728.234811\n",
      "Train Epoch: 292 [17253/17352 (99%)] Loss: -743.172498\n",
      "    epoch          : 292\n",
      "    loss           : -681.4734593455714\n",
      "    val_loss       : -543.4135988839728\n",
      "Train Epoch: 293 [512/17352 (3%)] Loss: -694.160706\n",
      "Train Epoch: 293 [10570/17352 (61%)] Loss: -768.900949\n",
      "Train Epoch: 293 [17335/17352 (100%)] Loss: -717.371986\n",
      "    epoch          : 293\n",
      "    loss           : -673.8019506518282\n",
      "    val_loss       : -493.9379462434462\n",
      "Train Epoch: 294 [512/17352 (3%)] Loss: -684.655212\n",
      "Train Epoch: 294 [10761/17352 (62%)] Loss: -731.639934\n",
      "Train Epoch: 294 [16957/17352 (98%)] Loss: -565.004635\n",
      "    epoch          : 294\n",
      "    loss           : -655.7098557313427\n",
      "    val_loss       : -533.4982840648797\n",
      "Train Epoch: 295 [512/17352 (3%)] Loss: -697.792725\n",
      "Train Epoch: 295 [9906/17352 (57%)] Loss: -688.676004\n",
      "Train Epoch: 295 [16988/17352 (98%)] Loss: -627.208767\n",
      "    epoch          : 295\n",
      "    loss           : -655.876316749551\n",
      "    val_loss       : -540.9632252613817\n",
      "Train Epoch: 296 [512/17352 (3%)] Loss: -710.587158\n",
      "Train Epoch: 296 [10164/17352 (59%)] Loss: -721.059177\n",
      "Train Epoch: 296 [17064/17352 (98%)] Loss: -585.193316\n",
      "    epoch          : 296\n",
      "    loss           : -654.9254743332671\n",
      "    val_loss       : -512.2734940623708\n",
      "Train Epoch: 297 [512/17352 (3%)] Loss: -698.396179\n",
      "Train Epoch: 297 [10239/17352 (59%)] Loss: -540.819032\n",
      "Train Epoch: 297 [17016/17352 (98%)] Loss: -602.938322\n",
      "    epoch          : 297\n",
      "    loss           : -646.9577535117911\n",
      "    val_loss       : -538.2925365539311\n",
      "Train Epoch: 298 [512/17352 (3%)] Loss: -709.345215\n",
      "Train Epoch: 298 [9770/17352 (56%)] Loss: -749.420922\n",
      "Train Epoch: 298 [17133/17352 (99%)] Loss: -715.143183\n",
      "    epoch          : 298\n",
      "    loss           : -659.5273742841676\n",
      "    val_loss       : -515.1486752637143\n",
      "Train Epoch: 299 [512/17352 (3%)] Loss: -714.179260\n",
      "Train Epoch: 299 [10535/17352 (61%)] Loss: -626.224089\n",
      "Train Epoch: 299 [17124/17352 (99%)] Loss: -711.783460\n",
      "    epoch          : 299\n",
      "    loss           : -688.3891209020147\n",
      "    val_loss       : -558.1090949115777\n",
      "Train Epoch: 300 [512/17352 (3%)] Loss: -519.610596\n",
      "Train Epoch: 300 [10037/17352 (58%)] Loss: -677.561322\n",
      "Train Epoch: 300 [17108/17352 (99%)] Loss: -416.455611\n",
      "    epoch          : 300\n",
      "    loss           : -606.1892079314518\n",
      "    val_loss       : 248.06475043373038\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch300.pth ...\n",
      "Train Epoch: 301 [512/17352 (3%)] Loss: -122.478256\n",
      "Train Epoch: 301 [10820/17352 (62%)] Loss: -565.250954\n",
      "Train Epoch: 301 [17108/17352 (99%)] Loss: -558.405465\n",
      "    epoch          : 301\n",
      "    loss           : -496.7785681181862\n",
      "    val_loss       : -504.0333787492973\n",
      "Train Epoch: 302 [512/17352 (3%)] Loss: -658.901855\n",
      "Train Epoch: 302 [9963/17352 (57%)] Loss: -802.616428\n",
      "Train Epoch: 302 [17106/17352 (99%)] Loss: -606.865130\n",
      "    epoch          : 302\n",
      "    loss           : -666.6014055670491\n",
      "    val_loss       : -550.9588723734178\n",
      "Train Epoch: 303 [512/17352 (3%)] Loss: -699.437561\n",
      "Train Epoch: 303 [10364/17352 (60%)] Loss: -664.159964\n",
      "Train Epoch: 303 [17106/17352 (99%)] Loss: -730.325774\n",
      "    epoch          : 303\n",
      "    loss           : -703.3713147761302\n",
      "    val_loss       : -573.9418637759561\n",
      "Train Epoch: 304 [512/17352 (3%)] Loss: -745.943298\n",
      "Train Epoch: 304 [10470/17352 (60%)] Loss: -661.326780\n",
      "Train Epoch: 304 [17253/17352 (99%)] Loss: -727.396708\n",
      "    epoch          : 304\n",
      "    loss           : -706.535786234942\n",
      "    val_loss       : -548.202699154396\n",
      "Train Epoch: 305 [512/17352 (3%)] Loss: -729.682739\n",
      "Train Epoch: 305 [10304/17352 (59%)] Loss: -727.076327\n",
      "Train Epoch: 305 [16922/17352 (98%)] Loss: -614.185257\n",
      "    epoch          : 305\n",
      "    loss           : -697.7616832625615\n",
      "    val_loss       : -570.1208674767283\n",
      "Train Epoch: 306 [512/17352 (3%)] Loss: -757.359741\n",
      "Train Epoch: 306 [10473/17352 (60%)] Loss: -791.758725\n",
      "Train Epoch: 306 [17064/17352 (98%)] Loss: -768.203416\n",
      "    epoch          : 306\n",
      "    loss           : -702.9748351116389\n",
      "    val_loss       : -564.0959753566507\n",
      "Train Epoch: 307 [512/17352 (3%)] Loss: -748.122803\n",
      "Train Epoch: 307 [10110/17352 (58%)] Loss: -608.910156\n",
      "Train Epoch: 307 [16923/17352 (98%)] Loss: -624.634186\n",
      "    epoch          : 307\n",
      "    loss           : -676.8112033764141\n",
      "    val_loss       : -502.5278778478567\n",
      "Train Epoch: 308 [512/17352 (3%)] Loss: -715.069824\n",
      "Train Epoch: 308 [10442/17352 (60%)] Loss: -778.070412\n",
      "Train Epoch: 308 [17049/17352 (98%)] Loss: -753.099368\n",
      "    epoch          : 308\n",
      "    loss           : -676.6413292546774\n",
      "    val_loss       : -543.8623375726595\n",
      "Train Epoch: 309 [512/17352 (3%)] Loss: -730.078186\n",
      "Train Epoch: 309 [10397/17352 (60%)] Loss: -766.814245\n",
      "Train Epoch: 309 [17263/17352 (99%)] Loss: -567.674940\n",
      "    epoch          : 309\n",
      "    loss           : -690.336780922348\n",
      "    val_loss       : -536.7979659232229\n",
      "Train Epoch: 310 [512/17352 (3%)] Loss: -738.482056\n",
      "Train Epoch: 310 [10709/17352 (62%)] Loss: -781.293229\n",
      "Train Epoch: 310 [17124/17352 (99%)] Loss: -61.656157\n",
      "    epoch          : 310\n",
      "    loss           : -600.7617312987652\n",
      "    val_loss       : -332.2097583828405\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch310.pth ...\n",
      "Train Epoch: 311 [512/17352 (3%)] Loss: -396.430664\n",
      "Train Epoch: 311 [10084/17352 (58%)] Loss: -459.004890\n",
      "Train Epoch: 311 [17143/17352 (99%)] Loss: -179.486936\n",
      "    epoch          : 311\n",
      "    loss           : -484.8782135120995\n",
      "    val_loss       : -427.39555911817115\n",
      "Train Epoch: 312 [512/17352 (3%)] Loss: -609.955078\n",
      "Train Epoch: 312 [9957/17352 (57%)] Loss: -674.443326\n",
      "Train Epoch: 312 [17263/17352 (99%)] Loss: -612.453810\n",
      "    epoch          : 312\n",
      "    loss           : -593.9723704566596\n",
      "    val_loss       : -499.3615590704106\n",
      "Train Epoch: 313 [512/17352 (3%)] Loss: -705.006592\n",
      "Train Epoch: 313 [10156/17352 (59%)] Loss: -620.919389\n",
      "Train Epoch: 313 [16958/17352 (98%)] Loss: -720.986554\n",
      "    epoch          : 313\n",
      "    loss           : -684.6263081346541\n",
      "    val_loss       : -536.3749267919335\n",
      "Train Epoch: 314 [512/17352 (3%)] Loss: -754.601562\n",
      "Train Epoch: 314 [9955/17352 (57%)] Loss: -783.115891\n",
      "Train Epoch: 314 [16872/17352 (97%)] Loss: -641.143973\n",
      "    epoch          : 314\n",
      "    loss           : -695.5321093183038\n",
      "    val_loss       : -550.1966794377936\n",
      "Train Epoch: 315 [512/17352 (3%)] Loss: -759.851257\n",
      "Train Epoch: 315 [9761/17352 (56%)] Loss: -575.815087\n",
      "Train Epoch: 315 [16922/17352 (98%)] Loss: -790.573824\n",
      "    epoch          : 315\n",
      "    loss           : -714.400108463774\n",
      "    val_loss       : -575.7371503902483\n",
      "Train Epoch: 316 [512/17352 (3%)] Loss: -776.755737\n",
      "Train Epoch: 316 [10446/17352 (60%)] Loss: -773.936483\n",
      "Train Epoch: 316 [17090/17352 (98%)] Loss: -793.246510\n",
      "    epoch          : 316\n",
      "    loss           : -723.1613619033694\n",
      "    val_loss       : -567.2417403738802\n",
      "Train Epoch: 317 [512/17352 (3%)] Loss: -769.556763\n",
      "Train Epoch: 317 [10599/17352 (61%)] Loss: -738.560217\n",
      "Train Epoch: 317 [17153/17352 (99%)] Loss: -777.739466\n",
      "    epoch          : 317\n",
      "    loss           : -712.318538072364\n",
      "    val_loss       : -544.0317436673784\n",
      "Train Epoch: 318 [512/17352 (3%)] Loss: -756.158447\n",
      "Train Epoch: 318 [10663/17352 (61%)] Loss: -728.319724\n",
      "Train Epoch: 318 [17253/17352 (99%)] Loss: -665.275391\n",
      "    epoch          : 318\n",
      "    loss           : -707.3737991950566\n",
      "    val_loss       : -382.2840598332325\n",
      "Train Epoch: 319 [512/17352 (3%)] Loss: -571.465820\n",
      "Train Epoch: 319 [10718/17352 (62%)] Loss: -542.034726\n",
      "Train Epoch: 319 [17108/17352 (99%)] Loss: -771.622868\n",
      "    epoch          : 319\n",
      "    loss           : -677.7837735741492\n",
      "    val_loss       : -520.240453502683\n",
      "Train Epoch: 320 [512/17352 (3%)] Loss: -723.840698\n",
      "Train Epoch: 320 [9789/17352 (56%)] Loss: -732.803662\n",
      "Train Epoch: 320 [17064/17352 (98%)] Loss: -806.484441\n",
      "    epoch          : 320\n",
      "    loss           : -701.473910998326\n",
      "    val_loss       : -561.7511071379554\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch320.pth ...\n",
      "Train Epoch: 321 [512/17352 (3%)] Loss: -754.259644\n",
      "Train Epoch: 321 [10934/17352 (63%)] Loss: -618.650058\n",
      "Train Epoch: 321 [17016/17352 (98%)] Loss: -779.447068\n",
      "    epoch          : 321\n",
      "    loss           : -697.8686746930085\n",
      "    val_loss       : -536.5875625598335\n",
      "Train Epoch: 322 [512/17352 (3%)] Loss: -743.188599\n",
      "Train Epoch: 322 [10752/17352 (62%)] Loss: -762.910156\n",
      "Train Epoch: 322 [17263/17352 (99%)] Loss: -795.648547\n",
      "    epoch          : 322\n",
      "    loss           : -720.8642451417829\n",
      "    val_loss       : -549.4511099527534\n",
      "Train Epoch: 323 [512/17352 (3%)] Loss: -565.566589\n",
      "Train Epoch: 323 [10341/17352 (60%)] Loss: -850.659342\n",
      "Train Epoch: 323 [17124/17352 (99%)] Loss: -594.535417\n",
      "    epoch          : 323\n",
      "    loss           : -733.5658729266402\n",
      "    val_loss       : -576.8048954191763\n",
      "Train Epoch: 324 [512/17352 (3%)] Loss: -596.870728\n",
      "Train Epoch: 324 [10147/17352 (58%)] Loss: -776.776382\n",
      "Train Epoch: 324 [16882/17352 (97%)] Loss: -691.654536\n",
      "    epoch          : 324\n",
      "    loss           : -738.6069631321221\n",
      "    val_loss       : -589.7930974143553\n",
      "Train Epoch: 325 [512/17352 (3%)] Loss: -781.453247\n",
      "Train Epoch: 325 [10196/17352 (59%)] Loss: -775.406093\n",
      "Train Epoch: 325 [16939/17352 (98%)] Loss: -537.690323\n",
      "    epoch          : 325\n",
      "    loss           : -731.3644735187693\n",
      "    val_loss       : -580.2547031796017\n",
      "Train Epoch: 326 [512/17352 (3%)] Loss: -764.408325\n",
      "Train Epoch: 326 [9414/17352 (54%)] Loss: -755.261324\n",
      "Train Epoch: 326 [16883/17352 (97%)] Loss: -683.212865\n",
      "    epoch          : 326\n",
      "    loss           : -738.8546210323976\n",
      "    val_loss       : -582.593377939596\n",
      "Train Epoch: 327 [512/17352 (3%)] Loss: -785.398132\n",
      "Train Epoch: 327 [10231/17352 (59%)] Loss: -775.281561\n",
      "Train Epoch: 327 [17090/17352 (98%)] Loss: -805.698180\n",
      "    epoch          : 327\n",
      "    loss           : -729.7910572420393\n",
      "    val_loss       : -562.9280311840234\n",
      "Train Epoch: 328 [512/17352 (3%)] Loss: -778.223511\n",
      "Train Epoch: 328 [10486/17352 (60%)] Loss: -742.703213\n",
      "Train Epoch: 328 [16882/17352 (97%)] Loss: -725.981850\n",
      "    epoch          : 328\n",
      "    loss           : -704.9057387711804\n",
      "    val_loss       : -544.2157715611487\n",
      "Train Epoch: 329 [512/17352 (3%)] Loss: -750.248047\n",
      "Train Epoch: 329 [9739/17352 (56%)] Loss: -707.449732\n",
      "Train Epoch: 329 [16934/17352 (98%)] Loss: -748.962587\n",
      "    epoch          : 329\n",
      "    loss           : -711.6483951776254\n",
      "    val_loss       : -570.1120480890094\n",
      "Train Epoch: 330 [512/17352 (3%)] Loss: -772.492432\n",
      "Train Epoch: 330 [10451/17352 (60%)] Loss: -576.525403\n",
      "Train Epoch: 330 [17126/17352 (99%)] Loss: -784.083854\n",
      "    epoch          : 330\n",
      "    loss           : -736.0297154495352\n",
      "    val_loss       : -579.029748124634\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch330.pth ...\n",
      "Train Epoch: 331 [512/17352 (3%)] Loss: -766.326294\n",
      "Train Epoch: 331 [10728/17352 (62%)] Loss: -823.633777\n",
      "Train Epoch: 331 [17277/17352 (100%)] Loss: -688.948010\n",
      "    epoch          : 331\n",
      "    loss           : -724.8667475503821\n",
      "    val_loss       : -528.024417944705\n",
      "Train Epoch: 332 [512/17352 (3%)] Loss: -747.948120\n",
      "Train Epoch: 332 [10684/17352 (62%)] Loss: -712.495028\n",
      "Train Epoch: 332 [16934/17352 (98%)] Loss: -656.418212\n",
      "    epoch          : 332\n",
      "    loss           : -695.8868978980896\n",
      "    val_loss       : -518.8815643179853\n",
      "Train Epoch: 333 [512/17352 (3%)] Loss: -748.340698\n",
      "Train Epoch: 333 [10526/17352 (61%)] Loss: -593.624053\n",
      "Train Epoch: 333 [16883/17352 (97%)] Loss: -769.295700\n",
      "    epoch          : 333\n",
      "    loss           : -700.0970943236346\n",
      "    val_loss       : -551.4714339195591\n",
      "Train Epoch: 334 [512/17352 (3%)] Loss: -753.916809\n",
      "Train Epoch: 334 [10407/17352 (60%)] Loss: -718.922766\n",
      "Train Epoch: 334 [17143/17352 (99%)] Loss: -801.484731\n",
      "    epoch          : 334\n",
      "    loss           : -709.9669736595636\n",
      "    val_loss       : -533.984227972542\n",
      "Train Epoch: 335 [512/17352 (3%)] Loss: -758.572754\n",
      "Train Epoch: 335 [9874/17352 (57%)] Loss: -692.207546\n",
      "Train Epoch: 335 [16958/17352 (98%)] Loss: -477.994456\n",
      "    epoch          : 335\n",
      "    loss           : -688.0896918934518\n",
      "    val_loss       : -462.2040313468033\n",
      "Train Epoch: 336 [512/17352 (3%)] Loss: -664.619629\n",
      "Train Epoch: 336 [9859/17352 (57%)] Loss: -779.579222\n",
      "Train Epoch: 336 [16992/17352 (98%)] Loss: -668.091667\n",
      "    epoch          : 336\n",
      "    loss           : -657.5347913043282\n",
      "    val_loss       : -516.3471073343927\n",
      "Train Epoch: 337 [512/17352 (3%)] Loss: -731.727661\n",
      "Train Epoch: 337 [9848/17352 (57%)] Loss: -714.539241\n",
      "Train Epoch: 337 [17106/17352 (99%)] Loss: -575.768177\n",
      "    epoch          : 337\n",
      "    loss           : -624.7874881131357\n",
      "    val_loss       : -428.0420207509884\n",
      "Train Epoch: 338 [512/17352 (3%)] Loss: -679.153442\n",
      "Train Epoch: 338 [10404/17352 (60%)] Loss: -444.587836\n",
      "Train Epoch: 338 [16992/17352 (98%)] Loss: -761.725188\n",
      "    epoch          : 338\n",
      "    loss           : -658.377938530179\n",
      "    val_loss       : -542.8114813946651\n",
      "Train Epoch: 339 [512/17352 (3%)] Loss: -758.479004\n",
      "Train Epoch: 339 [10128/17352 (58%)] Loss: -731.737477\n",
      "Train Epoch: 339 [16992/17352 (98%)] Loss: -712.045770\n",
      "    epoch          : 339\n",
      "    loss           : -727.7189423461224\n",
      "    val_loss       : -576.6721169424566\n",
      "Train Epoch: 340 [512/17352 (3%)] Loss: -762.754211\n",
      "Train Epoch: 340 [10645/17352 (61%)] Loss: -625.948864\n",
      "Train Epoch: 340 [17126/17352 (99%)] Loss: -789.603329\n",
      "    epoch          : 340\n",
      "    loss           : -739.1708313195916\n",
      "    val_loss       : -579.6697689496123\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch340.pth ...\n",
      "Train Epoch: 341 [512/17352 (3%)] Loss: -798.954956\n",
      "Train Epoch: 341 [10087/17352 (58%)] Loss: -688.220095\n",
      "Train Epoch: 341 [16923/17352 (98%)] Loss: -788.399928\n",
      "    epoch          : 341\n",
      "    loss           : -743.4193236715065\n",
      "    val_loss       : -586.3729060846425\n",
      "Train Epoch: 342 [512/17352 (3%)] Loss: -786.179688\n",
      "Train Epoch: 342 [10457/17352 (60%)] Loss: -860.743978\n",
      "Train Epoch: 342 [17253/17352 (99%)] Loss: -652.271132\n",
      "    epoch          : 342\n",
      "    loss           : -738.4416979095041\n",
      "    val_loss       : -561.7013852680604\n",
      "Train Epoch: 343 [512/17352 (3%)] Loss: -763.344299\n",
      "Train Epoch: 343 [9727/17352 (56%)] Loss: -682.696496\n",
      "Train Epoch: 343 [16883/17352 (97%)] Loss: -684.368908\n",
      "    epoch          : 343\n",
      "    loss           : -708.763483918579\n",
      "    val_loss       : -554.7818916536761\n",
      "Train Epoch: 344 [512/17352 (3%)] Loss: -759.894531\n",
      "Train Epoch: 344 [10681/17352 (62%)] Loss: -568.239219\n",
      "Train Epoch: 344 [17124/17352 (99%)] Loss: -828.504398\n",
      "    epoch          : 344\n",
      "    loss           : -728.0034484799318\n",
      "    val_loss       : -560.0265566274036\n",
      "Train Epoch: 345 [512/17352 (3%)] Loss: -781.373779\n",
      "Train Epoch: 345 [10478/17352 (60%)] Loss: -674.019513\n",
      "Train Epoch: 345 [17133/17352 (99%)] Loss: -780.501085\n",
      "    epoch          : 345\n",
      "    loss           : -736.6309484200607\n",
      "    val_loss       : -562.5990981121951\n",
      "Train Epoch: 346 [512/17352 (3%)] Loss: -767.813110\n",
      "Train Epoch: 346 [10380/17352 (60%)] Loss: -702.819393\n",
      "Train Epoch: 346 [16923/17352 (98%)] Loss: -800.619996\n",
      "    epoch          : 346\n",
      "    loss           : -748.0746168424433\n",
      "    val_loss       : -579.5510608385512\n",
      "Train Epoch: 347 [512/17352 (3%)] Loss: -794.976685\n",
      "Train Epoch: 347 [10265/17352 (59%)] Loss: -820.252776\n",
      "Train Epoch: 347 [17044/17352 (98%)] Loss: -797.617109\n",
      "    epoch          : 347\n",
      "    loss           : -757.3316223696573\n",
      "    val_loss       : -582.0597575090775\n",
      "Train Epoch: 348 [512/17352 (3%)] Loss: -788.953003\n",
      "Train Epoch: 348 [10481/17352 (60%)] Loss: -795.312292\n",
      "Train Epoch: 348 [17124/17352 (99%)] Loss: -789.602073\n",
      "    epoch          : 348\n",
      "    loss           : -744.3893785020825\n",
      "    val_loss       : -537.9203291239714\n",
      "Train Epoch: 349 [512/17352 (3%)] Loss: -772.226929\n",
      "Train Epoch: 349 [10195/17352 (59%)] Loss: -697.270597\n",
      "Train Epoch: 349 [17090/17352 (98%)] Loss: -829.406850\n",
      "    epoch          : 349\n",
      "    loss           : -724.8841885000886\n",
      "    val_loss       : -539.6794060214833\n",
      "Train Epoch: 350 [512/17352 (3%)] Loss: -752.757446\n",
      "Train Epoch: 350 [10203/17352 (59%)] Loss: -708.462029\n",
      "Train Epoch: 350 [16923/17352 (98%)] Loss: -616.922089\n",
      "    epoch          : 350\n",
      "    loss           : -734.1656775761539\n",
      "    val_loss       : -501.8989880931912\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch350.pth ...\n",
      "Train Epoch: 351 [512/17352 (3%)] Loss: -749.067749\n",
      "Train Epoch: 351 [10537/17352 (61%)] Loss: -778.188054\n",
      "Train Epoch: 351 [17016/17352 (98%)] Loss: -624.291724\n",
      "    epoch          : 351\n",
      "    loss           : -699.8759832352353\n",
      "    val_loss       : -453.90361352464015\n",
      "Train Epoch: 352 [512/17352 (3%)] Loss: -675.081970\n",
      "Train Epoch: 352 [10467/17352 (60%)] Loss: -756.595944\n",
      "Train Epoch: 352 [17101/17352 (99%)] Loss: -702.046796\n",
      "    epoch          : 352\n",
      "    loss           : -624.4873322083888\n",
      "    val_loss       : -397.7588070485284\n",
      "Train Epoch: 353 [512/17352 (3%)] Loss: -653.919067\n",
      "Train Epoch: 353 [10089/17352 (58%)] Loss: -426.647548\n",
      "Train Epoch: 353 [16988/17352 (98%)] Loss: -454.667005\n",
      "    epoch          : 353\n",
      "    loss           : -582.831364842116\n",
      "    val_loss       : -424.07178364719147\n",
      "Train Epoch: 354 [512/17352 (3%)] Loss: -669.508362\n",
      "Train Epoch: 354 [10277/17352 (59%)] Loss: -709.204072\n",
      "Train Epoch: 354 [16922/17352 (98%)] Loss: -811.730035\n",
      "    epoch          : 354\n",
      "    loss           : -671.7168593613183\n",
      "    val_loss       : -550.9749635078801\n",
      "Train Epoch: 355 [512/17352 (3%)] Loss: -774.828430\n",
      "Train Epoch: 355 [9757/17352 (56%)] Loss: -606.390532\n",
      "Train Epoch: 355 [16883/17352 (97%)] Loss: -569.719369\n",
      "    epoch          : 355\n",
      "    loss           : -689.0407638171063\n",
      "    val_loss       : -488.4525340750546\n",
      "Train Epoch: 356 [512/17352 (3%)] Loss: -518.815735\n",
      "Train Epoch: 356 [10144/17352 (58%)] Loss: -362.993631\n",
      "Train Epoch: 356 [16988/17352 (98%)] Loss: -502.903671\n",
      "    epoch          : 356\n",
      "    loss           : -584.5517823690583\n",
      "    val_loss       : -447.95444001746716\n",
      "Train Epoch: 357 [512/17352 (3%)] Loss: -456.393982\n",
      "Train Epoch: 357 [10511/17352 (61%)] Loss: -514.326013\n",
      "Train Epoch: 357 [17016/17352 (98%)] Loss: -799.563872\n",
      "    epoch          : 357\n",
      "    loss           : -698.6994711573044\n",
      "    val_loss       : -544.2140950047493\n",
      "Train Epoch: 358 [512/17352 (3%)] Loss: -712.402588\n",
      "Train Epoch: 358 [9335/17352 (54%)] Loss: -791.275281\n",
      "Train Epoch: 358 [17064/17352 (98%)] Loss: -724.386033\n",
      "    epoch          : 358\n",
      "    loss           : -730.326587848928\n",
      "    val_loss       : -580.1219587469091\n",
      "Train Epoch: 359 [512/17352 (3%)] Loss: -802.863647\n",
      "Train Epoch: 359 [10152/17352 (59%)] Loss: -773.915376\n",
      "Train Epoch: 359 [17124/17352 (99%)] Loss: -678.626253\n",
      "    epoch          : 359\n",
      "    loss           : -737.8272023077411\n",
      "    val_loss       : -553.570953224226\n",
      "Train Epoch: 360 [512/17352 (3%)] Loss: -776.020264\n",
      "Train Epoch: 360 [10457/17352 (60%)] Loss: -813.128125\n",
      "Train Epoch: 360 [17253/17352 (99%)] Loss: -701.709704\n",
      "    epoch          : 360\n",
      "    loss           : -738.1816286490628\n",
      "    val_loss       : -531.6737625595536\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch360.pth ...\n",
      "Train Epoch: 361 [512/17352 (3%)] Loss: -753.065430\n",
      "Train Epoch: 361 [10337/17352 (60%)] Loss: -766.799219\n",
      "Train Epoch: 361 [17106/17352 (99%)] Loss: -757.963081\n",
      "    epoch          : 361\n",
      "    loss           : -738.9810554190084\n",
      "    val_loss       : -504.718082238977\n",
      "Train Epoch: 362 [512/17352 (3%)] Loss: -702.610596\n",
      "Train Epoch: 362 [10605/17352 (61%)] Loss: -713.297809\n",
      "Train Epoch: 362 [17108/17352 (99%)] Loss: -266.587098\n",
      "    epoch          : 362\n",
      "    loss           : -666.2689141209979\n",
      "    val_loss       : -480.98514921154435\n",
      "Train Epoch: 363 [512/17352 (3%)] Loss: -695.437683\n",
      "Train Epoch: 363 [10416/17352 (60%)] Loss: -650.964154\n",
      "Train Epoch: 363 [17133/17352 (99%)] Loss: -840.053590\n",
      "    epoch          : 363\n",
      "    loss           : -695.167731868539\n",
      "    val_loss       : -568.8457643598896\n",
      "Train Epoch: 364 [512/17352 (3%)] Loss: -781.982544\n",
      "Train Epoch: 364 [10110/17352 (58%)] Loss: -784.019141\n",
      "Train Epoch: 364 [17090/17352 (98%)] Loss: -737.615057\n",
      "    epoch          : 364\n",
      "    loss           : -748.7847004972173\n",
      "    val_loss       : -570.3887183875461\n",
      "Train Epoch: 365 [512/17352 (3%)] Loss: -788.623230\n",
      "Train Epoch: 365 [10196/17352 (59%)] Loss: -675.285362\n",
      "Train Epoch: 365 [16957/17352 (98%)] Loss: -795.605451\n",
      "    epoch          : 365\n",
      "    loss           : -738.1984938865859\n",
      "    val_loss       : -584.6038517334631\n",
      "Train Epoch: 366 [512/17352 (3%)] Loss: -573.633789\n",
      "Train Epoch: 366 [10751/17352 (62%)] Loss: -791.168023\n",
      "Train Epoch: 366 [16958/17352 (98%)] Loss: -828.194835\n",
      "    epoch          : 366\n",
      "    loss           : -752.2884268685056\n",
      "    val_loss       : -581.2733281895875\n",
      "Train Epoch: 367 [512/17352 (3%)] Loss: -809.275940\n",
      "Train Epoch: 367 [9948/17352 (57%)] Loss: -759.552581\n",
      "Train Epoch: 367 [17277/17352 (100%)] Loss: -683.441508\n",
      "    epoch          : 367\n",
      "    loss           : -738.9084901817446\n",
      "    val_loss       : -552.3512152092085\n",
      "Train Epoch: 368 [512/17352 (3%)] Loss: -784.434265\n",
      "Train Epoch: 368 [9691/17352 (56%)] Loss: -739.582075\n",
      "Train Epoch: 368 [16957/17352 (98%)] Loss: -815.560505\n",
      "    epoch          : 368\n",
      "    loss           : -719.4935820668427\n",
      "    val_loss       : -535.7863947009808\n",
      "Train Epoch: 369 [512/17352 (3%)] Loss: -800.245300\n",
      "Train Epoch: 369 [10617/17352 (61%)] Loss: -600.004906\n",
      "Train Epoch: 369 [16872/17352 (97%)] Loss: -831.589010\n",
      "    epoch          : 369\n",
      "    loss           : -742.6505098045375\n",
      "    val_loss       : -582.328593654759\n",
      "Train Epoch: 370 [512/17352 (3%)] Loss: -817.929810\n",
      "Train Epoch: 370 [10455/17352 (60%)] Loss: -757.883757\n",
      "Train Epoch: 370 [17335/17352 (100%)] Loss: -645.368153\n",
      "    epoch          : 370\n",
      "    loss           : -769.848311765476\n",
      "    val_loss       : -580.1906452135922\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch370.pth ...\n",
      "Train Epoch: 371 [512/17352 (3%)] Loss: -807.767944\n",
      "Train Epoch: 371 [10621/17352 (61%)] Loss: -896.648709\n",
      "Train Epoch: 371 [16882/17352 (97%)] Loss: -663.634030\n",
      "    epoch          : 371\n",
      "    loss           : -764.6228633763898\n",
      "    val_loss       : -582.6439679781481\n",
      "Train Epoch: 372 [512/17352 (3%)] Loss: -786.793152\n",
      "Train Epoch: 372 [9859/17352 (57%)] Loss: -753.400678\n",
      "Train Epoch: 372 [17126/17352 (99%)] Loss: -888.823894\n",
      "    epoch          : 372\n",
      "    loss           : -777.1749801847884\n",
      "    val_loss       : -581.6421320260969\n",
      "Train Epoch: 373 [512/17352 (3%)] Loss: -820.501282\n",
      "Train Epoch: 373 [10621/17352 (61%)] Loss: -654.367003\n",
      "Train Epoch: 373 [17101/17352 (99%)] Loss: -694.810547\n",
      "    epoch          : 373\n",
      "    loss           : -760.8529060724978\n",
      "    val_loss       : -522.239937629073\n",
      "Train Epoch: 374 [512/17352 (3%)] Loss: -728.946960\n",
      "Train Epoch: 374 [10031/17352 (58%)] Loss: -832.153455\n",
      "Train Epoch: 374 [17090/17352 (98%)] Loss: -812.129161\n",
      "    epoch          : 374\n",
      "    loss           : -739.0464523755853\n",
      "    val_loss       : -549.528672217573\n",
      "Train Epoch: 375 [512/17352 (3%)] Loss: -790.806030\n",
      "Train Epoch: 375 [10325/17352 (60%)] Loss: -786.803628\n",
      "Train Epoch: 375 [17126/17352 (99%)] Loss: -881.906250\n",
      "    epoch          : 375\n",
      "    loss           : -759.0055495731172\n",
      "    val_loss       : -529.37730259825\n",
      "Train Epoch: 376 [512/17352 (3%)] Loss: -792.296631\n",
      "Train Epoch: 376 [10243/17352 (59%)] Loss: -694.918865\n",
      "Train Epoch: 376 [16923/17352 (98%)] Loss: -662.305745\n",
      "    epoch          : 376\n",
      "    loss           : -757.0353295533055\n",
      "    val_loss       : -604.4743387767963\n",
      "Train Epoch: 377 [512/17352 (3%)] Loss: -820.094604\n",
      "Train Epoch: 377 [10291/17352 (59%)] Loss: -638.206221\n",
      "Train Epoch: 377 [17016/17352 (98%)] Loss: -782.009845\n",
      "    epoch          : 377\n",
      "    loss           : -730.6051524332125\n",
      "    val_loss       : -491.34721909961684\n",
      "Train Epoch: 378 [512/17352 (3%)] Loss: -523.751343\n",
      "Train Epoch: 378 [9905/17352 (57%)] Loss: -716.681578\n",
      "Train Epoch: 378 [17335/17352 (100%)] Loss: -472.561587\n",
      "    epoch          : 378\n",
      "    loss           : -689.5811860866646\n",
      "    val_loss       : -426.70408116548685\n",
      "Train Epoch: 379 [512/17352 (3%)] Loss: -483.878906\n",
      "Train Epoch: 379 [9610/17352 (55%)] Loss: -743.880260\n",
      "Train Epoch: 379 [16922/17352 (98%)] Loss: -617.422933\n",
      "    epoch          : 379\n",
      "    loss           : -634.4105561720938\n",
      "    val_loss       : -503.60815222722357\n",
      "Train Epoch: 380 [512/17352 (3%)] Loss: -746.186035\n",
      "Train Epoch: 380 [10203/17352 (59%)] Loss: -496.914468\n",
      "Train Epoch: 380 [16923/17352 (98%)] Loss: -550.807118\n",
      "    epoch          : 380\n",
      "    loss           : -608.1926179029118\n",
      "    val_loss       : -468.05334434400964\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch380.pth ...\n",
      "Train Epoch: 381 [512/17352 (3%)] Loss: -695.590454\n",
      "Train Epoch: 381 [10231/17352 (59%)] Loss: -581.879193\n",
      "Train Epoch: 381 [16992/17352 (98%)] Loss: -600.821496\n",
      "    epoch          : 381\n",
      "    loss           : -658.0195322058016\n",
      "    val_loss       : -526.6572691467344\n",
      "Train Epoch: 382 [512/17352 (3%)] Loss: -744.607117\n",
      "Train Epoch: 382 [10820/17352 (62%)] Loss: -672.474618\n",
      "Train Epoch: 382 [16988/17352 (98%)] Loss: -690.144275\n",
      "    epoch          : 382\n",
      "    loss           : -748.9738484737347\n",
      "    val_loss       : -568.368630385953\n",
      "Train Epoch: 383 [512/17352 (3%)] Loss: -794.588745\n",
      "Train Epoch: 383 [10847/17352 (63%)] Loss: -773.610405\n",
      "Train Epoch: 383 [16922/17352 (98%)] Loss: -697.387602\n",
      "    epoch          : 383\n",
      "    loss           : -772.8342603144912\n",
      "    val_loss       : -579.4596933513978\n",
      "Train Epoch: 384 [512/17352 (3%)] Loss: -832.931274\n",
      "Train Epoch: 384 [10288/17352 (59%)] Loss: -860.065435\n",
      "Train Epoch: 384 [17153/17352 (99%)] Loss: -744.541493\n",
      "    epoch          : 384\n",
      "    loss           : -775.8453515220053\n",
      "    val_loss       : -575.5521863215987\n",
      "Train Epoch: 385 [512/17352 (3%)] Loss: -811.559509\n",
      "Train Epoch: 385 [10908/17352 (63%)] Loss: -736.022605\n",
      "Train Epoch: 385 [17143/17352 (99%)] Loss: -842.699564\n",
      "    epoch          : 385\n",
      "    loss           : -784.3938138047507\n",
      "    val_loss       : -576.1536726742902\n",
      "Train Epoch: 386 [512/17352 (3%)] Loss: -810.280151\n",
      "Train Epoch: 386 [10142/17352 (58%)] Loss: -653.085912\n",
      "Train Epoch: 386 [17106/17352 (99%)] Loss: -836.346094\n",
      "    epoch          : 386\n",
      "    loss           : -779.4167361214195\n",
      "    val_loss       : -567.4228871980704\n",
      "Train Epoch: 387 [512/17352 (3%)] Loss: -807.952148\n",
      "Train Epoch: 387 [9974/17352 (57%)] Loss: -831.696015\n",
      "Train Epoch: 387 [17016/17352 (98%)] Loss: -621.378065\n",
      "    epoch          : 387\n",
      "    loss           : -772.3517958825909\n",
      "    val_loss       : -570.6110437630215\n",
      "Train Epoch: 388 [512/17352 (3%)] Loss: -788.338501\n",
      "Train Epoch: 388 [10699/17352 (62%)] Loss: -818.018242\n",
      "Train Epoch: 388 [16992/17352 (98%)] Loss: -874.463759\n",
      "    epoch          : 388\n",
      "    loss           : -763.9075980858433\n",
      "    val_loss       : -572.0018469500791\n",
      "Train Epoch: 389 [512/17352 (3%)] Loss: -812.146667\n",
      "Train Epoch: 389 [10058/17352 (58%)] Loss: -754.344687\n",
      "Train Epoch: 389 [16872/17352 (97%)] Loss: -829.994767\n",
      "    epoch          : 389\n",
      "    loss           : -742.8928248046481\n",
      "    val_loss       : -563.4991977091698\n",
      "Train Epoch: 390 [512/17352 (3%)] Loss: -625.683167\n",
      "Train Epoch: 390 [10365/17352 (60%)] Loss: -819.547668\n",
      "Train Epoch: 390 [17090/17352 (98%)] Loss: -879.638148\n",
      "    epoch          : 390\n",
      "    loss           : -771.3747745242815\n",
      "    val_loss       : -569.9812793712186\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch390.pth ...\n",
      "Train Epoch: 391 [512/17352 (3%)] Loss: -632.399048\n",
      "Train Epoch: 391 [10448/17352 (60%)] Loss: -812.290525\n",
      "Train Epoch: 391 [17126/17352 (99%)] Loss: -774.640077\n",
      "    epoch          : 391\n",
      "    loss           : -766.2565556059462\n",
      "    val_loss       : -568.2474748948395\n",
      "Train Epoch: 392 [512/17352 (3%)] Loss: -823.184814\n",
      "Train Epoch: 392 [10437/17352 (60%)] Loss: -661.746803\n",
      "Train Epoch: 392 [17126/17352 (99%)] Loss: -805.383984\n",
      "    epoch          : 392\n",
      "    loss           : -780.3576272526325\n",
      "    val_loss       : -578.1667455645268\n",
      "Train Epoch: 393 [512/17352 (3%)] Loss: -831.555908\n",
      "Train Epoch: 393 [10307/17352 (59%)] Loss: -773.232486\n",
      "Train Epoch: 393 [17143/17352 (99%)] Loss: -732.308742\n",
      "    epoch          : 393\n",
      "    loss           : -782.2933570986614\n",
      "    val_loss       : -477.23349479511614\n",
      "Train Epoch: 394 [512/17352 (3%)] Loss: -724.760010\n",
      "Train Epoch: 394 [10690/17352 (62%)] Loss: -732.978163\n",
      "Train Epoch: 394 [17126/17352 (99%)] Loss: -833.272397\n",
      "    epoch          : 394\n",
      "    loss           : -742.5975436262722\n",
      "    val_loss       : -345.4515627039577\n",
      "Train Epoch: 395 [512/17352 (3%)] Loss: -656.220459\n",
      "Train Epoch: 395 [10061/17352 (58%)] Loss: -707.380339\n",
      "Train Epoch: 395 [17277/17352 (100%)] Loss: -800.330729\n",
      "    epoch          : 395\n",
      "    loss           : -674.5665698815744\n",
      "    val_loss       : -251.44044304291788\n",
      "Train Epoch: 396 [512/17352 (3%)] Loss: -261.748291\n",
      "Train Epoch: 396 [10325/17352 (60%)] Loss: -540.314904\n",
      "Train Epoch: 396 [16992/17352 (98%)] Loss: -688.140000\n",
      "    epoch          : 396\n",
      "    loss           : -612.652014891893\n",
      "    val_loss       : -448.26114826273056\n",
      "Train Epoch: 397 [512/17352 (3%)] Loss: -712.102417\n",
      "Train Epoch: 397 [10201/17352 (59%)] Loss: -590.925763\n",
      "Train Epoch: 397 [16939/17352 (98%)] Loss: -869.504666\n",
      "    epoch          : 397\n",
      "    loss           : -714.4955874565244\n",
      "    val_loss       : -565.0131852125635\n",
      "Train Epoch: 398 [512/17352 (3%)] Loss: -805.940186\n",
      "Train Epoch: 398 [10255/17352 (59%)] Loss: -696.386801\n",
      "Train Epoch: 398 [16882/17352 (97%)] Loss: -769.119162\n",
      "    epoch          : 398\n",
      "    loss           : -760.2692659762357\n",
      "    val_loss       : -579.6782741842044\n",
      "Train Epoch: 399 [512/17352 (3%)] Loss: -610.139343\n",
      "Train Epoch: 399 [10238/17352 (59%)] Loss: -783.851424\n",
      "Train Epoch: 399 [16939/17352 (98%)] Loss: -588.808201\n",
      "    epoch          : 399\n",
      "    loss           : -728.9305900098595\n",
      "    val_loss       : -521.1028952313243\n",
      "Train Epoch: 400 [512/17352 (3%)] Loss: -743.434814\n",
      "Train Epoch: 400 [10206/17352 (59%)] Loss: -670.506395\n",
      "Train Epoch: 400 [17064/17352 (98%)] Loss: -771.706461\n",
      "    epoch          : 400\n",
      "    loss           : -722.6365397884761\n",
      "    val_loss       : -538.6525908415446\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch400.pth ...\n",
      "Train Epoch: 401 [512/17352 (3%)] Loss: -776.326294\n",
      "Train Epoch: 401 [10545/17352 (61%)] Loss: -842.942708\n",
      "Train Epoch: 401 [16939/17352 (98%)] Loss: -817.731105\n",
      "    epoch          : 401\n",
      "    loss           : -728.7266102351687\n",
      "    val_loss       : -533.0605860144966\n",
      "Train Epoch: 402 [512/17352 (3%)] Loss: -600.809387\n",
      "Train Epoch: 402 [10174/17352 (59%)] Loss: -878.595973\n",
      "Train Epoch: 402 [17101/17352 (99%)] Loss: -749.453947\n",
      "    epoch          : 402\n",
      "    loss           : -775.931183906657\n",
      "    val_loss       : -553.6771454893221\n",
      "Train Epoch: 403 [512/17352 (3%)] Loss: -628.830322\n",
      "Train Epoch: 403 [10420/17352 (60%)] Loss: -665.390297\n",
      "Train Epoch: 403 [16988/17352 (98%)] Loss: -654.068229\n",
      "    epoch          : 403\n",
      "    loss           : -773.0674795214032\n",
      "    val_loss       : -557.8634785369482\n",
      "Train Epoch: 404 [512/17352 (3%)] Loss: -799.121033\n",
      "Train Epoch: 404 [10295/17352 (59%)] Loss: -831.069970\n",
      "Train Epoch: 404 [17090/17352 (98%)] Loss: -816.714975\n",
      "    epoch          : 404\n",
      "    loss           : -774.3629233849722\n",
      "    val_loss       : -577.4650969512371\n",
      "Train Epoch: 405 [512/17352 (3%)] Loss: -828.955811\n",
      "Train Epoch: 405 [10095/17352 (58%)] Loss: -675.192066\n",
      "Train Epoch: 405 [17124/17352 (99%)] Loss: -684.979385\n",
      "    epoch          : 405\n",
      "    loss           : -777.3860320111878\n",
      "    val_loss       : -569.3111800701374\n",
      "Train Epoch: 406 [512/17352 (3%)] Loss: -807.115601\n",
      "Train Epoch: 406 [9877/17352 (57%)] Loss: -823.333449\n",
      "Train Epoch: 406 [16923/17352 (98%)] Loss: -850.585729\n",
      "    epoch          : 406\n",
      "    loss           : -796.39425677505\n",
      "    val_loss       : -578.6996269768214\n",
      "Train Epoch: 407 [512/17352 (3%)] Loss: -839.235229\n",
      "Train Epoch: 407 [10558/17352 (61%)] Loss: -752.229446\n",
      "Train Epoch: 407 [16922/17352 (98%)] Loss: -912.426649\n",
      "    epoch          : 407\n",
      "    loss           : -802.4712371803599\n",
      "    val_loss       : -598.9025390676878\n",
      "Train Epoch: 408 [512/17352 (3%)] Loss: -831.057556\n",
      "Train Epoch: 408 [10250/17352 (59%)] Loss: -656.378205\n",
      "Train Epoch: 408 [16958/17352 (98%)] Loss: -852.393750\n",
      "    epoch          : 408\n",
      "    loss           : -793.4862755929037\n",
      "    val_loss       : -579.411505835605\n",
      "Train Epoch: 409 [512/17352 (3%)] Loss: -837.582458\n",
      "Train Epoch: 409 [10204/17352 (59%)] Loss: -823.963021\n",
      "Train Epoch: 409 [17108/17352 (99%)] Loss: -834.427639\n",
      "    epoch          : 409\n",
      "    loss           : -767.136897583935\n",
      "    val_loss       : -501.0374734673545\n",
      "Train Epoch: 410 [512/17352 (3%)] Loss: -748.787964\n",
      "Train Epoch: 410 [10573/17352 (61%)] Loss: -891.340345\n",
      "Train Epoch: 410 [17044/17352 (98%)] Loss: -728.923003\n",
      "    epoch          : 410\n",
      "    loss           : -773.9137276038313\n",
      "    val_loss       : -570.6299691092789\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch410.pth ...\n",
      "Train Epoch: 411 [512/17352 (3%)] Loss: -816.898010\n",
      "Train Epoch: 411 [10576/17352 (61%)] Loss: -743.501281\n",
      "Train Epoch: 411 [17263/17352 (99%)] Loss: -776.632066\n",
      "    epoch          : 411\n",
      "    loss           : -799.0857316742855\n",
      "    val_loss       : -570.3975747704155\n",
      "Train Epoch: 412 [512/17352 (3%)] Loss: -835.103516\n",
      "Train Epoch: 412 [10053/17352 (58%)] Loss: -861.162832\n",
      "Train Epoch: 412 [16957/17352 (98%)] Loss: -910.673394\n",
      "    epoch          : 412\n",
      "    loss           : -793.4163658514578\n",
      "    val_loss       : -589.1507125401829\n",
      "Train Epoch: 413 [512/17352 (3%)] Loss: -854.973206\n",
      "Train Epoch: 413 [10013/17352 (58%)] Loss: -728.166131\n",
      "Train Epoch: 413 [17044/17352 (98%)] Loss: -670.355794\n",
      "    epoch          : 413\n",
      "    loss           : -724.7438950881843\n",
      "    val_loss       : -517.5431063028586\n",
      "Train Epoch: 414 [512/17352 (3%)] Loss: -716.486084\n",
      "Train Epoch: 414 [10541/17352 (61%)] Loss: -811.856679\n",
      "Train Epoch: 414 [16872/17352 (97%)] Loss: -773.932584\n",
      "    epoch          : 414\n",
      "    loss           : -757.626413692101\n",
      "    val_loss       : -520.2088303892516\n",
      "Train Epoch: 415 [512/17352 (3%)] Loss: -810.002808\n",
      "Train Epoch: 415 [10244/17352 (59%)] Loss: -902.248222\n",
      "Train Epoch: 415 [16887/17352 (97%)] Loss: -721.112342\n",
      "    epoch          : 415\n",
      "    loss           : -794.5339836469878\n",
      "    val_loss       : -555.6985929836294\n",
      "Train Epoch: 416 [512/17352 (3%)] Loss: -813.675598\n",
      "Train Epoch: 416 [10002/17352 (58%)] Loss: -759.541570\n",
      "Train Epoch: 416 [17335/17352 (100%)] Loss: -735.758371\n",
      "    epoch          : 416\n",
      "    loss           : -780.2975351901788\n",
      "    val_loss       : -506.3218124643971\n",
      "Train Epoch: 417 [512/17352 (3%)] Loss: -731.371643\n",
      "Train Epoch: 417 [10753/17352 (62%)] Loss: -829.192297\n",
      "Train Epoch: 417 [17277/17352 (100%)] Loss: -570.257175\n",
      "    epoch          : 417\n",
      "    loss           : -735.3412936486319\n",
      "    val_loss       : -517.4151763751844\n",
      "Train Epoch: 418 [512/17352 (3%)] Loss: -736.721802\n",
      "Train Epoch: 418 [10330/17352 (60%)] Loss: -729.696094\n",
      "Train Epoch: 418 [17335/17352 (100%)] Loss: -870.591717\n",
      "    epoch          : 418\n",
      "    loss           : -720.239209772233\n",
      "    val_loss       : -507.92379815124497\n",
      "Train Epoch: 419 [512/17352 (3%)] Loss: -795.175964\n",
      "Train Epoch: 419 [10459/17352 (60%)] Loss: -632.349798\n",
      "Train Epoch: 419 [17016/17352 (98%)] Loss: -849.576194\n",
      "    epoch          : 419\n",
      "    loss           : -764.4136406806784\n",
      "    val_loss       : -568.9154511077587\n",
      "Train Epoch: 420 [512/17352 (3%)] Loss: -807.647156\n",
      "Train Epoch: 420 [10010/17352 (58%)] Loss: -685.944414\n",
      "Train Epoch: 420 [17016/17352 (98%)] Loss: -719.985540\n",
      "    epoch          : 420\n",
      "    loss           : -735.1732411002747\n",
      "    val_loss       : -549.8468233243128\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch420.pth ...\n",
      "Train Epoch: 421 [512/17352 (3%)] Loss: -811.460022\n",
      "Train Epoch: 421 [10682/17352 (62%)] Loss: -633.689651\n",
      "Train Epoch: 421 [17044/17352 (98%)] Loss: -819.543280\n",
      "    epoch          : 421\n",
      "    loss           : -772.60446590369\n",
      "    val_loss       : -567.5940837872723\n",
      "Train Epoch: 422 [512/17352 (3%)] Loss: -822.958435\n",
      "Train Epoch: 422 [10602/17352 (61%)] Loss: -761.718063\n",
      "Train Epoch: 422 [17090/17352 (98%)] Loss: -594.974494\n",
      "    epoch          : 422\n",
      "    loss           : -762.4751795199344\n",
      "    val_loss       : -530.8265428857632\n",
      "Train Epoch: 423 [512/17352 (3%)] Loss: -768.005859\n",
      "Train Epoch: 423 [10538/17352 (61%)] Loss: 100.086283\n",
      "Train Epoch: 423 [16883/17352 (97%)] Loss: -718.896502\n",
      "    epoch          : 423\n",
      "    loss           : -479.7915538962487\n",
      "    val_loss       : -364.8222405164564\n",
      "Train Epoch: 424 [512/17352 (3%)] Loss: -669.113281\n",
      "Train Epoch: 424 [10060/17352 (58%)] Loss: -351.864440\n",
      "Train Epoch: 424 [17277/17352 (100%)] Loss: 76.742722\n",
      "    epoch          : 424\n",
      "    loss           : -463.9005603594384\n",
      "    val_loss       : -166.88506384195185\n",
      "Train Epoch: 425 [512/17352 (3%)] Loss: -470.375824\n",
      "Train Epoch: 425 [9832/17352 (57%)] Loss: -446.627177\n",
      "Train Epoch: 425 [17126/17352 (99%)] Loss: -611.491550\n",
      "    epoch          : 425\n",
      "    loss           : -600.9731963082304\n",
      "    val_loss       : -201.33479742078435\n",
      "Train Epoch: 426 [512/17352 (3%)] Loss: -507.960449\n",
      "Train Epoch: 426 [10510/17352 (61%)] Loss: -751.758958\n",
      "Train Epoch: 426 [16883/17352 (97%)] Loss: -613.714788\n",
      "    epoch          : 426\n",
      "    loss           : -678.9043239797575\n",
      "    val_loss       : -468.2345352696574\n",
      "Train Epoch: 427 [512/17352 (3%)] Loss: -725.509644\n",
      "Train Epoch: 427 [10488/17352 (60%)] Loss: -753.051011\n",
      "Train Epoch: 427 [16958/17352 (98%)] Loss: -770.042484\n",
      "    epoch          : 427\n",
      "    loss           : -731.7540096266173\n",
      "    val_loss       : -561.0260086359838\n",
      "Train Epoch: 428 [512/17352 (3%)] Loss: -810.662842\n",
      "Train Epoch: 428 [11327/17352 (65%)] Loss: -751.004285\n",
      "Train Epoch: 428 [17126/17352 (99%)] Loss: -750.062399\n",
      "    epoch          : 428\n",
      "    loss           : -802.3530944159677\n",
      "    val_loss       : -606.3487095412395\n",
      "Train Epoch: 429 [512/17352 (3%)] Loss: -856.714905\n",
      "Train Epoch: 429 [10193/17352 (59%)] Loss: -769.454706\n",
      "Train Epoch: 429 [17143/17352 (99%)] Loss: -714.933712\n",
      "    epoch          : 429\n",
      "    loss           : -812.2693123978736\n",
      "    val_loss       : -603.0560870854474\n",
      "Train Epoch: 430 [512/17352 (3%)] Loss: -872.511292\n",
      "Train Epoch: 430 [10266/17352 (59%)] Loss: -882.995276\n",
      "Train Epoch: 430 [16957/17352 (98%)] Loss: -842.418734\n",
      "    epoch          : 430\n",
      "    loss           : -819.8753334917645\n",
      "    val_loss       : -579.8827403747736\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch430.pth ...\n",
      "Train Epoch: 431 [512/17352 (3%)] Loss: -857.943848\n",
      "Train Epoch: 431 [9933/17352 (57%)] Loss: -927.409397\n",
      "Train Epoch: 431 [17124/17352 (99%)] Loss: -826.666897\n",
      "    epoch          : 431\n",
      "    loss           : -812.178489718201\n",
      "    val_loss       : -594.9890144304012\n",
      "Train Epoch: 432 [512/17352 (3%)] Loss: -838.188660\n",
      "Train Epoch: 432 [10469/17352 (60%)] Loss: -925.750217\n",
      "Train Epoch: 432 [17106/17352 (99%)] Loss: -895.515801\n",
      "    epoch          : 432\n",
      "    loss           : -820.0517339588448\n",
      "    val_loss       : -606.1173338416943\n",
      "Train Epoch: 433 [512/17352 (3%)] Loss: -870.312317\n",
      "Train Epoch: 433 [10318/17352 (59%)] Loss: -889.948473\n",
      "Train Epoch: 433 [16922/17352 (98%)] Loss: -772.034480\n",
      "    epoch          : 433\n",
      "    loss           : -827.5090229332451\n",
      "    val_loss       : -606.3183454047638\n",
      "Train Epoch: 434 [512/17352 (3%)] Loss: -873.416443\n",
      "Train Epoch: 434 [9954/17352 (57%)] Loss: -902.802690\n",
      "Train Epoch: 434 [16992/17352 (98%)] Loss: -846.043073\n",
      "    epoch          : 434\n",
      "    loss           : -832.5724015265729\n",
      "    val_loss       : -577.6281461464996\n",
      "Train Epoch: 435 [512/17352 (3%)] Loss: -870.250854\n",
      "Train Epoch: 435 [10729/17352 (62%)] Loss: -878.169146\n",
      "Train Epoch: 435 [17277/17352 (100%)] Loss: -846.937500\n",
      "    epoch          : 435\n",
      "    loss           : -820.9790858800702\n",
      "    val_loss       : -559.4690595301112\n",
      "Train Epoch: 436 [512/17352 (3%)] Loss: -829.021484\n",
      "Train Epoch: 436 [10284/17352 (59%)] Loss: -769.925090\n",
      "Train Epoch: 436 [17064/17352 (98%)] Loss: -812.522518\n",
      "    epoch          : 436\n",
      "    loss           : -815.1536001481217\n",
      "    val_loss       : -580.0259430398276\n",
      "Train Epoch: 437 [512/17352 (3%)] Loss: -855.033325\n",
      "Train Epoch: 437 [10657/17352 (61%)] Loss: -748.414336\n",
      "Train Epoch: 437 [16988/17352 (98%)] Loss: -880.640274\n",
      "    epoch          : 437\n",
      "    loss           : -824.2309947560947\n",
      "    val_loss       : -568.9952737858473\n",
      "Train Epoch: 438 [512/17352 (3%)] Loss: -864.700928\n",
      "Train Epoch: 438 [10356/17352 (60%)] Loss: -911.728360\n",
      "Train Epoch: 438 [17335/17352 (100%)] Loss: -907.687818\n",
      "    epoch          : 438\n",
      "    loss           : -805.7797851521519\n",
      "    val_loss       : -580.5276265296475\n",
      "Train Epoch: 439 [512/17352 (3%)] Loss: -865.334412\n",
      "Train Epoch: 439 [10311/17352 (59%)] Loss: -863.702423\n",
      "Train Epoch: 439 [17016/17352 (98%)] Loss: -850.210069\n",
      "    epoch          : 439\n",
      "    loss           : -798.2968128372521\n",
      "    val_loss       : -583.1703052055266\n",
      "Train Epoch: 440 [512/17352 (3%)] Loss: -811.254761\n",
      "Train Epoch: 440 [10028/17352 (58%)] Loss: -862.006198\n",
      "Train Epoch: 440 [16957/17352 (98%)] Loss: -663.798594\n",
      "    epoch          : 440\n",
      "    loss           : -811.890215485995\n",
      "    val_loss       : -590.9119086466332\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch440.pth ...\n",
      "Train Epoch: 441 [512/17352 (3%)] Loss: -860.524292\n",
      "Train Epoch: 441 [10651/17352 (61%)] Loss: -875.954632\n",
      "Train Epoch: 441 [17335/17352 (100%)] Loss: -635.127617\n",
      "    epoch          : 441\n",
      "    loss           : -797.3523047191164\n",
      "    val_loss       : -504.470239365276\n",
      "Train Epoch: 442 [512/17352 (3%)] Loss: -754.353271\n",
      "Train Epoch: 442 [10364/17352 (60%)] Loss: -868.772083\n",
      "Train Epoch: 442 [17108/17352 (99%)] Loss: -745.527604\n",
      "    epoch          : 442\n",
      "    loss           : -784.9428429140679\n",
      "    val_loss       : -546.2426260004047\n",
      "Train Epoch: 443 [512/17352 (3%)] Loss: -823.203064\n",
      "Train Epoch: 443 [9417/17352 (54%)] Loss: -774.837086\n",
      "Train Epoch: 443 [16872/17352 (97%)] Loss: -700.512410\n",
      "    epoch          : 443\n",
      "    loss           : -815.0781243973838\n",
      "    val_loss       : -592.3406575030839\n",
      "Train Epoch: 444 [512/17352 (3%)] Loss: -871.024841\n",
      "Train Epoch: 444 [10879/17352 (63%)] Loss: -721.098922\n",
      "Train Epoch: 444 [17064/17352 (98%)] Loss: -851.007705\n",
      "    epoch          : 444\n",
      "    loss           : -829.4042258106222\n",
      "    val_loss       : -573.9726645150934\n",
      "Train Epoch: 445 [512/17352 (3%)] Loss: -851.648499\n",
      "Train Epoch: 445 [10122/17352 (58%)] Loss: -809.978745\n",
      "Train Epoch: 445 [17016/17352 (98%)] Loss: -870.738021\n",
      "    epoch          : 445\n",
      "    loss           : -821.8953123428284\n",
      "    val_loss       : -584.0896801406011\n",
      "Train Epoch: 446 [512/17352 (3%)] Loss: -867.530579\n",
      "Train Epoch: 446 [10347/17352 (60%)] Loss: -802.009186\n",
      "Train Epoch: 446 [16882/17352 (97%)] Loss: -800.248794\n",
      "    epoch          : 446\n",
      "    loss           : -829.4581537616376\n",
      "    val_loss       : -579.9263764352901\n",
      "Train Epoch: 447 [512/17352 (3%)] Loss: -871.719727\n",
      "Train Epoch: 447 [9951/17352 (57%)] Loss: -884.142449\n",
      "Train Epoch: 447 [16882/17352 (97%)] Loss: -874.703721\n",
      "    epoch          : 447\n",
      "    loss           : -838.5913988493755\n",
      "    val_loss       : -589.6482626272733\n",
      "Train Epoch: 448 [512/17352 (3%)] Loss: -893.881226\n",
      "Train Epoch: 448 [10660/17352 (61%)] Loss: -841.085035\n",
      "Train Epoch: 448 [16957/17352 (98%)] Loss: -886.213075\n",
      "    epoch          : 448\n",
      "    loss           : -794.3664147288557\n",
      "    val_loss       : -464.48229922497205\n",
      "Train Epoch: 449 [512/17352 (3%)] Loss: -714.138794\n",
      "Train Epoch: 449 [10072/17352 (58%)] Loss: -770.015487\n",
      "Train Epoch: 449 [16939/17352 (98%)] Loss: -724.128348\n",
      "    epoch          : 449\n",
      "    loss           : -716.1537944842814\n",
      "    val_loss       : -498.12845354529713\n",
      "Train Epoch: 450 [512/17352 (3%)] Loss: -783.141479\n",
      "Train Epoch: 450 [10082/17352 (58%)] Loss: -773.970104\n",
      "Train Epoch: 450 [17253/17352 (99%)] Loss: -576.898925\n",
      "    epoch          : 450\n",
      "    loss           : -698.3634515795403\n",
      "    val_loss       : -432.68210166384523\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch450.pth ...\n",
      "Train Epoch: 451 [512/17352 (3%)] Loss: -685.179138\n",
      "Train Epoch: 451 [10109/17352 (58%)] Loss: -757.714641\n",
      "Train Epoch: 451 [17335/17352 (100%)] Loss: -683.531326\n",
      "    epoch          : 451\n",
      "    loss           : -695.5190458586376\n",
      "    val_loss       : 709.0805355723563\n",
      "Train Epoch: 452 [512/17352 (3%)] Loss: 485.435822\n",
      "Train Epoch: 452 [10078/17352 (58%)] Loss: -493.497103\n",
      "Train Epoch: 452 [17153/17352 (99%)] Loss: -571.677893\n",
      "    epoch          : 452\n",
      "    loss           : -483.3921914574457\n",
      "    val_loss       : -428.01489171030863\n",
      "Train Epoch: 453 [512/17352 (3%)] Loss: -743.657593\n",
      "Train Epoch: 453 [10377/17352 (60%)] Loss: -756.022786\n",
      "Train Epoch: 453 [17106/17352 (99%)] Loss: -800.010334\n",
      "    epoch          : 453\n",
      "    loss           : -742.6840360986163\n",
      "    val_loss       : -557.2474039497004\n",
      "Train Epoch: 454 [512/17352 (3%)] Loss: -811.988403\n",
      "Train Epoch: 454 [10261/17352 (59%)] Loss: -768.853451\n",
      "Train Epoch: 454 [17133/17352 (99%)] Loss: -882.665133\n",
      "    epoch          : 454\n",
      "    loss           : -788.4249858372116\n",
      "    val_loss       : -577.5674365382994\n",
      "Train Epoch: 455 [512/17352 (3%)] Loss: -864.437927\n",
      "Train Epoch: 455 [10048/17352 (58%)] Loss: -878.469497\n",
      "Train Epoch: 455 [17153/17352 (99%)] Loss: -933.114339\n",
      "    epoch          : 455\n",
      "    loss           : -827.4606800611707\n",
      "    val_loss       : -579.1311705707665\n",
      "Train Epoch: 456 [512/17352 (3%)] Loss: -682.567383\n",
      "Train Epoch: 456 [10416/17352 (60%)] Loss: -936.358181\n",
      "Train Epoch: 456 [17108/17352 (99%)] Loss: -849.306209\n",
      "    epoch          : 456\n",
      "    loss           : -831.4819359418445\n",
      "    val_loss       : -608.9841892757464\n",
      "Train Epoch: 457 [512/17352 (3%)] Loss: -861.116516\n",
      "Train Epoch: 457 [10489/17352 (60%)] Loss: -912.550633\n",
      "Train Epoch: 457 [17126/17352 (99%)] Loss: -895.238182\n",
      "    epoch          : 457\n",
      "    loss           : -839.3795517577836\n",
      "    val_loss       : -612.4966520880955\n",
      "Train Epoch: 458 [512/17352 (3%)] Loss: -732.680176\n",
      "Train Epoch: 458 [10525/17352 (61%)] Loss: -831.023352\n",
      "Train Epoch: 458 [17143/17352 (99%)] Loss: -727.140365\n",
      "    epoch          : 458\n",
      "    loss           : -846.4342131493178\n",
      "    val_loss       : -577.830041457943\n",
      "Train Epoch: 459 [512/17352 (3%)] Loss: -876.014282\n",
      "Train Epoch: 459 [10748/17352 (62%)] Loss: -865.907031\n",
      "Train Epoch: 459 [17101/17352 (99%)] Loss: -755.490564\n",
      "    epoch          : 459\n",
      "    loss           : -830.2361401374568\n",
      "    val_loss       : -590.5659669147893\n",
      "Train Epoch: 460 [512/17352 (3%)] Loss: -877.422729\n",
      "Train Epoch: 460 [10408/17352 (60%)] Loss: -768.166713\n",
      "Train Epoch: 460 [17253/17352 (99%)] Loss: -694.262030\n",
      "    epoch          : 460\n",
      "    loss           : -835.5047578542268\n",
      "    val_loss       : -572.4431258738828\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch460.pth ...\n",
      "Train Epoch: 461 [512/17352 (3%)] Loss: -861.992126\n",
      "Train Epoch: 461 [10577/17352 (61%)] Loss: -857.322871\n",
      "Train Epoch: 461 [16882/17352 (97%)] Loss: -813.024123\n",
      "    epoch          : 461\n",
      "    loss           : -836.8742830253954\n",
      "    val_loss       : -591.9688430648332\n",
      "Train Epoch: 462 [512/17352 (3%)] Loss: -876.368347\n",
      "Train Epoch: 462 [10701/17352 (62%)] Loss: -914.527294\n",
      "Train Epoch: 462 [17049/17352 (98%)] Loss: -910.961453\n",
      "    epoch          : 462\n",
      "    loss           : -843.9278460927937\n",
      "    val_loss       : -599.8929373864852\n",
      "Train Epoch: 463 [512/17352 (3%)] Loss: -881.756470\n",
      "Train Epoch: 463 [10481/17352 (60%)] Loss: -891.930924\n",
      "Train Epoch: 463 [17263/17352 (99%)] Loss: -886.447110\n",
      "    epoch          : 463\n",
      "    loss           : -856.5053372907547\n",
      "    val_loss       : -594.156680781233\n",
      "Train Epoch: 464 [512/17352 (3%)] Loss: -886.659851\n",
      "Train Epoch: 464 [10825/17352 (62%)] Loss: -731.184715\n",
      "Train Epoch: 464 [17124/17352 (99%)] Loss: -821.370536\n",
      "    epoch          : 464\n",
      "    loss           : -844.751853252204\n",
      "    val_loss       : -581.3194086912731\n",
      "Train Epoch: 465 [512/17352 (3%)] Loss: -890.287964\n",
      "Train Epoch: 465 [10314/17352 (59%)] Loss: -773.335633\n",
      "Train Epoch: 465 [16923/17352 (98%)] Loss: -645.625274\n",
      "    epoch          : 465\n",
      "    loss           : -819.1881613127172\n",
      "    val_loss       : -527.5589304650812\n",
      "Train Epoch: 466 [512/17352 (3%)] Loss: -819.465820\n",
      "Train Epoch: 466 [10608/17352 (61%)] Loss: -861.111849\n",
      "Train Epoch: 466 [16922/17352 (98%)] Loss: -796.597714\n",
      "    epoch          : 466\n",
      "    loss           : -799.3393718087827\n",
      "    val_loss       : -549.27798634039\n",
      "Train Epoch: 467 [512/17352 (3%)] Loss: -869.016602\n",
      "Train Epoch: 467 [10439/17352 (60%)] Loss: -709.326555\n",
      "Train Epoch: 467 [16992/17352 (98%)] Loss: -771.870825\n",
      "    epoch          : 467\n",
      "    loss           : -793.9839883466933\n",
      "    val_loss       : -335.29478618800505\n",
      "Train Epoch: 468 [512/17352 (3%)] Loss: -604.638672\n",
      "Train Epoch: 468 [9769/17352 (56%)] Loss: -764.343213\n",
      "Train Epoch: 468 [16922/17352 (98%)] Loss: -660.928977\n",
      "    epoch          : 468\n",
      "    loss           : -614.2174545235164\n",
      "    val_loss       : -502.9591043364907\n",
      "Train Epoch: 469 [512/17352 (3%)] Loss: -802.539795\n",
      "Train Epoch: 469 [10621/17352 (61%)] Loss: -822.565052\n",
      "Train Epoch: 469 [17335/17352 (100%)] Loss: -505.768490\n",
      "    epoch          : 469\n",
      "    loss           : -724.1958419397786\n",
      "    val_loss       : -237.2226017949949\n",
      "Train Epoch: 470 [512/17352 (3%)] Loss: -506.952545\n",
      "Train Epoch: 470 [10592/17352 (61%)] Loss: -869.037184\n",
      "Train Epoch: 470 [16923/17352 (98%)] Loss: -829.762306\n",
      "    epoch          : 470\n",
      "    loss           : -766.2006879701802\n",
      "    val_loss       : -580.4795827241143\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch470.pth ...\n",
      "Train Epoch: 471 [512/17352 (3%)] Loss: -879.567322\n",
      "Train Epoch: 471 [10609/17352 (61%)] Loss: -851.700927\n",
      "Train Epoch: 471 [17016/17352 (98%)] Loss: -722.433746\n",
      "    epoch          : 471\n",
      "    loss           : -823.0415811671144\n",
      "    val_loss       : -583.2066532089475\n",
      "Train Epoch: 472 [512/17352 (3%)] Loss: -861.747620\n",
      "Train Epoch: 472 [10338/17352 (60%)] Loss: -742.800846\n",
      "Train Epoch: 472 [16872/17352 (97%)] Loss: -887.367580\n",
      "    epoch          : 472\n",
      "    loss           : -841.1518435422985\n",
      "    val_loss       : -568.5957612864348\n",
      "Train Epoch: 473 [512/17352 (3%)] Loss: -899.273071\n",
      "Train Epoch: 473 [10362/17352 (60%)] Loss: -953.619325\n",
      "Train Epoch: 473 [16883/17352 (97%)] Loss: -895.023469\n",
      "    epoch          : 473\n",
      "    loss           : -845.5044214518824\n",
      "    val_loss       : -589.3369792815496\n",
      "Train Epoch: 474 [512/17352 (3%)] Loss: -910.735596\n",
      "Train Epoch: 474 [10060/17352 (58%)] Loss: -744.874709\n",
      "Train Epoch: 474 [17335/17352 (100%)] Loss: -832.209019\n",
      "    epoch          : 474\n",
      "    loss           : -853.1145745504384\n",
      "    val_loss       : -581.0681041187491\n",
      "Train Epoch: 475 [512/17352 (3%)] Loss: -904.223389\n",
      "Train Epoch: 475 [10560/17352 (61%)] Loss: -726.913508\n",
      "Train Epoch: 475 [17126/17352 (99%)] Loss: -906.098917\n",
      "    epoch          : 475\n",
      "    loss           : -857.9803271176262\n",
      "    val_loss       : -587.8969329511197\n",
      "Train Epoch: 476 [512/17352 (3%)] Loss: -899.766846\n",
      "Train Epoch: 476 [10224/17352 (59%)] Loss: -727.128140\n",
      "Train Epoch: 476 [17263/17352 (99%)] Loss: -739.889350\n",
      "    epoch          : 476\n",
      "    loss           : -847.6799420566498\n",
      "    val_loss       : -553.3816311296652\n",
      "Train Epoch: 477 [512/17352 (3%)] Loss: -860.186096\n",
      "Train Epoch: 477 [10380/17352 (60%)] Loss: -815.256664\n",
      "Train Epoch: 477 [16883/17352 (97%)] Loss: -945.930319\n",
      "    epoch          : 477\n",
      "    loss           : -849.7435416358727\n",
      "    val_loss       : -587.4467241150576\n",
      "Train Epoch: 478 [512/17352 (3%)] Loss: -692.909424\n",
      "Train Epoch: 478 [10209/17352 (59%)] Loss: -901.185121\n",
      "Train Epoch: 478 [16957/17352 (98%)] Loss: -735.897727\n",
      "    epoch          : 478\n",
      "    loss           : -847.6568281580726\n",
      "    val_loss       : -582.3532796750676\n",
      "Train Epoch: 479 [512/17352 (3%)] Loss: -857.558044\n",
      "Train Epoch: 479 [10227/17352 (59%)] Loss: -959.859715\n",
      "Train Epoch: 479 [17064/17352 (98%)] Loss: -909.404029\n",
      "    epoch          : 479\n",
      "    loss           : -843.1563288723457\n",
      "    val_loss       : -598.2867028318674\n",
      "Train Epoch: 480 [512/17352 (3%)] Loss: -898.419617\n",
      "Train Epoch: 480 [10166/17352 (59%)] Loss: -936.201729\n",
      "Train Epoch: 480 [17335/17352 (100%)] Loss: -923.893823\n",
      "    epoch          : 480\n",
      "    loss           : -854.9016328622166\n",
      "    val_loss       : -564.9753107863199\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch480.pth ...\n",
      "Train Epoch: 481 [512/17352 (3%)] Loss: -886.024292\n",
      "Train Epoch: 481 [9758/17352 (56%)] Loss: -892.086719\n",
      "Train Epoch: 481 [17108/17352 (99%)] Loss: -811.657072\n",
      "    epoch          : 481\n",
      "    loss           : -856.6353510762914\n",
      "    val_loss       : -586.8463301376543\n",
      "Train Epoch: 482 [512/17352 (3%)] Loss: -903.357300\n",
      "Train Epoch: 482 [10839/17352 (62%)] Loss: -730.497648\n",
      "Train Epoch: 482 [17277/17352 (100%)] Loss: -939.800079\n",
      "    epoch          : 482\n",
      "    loss           : -860.4167577016262\n",
      "    val_loss       : -534.697611144829\n",
      "Train Epoch: 483 [512/17352 (3%)] Loss: -876.094604\n",
      "Train Epoch: 483 [10031/17352 (58%)] Loss: -912.661773\n",
      "Train Epoch: 483 [17016/17352 (98%)] Loss: -713.763226\n",
      "    epoch          : 483\n",
      "    loss           : -820.348938925151\n",
      "    val_loss       : -545.9666614993719\n",
      "Train Epoch: 484 [512/17352 (3%)] Loss: -859.009155\n",
      "Train Epoch: 484 [10368/17352 (60%)] Loss: -557.655203\n",
      "Train Epoch: 484 [16887/17352 (97%)] Loss: -795.029755\n",
      "    epoch          : 484\n",
      "    loss           : -827.8383228633014\n",
      "    val_loss       : -554.5632956848134\n",
      "Train Epoch: 485 [512/17352 (3%)] Loss: -885.982300\n",
      "Train Epoch: 485 [10894/17352 (63%)] Loss: -746.302805\n",
      "Train Epoch: 485 [16958/17352 (98%)] Loss: -847.171395\n",
      "    epoch          : 485\n",
      "    loss           : -847.4541616641699\n",
      "    val_loss       : -579.2798995014035\n",
      "Train Epoch: 486 [512/17352 (3%)] Loss: -907.425415\n",
      "Train Epoch: 486 [10503/17352 (61%)] Loss: -913.551906\n",
      "Train Epoch: 486 [17106/17352 (99%)] Loss: -712.143648\n",
      "    epoch          : 486\n",
      "    loss           : -786.100162706456\n",
      "    val_loss       : -435.9757403858881\n",
      "Train Epoch: 487 [512/17352 (3%)] Loss: -747.416748\n",
      "Train Epoch: 487 [11047/17352 (64%)] Loss: -897.395543\n",
      "Train Epoch: 487 [17108/17352 (99%)] Loss: -946.490451\n",
      "    epoch          : 487\n",
      "    loss           : -782.898850725601\n",
      "    val_loss       : -549.478400194038\n",
      "Train Epoch: 488 [512/17352 (3%)] Loss: -877.925720\n",
      "Train Epoch: 488 [10357/17352 (60%)] Loss: -905.653779\n",
      "Train Epoch: 488 [16878/17352 (97%)] Loss: -703.868490\n",
      "    epoch          : 488\n",
      "    loss           : -810.3698542130252\n",
      "    val_loss       : -516.8747299948582\n",
      "Train Epoch: 489 [512/17352 (3%)] Loss: -658.306335\n",
      "Train Epoch: 489 [9998/17352 (58%)] Loss: -726.668959\n",
      "Train Epoch: 489 [16934/17352 (98%)] Loss: -774.463981\n",
      "    epoch          : 489\n",
      "    loss           : -803.6717407356016\n",
      "    val_loss       : -541.827203196845\n",
      "Train Epoch: 490 [512/17352 (3%)] Loss: -860.661865\n",
      "Train Epoch: 490 [10088/17352 (58%)] Loss: -723.282998\n",
      "Train Epoch: 490 [17263/17352 (99%)] Loss: -828.582545\n",
      "    epoch          : 490\n",
      "    loss           : -805.0680914998956\n",
      "    val_loss       : -513.8494219598605\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch490.pth ...\n",
      "Train Epoch: 491 [512/17352 (3%)] Loss: -848.065674\n",
      "Train Epoch: 491 [10586/17352 (61%)] Loss: -663.805248\n",
      "Train Epoch: 491 [17263/17352 (99%)] Loss: -753.143532\n",
      "    epoch          : 491\n",
      "    loss           : -735.817207903414\n",
      "    val_loss       : 1211.7694533476345\n",
      "Train Epoch: 492 [512/17352 (3%)] Loss: 730.562439\n",
      "Train Epoch: 492 [10745/17352 (62%)] Loss: -472.400024\n",
      "Train Epoch: 492 [16878/17352 (97%)] Loss: -506.771814\n",
      "    epoch          : 492\n",
      "    loss           : -324.914862896252\n",
      "    val_loss       : -402.61887674291773\n",
      "Train Epoch: 493 [512/17352 (3%)] Loss: -730.171997\n",
      "Train Epoch: 493 [10435/17352 (60%)] Loss: -652.103484\n",
      "Train Epoch: 493 [16934/17352 (98%)] Loss: -916.668908\n",
      "    epoch          : 493\n",
      "    loss           : -745.800686625548\n",
      "    val_loss       : -524.5467515529959\n",
      "Train Epoch: 494 [512/17352 (3%)] Loss: -867.187866\n",
      "Train Epoch: 494 [10335/17352 (60%)] Loss: -775.065442\n",
      "Train Epoch: 494 [17143/17352 (99%)] Loss: -904.363333\n",
      "    epoch          : 494\n",
      "    loss           : -832.7797760987698\n",
      "    val_loss       : -534.0586188086169\n",
      "Train Epoch: 495 [512/17352 (3%)] Loss: -831.678650\n",
      "Train Epoch: 495 [10272/17352 (59%)] Loss: -729.500980\n",
      "Train Epoch: 495 [16922/17352 (98%)] Loss: -923.375000\n",
      "    epoch          : 495\n",
      "    loss           : -820.9950264066807\n",
      "    val_loss       : -523.673407054746\n",
      "Train Epoch: 496 [512/17352 (3%)] Loss: -673.453796\n",
      "Train Epoch: 496 [10478/17352 (60%)] Loss: -851.876743\n",
      "Train Epoch: 496 [17108/17352 (99%)] Loss: -889.401919\n",
      "    epoch          : 496\n",
      "    loss           : -780.5299723580227\n",
      "    val_loss       : -525.1672533114319\n",
      "Train Epoch: 497 [512/17352 (3%)] Loss: -842.432861\n",
      "Train Epoch: 497 [10842/17352 (62%)] Loss: -834.571464\n",
      "Train Epoch: 497 [17277/17352 (100%)] Loss: -896.010207\n",
      "    epoch          : 497\n",
      "    loss           : -828.064224089921\n",
      "    val_loss       : -571.9070195278174\n",
      "Train Epoch: 498 [512/17352 (3%)] Loss: -894.273926\n",
      "Train Epoch: 498 [10567/17352 (61%)] Loss: -809.912431\n",
      "Train Epoch: 498 [16883/17352 (97%)] Loss: -768.272925\n",
      "    epoch          : 498\n",
      "    loss           : -814.7689684120511\n",
      "    val_loss       : -539.1300651202326\n",
      "Train Epoch: 499 [512/17352 (3%)] Loss: -833.551758\n",
      "Train Epoch: 499 [10343/17352 (60%)] Loss: -704.472902\n",
      "Train Epoch: 499 [17101/17352 (99%)] Loss: -737.002951\n",
      "    epoch          : 499\n",
      "    loss           : -829.9682056996595\n",
      "    val_loss       : -576.5390405527664\n",
      "Train Epoch: 500 [512/17352 (3%)] Loss: -893.363647\n",
      "Train Epoch: 500 [10234/17352 (59%)] Loss: -912.968750\n",
      "Train Epoch: 500 [16872/17352 (97%)] Loss: -785.132684\n",
      "    epoch          : 500\n",
      "    loss           : -858.2473502692279\n",
      "    val_loss       : -595.7961716340934\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch500.pth ...\n",
      "Train Epoch: 501 [512/17352 (3%)] Loss: -903.796204\n",
      "Train Epoch: 501 [10339/17352 (60%)] Loss: -714.052931\n",
      "Train Epoch: 501 [17126/17352 (99%)] Loss: -789.367828\n",
      "    epoch          : 501\n",
      "    loss           : -860.8923818193787\n",
      "    val_loss       : -598.1479784615426\n",
      "Train Epoch: 502 [512/17352 (3%)] Loss: -893.088867\n",
      "Train Epoch: 502 [10641/17352 (61%)] Loss: -912.183854\n",
      "Train Epoch: 502 [17044/17352 (98%)] Loss: -733.542322\n",
      "    epoch          : 502\n",
      "    loss           : -852.9906369913951\n",
      "    val_loss       : -539.8539532503964\n",
      "Train Epoch: 503 [512/17352 (3%)] Loss: -851.028076\n",
      "Train Epoch: 503 [10349/17352 (60%)] Loss: -963.848090\n",
      "Train Epoch: 503 [16882/17352 (97%)] Loss: -911.141297\n",
      "    epoch          : 503\n",
      "    loss           : -823.155543784448\n",
      "    val_loss       : -568.5177306115851\n",
      "Train Epoch: 504 [512/17352 (3%)] Loss: -897.224304\n",
      "Train Epoch: 504 [9674/17352 (56%)] Loss: -792.765561\n",
      "Train Epoch: 504 [17153/17352 (99%)] Loss: -881.549797\n",
      "    epoch          : 504\n",
      "    loss           : -839.1173628402474\n",
      "    val_loss       : -557.7161801319738\n",
      "Train Epoch: 505 [512/17352 (3%)] Loss: -877.190857\n",
      "Train Epoch: 505 [10716/17352 (62%)] Loss: -952.190981\n",
      "Train Epoch: 505 [16958/17352 (98%)] Loss: -945.354611\n",
      "    epoch          : 505\n",
      "    loss           : -860.1045512471912\n",
      "    val_loss       : -599.8422073146361\n",
      "Train Epoch: 506 [512/17352 (3%)] Loss: -909.435608\n",
      "Train Epoch: 506 [10330/17352 (60%)] Loss: -825.897221\n",
      "Train Epoch: 506 [17335/17352 (100%)] Loss: -993.423720\n",
      "    epoch          : 506\n",
      "    loss           : -871.1359007869785\n",
      "    val_loss       : -592.4589085940156\n",
      "Train Epoch: 507 [512/17352 (3%)] Loss: -918.235229\n",
      "Train Epoch: 507 [10421/17352 (60%)] Loss: -919.897659\n",
      "Train Epoch: 507 [17106/17352 (99%)] Loss: -931.702604\n",
      "    epoch          : 507\n",
      "    loss           : -872.8119028045714\n",
      "    val_loss       : -580.2671508214797\n",
      "Train Epoch: 508 [512/17352 (3%)] Loss: -907.897339\n",
      "Train Epoch: 508 [10535/17352 (61%)] Loss: -835.377418\n",
      "Train Epoch: 508 [17101/17352 (99%)] Loss: -954.828476\n",
      "    epoch          : 508\n",
      "    loss           : -881.1622362655993\n",
      "    val_loss       : -598.6691394892557\n",
      "Train Epoch: 509 [512/17352 (3%)] Loss: -927.835938\n",
      "Train Epoch: 509 [10046/17352 (58%)] Loss: -890.857163\n",
      "Train Epoch: 509 [16958/17352 (98%)] Loss: -908.347396\n",
      "    epoch          : 509\n",
      "    loss           : -869.7142971854261\n",
      "    val_loss       : -589.352768602145\n",
      "Train Epoch: 510 [512/17352 (3%)] Loss: -889.987183\n",
      "Train Epoch: 510 [10568/17352 (61%)] Loss: -906.680664\n",
      "Train Epoch: 510 [17253/17352 (99%)] Loss: -940.721123\n",
      "    epoch          : 510\n",
      "    loss           : -872.2720141185528\n",
      "    val_loss       : -580.1419789233216\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch510.pth ...\n",
      "Train Epoch: 511 [512/17352 (3%)] Loss: -868.407349\n",
      "Train Epoch: 511 [9687/17352 (56%)] Loss: -927.141525\n",
      "Train Epoch: 511 [16882/17352 (97%)] Loss: -932.275597\n",
      "    epoch          : 511\n",
      "    loss           : -856.022340636297\n",
      "    val_loss       : -575.9564722842279\n",
      "Train Epoch: 512 [512/17352 (3%)] Loss: -904.607117\n",
      "Train Epoch: 512 [10121/17352 (58%)] Loss: -694.507986\n",
      "Train Epoch: 512 [16922/17352 (98%)] Loss: -901.903441\n",
      "    epoch          : 512\n",
      "    loss           : -840.5564213839424\n",
      "    val_loss       : -568.8482290147149\n",
      "Train Epoch: 513 [512/17352 (3%)] Loss: -907.103149\n",
      "Train Epoch: 513 [10101/17352 (58%)] Loss: -695.799436\n",
      "Train Epoch: 513 [17124/17352 (99%)] Loss: -799.676743\n",
      "    epoch          : 513\n",
      "    loss           : -807.260818729307\n",
      "    val_loss       : -388.4866860927467\n",
      "Train Epoch: 514 [512/17352 (3%)] Loss: -774.071655\n",
      "Train Epoch: 514 [10654/17352 (61%)] Loss: -827.424937\n",
      "Train Epoch: 514 [17124/17352 (99%)] Loss: -797.257850\n",
      "    epoch          : 514\n",
      "    loss           : -775.2861851820126\n",
      "    val_loss       : -510.4179229151011\n",
      "Train Epoch: 515 [512/17352 (3%)] Loss: -794.276367\n",
      "Train Epoch: 515 [10483/17352 (60%)] Loss: -866.261149\n",
      "Train Epoch: 515 [17335/17352 (100%)] Loss: -862.475224\n",
      "    epoch          : 515\n",
      "    loss           : -833.4741820852153\n",
      "    val_loss       : -546.8404543583496\n",
      "Train Epoch: 516 [512/17352 (3%)] Loss: -886.594055\n",
      "Train Epoch: 516 [10247/17352 (59%)] Loss: -963.444215\n",
      "Train Epoch: 516 [17049/17352 (98%)] Loss: -932.836919\n",
      "    epoch          : 516\n",
      "    loss           : -863.7722552941552\n",
      "    val_loss       : -578.1232749528376\n",
      "Train Epoch: 517 [512/17352 (3%)] Loss: -899.407043\n",
      "Train Epoch: 517 [9955/17352 (57%)] Loss: -907.604809\n",
      "Train Epoch: 517 [17126/17352 (99%)] Loss: -803.755937\n",
      "    epoch          : 517\n",
      "    loss           : -839.8907627190398\n",
      "    val_loss       : -512.4022572956153\n",
      "Train Epoch: 518 [512/17352 (3%)] Loss: -839.704285\n",
      "Train Epoch: 518 [10557/17352 (61%)] Loss: -824.305365\n",
      "Train Epoch: 518 [16878/17352 (97%)] Loss: -811.754115\n",
      "    epoch          : 518\n",
      "    loss           : -783.2978723736422\n",
      "    val_loss       : -505.27267881867493\n",
      "Train Epoch: 519 [512/17352 (3%)] Loss: -523.636963\n",
      "Train Epoch: 519 [10139/17352 (58%)] Loss: -793.987424\n",
      "Train Epoch: 519 [16988/17352 (98%)] Loss: -897.556582\n",
      "    epoch          : 519\n",
      "    loss           : -718.7373378645534\n",
      "    val_loss       : -503.0203390823012\n",
      "Train Epoch: 520 [512/17352 (3%)] Loss: -870.836914\n",
      "Train Epoch: 520 [10140/17352 (58%)] Loss: -867.742776\n",
      "Train Epoch: 520 [17124/17352 (99%)] Loss: -807.533310\n",
      "    epoch          : 520\n",
      "    loss           : -809.7250483140289\n",
      "    val_loss       : -447.06954129537206\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch520.pth ...\n",
      "Train Epoch: 521 [512/17352 (3%)] Loss: -780.255859\n",
      "Train Epoch: 521 [10694/17352 (62%)] Loss: -628.699836\n",
      "Train Epoch: 521 [17253/17352 (99%)] Loss: -676.077823\n",
      "    epoch          : 521\n",
      "    loss           : -806.2288709152623\n",
      "    val_loss       : -410.6981898198585\n",
      "Train Epoch: 522 [512/17352 (3%)] Loss: -720.230225\n",
      "Train Epoch: 522 [10325/17352 (60%)] Loss: -792.895044\n",
      "Train Epoch: 522 [17108/17352 (99%)] Loss: 106.786659\n",
      "    epoch          : 522\n",
      "    loss           : -633.0466149177599\n",
      "    val_loss       : -310.56007059523085\n",
      "Train Epoch: 523 [512/17352 (3%)] Loss: -706.650146\n",
      "Train Epoch: 523 [9943/17352 (57%)] Loss: -767.179635\n",
      "Train Epoch: 523 [17108/17352 (99%)] Loss: -770.155517\n",
      "    epoch          : 523\n",
      "    loss           : -615.1956033354172\n",
      "    val_loss       : -430.5106139429962\n",
      "Train Epoch: 524 [512/17352 (3%)] Loss: -746.899719\n",
      "Train Epoch: 524 [10580/17352 (61%)] Loss: -704.750725\n",
      "Train Epoch: 524 [16923/17352 (98%)] Loss: -799.731957\n",
      "    epoch          : 524\n",
      "    loss           : -792.1341550522391\n",
      "    val_loss       : -550.7219922940469\n",
      "Train Epoch: 525 [512/17352 (3%)] Loss: -851.033875\n",
      "Train Epoch: 525 [9885/17352 (57%)] Loss: -950.696103\n",
      "Train Epoch: 525 [17133/17352 (99%)] Loss: -747.366987\n",
      "    epoch          : 525\n",
      "    loss           : -861.018995889747\n",
      "    val_loss       : -595.7201687550336\n",
      "Train Epoch: 526 [512/17352 (3%)] Loss: -902.808105\n",
      "Train Epoch: 526 [10045/17352 (58%)] Loss: -811.821172\n",
      "Train Epoch: 526 [16872/17352 (97%)] Loss: -764.118750\n",
      "    epoch          : 526\n",
      "    loss           : -884.1649322457367\n",
      "    val_loss       : -616.3366489794539\n",
      "Train Epoch: 527 [512/17352 (3%)] Loss: -932.400757\n",
      "Train Epoch: 527 [10464/17352 (60%)] Loss: -901.716698\n",
      "Train Epoch: 527 [16887/17352 (97%)] Loss: -829.580667\n",
      "    epoch          : 527\n",
      "    loss           : -893.0324737477782\n",
      "    val_loss       : -602.966402753925\n",
      "Train Epoch: 528 [512/17352 (3%)] Loss: -939.149963\n",
      "Train Epoch: 528 [10463/17352 (60%)] Loss: -847.441919\n",
      "Train Epoch: 528 [17143/17352 (99%)] Loss: -918.281962\n",
      "    epoch          : 528\n",
      "    loss           : -879.5703713423678\n",
      "    val_loss       : -436.62509850973777\n",
      "Train Epoch: 529 [512/17352 (3%)] Loss: -803.748596\n",
      "Train Epoch: 529 [10204/17352 (59%)] Loss: -896.534705\n",
      "Train Epoch: 529 [16887/17352 (97%)] Loss: -924.866489\n",
      "    epoch          : 529\n",
      "    loss           : -825.8854304461609\n",
      "    val_loss       : -557.9347577960791\n",
      "Train Epoch: 530 [512/17352 (3%)] Loss: -850.963013\n",
      "Train Epoch: 530 [11177/17352 (64%)] Loss: -906.667318\n",
      "Train Epoch: 530 [17106/17352 (99%)] Loss: -921.681399\n",
      "    epoch          : 530\n",
      "    loss           : -863.984492518058\n",
      "    val_loss       : -580.6260050801493\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch530.pth ...\n",
      "Train Epoch: 531 [512/17352 (3%)] Loss: -890.145813\n",
      "Train Epoch: 531 [10635/17352 (61%)] Loss: -819.227772\n",
      "Train Epoch: 531 [17101/17352 (99%)] Loss: -965.535315\n",
      "    epoch          : 531\n",
      "    loss           : -874.6334303219362\n",
      "    val_loss       : -577.3509597991788\n",
      "Train Epoch: 532 [512/17352 (3%)] Loss: -920.145630\n",
      "Train Epoch: 532 [10455/17352 (60%)] Loss: -748.081116\n",
      "Train Epoch: 532 [16992/17352 (98%)] Loss: -868.990866\n",
      "    epoch          : 532\n",
      "    loss           : -875.1732291251473\n",
      "    val_loss       : -570.8567483062016\n",
      "Train Epoch: 533 [512/17352 (3%)] Loss: -929.359863\n",
      "Train Epoch: 533 [10441/17352 (60%)] Loss: -790.299412\n",
      "Train Epoch: 533 [17090/17352 (98%)] Loss: -916.464844\n",
      "    epoch          : 533\n",
      "    loss           : -874.2471266616049\n",
      "    val_loss       : -551.7161013053573\n",
      "Train Epoch: 534 [512/17352 (3%)] Loss: -857.726562\n",
      "Train Epoch: 534 [10555/17352 (61%)] Loss: -688.885262\n",
      "Train Epoch: 534 [17133/17352 (99%)] Loss: -788.303678\n",
      "    epoch          : 534\n",
      "    loss           : -794.4427377620527\n",
      "    val_loss       : -458.82468847736584\n",
      "Train Epoch: 535 [512/17352 (3%)] Loss: -785.236328\n",
      "Train Epoch: 535 [10535/17352 (61%)] Loss: -750.220576\n",
      "Train Epoch: 535 [16922/17352 (98%)] Loss: -859.940184\n",
      "    epoch          : 535\n",
      "    loss           : -820.9824294477525\n",
      "    val_loss       : -545.3615581494112\n",
      "Train Epoch: 536 [512/17352 (3%)] Loss: -885.872681\n",
      "Train Epoch: 536 [9844/17352 (57%)] Loss: -902.353461\n",
      "Train Epoch: 536 [17064/17352 (98%)] Loss: -899.851079\n",
      "    epoch          : 536\n",
      "    loss           : -853.8663786076208\n",
      "    val_loss       : -555.1982690916275\n",
      "Train Epoch: 537 [512/17352 (3%)] Loss: -899.900635\n",
      "Train Epoch: 537 [10266/17352 (59%)] Loss: -918.409861\n",
      "Train Epoch: 537 [17090/17352 (98%)] Loss: -764.045228\n",
      "    epoch          : 537\n",
      "    loss           : -872.9436552736483\n",
      "    val_loss       : -591.6147173746828\n",
      "Train Epoch: 538 [512/17352 (3%)] Loss: -919.927612\n",
      "Train Epoch: 538 [10141/17352 (58%)] Loss: -911.630069\n",
      "Train Epoch: 538 [17124/17352 (99%)] Loss: -848.519271\n",
      "    epoch          : 538\n",
      "    loss           : -869.4265234177662\n",
      "    val_loss       : -565.0663267905987\n",
      "Train Epoch: 539 [512/17352 (3%)] Loss: -914.196777\n",
      "Train Epoch: 539 [10184/17352 (59%)] Loss: -919.374585\n",
      "Train Epoch: 539 [17101/17352 (99%)] Loss: -894.684580\n",
      "    epoch          : 539\n",
      "    loss           : -888.6977001760623\n",
      "    val_loss       : -567.8886307383913\n",
      "Train Epoch: 540 [512/17352 (3%)] Loss: -776.150940\n",
      "Train Epoch: 540 [10103/17352 (58%)] Loss: -771.591200\n",
      "Train Epoch: 540 [16957/17352 (98%)] Loss: -751.665150\n",
      "    epoch          : 540\n",
      "    loss           : -868.683655668031\n",
      "    val_loss       : -540.6962042888258\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch540.pth ...\n",
      "Train Epoch: 541 [512/17352 (3%)] Loss: -928.194458\n",
      "Train Epoch: 541 [10212/17352 (59%)] Loss: -995.458116\n",
      "Train Epoch: 541 [17143/17352 (99%)] Loss: -839.155208\n",
      "    epoch          : 541\n",
      "    loss           : -871.7076158952266\n",
      "    val_loss       : -563.1886066860666\n",
      "Train Epoch: 542 [512/17352 (3%)] Loss: -912.297607\n",
      "Train Epoch: 542 [9970/17352 (57%)] Loss: -1021.290473\n",
      "Train Epoch: 542 [16988/17352 (98%)] Loss: -945.391185\n",
      "    epoch          : 542\n",
      "    loss           : -897.9222421945814\n",
      "    val_loss       : -584.6824277847362\n",
      "Train Epoch: 543 [512/17352 (3%)] Loss: -947.627197\n",
      "Train Epoch: 543 [10280/17352 (59%)] Loss: -860.633557\n",
      "Train Epoch: 543 [17049/17352 (98%)] Loss: -826.232518\n",
      "    epoch          : 543\n",
      "    loss           : -898.0383799829642\n",
      "    val_loss       : -589.2945532666881\n",
      "Train Epoch: 544 [512/17352 (3%)] Loss: -774.172485\n",
      "Train Epoch: 544 [10720/17352 (62%)] Loss: -963.213445\n",
      "Train Epoch: 544 [16934/17352 (98%)] Loss: -888.535430\n",
      "    epoch          : 544\n",
      "    loss           : -900.959246732875\n",
      "    val_loss       : -591.5520792444047\n",
      "Train Epoch: 545 [512/17352 (3%)] Loss: -941.296143\n",
      "Train Epoch: 545 [10028/17352 (58%)] Loss: -952.507048\n",
      "Train Epoch: 545 [16923/17352 (98%)] Loss: -946.348983\n",
      "    epoch          : 545\n",
      "    loss           : -893.8140370518022\n",
      "    val_loss       : -582.2944998811148\n",
      "Train Epoch: 546 [512/17352 (3%)] Loss: -940.487549\n",
      "Train Epoch: 546 [10629/17352 (61%)] Loss: -991.106743\n",
      "Train Epoch: 546 [16957/17352 (98%)] Loss: -821.558463\n",
      "    epoch          : 546\n",
      "    loss           : -892.0159078100587\n",
      "    val_loss       : -586.4314687083919\n",
      "Train Epoch: 547 [512/17352 (3%)] Loss: -932.068481\n",
      "Train Epoch: 547 [10120/17352 (58%)] Loss: -961.749921\n",
      "Train Epoch: 547 [17049/17352 (98%)] Loss: -977.386350\n",
      "    epoch          : 547\n",
      "    loss           : -881.3460780298742\n",
      "    val_loss       : -570.868677302424\n",
      "Train Epoch: 548 [512/17352 (3%)] Loss: -934.729492\n",
      "Train Epoch: 548 [10585/17352 (61%)] Loss: -948.844146\n",
      "Train Epoch: 548 [17263/17352 (99%)] Loss: -943.300291\n",
      "    epoch          : 548\n",
      "    loss           : -886.8852212587027\n",
      "    val_loss       : -530.7650467279014\n",
      "Train Epoch: 549 [512/17352 (3%)] Loss: -903.633545\n",
      "Train Epoch: 549 [9862/17352 (57%)] Loss: -882.459261\n",
      "Train Epoch: 549 [16887/17352 (97%)] Loss: -952.961374\n",
      "    epoch          : 549\n",
      "    loss           : -889.0162713184444\n",
      "    val_loss       : -570.7396965315152\n",
      "Train Epoch: 550 [512/17352 (3%)] Loss: -945.387695\n",
      "Train Epoch: 550 [10295/17352 (59%)] Loss: -883.625000\n",
      "Train Epoch: 550 [16872/17352 (97%)] Loss: -739.095170\n",
      "    epoch          : 550\n",
      "    loss           : -885.9249935726633\n",
      "    val_loss       : -542.7388881947962\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch550.pth ...\n",
      "Train Epoch: 551 [512/17352 (3%)] Loss: -894.708191\n",
      "Train Epoch: 551 [10121/17352 (58%)] Loss: -813.451910\n",
      "Train Epoch: 551 [16934/17352 (98%)] Loss: -739.094739\n",
      "    epoch          : 551\n",
      "    loss           : -870.7919884789856\n",
      "    val_loss       : -553.1932067998874\n",
      "Train Epoch: 552 [512/17352 (3%)] Loss: -926.384460\n",
      "Train Epoch: 552 [10333/17352 (60%)] Loss: -808.078445\n",
      "Train Epoch: 552 [16878/17352 (97%)] Loss: -920.887292\n",
      "    epoch          : 552\n",
      "    loss           : -879.7643369999001\n",
      "    val_loss       : -563.0345918462233\n",
      "Train Epoch: 553 [512/17352 (3%)] Loss: -935.883789\n",
      "Train Epoch: 553 [9954/17352 (57%)] Loss: -922.720271\n",
      "Train Epoch: 553 [17108/17352 (99%)] Loss: -919.073307\n",
      "    epoch          : 553\n",
      "    loss           : -884.7367399559197\n",
      "    val_loss       : -547.198578324297\n",
      "Train Epoch: 554 [512/17352 (3%)] Loss: -930.080200\n",
      "Train Epoch: 554 [10393/17352 (60%)] Loss: -974.205666\n",
      "Train Epoch: 554 [17133/17352 (99%)] Loss: -939.059574\n",
      "    epoch          : 554\n",
      "    loss           : -890.0972522469166\n",
      "    val_loss       : -471.38951093345804\n",
      "Train Epoch: 555 [512/17352 (3%)] Loss: -850.514282\n",
      "Train Epoch: 555 [10522/17352 (61%)] Loss: -890.383988\n",
      "Train Epoch: 555 [17263/17352 (99%)] Loss: -911.654167\n",
      "    epoch          : 555\n",
      "    loss           : -856.8284601702335\n",
      "    val_loss       : -450.4114530198638\n",
      "Train Epoch: 556 [512/17352 (3%)] Loss: -822.665527\n",
      "Train Epoch: 556 [10648/17352 (61%)] Loss: -901.095573\n",
      "Train Epoch: 556 [16934/17352 (98%)] Loss: -905.168977\n",
      "    epoch          : 556\n",
      "    loss           : -858.4878758307783\n",
      "    val_loss       : -458.88522427299336\n",
      "Train Epoch: 557 [512/17352 (3%)] Loss: -827.040039\n",
      "Train Epoch: 557 [9877/17352 (57%)] Loss: -762.071072\n",
      "Train Epoch: 557 [17277/17352 (100%)] Loss: -842.068553\n",
      "    epoch          : 557\n",
      "    loss           : -746.0650350547767\n",
      "    val_loss       : 135.23732030305726\n",
      "Train Epoch: 558 [512/17352 (3%)] Loss: -364.291046\n",
      "Train Epoch: 558 [9746/17352 (56%)] Loss: 52.688939\n",
      "Train Epoch: 558 [16887/17352 (97%)] Loss: 142.511888\n",
      "    epoch          : 558\n",
      "    loss           : -452.84204046404705\n",
      "    val_loss       : -380.7424094003024\n",
      "Train Epoch: 559 [512/17352 (3%)] Loss: -510.531677\n",
      "Train Epoch: 559 [9899/17352 (57%)] Loss: -202.404684\n",
      "Train Epoch: 559 [17016/17352 (98%)] Loss: -854.698802\n",
      "    epoch          : 559\n",
      "    loss           : -507.66536768711535\n",
      "    val_loss       : -425.58946871512217\n",
      "Train Epoch: 560 [512/17352 (3%)] Loss: -795.733459\n",
      "Train Epoch: 560 [9994/17352 (58%)] Loss: -721.484695\n",
      "Train Epoch: 560 [17090/17352 (98%)] Loss: -968.309007\n",
      "    epoch          : 560\n",
      "    loss           : -817.092091673958\n",
      "    val_loss       : -536.031776331442\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch560.pth ...\n",
      "Train Epoch: 561 [512/17352 (3%)] Loss: -892.002014\n",
      "Train Epoch: 561 [10101/17352 (58%)] Loss: -823.975868\n",
      "Train Epoch: 561 [16958/17352 (98%)] Loss: -883.556405\n",
      "    epoch          : 561\n",
      "    loss           : -860.1245580865912\n",
      "    val_loss       : -570.9761274480395\n",
      "Train Epoch: 562 [512/17352 (3%)] Loss: -931.940125\n",
      "Train Epoch: 562 [10038/17352 (58%)] Loss: -938.654052\n",
      "Train Epoch: 562 [16934/17352 (98%)] Loss: -940.259524\n",
      "    epoch          : 562\n",
      "    loss           : -888.8065996644555\n",
      "    val_loss       : -585.7817532924022\n",
      "Train Epoch: 563 [512/17352 (3%)] Loss: -938.086060\n",
      "Train Epoch: 563 [9943/17352 (57%)] Loss: -870.684066\n",
      "Train Epoch: 563 [17143/17352 (99%)] Loss: -969.251580\n",
      "    epoch          : 563\n",
      "    loss           : -901.0838250377117\n",
      "    val_loss       : -581.5557785546315\n",
      "Train Epoch: 564 [512/17352 (3%)] Loss: -949.687866\n",
      "Train Epoch: 564 [10642/17352 (61%)] Loss: -797.694719\n",
      "Train Epoch: 564 [16872/17352 (97%)] Loss: -942.255729\n",
      "    epoch          : 564\n",
      "    loss           : -898.7254380509127\n",
      "    val_loss       : -553.176940012279\n",
      "Train Epoch: 565 [512/17352 (3%)] Loss: -953.160339\n",
      "Train Epoch: 565 [10154/17352 (59%)] Loss: -900.034223\n",
      "Train Epoch: 565 [17106/17352 (99%)] Loss: -786.149372\n",
      "    epoch          : 565\n",
      "    loss           : -890.1361417291827\n",
      "    val_loss       : -540.8396629722799\n",
      "Train Epoch: 566 [512/17352 (3%)] Loss: -901.795288\n",
      "Train Epoch: 566 [10245/17352 (59%)] Loss: -949.805539\n",
      "Train Epoch: 566 [17277/17352 (100%)] Loss: -850.619001\n",
      "    epoch          : 566\n",
      "    loss           : -887.5576043387312\n",
      "    val_loss       : -510.79197774037\n",
      "Train Epoch: 567 [512/17352 (3%)] Loss: -892.076721\n",
      "Train Epoch: 567 [10657/17352 (61%)] Loss: -974.032360\n",
      "Train Epoch: 567 [16878/17352 (97%)] Loss: -938.485371\n",
      "    epoch          : 567\n",
      "    loss           : -879.7267949185242\n",
      "    val_loss       : -565.2280412747799\n",
      "Train Epoch: 568 [512/17352 (3%)] Loss: -940.493164\n",
      "Train Epoch: 568 [10642/17352 (61%)] Loss: -1014.441898\n",
      "Train Epoch: 568 [16923/17352 (98%)] Loss: -900.041067\n",
      "    epoch          : 568\n",
      "    loss           : -895.2650530737565\n",
      "    val_loss       : -548.6313041477633\n",
      "Train Epoch: 569 [512/17352 (3%)] Loss: -923.116760\n",
      "Train Epoch: 569 [10374/17352 (60%)] Loss: -748.579246\n",
      "Train Epoch: 569 [16872/17352 (97%)] Loss: -847.683662\n",
      "    epoch          : 569\n",
      "    loss           : -819.661587725437\n",
      "    val_loss       : -512.3357731422976\n",
      "Train Epoch: 570 [512/17352 (3%)] Loss: -889.926697\n",
      "Train Epoch: 570 [10096/17352 (58%)] Loss: -739.475254\n",
      "Train Epoch: 570 [16992/17352 (98%)] Loss: -948.123813\n",
      "    epoch          : 570\n",
      "    loss           : -858.4369503086899\n",
      "    val_loss       : -553.4472217212273\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch570.pth ...\n",
      "Train Epoch: 571 [512/17352 (3%)] Loss: -920.499573\n",
      "Train Epoch: 571 [10244/17352 (59%)] Loss: -761.291866\n",
      "Train Epoch: 571 [16958/17352 (98%)] Loss: -742.407366\n",
      "    epoch          : 571\n",
      "    loss           : -853.6685730511206\n",
      "    val_loss       : -493.55447121407065\n",
      "Train Epoch: 572 [512/17352 (3%)] Loss: -890.872070\n",
      "Train Epoch: 572 [10399/17352 (60%)] Loss: -944.303100\n",
      "Train Epoch: 572 [17153/17352 (99%)] Loss: -679.332552\n",
      "    epoch          : 572\n",
      "    loss           : -722.1680664808467\n",
      "    val_loss       : 310.7731617293465\n",
      "Train Epoch: 573 [512/17352 (3%)] Loss: -122.779404\n",
      "Train Epoch: 573 [10457/17352 (60%)] Loss: -669.801820\n",
      "Train Epoch: 573 [17253/17352 (99%)] Loss: -662.253023\n",
      "    epoch          : 573\n",
      "    loss           : -528.6763934284344\n",
      "    val_loss       : -275.2481990283071\n",
      "Train Epoch: 574 [512/17352 (3%)] Loss: -586.826538\n",
      "Train Epoch: 574 [10308/17352 (59%)] Loss: -602.577340\n",
      "Train Epoch: 574 [16958/17352 (98%)] Loss: -905.318031\n",
      "    epoch          : 574\n",
      "    loss           : -783.7981942114825\n",
      "    val_loss       : -529.846975487185\n",
      "Train Epoch: 575 [512/17352 (3%)] Loss: -853.506348\n",
      "Train Epoch: 575 [10241/17352 (59%)] Loss: -967.593145\n",
      "Train Epoch: 575 [16922/17352 (98%)] Loss: -682.691801\n",
      "    epoch          : 575\n",
      "    loss           : -861.3484398311136\n",
      "    val_loss       : -520.6404386811441\n",
      "Train Epoch: 576 [512/17352 (3%)] Loss: -892.409607\n",
      "Train Epoch: 576 [10611/17352 (61%)] Loss: -761.417614\n",
      "Train Epoch: 576 [16922/17352 (98%)] Loss: -974.602690\n",
      "    epoch          : 576\n",
      "    loss           : -886.1903062540212\n",
      "    val_loss       : -573.5733087404838\n",
      "Train Epoch: 577 [512/17352 (3%)] Loss: -948.294373\n",
      "Train Epoch: 577 [10940/17352 (63%)] Loss: -1006.930160\n",
      "Train Epoch: 577 [17133/17352 (99%)] Loss: -860.008373\n",
      "    epoch          : 577\n",
      "    loss           : -908.794110430993\n",
      "    val_loss       : -563.7590840940991\n",
      "Train Epoch: 578 [512/17352 (3%)] Loss: -946.776184\n",
      "Train Epoch: 578 [10158/17352 (59%)] Loss: -921.577732\n",
      "Train Epoch: 578 [16939/17352 (98%)] Loss: -913.246979\n",
      "    epoch          : 578\n",
      "    loss           : -903.1657847501099\n",
      "    val_loss       : -574.1318489301258\n",
      "Train Epoch: 579 [512/17352 (3%)] Loss: -953.942810\n",
      "Train Epoch: 579 [9976/17352 (57%)] Loss: -953.689712\n",
      "Train Epoch: 579 [17101/17352 (99%)] Loss: -937.424154\n",
      "    epoch          : 579\n",
      "    loss           : -912.9737129733958\n",
      "    val_loss       : -549.9529796347827\n",
      "Train Epoch: 580 [512/17352 (3%)] Loss: -930.340088\n",
      "Train Epoch: 580 [10602/17352 (61%)] Loss: -812.758304\n",
      "Train Epoch: 580 [16872/17352 (97%)] Loss: -1027.631397\n",
      "    epoch          : 580\n",
      "    loss           : -913.0455094661571\n",
      "    val_loss       : -575.6784905869541\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch580.pth ...\n",
      "Train Epoch: 581 [512/17352 (3%)] Loss: -962.264893\n",
      "Train Epoch: 581 [10400/17352 (60%)] Loss: -912.026752\n",
      "Train Epoch: 581 [17153/17352 (99%)] Loss: -863.898536\n",
      "    epoch          : 581\n",
      "    loss           : -907.8780894116453\n",
      "    val_loss       : -560.6028150475216\n",
      "Train Epoch: 582 [512/17352 (3%)] Loss: -959.001587\n",
      "Train Epoch: 582 [10455/17352 (60%)] Loss: -899.547105\n",
      "Train Epoch: 582 [17016/17352 (98%)] Loss: -954.286222\n",
      "    epoch          : 582\n",
      "    loss           : -915.0881645926315\n",
      "    val_loss       : -589.4159751318923\n",
      "Train Epoch: 583 [512/17352 (3%)] Loss: -965.470642\n",
      "Train Epoch: 583 [9853/17352 (57%)] Loss: -951.731807\n",
      "Train Epoch: 583 [17044/17352 (98%)] Loss: -1017.271588\n",
      "    epoch          : 583\n",
      "    loss           : -916.9197256641295\n",
      "    val_loss       : -539.1165781676858\n",
      "Train Epoch: 584 [512/17352 (3%)] Loss: -945.034058\n",
      "Train Epoch: 584 [9594/17352 (55%)] Loss: -873.104535\n",
      "Train Epoch: 584 [17263/17352 (99%)] Loss: -900.123828\n",
      "    epoch          : 584\n",
      "    loss           : -902.1956713053563\n",
      "    val_loss       : -536.7796801720299\n",
      "Train Epoch: 585 [512/17352 (3%)] Loss: -934.021912\n",
      "Train Epoch: 585 [11028/17352 (64%)] Loss: -1024.388060\n",
      "Train Epoch: 585 [17090/17352 (98%)] Loss: -951.429177\n",
      "    epoch          : 585\n",
      "    loss           : -897.2779133769719\n",
      "    val_loss       : -559.6047999923887\n",
      "Train Epoch: 586 [512/17352 (3%)] Loss: -942.241211\n",
      "Train Epoch: 586 [10059/17352 (58%)] Loss: -800.137675\n",
      "Train Epoch: 586 [16922/17352 (98%)] Loss: -818.513194\n",
      "    epoch          : 586\n",
      "    loss           : -879.0352743865542\n",
      "    val_loss       : -540.2287895511105\n",
      "Train Epoch: 587 [512/17352 (3%)] Loss: -958.109863\n",
      "Train Epoch: 587 [9907/17352 (57%)] Loss: -743.615718\n",
      "Train Epoch: 587 [17253/17352 (99%)] Loss: -751.489351\n",
      "    epoch          : 587\n",
      "    loss           : -821.7810379556754\n",
      "    val_loss       : -431.922364775781\n",
      "Train Epoch: 588 [512/17352 (3%)] Loss: -747.573975\n",
      "Train Epoch: 588 [10927/17352 (63%)] Loss: -684.177373\n",
      "Train Epoch: 588 [17124/17352 (99%)] Loss: -785.098920\n",
      "    epoch          : 588\n",
      "    loss           : -743.2934575736475\n",
      "    val_loss       : -304.660726567342\n",
      "Train Epoch: 589 [512/17352 (3%)] Loss: -733.756042\n",
      "Train Epoch: 589 [10997/17352 (63%)] Loss: -944.601529\n",
      "Train Epoch: 589 [17335/17352 (100%)] Loss: -832.200628\n",
      "    epoch          : 589\n",
      "    loss           : -807.2719945125217\n",
      "    val_loss       : -498.53936079243607\n",
      "Train Epoch: 590 [512/17352 (3%)] Loss: -871.019897\n",
      "Train Epoch: 590 [10574/17352 (61%)] Loss: -832.583460\n",
      "Train Epoch: 590 [17044/17352 (98%)] Loss: -873.518765\n",
      "    epoch          : 590\n",
      "    loss           : -817.4349853730688\n",
      "    val_loss       : -401.37990047792584\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch590.pth ...\n",
      "Train Epoch: 591 [512/17352 (3%)] Loss: -791.892090\n",
      "Train Epoch: 591 [10307/17352 (59%)] Loss: -813.866635\n",
      "Train Epoch: 591 [17133/17352 (99%)] Loss: -862.947500\n",
      "    epoch          : 591\n",
      "    loss           : -793.2617151917176\n",
      "    val_loss       : -444.76764586063643\n",
      "Train Epoch: 592 [512/17352 (3%)] Loss: -846.112549\n",
      "Train Epoch: 592 [10466/17352 (60%)] Loss: -884.359946\n",
      "Train Epoch: 592 [17153/17352 (99%)] Loss: -721.537515\n",
      "    epoch          : 592\n",
      "    loss           : -841.5864766486868\n",
      "    val_loss       : -499.7831574335577\n",
      "Train Epoch: 593 [512/17352 (3%)] Loss: -904.163635\n",
      "Train Epoch: 593 [10169/17352 (59%)] Loss: -947.242433\n",
      "Train Epoch: 593 [17064/17352 (98%)] Loss: -938.267405\n",
      "    epoch          : 593\n",
      "    loss           : -855.0841428925047\n",
      "    val_loss       : -515.1605424176039\n",
      "Train Epoch: 594 [512/17352 (3%)] Loss: -704.854980\n",
      "Train Epoch: 594 [9690/17352 (56%)] Loss: -831.458184\n",
      "Train Epoch: 594 [16992/17352 (98%)] Loss: -988.610803\n",
      "    epoch          : 594\n",
      "    loss           : -890.3842359104568\n",
      "    val_loss       : -560.8364590584214\n",
      "Train Epoch: 595 [512/17352 (3%)] Loss: -953.579285\n",
      "Train Epoch: 595 [10565/17352 (61%)] Loss: -862.159395\n",
      "Train Epoch: 595 [16988/17352 (98%)] Loss: -945.663509\n",
      "    epoch          : 595\n",
      "    loss           : -920.5120475521686\n",
      "    val_loss       : -575.5126879126346\n",
      "Train Epoch: 596 [512/17352 (3%)] Loss: -950.214661\n",
      "Train Epoch: 596 [10665/17352 (61%)] Loss: -855.942675\n",
      "Train Epoch: 596 [16923/17352 (98%)] Loss: -793.758224\n",
      "    epoch          : 596\n",
      "    loss           : -926.1685475800515\n",
      "    val_loss       : -585.4044694755609\n",
      "Train Epoch: 597 [512/17352 (3%)] Loss: -970.295837\n",
      "Train Epoch: 597 [10120/17352 (58%)] Loss: -999.332338\n",
      "Train Epoch: 597 [17253/17352 (99%)] Loss: -873.842938\n",
      "    epoch          : 597\n",
      "    loss           : -933.9709285704687\n",
      "    val_loss       : -583.5798617527624\n",
      "Train Epoch: 598 [512/17352 (3%)] Loss: -972.535156\n",
      "Train Epoch: 598 [10116/17352 (58%)] Loss: -1011.824759\n",
      "Train Epoch: 598 [16923/17352 (98%)] Loss: -898.881990\n",
      "    epoch          : 598\n",
      "    loss           : -928.881223583361\n",
      "    val_loss       : -551.69717251048\n",
      "Train Epoch: 599 [512/17352 (3%)] Loss: -965.379211\n",
      "Train Epoch: 599 [10497/17352 (60%)] Loss: -815.101909\n",
      "Train Epoch: 599 [17049/17352 (98%)] Loss: -974.961773\n",
      "    epoch          : 599\n",
      "    loss           : -923.929228946067\n",
      "    val_loss       : -562.8974658234029\n",
      "Train Epoch: 600 [512/17352 (3%)] Loss: -949.559326\n",
      "Train Epoch: 600 [10154/17352 (59%)] Loss: -870.432639\n",
      "Train Epoch: 600 [16872/17352 (97%)] Loss: -996.896835\n",
      "    epoch          : 600\n",
      "    loss           : -923.8019839930978\n",
      "    val_loss       : -565.7628588579565\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch600.pth ...\n",
      "Train Epoch: 601 [512/17352 (3%)] Loss: -962.488586\n",
      "Train Epoch: 601 [10417/17352 (60%)] Loss: -911.538808\n",
      "Train Epoch: 601 [17106/17352 (99%)] Loss: -944.401861\n",
      "    epoch          : 601\n",
      "    loss           : -872.0238492736421\n",
      "    val_loss       : -446.465831914067\n",
      "Train Epoch: 602 [512/17352 (3%)] Loss: -820.638550\n",
      "Train Epoch: 602 [10337/17352 (60%)] Loss: -937.650727\n",
      "Train Epoch: 602 [17106/17352 (99%)] Loss: -884.992531\n",
      "    epoch          : 602\n",
      "    loss           : -863.0526730962064\n",
      "    val_loss       : -530.079485784965\n",
      "Train Epoch: 603 [512/17352 (3%)] Loss: -927.921875\n",
      "Train Epoch: 603 [10224/17352 (59%)] Loss: -698.688957\n",
      "Train Epoch: 603 [16988/17352 (98%)] Loss: -963.011562\n",
      "    epoch          : 603\n",
      "    loss           : -882.7777857713793\n",
      "    val_loss       : -529.5245012160249\n",
      "Train Epoch: 604 [512/17352 (3%)] Loss: -919.798096\n",
      "Train Epoch: 604 [10419/17352 (60%)] Loss: -964.865413\n",
      "Train Epoch: 604 [17124/17352 (99%)] Loss: -869.140972\n",
      "    epoch          : 604\n",
      "    loss           : -915.7000793250511\n",
      "    val_loss       : -580.169251140838\n",
      "Train Epoch: 605 [512/17352 (3%)] Loss: -965.184204\n",
      "Train Epoch: 605 [11392/17352 (66%)] Loss: -884.493671\n",
      "Train Epoch: 605 [17049/17352 (98%)] Loss: -860.607506\n",
      "    epoch          : 605\n",
      "    loss           : -933.146081795069\n",
      "    val_loss       : -564.58827641236\n",
      "Train Epoch: 606 [512/17352 (3%)] Loss: -954.877319\n",
      "Train Epoch: 606 [10697/17352 (62%)] Loss: -760.593750\n",
      "Train Epoch: 606 [17253/17352 (99%)] Loss: -813.914767\n",
      "    epoch          : 606\n",
      "    loss           : -881.7252156140557\n",
      "    val_loss       : -469.82475856461707\n",
      "Train Epoch: 607 [512/17352 (3%)] Loss: -901.460327\n",
      "Train Epoch: 607 [10673/17352 (62%)] Loss: -779.053322\n",
      "Train Epoch: 607 [17101/17352 (99%)] Loss: -988.391006\n",
      "    epoch          : 607\n",
      "    loss           : -893.8427064496528\n",
      "    val_loss       : -532.5198898522747\n",
      "Train Epoch: 608 [512/17352 (3%)] Loss: -952.066650\n",
      "Train Epoch: 608 [10138/17352 (58%)] Loss: -735.210887\n",
      "Train Epoch: 608 [16872/17352 (97%)] Loss: -981.709065\n",
      "    epoch          : 608\n",
      "    loss           : -884.2332956236697\n",
      "    val_loss       : -508.26051062764907\n",
      "Train Epoch: 609 [512/17352 (3%)] Loss: -933.515686\n",
      "Train Epoch: 609 [10389/17352 (60%)] Loss: -865.779576\n",
      "Train Epoch: 609 [16872/17352 (97%)] Loss: -941.670733\n",
      "    epoch          : 609\n",
      "    loss           : -893.9675650657923\n",
      "    val_loss       : -543.2309364596852\n",
      "Train Epoch: 610 [512/17352 (3%)] Loss: -959.104248\n",
      "Train Epoch: 610 [10707/17352 (62%)] Loss: -949.987535\n",
      "Train Epoch: 610 [17153/17352 (99%)] Loss: -959.760583\n",
      "    epoch          : 610\n",
      "    loss           : -915.5726211451059\n",
      "    val_loss       : -553.3437755880557\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch610.pth ...\n",
      "Train Epoch: 611 [512/17352 (3%)] Loss: -972.942078\n",
      "Train Epoch: 611 [10240/17352 (59%)] Loss: -901.665299\n",
      "Train Epoch: 611 [17016/17352 (98%)] Loss: -979.034167\n",
      "    epoch          : 611\n",
      "    loss           : -911.3182646690763\n",
      "    val_loss       : -524.4575603864225\n",
      "Train Epoch: 612 [512/17352 (3%)] Loss: -955.712402\n",
      "Train Epoch: 612 [10302/17352 (59%)] Loss: -791.255536\n",
      "Train Epoch: 612 [16934/17352 (98%)] Loss: -874.550391\n",
      "    epoch          : 612\n",
      "    loss           : -878.9179192076995\n",
      "    val_loss       : -473.42192361877113\n",
      "Train Epoch: 613 [512/17352 (3%)] Loss: -894.005127\n",
      "Train Epoch: 613 [10369/17352 (60%)] Loss: -976.542178\n",
      "Train Epoch: 613 [17064/17352 (98%)] Loss: -979.148022\n",
      "    epoch          : 613\n",
      "    loss           : -898.3198028055913\n",
      "    val_loss       : -551.6752744815362\n",
      "Train Epoch: 614 [512/17352 (3%)] Loss: -945.612366\n",
      "Train Epoch: 614 [10114/17352 (58%)] Loss: -980.506671\n",
      "Train Epoch: 614 [17064/17352 (98%)] Loss: -997.723196\n",
      "    epoch          : 614\n",
      "    loss           : -918.767150615101\n",
      "    val_loss       : -539.8437796315528\n",
      "Train Epoch: 615 [512/17352 (3%)] Loss: -949.209229\n",
      "Train Epoch: 615 [10330/17352 (60%)] Loss: -788.056317\n",
      "Train Epoch: 615 [17133/17352 (99%)] Loss: -973.474674\n",
      "    epoch          : 615\n",
      "    loss           : -923.9800574904248\n",
      "    val_loss       : -565.9223195304899\n",
      "Train Epoch: 616 [512/17352 (3%)] Loss: -972.007812\n",
      "Train Epoch: 616 [10146/17352 (58%)] Loss: -986.327394\n",
      "Train Epoch: 616 [17106/17352 (99%)] Loss: -982.155475\n",
      "    epoch          : 616\n",
      "    loss           : -925.1377963689354\n",
      "    val_loss       : -547.9022666710055\n",
      "Train Epoch: 617 [512/17352 (3%)] Loss: -970.628235\n",
      "Train Epoch: 617 [10453/17352 (60%)] Loss: -1012.055519\n",
      "Train Epoch: 617 [17277/17352 (100%)] Loss: -974.460677\n",
      "    epoch          : 617\n",
      "    loss           : -937.3537553831237\n",
      "    val_loss       : -530.6167707063012\n",
      "Train Epoch: 618 [512/17352 (3%)] Loss: -948.195557\n",
      "Train Epoch: 618 [10541/17352 (61%)] Loss: -971.435757\n",
      "Train Epoch: 618 [16988/17352 (98%)] Loss: -786.311379\n",
      "    epoch          : 618\n",
      "    loss           : -920.8029530589197\n",
      "    val_loss       : -474.11342966118696\n",
      "Train Epoch: 619 [512/17352 (3%)] Loss: -896.402832\n",
      "Train Epoch: 619 [10884/17352 (63%)] Loss: -776.909140\n",
      "Train Epoch: 619 [16922/17352 (98%)] Loss: -755.542315\n",
      "    epoch          : 619\n",
      "    loss           : -909.8599658575432\n",
      "    val_loss       : -465.56893426233955\n",
      "Train Epoch: 620 [512/17352 (3%)] Loss: -903.975952\n",
      "Train Epoch: 620 [10451/17352 (60%)] Loss: -821.827228\n",
      "Train Epoch: 620 [17044/17352 (98%)] Loss: -931.147321\n",
      "    epoch          : 620\n",
      "    loss           : -897.4897502615071\n",
      "    val_loss       : -528.5669351244655\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch620.pth ...\n",
      "Train Epoch: 621 [512/17352 (3%)] Loss: -948.171082\n",
      "Train Epoch: 621 [10453/17352 (60%)] Loss: -1002.146151\n",
      "Train Epoch: 621 [16883/17352 (97%)] Loss: -883.479320\n",
      "    epoch          : 621\n",
      "    loss           : -920.1507672077554\n",
      "    val_loss       : -529.1976296690019\n",
      "Train Epoch: 622 [512/17352 (3%)] Loss: -953.732239\n",
      "Train Epoch: 622 [10844/17352 (62%)] Loss: -1010.674934\n",
      "Train Epoch: 622 [17016/17352 (98%)] Loss: -1009.231771\n",
      "    epoch          : 622\n",
      "    loss           : -923.456275145377\n",
      "    val_loss       : -547.4708640639259\n",
      "Train Epoch: 623 [512/17352 (3%)] Loss: -986.843750\n",
      "Train Epoch: 623 [10360/17352 (60%)] Loss: -933.973619\n",
      "Train Epoch: 623 [17108/17352 (99%)] Loss: -1007.089894\n",
      "    epoch          : 623\n",
      "    loss           : -932.0693862027624\n",
      "    val_loss       : -544.4107732641506\n",
      "Train Epoch: 624 [512/17352 (3%)] Loss: -965.882874\n",
      "Train Epoch: 624 [10569/17352 (61%)] Loss: -796.682416\n",
      "Train Epoch: 624 [17253/17352 (99%)] Loss: -833.642555\n",
      "    epoch          : 624\n",
      "    loss           : -931.5797017957718\n",
      "    val_loss       : -543.9843080924398\n",
      "Train Epoch: 625 [512/17352 (3%)] Loss: -951.175659\n",
      "Train Epoch: 625 [10173/17352 (59%)] Loss: -880.259840\n",
      "Train Epoch: 625 [16988/17352 (98%)] Loss: -770.905438\n",
      "    epoch          : 625\n",
      "    loss           : -849.9839395843867\n",
      "    val_loss       : -488.04987806838847\n",
      "Train Epoch: 626 [512/17352 (3%)] Loss: -929.325562\n",
      "Train Epoch: 626 [10615/17352 (61%)] Loss: -722.186492\n",
      "Train Epoch: 626 [17133/17352 (99%)] Loss: -1027.515059\n",
      "    epoch          : 626\n",
      "    loss           : -891.35601589782\n",
      "    val_loss       : -517.0869645897031\n",
      "Train Epoch: 627 [512/17352 (3%)] Loss: -761.722656\n",
      "Train Epoch: 627 [9877/17352 (57%)] Loss: -683.549092\n",
      "Train Epoch: 627 [17263/17352 (99%)] Loss: -882.161846\n",
      "    epoch          : 627\n",
      "    loss           : -855.936543798977\n",
      "    val_loss       : -243.58691189874077\n",
      "Train Epoch: 628 [512/17352 (3%)] Loss: -705.993164\n",
      "Train Epoch: 628 [10560/17352 (61%)] Loss: -829.171775\n",
      "Train Epoch: 628 [17064/17352 (98%)] Loss: -949.437197\n",
      "    epoch          : 628\n",
      "    loss           : -750.0877324619801\n",
      "    val_loss       : -463.387298612244\n",
      "Train Epoch: 629 [512/17352 (3%)] Loss: -850.392578\n",
      "Train Epoch: 629 [10150/17352 (58%)] Loss: -882.132418\n",
      "Train Epoch: 629 [16923/17352 (98%)] Loss: -1027.577908\n",
      "    epoch          : 629\n",
      "    loss           : -881.9840714980855\n",
      "    val_loss       : -549.3811276491423\n",
      "Train Epoch: 630 [512/17352 (3%)] Loss: -965.086975\n",
      "Train Epoch: 630 [10235/17352 (59%)] Loss: -870.416295\n",
      "Train Epoch: 630 [16958/17352 (98%)] Loss: -846.858441\n",
      "    epoch          : 630\n",
      "    loss           : -897.5179345219993\n",
      "    val_loss       : -485.2818720843987\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch630.pth ...\n",
      "Train Epoch: 631 [512/17352 (3%)] Loss: -898.309143\n",
      "Train Epoch: 631 [10355/17352 (60%)] Loss: -933.590138\n",
      "Train Epoch: 631 [16957/17352 (98%)] Loss: -843.947917\n",
      "    epoch          : 631\n",
      "    loss           : -919.8207782084977\n",
      "    val_loss       : -544.8876993864446\n",
      "Train Epoch: 632 [512/17352 (3%)] Loss: -966.803223\n",
      "Train Epoch: 632 [10509/17352 (61%)] Loss: -784.199738\n",
      "Train Epoch: 632 [17106/17352 (99%)] Loss: -768.885139\n",
      "    epoch          : 632\n",
      "    loss           : -813.1248278768669\n",
      "    val_loss       : -387.735017546024\n",
      "Train Epoch: 633 [512/17352 (3%)] Loss: -797.351562\n",
      "Train Epoch: 633 [10753/17352 (62%)] Loss: -627.547847\n",
      "Train Epoch: 633 [16988/17352 (98%)] Loss: -836.073655\n",
      "    epoch          : 633\n",
      "    loss           : -758.041358270623\n",
      "    val_loss       : -453.40816996477855\n",
      "Train Epoch: 634 [512/17352 (3%)] Loss: -839.736572\n",
      "Train Epoch: 634 [10230/17352 (59%)] Loss: -929.914853\n",
      "Train Epoch: 634 [17106/17352 (99%)] Loss: -792.700521\n",
      "    epoch          : 634\n",
      "    loss           : -822.1221905348519\n",
      "    val_loss       : -411.4445855390761\n",
      "Train Epoch: 635 [512/17352 (3%)] Loss: -807.122803\n",
      "Train Epoch: 635 [10427/17352 (60%)] Loss: -882.360541\n",
      "Train Epoch: 635 [16934/17352 (98%)] Loss: -705.039119\n",
      "    epoch          : 635\n",
      "    loss           : -746.442382077597\n",
      "    val_loss       : -269.45210995664036\n",
      "Train Epoch: 636 [512/17352 (3%)] Loss: -583.105347\n",
      "Train Epoch: 636 [10386/17352 (60%)] Loss: -825.897228\n",
      "Train Epoch: 636 [17277/17352 (100%)] Loss: -750.854516\n",
      "    epoch          : 636\n",
      "    loss           : -818.4694497356849\n",
      "    val_loss       : -517.1621931658315\n",
      "Train Epoch: 637 [512/17352 (3%)] Loss: -928.231445\n",
      "Train Epoch: 637 [10441/17352 (60%)] Loss: -1010.074335\n",
      "Train Epoch: 637 [17101/17352 (99%)] Loss: -996.192655\n",
      "    epoch          : 637\n",
      "    loss           : -927.5857128579172\n",
      "    val_loss       : -563.4347752490281\n",
      "Train Epoch: 638 [512/17352 (3%)] Loss: -975.147156\n",
      "Train Epoch: 638 [10435/17352 (60%)] Loss: -975.167321\n",
      "Train Epoch: 638 [16934/17352 (98%)] Loss: -884.982506\n",
      "    epoch          : 638\n",
      "    loss           : -938.3545641657\n",
      "    val_loss       : -562.4615517543625\n",
      "Train Epoch: 639 [512/17352 (3%)] Loss: -985.375305\n",
      "Train Epoch: 639 [10273/17352 (59%)] Loss: -865.868215\n",
      "Train Epoch: 639 [16958/17352 (98%)] Loss: -830.706639\n",
      "    epoch          : 639\n",
      "    loss           : -927.6037881157243\n",
      "    val_loss       : -555.3782370129716\n",
      "Train Epoch: 640 [512/17352 (3%)] Loss: -964.639893\n",
      "Train Epoch: 640 [10893/17352 (63%)] Loss: -877.530878\n",
      "Train Epoch: 640 [17101/17352 (99%)] Loss: -942.693938\n",
      "    epoch          : 640\n",
      "    loss           : -929.6092370738668\n",
      "    val_loss       : -556.9540710575963\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch640.pth ...\n",
      "Train Epoch: 641 [512/17352 (3%)] Loss: -979.129944\n",
      "Train Epoch: 641 [10372/17352 (60%)] Loss: -971.455087\n",
      "Train Epoch: 641 [17106/17352 (99%)] Loss: -1006.598747\n",
      "    epoch          : 641\n",
      "    loss           : -938.3095358882209\n",
      "    val_loss       : -557.9545945777419\n",
      "Train Epoch: 642 [512/17352 (3%)] Loss: -967.146667\n",
      "Train Epoch: 642 [9864/17352 (57%)] Loss: -972.670833\n",
      "Train Epoch: 642 [17090/17352 (98%)] Loss: -925.930784\n",
      "    epoch          : 642\n",
      "    loss           : -936.8866506250731\n",
      "    val_loss       : -544.5106181471008\n",
      "Train Epoch: 643 [512/17352 (3%)] Loss: -986.253052\n",
      "Train Epoch: 643 [10473/17352 (60%)] Loss: -798.567473\n",
      "Train Epoch: 643 [16992/17352 (98%)] Loss: -937.028503\n",
      "    epoch          : 643\n",
      "    loss           : -944.581310121337\n",
      "    val_loss       : -548.3451633339315\n",
      "Train Epoch: 644 [512/17352 (3%)] Loss: -989.565552\n",
      "Train Epoch: 644 [10441/17352 (60%)] Loss: -925.438048\n",
      "Train Epoch: 644 [17133/17352 (99%)] Loss: -827.900578\n",
      "    epoch          : 644\n",
      "    loss           : -941.9389032107201\n",
      "    val_loss       : -561.8539818275726\n",
      "Train Epoch: 645 [512/17352 (3%)] Loss: -968.875732\n",
      "Train Epoch: 645 [10496/17352 (60%)] Loss: -989.465312\n",
      "Train Epoch: 645 [16922/17352 (98%)] Loss: -973.107180\n",
      "    epoch          : 645\n",
      "    loss           : -936.5508545830068\n",
      "    val_loss       : -558.9941993669572\n",
      "Train Epoch: 646 [512/17352 (3%)] Loss: -991.463013\n",
      "Train Epoch: 646 [10666/17352 (61%)] Loss: -958.362417\n",
      "Train Epoch: 646 [17016/17352 (98%)] Loss: -941.035411\n",
      "    epoch          : 646\n",
      "    loss           : -916.142006977173\n",
      "    val_loss       : -453.2225837870248\n",
      "Train Epoch: 647 [512/17352 (3%)] Loss: -938.402832\n",
      "Train Epoch: 647 [10521/17352 (61%)] Loss: -797.904841\n",
      "Train Epoch: 647 [17153/17352 (99%)] Loss: -886.910742\n",
      "    epoch          : 647\n",
      "    loss           : -824.1497531234348\n",
      "    val_loss       : -391.30505286961767\n",
      "Train Epoch: 648 [512/17352 (3%)] Loss: -885.544800\n",
      "Train Epoch: 648 [9839/17352 (57%)] Loss: -771.045501\n",
      "Train Epoch: 648 [17064/17352 (98%)] Loss: -950.233464\n",
      "    epoch          : 648\n",
      "    loss           : -888.1345555971097\n",
      "    val_loss       : -533.7569514520579\n",
      "Train Epoch: 649 [512/17352 (3%)] Loss: -928.444946\n",
      "Train Epoch: 649 [10348/17352 (60%)] Loss: -881.866680\n",
      "Train Epoch: 649 [16934/17352 (98%)] Loss: -886.904966\n",
      "    epoch          : 649\n",
      "    loss           : -916.487618472759\n",
      "    val_loss       : -542.8616893166039\n",
      "Train Epoch: 650 [512/17352 (3%)] Loss: -793.434692\n",
      "Train Epoch: 650 [10481/17352 (60%)] Loss: -791.210602\n",
      "Train Epoch: 650 [16958/17352 (98%)] Loss: -913.352659\n",
      "    epoch          : 650\n",
      "    loss           : -928.1901290112078\n",
      "    val_loss       : -554.5650728237019\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch650.pth ...\n",
      "Train Epoch: 651 [512/17352 (3%)] Loss: -991.141357\n",
      "Train Epoch: 651 [10388/17352 (60%)] Loss: -985.720340\n",
      "Train Epoch: 651 [16882/17352 (97%)] Loss: -804.239113\n",
      "    epoch          : 651\n",
      "    loss           : -947.6647610311285\n",
      "    val_loss       : -545.9483646782467\n",
      "Train Epoch: 652 [512/17352 (3%)] Loss: -974.731812\n",
      "Train Epoch: 652 [10009/17352 (58%)] Loss: -863.890726\n",
      "Train Epoch: 652 [16922/17352 (98%)] Loss: -761.734121\n",
      "    epoch          : 652\n",
      "    loss           : -879.0691347681626\n",
      "    val_loss       : -217.19259173449717\n",
      "Train Epoch: 653 [512/17352 (3%)] Loss: -740.002319\n",
      "Train Epoch: 653 [10539/17352 (61%)] Loss: -688.594647\n",
      "Train Epoch: 653 [17016/17352 (98%)] Loss: 1094.408144\n",
      "    epoch          : 653\n",
      "    loss           : -569.368314976854\n",
      "    val_loss       : -371.1056487187822\n",
      "Train Epoch: 654 [512/17352 (3%)] Loss: -823.693970\n",
      "Train Epoch: 654 [9950/17352 (57%)] Loss: -374.938639\n",
      "Train Epoch: 654 [17044/17352 (98%)] Loss: -281.590323\n",
      "    epoch          : 654\n",
      "    loss           : -243.96307633621456\n",
      "    val_loss       : -214.1473800353636\n",
      "Train Epoch: 655 [512/17352 (3%)] Loss: -418.987427\n",
      "Train Epoch: 655 [10402/17352 (60%)] Loss: -865.254182\n",
      "Train Epoch: 655 [17263/17352 (99%)] Loss: -922.154522\n",
      "    epoch          : 655\n",
      "    loss           : -795.3997065736331\n",
      "    val_loss       : -475.50898003063924\n",
      "Train Epoch: 656 [512/17352 (3%)] Loss: -830.848755\n",
      "Train Epoch: 656 [10476/17352 (60%)] Loss: -900.695391\n",
      "Train Epoch: 656 [17263/17352 (99%)] Loss: -872.255990\n",
      "    epoch          : 656\n",
      "    loss           : -892.6400500949693\n",
      "    val_loss       : -562.0488050544906\n",
      "Train Epoch: 657 [512/17352 (3%)] Loss: -931.487305\n",
      "Train Epoch: 657 [10849/17352 (63%)] Loss: -1046.893723\n",
      "Train Epoch: 657 [16958/17352 (98%)] Loss: -832.364001\n",
      "    epoch          : 657\n",
      "    loss           : -932.0609831483353\n",
      "    val_loss       : -575.8935251774678\n",
      "Train Epoch: 658 [512/17352 (3%)] Loss: -985.056335\n",
      "Train Epoch: 658 [11017/17352 (63%)] Loss: -1050.380070\n",
      "Train Epoch: 658 [17277/17352 (100%)] Loss: -970.561325\n",
      "    epoch          : 658\n",
      "    loss           : -947.1208641310325\n",
      "    val_loss       : -562.7343931380487\n",
      "Train Epoch: 659 [512/17352 (3%)] Loss: -974.507080\n",
      "Train Epoch: 659 [10038/17352 (58%)] Loss: -860.028349\n",
      "Train Epoch: 659 [17049/17352 (98%)] Loss: -986.119896\n",
      "    epoch          : 659\n",
      "    loss           : -946.7793319799255\n",
      "    val_loss       : -533.9532658408085\n",
      "Train Epoch: 660 [512/17352 (3%)] Loss: -979.266235\n",
      "Train Epoch: 660 [10923/17352 (63%)] Loss: -976.884956\n",
      "Train Epoch: 660 [17064/17352 (98%)] Loss: -942.762277\n",
      "    epoch          : 660\n",
      "    loss           : -949.2334122558309\n",
      "    val_loss       : -558.2614468372918\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch660.pth ...\n",
      "Train Epoch: 661 [512/17352 (3%)] Loss: -821.482178\n",
      "Train Epoch: 661 [10450/17352 (60%)] Loss: -1014.572890\n",
      "Train Epoch: 661 [17143/17352 (99%)] Loss: -889.356542\n",
      "    epoch          : 661\n",
      "    loss           : -943.0087338886281\n",
      "    val_loss       : -558.6088064585064\n",
      "Train Epoch: 662 [512/17352 (3%)] Loss: -996.867310\n",
      "Train Epoch: 662 [10485/17352 (60%)] Loss: -926.432429\n",
      "Train Epoch: 662 [17143/17352 (99%)] Loss: -989.650066\n",
      "    epoch          : 662\n",
      "    loss           : -944.2390198291961\n",
      "    val_loss       : -562.8344427281734\n",
      "Train Epoch: 663 [512/17352 (3%)] Loss: -990.488281\n",
      "Train Epoch: 663 [10767/17352 (62%)] Loss: -910.792128\n",
      "Train Epoch: 663 [17253/17352 (99%)] Loss: -1009.762658\n",
      "    epoch          : 663\n",
      "    loss           : -954.2431017336903\n",
      "    val_loss       : -553.0870272650079\n",
      "Train Epoch: 664 [512/17352 (3%)] Loss: -982.315308\n",
      "Train Epoch: 664 [9693/17352 (56%)] Loss: -1023.294146\n",
      "Train Epoch: 664 [16923/17352 (98%)] Loss: -828.782596\n",
      "    epoch          : 664\n",
      "    loss           : -954.6296467065516\n",
      "    val_loss       : -564.6328815164605\n",
      "Train Epoch: 665 [512/17352 (3%)] Loss: -849.375854\n",
      "Train Epoch: 665 [10347/17352 (60%)] Loss: -933.912897\n",
      "Train Epoch: 665 [16922/17352 (98%)] Loss: -900.686632\n",
      "    epoch          : 665\n",
      "    loss           : -955.1455042719884\n",
      "    val_loss       : -557.1174670231203\n",
      "Train Epoch: 666 [512/17352 (3%)] Loss: -1000.388306\n",
      "Train Epoch: 666 [10482/17352 (60%)] Loss: -1035.351424\n",
      "Train Epoch: 666 [17263/17352 (99%)] Loss: -971.639795\n",
      "    epoch          : 666\n",
      "    loss           : -955.0427848662771\n",
      "    val_loss       : -545.365139326909\n",
      "Train Epoch: 667 [512/17352 (3%)] Loss: -991.808350\n",
      "Train Epoch: 667 [10477/17352 (60%)] Loss: -1034.972739\n",
      "Train Epoch: 667 [16887/17352 (97%)] Loss: -985.223958\n",
      "    epoch          : 667\n",
      "    loss           : -950.6375122814904\n",
      "    val_loss       : -535.9191266635653\n",
      "Train Epoch: 668 [512/17352 (3%)] Loss: -838.611755\n",
      "Train Epoch: 668 [10312/17352 (59%)] Loss: -865.362908\n",
      "Train Epoch: 668 [17277/17352 (100%)] Loss: -1000.790234\n",
      "    epoch          : 668\n",
      "    loss           : -959.8842420818236\n",
      "    val_loss       : -530.0600257687299\n",
      "Train Epoch: 669 [512/17352 (3%)] Loss: -993.126221\n",
      "Train Epoch: 669 [10373/17352 (60%)] Loss: -911.591319\n",
      "Train Epoch: 669 [17153/17352 (99%)] Loss: -1046.114861\n",
      "    epoch          : 669\n",
      "    loss           : -959.8877632613957\n",
      "    val_loss       : -503.262833027757\n",
      "Train Epoch: 670 [512/17352 (3%)] Loss: -987.403687\n",
      "Train Epoch: 670 [10243/17352 (59%)] Loss: -758.053678\n",
      "Train Epoch: 670 [17016/17352 (98%)] Loss: -873.631439\n",
      "    epoch          : 670\n",
      "    loss           : -912.2015872858493\n",
      "    val_loss       : -416.3246001251891\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch670.pth ...\n",
      "Train Epoch: 671 [512/17352 (3%)] Loss: -863.973083\n",
      "Train Epoch: 671 [10599/17352 (61%)] Loss: -1019.420351\n",
      "Train Epoch: 671 [16883/17352 (97%)] Loss: -773.181183\n",
      "    epoch          : 671\n",
      "    loss           : -922.7248847372692\n",
      "    val_loss       : -538.1725254813925\n",
      "Train Epoch: 672 [512/17352 (3%)] Loss: -985.525146\n",
      "Train Epoch: 672 [10272/17352 (59%)] Loss: -886.659238\n",
      "Train Epoch: 672 [17016/17352 (98%)] Loss: -954.860480\n",
      "    epoch          : 672\n",
      "    loss           : -931.0185466359862\n",
      "    val_loss       : -499.859363163994\n",
      "Train Epoch: 673 [512/17352 (3%)] Loss: -973.837280\n",
      "Train Epoch: 673 [10501/17352 (61%)] Loss: -978.515293\n",
      "Train Epoch: 673 [16922/17352 (98%)] Loss: -838.834462\n",
      "    epoch          : 673\n",
      "    loss           : -915.2256331916893\n",
      "    val_loss       : -488.328549325323\n",
      "Train Epoch: 674 [512/17352 (3%)] Loss: -963.472351\n",
      "Train Epoch: 674 [9963/17352 (57%)] Loss: -855.351824\n",
      "Train Epoch: 674 [17153/17352 (99%)] Loss: -819.005035\n",
      "    epoch          : 674\n",
      "    loss           : -904.2903892283055\n",
      "    val_loss       : -377.37426982828447\n",
      "Train Epoch: 675 [512/17352 (3%)] Loss: -855.092468\n",
      "Train Epoch: 675 [10467/17352 (60%)] Loss: -966.523537\n",
      "Train Epoch: 675 [16872/17352 (97%)] Loss: -919.127108\n",
      "    epoch          : 675\n",
      "    loss           : -869.3923241941246\n",
      "    val_loss       : -442.7231010848119\n",
      "Train Epoch: 676 [512/17352 (3%)] Loss: -909.896667\n",
      "Train Epoch: 676 [10538/17352 (61%)] Loss: -977.150000\n",
      "Train Epoch: 676 [17064/17352 (98%)] Loss: -630.518962\n",
      "    epoch          : 676\n",
      "    loss           : -780.101100288558\n",
      "    val_loss       : -312.20402617603645\n",
      "Train Epoch: 677 [512/17352 (3%)] Loss: -831.491211\n",
      "Train Epoch: 677 [10638/17352 (61%)] Loss: -940.619601\n",
      "Train Epoch: 677 [17253/17352 (99%)] Loss: -912.564856\n",
      "    epoch          : 677\n",
      "    loss           : -854.2898799954795\n",
      "    val_loss       : -467.44754669121016\n",
      "Train Epoch: 678 [512/17352 (3%)] Loss: -918.867798\n",
      "Train Epoch: 678 [10280/17352 (59%)] Loss: -981.624365\n",
      "Train Epoch: 678 [16992/17352 (98%)] Loss: -659.910181\n",
      "    epoch          : 678\n",
      "    loss           : -669.243371134058\n",
      "    val_loss       : 1022.0612155453246\n",
      "Train Epoch: 679 [512/17352 (3%)] Loss: 664.847412\n",
      "Train Epoch: 679 [10109/17352 (58%)] Loss: -560.346423\n",
      "Train Epoch: 679 [16922/17352 (98%)] Loss: -528.834557\n",
      "    epoch          : 679\n",
      "    loss           : -495.6006427960668\n",
      "    val_loss       : -330.7232902996162\n",
      "Train Epoch: 680 [512/17352 (3%)] Loss: -821.255249\n",
      "Train Epoch: 680 [11017/17352 (63%)] Loss: -928.135206\n",
      "Train Epoch: 680 [17253/17352 (99%)] Loss: -968.333079\n",
      "    epoch          : 680\n",
      "    loss           : -799.165133928239\n",
      "    val_loss       : -463.46220184027794\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch680.pth ...\n",
      "Train Epoch: 681 [512/17352 (3%)] Loss: -871.715942\n",
      "Train Epoch: 681 [10306/17352 (59%)] Loss: -965.889259\n",
      "Train Epoch: 681 [17106/17352 (99%)] Loss: -956.850473\n",
      "    epoch          : 681\n",
      "    loss           : -897.273864073921\n",
      "    val_loss       : -518.4616661461215\n",
      "Train Epoch: 682 [512/17352 (3%)] Loss: -953.329346\n",
      "Train Epoch: 682 [10812/17352 (62%)] Loss: -1010.888166\n",
      "Train Epoch: 682 [17044/17352 (98%)] Loss: -806.979064\n",
      "    epoch          : 682\n",
      "    loss           : -940.6909683003578\n",
      "    val_loss       : -556.4371037008387\n",
      "Train Epoch: 683 [512/17352 (3%)] Loss: -989.611633\n",
      "Train Epoch: 683 [10709/17352 (62%)] Loss: -852.597360\n",
      "Train Epoch: 683 [16878/17352 (97%)] Loss: -903.319800\n",
      "    epoch          : 683\n",
      "    loss           : -959.0580911057469\n",
      "    val_loss       : -568.997174827453\n",
      "Train Epoch: 684 [512/17352 (3%)] Loss: -1009.830322\n",
      "Train Epoch: 684 [10347/17352 (60%)] Loss: -913.981758\n",
      "Train Epoch: 684 [16882/17352 (97%)] Loss: -1012.942917\n",
      "    epoch          : 684\n",
      "    loss           : -958.9467581269656\n",
      "    val_loss       : -536.974899170196\n",
      "Train Epoch: 685 [512/17352 (3%)] Loss: -1004.530762\n",
      "Train Epoch: 685 [10217/17352 (59%)] Loss: -951.122081\n",
      "Train Epoch: 685 [16887/17352 (97%)] Loss: -845.113345\n",
      "    epoch          : 685\n",
      "    loss           : -960.2155590971568\n",
      "    val_loss       : -557.941933217893\n",
      "Train Epoch: 686 [512/17352 (3%)] Loss: -1008.363586\n",
      "Train Epoch: 686 [10268/17352 (59%)] Loss: -933.916760\n",
      "Train Epoch: 686 [17126/17352 (99%)] Loss: -1010.218532\n",
      "    epoch          : 686\n",
      "    loss           : -963.6728378704007\n",
      "    val_loss       : -537.3543430172813\n",
      "Train Epoch: 687 [512/17352 (3%)] Loss: -989.508179\n",
      "Train Epoch: 687 [10389/17352 (60%)] Loss: -953.892600\n",
      "Train Epoch: 687 [16957/17352 (98%)] Loss: -1003.542237\n",
      "    epoch          : 687\n",
      "    loss           : -966.2543051036083\n",
      "    val_loss       : -550.6364835636231\n",
      "Train Epoch: 688 [512/17352 (3%)] Loss: -1009.801453\n",
      "Train Epoch: 688 [10048/17352 (58%)] Loss: -801.612066\n",
      "Train Epoch: 688 [17133/17352 (99%)] Loss: -798.766074\n",
      "    epoch          : 688\n",
      "    loss           : -922.6114649338302\n",
      "    val_loss       : -514.4699029938241\n",
      "Train Epoch: 689 [512/17352 (3%)] Loss: -981.024536\n",
      "Train Epoch: 689 [10320/17352 (59%)] Loss: -809.724723\n",
      "Train Epoch: 689 [16878/17352 (97%)] Loss: -900.520647\n",
      "    epoch          : 689\n",
      "    loss           : -939.4199247168964\n",
      "    val_loss       : -528.1209673320993\n",
      "Train Epoch: 690 [512/17352 (3%)] Loss: -997.196228\n",
      "Train Epoch: 690 [10715/17352 (62%)] Loss: -1087.247135\n",
      "Train Epoch: 690 [17153/17352 (99%)] Loss: -907.070275\n",
      "    epoch          : 690\n",
      "    loss           : -960.3750820171983\n",
      "    val_loss       : -537.7378416645237\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch690.pth ...\n",
      "Train Epoch: 691 [512/17352 (3%)] Loss: -1001.833191\n",
      "Train Epoch: 691 [10706/17352 (62%)] Loss: -841.694355\n",
      "Train Epoch: 691 [17263/17352 (99%)] Loss: -893.875598\n",
      "    epoch          : 691\n",
      "    loss           : -961.5514219905093\n",
      "    val_loss       : -542.882040946038\n",
      "Train Epoch: 692 [512/17352 (3%)] Loss: -995.052124\n",
      "Train Epoch: 692 [10687/17352 (62%)] Loss: -1025.401253\n",
      "Train Epoch: 692 [16883/17352 (97%)] Loss: -1028.951661\n",
      "    epoch          : 692\n",
      "    loss           : -964.7032948824922\n",
      "    val_loss       : -552.4685411261214\n",
      "Train Epoch: 693 [512/17352 (3%)] Loss: -998.504028\n",
      "Train Epoch: 693 [10313/17352 (59%)] Loss: -828.598161\n",
      "Train Epoch: 693 [17335/17352 (100%)] Loss: -910.045146\n",
      "    epoch          : 693\n",
      "    loss           : -960.7010636834781\n",
      "    val_loss       : -486.0553241364465\n",
      "Train Epoch: 694 [512/17352 (3%)] Loss: -966.807068\n",
      "Train Epoch: 694 [10307/17352 (59%)] Loss: -1034.803165\n",
      "Train Epoch: 694 [17064/17352 (98%)] Loss: -891.388021\n",
      "    epoch          : 694\n",
      "    loss           : -956.3630668968829\n",
      "    val_loss       : -521.7691971112345\n",
      "Train Epoch: 695 [512/17352 (3%)] Loss: -986.772827\n",
      "Train Epoch: 695 [10180/17352 (59%)] Loss: -1025.197890\n",
      "Train Epoch: 695 [17153/17352 (99%)] Loss: -898.643262\n",
      "    epoch          : 695\n",
      "    loss           : -951.2553404454605\n",
      "    val_loss       : -446.7835850493989\n",
      "Train Epoch: 696 [512/17352 (3%)] Loss: -914.531494\n",
      "Train Epoch: 696 [10589/17352 (61%)] Loss: -906.813017\n",
      "Train Epoch: 696 [17253/17352 (99%)] Loss: -1038.356337\n",
      "    epoch          : 696\n",
      "    loss           : -852.8242637122479\n",
      "    val_loss       : -224.0115973433866\n",
      "Train Epoch: 697 [512/17352 (3%)] Loss: -649.679077\n",
      "Train Epoch: 697 [10016/17352 (58%)] Loss: -675.486939\n",
      "Train Epoch: 697 [17133/17352 (99%)] Loss: -928.589510\n",
      "    epoch          : 697\n",
      "    loss           : -810.5398506847106\n",
      "    val_loss       : -341.1529139560107\n",
      "Train Epoch: 698 [512/17352 (3%)] Loss: -858.267639\n",
      "Train Epoch: 698 [10599/17352 (61%)] Loss: -870.155261\n",
      "Train Epoch: 698 [17335/17352 (100%)] Loss: -868.047061\n",
      "    epoch          : 698\n",
      "    loss           : -880.2178031604709\n",
      "    val_loss       : -509.8198595969221\n",
      "Train Epoch: 699 [512/17352 (3%)] Loss: -988.434998\n",
      "Train Epoch: 699 [10672/17352 (62%)] Loss: -996.581997\n",
      "Train Epoch: 699 [16992/17352 (98%)] Loss: -948.002056\n",
      "    epoch          : 699\n",
      "    loss           : -946.8210953527794\n",
      "    val_loss       : -535.0883677211575\n",
      "Train Epoch: 700 [512/17352 (3%)] Loss: -1004.736328\n",
      "Train Epoch: 700 [9554/17352 (55%)] Loss: -983.754532\n",
      "Train Epoch: 700 [16934/17352 (98%)] Loss: -983.738929\n",
      "    epoch          : 700\n",
      "    loss           : -963.5268236252786\n",
      "    val_loss       : -526.1910054578515\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch700.pth ...\n",
      "Train Epoch: 701 [512/17352 (3%)] Loss: -1016.488281\n",
      "Train Epoch: 701 [9970/17352 (57%)] Loss: -1005.886788\n",
      "Train Epoch: 701 [17126/17352 (99%)] Loss: -851.897177\n",
      "    epoch          : 701\n",
      "    loss           : -965.3274876322857\n",
      "    val_loss       : -519.4439227342116\n",
      "Train Epoch: 702 [512/17352 (3%)] Loss: -1023.803101\n",
      "Train Epoch: 702 [10189/17352 (59%)] Loss: -1000.569278\n",
      "Train Epoch: 702 [16923/17352 (98%)] Loss: -1037.857753\n",
      "    epoch          : 702\n",
      "    loss           : -977.5518311884694\n",
      "    val_loss       : -516.2982532062775\n",
      "Train Epoch: 703 [512/17352 (3%)] Loss: -1008.403320\n",
      "Train Epoch: 703 [10277/17352 (59%)] Loss: -1082.705512\n",
      "Train Epoch: 703 [16992/17352 (98%)] Loss: -1030.144186\n",
      "    epoch          : 703\n",
      "    loss           : -974.1508307088981\n",
      "    val_loss       : -518.9874109800144\n",
      "Train Epoch: 704 [512/17352 (3%)] Loss: -1001.839722\n",
      "Train Epoch: 704 [10395/17352 (60%)] Loss: -959.203364\n",
      "Train Epoch: 704 [16957/17352 (98%)] Loss: -978.542829\n",
      "    epoch          : 704\n",
      "    loss           : -963.3652063714395\n",
      "    val_loss       : -499.32782995269116\n",
      "Train Epoch: 705 [512/17352 (3%)] Loss: -983.411865\n",
      "Train Epoch: 705 [10398/17352 (60%)] Loss: -960.264492\n",
      "Train Epoch: 705 [17263/17352 (99%)] Loss: -971.298673\n",
      "    epoch          : 705\n",
      "    loss           : -921.7054253620784\n",
      "    val_loss       : -471.8115109760268\n",
      "Train Epoch: 706 [512/17352 (3%)] Loss: -943.904541\n",
      "Train Epoch: 706 [10049/17352 (58%)] Loss: -1010.667837\n",
      "Train Epoch: 706 [16922/17352 (98%)] Loss: -903.608590\n",
      "    epoch          : 706\n",
      "    loss           : -940.3599510632421\n",
      "    val_loss       : -469.0659689874416\n",
      "Train Epoch: 707 [512/17352 (3%)] Loss: -929.606140\n",
      "Train Epoch: 707 [10072/17352 (58%)] Loss: -983.573456\n",
      "Train Epoch: 707 [17153/17352 (99%)] Loss: -998.018085\n",
      "    epoch          : 707\n",
      "    loss           : -929.3629459773624\n",
      "    val_loss       : -509.281920635295\n",
      "Train Epoch: 708 [512/17352 (3%)] Loss: -985.005859\n",
      "Train Epoch: 708 [10521/17352 (61%)] Loss: -1039.933245\n",
      "Train Epoch: 708 [16957/17352 (98%)] Loss: -1077.360460\n",
      "    epoch          : 708\n",
      "    loss           : -952.4460690094234\n",
      "    val_loss       : -514.072078910606\n",
      "Train Epoch: 709 [512/17352 (3%)] Loss: -971.905701\n",
      "Train Epoch: 709 [10860/17352 (63%)] Loss: -984.186009\n",
      "Train Epoch: 709 [16882/17352 (97%)] Loss: -1005.878068\n",
      "    epoch          : 709\n",
      "    loss           : -954.6704583529163\n",
      "    val_loss       : -532.7220419133849\n",
      "Train Epoch: 710 [512/17352 (3%)] Loss: -1018.056641\n",
      "Train Epoch: 710 [10251/17352 (59%)] Loss: -977.327708\n",
      "Train Epoch: 710 [16882/17352 (97%)] Loss: -828.838883\n",
      "    epoch          : 710\n",
      "    loss           : -959.0328263544967\n",
      "    val_loss       : -503.3997349437731\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch710.pth ...\n",
      "Train Epoch: 711 [512/17352 (3%)] Loss: -966.673584\n",
      "Train Epoch: 711 [10244/17352 (59%)] Loss: -964.849143\n",
      "Train Epoch: 711 [17044/17352 (98%)] Loss: -700.741734\n",
      "    epoch          : 711\n",
      "    loss           : -942.4394597782505\n",
      "    val_loss       : -460.781346237023\n",
      "Train Epoch: 712 [512/17352 (3%)] Loss: -934.667358\n",
      "Train Epoch: 712 [9982/17352 (58%)] Loss: -806.220062\n",
      "Train Epoch: 712 [16939/17352 (98%)] Loss: -902.383217\n",
      "    epoch          : 712\n",
      "    loss           : -861.0426181417171\n",
      "    val_loss       : -427.4290291075168\n",
      "Train Epoch: 713 [512/17352 (3%)] Loss: -924.644043\n",
      "Train Epoch: 713 [10748/17352 (62%)] Loss: -968.235343\n",
      "Train Epoch: 713 [17044/17352 (98%)] Loss: -987.288564\n",
      "    epoch          : 713\n",
      "    loss           : -905.5319099183895\n",
      "    val_loss       : -469.5850697572415\n",
      "Train Epoch: 714 [512/17352 (3%)] Loss: -917.894897\n",
      "Train Epoch: 714 [9760/17352 (56%)] Loss: -843.259543\n",
      "Train Epoch: 714 [16882/17352 (97%)] Loss: -907.851749\n",
      "    epoch          : 714\n",
      "    loss           : -939.7056853943483\n",
      "    val_loss       : -523.3089538144038\n",
      "Train Epoch: 715 [512/17352 (3%)] Loss: -847.231140\n",
      "Train Epoch: 715 [10449/17352 (60%)] Loss: -1062.123264\n",
      "Train Epoch: 715 [17153/17352 (99%)] Loss: -920.392818\n",
      "    epoch          : 715\n",
      "    loss           : -964.6248432083416\n",
      "    val_loss       : -517.6671303114568\n",
      "Train Epoch: 716 [512/17352 (3%)] Loss: -1012.865234\n",
      "Train Epoch: 716 [10732/17352 (62%)] Loss: -1044.095649\n",
      "Train Epoch: 716 [16939/17352 (98%)] Loss: -930.188952\n",
      "    epoch          : 716\n",
      "    loss           : -964.3405596201655\n",
      "    val_loss       : -473.32641019574913\n",
      "Train Epoch: 717 [512/17352 (3%)] Loss: -974.100464\n",
      "Train Epoch: 717 [10302/17352 (59%)] Loss: -817.404704\n",
      "Train Epoch: 717 [16883/17352 (97%)] Loss: -889.968986\n",
      "    epoch          : 717\n",
      "    loss           : -951.3231181785362\n",
      "    val_loss       : -421.60017959713207\n",
      "Train Epoch: 718 [512/17352 (3%)] Loss: -901.376465\n",
      "Train Epoch: 718 [10155/17352 (59%)] Loss: -1022.722081\n",
      "Train Epoch: 718 [17153/17352 (99%)] Loss: -907.758018\n",
      "    epoch          : 718\n",
      "    loss           : -940.3226999330825\n",
      "    val_loss       : -484.55035577979385\n",
      "Train Epoch: 719 [512/17352 (3%)] Loss: -897.561279\n",
      "Train Epoch: 719 [10490/17352 (60%)] Loss: -1063.031850\n",
      "Train Epoch: 719 [17106/17352 (99%)] Loss: -801.707661\n",
      "    epoch          : 719\n",
      "    loss           : -931.6969528023758\n",
      "    val_loss       : -416.3554795503504\n",
      "Train Epoch: 720 [512/17352 (3%)] Loss: -925.919800\n",
      "Train Epoch: 720 [10135/17352 (58%)] Loss: -788.711349\n",
      "Train Epoch: 720 [17335/17352 (100%)] Loss: -862.203468\n",
      "    epoch          : 720\n",
      "    loss           : -923.7992321650502\n",
      "    val_loss       : -444.9440289882399\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0405_174348/checkpoint-epoch720.pth ...\n",
      "Train Epoch: 721 [512/17352 (3%)] Loss: -949.635498\n",
      "Train Epoch: 721 [10474/17352 (60%)] Loss: -1002.451056\n",
      "Train Epoch: 721 [16939/17352 (98%)] Loss: -976.652146\n",
      "    epoch          : 721\n",
      "    loss           : -927.9174631338718\n",
      "    val_loss       : -484.8599833983414\n",
      "Train Epoch: 722 [512/17352 (3%)] Loss: -985.147461\n",
      "Train Epoch: 722 [10521/17352 (61%)] Loss: -890.360129\n",
      "Train Epoch: 722 [17108/17352 (99%)] Loss: -953.237158\n",
      "    epoch          : 722\n",
      "    loss           : -927.583210852882\n",
      "    val_loss       : -476.1852453596772\n",
      "Train Epoch: 723 [512/17352 (3%)] Loss: -969.442505\n",
      "Train Epoch: 723 [9898/17352 (57%)] Loss: -919.605748\n",
      "Train Epoch: 723 [17133/17352 (99%)] Loss: -949.716856\n",
      "    epoch          : 723\n",
      "    loss           : -935.7595731783015\n",
      "    val_loss       : -409.10058075484966\n",
      "Train Epoch: 724 [512/17352 (3%)] Loss: -955.242432\n",
      "Train Epoch: 724 [10637/17352 (61%)] Loss: -839.867823\n",
      "Train Epoch: 724 [16923/17352 (98%)] Loss: -922.592256\n",
      "    epoch          : 724\n",
      "    loss           : -963.0713806883451\n",
      "    val_loss       : -528.3440412775988\n",
      "Train Epoch: 725 [512/17352 (3%)] Loss: -1020.587708\n",
      "Train Epoch: 725 [10139/17352 (58%)] Loss: -747.574446\n",
      "Train Epoch: 725 [16988/17352 (98%)] Loss: -907.698770\n",
      "    epoch          : 725\n",
      "    loss           : -918.6969875045216\n",
      "    val_loss       : -512.7496098895941\n",
      "Train Epoch: 726 [512/17352 (3%)] Loss: -956.141052\n",
      "Train Epoch: 726 [10440/17352 (60%)] Loss: -927.908462\n",
      "Train Epoch: 726 [17049/17352 (98%)] Loss: -879.206883\n",
      "    epoch          : 726\n",
      "    loss           : -936.3339657339841\n",
      "    val_loss       : -460.53750807672014\n",
      "Train Epoch: 727 [512/17352 (3%)] Loss: -929.744690\n",
      "Train Epoch: 727 [10714/17352 (62%)] Loss: -1052.927772\n",
      "Train Epoch: 727 [17263/17352 (99%)] Loss: -943.908375\n",
      "    epoch          : 727\n",
      "    loss           : -927.1306515095604\n",
      "    val_loss       : -408.93751215486066\n",
      "Validation performance didn't improve for 200 epochs. Training stops.\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:categorical_bpl] *",
   "language": "python",
   "name": "conda-env-categorical_bpl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
