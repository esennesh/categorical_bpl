{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/categorical_bpl\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = collections.namedtuple('Args', 'config resume device')\n",
    "config = ConfigParser.from_args(Args(config='omniglot_config.json', resume=None, device=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = config.get_logger('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = pyro.optim.ReduceLROnPlateau({\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'optim_args': {\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": 0,\n",
    "        \"amsgrad\": True\n",
    "    },\n",
    "    \"patience\": 50,\n",
    "    \"cooldown\": 25,\n",
    "    \"factor\": 0.1,\n",
    "    \"verbose\": True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, [], optimizer, config=config,\n",
    "                  data_loader=data_loader,\n",
    "                  valid_data_loader=valid_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [512/17352 (3%)] Loss: 1880.181763\n",
      "Train Epoch: 1 [10068/17352 (58%)] Loss: 1042.070658\n",
      "Train Epoch: 1 [16939/17352 (98%)] Loss: 971.999540\n",
      "    epoch          : 1\n",
      "    loss           : 1157.684643665039\n",
      "    val_loss       : 970.5192843715782\n",
      "    val_log_likelihood: -821.6840605225043\n",
      "    val_log_marginal: -901.7788107347708\n",
      "Train Epoch: 2 [512/17352 (3%)] Loss: 911.271362\n",
      "Train Epoch: 2 [10382/17352 (60%)] Loss: 910.432940\n",
      "Train Epoch: 2 [17263/17352 (99%)] Loss: 957.810257\n",
      "    epoch          : 2\n",
      "    loss           : 912.6685501097813\n",
      "    val_loss       : 853.8396809985271\n",
      "    val_log_likelihood: -765.0810075687353\n",
      "    val_log_marginal: -816.2971422278513\n",
      "Train Epoch: 3 [512/17352 (3%)] Loss: 879.162537\n",
      "Train Epoch: 3 [10694/17352 (62%)] Loss: 792.861968\n",
      "Train Epoch: 3 [17153/17352 (99%)] Loss: 896.165133\n",
      "    epoch          : 3\n",
      "    loss           : 826.8902764645973\n",
      "    val_loss       : 791.9512243253893\n",
      "    val_log_likelihood: -726.4330610818407\n",
      "    val_log_marginal: -757.4603210806864\n",
      "Train Epoch: 4 [512/17352 (3%)] Loss: 803.153503\n",
      "Train Epoch: 4 [10007/17352 (58%)] Loss: 804.083248\n",
      "Train Epoch: 4 [17049/17352 (98%)] Loss: 742.903457\n",
      "    epoch          : 4\n",
      "    loss           : 767.7418025185644\n",
      "    val_loss       : 758.1466867754168\n",
      "    val_log_likelihood: -700.715828197769\n",
      "    val_log_marginal: -725.7511544574311\n",
      "Train Epoch: 5 [512/17352 (3%)] Loss: 733.493408\n",
      "Train Epoch: 5 [10769/17352 (62%)] Loss: 726.553151\n",
      "Train Epoch: 5 [17126/17352 (99%)] Loss: 694.329795\n",
      "    epoch          : 5\n",
      "    loss           : 734.8823524850546\n",
      "    val_loss       : 718.312248805137\n",
      "    val_log_likelihood: -677.7922813613991\n",
      "    val_log_marginal: -699.2821085659967\n",
      "Train Epoch: 6 [512/17352 (3%)] Loss: 714.717834\n",
      "Train Epoch: 6 [10226/17352 (59%)] Loss: 711.129325\n",
      "Train Epoch: 6 [16887/17352 (97%)] Loss: 675.171094\n",
      "    epoch          : 6\n",
      "    loss           : 702.9938226139424\n",
      "    val_loss       : 689.7211177243954\n",
      "    val_log_likelihood: -659.6549483156705\n",
      "    val_log_marginal: -679.5372268913591\n",
      "Train Epoch: 7 [512/17352 (3%)] Loss: 676.712830\n",
      "Train Epoch: 7 [10715/17352 (62%)] Loss: 675.971304\n",
      "Train Epoch: 7 [17044/17352 (98%)] Loss: 660.417626\n",
      "    epoch          : 7\n",
      "    loss           : 668.2889958325256\n",
      "    val_loss       : 661.9756632617884\n",
      "    val_log_likelihood: -638.3234016979172\n",
      "    val_log_marginal: -654.7417767512078\n",
      "Train Epoch: 8 [512/17352 (3%)] Loss: 660.951904\n",
      "Train Epoch: 8 [10595/17352 (61%)] Loss: 646.195080\n",
      "Train Epoch: 8 [17263/17352 (99%)] Loss: 643.869617\n",
      "    epoch          : 8\n",
      "    loss           : 646.5852832268371\n",
      "    val_loss       : 650.6697143355512\n",
      "    val_log_likelihood: -621.0080315685454\n",
      "    val_log_marginal: -645.2631642856552\n",
      "Train Epoch: 9 [512/17352 (3%)] Loss: 643.309265\n",
      "Train Epoch: 9 [10243/17352 (59%)] Loss: 624.463476\n",
      "Train Epoch: 9 [16887/17352 (97%)] Loss: 641.948536\n",
      "    epoch          : 9\n",
      "    loss           : 629.5127110692355\n",
      "    val_loss       : 631.6436525816625\n",
      "    val_log_likelihood: -606.894393319993\n",
      "    val_log_marginal: -629.1987344734565\n",
      "Train Epoch: 10 [512/17352 (3%)] Loss: 626.722595\n",
      "Train Epoch: 10 [10504/17352 (61%)] Loss: 605.566977\n",
      "Train Epoch: 10 [16883/17352 (97%)] Loss: 617.067608\n",
      "    epoch          : 10\n",
      "    loss           : 612.3829084886593\n",
      "    val_loss       : 608.084952643167\n",
      "    val_log_likelihood: -589.6908059998416\n",
      "    val_log_marginal: -605.6983064307396\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch10.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 11 [512/17352 (3%)] Loss: 606.835938\n",
      "Train Epoch: 11 [9856/17352 (57%)] Loss: 596.029138\n",
      "Train Epoch: 11 [17049/17352 (98%)] Loss: 574.272122\n",
      "    epoch          : 11\n",
      "    loss           : 591.0326651262998\n",
      "    val_loss       : 584.5231449458403\n",
      "    val_log_likelihood: -568.9164457198688\n",
      "    val_log_marginal: -582.7332580123771\n",
      "Train Epoch: 12 [512/17352 (3%)] Loss: 580.665833\n",
      "Train Epoch: 12 [9838/17352 (57%)] Loss: 587.382708\n",
      "Train Epoch: 12 [17064/17352 (98%)] Loss: 575.725509\n",
      "    epoch          : 12\n",
      "    loss           : 576.6691309857532\n",
      "    val_loss       : 583.2603484468648\n",
      "    val_log_likelihood: -552.1622481022343\n",
      "    val_log_marginal: -575.8876962778503\n",
      "Train Epoch: 13 [512/17352 (3%)] Loss: 565.276062\n",
      "Train Epoch: 13 [10313/17352 (59%)] Loss: 548.650698\n",
      "Train Epoch: 13 [17253/17352 (99%)] Loss: 568.000125\n",
      "    epoch          : 13\n",
      "    loss           : 559.5725825853284\n",
      "    val_loss       : 562.1491889279039\n",
      "    val_log_likelihood: -538.4919204322838\n",
      "    val_log_marginal: -558.0572006947017\n",
      "Train Epoch: 14 [512/17352 (3%)] Loss: 553.771057\n",
      "Train Epoch: 14 [10999/17352 (63%)] Loss: 537.470410\n",
      "Train Epoch: 14 [16992/17352 (98%)] Loss: 532.671294\n",
      "    epoch          : 14\n",
      "    loss           : 545.2561911920209\n",
      "    val_loss       : 550.026183455379\n",
      "    val_log_likelihood: -520.0323150053773\n",
      "    val_log_marginal: -541.3327392482595\n",
      "Train Epoch: 15 [512/17352 (3%)] Loss: 529.318298\n",
      "Train Epoch: 15 [10563/17352 (61%)] Loss: 527.923481\n",
      "Train Epoch: 15 [17016/17352 (98%)] Loss: 511.323692\n",
      "    epoch          : 15\n",
      "    loss           : 524.563292461332\n",
      "    val_loss       : 524.2675187256962\n",
      "    val_log_likelihood: -503.8634583801612\n",
      "    val_log_marginal: -520.9718618726092\n",
      "Train Epoch: 16 [512/17352 (3%)] Loss: 514.229065\n",
      "Train Epoch: 16 [10191/17352 (59%)] Loss: 511.110717\n",
      "Train Epoch: 16 [17090/17352 (98%)] Loss: 517.567361\n",
      "    epoch          : 16\n",
      "    loss           : 507.72273530608817\n",
      "    val_loss       : 522.6685606983344\n",
      "    val_log_likelihood: -487.1896213653812\n",
      "    val_log_marginal: -519.5296295125262\n",
      "Train Epoch: 17 [512/17352 (3%)] Loss: 514.600464\n",
      "Train Epoch: 17 [10427/17352 (60%)] Loss: 493.167509\n",
      "Train Epoch: 17 [16957/17352 (98%)] Loss: 518.859442\n",
      "    epoch          : 17\n",
      "    loss           : 495.5824447672356\n",
      "    val_loss       : 501.73104483452215\n",
      "    val_log_likelihood: -471.83290901380883\n",
      "    val_log_marginal: -499.83599192131317\n",
      "Train Epoch: 18 [512/17352 (3%)] Loss: 494.875366\n",
      "Train Epoch: 18 [10135/17352 (58%)] Loss: 487.314219\n",
      "Train Epoch: 18 [17335/17352 (100%)] Loss: 480.529703\n",
      "    epoch          : 18\n",
      "    loss           : 474.9732234279606\n",
      "    val_loss       : 473.98371361788395\n",
      "    val_log_likelihood: -454.7178698029296\n",
      "    val_log_marginal: -471.7543794107611\n",
      "Train Epoch: 19 [512/17352 (3%)] Loss: 466.420532\n",
      "Train Epoch: 19 [10251/17352 (59%)] Loss: 456.095285\n",
      "Train Epoch: 19 [16922/17352 (98%)] Loss: 475.640176\n",
      "    epoch          : 19\n",
      "    loss           : 459.067599158663\n",
      "    val_loss       : 454.9956834231776\n",
      "    val_log_likelihood: -438.8504849502283\n",
      "    val_log_marginal: -450.8490409127193\n",
      "Train Epoch: 20 [512/17352 (3%)] Loss: 445.985382\n",
      "Train Epoch: 20 [10151/17352 (59%)] Loss: 440.976720\n",
      "Train Epoch: 20 [16872/17352 (97%)] Loss: 429.544575\n",
      "    epoch          : 20\n",
      "    loss           : 445.3383905394562\n",
      "    val_loss       : 454.0638189634425\n",
      "    val_log_likelihood: -421.24650971426615\n",
      "    val_log_marginal: -446.5757927642964\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch20.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 21 [512/17352 (3%)] Loss: 432.263885\n",
      "Train Epoch: 21 [10491/17352 (60%)] Loss: 413.511827\n",
      "Train Epoch: 21 [17126/17352 (99%)] Loss: 409.857247\n",
      "    epoch          : 21\n",
      "    loss           : 425.90648626140415\n",
      "    val_loss       : 428.98603287513663\n",
      "    val_log_likelihood: -403.2776384320217\n",
      "    val_log_marginal: -424.73089481896767\n",
      "Train Epoch: 22 [512/17352 (3%)] Loss: 415.866730\n",
      "Train Epoch: 22 [9965/17352 (57%)] Loss: 393.715495\n",
      "Train Epoch: 22 [16878/17352 (97%)] Loss: 412.995966\n",
      "    epoch          : 22\n",
      "    loss           : 410.1124360245205\n",
      "    val_loss       : 408.66739283959856\n",
      "    val_log_likelihood: -388.1842817674653\n",
      "    val_log_marginal: -404.90904054945617\n",
      "Train Epoch: 23 [512/17352 (3%)] Loss: 400.677734\n",
      "Train Epoch: 23 [10405/17352 (60%)] Loss: 404.496112\n",
      "Train Epoch: 23 [17133/17352 (99%)] Loss: 380.836410\n",
      "    epoch          : 23\n",
      "    loss           : 393.4388866947365\n",
      "    val_loss       : 393.4177414815958\n",
      "    val_log_likelihood: -371.8461974034897\n",
      "    val_log_marginal: -389.91496388947064\n",
      "Train Epoch: 24 [512/17352 (3%)] Loss: 384.068787\n",
      "Train Epoch: 24 [9762/17352 (56%)] Loss: 387.570889\n",
      "Train Epoch: 24 [17106/17352 (99%)] Loss: 372.665348\n",
      "    epoch          : 24\n",
      "    loss           : 380.8011589268854\n",
      "    val_loss       : 391.2111949582108\n",
      "    val_log_likelihood: -358.5162256169454\n",
      "    val_log_marginal: -387.7050352898477\n",
      "Train Epoch: 25 [512/17352 (3%)] Loss: 383.501526\n",
      "Train Epoch: 25 [9896/17352 (57%)] Loss: 383.692584\n",
      "Train Epoch: 25 [16922/17352 (98%)] Loss: 348.368045\n",
      "    epoch          : 25\n",
      "    loss           : 367.8380262423305\n",
      "    val_loss       : 362.715389503659\n",
      "    val_log_likelihood: -343.82880590566424\n",
      "    val_log_marginal: -359.9049204190497\n",
      "Train Epoch: 26 [512/17352 (3%)] Loss: 353.740662\n",
      "Train Epoch: 26 [10526/17352 (61%)] Loss: 350.788783\n",
      "Train Epoch: 26 [17101/17352 (99%)] Loss: 360.407371\n",
      "    epoch          : 26\n",
      "    loss           : 347.5188339958975\n",
      "    val_loss       : 341.04060439494015\n",
      "    val_log_likelihood: -323.56360647520086\n",
      "    val_log_marginal: -338.269247883875\n",
      "Train Epoch: 27 [512/17352 (3%)] Loss: 336.326630\n",
      "Train Epoch: 27 [9710/17352 (56%)] Loss: 350.424557\n",
      "Train Epoch: 27 [17108/17352 (99%)] Loss: 342.915147\n",
      "    epoch          : 27\n",
      "    loss           : 331.5458855056246\n",
      "    val_loss       : 325.8333420755589\n",
      "    val_log_likelihood: -309.2306080893585\n",
      "    val_log_marginal: -322.6952035732534\n",
      "Train Epoch: 28 [512/17352 (3%)] Loss: 326.646057\n",
      "Train Epoch: 28 [9917/17352 (57%)] Loss: 326.152344\n",
      "Train Epoch: 28 [16958/17352 (98%)] Loss: 305.427569\n",
      "    epoch          : 28\n",
      "    loss           : 320.55439906838285\n",
      "    val_loss       : 323.55311479329185\n",
      "    val_log_likelihood: -295.7981093849312\n",
      "    val_log_marginal: -320.6150228106702\n",
      "Train Epoch: 29 [512/17352 (3%)] Loss: 320.492737\n",
      "Train Epoch: 29 [10190/17352 (59%)] Loss: 311.490712\n",
      "Train Epoch: 29 [16992/17352 (98%)] Loss: 293.762354\n",
      "    epoch          : 29\n",
      "    loss           : 316.01811860001015\n",
      "    val_loss       : 301.4664452421499\n",
      "    val_log_likelihood: -282.89205342142907\n",
      "    val_log_marginal: -298.1087826335744\n",
      "Train Epoch: 30 [512/17352 (3%)] Loss: 293.863922\n",
      "Train Epoch: 30 [10295/17352 (59%)] Loss: 319.490222\n",
      "Train Epoch: 30 [16992/17352 (98%)] Loss: 283.013928\n",
      "    epoch          : 30\n",
      "    loss           : 291.3104646095051\n",
      "    val_loss       : 285.4612589901114\n",
      "    val_log_likelihood: -266.8744885201702\n",
      "    val_log_marginal: -281.10798507733824\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch30.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 31 [512/17352 (3%)] Loss: 279.330353\n",
      "Train Epoch: 31 [10667/17352 (61%)] Loss: 267.621403\n",
      "Train Epoch: 31 [17044/17352 (98%)] Loss: 272.824639\n",
      "    epoch          : 31\n",
      "    loss           : 276.03072167113265\n",
      "    val_loss       : 272.9930062168738\n",
      "    val_log_likelihood: -250.9439779881045\n",
      "    val_log_marginal: -268.70450662801613\n",
      "Train Epoch: 32 [512/17352 (3%)] Loss: 271.870789\n",
      "Train Epoch: 32 [10581/17352 (61%)] Loss: 275.502501\n",
      "Train Epoch: 32 [16958/17352 (98%)] Loss: 235.625719\n",
      "    epoch          : 32\n",
      "    loss           : 265.7008030633448\n",
      "    val_loss       : 266.65895081951163\n",
      "    val_log_likelihood: -240.7196306910363\n",
      "    val_log_marginal: -262.7684082510339\n",
      "Train Epoch: 33 [512/17352 (3%)] Loss: 259.956543\n",
      "Train Epoch: 33 [10075/17352 (58%)] Loss: 221.335471\n",
      "Train Epoch: 33 [17126/17352 (99%)] Loss: 256.013759\n",
      "    epoch          : 33\n",
      "    loss           : 253.05900695641753\n",
      "    val_loss       : 252.85073155551987\n",
      "    val_log_likelihood: -224.75076954698548\n",
      "    val_log_marginal: -250.28288136488345\n",
      "Train Epoch: 34 [512/17352 (3%)] Loss: 245.932007\n",
      "Train Epoch: 34 [10108/17352 (58%)] Loss: 230.446278\n",
      "Train Epoch: 34 [16883/17352 (97%)] Loss: 248.977351\n",
      "    epoch          : 34\n",
      "    loss           : 239.7174407294417\n",
      "    val_loss       : 235.90463371145282\n",
      "    val_log_likelihood: -212.9014585885744\n",
      "    val_log_marginal: -232.1596896214056\n",
      "Train Epoch: 35 [512/17352 (3%)] Loss: 228.419495\n",
      "Train Epoch: 35 [10108/17352 (58%)] Loss: 194.170044\n",
      "Train Epoch: 35 [17108/17352 (99%)] Loss: 230.409015\n",
      "    epoch          : 35\n",
      "    loss           : 230.00333205490804\n",
      "    val_loss       : 232.51149175091317\n",
      "    val_log_likelihood: -201.8352935353776\n",
      "    val_log_marginal: -227.67392541475573\n",
      "Train Epoch: 36 [512/17352 (3%)] Loss: 222.845657\n",
      "Train Epoch: 36 [10298/17352 (59%)] Loss: 212.708633\n",
      "Train Epoch: 36 [16957/17352 (98%)] Loss: 187.629289\n",
      "    epoch          : 36\n",
      "    loss           : 213.63320593959574\n",
      "    val_loss       : 211.4886433054076\n",
      "    val_log_likelihood: -185.91009150681296\n",
      "    val_log_marginal: -206.30617202487855\n",
      "Train Epoch: 37 [512/17352 (3%)] Loss: 201.804382\n",
      "Train Epoch: 37 [10429/17352 (60%)] Loss: 183.099659\n",
      "Train Epoch: 37 [17143/17352 (99%)] Loss: 168.427422\n",
      "    epoch          : 37\n",
      "    loss           : 200.60289759793957\n",
      "    val_loss       : 205.3903269723623\n",
      "    val_log_likelihood: -172.54111503575797\n",
      "    val_log_marginal: -201.013584091289\n",
      "Train Epoch: 38 [512/17352 (3%)] Loss: 198.248199\n",
      "Train Epoch: 38 [10365/17352 (60%)] Loss: 218.071086\n",
      "Train Epoch: 38 [17133/17352 (99%)] Loss: 189.288346\n",
      "    epoch          : 38\n",
      "    loss           : 191.83927445865848\n",
      "    val_loss       : 194.5925417954677\n",
      "    val_log_likelihood: -158.37012586265195\n",
      "    val_log_marginal: -191.97891173565816\n",
      "Train Epoch: 39 [512/17352 (3%)] Loss: 182.601105\n",
      "Train Epoch: 39 [10420/17352 (60%)] Loss: 176.920070\n",
      "Train Epoch: 39 [16922/17352 (98%)] Loss: 188.187393\n",
      "    epoch          : 39\n",
      "    loss           : 185.37341317145595\n",
      "    val_loss       : 180.84066680663503\n",
      "    val_log_likelihood: -152.1439857326662\n",
      "    val_log_marginal: -175.89880139440055\n",
      "Train Epoch: 40 [512/17352 (3%)] Loss: 167.821655\n",
      "Train Epoch: 40 [10017/17352 (58%)] Loss: 177.393701\n",
      "Train Epoch: 40 [16992/17352 (98%)] Loss: 171.449254\n",
      "    epoch          : 40\n",
      "    loss           : 173.7628685424576\n",
      "    val_loss       : 168.05255774295833\n",
      "    val_log_likelihood: -137.38408764556047\n",
      "    val_log_marginal: -163.46912998416454\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch40.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 41 [512/17352 (3%)] Loss: 154.437302\n",
      "Train Epoch: 41 [10705/17352 (62%)] Loss: 133.583841\n",
      "Train Epoch: 41 [16988/17352 (98%)] Loss: 167.396871\n",
      "    epoch          : 41\n",
      "    loss           : 155.04884983402258\n",
      "    val_loss       : 157.85629519566814\n",
      "    val_log_likelihood: -122.64921982275835\n",
      "    val_log_marginal: -151.84985988430412\n",
      "Train Epoch: 42 [512/17352 (3%)] Loss: 156.508636\n",
      "Train Epoch: 42 [10394/17352 (60%)] Loss: 154.880512\n",
      "Train Epoch: 42 [17049/17352 (98%)] Loss: 165.218366\n",
      "    epoch          : 42\n",
      "    loss           : 147.75028007695312\n",
      "    val_loss       : 147.39996307023972\n",
      "    val_log_likelihood: -116.80036699204204\n",
      "    val_log_marginal: -143.53675875075356\n",
      "Train Epoch: 43 [512/17352 (3%)] Loss: 137.729767\n",
      "Train Epoch: 43 [10404/17352 (60%)] Loss: 169.055884\n",
      "Train Epoch: 43 [17153/17352 (99%)] Loss: 125.380000\n",
      "    epoch          : 43\n",
      "    loss           : 141.28165877496514\n",
      "    val_loss       : 144.3124554219871\n",
      "    val_log_likelihood: -103.66780764695791\n",
      "    val_log_marginal: -136.70150100131204\n",
      "Train Epoch: 44 [512/17352 (3%)] Loss: 130.045807\n",
      "Train Epoch: 44 [10269/17352 (59%)] Loss: 154.002090\n",
      "Train Epoch: 44 [17335/17352 (100%)] Loss: 133.753509\n",
      "    epoch          : 44\n",
      "    loss           : 136.09115959967986\n",
      "    val_loss       : 223.95793677434443\n",
      "    val_log_likelihood: -102.7081448739511\n",
      "    val_log_marginal: -212.5240918543694\n",
      "Train Epoch: 45 [512/17352 (3%)] Loss: 209.244400\n",
      "Train Epoch: 45 [9592/17352 (55%)] Loss: 182.414755\n",
      "Train Epoch: 45 [17049/17352 (98%)] Loss: 115.297013\n",
      "    epoch          : 45\n",
      "    loss           : 143.19490307969232\n",
      "    val_loss       : 133.66852646497304\n",
      "    val_log_likelihood: -89.29723372274235\n",
      "    val_log_marginal: -130.94022212857772\n",
      "Train Epoch: 46 [512/17352 (3%)] Loss: 123.833328\n",
      "Train Epoch: 46 [10913/17352 (63%)] Loss: 100.465169\n",
      "Train Epoch: 46 [17277/17352 (100%)] Loss: 88.059722\n",
      "    epoch          : 46\n",
      "    loss           : 113.41149355555676\n",
      "    val_loss       : 116.25930257470881\n",
      "    val_log_likelihood: -72.08034104390393\n",
      "    val_log_marginal: -109.78736567254077\n",
      "Train Epoch: 47 [512/17352 (3%)] Loss: 113.001846\n",
      "Train Epoch: 47 [10264/17352 (59%)] Loss: 76.129322\n",
      "Train Epoch: 47 [17143/17352 (99%)] Loss: 99.397064\n",
      "    epoch          : 47\n",
      "    loss           : 102.84059297252875\n",
      "    val_loss       : 108.13965269040966\n",
      "    val_log_likelihood: -66.03148974979784\n",
      "    val_log_marginal: -101.4340313927263\n",
      "Train Epoch: 48 [512/17352 (3%)] Loss: 98.882820\n",
      "Train Epoch: 48 [10189/17352 (59%)] Loss: 69.918597\n",
      "Train Epoch: 48 [17253/17352 (99%)] Loss: 108.796368\n",
      "    epoch          : 48\n",
      "    loss           : 92.9569380279259\n",
      "    val_loss       : 94.29392773323084\n",
      "    val_log_likelihood: -52.975059156948106\n",
      "    val_log_marginal: -87.41805734416658\n",
      "Train Epoch: 49 [512/17352 (3%)] Loss: 86.627975\n",
      "Train Epoch: 49 [10375/17352 (60%)] Loss: 82.974228\n",
      "Train Epoch: 49 [17153/17352 (99%)] Loss: 88.890733\n",
      "    epoch          : 49\n",
      "    loss           : 90.131901689298\n",
      "    val_loss       : 101.60695199192345\n",
      "    val_log_likelihood: -47.97900169028338\n",
      "    val_log_marginal: -94.5093942247934\n",
      "Train Epoch: 50 [512/17352 (3%)] Loss: 93.725075\n",
      "Train Epoch: 50 [10743/17352 (62%)] Loss: 43.065830\n",
      "Train Epoch: 50 [17049/17352 (98%)] Loss: 101.137305\n",
      "    epoch          : 50\n",
      "    loss           : 82.98709558418777\n",
      "    val_loss       : 81.13324642909905\n",
      "    val_log_likelihood: -39.31390523424024\n",
      "    val_log_marginal: -74.49777004614752\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch50.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 51 [512/17352 (3%)] Loss: 67.475677\n",
      "Train Epoch: 51 [10471/17352 (60%)] Loss: 69.397118\n",
      "Train Epoch: 51 [17263/17352 (99%)] Loss: 54.445148\n",
      "    epoch          : 51\n",
      "    loss           : 70.38482798316029\n",
      "    val_loss       : 72.96461622544662\n",
      "    val_log_likelihood: -28.210822113458672\n",
      "    val_log_marginal: -66.9077223642522\n",
      "Train Epoch: 52 [512/17352 (3%)] Loss: 67.235580\n",
      "Train Epoch: 52 [10466/17352 (60%)] Loss: 44.885090\n",
      "Train Epoch: 52 [16922/17352 (98%)] Loss: 54.155789\n",
      "    epoch          : 52\n",
      "    loss           : 65.25866947473949\n",
      "    val_loss       : 61.36166572560717\n",
      "    val_log_likelihood: -18.361305701041125\n",
      "    val_log_marginal: -55.89678783999834\n",
      "Train Epoch: 53 [512/17352 (3%)] Loss: 55.434326\n",
      "Train Epoch: 53 [10416/17352 (60%)] Loss: 28.894462\n",
      "Train Epoch: 53 [17133/17352 (99%)] Loss: 31.162292\n",
      "    epoch          : 53\n",
      "    loss           : 56.17378559424957\n",
      "    val_loss       : 61.271577987864156\n",
      "    val_log_likelihood: -12.65226789645594\n",
      "    val_log_marginal: -53.20677339283541\n",
      "Train Epoch: 54 [512/17352 (3%)] Loss: 54.589169\n",
      "Train Epoch: 54 [9728/17352 (56%)] Loss: 119.660174\n",
      "Train Epoch: 54 [17016/17352 (98%)] Loss: 81.424438\n",
      "    epoch          : 54\n",
      "    loss           : 92.71416870772661\n",
      "    val_loss       : 136.48876035566872\n",
      "    val_log_likelihood: -34.68409265127536\n",
      "    val_log_marginal: -122.54111111800597\n",
      "Train Epoch: 55 [512/17352 (3%)] Loss: 118.371719\n",
      "Train Epoch: 55 [10093/17352 (58%)] Loss: 28.896422\n",
      "Train Epoch: 55 [17016/17352 (98%)] Loss: 73.258933\n",
      "    epoch          : 55\n",
      "    loss           : 74.89015031528133\n",
      "    val_loss       : 62.358541017872795\n",
      "    val_log_likelihood: -4.893938743631587\n",
      "    val_log_marginal: -56.78074717405461\n",
      "Train Epoch: 56 [512/17352 (3%)] Loss: 52.869946\n",
      "Train Epoch: 56 [10215/17352 (59%)] Loss: 42.431147\n",
      "Train Epoch: 56 [17064/17352 (98%)] Loss: 35.914676\n",
      "    epoch          : 56\n",
      "    loss           : 42.90184139140132\n",
      "    val_loss       : 43.10544201523266\n",
      "    val_log_likelihood: 5.637476573926897\n",
      "    val_log_marginal: -36.91672195123652\n",
      "Train Epoch: 57 [512/17352 (3%)] Loss: 25.755093\n",
      "Train Epoch: 57 [9851/17352 (57%)] Loss: 2.557372\n",
      "Train Epoch: 57 [17126/17352 (99%)] Loss: 16.037459\n",
      "    epoch          : 57\n",
      "    loss           : 30.33620298898208\n",
      "    val_loss       : 33.65057259677362\n",
      "    val_log_likelihood: 24.235739367763244\n",
      "    val_log_marginal: -26.845792156886993\n",
      "Train Epoch: 58 [512/17352 (3%)] Loss: 17.050951\n",
      "Train Epoch: 58 [10257/17352 (59%)] Loss: -5.865362\n",
      "Train Epoch: 58 [17126/17352 (99%)] Loss: 41.029948\n",
      "    epoch          : 58\n",
      "    loss           : 22.367601999678072\n",
      "    val_loss       : 24.93540249714921\n",
      "    val_log_likelihood: 31.31305875021641\n",
      "    val_log_marginal: -17.759100195271483\n",
      "Train Epoch: 59 [512/17352 (3%)] Loss: 12.500490\n",
      "Train Epoch: 59 [10426/17352 (60%)] Loss: -12.484166\n",
      "Train Epoch: 59 [16887/17352 (97%)] Loss: -17.836897\n",
      "    epoch          : 59\n",
      "    loss           : 18.769278036963545\n",
      "    val_loss       : 24.301480717085223\n",
      "    val_log_likelihood: 39.827076662632976\n",
      "    val_log_marginal: -12.692380181309677\n",
      "Train Epoch: 60 [512/17352 (3%)] Loss: 8.690797\n",
      "Train Epoch: 60 [10639/17352 (61%)] Loss: 67.891952\n",
      "Train Epoch: 60 [17106/17352 (99%)] Loss: -40.113566\n",
      "    epoch          : 60\n",
      "    loss           : 15.315714595566405\n",
      "    val_loss       : 32.45078385003596\n",
      "    val_log_likelihood: 47.08960779571214\n",
      "    val_log_marginal: -20.41642557482549\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch60.pth ...\n",
      "Train Epoch: 61 [512/17352 (3%)] Loss: 18.644300\n",
      "Train Epoch: 61 [9778/17352 (56%)] Loss: -20.459102\n",
      "Train Epoch: 61 [16923/17352 (98%)] Loss: 28.197855\n",
      "    epoch          : 61\n",
      "    loss           : 10.420763407429481\n",
      "    val_loss       : 11.273069240832152\n",
      "    val_log_likelihood: 56.29919830506795\n",
      "    val_log_marginal: -2.875943603253937\n",
      "Train Epoch: 62 [512/17352 (3%)] Loss: -4.387681\n",
      "Train Epoch: 62 [10783/17352 (62%)] Loss: 70.230477\n",
      "Train Epoch: 62 [16923/17352 (98%)] Loss: 82.900513\n",
      "    epoch          : 62\n",
      "    loss           : 5.603439291531063\n",
      "    val_loss       : 26.450455329954764\n",
      "    val_log_likelihood: 57.08134032237009\n",
      "    val_log_marginal: -18.079365753076413\n",
      "Train Epoch: 63 [512/17352 (3%)] Loss: 5.785251\n",
      "Train Epoch: 63 [10198/17352 (59%)] Loss: -29.763041\n",
      "Train Epoch: 63 [16957/17352 (98%)] Loss: 77.019540\n",
      "    epoch          : 63\n",
      "    loss           : 6.107346896737854\n",
      "    val_loss       : 5.038038768595325\n",
      "    val_log_likelihood: 68.84454727179659\n",
      "    val_log_marginal: 2.409867127094111\n",
      "Train Epoch: 64 [512/17352 (3%)] Loss: -15.322399\n",
      "Train Epoch: 64 [10478/17352 (60%)] Loss: -41.674825\n",
      "Train Epoch: 64 [16992/17352 (98%)] Loss: -13.962027\n",
      "    epoch          : 64\n",
      "    loss           : -5.229698197738179\n",
      "    val_loss       : 2.04080242059518\n",
      "    val_log_likelihood: 69.1540012809582\n",
      "    val_log_marginal: 9.205115641441791\n",
      "Train Epoch: 65 [512/17352 (3%)] Loss: -22.918859\n",
      "Train Epoch: 65 [10656/17352 (61%)] Loss: 4.066299\n",
      "Train Epoch: 65 [16882/17352 (97%)] Loss: -50.428696\n",
      "    epoch          : 65\n",
      "    loss           : -10.946265937971734\n",
      "    val_loss       : -5.2401346342532324\n",
      "    val_log_likelihood: 90.13381326640898\n",
      "    val_log_marginal: 12.269277965635895\n",
      "Train Epoch: 66 [512/17352 (3%)] Loss: -18.874413\n",
      "Train Epoch: 66 [10770/17352 (62%)] Loss: 20.914220\n",
      "Train Epoch: 66 [17106/17352 (99%)] Loss: -42.980513\n",
      "    epoch          : 66\n",
      "    loss           : -11.156227294200876\n",
      "    val_loss       : 15.399456627048805\n",
      "    val_log_likelihood: 90.86542983275588\n",
      "    val_log_marginal: -0.08613002829747582\n",
      "Train Epoch: 67 [512/17352 (3%)] Loss: -14.282163\n",
      "Train Epoch: 67 [10488/17352 (60%)] Loss: 67.448181\n",
      "Train Epoch: 67 [17263/17352 (99%)] Loss: -22.534218\n",
      "    epoch          : 67\n",
      "    loss           : -8.322875269277471\n",
      "    val_loss       : -6.49169531404292\n",
      "    val_log_likelihood: 95.77595413195068\n",
      "    val_log_marginal: 14.604890854049877\n",
      "Train Epoch: 68 [512/17352 (3%)] Loss: -19.916676\n",
      "Train Epoch: 68 [10649/17352 (61%)] Loss: 44.864425\n",
      "Train Epoch: 68 [16922/17352 (98%)] Loss: -32.554876\n",
      "    epoch          : 68\n",
      "    loss           : -23.106144778276096\n",
      "    val_loss       : -17.42803868133318\n",
      "    val_log_likelihood: 109.32861165537985\n",
      "    val_log_marginal: 27.415476211074477\n",
      "Train Epoch: 69 [512/17352 (3%)] Loss: -34.369156\n",
      "Train Epoch: 69 [10359/17352 (60%)] Loss: -99.941569\n",
      "Train Epoch: 69 [17049/17352 (98%)] Loss: -103.561342\n",
      "    epoch          : 69\n",
      "    loss           : -26.020072887065513\n",
      "    val_loss       : -17.696345723623498\n",
      "    val_log_likelihood: 105.57297440691859\n",
      "    val_log_marginal: 27.22805227229204\n",
      "Train Epoch: 70 [512/17352 (3%)] Loss: -34.711056\n",
      "Train Epoch: 70 [10134/17352 (58%)] Loss: -70.107427\n",
      "Train Epoch: 70 [17126/17352 (99%)] Loss: -1.125134\n",
      "    epoch          : 70\n",
      "    loss           : -29.304506187568855\n",
      "    val_loss       : 38.66505979523693\n",
      "    val_log_likelihood: 118.27947535241549\n",
      "    val_log_marginal: -28.23354886732494\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch70.pth ...\n",
      "Train Epoch: 71 [512/17352 (3%)] Loss: 28.656628\n",
      "Train Epoch: 71 [10138/17352 (58%)] Loss: -50.211043\n",
      "Train Epoch: 71 [16934/17352 (98%)] Loss: -25.764708\n",
      "    epoch          : 71\n",
      "    loss           : -30.126413852680777\n",
      "    val_loss       : -35.11262263445631\n",
      "    val_log_likelihood: 125.6210315284317\n",
      "    val_log_marginal: 44.82792211454929\n",
      "Train Epoch: 72 [512/17352 (3%)] Loss: -49.373318\n",
      "Train Epoch: 72 [10304/17352 (59%)] Loss: -73.155244\n",
      "Train Epoch: 72 [17335/17352 (100%)] Loss: 56.996615\n",
      "    epoch          : 72\n",
      "    loss           : -38.50005584648272\n",
      "    val_loss       : 8.03470126988312\n",
      "    val_log_likelihood: 127.89505919631706\n",
      "    val_log_marginal: 5.57326176006394\n",
      "Train Epoch: 73 [512/17352 (3%)] Loss: -12.754893\n",
      "Train Epoch: 73 [10020/17352 (58%)] Loss: -6.841908\n",
      "Train Epoch: 73 [17090/17352 (98%)] Loss: 66.389499\n",
      "    epoch          : 73\n",
      "    loss           : -3.9652659629371887\n",
      "    val_loss       : -5.876550362658592\n",
      "    val_log_likelihood: 121.12966042460835\n",
      "    val_log_marginal: 16.832759268394113\n",
      "Train Epoch: 74 [512/17352 (3%)] Loss: 62.535538\n",
      "Train Epoch: 74 [10640/17352 (61%)] Loss: -5.309386\n",
      "Train Epoch: 74 [17016/17352 (98%)] Loss: 0.889991\n",
      "    epoch          : 74\n",
      "    loss           : -14.699455939785162\n",
      "    val_loss       : -15.345212813462142\n",
      "    val_log_likelihood: 118.48047507390584\n",
      "    val_log_marginal: 28.902506419011445\n",
      "Train Epoch: 75 [512/17352 (3%)] Loss: -32.361065\n",
      "Train Epoch: 75 [10363/17352 (60%)] Loss: -33.736241\n",
      "Train Epoch: 75 [17253/17352 (99%)] Loss: -139.599480\n",
      "    epoch          : 75\n",
      "    loss           : -33.01085169227051\n",
      "    val_loss       : -31.963170993296277\n",
      "    val_log_likelihood: 147.2159888988749\n",
      "    val_log_marginal: 45.754091410993084\n",
      "Train Epoch: 76 [512/17352 (3%)] Loss: -62.365875\n",
      "Train Epoch: 76 [9968/17352 (57%)] Loss: -9.786806\n",
      "Train Epoch: 76 [16887/17352 (97%)] Loss: 1.798326\n",
      "    epoch          : 76\n",
      "    loss           : -53.96225147999604\n",
      "    val_loss       : -50.11562318761157\n",
      "    val_log_likelihood: 153.8370667178479\n",
      "    val_log_marginal: 60.74764062661823\n",
      "Train Epoch: 77 [512/17352 (3%)] Loss: -74.317612\n",
      "Train Epoch: 77 [10567/17352 (61%)] Loss: -31.180356\n",
      "Train Epoch: 77 [16883/17352 (97%)] Loss: -96.748919\n",
      "    epoch          : 77\n",
      "    loss           : -62.42044093567781\n",
      "    val_loss       : -58.19895970228097\n",
      "    val_log_likelihood: 165.66419111651234\n",
      "    val_log_marginal: 70.01047327127507\n",
      "Train Epoch: 78 [512/17352 (3%)] Loss: -67.507812\n",
      "Train Epoch: 78 [11032/17352 (64%)] Loss: -75.836045\n",
      "Train Epoch: 78 [17090/17352 (98%)] Loss: -25.991509\n",
      "    epoch          : 78\n",
      "    loss           : -64.72733603168318\n",
      "    val_loss       : -62.202577432858355\n",
      "    val_log_likelihood: 173.8227438591425\n",
      "    val_log_marginal: 74.23929806140607\n",
      "Train Epoch: 79 [512/17352 (3%)] Loss: -83.667923\n",
      "Train Epoch: 79 [10526/17352 (61%)] Loss: -1.723925\n",
      "Train Epoch: 79 [17064/17352 (98%)] Loss: -98.593314\n",
      "    epoch          : 79\n",
      "    loss           : -67.23398536412408\n",
      "    val_loss       : -64.78280766774559\n",
      "    val_log_likelihood: 177.316469359569\n",
      "    val_log_marginal: 71.75212123268645\n",
      "Train Epoch: 80 [512/17352 (3%)] Loss: 29.985870\n",
      "Train Epoch: 80 [10405/17352 (60%)] Loss: -98.907150\n",
      "Train Epoch: 80 [17044/17352 (98%)] Loss: -37.757233\n",
      "    epoch          : 80\n",
      "    loss           : -61.05598617698486\n",
      "    val_loss       : -70.33401557628649\n",
      "    val_log_likelihood: 189.64462622081163\n",
      "    val_log_marginal: 80.31195815442207\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch80.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 81 [512/17352 (3%)] Loss: -85.404312\n",
      "Train Epoch: 81 [10585/17352 (61%)] Loss: -61.736380\n",
      "Train Epoch: 81 [17143/17352 (99%)] Loss: -68.357210\n",
      "    epoch          : 81\n",
      "    loss           : -62.19915443991454\n",
      "    val_loss       : -25.375048185282797\n",
      "    val_log_likelihood: 176.98024399203015\n",
      "    val_log_marginal: 45.049847334138626\n",
      "Train Epoch: 82 [512/17352 (3%)] Loss: -56.001343\n",
      "Train Epoch: 82 [10051/17352 (58%)] Loss: -79.314990\n",
      "Train Epoch: 82 [16988/17352 (98%)] Loss: -40.006433\n",
      "    epoch          : 82\n",
      "    loss           : -67.53548414237069\n",
      "    val_loss       : -64.25576724008188\n",
      "    val_log_likelihood: 199.70739586105515\n",
      "    val_log_marginal: 78.19890081308687\n",
      "Train Epoch: 83 [512/17352 (3%)] Loss: -99.959854\n",
      "Train Epoch: 83 [10043/17352 (58%)] Loss: -113.728045\n",
      "Train Epoch: 83 [16988/17352 (98%)] Loss: -30.711488\n",
      "    epoch          : 83\n",
      "    loss           : -79.00626417222193\n",
      "    val_loss       : -70.80308829454918\n",
      "    val_log_likelihood: 196.70879677415476\n",
      "    val_log_marginal: 82.61048070397146\n",
      "Train Epoch: 84 [512/17352 (3%)] Loss: -106.517052\n",
      "Train Epoch: 84 [10188/17352 (59%)] Loss: -60.975970\n",
      "Train Epoch: 84 [17277/17352 (100%)] Loss: -43.711546\n",
      "    epoch          : 84\n",
      "    loss           : -84.25059070315639\n",
      "    val_loss       : -63.688128836890904\n",
      "    val_log_likelihood: 215.6159941625577\n",
      "    val_log_marginal: 75.73067200755804\n",
      "Train Epoch: 85 [512/17352 (3%)] Loss: -102.710152\n",
      "Train Epoch: 85 [10404/17352 (60%)] Loss: -111.554541\n",
      "Train Epoch: 85 [16958/17352 (98%)] Loss: -46.254659\n",
      "    epoch          : 85\n",
      "    loss           : -89.36129620726378\n",
      "    val_loss       : -81.18287004866895\n",
      "    val_log_likelihood: 221.58564153010062\n",
      "    val_log_marginal: 94.72633950121916\n",
      "Train Epoch: 86 [512/17352 (3%)] Loss: -110.763702\n",
      "Train Epoch: 86 [10360/17352 (60%)] Loss: -130.506654\n",
      "Train Epoch: 86 [16934/17352 (98%)] Loss: -49.576111\n",
      "    epoch          : 86\n",
      "    loss           : -90.12127132494173\n",
      "    val_loss       : -76.07023326238826\n",
      "    val_log_likelihood: 227.11610129446922\n",
      "    val_log_marginal: 87.87479146830695\n",
      "Train Epoch: 87 [512/17352 (3%)] Loss: -111.092842\n",
      "Train Epoch: 87 [10322/17352 (59%)] Loss: 13.494838\n",
      "Train Epoch: 87 [17335/17352 (100%)] Loss: -130.466929\n",
      "    epoch          : 87\n",
      "    loss           : -96.09906621386116\n",
      "    val_loss       : -40.28198343615825\n",
      "    val_log_likelihood: 238.6705517649603\n",
      "    val_log_marginal: 56.57554378405568\n",
      "Train Epoch: 88 [512/17352 (3%)] Loss: -68.907135\n",
      "Train Epoch: 88 [9941/17352 (57%)] Loss: -76.116833\n",
      "Train Epoch: 88 [17253/17352 (99%)] Loss: 1.404803\n",
      "    epoch          : 88\n",
      "    loss           : -85.74526699637097\n",
      "    val_loss       : -6.395943237685653\n",
      "    val_log_likelihood: 223.41257869489257\n",
      "    val_log_marginal: 37.54305965038918\n",
      "Train Epoch: 89 [512/17352 (3%)] Loss: -48.782215\n",
      "Train Epoch: 89 [10528/17352 (61%)] Loss: -137.787999\n",
      "Train Epoch: 89 [17253/17352 (99%)] Loss: -126.306341\n",
      "    epoch          : 89\n",
      "    loss           : -83.08692569702848\n",
      "    val_loss       : -72.37225152073773\n",
      "    val_log_likelihood: 230.545298150648\n",
      "    val_log_marginal: 92.35318341293681\n",
      "Train Epoch: 90 [512/17352 (3%)] Loss: -106.776337\n",
      "Train Epoch: 90 [10057/17352 (58%)] Loss: -68.297959\n",
      "Train Epoch: 90 [16988/17352 (98%)] Loss: -185.305406\n",
      "    epoch          : 90\n",
      "    loss           : -101.77879904739483\n",
      "    val_loss       : -69.20007097275574\n",
      "    val_log_likelihood: 258.2711111664888\n",
      "    val_log_marginal: 87.14901898720714\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch90.pth ...\n",
      "Train Epoch: 91 [512/17352 (3%)] Loss: 19.744989\n",
      "Train Epoch: 91 [10525/17352 (61%)] Loss: -2.316642\n",
      "Train Epoch: 91 [17133/17352 (99%)] Loss: -40.825297\n",
      "    epoch          : 91\n",
      "    loss           : -103.6036966054367\n",
      "    val_loss       : -92.20776916358128\n",
      "    val_log_likelihood: 263.81575371031596\n",
      "    val_log_marginal: 115.89856754848104\n",
      "Train Epoch: 92 [512/17352 (3%)] Loss: -27.506403\n",
      "Train Epoch: 92 [10194/17352 (59%)] Loss: -194.843392\n",
      "Train Epoch: 92 [16988/17352 (98%)] Loss: -130.939757\n",
      "    epoch          : 92\n",
      "    loss           : -118.75048819411641\n",
      "    val_loss       : -119.03158486407972\n",
      "    val_log_likelihood: 275.6145124618784\n",
      "    val_log_marginal: 132.2721640951073\n",
      "Train Epoch: 93 [512/17352 (3%)] Loss: -144.572296\n",
      "Train Epoch: 93 [10707/17352 (62%)] Loss: -97.922449\n",
      "Train Epoch: 93 [17277/17352 (100%)] Loss: -131.982910\n",
      "    epoch          : 93\n",
      "    loss           : -132.55612313705885\n",
      "    val_loss       : -120.70913324780284\n",
      "    val_log_likelihood: 284.3257037923915\n",
      "    val_log_marginal: 133.18237962876498\n",
      "Train Epoch: 94 [512/17352 (3%)] Loss: -143.785812\n",
      "Train Epoch: 94 [10263/17352 (59%)] Loss: -125.603161\n",
      "Train Epoch: 94 [17277/17352 (100%)] Loss: -117.952962\n",
      "    epoch          : 94\n",
      "    loss           : -138.0385739396207\n",
      "    val_loss       : -126.64792873747245\n",
      "    val_log_likelihood: 296.5736052260356\n",
      "    val_log_marginal: 140.45194416253113\n",
      "Train Epoch: 95 [512/17352 (3%)] Loss: -154.605560\n",
      "Train Epoch: 95 [10042/17352 (58%)] Loss: -104.537119\n",
      "Train Epoch: 95 [16923/17352 (98%)] Loss: -66.710226\n",
      "    epoch          : 95\n",
      "    loss           : -100.84918088278539\n",
      "    val_loss       : -66.3846304891223\n",
      "    val_log_likelihood: 268.81140143820585\n",
      "    val_log_marginal: 101.17490899508942\n",
      "Train Epoch: 96 [512/17352 (3%)] Loss: -29.491596\n",
      "Train Epoch: 96 [10819/17352 (62%)] Loss: -29.345311\n",
      "Train Epoch: 96 [17126/17352 (99%)] Loss: -164.667686\n",
      "    epoch          : 96\n",
      "    loss           : -65.62563876745962\n",
      "    val_loss       : -65.59103033484318\n",
      "    val_log_likelihood: 218.52374393393248\n",
      "    val_log_marginal: 94.95494021595673\n",
      "Train Epoch: 97 [512/17352 (3%)] Loss: -97.985512\n",
      "Train Epoch: 97 [9868/17352 (57%)] Loss: -88.954136\n",
      "Train Epoch: 97 [16957/17352 (98%)] Loss: -185.129100\n",
      "    epoch          : 97\n",
      "    loss           : -110.22759924095368\n",
      "    val_loss       : -119.25990564310575\n",
      "    val_log_likelihood: 288.09497003306495\n",
      "    val_log_marginal: 137.5159338508152\n",
      "Train Epoch: 98 [512/17352 (3%)] Loss: -165.020233\n",
      "Train Epoch: 98 [10510/17352 (61%)] Loss: -131.429572\n",
      "Train Epoch: 98 [16939/17352 (98%)] Loss: -163.000140\n",
      "    epoch          : 98\n",
      "    loss           : -139.67671785657046\n",
      "    val_loss       : -135.14344118772178\n",
      "    val_log_likelihood: 299.1225236657636\n",
      "    val_log_marginal: 151.41985140604322\n",
      "Train Epoch: 99 [512/17352 (3%)] Loss: -175.789215\n",
      "Train Epoch: 99 [10488/17352 (60%)] Loss: -196.786776\n",
      "Train Epoch: 99 [17090/17352 (98%)] Loss: -111.251964\n",
      "    epoch          : 99\n",
      "    loss           : -149.85395452054283\n",
      "    val_loss       : -138.00111047982313\n",
      "    val_log_likelihood: 310.94903096536063\n",
      "    val_log_marginal: 153.8412712969044\n",
      "Train Epoch: 100 [512/17352 (3%)] Loss: -154.774231\n",
      "Train Epoch: 100 [10541/17352 (61%)] Loss: -117.418273\n",
      "Train Epoch: 100 [16878/17352 (97%)] Loss: -72.097586\n",
      "    epoch          : 100\n",
      "    loss           : -129.47070755161423\n",
      "    val_loss       : -36.74142147681568\n",
      "    val_log_likelihood: 306.3052073100516\n",
      "    val_log_marginal: 69.64390013397262\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch100.pth ...\n",
      "Train Epoch: 101 [512/17352 (3%)] Loss: -2.080091\n",
      "Train Epoch: 101 [10051/17352 (58%)] Loss: -33.770654\n",
      "Train Epoch: 101 [17108/17352 (99%)] Loss: -185.601453\n",
      "    epoch          : 101\n",
      "    loss           : -112.72410958375022\n",
      "    val_loss       : -126.15245999706629\n",
      "    val_log_likelihood: 301.9601888127967\n",
      "    val_log_marginal: 145.54616004077735\n",
      "Train Epoch: 102 [512/17352 (3%)] Loss: -155.493500\n",
      "Train Epoch: 102 [10645/17352 (61%)] Loss: -53.779398\n",
      "Train Epoch: 102 [17335/17352 (100%)] Loss: -252.041143\n",
      "    epoch          : 102\n",
      "    loss           : -153.51609579455445\n",
      "    val_loss       : -146.68982729856643\n",
      "    val_log_likelihood: 328.0320243372882\n",
      "    val_log_marginal: 165.92326176686552\n",
      "Train Epoch: 103 [512/17352 (3%)] Loss: -157.927170\n",
      "Train Epoch: 103 [10548/17352 (61%)] Loss: -145.835438\n",
      "Train Epoch: 103 [17124/17352 (99%)] Loss: -183.783868\n",
      "    epoch          : 103\n",
      "    loss           : -169.55330643632604\n",
      "    val_loss       : -159.30625866923563\n",
      "    val_log_likelihood: 333.0025871556222\n",
      "    val_log_marginal: 173.51184797011874\n",
      "Train Epoch: 104 [512/17352 (3%)] Loss: -186.652191\n",
      "Train Epoch: 104 [10545/17352 (61%)] Loss: -241.523188\n",
      "Train Epoch: 104 [17016/17352 (98%)] Loss: -146.060872\n",
      "    epoch          : 104\n",
      "    loss           : -171.84409476695424\n",
      "    val_loss       : -168.29138647633948\n",
      "    val_log_likelihood: 346.4889657839446\n",
      "    val_log_marginal: 183.93830078317225\n",
      "Train Epoch: 105 [512/17352 (3%)] Loss: -205.551270\n",
      "Train Epoch: 105 [10745/17352 (62%)] Loss: -235.297943\n",
      "Train Epoch: 105 [16878/17352 (97%)] Loss: -188.806493\n",
      "    epoch          : 105\n",
      "    loss           : -177.85830043012834\n",
      "    val_loss       : -146.4255928450308\n",
      "    val_log_likelihood: 355.18287588650463\n",
      "    val_log_marginal: 168.18269183626094\n",
      "Train Epoch: 106 [512/17352 (3%)] Loss: -193.768829\n",
      "Train Epoch: 106 [10049/17352 (58%)] Loss: -235.195331\n",
      "Train Epoch: 106 [17101/17352 (99%)] Loss: 44.767014\n",
      "    epoch          : 106\n",
      "    loss           : -138.04887972779832\n",
      "    val_loss       : 29.083946664678468\n",
      "    val_log_likelihood: 307.9782653091657\n",
      "    val_log_marginal: 5.533201930729868\n",
      "Train Epoch: 107 [512/17352 (3%)] Loss: -6.292565\n",
      "Train Epoch: 107 [10503/17352 (61%)] Loss: -23.576657\n",
      "Train Epoch: 107 [16988/17352 (98%)] Loss: -125.048735\n",
      "    epoch          : 107\n",
      "    loss           : -120.59039226301296\n",
      "    val_loss       : -147.8970345813431\n",
      "    val_log_likelihood: 327.8482364884741\n",
      "    val_log_marginal: 171.49392679512192\n",
      "Train Epoch: 108 [512/17352 (3%)] Loss: -165.068024\n",
      "Train Epoch: 108 [9692/17352 (56%)] Loss: -229.517483\n",
      "Train Epoch: 108 [16883/17352 (97%)] Loss: -264.873141\n",
      "    epoch          : 108\n",
      "    loss           : -180.6903346811417\n",
      "    val_loss       : -180.4226342251611\n",
      "    val_log_likelihood: 360.4911930124162\n",
      "    val_log_marginal: 198.58005984906518\n",
      "Train Epoch: 109 [512/17352 (3%)] Loss: -236.866013\n",
      "Train Epoch: 109 [10711/17352 (62%)] Loss: -121.756910\n",
      "Train Epoch: 109 [16934/17352 (98%)] Loss: -136.357672\n",
      "    epoch          : 109\n",
      "    loss           : -201.01371158367812\n",
      "    val_loss       : -180.65611734207462\n",
      "    val_log_likelihood: 369.949124484701\n",
      "    val_log_marginal: 193.97327460381916\n",
      "Train Epoch: 110 [512/17352 (3%)] Loss: -205.536499\n",
      "Train Epoch: 110 [9894/17352 (57%)] Loss: -170.881866\n",
      "Train Epoch: 110 [16878/17352 (97%)] Loss: -258.345076\n",
      "    epoch          : 110\n",
      "    loss           : -200.56335917728626\n",
      "    val_loss       : -197.95807479838754\n",
      "    val_log_likelihood: 382.8422114143251\n",
      "    val_log_marginal: 214.6298904607944\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch110.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 111 [512/17352 (3%)] Loss: -245.305328\n",
      "Train Epoch: 111 [10649/17352 (61%)] Loss: -179.341471\n",
      "Train Epoch: 111 [17064/17352 (98%)] Loss: -72.869380\n",
      "    epoch          : 111\n",
      "    loss           : -212.0372529769705\n",
      "    val_loss       : -204.69042319812885\n",
      "    val_log_likelihood: 400.1673411458888\n",
      "    val_log_marginal: 223.66455402470282\n",
      "Train Epoch: 112 [512/17352 (3%)] Loss: -217.959991\n",
      "Train Epoch: 112 [10345/17352 (60%)] Loss: -179.144120\n",
      "Train Epoch: 112 [16887/17352 (97%)] Loss: -260.705658\n",
      "    epoch          : 112\n",
      "    loss           : -224.12628554409304\n",
      "    val_loss       : -218.17713334208523\n",
      "    val_log_likelihood: 407.76573607188254\n",
      "    val_log_marginal: 232.11797222946188\n",
      "Train Epoch: 113 [512/17352 (3%)] Loss: -259.824158\n",
      "Train Epoch: 113 [10609/17352 (61%)] Loss: -194.099098\n",
      "Train Epoch: 113 [17106/17352 (99%)] Loss: -342.742737\n",
      "    epoch          : 113\n",
      "    loss           : -229.60970413114157\n",
      "    val_loss       : -202.97160327423595\n",
      "    val_log_likelihood: 408.7962147054347\n",
      "    val_log_marginal: 221.64303353500873\n",
      "Train Epoch: 114 [512/17352 (3%)] Loss: -247.818024\n",
      "Train Epoch: 114 [9745/17352 (56%)] Loss: -257.730596\n",
      "Train Epoch: 114 [17044/17352 (98%)] Loss: -148.266299\n",
      "    epoch          : 114\n",
      "    loss           : -192.18058961507862\n",
      "    val_loss       : -172.90409599502823\n",
      "    val_log_likelihood: 375.4445165052909\n",
      "    val_log_marginal: 193.5212605990023\n",
      "Train Epoch: 115 [512/17352 (3%)] Loss: -212.273895\n",
      "Train Epoch: 115 [10369/17352 (60%)] Loss: -145.628682\n",
      "Train Epoch: 115 [16958/17352 (98%)] Loss: -252.240725\n",
      "    epoch          : 115\n",
      "    loss           : -207.93927606858668\n",
      "    val_loss       : -206.15854044467042\n",
      "    val_log_likelihood: 417.70459796268113\n",
      "    val_log_marginal: 234.2722308884371\n",
      "Train Epoch: 116 [512/17352 (3%)] Loss: -258.969666\n",
      "Train Epoch: 116 [10351/17352 (60%)] Loss: -88.716919\n",
      "Train Epoch: 116 [17106/17352 (99%)] Loss: -240.313891\n",
      "    epoch          : 116\n",
      "    loss           : -231.11830362934535\n",
      "    val_loss       : -225.02035679984579\n",
      "    val_log_likelihood: 424.148963306775\n",
      "    val_log_marginal: 239.75070377350627\n",
      "Train Epoch: 117 [512/17352 (3%)] Loss: -272.593079\n",
      "Train Epoch: 117 [10312/17352 (59%)] Loss: -266.982992\n",
      "Train Epoch: 117 [17153/17352 (99%)] Loss: -311.067187\n",
      "    epoch          : 117\n",
      "    loss           : -240.99037147390055\n",
      "    val_loss       : -207.07700612215464\n",
      "    val_log_likelihood: 435.6932315062204\n",
      "    val_log_marginal: 232.15078622077394\n",
      "Train Epoch: 118 [512/17352 (3%)] Loss: -234.163300\n",
      "Train Epoch: 118 [9978/17352 (58%)] Loss: -283.508427\n",
      "Train Epoch: 118 [17124/17352 (99%)] Loss: -246.189960\n",
      "    epoch          : 118\n",
      "    loss           : -220.61399839410245\n",
      "    val_loss       : -176.25471083656046\n",
      "    val_log_likelihood: 417.755328019275\n",
      "    val_log_marginal: 206.07551173203296\n",
      "Train Epoch: 119 [512/17352 (3%)] Loss: -240.788193\n",
      "Train Epoch: 119 [10442/17352 (60%)] Loss: -175.139859\n",
      "Train Epoch: 119 [17090/17352 (98%)] Loss: -272.968888\n",
      "    epoch          : 119\n",
      "    loss           : -230.9567116825343\n",
      "    val_loss       : -203.8177082568177\n",
      "    val_log_likelihood: 411.1321492478463\n",
      "    val_log_marginal: 224.67600590768495\n",
      "Train Epoch: 120 [512/17352 (3%)] Loss: -246.751251\n",
      "Train Epoch: 120 [9988/17352 (58%)] Loss: -294.328778\n",
      "Train Epoch: 120 [17064/17352 (98%)] Loss: -186.348193\n",
      "    epoch          : 120\n",
      "    loss           : -235.49508660758735\n",
      "    val_loss       : -229.78147064076248\n",
      "    val_log_likelihood: 440.8650768806555\n",
      "    val_log_marginal: 253.78052201249247\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch120.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 121 [512/17352 (3%)] Loss: -267.472717\n",
      "Train Epoch: 121 [9931/17352 (57%)] Loss: -271.626272\n",
      "Train Epoch: 121 [16887/17352 (97%)] Loss: -309.029264\n",
      "    epoch          : 121\n",
      "    loss           : -255.3804316905705\n",
      "    val_loss       : -244.72214924546594\n",
      "    val_log_likelihood: 460.3684262953983\n",
      "    val_log_marginal: 270.6140809278197\n",
      "Train Epoch: 122 [512/17352 (3%)] Loss: -293.500610\n",
      "Train Epoch: 122 [10309/17352 (59%)] Loss: -307.580787\n",
      "Train Epoch: 122 [17049/17352 (98%)] Loss: -264.198272\n",
      "    epoch          : 122\n",
      "    loss           : -271.7669428126581\n",
      "    val_loss       : -257.6159735002149\n",
      "    val_log_likelihood: 462.7741735991918\n",
      "    val_log_marginal: 271.1751596831071\n",
      "Train Epoch: 123 [512/17352 (3%)] Loss: -300.907593\n",
      "Train Epoch: 123 [10345/17352 (60%)] Loss: -237.178037\n",
      "Train Epoch: 123 [16934/17352 (98%)] Loss: -399.517724\n",
      "    epoch          : 123\n",
      "    loss           : -279.99737386202736\n",
      "    val_loss       : -267.1067403780411\n",
      "    val_log_likelihood: 472.762228890863\n",
      "    val_log_marginal: 283.4287524898771\n",
      "Train Epoch: 124 [512/17352 (3%)] Loss: -301.606018\n",
      "Train Epoch: 124 [10580/17352 (61%)] Loss: -352.715791\n",
      "Train Epoch: 124 [17133/17352 (99%)] Loss: -225.655838\n",
      "    epoch          : 124\n",
      "    loss           : -273.3029888918182\n",
      "    val_loss       : -245.6818217567016\n",
      "    val_log_likelihood: 475.2020899202363\n",
      "    val_log_marginal: 265.69474006100734\n",
      "Train Epoch: 125 [512/17352 (3%)] Loss: -295.346802\n",
      "Train Epoch: 125 [10641/17352 (61%)] Loss: -234.404362\n",
      "Train Epoch: 125 [16883/17352 (97%)] Loss: -327.653416\n",
      "    epoch          : 125\n",
      "    loss           : -286.6179718245247\n",
      "    val_loss       : -272.6133296901593\n",
      "    val_log_likelihood: 491.0799258996384\n",
      "    val_log_marginal: 294.9177383278513\n",
      "Train Epoch: 126 [512/17352 (3%)] Loss: -346.928131\n",
      "Train Epoch: 126 [10212/17352 (59%)] Loss: -343.562023\n",
      "Train Epoch: 126 [16934/17352 (98%)] Loss: -225.821002\n",
      "    epoch          : 126\n",
      "    loss           : -265.23349599255465\n",
      "    val_loss       : -221.482121726879\n",
      "    val_log_likelihood: 466.66751042406406\n",
      "    val_log_marginal: 260.2151757122642\n",
      "Train Epoch: 127 [512/17352 (3%)] Loss: -271.242218\n",
      "Train Epoch: 127 [10629/17352 (61%)] Loss: -316.384019\n",
      "Train Epoch: 127 [16958/17352 (98%)] Loss: -187.453125\n",
      "    epoch          : 127\n",
      "    loss           : -258.97086235416566\n",
      "    val_loss       : -274.12518417002804\n",
      "    val_log_likelihood: 487.90244650325894\n",
      "    val_log_marginal: 295.0001736895337\n",
      "Train Epoch: 128 [512/17352 (3%)] Loss: -318.905457\n",
      "Train Epoch: 128 [10401/17352 (60%)] Loss: -345.031577\n",
      "Train Epoch: 128 [16957/17352 (98%)] Loss: -311.042025\n",
      "    epoch          : 128\n",
      "    loss           : -299.08023563826833\n",
      "    val_loss       : -289.64979406069847\n",
      "    val_log_likelihood: 503.1235465290141\n",
      "    val_log_marginal: 306.5790460140508\n",
      "Train Epoch: 129 [512/17352 (3%)] Loss: -336.850403\n",
      "Train Epoch: 129 [9867/17352 (57%)] Loss: -266.939402\n",
      "Train Epoch: 129 [17277/17352 (100%)] Loss: -253.799934\n",
      "    epoch          : 129\n",
      "    loss           : -305.9974613134069\n",
      "    val_loss       : -287.32356393041835\n",
      "    val_log_likelihood: 514.183062528708\n",
      "    val_log_marginal: 308.89114673142257\n",
      "Train Epoch: 130 [512/17352 (3%)] Loss: -343.929260\n",
      "Train Epoch: 130 [10519/17352 (61%)] Loss: -236.539527\n",
      "Train Epoch: 130 [16957/17352 (98%)] Loss: -366.095098\n",
      "    epoch          : 130\n",
      "    loss           : -320.3675516095239\n",
      "    val_loss       : -282.8474932675632\n",
      "    val_log_likelihood: 521.7369602897584\n",
      "    val_log_marginal: 307.9597445189662\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch130.pth ...\n",
      "Train Epoch: 131 [512/17352 (3%)] Loss: -349.593628\n",
      "Train Epoch: 131 [10218/17352 (59%)] Loss: -390.091485\n",
      "Train Epoch: 131 [17126/17352 (99%)] Loss: -150.161044\n",
      "    epoch          : 131\n",
      "    loss           : -283.673638136534\n",
      "    val_loss       : -247.37421509305662\n",
      "    val_log_likelihood: 508.1882134462163\n",
      "    val_log_marginal: 272.69969588521525\n",
      "Train Epoch: 132 [512/17352 (3%)] Loss: -302.612885\n",
      "Train Epoch: 132 [10511/17352 (61%)] Loss: -302.970768\n",
      "Train Epoch: 132 [16923/17352 (98%)] Loss: -259.670833\n",
      "    epoch          : 132\n",
      "    loss           : -281.82330925220265\n",
      "    val_loss       : -198.26042715323428\n",
      "    val_log_likelihood: 509.8272880938872\n",
      "    val_log_marginal: 224.50165133088626\n",
      "Train Epoch: 133 [512/17352 (3%)] Loss: -272.999207\n",
      "Train Epoch: 133 [10281/17352 (59%)] Loss: -168.464822\n",
      "Train Epoch: 133 [17090/17352 (98%)] Loss: -266.905182\n",
      "    epoch          : 133\n",
      "    loss           : -161.70056187501422\n",
      "    val_loss       : -208.14786877749398\n",
      "    val_log_likelihood: 462.9287313938915\n",
      "    val_log_marginal: 239.84258690538397\n",
      "Train Epoch: 134 [512/17352 (3%)] Loss: -197.359863\n",
      "Train Epoch: 134 [10198/17352 (59%)] Loss: -271.244485\n",
      "Train Epoch: 134 [17106/17352 (99%)] Loss: -202.219790\n",
      "    epoch          : 134\n",
      "    loss           : -253.66892440321448\n",
      "    val_loss       : -271.96939164002583\n",
      "    val_log_likelihood: 505.52055458565223\n",
      "    val_log_marginal: 298.9473194047339\n",
      "Train Epoch: 135 [512/17352 (3%)] Loss: -328.703613\n",
      "Train Epoch: 135 [10224/17352 (59%)] Loss: -360.658017\n",
      "Train Epoch: 135 [17106/17352 (99%)] Loss: -401.090383\n",
      "    epoch          : 135\n",
      "    loss           : -310.47464420659065\n",
      "    val_loss       : -303.6346115974501\n",
      "    val_log_likelihood: 528.2170619743665\n",
      "    val_log_marginal: 326.8743380630786\n",
      "Train Epoch: 136 [512/17352 (3%)] Loss: -369.376465\n",
      "Train Epoch: 136 [10262/17352 (59%)] Loss: -114.349479\n",
      "Train Epoch: 136 [16882/17352 (97%)] Loss: -319.293945\n",
      "    epoch          : 136\n",
      "    loss           : -311.95798832647\n",
      "    val_loss       : -295.8038393325373\n",
      "    val_log_likelihood: 531.4461458652859\n",
      "    val_log_marginal: 321.0578280875252\n",
      "Train Epoch: 137 [512/17352 (3%)] Loss: -364.221863\n",
      "Train Epoch: 137 [10186/17352 (59%)] Loss: -347.423088\n",
      "Train Epoch: 137 [16958/17352 (98%)] Loss: -403.746928\n",
      "    epoch          : 137\n",
      "    loss           : -321.47724086800275\n",
      "    val_loss       : -310.3833127110453\n",
      "    val_log_likelihood: 534.5293714197907\n",
      "    val_log_marginal: 329.7071451868665\n",
      "Train Epoch: 138 [512/17352 (3%)] Loss: -369.877045\n",
      "Train Epoch: 138 [10462/17352 (60%)] Loss: -400.546831\n",
      "Train Epoch: 138 [17126/17352 (99%)] Loss: -357.207420\n",
      "    epoch          : 138\n",
      "    loss           : -329.81386356624216\n",
      "    val_loss       : -296.0152134279376\n",
      "    val_log_likelihood: 551.5055137046766\n",
      "    val_log_marginal: 331.08601259806863\n",
      "Train Epoch: 139 [512/17352 (3%)] Loss: -378.374237\n",
      "Train Epoch: 139 [9945/17352 (57%)] Loss: -385.941187\n",
      "Train Epoch: 139 [17090/17352 (98%)] Loss: -414.191290\n",
      "    epoch          : 139\n",
      "    loss           : -325.9431460682543\n",
      "    val_loss       : -312.47876957550903\n",
      "    val_log_likelihood: 547.739653528443\n",
      "    val_log_marginal: 334.8415189670803\n",
      "Train Epoch: 140 [512/17352 (3%)] Loss: -378.466492\n",
      "Train Epoch: 140 [10506/17352 (61%)] Loss: -397.711491\n",
      "Train Epoch: 140 [17124/17352 (99%)] Loss: -325.235297\n",
      "    epoch          : 140\n",
      "    loss           : -338.09561610232225\n",
      "    val_loss       : -294.86162437807144\n",
      "    val_log_likelihood: 556.8786812852993\n",
      "    val_log_marginal: 338.7244027654499\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch140.pth ...\n",
      "Train Epoch: 141 [512/17352 (3%)] Loss: -376.212036\n",
      "Train Epoch: 141 [9931/17352 (57%)] Loss: -435.583724\n",
      "Train Epoch: 141 [16878/17352 (97%)] Loss: -395.224235\n",
      "    epoch          : 141\n",
      "    loss           : -310.2276102607464\n",
      "    val_loss       : -295.20238685307345\n",
      "    val_log_likelihood: 541.5861801824956\n",
      "    val_log_marginal: 321.62760143713365\n",
      "Train Epoch: 142 [512/17352 (3%)] Loss: -342.917084\n",
      "Train Epoch: 142 [10641/17352 (61%)] Loss: -169.268952\n",
      "Train Epoch: 142 [16923/17352 (98%)] Loss: -453.300640\n",
      "    epoch          : 142\n",
      "    loss           : -333.5539146195257\n",
      "    val_loss       : -309.51341783824455\n",
      "    val_log_likelihood: 564.9556971503592\n",
      "    val_log_marginal: 332.0796846236396\n",
      "Train Epoch: 143 [512/17352 (3%)] Loss: -335.956909\n",
      "Train Epoch: 143 [10549/17352 (61%)] Loss: -408.791839\n",
      "Train Epoch: 143 [17253/17352 (99%)] Loss: -295.474667\n",
      "    epoch          : 143\n",
      "    loss           : -329.5617821756988\n",
      "    val_loss       : -45.877068237608775\n",
      "    val_log_likelihood: 549.6450864169641\n",
      "    val_log_marginal: 68.96585070358206\n",
      "Train Epoch: 144 [512/17352 (3%)] Loss: -73.195312\n",
      "Train Epoch: 144 [10288/17352 (59%)] Loss: -219.494680\n",
      "Train Epoch: 144 [16934/17352 (98%)] Loss: -416.182148\n",
      "    epoch          : 144\n",
      "    loss           : -242.31914360563798\n",
      "    val_loss       : -284.24061620923806\n",
      "    val_log_likelihood: 541.1070443510606\n",
      "    val_log_marginal: 312.7563361705325\n",
      "Train Epoch: 145 [512/17352 (3%)] Loss: -343.228149\n",
      "Train Epoch: 145 [10253/17352 (59%)] Loss: -442.800293\n",
      "Train Epoch: 145 [17153/17352 (99%)] Loss: -431.991488\n",
      "    epoch          : 145\n",
      "    loss           : -321.605658239498\n",
      "    val_loss       : -303.6121607239873\n",
      "    val_log_likelihood: 564.5254883392322\n",
      "    val_log_marginal: 336.33643069807755\n",
      "Train Epoch: 146 [512/17352 (3%)] Loss: -178.307220\n",
      "Train Epoch: 146 [10403/17352 (60%)] Loss: -382.579469\n",
      "Train Epoch: 146 [16988/17352 (98%)] Loss: -459.883248\n",
      "    epoch          : 146\n",
      "    loss           : -353.80539019369144\n",
      "    val_loss       : -342.47919102568557\n",
      "    val_log_likelihood: 578.8879220271449\n",
      "    val_log_marginal: 364.26930759024543\n",
      "Train Epoch: 147 [512/17352 (3%)] Loss: -401.619324\n",
      "Train Epoch: 147 [10194/17352 (59%)] Loss: -245.701106\n",
      "Train Epoch: 147 [17133/17352 (99%)] Loss: -432.893010\n",
      "    epoch          : 147\n",
      "    loss           : -376.6528838242082\n",
      "    val_loss       : -344.0246712304905\n",
      "    val_log_likelihood: 596.1362437380272\n",
      "    val_log_marginal: 372.1009616672849\n",
      "Train Epoch: 148 [512/17352 (3%)] Loss: -275.972473\n",
      "Train Epoch: 148 [10370/17352 (60%)] Loss: -482.909017\n",
      "Train Epoch: 148 [16923/17352 (98%)] Loss: -442.740169\n",
      "    epoch          : 148\n",
      "    loss           : -388.1639631341287\n",
      "    val_loss       : -364.86056656422704\n",
      "    val_log_likelihood: 602.9874693698844\n",
      "    val_log_marginal: 383.2416649465753\n",
      "Train Epoch: 149 [512/17352 (3%)] Loss: -431.284973\n",
      "Train Epoch: 149 [9731/17352 (56%)] Loss: -357.257641\n",
      "Train Epoch: 149 [16887/17352 (97%)] Loss: -393.600126\n",
      "    epoch          : 149\n",
      "    loss           : -394.85168864431455\n",
      "    val_loss       : -371.58694506209247\n",
      "    val_log_likelihood: 614.0103197686495\n",
      "    val_log_marginal: 389.2488372108626\n",
      "Train Epoch: 150 [512/17352 (3%)] Loss: -433.190552\n",
      "Train Epoch: 150 [10430/17352 (60%)] Loss: -397.774345\n",
      "Train Epoch: 150 [16872/17352 (97%)] Loss: -428.022474\n",
      "    epoch          : 150\n",
      "    loss           : -398.58481026563805\n",
      "    val_loss       : -369.43332213332377\n",
      "    val_log_likelihood: 618.1454451323806\n",
      "    val_log_marginal: 388.07267920927166\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch150.pth ...\n",
      "Train Epoch: 151 [512/17352 (3%)] Loss: -437.642212\n",
      "Train Epoch: 151 [10140/17352 (58%)] Loss: -425.687025\n",
      "Train Epoch: 151 [16988/17352 (98%)] Loss: -310.083778\n",
      "    epoch          : 151\n",
      "    loss           : -361.8641063179897\n",
      "    val_loss       : -320.14484992923684\n",
      "    val_log_likelihood: 591.9193496910908\n",
      "    val_log_marginal: 348.7983606400672\n",
      "Train Epoch: 152 [512/17352 (3%)] Loss: -204.626785\n",
      "Train Epoch: 152 [10944/17352 (63%)] Loss: -462.136501\n",
      "Train Epoch: 152 [17126/17352 (99%)] Loss: -410.903480\n",
      "    epoch          : 152\n",
      "    loss           : -369.8726107615702\n",
      "    val_loss       : -339.457103107798\n",
      "    val_log_likelihood: 614.8038739339587\n",
      "    val_log_marginal: 372.33991656608106\n",
      "Train Epoch: 153 [512/17352 (3%)] Loss: -399.538208\n",
      "Train Epoch: 153 [10534/17352 (61%)] Loss: -437.598697\n",
      "Train Epoch: 153 [16992/17352 (98%)] Loss: 287.434262\n",
      "    epoch          : 153\n",
      "    loss           : -333.0578260476194\n",
      "    val_loss       : 44.03366910089107\n",
      "    val_log_likelihood: 563.2491098795527\n",
      "    val_log_marginal: -11.80419255665943\n",
      "Train Epoch: 154 [512/17352 (3%)] Loss: 103.603897\n",
      "Train Epoch: 154 [10942/17352 (63%)] Loss: -133.637485\n",
      "Train Epoch: 154 [17263/17352 (99%)] Loss: -2.682732\n",
      "    epoch          : 154\n",
      "    loss           : -210.10097155825508\n",
      "    val_loss       : -247.91141426320172\n",
      "    val_log_likelihood: 536.9862259671766\n",
      "    val_log_marginal: 294.34383172759703\n",
      "Train Epoch: 155 [512/17352 (3%)] Loss: -88.899170\n",
      "Train Epoch: 155 [10890/17352 (63%)] Loss: -373.461686\n",
      "Train Epoch: 155 [17044/17352 (98%)] Loss: -297.073012\n",
      "    epoch          : 155\n",
      "    loss           : -317.136317338544\n",
      "    val_loss       : -296.14920080237897\n",
      "    val_log_likelihood: 553.4862429016778\n",
      "    val_log_marginal: 323.5272879215349\n",
      "Train Epoch: 156 [512/17352 (3%)] Loss: -362.150757\n",
      "Train Epoch: 156 [10405/17352 (60%)] Loss: -407.642056\n",
      "Train Epoch: 156 [17044/17352 (98%)] Loss: -361.184501\n",
      "    epoch          : 156\n",
      "    loss           : -361.66895195010284\n",
      "    val_loss       : -346.54514151750476\n",
      "    val_log_likelihood: 607.6828582722968\n",
      "    val_log_marginal: 376.12267660946793\n",
      "Train Epoch: 157 [512/17352 (3%)] Loss: -434.824280\n",
      "Train Epoch: 157 [10224/17352 (59%)] Loss: -365.063953\n",
      "Train Epoch: 157 [17263/17352 (99%)] Loss: -286.132190\n",
      "    epoch          : 157\n",
      "    loss           : -307.89889966672496\n",
      "    val_loss       : -204.202978290934\n",
      "    val_log_likelihood: 526.4411040929084\n",
      "    val_log_marginal: 282.9186792639686\n",
      "Train Epoch: 158 [512/17352 (3%)] Loss: -204.437241\n",
      "Train Epoch: 158 [10198/17352 (59%)] Loss: -423.725158\n",
      "Train Epoch: 158 [16934/17352 (98%)] Loss: -300.409856\n",
      "    epoch          : 158\n",
      "    loss           : -305.16348189352567\n",
      "    val_loss       : -284.010340696338\n",
      "    val_log_likelihood: 594.9968144749258\n",
      "    val_log_marginal: 316.89390560864996\n",
      "Train Epoch: 159 [512/17352 (3%)] Loss: -341.407135\n",
      "Train Epoch: 159 [10389/17352 (60%)] Loss: -471.685676\n",
      "Train Epoch: 159 [17090/17352 (98%)] Loss: -346.614537\n",
      "    epoch          : 159\n",
      "    loss           : -373.9303687118787\n",
      "    val_loss       : -366.9956525144074\n",
      "    val_log_likelihood: 618.1046953769519\n",
      "    val_log_marginal: 392.57264007862943\n",
      "Train Epoch: 160 [512/17352 (3%)] Loss: -448.692383\n",
      "Train Epoch: 160 [10713/17352 (62%)] Loss: -462.032281\n",
      "Train Epoch: 160 [17335/17352 (100%)] Loss: -413.873879\n",
      "    epoch          : 160\n",
      "    loss           : -384.4946237373137\n",
      "    val_loss       : -283.7129290114924\n",
      "    val_log_likelihood: 616.184577715064\n",
      "    val_log_marginal: 313.35735638117444\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch160.pth ...\n",
      "Train Epoch: 161 [512/17352 (3%)] Loss: -358.571106\n",
      "Train Epoch: 161 [10233/17352 (59%)] Loss: -275.758586\n",
      "Train Epoch: 161 [17106/17352 (99%)] Loss: -453.635102\n",
      "    epoch          : 161\n",
      "    loss           : -377.2407944045204\n",
      "    val_loss       : -359.746450505533\n",
      "    val_log_likelihood: 624.1091973932049\n",
      "    val_log_marginal: 383.41686679215593\n",
      "Train Epoch: 162 [512/17352 (3%)] Loss: -437.787537\n",
      "Train Epoch: 162 [9927/17352 (57%)] Loss: -341.857842\n",
      "Train Epoch: 162 [16878/17352 (97%)] Loss: -464.640443\n",
      "    epoch          : 162\n",
      "    loss           : -409.81375346259017\n",
      "    val_loss       : -395.1580054129485\n",
      "    val_log_likelihood: 642.5656910607568\n",
      "    val_log_marginal: 413.26301273728865\n",
      "Train Epoch: 163 [512/17352 (3%)] Loss: -464.909760\n",
      "Train Epoch: 163 [10028/17352 (58%)] Loss: -489.408854\n",
      "Train Epoch: 163 [17106/17352 (99%)] Loss: -327.492418\n",
      "    epoch          : 163\n",
      "    loss           : -413.7131311917084\n",
      "    val_loss       : -354.3529665808175\n",
      "    val_log_likelihood: 650.9777899007192\n",
      "    val_log_marginal: 383.86795759321194\n",
      "Train Epoch: 164 [512/17352 (3%)] Loss: -456.474121\n",
      "Train Epoch: 164 [10314/17352 (59%)] Loss: -470.924169\n",
      "Train Epoch: 164 [16958/17352 (98%)] Loss: 183.573652\n",
      "    epoch          : 164\n",
      "    loss           : -272.4423611447367\n",
      "    val_loss       : 399.8131997338799\n",
      "    val_log_likelihood: 541.7270676809571\n",
      "    val_log_marginal: -368.4315504087928\n",
      "Train Epoch: 165 [512/17352 (3%)] Loss: 319.031891\n",
      "Train Epoch: 165 [10989/17352 (63%)] Loss: -44.069934\n",
      "Train Epoch: 165 [17253/17352 (99%)] Loss: -378.988154\n",
      "    epoch          : 165\n",
      "    loss           : -142.67199825154515\n",
      "    val_loss       : -84.1052857930099\n",
      "    val_log_likelihood: 533.6050868355642\n",
      "    val_log_marginal: 126.27617437109345\n",
      "Train Epoch: 166 [512/17352 (3%)] Loss: -119.477753\n",
      "Train Epoch: 166 [10688/17352 (62%)] Loss: -160.284493\n",
      "Train Epoch: 166 [16992/17352 (98%)] Loss: -156.667931\n",
      "    epoch          : 166\n",
      "    loss           : -293.37407053451875\n",
      "    val_loss       : -324.7951399957872\n",
      "    val_log_likelihood: 595.7276966107141\n",
      "    val_log_marginal: 349.38359772939145\n",
      "Train Epoch: 167 [512/17352 (3%)] Loss: -390.063263\n",
      "Train Epoch: 167 [10185/17352 (59%)] Loss: -335.619293\n",
      "Train Epoch: 167 [17108/17352 (99%)] Loss: -450.061501\n",
      "    epoch          : 167\n",
      "    loss           : -382.14261075993124\n",
      "    val_loss       : -376.2428009018956\n",
      "    val_log_likelihood: 633.0768902567426\n",
      "    val_log_marginal: 403.59593358793103\n",
      "Train Epoch: 168 [512/17352 (3%)] Loss: -445.726715\n",
      "Train Epoch: 168 [10009/17352 (58%)] Loss: -375.744909\n",
      "Train Epoch: 168 [16887/17352 (97%)] Loss: -491.388449\n",
      "    epoch          : 168\n",
      "    loss           : -419.2213129172874\n",
      "    val_loss       : -381.0756027918792\n",
      "    val_log_likelihood: 653.3590602870895\n",
      "    val_log_marginal: 409.0262604146261\n",
      "Train Epoch: 169 [512/17352 (3%)] Loss: -434.610474\n",
      "Train Epoch: 169 [10294/17352 (59%)] Loss: -479.734650\n",
      "Train Epoch: 169 [17277/17352 (100%)] Loss: -416.407366\n",
      "    epoch          : 169\n",
      "    loss           : -425.4376130649057\n",
      "    val_loss       : -396.6780475143695\n",
      "    val_log_likelihood: 658.2543961746909\n",
      "    val_log_marginal: 415.7230217965648\n",
      "Train Epoch: 170 [512/17352 (3%)] Loss: -461.584839\n",
      "Train Epoch: 170 [9905/17352 (57%)] Loss: -416.027896\n",
      "Train Epoch: 170 [16883/17352 (97%)] Loss: -372.259594\n",
      "    epoch          : 170\n",
      "    loss           : -435.54273302628224\n",
      "    val_loss       : -409.77279925790737\n",
      "    val_log_likelihood: 666.9110622242621\n",
      "    val_log_marginal: 426.2194725557724\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch170.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 171 [512/17352 (3%)] Loss: -464.831787\n",
      "Train Epoch: 171 [10647/17352 (61%)] Loss: -516.405538\n",
      "Train Epoch: 171 [17335/17352 (100%)] Loss: -475.745580\n",
      "    epoch          : 171\n",
      "    loss           : -436.93972446832004\n",
      "    val_loss       : -404.15876108062\n",
      "    val_log_likelihood: 675.991850525562\n",
      "    val_log_marginal: 431.47479341746333\n",
      "Train Epoch: 172 [512/17352 (3%)] Loss: -484.836121\n",
      "Train Epoch: 172 [10221/17352 (59%)] Loss: -480.552613\n",
      "Train Epoch: 172 [17090/17352 (98%)] Loss: -451.750115\n",
      "    epoch          : 172\n",
      "    loss           : -448.6854126549586\n",
      "    val_loss       : -417.8765763298893\n",
      "    val_log_likelihood: 679.7383661881499\n",
      "    val_log_marginal: 435.1695146778974\n",
      "Train Epoch: 173 [512/17352 (3%)] Loss: -480.934113\n",
      "Train Epoch: 173 [10704/17352 (62%)] Loss: -408.329433\n",
      "Train Epoch: 173 [16939/17352 (98%)] Loss: -355.713017\n",
      "    epoch          : 173\n",
      "    loss           : -449.24324337897093\n",
      "    val_loss       : -418.22460525542937\n",
      "    val_log_likelihood: 682.8943398050351\n",
      "    val_log_marginal: 436.7353435923248\n",
      "Train Epoch: 174 [512/17352 (3%)] Loss: -482.440857\n",
      "Train Epoch: 174 [10370/17352 (60%)] Loss: -381.755697\n",
      "Train Epoch: 174 [17044/17352 (98%)] Loss: -343.666885\n",
      "    epoch          : 174\n",
      "    loss           : -454.01967016013197\n",
      "    val_loss       : -416.7364581845701\n",
      "    val_log_likelihood: 689.9513621900306\n",
      "    val_log_marginal: 443.1759909500222\n",
      "Train Epoch: 175 [512/17352 (3%)] Loss: -505.578247\n",
      "Train Epoch: 175 [10177/17352 (59%)] Loss: -552.258030\n",
      "Train Epoch: 175 [17016/17352 (98%)] Loss: -366.387672\n",
      "    epoch          : 175\n",
      "    loss           : -457.2380718130235\n",
      "    val_loss       : -430.0843561446121\n",
      "    val_log_likelihood: 697.5927897381625\n",
      "    val_log_marginal: 450.7742957945583\n",
      "Train Epoch: 176 [512/17352 (3%)] Loss: -478.565247\n",
      "Train Epoch: 176 [10501/17352 (61%)] Loss: -406.698876\n",
      "Train Epoch: 176 [17044/17352 (98%)] Loss: -432.559549\n",
      "    epoch          : 176\n",
      "    loss           : -461.2562442149824\n",
      "    val_loss       : -429.87890101503575\n",
      "    val_log_likelihood: 700.4391575646221\n",
      "    val_log_marginal: 449.25040214458903\n",
      "Train Epoch: 177 [512/17352 (3%)] Loss: -510.823181\n",
      "Train Epoch: 177 [10324/17352 (59%)] Loss: -407.901110\n",
      "Train Epoch: 177 [16878/17352 (97%)] Loss: -333.871652\n",
      "    epoch          : 177\n",
      "    loss           : -444.76738533976663\n",
      "    val_loss       : -385.0554983441582\n",
      "    val_log_likelihood: 686.7665679327376\n",
      "    val_log_marginal: 419.41923701645584\n",
      "Train Epoch: 178 [512/17352 (3%)] Loss: -452.380432\n",
      "Train Epoch: 178 [9552/17352 (55%)] Loss: -431.480237\n",
      "Train Epoch: 178 [17044/17352 (98%)] Loss: -497.509085\n",
      "    epoch          : 178\n",
      "    loss           : -410.1202831964905\n",
      "    val_loss       : -414.2237142165968\n",
      "    val_log_likelihood: 679.6125791673155\n",
      "    val_log_marginal: 437.67859902776866\n",
      "Train Epoch: 179 [512/17352 (3%)] Loss: -471.066742\n",
      "Train Epoch: 179 [9716/17352 (56%)] Loss: -372.365005\n",
      "Train Epoch: 179 [16923/17352 (98%)] Loss: -312.118750\n",
      "    epoch          : 179\n",
      "    loss           : -460.0629753019839\n",
      "    val_loss       : -431.145912902784\n",
      "    val_log_likelihood: 700.8824763078973\n",
      "    val_log_marginal: 452.51433660779975\n",
      "Train Epoch: 180 [512/17352 (3%)] Loss: -519.588074\n",
      "Train Epoch: 180 [10323/17352 (59%)] Loss: -423.454991\n",
      "Train Epoch: 180 [16878/17352 (97%)] Loss: -436.797898\n",
      "    epoch          : 180\n",
      "    loss           : -471.9941631075118\n",
      "    val_loss       : -437.62875170671504\n",
      "    val_log_likelihood: 716.7247727235385\n",
      "    val_log_marginal: 460.2387771243269\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch180.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 181 [512/17352 (3%)] Loss: -486.977600\n",
      "Train Epoch: 181 [10979/17352 (63%)] Loss: -391.954105\n",
      "Train Epoch: 181 [17101/17352 (99%)] Loss: -492.580268\n",
      "    epoch          : 181\n",
      "    loss           : -473.98929642105094\n",
      "    val_loss       : -425.4703928727802\n",
      "    val_log_likelihood: 719.6745284501849\n",
      "    val_log_marginal: 458.4814674219171\n",
      "Train Epoch: 182 [512/17352 (3%)] Loss: -512.612488\n",
      "Train Epoch: 182 [10574/17352 (61%)] Loss: -361.690899\n",
      "Train Epoch: 182 [17064/17352 (98%)] Loss: -514.486180\n",
      "    epoch          : 182\n",
      "    loss           : -465.6084072142072\n",
      "    val_loss       : -429.2089020868724\n",
      "    val_log_likelihood: 711.2567882812184\n",
      "    val_log_marginal: 455.34008541255633\n",
      "Train Epoch: 183 [512/17352 (3%)] Loss: -518.161438\n",
      "Train Epoch: 183 [10037/17352 (58%)] Loss: -534.601042\n",
      "Train Epoch: 183 [17016/17352 (98%)] Loss: -534.852767\n",
      "    epoch          : 183\n",
      "    loss           : -482.9591410427619\n",
      "    val_loss       : -437.91542198161443\n",
      "    val_log_likelihood: 718.4176503232769\n",
      "    val_log_marginal: 463.62730753437665\n",
      "Train Epoch: 184 [512/17352 (3%)] Loss: -526.368958\n",
      "Train Epoch: 184 [10887/17352 (63%)] Loss: -568.378049\n",
      "Train Epoch: 184 [16922/17352 (98%)] Loss: -584.393084\n",
      "    epoch          : 184\n",
      "    loss           : -486.3826555262972\n",
      "    val_loss       : -453.16509007812\n",
      "    val_log_likelihood: 735.9543689475933\n",
      "    val_log_marginal: 476.2048331148252\n",
      "Train Epoch: 185 [512/17352 (3%)] Loss: -526.655701\n",
      "Train Epoch: 185 [10610/17352 (61%)] Loss: -605.930230\n",
      "Train Epoch: 185 [17049/17352 (98%)] Loss: -526.923556\n",
      "    epoch          : 185\n",
      "    loss           : -471.6564182563018\n",
      "    val_loss       : -427.534625172553\n",
      "    val_log_likelihood: 725.9951921357449\n",
      "    val_log_marginal: 454.81081028773514\n",
      "Train Epoch: 186 [512/17352 (3%)] Loss: -534.116455\n",
      "Train Epoch: 186 [10702/17352 (62%)] Loss: -329.782460\n",
      "Train Epoch: 186 [17335/17352 (100%)] Loss: -558.300973\n",
      "    epoch          : 186\n",
      "    loss           : -477.5031884913797\n",
      "    val_loss       : -432.58604134771906\n",
      "    val_log_likelihood: 730.3739072039918\n",
      "    val_log_marginal: 449.9768163273595\n",
      "Train Epoch: 187 [512/17352 (3%)] Loss: -341.813171\n",
      "Train Epoch: 187 [10159/17352 (59%)] Loss: -364.226734\n",
      "Train Epoch: 187 [17090/17352 (98%)] Loss: -435.131824\n",
      "    epoch          : 187\n",
      "    loss           : -487.0558329492124\n",
      "    val_loss       : -443.6772185199773\n",
      "    val_log_likelihood: 744.2425045474989\n",
      "    val_log_marginal: 468.74157664590655\n",
      "Train Epoch: 188 [512/17352 (3%)] Loss: -533.014709\n",
      "Train Epoch: 188 [10272/17352 (59%)] Loss: -412.555386\n",
      "Train Epoch: 188 [17263/17352 (99%)] Loss: -223.766070\n",
      "    epoch          : 188\n",
      "    loss           : -391.2652392288017\n",
      "    val_loss       : -205.4868431802524\n",
      "    val_log_likelihood: 689.1179456712064\n",
      "    val_log_marginal: 246.8543471148663\n",
      "Train Epoch: 189 [512/17352 (3%)] Loss: -228.495804\n",
      "Train Epoch: 189 [9805/17352 (57%)] Loss: -291.160840\n",
      "Train Epoch: 189 [17090/17352 (98%)] Loss: -564.637636\n",
      "    epoch          : 189\n",
      "    loss           : -386.7691445485461\n",
      "    val_loss       : -375.3413104897756\n",
      "    val_log_likelihood: 694.2365864926269\n",
      "    val_log_marginal: 410.9614518674816\n",
      "Train Epoch: 190 [512/17352 (3%)] Loss: -450.979370\n",
      "Train Epoch: 190 [10576/17352 (61%)] Loss: -353.580230\n",
      "Train Epoch: 190 [17143/17352 (99%)] Loss: -417.456112\n",
      "    epoch          : 190\n",
      "    loss           : -461.2552170891935\n",
      "    val_loss       : -427.8067149619243\n",
      "    val_log_likelihood: 717.9602777759944\n",
      "    val_log_marginal: 458.0265045562875\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch190.pth ...\n",
      "Train Epoch: 191 [512/17352 (3%)] Loss: -517.819397\n",
      "Train Epoch: 191 [10501/17352 (61%)] Loss: -383.951552\n",
      "Train Epoch: 191 [16934/17352 (98%)] Loss: -556.583125\n",
      "    epoch          : 191\n",
      "    loss           : -483.12877130398823\n",
      "    val_loss       : -445.6092473412382\n",
      "    val_log_likelihood: 746.9207950560535\n",
      "    val_log_marginal: 478.12455227926034\n",
      "Train Epoch: 192 [512/17352 (3%)] Loss: -530.938660\n",
      "Train Epoch: 192 [10085/17352 (58%)] Loss: -570.115668\n",
      "Train Epoch: 192 [17101/17352 (99%)] Loss: -417.263614\n",
      "    epoch          : 192\n",
      "    loss           : -489.35788792515467\n",
      "    val_loss       : -456.2551417349931\n",
      "    val_log_likelihood: 746.3491553066925\n",
      "    val_log_marginal: 480.3773135379621\n",
      "Train Epoch: 193 [512/17352 (3%)] Loss: -532.500977\n",
      "Train Epoch: 193 [9797/17352 (56%)] Loss: -318.652218\n",
      "Train Epoch: 193 [17016/17352 (98%)] Loss: -438.657465\n",
      "    epoch          : 193\n",
      "    loss           : -496.6690094694223\n",
      "    val_loss       : -457.7355033715053\n",
      "    val_log_likelihood: 755.1186349628708\n",
      "    val_log_marginal: 483.64492632928955\n",
      "Train Epoch: 194 [512/17352 (3%)] Loss: -558.779663\n",
      "Train Epoch: 194 [10640/17352 (61%)] Loss: -486.593622\n",
      "Train Epoch: 194 [16958/17352 (98%)] Loss: -552.430159\n",
      "    epoch          : 194\n",
      "    loss           : -503.4623230505953\n",
      "    val_loss       : -457.6503724303174\n",
      "    val_log_likelihood: 760.773902729291\n",
      "    val_log_marginal: 480.6021832246526\n",
      "Train Epoch: 195 [512/17352 (3%)] Loss: -553.069336\n",
      "Train Epoch: 195 [10833/17352 (62%)] Loss: -470.377691\n",
      "Train Epoch: 195 [17064/17352 (98%)] Loss: -454.783892\n",
      "    epoch          : 195\n",
      "    loss           : -508.9028302865127\n",
      "    val_loss       : -453.5402559406343\n",
      "    val_log_likelihood: 763.6345560624909\n",
      "    val_log_marginal: 473.47738310033327\n",
      "Train Epoch: 196 [512/17352 (3%)] Loss: -535.270325\n",
      "Train Epoch: 196 [10700/17352 (62%)] Loss: -558.845654\n",
      "Train Epoch: 196 [16883/17352 (97%)] Loss: -421.561030\n",
      "    epoch          : 196\n",
      "    loss           : -501.39191190974753\n",
      "    val_loss       : -475.6415710114441\n",
      "    val_log_likelihood: 771.7999369085722\n",
      "    val_log_marginal: 499.8530108955487\n",
      "Train Epoch: 197 [512/17352 (3%)] Loss: -405.975769\n",
      "Train Epoch: 197 [10695/17352 (62%)] Loss: -558.069321\n",
      "Train Epoch: 197 [17044/17352 (98%)] Loss: -364.798520\n",
      "    epoch          : 197\n",
      "    loss           : -481.5586708478169\n",
      "    val_loss       : -441.6072509743091\n",
      "    val_log_likelihood: 755.1873738443435\n",
      "    val_log_marginal: 466.9991793416337\n",
      "Train Epoch: 198 [512/17352 (3%)] Loss: -517.525085\n",
      "Train Epoch: 198 [10544/17352 (61%)] Loss: -400.185861\n",
      "Train Epoch: 198 [17106/17352 (99%)] Loss: -527.236041\n",
      "    epoch          : 198\n",
      "    loss           : -485.0048129663753\n",
      "    val_loss       : -427.9945898778121\n",
      "    val_log_likelihood: 750.8232144379859\n",
      "    val_log_marginal: 450.88160493452625\n",
      "Train Epoch: 199 [512/17352 (3%)] Loss: -486.556396\n",
      "Train Epoch: 199 [10566/17352 (61%)] Loss: -555.815585\n",
      "Train Epoch: 199 [17153/17352 (99%)] Loss: -435.308276\n",
      "    epoch          : 199\n",
      "    loss           : -504.2236991800411\n",
      "    val_loss       : -457.27581234203655\n",
      "    val_log_likelihood: 766.4144762829781\n",
      "    val_log_marginal: 483.8700882936769\n",
      "Train Epoch: 200 [512/17352 (3%)] Loss: -569.873413\n",
      "Train Epoch: 200 [10698/17352 (62%)] Loss: -346.649559\n",
      "Train Epoch: 200 [17143/17352 (99%)] Loss: -597.557863\n",
      "    epoch          : 200\n",
      "    loss           : -518.0445451339532\n",
      "    val_loss       : -478.988761621321\n",
      "    val_log_likelihood: 781.5602150941888\n",
      "    val_log_marginal: 501.9029549829929\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch200.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 201 [512/17352 (3%)] Loss: -562.418152\n",
      "Train Epoch: 201 [9953/17352 (57%)] Loss: -546.460159\n",
      "Train Epoch: 201 [16958/17352 (98%)] Loss: -500.631934\n",
      "    epoch          : 201\n",
      "    loss           : -516.8473408702688\n",
      "    val_loss       : -418.1595035265765\n",
      "    val_log_likelihood: 768.4523288098414\n",
      "    val_log_marginal: 474.48909833712025\n",
      "Train Epoch: 202 [512/17352 (3%)] Loss: -562.728638\n",
      "Train Epoch: 202 [10182/17352 (59%)] Loss: -221.562913\n",
      "Train Epoch: 202 [16988/17352 (98%)] Loss: -455.324253\n",
      "    epoch          : 202\n",
      "    loss           : -425.0342634611581\n",
      "    val_loss       : -323.632182604506\n",
      "    val_log_likelihood: 644.5246214859551\n",
      "    val_log_marginal: 389.9694347423056\n",
      "Train Epoch: 203 [512/17352 (3%)] Loss: -442.770630\n",
      "Train Epoch: 203 [10119/17352 (58%)] Loss: -207.089818\n",
      "Train Epoch: 203 [16988/17352 (98%)] Loss: -505.328268\n",
      "    epoch          : 203\n",
      "    loss           : -381.37909966810406\n",
      "    val_loss       : -405.5533433270972\n",
      "    val_log_likelihood: 717.7292878510117\n",
      "    val_log_marginal: 444.9535732295754\n",
      "Train Epoch: 204 [512/17352 (3%)] Loss: -500.061584\n",
      "Train Epoch: 204 [10041/17352 (58%)] Loss: -448.093091\n",
      "Train Epoch: 204 [17049/17352 (98%)] Loss: -450.245215\n",
      "    epoch          : 204\n",
      "    loss           : -477.22993047396506\n",
      "    val_loss       : -425.57619956166326\n",
      "    val_log_likelihood: 754.2718283924991\n",
      "    val_log_marginal: 466.66897230464923\n",
      "Train Epoch: 205 [512/17352 (3%)] Loss: -527.875366\n",
      "Train Epoch: 205 [10342/17352 (60%)] Loss: -559.969195\n",
      "Train Epoch: 205 [16922/17352 (98%)] Loss: -551.591992\n",
      "    epoch          : 205\n",
      "    loss           : -486.342544502902\n",
      "    val_loss       : -443.0717210307765\n",
      "    val_log_likelihood: 752.6136402392925\n",
      "    val_log_marginal: 468.8887876518063\n",
      "Train Epoch: 206 [512/17352 (3%)] Loss: -471.612213\n",
      "Train Epoch: 206 [10225/17352 (59%)] Loss: -318.312371\n",
      "Train Epoch: 206 [16958/17352 (98%)] Loss: -602.396855\n",
      "    epoch          : 206\n",
      "    loss           : -482.78207527078894\n",
      "    val_loss       : -463.81902176067615\n",
      "    val_log_likelihood: 758.7807324427482\n",
      "    val_log_marginal: 486.64731765636935\n",
      "Train Epoch: 207 [512/17352 (3%)] Loss: -532.470154\n",
      "Train Epoch: 207 [10012/17352 (58%)] Loss: -396.449337\n",
      "Train Epoch: 207 [17133/17352 (99%)] Loss: -602.823737\n",
      "    epoch          : 207\n",
      "    loss           : -475.1669641626554\n",
      "    val_loss       : -434.6665017184994\n",
      "    val_log_likelihood: 760.4928641939988\n",
      "    val_log_marginal: 473.59300779305215\n",
      "Train Epoch: 208 [512/17352 (3%)] Loss: -548.604736\n",
      "Train Epoch: 208 [10414/17352 (60%)] Loss: -518.317480\n",
      "Train Epoch: 208 [16878/17352 (97%)] Loss: -481.881596\n",
      "    epoch          : 208\n",
      "    loss           : -482.1698061863448\n",
      "    val_loss       : -444.2214886158832\n",
      "    val_log_likelihood: 776.7767415633\n",
      "    val_log_marginal: 486.80254614775765\n",
      "Train Epoch: 209 [512/17352 (3%)] Loss: -547.936523\n",
      "Train Epoch: 209 [10310/17352 (59%)] Loss: -333.157278\n",
      "Train Epoch: 209 [17277/17352 (100%)] Loss: -382.507856\n",
      "    epoch          : 209\n",
      "    loss           : -444.38585222509874\n",
      "    val_loss       : -77.87230102114019\n",
      "    val_log_likelihood: 739.9590458567595\n",
      "    val_log_marginal: 106.87747402108947\n",
      "Train Epoch: 210 [512/17352 (3%)] Loss: -109.615601\n",
      "Train Epoch: 210 [10299/17352 (59%)] Loss: -518.273501\n",
      "Train Epoch: 210 [16922/17352 (98%)] Loss: -411.223917\n",
      "    epoch          : 210\n",
      "    loss           : -344.1554602691704\n",
      "    val_loss       : -398.73508816203537\n",
      "    val_log_likelihood: 729.341714764907\n",
      "    val_log_marginal: 441.7371543474638\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch210.pth ...\n",
      "Train Epoch: 211 [512/17352 (3%)] Loss: -496.785950\n",
      "Train Epoch: 211 [10545/17352 (61%)] Loss: -564.221248\n",
      "Train Epoch: 211 [17153/17352 (99%)] Loss: -560.863054\n",
      "    epoch          : 211\n",
      "    loss           : -471.2468040350721\n",
      "    val_loss       : -399.78043968721084\n",
      "    val_log_likelihood: 755.6581165386544\n",
      "    val_log_marginal: 434.4922541831501\n",
      "Train Epoch: 212 [512/17352 (3%)] Loss: -511.749603\n",
      "Train Epoch: 212 [10227/17352 (59%)] Loss: -550.681543\n",
      "Train Epoch: 212 [16958/17352 (98%)] Loss: -599.357656\n",
      "    epoch          : 212\n",
      "    loss           : -505.13603642350427\n",
      "    val_loss       : -476.62818183200807\n",
      "    val_log_likelihood: 774.3010469722608\n",
      "    val_log_marginal: 501.6600718320997\n",
      "Train Epoch: 213 [512/17352 (3%)] Loss: -584.359619\n",
      "Train Epoch: 213 [10207/17352 (59%)] Loss: -492.212103\n",
      "Train Epoch: 213 [17016/17352 (98%)] Loss: -471.677792\n",
      "    epoch          : 213\n",
      "    loss           : -531.3208022545806\n",
      "    val_loss       : -478.7316149545493\n",
      "    val_log_likelihood: 785.4464292151031\n",
      "    val_log_marginal: 502.64421461025364\n",
      "Train Epoch: 214 [512/17352 (3%)] Loss: -585.127625\n",
      "Train Epoch: 214 [10357/17352 (60%)] Loss: -663.922201\n",
      "Train Epoch: 214 [17106/17352 (99%)] Loss: -456.133302\n",
      "    epoch          : 214\n",
      "    loss           : -538.9364914592725\n",
      "    val_loss       : -491.1178020707788\n",
      "    val_log_likelihood: 797.182489685981\n",
      "    val_log_marginal: 514.5405900078879\n",
      "Train Epoch: 215 [512/17352 (3%)] Loss: -554.800415\n",
      "Train Epoch: 215 [10332/17352 (60%)] Loss: -593.020050\n",
      "Train Epoch: 215 [17153/17352 (99%)] Loss: -622.120885\n",
      "    epoch          : 215\n",
      "    loss           : -543.9223139050408\n",
      "    val_loss       : -486.5672090416412\n",
      "    val_log_likelihood: 800.3371547225983\n",
      "    val_log_marginal: 517.5354839451709\n",
      "Train Epoch: 216 [512/17352 (3%)] Loss: -579.551575\n",
      "Train Epoch: 216 [10384/17352 (60%)] Loss: -597.291269\n",
      "Train Epoch: 216 [17064/17352 (98%)] Loss: -367.489459\n",
      "    epoch          : 216\n",
      "    loss           : -543.5300183081127\n",
      "    val_loss       : -485.3812787045014\n",
      "    val_log_likelihood: 809.0590942761924\n",
      "    val_log_marginal: 509.80600297008476\n",
      "Train Epoch: 217 [512/17352 (3%)] Loss: -577.679199\n",
      "Train Epoch: 217 [10585/17352 (61%)] Loss: -358.751142\n",
      "Train Epoch: 217 [16934/17352 (98%)] Loss: -513.349065\n",
      "    epoch          : 217\n",
      "    loss           : -542.0769926600658\n",
      "    val_loss       : -472.20673541162614\n",
      "    val_log_likelihood: 801.611317675589\n",
      "    val_log_marginal: 497.4279365972019\n",
      "Train Epoch: 218 [512/17352 (3%)] Loss: -597.938904\n",
      "Train Epoch: 218 [10658/17352 (61%)] Loss: -638.603587\n",
      "Train Epoch: 218 [17335/17352 (100%)] Loss: -581.414669\n",
      "    epoch          : 218\n",
      "    loss           : -505.5780675757176\n",
      "    val_loss       : -141.4761019325487\n",
      "    val_log_likelihood: 774.5639199973423\n",
      "    val_log_marginal: 178.4388285807127\n",
      "Train Epoch: 219 [512/17352 (3%)] Loss: -206.292603\n",
      "Train Epoch: 219 [10355/17352 (60%)] Loss: -535.942010\n",
      "Train Epoch: 219 [16957/17352 (98%)] Loss: -522.846999\n",
      "    epoch          : 219\n",
      "    loss           : -400.8944610996639\n",
      "    val_loss       : -416.9684896137502\n",
      "    val_log_likelihood: 752.7392118624491\n",
      "    val_log_marginal: 450.68870445237206\n",
      "Train Epoch: 220 [512/17352 (3%)] Loss: -306.265930\n",
      "Train Epoch: 220 [10353/17352 (60%)] Loss: -458.910586\n",
      "Train Epoch: 220 [16958/17352 (98%)] Loss: -300.918118\n",
      "    epoch          : 220\n",
      "    loss           : -507.8300919519835\n",
      "    val_loss       : -477.4322073522026\n",
      "    val_log_likelihood: 790.5973590092491\n",
      "    val_log_marginal: 506.7503460135822\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch220.pth ...\n",
      "Train Epoch: 221 [512/17352 (3%)] Loss: -575.631592\n",
      "Train Epoch: 221 [10454/17352 (60%)] Loss: -534.783053\n",
      "Train Epoch: 221 [17277/17352 (100%)] Loss: -579.499626\n",
      "    epoch          : 221\n",
      "    loss           : -526.6059761494597\n",
      "    val_loss       : -469.57185178546933\n",
      "    val_log_likelihood: 796.234834285232\n",
      "    val_log_marginal: 493.6088883285502\n",
      "Train Epoch: 222 [512/17352 (3%)] Loss: -578.477539\n",
      "Train Epoch: 222 [10246/17352 (59%)] Loss: -547.221275\n",
      "Train Epoch: 222 [17106/17352 (99%)] Loss: -461.144522\n",
      "    epoch          : 222\n",
      "    loss           : -552.6708084429395\n",
      "    val_loss       : -475.31587646111734\n",
      "    val_log_likelihood: 817.1115568948089\n",
      "    val_log_marginal: 502.6250668545146\n",
      "Train Epoch: 223 [512/17352 (3%)] Loss: -587.202148\n",
      "Train Epoch: 223 [9996/17352 (58%)] Loss: -487.087250\n",
      "Train Epoch: 223 [17044/17352 (98%)] Loss: -456.916996\n",
      "    epoch          : 223\n",
      "    loss           : -508.41849378222685\n",
      "    val_loss       : -438.81580123268924\n",
      "    val_log_likelihood: 799.2333554045713\n",
      "    val_log_marginal: 490.333134188477\n",
      "Train Epoch: 224 [512/17352 (3%)] Loss: -485.141693\n",
      "Train Epoch: 224 [10772/17352 (62%)] Loss: -643.361003\n",
      "Train Epoch: 224 [17153/17352 (99%)] Loss: -485.355054\n",
      "    epoch          : 224\n",
      "    loss           : -491.4282346809818\n",
      "    val_loss       : -411.6860660359813\n",
      "    val_log_likelihood: 773.4508890749544\n",
      "    val_log_marginal: 459.7495558055362\n",
      "Train Epoch: 225 [512/17352 (3%)] Loss: -520.161987\n",
      "Train Epoch: 225 [10393/17352 (60%)] Loss: -611.349728\n",
      "Train Epoch: 225 [16958/17352 (98%)] Loss: -550.868432\n",
      "    epoch          : 225\n",
      "    loss           : -488.4178380373641\n",
      "    val_loss       : -444.9501812597196\n",
      "    val_log_likelihood: 772.6053594546357\n",
      "    val_log_marginal: 483.9804617301817\n",
      "Train Epoch: 226 [512/17352 (3%)] Loss: -538.916321\n",
      "Train Epoch: 226 [10062/17352 (58%)] Loss: -480.365266\n",
      "Train Epoch: 226 [17126/17352 (99%)] Loss: -354.524403\n",
      "    epoch          : 226\n",
      "    loss           : -512.4051538454206\n",
      "    val_loss       : -439.36613631598044\n",
      "    val_log_likelihood: 793.2273569511574\n",
      "    val_log_marginal: 465.6895126861432\n",
      "Train Epoch: 227 [512/17352 (3%)] Loss: -516.880371\n",
      "Train Epoch: 227 [9957/17352 (57%)] Loss: -599.520676\n",
      "Train Epoch: 227 [16934/17352 (98%)] Loss: -439.243769\n",
      "    epoch          : 227\n",
      "    loss           : -526.1863853654978\n",
      "    val_loss       : -473.27421432320153\n",
      "    val_log_likelihood: 801.2795436157622\n",
      "    val_log_marginal: 507.79411811602483\n",
      "Train Epoch: 228 [512/17352 (3%)] Loss: -593.052734\n",
      "Train Epoch: 228 [9632/17352 (56%)] Loss: -615.103542\n",
      "Train Epoch: 228 [16957/17352 (98%)] Loss: -437.193821\n",
      "    epoch          : 228\n",
      "    loss           : -510.3477967215462\n",
      "    val_loss       : -491.369011176383\n",
      "    val_log_likelihood: 816.787874821637\n",
      "    val_log_marginal: 518.5942175953245\n",
      "Train Epoch: 229 [512/17352 (3%)] Loss: -599.389343\n",
      "Train Epoch: 229 [10441/17352 (60%)] Loss: -444.534219\n",
      "Train Epoch: 229 [17101/17352 (99%)] Loss: -297.393443\n",
      "    epoch          : 229\n",
      "    loss           : -339.2193907362904\n",
      "    val_loss       : 886.1753918008733\n",
      "    val_log_likelihood: 680.8690755926423\n",
      "    val_log_marginal: -828.8376471943851\n",
      "Train Epoch: 230 [512/17352 (3%)] Loss: 802.326721\n",
      "Train Epoch: 230 [10330/17352 (60%)] Loss: -488.446900\n",
      "Train Epoch: 230 [17133/17352 (99%)] Loss: -347.877999\n",
      "    epoch          : 230\n",
      "    loss           : -297.88126368140166\n",
      "    val_loss       : -354.9689095145075\n",
      "    val_log_likelihood: 726.0224716838562\n",
      "    val_log_marginal: 398.79936378726654\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch230.pth ...\n",
      "Train Epoch: 231 [512/17352 (3%)] Loss: -441.947388\n",
      "Train Epoch: 231 [11012/17352 (63%)] Loss: -617.403718\n",
      "Train Epoch: 231 [17277/17352 (100%)] Loss: -593.978801\n",
      "    epoch          : 231\n",
      "    loss           : -506.5942371510353\n",
      "    val_loss       : -436.48766780725947\n",
      "    val_log_likelihood: 779.9890644720629\n",
      "    val_log_marginal: 479.2588415381693\n",
      "Train Epoch: 232 [512/17352 (3%)] Loss: -549.261902\n",
      "Train Epoch: 232 [10073/17352 (58%)] Loss: -430.399300\n",
      "Train Epoch: 232 [17253/17352 (99%)] Loss: -394.939149\n",
      "    epoch          : 232\n",
      "    loss           : -523.5461185819267\n",
      "    val_loss       : -478.59682776405583\n",
      "    val_log_likelihood: 785.461286607149\n",
      "    val_log_marginal: 509.1885824275359\n",
      "Train Epoch: 233 [512/17352 (3%)] Loss: -592.319763\n",
      "Train Epoch: 233 [10884/17352 (63%)] Loss: -635.585173\n",
      "Train Epoch: 233 [16934/17352 (98%)] Loss: -641.708385\n",
      "    epoch          : 233\n",
      "    loss           : -553.964024820894\n",
      "    val_loss       : -503.30561516672765\n",
      "    val_log_likelihood: 819.1633584020681\n",
      "    val_log_marginal: 531.3419229992996\n",
      "Train Epoch: 234 [512/17352 (3%)] Loss: -605.925293\n",
      "Train Epoch: 234 [10350/17352 (60%)] Loss: -561.794559\n",
      "Train Epoch: 234 [17126/17352 (99%)] Loss: -552.020556\n",
      "    epoch          : 234\n",
      "    loss           : -571.3236772923505\n",
      "    val_loss       : -514.9340571836478\n",
      "    val_log_likelihood: 836.0613962729894\n",
      "    val_log_marginal: 540.244070738102\n",
      "Train Epoch: 235 [512/17352 (3%)] Loss: -622.011536\n",
      "Train Epoch: 235 [9620/17352 (55%)] Loss: -646.519754\n",
      "Train Epoch: 235 [17090/17352 (98%)] Loss: -469.660948\n",
      "    epoch          : 235\n",
      "    loss           : -576.827459585366\n",
      "    val_loss       : -531.0643368499716\n",
      "    val_log_likelihood: 845.1881540525447\n",
      "    val_log_marginal: 552.6320430640477\n",
      "Train Epoch: 236 [512/17352 (3%)] Loss: -610.919739\n",
      "Train Epoch: 236 [10607/17352 (61%)] Loss: -352.004603\n",
      "Train Epoch: 236 [17133/17352 (99%)] Loss: -548.532495\n",
      "    epoch          : 236\n",
      "    loss           : -566.0448770578947\n",
      "    val_loss       : -506.58103403337356\n",
      "    val_log_likelihood: 834.1016491439706\n",
      "    val_log_marginal: 531.5851094428065\n",
      "Train Epoch: 237 [512/17352 (3%)] Loss: -611.242188\n",
      "Train Epoch: 237 [10445/17352 (60%)] Loss: -624.165240\n",
      "Train Epoch: 237 [16939/17352 (98%)] Loss: -666.713224\n",
      "    epoch          : 237\n",
      "    loss           : -580.9729966506198\n",
      "    val_loss       : -526.8295992283485\n",
      "    val_log_likelihood: 846.1869371153854\n",
      "    val_log_marginal: 549.1554936997946\n",
      "Train Epoch: 238 [512/17352 (3%)] Loss: -626.793457\n",
      "Train Epoch: 238 [10325/17352 (60%)] Loss: -541.637148\n",
      "Train Epoch: 238 [16992/17352 (98%)] Loss: -527.313909\n",
      "    epoch          : 238\n",
      "    loss           : -567.7303204028136\n",
      "    val_loss       : -509.6431865487047\n",
      "    val_log_likelihood: 831.6126195165291\n",
      "    val_log_marginal: 541.1679008945305\n",
      "Train Epoch: 239 [512/17352 (3%)] Loss: -616.321289\n",
      "Train Epoch: 239 [9697/17352 (56%)] Loss: -636.275156\n",
      "Train Epoch: 239 [17049/17352 (98%)] Loss: -450.111693\n",
      "    epoch          : 239\n",
      "    loss           : -584.9065573896097\n",
      "    val_loss       : -531.5034716140849\n",
      "    val_log_likelihood: 851.7310212262287\n",
      "    val_log_marginal: 553.5724417229989\n",
      "Train Epoch: 240 [512/17352 (3%)] Loss: -644.992554\n",
      "Train Epoch: 240 [10009/17352 (58%)] Loss: -598.470209\n",
      "Train Epoch: 240 [16957/17352 (98%)] Loss: -554.470266\n",
      "    epoch          : 240\n",
      "    loss           : -599.4047894225899\n",
      "    val_loss       : -544.4348874376427\n",
      "    val_log_likelihood: 859.0112049143033\n",
      "    val_log_marginal: 562.3261776823218\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch240.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 241 [512/17352 (3%)] Loss: -649.786621\n",
      "Train Epoch: 241 [9869/17352 (57%)] Loss: -665.541978\n",
      "Train Epoch: 241 [17090/17352 (98%)] Loss: -692.552992\n",
      "    epoch          : 241\n",
      "    loss           : -592.5295864286104\n",
      "    val_loss       : -536.6614113947256\n",
      "    val_log_likelihood: 861.1635887265782\n",
      "    val_log_marginal: 562.8368102197733\n",
      "Train Epoch: 242 [512/17352 (3%)] Loss: -619.270569\n",
      "Train Epoch: 242 [10960/17352 (63%)] Loss: -652.300000\n",
      "Train Epoch: 242 [17133/17352 (99%)] Loss: -510.695686\n",
      "    epoch          : 242\n",
      "    loss           : -565.0519803576598\n",
      "    val_loss       : -512.1106134353417\n",
      "    val_log_likelihood: 845.6791173181285\n",
      "    val_log_marginal: 538.4417908087216\n",
      "Train Epoch: 243 [512/17352 (3%)] Loss: -623.336365\n",
      "Train Epoch: 243 [10249/17352 (59%)] Loss: -483.567675\n",
      "Train Epoch: 243 [16992/17352 (98%)] Loss: -681.801839\n",
      "    epoch          : 243\n",
      "    loss           : -580.6695429443158\n",
      "    val_loss       : -525.9853214212683\n",
      "    val_log_likelihood: 856.0109809982846\n",
      "    val_log_marginal: 549.6141705669563\n",
      "Train Epoch: 244 [512/17352 (3%)] Loss: -653.186768\n",
      "Train Epoch: 244 [10338/17352 (60%)] Loss: -629.553256\n",
      "Train Epoch: 244 [17101/17352 (99%)] Loss: -449.902923\n",
      "    epoch          : 244\n",
      "    loss           : -583.2971076611669\n",
      "    val_loss       : -496.4000440475045\n",
      "    val_log_likelihood: 847.9098318862684\n",
      "    val_log_marginal: 528.8702055349179\n",
      "Train Epoch: 245 [512/17352 (3%)] Loss: -576.272400\n",
      "Train Epoch: 245 [10744/17352 (62%)] Loss: -565.966233\n",
      "Train Epoch: 245 [17335/17352 (100%)] Loss: -631.029433\n",
      "    epoch          : 245\n",
      "    loss           : -580.4056769860545\n",
      "    val_loss       : -516.0364603956856\n",
      "    val_log_likelihood: 853.4110372679255\n",
      "    val_log_marginal: 545.464683221735\n",
      "Train Epoch: 246 [512/17352 (3%)] Loss: -633.275574\n",
      "Train Epoch: 246 [10540/17352 (61%)] Loss: -645.841758\n",
      "Train Epoch: 246 [16883/17352 (97%)] Loss: -572.452440\n",
      "    epoch          : 246\n",
      "    loss           : -600.9181588917148\n",
      "    val_loss       : -543.7674026210177\n",
      "    val_log_likelihood: 868.4251484909214\n",
      "    val_log_marginal: 565.567088052604\n",
      "Train Epoch: 247 [512/17352 (3%)] Loss: -649.544861\n",
      "Train Epoch: 247 [10537/17352 (61%)] Loss: -728.190213\n",
      "Train Epoch: 247 [17049/17352 (98%)] Loss: -652.722388\n",
      "    epoch          : 247\n",
      "    loss           : -601.7287049408671\n",
      "    val_loss       : -540.925677830339\n",
      "    val_log_likelihood: 867.8711386186761\n",
      "    val_log_marginal: 560.7164956593161\n",
      "Train Epoch: 248 [512/17352 (3%)] Loss: -658.487854\n",
      "Train Epoch: 248 [10440/17352 (60%)] Loss: -598.259272\n",
      "Train Epoch: 248 [17106/17352 (99%)] Loss: -576.383681\n",
      "    epoch          : 248\n",
      "    loss           : -597.8270781241883\n",
      "    val_loss       : -495.03966144182834\n",
      "    val_log_likelihood: 877.8625219226624\n",
      "    val_log_marginal: 525.39582796555\n",
      "Train Epoch: 249 [512/17352 (3%)] Loss: -599.670288\n",
      "Train Epoch: 249 [10397/17352 (60%)] Loss: -492.481388\n",
      "Train Epoch: 249 [16878/17352 (97%)] Loss: -694.482597\n",
      "    epoch          : 249\n",
      "    loss           : -590.7408824285595\n",
      "    val_loss       : -530.9006596324451\n",
      "    val_log_likelihood: 873.7557682784693\n",
      "    val_log_marginal: 551.0511790133106\n",
      "Train Epoch: 250 [512/17352 (3%)] Loss: -627.643066\n",
      "Train Epoch: 250 [10278/17352 (59%)] Loss: -587.629161\n",
      "Train Epoch: 250 [16922/17352 (98%)] Loss: -706.219184\n",
      "    epoch          : 250\n",
      "    loss           : -564.9351070033175\n",
      "    val_loss       : -510.4020216141651\n",
      "    val_log_likelihood: 869.5505063007607\n",
      "    val_log_marginal: 534.8865777429804\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch250.pth ...\n",
      "Train Epoch: 251 [512/17352 (3%)] Loss: -608.669800\n",
      "Train Epoch: 251 [10298/17352 (59%)] Loss: -577.786472\n",
      "Train Epoch: 251 [16882/17352 (97%)] Loss: -664.114006\n",
      "    epoch          : 251\n",
      "    loss           : -536.206621875993\n",
      "    val_loss       : -503.7841782697658\n",
      "    val_log_likelihood: 849.3200828635953\n",
      "    val_log_marginal: 532.9309568162371\n",
      "Train Epoch: 252 [512/17352 (3%)] Loss: -633.338745\n",
      "Train Epoch: 252 [10009/17352 (58%)] Loss: -498.494026\n",
      "Train Epoch: 252 [17108/17352 (99%)] Loss: -702.836954\n",
      "    epoch          : 252\n",
      "    loss           : -584.5718236090673\n",
      "    val_loss       : -534.0414493497481\n",
      "    val_log_likelihood: 875.1861006420551\n",
      "    val_log_marginal: 552.1526243952534\n",
      "Train Epoch: 253 [512/17352 (3%)] Loss: -645.756897\n",
      "Train Epoch: 253 [10763/17352 (62%)] Loss: -528.517045\n",
      "Train Epoch: 253 [16883/17352 (97%)] Loss: -469.979604\n",
      "    epoch          : 253\n",
      "    loss           : -600.2436382867747\n",
      "    val_loss       : -470.2607509438669\n",
      "    val_log_likelihood: 876.9752723307658\n",
      "    val_log_marginal: 495.61724331615926\n",
      "Train Epoch: 254 [512/17352 (3%)] Loss: -599.285889\n",
      "Train Epoch: 254 [10249/17352 (59%)] Loss: -663.239219\n",
      "Train Epoch: 254 [17090/17352 (98%)] Loss: -634.011068\n",
      "    epoch          : 254\n",
      "    loss           : -575.0972849647309\n",
      "    val_loss       : -521.5453310525754\n",
      "    val_log_likelihood: 873.0219368093304\n",
      "    val_log_marginal: 547.8850961726482\n",
      "Train Epoch: 255 [512/17352 (3%)] Loss: -650.194214\n",
      "Train Epoch: 255 [10343/17352 (60%)] Loss: -673.100673\n",
      "Train Epoch: 255 [16878/17352 (97%)] Loss: -465.694488\n",
      "    epoch          : 255\n",
      "    loss           : -574.1258370068444\n",
      "    val_loss       : -454.2472652319619\n",
      "    val_log_likelihood: 872.732036881476\n",
      "    val_log_marginal: 483.66781404668546\n",
      "Train Epoch: 256 [512/17352 (3%)] Loss: -609.679077\n",
      "Train Epoch: 256 [10577/17352 (61%)] Loss: -496.506692\n",
      "Train Epoch: 256 [16934/17352 (98%)] Loss: -662.976995\n",
      "    epoch          : 256\n",
      "    loss           : -557.3525650736973\n",
      "    val_loss       : -536.053238747617\n",
      "    val_log_likelihood: 878.5041061776641\n",
      "    val_log_marginal: 565.0804517723092\n",
      "Train Epoch: 257 [512/17352 (3%)] Loss: -661.149780\n",
      "Train Epoch: 257 [10169/17352 (59%)] Loss: -596.387695\n",
      "Train Epoch: 257 [16958/17352 (98%)] Loss: -519.259495\n",
      "    epoch          : 257\n",
      "    loss           : -584.5646919638647\n",
      "    val_loss       : -542.7255123060036\n",
      "    val_log_likelihood: 872.15548057779\n",
      "    val_log_marginal: 565.8648754906466\n",
      "Train Epoch: 258 [512/17352 (3%)] Loss: -627.409912\n",
      "Train Epoch: 258 [10399/17352 (60%)] Loss: -666.476146\n",
      "Train Epoch: 258 [17090/17352 (98%)] Loss: -636.656963\n",
      "    epoch          : 258\n",
      "    loss           : -594.0073884992696\n",
      "    val_loss       : -504.98003504148016\n",
      "    val_log_likelihood: 867.6343278493478\n",
      "    val_log_marginal: 538.4993987501093\n",
      "Train Epoch: 259 [512/17352 (3%)] Loss: -592.296997\n",
      "Train Epoch: 259 [10687/17352 (62%)] Loss: -567.438699\n",
      "Train Epoch: 259 [16957/17352 (98%)] Loss: -489.133185\n",
      "    epoch          : 259\n",
      "    loss           : -461.3247862491765\n",
      "    val_loss       : -429.26832910536496\n",
      "    val_log_likelihood: 801.1176752787294\n",
      "    val_log_marginal: 476.88617275007033\n",
      "Train Epoch: 260 [512/17352 (3%)] Loss: -569.285034\n",
      "Train Epoch: 260 [10919/17352 (63%)] Loss: -644.304987\n",
      "Train Epoch: 260 [17124/17352 (99%)] Loss: -659.200843\n",
      "    epoch          : 260\n",
      "    loss           : -551.2327209939474\n",
      "    val_loss       : -503.4054412181843\n",
      "    val_log_likelihood: 841.2013525619952\n",
      "    val_log_marginal: 530.5105236628924\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch260.pth ...\n",
      "Train Epoch: 261 [512/17352 (3%)] Loss: -600.515015\n",
      "Train Epoch: 261 [10612/17352 (61%)] Loss: -686.652519\n",
      "Train Epoch: 261 [16878/17352 (97%)] Loss: -604.982126\n",
      "    epoch          : 261\n",
      "    loss           : -597.2252018636956\n",
      "    val_loss       : -545.9812483881891\n",
      "    val_log_likelihood: 882.8465523371367\n",
      "    val_log_marginal: 570.9108850304352\n",
      "Train Epoch: 262 [512/17352 (3%)] Loss: -657.961060\n",
      "Train Epoch: 262 [10202/17352 (59%)] Loss: -519.491164\n",
      "Train Epoch: 262 [17153/17352 (99%)] Loss: -467.171447\n",
      "    epoch          : 262\n",
      "    loss           : -547.6736405300381\n",
      "    val_loss       : -472.7852130285586\n",
      "    val_log_likelihood: 876.9787953639798\n",
      "    val_log_marginal: 502.5839041020023\n",
      "Train Epoch: 263 [512/17352 (3%)] Loss: -563.218201\n",
      "Train Epoch: 263 [10179/17352 (59%)] Loss: -214.430933\n",
      "Train Epoch: 263 [17126/17352 (99%)] Loss: -364.402497\n",
      "    epoch          : 263\n",
      "    loss           : -300.15032112991804\n",
      "    val_loss       : -159.0650792835814\n",
      "    val_log_likelihood: 700.1588263810105\n",
      "    val_log_marginal: 234.75388116378068\n",
      "Train Epoch: 264 [512/17352 (3%)] Loss: -344.903625\n",
      "Train Epoch: 264 [10362/17352 (60%)] Loss: -425.585650\n",
      "Train Epoch: 264 [16988/17352 (98%)] Loss: -649.363501\n",
      "    epoch          : 264\n",
      "    loss           : -479.44022917761265\n",
      "    val_loss       : -498.8665617467613\n",
      "    val_log_likelihood: 838.9698072226072\n",
      "    val_log_marginal: 523.3193291138223\n",
      "Train Epoch: 265 [512/17352 (3%)] Loss: -416.421783\n",
      "Train Epoch: 265 [10312/17352 (59%)] Loss: -318.785399\n",
      "Train Epoch: 265 [16882/17352 (97%)] Loss: -684.415904\n",
      "    epoch          : 265\n",
      "    loss           : -584.2661934474778\n",
      "    val_loss       : -537.2294648755433\n",
      "    val_log_likelihood: 877.6343295008652\n",
      "    val_log_marginal: 571.2725210593203\n",
      "Train Epoch: 266 [512/17352 (3%)] Loss: -624.345947\n",
      "Train Epoch: 266 [10663/17352 (61%)] Loss: -539.435268\n",
      "Train Epoch: 266 [17277/17352 (100%)] Loss: -656.513348\n",
      "    epoch          : 266\n",
      "    loss           : -607.7404746905481\n",
      "    val_loss       : -533.8839290530819\n",
      "    val_log_likelihood: 880.2046234474196\n",
      "    val_log_marginal: 558.7367543596404\n",
      "Train Epoch: 267 [512/17352 (3%)] Loss: -653.685974\n",
      "Train Epoch: 267 [10243/17352 (59%)] Loss: -589.633292\n",
      "Train Epoch: 267 [17133/17352 (99%)] Loss: -565.805601\n",
      "    epoch          : 267\n",
      "    loss           : -625.2704235470843\n",
      "    val_loss       : -559.4315968452578\n",
      "    val_log_likelihood: 892.4471707706718\n",
      "    val_log_marginal: 587.4373485155014\n",
      "Train Epoch: 268 [512/17352 (3%)] Loss: -676.640320\n",
      "Train Epoch: 268 [10176/17352 (59%)] Loss: -566.677015\n",
      "Train Epoch: 268 [16934/17352 (98%)] Loss: -583.496438\n",
      "    epoch          : 268\n",
      "    loss           : -627.8531285324709\n",
      "    val_loss       : -566.3579835430296\n",
      "    val_log_likelihood: 900.9137416008091\n",
      "    val_log_marginal: 585.6351823651025\n",
      "Train Epoch: 269 [512/17352 (3%)] Loss: -651.158447\n",
      "Train Epoch: 269 [9294/17352 (54%)] Loss: -624.796990\n",
      "Train Epoch: 269 [16922/17352 (98%)] Loss: -589.071847\n",
      "    epoch          : 269\n",
      "    loss           : -624.7675960538352\n",
      "    val_loss       : -562.8770384502103\n",
      "    val_log_likelihood: 904.8244613591734\n",
      "    val_log_marginal: 583.156392502591\n",
      "Train Epoch: 270 [512/17352 (3%)] Loss: -686.865784\n",
      "Train Epoch: 270 [10868/17352 (63%)] Loss: -713.049574\n",
      "Train Epoch: 270 [16992/17352 (98%)] Loss: -645.577139\n",
      "    epoch          : 270\n",
      "    loss           : -631.2785768196977\n",
      "    val_loss       : -559.0464741430028\n",
      "    val_log_likelihood: 903.5085473029746\n",
      "    val_log_marginal: 582.8664383176539\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch270.pth ...\n",
      "Train Epoch: 271 [512/17352 (3%)] Loss: -668.511963\n",
      "Train Epoch: 271 [10589/17352 (61%)] Loss: -687.001570\n",
      "Train Epoch: 271 [16958/17352 (98%)] Loss: -674.967405\n",
      "    epoch          : 271\n",
      "    loss           : -621.5979622036928\n",
      "    val_loss       : -557.4356259004671\n",
      "    val_log_likelihood: 901.5815464586615\n",
      "    val_log_marginal: 579.853964558126\n",
      "Train Epoch: 272 [512/17352 (3%)] Loss: -683.460693\n",
      "Train Epoch: 272 [10288/17352 (59%)] Loss: -394.662187\n",
      "Train Epoch: 272 [17016/17352 (98%)] Loss: -621.521689\n",
      "    epoch          : 272\n",
      "    loss           : -609.4497141863219\n",
      "    val_loss       : -533.690728263707\n",
      "    val_log_likelihood: 889.7817493577222\n",
      "    val_log_marginal: 574.7523609425332\n",
      "Train Epoch: 273 [512/17352 (3%)] Loss: -666.123291\n",
      "Train Epoch: 273 [10739/17352 (62%)] Loss: -594.447731\n",
      "Train Epoch: 273 [16939/17352 (98%)] Loss: -583.055264\n",
      "    epoch          : 273\n",
      "    loss           : -631.1573059937406\n",
      "    val_loss       : -572.1543962895284\n",
      "    val_log_likelihood: 906.9951046844162\n",
      "    val_log_marginal: 594.5207132250009\n",
      "Train Epoch: 274 [512/17352 (3%)] Loss: -695.192627\n",
      "Train Epoch: 274 [10510/17352 (61%)] Loss: -544.371602\n",
      "Train Epoch: 274 [16923/17352 (98%)] Loss: -586.687846\n",
      "    epoch          : 274\n",
      "    loss           : -575.6545880392745\n",
      "    val_loss       : -490.1384906488475\n",
      "    val_log_likelihood: 887.3588473400273\n",
      "    val_log_marginal: 549.3079748758752\n",
      "Train Epoch: 275 [512/17352 (3%)] Loss: -607.852051\n",
      "Train Epoch: 275 [10421/17352 (60%)] Loss: -429.669799\n",
      "Train Epoch: 275 [16878/17352 (97%)] Loss: -686.853150\n",
      "    epoch          : 275\n",
      "    loss           : -592.564199326878\n",
      "    val_loss       : -538.7986713781348\n",
      "    val_log_likelihood: 892.4096707653737\n",
      "    val_log_marginal: 574.3943516496854\n",
      "Train Epoch: 276 [512/17352 (3%)] Loss: -579.314880\n",
      "Train Epoch: 276 [9836/17352 (57%)] Loss: -629.687342\n",
      "Train Epoch: 276 [17126/17352 (99%)] Loss: -638.554215\n",
      "    epoch          : 276\n",
      "    loss           : -613.7032384886684\n",
      "    val_loss       : -552.4144802542239\n",
      "    val_log_likelihood: 911.3464422205566\n",
      "    val_log_marginal: 591.7436300722296\n",
      "Train Epoch: 277 [512/17352 (3%)] Loss: -643.797607\n",
      "Train Epoch: 277 [10587/17352 (61%)] Loss: -693.521336\n",
      "Train Epoch: 277 [17263/17352 (99%)] Loss: -661.993247\n",
      "    epoch          : 277\n",
      "    loss           : -614.9030592499646\n",
      "    val_loss       : -531.5443945462912\n",
      "    val_log_likelihood: 893.9891834948137\n",
      "    val_log_marginal: 561.667859759294\n",
      "Train Epoch: 278 [512/17352 (3%)] Loss: -637.064209\n",
      "Train Epoch: 278 [10205/17352 (59%)] Loss: -535.556813\n",
      "Train Epoch: 278 [16992/17352 (98%)] Loss: -657.500785\n",
      "    epoch          : 278\n",
      "    loss           : -626.3720396650808\n",
      "    val_loss       : -569.1162280574565\n",
      "    val_log_likelihood: 909.7880682086386\n",
      "    val_log_marginal: 590.4804851153979\n",
      "Train Epoch: 279 [512/17352 (3%)] Loss: -691.978455\n",
      "Train Epoch: 279 [10248/17352 (59%)] Loss: -676.354950\n",
      "Train Epoch: 279 [17049/17352 (98%)] Loss: -690.075485\n",
      "    epoch          : 279\n",
      "    loss           : -638.8033476231401\n",
      "    val_loss       : -526.1774368295256\n",
      "    val_log_likelihood: 915.9259401089162\n",
      "    val_log_marginal: 550.1700210848035\n",
      "Train Epoch: 280 [512/17352 (3%)] Loss: -628.022949\n",
      "Train Epoch: 280 [10075/17352 (58%)] Loss: -609.624041\n",
      "Train Epoch: 280 [17126/17352 (99%)] Loss: -635.125000\n",
      "    epoch          : 280\n",
      "    loss           : -621.4580366351189\n",
      "    val_loss       : -521.9787868171159\n",
      "    val_log_likelihood: 909.2718398424321\n",
      "    val_log_marginal: 542.19455738123\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch280.pth ...\n",
      "Train Epoch: 281 [512/17352 (3%)] Loss: -608.996094\n",
      "Train Epoch: 281 [10449/17352 (60%)] Loss: -769.286458\n",
      "Train Epoch: 281 [16939/17352 (98%)] Loss: -724.222688\n",
      "    epoch          : 281\n",
      "    loss           : -600.2538972472996\n",
      "    val_loss       : -540.4618578739131\n",
      "    val_log_likelihood: 912.4945078331313\n",
      "    val_log_marginal: 562.7738471471015\n",
      "Train Epoch: 282 [512/17352 (3%)] Loss: -672.371765\n",
      "Train Epoch: 282 [10846/17352 (63%)] Loss: -656.129731\n",
      "Train Epoch: 282 [16939/17352 (98%)] Loss: -479.881265\n",
      "    epoch          : 282\n",
      "    loss           : -620.7323177337701\n",
      "    val_loss       : -531.143778832314\n",
      "    val_log_likelihood: 916.9020200132013\n",
      "    val_log_marginal: 557.8827433650004\n",
      "Train Epoch: 283 [512/17352 (3%)] Loss: -617.937622\n",
      "Train Epoch: 283 [10629/17352 (61%)] Loss: -539.601562\n",
      "Train Epoch: 283 [16958/17352 (98%)] Loss: -723.632552\n",
      "    epoch          : 283\n",
      "    loss           : -629.7696361515503\n",
      "    val_loss       : -580.936990735427\n",
      "    val_log_likelihood: 921.6808939648602\n",
      "    val_log_marginal: 601.7565304732689\n",
      "Train Epoch: 284 [512/17352 (3%)] Loss: -493.608063\n",
      "Train Epoch: 284 [10382/17352 (60%)] Loss: -643.036959\n",
      "Train Epoch: 284 [17090/17352 (98%)] Loss: -572.642923\n",
      "    epoch          : 284\n",
      "    loss           : -648.710262913148\n",
      "    val_loss       : -564.7985136671067\n",
      "    val_log_likelihood: 925.6849585614642\n",
      "    val_log_marginal: 591.9137528219705\n",
      "Train Epoch: 285 [512/17352 (3%)] Loss: -675.761658\n",
      "Train Epoch: 285 [10523/17352 (61%)] Loss: -690.020356\n",
      "Train Epoch: 285 [17106/17352 (99%)] Loss: -536.970368\n",
      "    epoch          : 285\n",
      "    loss           : -612.6494103027159\n",
      "    val_loss       : -551.9992729506322\n",
      "    val_log_likelihood: 918.7751756548255\n",
      "    val_log_marginal: 580.8461393115055\n",
      "Train Epoch: 286 [512/17352 (3%)] Loss: -658.587463\n",
      "Train Epoch: 286 [10005/17352 (58%)] Loss: -425.339825\n",
      "Train Epoch: 286 [16882/17352 (97%)] Loss: -565.880664\n",
      "    epoch          : 286\n",
      "    loss           : -602.7460335157579\n",
      "    val_loss       : -455.3680244595835\n",
      "    val_log_likelihood: 920.9611877961449\n",
      "    val_log_marginal: 480.4441162924955\n",
      "Train Epoch: 287 [512/17352 (3%)] Loss: -545.447388\n",
      "Train Epoch: 287 [10365/17352 (60%)] Loss: -674.079792\n",
      "Train Epoch: 287 [16923/17352 (98%)] Loss: -736.646543\n",
      "    epoch          : 287\n",
      "    loss           : -600.3039742059693\n",
      "    val_loss       : -560.5600300050519\n",
      "    val_log_likelihood: 924.9277461960328\n",
      "    val_log_marginal: 587.3311053316436\n",
      "Train Epoch: 288 [512/17352 (3%)] Loss: -679.564636\n",
      "Train Epoch: 288 [10838/17352 (62%)] Loss: -634.419385\n",
      "Train Epoch: 288 [17263/17352 (99%)] Loss: -607.939281\n",
      "    epoch          : 288\n",
      "    loss           : -648.8829107635981\n",
      "    val_loss       : -506.35323525207843\n",
      "    val_log_likelihood: 910.590760584645\n",
      "    val_log_marginal: 532.8494392020567\n",
      "Train Epoch: 289 [512/17352 (3%)] Loss: -627.854614\n",
      "Train Epoch: 289 [10226/17352 (59%)] Loss: -646.778415\n",
      "Train Epoch: 289 [16934/17352 (98%)] Loss: -698.708838\n",
      "    epoch          : 289\n",
      "    loss           : -619.4012920458247\n",
      "    val_loss       : -542.812631800257\n",
      "    val_log_likelihood: 915.5910003147192\n",
      "    val_log_marginal: 569.9887663353587\n",
      "Train Epoch: 290 [512/17352 (3%)] Loss: -665.163452\n",
      "Train Epoch: 290 [9682/17352 (56%)] Loss: -689.747304\n",
      "Train Epoch: 290 [17090/17352 (98%)] Loss: -673.689714\n",
      "    epoch          : 290\n",
      "    loss           : -650.3965806691045\n",
      "    val_loss       : -532.7486555067552\n",
      "    val_log_likelihood: 936.7858426161065\n",
      "    val_log_marginal: 564.5325879346927\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch290.pth ...\n",
      "Train Epoch: 291 [512/17352 (3%)] Loss: -641.074951\n",
      "Train Epoch: 291 [10458/17352 (60%)] Loss: -502.773611\n",
      "Train Epoch: 291 [17124/17352 (99%)] Loss: -575.593091\n",
      "    epoch          : 291\n",
      "    loss           : -595.5327885361814\n",
      "    val_loss       : -541.8609304281069\n",
      "    val_log_likelihood: 919.2864722770788\n",
      "    val_log_marginal: 579.6811624296714\n",
      "Train Epoch: 292 [512/17352 (3%)] Loss: -667.523193\n",
      "Train Epoch: 292 [10123/17352 (58%)] Loss: -491.059973\n",
      "Train Epoch: 292 [16883/17352 (97%)] Loss: -719.831329\n",
      "    epoch          : 292\n",
      "    loss           : -631.3590513120508\n",
      "    val_loss       : -517.0157199527613\n",
      "    val_log_likelihood: 914.3715415305247\n",
      "    val_log_marginal: 533.9623853214359\n",
      "Train Epoch: 293 [512/17352 (3%)] Loss: -635.610046\n",
      "Train Epoch: 293 [10673/17352 (62%)] Loss: -661.282035\n",
      "Train Epoch: 293 [16922/17352 (98%)] Loss: -724.614241\n",
      "    epoch          : 293\n",
      "    loss           : -606.605056542256\n",
      "    val_loss       : -558.5699543346798\n",
      "    val_log_likelihood: 925.5760226526213\n",
      "    val_log_marginal: 585.6160053966702\n",
      "Train Epoch: 294 [512/17352 (3%)] Loss: -695.676208\n",
      "Train Epoch: 294 [10691/17352 (62%)] Loss: -738.456456\n",
      "Train Epoch: 294 [16922/17352 (98%)] Loss: -730.105251\n",
      "    epoch          : 294\n",
      "    loss           : -651.6350761704588\n",
      "    val_loss       : -590.5805419512741\n",
      "    val_log_likelihood: 942.8565061126956\n",
      "    val_log_marginal: 610.5862521477908\n",
      "Train Epoch: 295 [512/17352 (3%)] Loss: -694.823975\n",
      "Train Epoch: 295 [10184/17352 (59%)] Loss: -689.449531\n",
      "Train Epoch: 295 [17263/17352 (99%)] Loss: -691.943605\n",
      "    epoch          : 295\n",
      "    loss           : -635.4842033928023\n",
      "    val_loss       : -537.6117833880822\n",
      "    val_log_likelihood: 929.9890532945985\n",
      "    val_log_marginal: 567.5061235308519\n",
      "Train Epoch: 296 [512/17352 (3%)] Loss: -455.913910\n",
      "Train Epoch: 296 [10372/17352 (60%)] Loss: -596.373008\n",
      "Train Epoch: 296 [16992/17352 (98%)] Loss: -497.267676\n",
      "    epoch          : 296\n",
      "    loss           : -586.8332526298441\n",
      "    val_loss       : -361.3864123422424\n",
      "    val_log_likelihood: 905.2711713797361\n",
      "    val_log_marginal: 403.9811305912934\n",
      "Train Epoch: 297 [512/17352 (3%)] Loss: -524.616150\n",
      "Train Epoch: 297 [10614/17352 (61%)] Loss: -374.628758\n",
      "Train Epoch: 297 [16958/17352 (98%)] Loss: -546.118001\n",
      "    epoch          : 297\n",
      "    loss           : -310.9531492567098\n",
      "    val_loss       : 229.3318440360463\n",
      "    val_log_likelihood: 775.8405976923566\n",
      "    val_log_marginal: -169.98507251841593\n",
      "Train Epoch: 298 [512/17352 (3%)] Loss: 238.608246\n",
      "Train Epoch: 298 [10428/17352 (60%)] Loss: -511.955775\n",
      "Train Epoch: 298 [17277/17352 (100%)] Loss: -669.106782\n",
      "    epoch          : 298\n",
      "    loss           : -361.32761826150096\n",
      "    val_loss       : -385.7346433505496\n",
      "    val_log_likelihood: 843.3128029177502\n",
      "    val_log_marginal: 420.90693172860216\n",
      "Train Epoch: 299 [512/17352 (3%)] Loss: -548.618652\n",
      "Train Epoch: 299 [9810/17352 (57%)] Loss: -688.782076\n",
      "Train Epoch: 299 [16883/17352 (97%)] Loss: -581.948054\n",
      "    epoch          : 299\n",
      "    loss           : -585.4460001064301\n",
      "    val_loss       : -554.2818456582833\n",
      "    val_log_likelihood: 895.03674776651\n",
      "    val_log_marginal: 580.671014649571\n",
      "Train Epoch: 300 [512/17352 (3%)] Loss: -672.510742\n",
      "Train Epoch: 300 [10448/17352 (60%)] Loss: -559.934462\n",
      "Train Epoch: 300 [16988/17352 (98%)] Loss: -570.120130\n",
      "    epoch          : 300\n",
      "    loss           : -637.0366275826818\n",
      "    val_loss       : -565.309803135002\n",
      "    val_log_likelihood: 934.4742014944218\n",
      "    val_log_marginal: 592.8871276781242\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch300.pth ...\n",
      "Train Epoch: 301 [512/17352 (3%)] Loss: -721.333191\n",
      "Train Epoch: 301 [10860/17352 (63%)] Loss: -746.106848\n",
      "Train Epoch: 301 [16872/17352 (97%)] Loss: -640.812902\n",
      "    epoch          : 301\n",
      "    loss           : -667.0951216118949\n",
      "    val_loss       : -589.3767036063432\n",
      "    val_log_likelihood: 937.3292991169282\n",
      "    val_log_marginal: 609.2394187026817\n",
      "Train Epoch: 302 [512/17352 (3%)] Loss: -721.309814\n",
      "Train Epoch: 302 [10094/17352 (58%)] Loss: -640.501953\n",
      "Train Epoch: 302 [17124/17352 (99%)] Loss: -726.990407\n",
      "    epoch          : 302\n",
      "    loss           : -671.2368256164269\n",
      "    val_loss       : -584.5280886210213\n",
      "    val_log_likelihood: 949.8798256530605\n",
      "    val_log_marginal: 612.8380752652618\n",
      "Train Epoch: 303 [512/17352 (3%)] Loss: -696.446655\n",
      "Train Epoch: 303 [10644/17352 (61%)] Loss: -745.199227\n",
      "Train Epoch: 303 [17126/17352 (99%)] Loss: -649.997854\n",
      "    epoch          : 303\n",
      "    loss           : -665.7494252374496\n",
      "    val_loss       : -556.0230479203835\n",
      "    val_log_likelihood: 918.0101596122992\n",
      "    val_log_marginal: 578.6865065787254\n",
      "Train Epoch: 304 [512/17352 (3%)] Loss: -669.203674\n",
      "Train Epoch: 304 [10773/17352 (62%)] Loss: -420.642045\n",
      "Train Epoch: 304 [16887/17352 (97%)] Loss: -646.534004\n",
      "    epoch          : 304\n",
      "    loss           : -658.9304610908011\n",
      "    val_loss       : -587.0654068837522\n",
      "    val_log_likelihood: 946.5975914088141\n",
      "    val_log_marginal: 613.5500361922386\n",
      "Train Epoch: 305 [512/17352 (3%)] Loss: -728.138306\n",
      "Train Epoch: 305 [10652/17352 (61%)] Loss: -527.832947\n",
      "Train Epoch: 305 [16957/17352 (98%)] Loss: -721.703802\n",
      "    epoch          : 305\n",
      "    loss           : -665.623963036818\n",
      "    val_loss       : -603.7469041735272\n",
      "    val_log_likelihood: 952.7202007587275\n",
      "    val_log_marginal: 621.0962763022582\n",
      "Train Epoch: 306 [512/17352 (3%)] Loss: -550.284912\n",
      "Train Epoch: 306 [10658/17352 (61%)] Loss: -807.236382\n",
      "Train Epoch: 306 [17133/17352 (99%)] Loss: -765.712924\n",
      "    epoch          : 306\n",
      "    loss           : -683.4945628055085\n",
      "    val_loss       : -601.9390128155045\n",
      "    val_log_likelihood: 949.9462117060469\n",
      "    val_log_marginal: 619.6076902722075\n",
      "Train Epoch: 307 [512/17352 (3%)] Loss: -722.031738\n",
      "Train Epoch: 307 [9669/17352 (56%)] Loss: -683.479452\n",
      "Train Epoch: 307 [17049/17352 (98%)] Loss: -747.648002\n",
      "    epoch          : 307\n",
      "    loss           : -660.658540196596\n",
      "    val_loss       : -582.0993609706387\n",
      "    val_log_likelihood: 945.9324806222749\n",
      "    val_log_marginal: 614.8596459742156\n",
      "Train Epoch: 308 [512/17352 (3%)] Loss: -707.464355\n",
      "Train Epoch: 308 [10365/17352 (60%)] Loss: -740.254038\n",
      "Train Epoch: 308 [17143/17352 (99%)] Loss: -727.747747\n",
      "    epoch          : 308\n",
      "    loss           : -667.8393119352403\n",
      "    val_loss       : -595.7160089410587\n",
      "    val_log_likelihood: 950.4518119978702\n",
      "    val_log_marginal: 613.3949312587995\n",
      "Train Epoch: 309 [512/17352 (3%)] Loss: -713.706665\n",
      "Train Epoch: 309 [10198/17352 (59%)] Loss: -744.778956\n",
      "Train Epoch: 309 [16922/17352 (98%)] Loss: -807.337674\n",
      "    epoch          : 309\n",
      "    loss           : -671.0589123138828\n",
      "    val_loss       : -557.3502763687463\n",
      "    val_log_likelihood: 953.4008260691264\n",
      "    val_log_marginal: 601.277226992198\n",
      "Train Epoch: 310 [512/17352 (3%)] Loss: -718.933960\n",
      "Train Epoch: 310 [9957/17352 (57%)] Loss: -728.295356\n",
      "Train Epoch: 310 [17335/17352 (100%)] Loss: -673.211490\n",
      "    epoch          : 310\n",
      "    loss           : -656.0784211007165\n",
      "    val_loss       : -557.3846378515822\n",
      "    val_log_likelihood: 935.3811922167483\n",
      "    val_log_marginal: 580.6321166819881\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch310.pth ...\n",
      "Train Epoch: 311 [512/17352 (3%)] Loss: -705.833374\n",
      "Train Epoch: 311 [10072/17352 (58%)] Loss: -686.143726\n",
      "Train Epoch: 311 [17108/17352 (99%)] Loss: -771.118902\n",
      "    epoch          : 311\n",
      "    loss           : -665.0844217899561\n",
      "    val_loss       : -583.9515745249032\n",
      "    val_log_likelihood: 955.5493420118936\n",
      "    val_log_marginal: 611.9958277717421\n",
      "Train Epoch: 312 [512/17352 (3%)] Loss: -722.581299\n",
      "Train Epoch: 312 [10390/17352 (60%)] Loss: -685.702197\n",
      "Train Epoch: 312 [17124/17352 (99%)] Loss: -579.178467\n",
      "    epoch          : 312\n",
      "    loss           : -678.1687671142498\n",
      "    val_loss       : -603.619424842556\n",
      "    val_log_likelihood: 969.9374202287856\n",
      "    val_log_marginal: 631.8624045869958\n",
      "Train Epoch: 313 [512/17352 (3%)] Loss: -730.410522\n",
      "Train Epoch: 313 [9989/17352 (58%)] Loss: -758.266895\n",
      "Train Epoch: 313 [16887/17352 (97%)] Loss: -600.961282\n",
      "    epoch          : 313\n",
      "    loss           : -682.0688957512085\n",
      "    val_loss       : -554.5066779512102\n",
      "    val_log_likelihood: 930.2311591182588\n",
      "    val_log_marginal: 570.499182496347\n",
      "Train Epoch: 314 [512/17352 (3%)] Loss: -650.878479\n",
      "Train Epoch: 314 [9648/17352 (56%)] Loss: -750.690038\n",
      "Train Epoch: 314 [17143/17352 (99%)] Loss: -601.740843\n",
      "    epoch          : 314\n",
      "    loss           : -668.7379265436239\n",
      "    val_loss       : -597.0323075317103\n",
      "    val_log_likelihood: 960.5500542021745\n",
      "    val_log_marginal: 621.9288637422993\n",
      "Train Epoch: 315 [512/17352 (3%)] Loss: -710.628479\n",
      "Train Epoch: 315 [10731/17352 (62%)] Loss: -521.935519\n",
      "Train Epoch: 315 [17101/17352 (99%)] Loss: -578.878764\n",
      "    epoch          : 315\n",
      "    loss           : -693.7354321353963\n",
      "    val_loss       : -600.0540937574389\n",
      "    val_log_likelihood: 975.8591394796307\n",
      "    val_log_marginal: 620.3059382015981\n",
      "Train Epoch: 316 [512/17352 (3%)] Loss: -730.919922\n",
      "Train Epoch: 316 [10315/17352 (59%)] Loss: -635.850564\n",
      "Train Epoch: 316 [16988/17352 (98%)] Loss: -759.981977\n",
      "    epoch          : 316\n",
      "    loss           : -692.5825084387153\n",
      "    val_loss       : -600.8030157261339\n",
      "    val_log_likelihood: 974.1860549202272\n",
      "    val_log_marginal: 623.5471584943951\n",
      "Train Epoch: 317 [512/17352 (3%)] Loss: -712.989746\n",
      "Train Epoch: 317 [10252/17352 (59%)] Loss: -524.164604\n",
      "Train Epoch: 317 [16883/17352 (97%)] Loss: -619.373463\n",
      "    epoch          : 317\n",
      "    loss           : -673.7185947428839\n",
      "    val_loss       : -589.379807035684\n",
      "    val_log_likelihood: 966.2578213549991\n",
      "    val_log_marginal: 617.2549628375882\n",
      "Train Epoch: 318 [512/17352 (3%)] Loss: -685.956909\n",
      "Train Epoch: 318 [10198/17352 (59%)] Loss: -602.189229\n",
      "Train Epoch: 318 [17263/17352 (99%)] Loss: -773.893723\n",
      "    epoch          : 318\n",
      "    loss           : -683.7859204011618\n",
      "    val_loss       : -587.9548956449744\n",
      "    val_log_likelihood: 968.4139493365726\n",
      "    val_log_marginal: 602.115374532271\n",
      "Train Epoch: 319 [512/17352 (3%)] Loss: -724.711060\n",
      "Train Epoch: 319 [10938/17352 (63%)] Loss: -604.656436\n",
      "Train Epoch: 319 [17253/17352 (99%)] Loss: -545.230301\n",
      "    epoch          : 319\n",
      "    loss           : -686.2989537838127\n",
      "    val_loss       : -603.8396751452264\n",
      "    val_log_likelihood: 982.2583984845909\n",
      "    val_log_marginal: 631.2005344756428\n",
      "Train Epoch: 320 [512/17352 (3%)] Loss: -752.811768\n",
      "Train Epoch: 320 [10384/17352 (60%)] Loss: -626.316795\n",
      "Train Epoch: 320 [17335/17352 (100%)] Loss: -603.805702\n",
      "    epoch          : 320\n",
      "    loss           : -691.1216006967322\n",
      "    val_loss       : -592.2056628757431\n",
      "    val_log_likelihood: 970.0507525079199\n",
      "    val_log_marginal: 621.6453362459931\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch320.pth ...\n",
      "Train Epoch: 321 [512/17352 (3%)] Loss: -687.462402\n",
      "Train Epoch: 321 [10303/17352 (59%)] Loss: -742.669310\n",
      "Train Epoch: 321 [16957/17352 (98%)] Loss: -704.183073\n",
      "    epoch          : 321\n",
      "    loss           : -686.0398566662061\n",
      "    val_loss       : -600.7105998712734\n",
      "    val_log_likelihood: 981.7071247050256\n",
      "    val_log_marginal: 623.5277549220049\n",
      "Train Epoch: 322 [512/17352 (3%)] Loss: -753.420105\n",
      "Train Epoch: 322 [10409/17352 (60%)] Loss: -791.106758\n",
      "Train Epoch: 322 [16883/17352 (97%)] Loss: -581.717949\n",
      "    epoch          : 322\n",
      "    loss           : -703.7147930067345\n",
      "    val_loss       : -618.5853950190073\n",
      "    val_log_likelihood: 985.9291479994047\n",
      "    val_log_marginal: 637.7478107754282\n",
      "Train Epoch: 323 [512/17352 (3%)] Loss: -770.437256\n",
      "Train Epoch: 323 [10569/17352 (61%)] Loss: -758.564070\n",
      "Train Epoch: 323 [17101/17352 (99%)] Loss: -741.168950\n",
      "    epoch          : 323\n",
      "    loss           : -700.8103798820486\n",
      "    val_loss       : -621.0304186675157\n",
      "    val_log_likelihood: 990.4127632396633\n",
      "    val_log_marginal: 640.2181206781964\n",
      "Train Epoch: 324 [512/17352 (3%)] Loss: -747.751587\n",
      "Train Epoch: 324 [10214/17352 (59%)] Loss: -632.689519\n",
      "Train Epoch: 324 [17277/17352 (100%)] Loss: -610.760696\n",
      "    epoch          : 324\n",
      "    loss           : -698.1122028476718\n",
      "    val_loss       : -605.6386981469235\n",
      "    val_log_likelihood: 990.1882068030438\n",
      "    val_log_marginal: 629.6449016771192\n",
      "Train Epoch: 325 [512/17352 (3%)] Loss: -732.849976\n",
      "Train Epoch: 325 [10995/17352 (63%)] Loss: -637.697483\n",
      "Train Epoch: 325 [16988/17352 (98%)] Loss: -685.519466\n",
      "    epoch          : 325\n",
      "    loss           : -678.8052424533031\n",
      "    val_loss       : -560.509540525755\n",
      "    val_log_likelihood: 970.0637981796488\n",
      "    val_log_marginal: 605.6282908005571\n",
      "Train Epoch: 326 [512/17352 (3%)] Loss: -581.302856\n",
      "Train Epoch: 326 [10077/17352 (58%)] Loss: -530.526815\n",
      "Train Epoch: 326 [17253/17352 (99%)] Loss: -468.809098\n",
      "    epoch          : 326\n",
      "    loss           : -632.9593179785827\n",
      "    val_loss       : -544.962124361957\n",
      "    val_log_likelihood: 962.187269798719\n",
      "    val_log_marginal: 599.9403304647898\n",
      "Train Epoch: 327 [512/17352 (3%)] Loss: -670.515381\n",
      "Train Epoch: 327 [10143/17352 (58%)] Loss: -556.376302\n",
      "Train Epoch: 327 [17106/17352 (99%)] Loss: -589.545109\n",
      "    epoch          : 327\n",
      "    loss           : -548.5851579954666\n",
      "    val_loss       : -422.16061505143614\n",
      "    val_log_likelihood: 896.6252748538296\n",
      "    val_log_marginal: 532.3186266712382\n",
      "Train Epoch: 328 [512/17352 (3%)] Loss: -567.411011\n",
      "Train Epoch: 328 [10962/17352 (63%)] Loss: -747.071809\n",
      "Train Epoch: 328 [16887/17352 (97%)] Loss: -751.373576\n",
      "    epoch          : 328\n",
      "    loss           : -587.7069875656017\n",
      "    val_loss       : -545.5245285914207\n",
      "    val_log_likelihood: 937.6916232246497\n",
      "    val_log_marginal: 589.6115956053667\n",
      "Train Epoch: 329 [512/17352 (3%)] Loss: -705.254517\n",
      "Train Epoch: 329 [10195/17352 (59%)] Loss: -657.214583\n",
      "Train Epoch: 329 [16934/17352 (98%)] Loss: -441.716566\n",
      "    epoch          : 329\n",
      "    loss           : -633.5027785000315\n",
      "    val_loss       : -590.027366022334\n",
      "    val_log_likelihood: 956.0941429276044\n",
      "    val_log_marginal: 617.2850695718483\n",
      "Train Epoch: 330 [512/17352 (3%)] Loss: -687.253967\n",
      "Train Epoch: 330 [10149/17352 (58%)] Loss: -643.850946\n",
      "Train Epoch: 330 [16957/17352 (98%)] Loss: -644.903349\n",
      "    epoch          : 330\n",
      "    loss           : -667.3450456067566\n",
      "    val_loss       : -584.4699456753541\n",
      "    val_log_likelihood: 967.8436801761925\n",
      "    val_log_marginal: 619.3349076435833\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch330.pth ...\n",
      "Train Epoch: 331 [512/17352 (3%)] Loss: -735.789978\n",
      "Train Epoch: 331 [9778/17352 (56%)] Loss: -733.529908\n",
      "Train Epoch: 331 [17124/17352 (99%)] Loss: -702.173231\n",
      "    epoch          : 331\n",
      "    loss           : -669.1475609427313\n",
      "    val_loss       : -563.6472250881893\n",
      "    val_log_likelihood: 962.7681468614718\n",
      "    val_log_marginal: 591.5022159060061\n",
      "Train Epoch: 332 [512/17352 (3%)] Loss: -725.937317\n",
      "Train Epoch: 332 [10091/17352 (58%)] Loss: -535.516640\n",
      "Train Epoch: 332 [16923/17352 (98%)] Loss: -633.533491\n",
      "    epoch          : 332\n",
      "    loss           : -662.8166278916184\n",
      "    val_loss       : -602.8597637840415\n",
      "    val_log_likelihood: 982.5742550999955\n",
      "    val_log_marginal: 634.41549712793\n",
      "Train Epoch: 333 [512/17352 (3%)] Loss: -751.378601\n",
      "Train Epoch: 333 [10653/17352 (61%)] Loss: -718.634265\n",
      "Train Epoch: 333 [17101/17352 (99%)] Loss: -713.326258\n",
      "    epoch          : 333\n",
      "    loss           : -687.6207733468797\n",
      "    val_loss       : -573.8835694327281\n",
      "    val_log_likelihood: 975.2102254221584\n",
      "    val_log_marginal: 595.5193960532956\n",
      "Train Epoch: 334 [512/17352 (3%)] Loss: -730.965027\n",
      "Train Epoch: 334 [10699/17352 (62%)] Loss: -795.693513\n",
      "Train Epoch: 334 [17277/17352 (100%)] Loss: -574.499794\n",
      "    epoch          : 334\n",
      "    loss           : -679.222193212332\n",
      "    val_loss       : -503.3596449980284\n",
      "    val_log_likelihood: 975.8250030578598\n",
      "    val_log_marginal: 534.6766335181378\n",
      "Train Epoch: 335 [512/17352 (3%)] Loss: -677.426636\n",
      "Train Epoch: 335 [9721/17352 (56%)] Loss: -423.873092\n",
      "Train Epoch: 335 [17133/17352 (99%)] Loss: -567.295436\n",
      "    epoch          : 335\n",
      "    loss           : -589.3294040323107\n",
      "    val_loss       : -457.6338004989189\n",
      "    val_log_likelihood: 908.2745427206203\n",
      "    val_log_marginal: 511.1671744780592\n",
      "Train Epoch: 336 [512/17352 (3%)] Loss: -627.824097\n",
      "Train Epoch: 336 [9939/17352 (57%)] Loss: -464.511230\n",
      "Train Epoch: 336 [17016/17352 (98%)] Loss: -355.432357\n",
      "    epoch          : 336\n",
      "    loss           : -279.0204281357812\n",
      "    val_loss       : 194.28783776194572\n",
      "    val_log_likelihood: 809.1615239548937\n",
      "    val_log_marginal: -154.64387655583872\n",
      "Train Epoch: 337 [512/17352 (3%)] Loss: 59.827557\n",
      "Train Epoch: 337 [10316/17352 (59%)] Loss: -345.570825\n",
      "Train Epoch: 337 [17126/17352 (99%)] Loss: -578.562233\n",
      "    epoch          : 337\n",
      "    loss           : -342.87161480328484\n",
      "    val_loss       : -423.85487915292526\n",
      "    val_log_likelihood: 876.6245283454289\n",
      "    val_log_marginal: 452.52842248543516\n",
      "Train Epoch: 338 [512/17352 (3%)] Loss: -545.010376\n",
      "Train Epoch: 338 [9991/17352 (58%)] Loss: -546.972208\n",
      "Train Epoch: 338 [16934/17352 (98%)] Loss: -520.529356\n",
      "    epoch          : 338\n",
      "    loss           : -598.948213113176\n",
      "    val_loss       : -566.1851399333888\n",
      "    val_log_likelihood: 942.424553068393\n",
      "    val_log_marginal: 596.1282914653348\n",
      "Train Epoch: 339 [512/17352 (3%)] Loss: -705.630432\n",
      "Train Epoch: 339 [10301/17352 (59%)] Loss: -708.024089\n",
      "Train Epoch: 339 [17106/17352 (99%)] Loss: -766.346923\n",
      "    epoch          : 339\n",
      "    loss           : -680.1634316174607\n",
      "    val_loss       : -590.6933767994855\n",
      "    val_log_likelihood: 963.9676699404177\n",
      "    val_log_marginal: 616.1507362367539\n",
      "Train Epoch: 340 [512/17352 (3%)] Loss: -728.980591\n",
      "Train Epoch: 340 [10073/17352 (58%)] Loss: -497.190239\n",
      "Train Epoch: 340 [16988/17352 (98%)] Loss: -737.748418\n",
      "    epoch          : 340\n",
      "    loss           : -657.9014461074524\n",
      "    val_loss       : -585.8366619217343\n",
      "    val_log_likelihood: 951.4811735912334\n",
      "    val_log_marginal: 620.7274899403009\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch340.pth ...\n",
      "Train Epoch: 341 [512/17352 (3%)] Loss: -715.251709\n",
      "Train Epoch: 341 [10180/17352 (59%)] Loss: -734.102755\n",
      "Train Epoch: 341 [16934/17352 (98%)] Loss: -738.717808\n",
      "    epoch          : 341\n",
      "    loss           : -685.6974919880362\n",
      "    val_loss       : -618.4929945365406\n",
      "    val_log_likelihood: 978.3656409380758\n",
      "    val_log_marginal: 643.489525699017\n",
      "Train Epoch: 342 [512/17352 (3%)] Loss: -558.031616\n",
      "Train Epoch: 342 [10643/17352 (61%)] Loss: -784.280301\n",
      "Train Epoch: 342 [16887/17352 (97%)] Loss: -793.555478\n",
      "    epoch          : 342\n",
      "    loss           : -706.1209049804412\n",
      "    val_loss       : -623.1981175377161\n",
      "    val_log_likelihood: 987.6739929709894\n",
      "    val_log_marginal: 641.1902606154508\n",
      "Train Epoch: 343 [512/17352 (3%)] Loss: -722.443359\n",
      "Train Epoch: 343 [10681/17352 (62%)] Loss: -755.831336\n",
      "Train Epoch: 343 [16872/17352 (97%)] Loss: -606.958984\n",
      "    epoch          : 343\n",
      "    loss           : -692.820805457784\n",
      "    val_loss       : -572.5001536306846\n",
      "    val_log_likelihood: 983.0705325603326\n",
      "    val_log_marginal: 612.0672606320892\n",
      "Train Epoch: 344 [512/17352 (3%)] Loss: -698.110535\n",
      "Train Epoch: 344 [10574/17352 (61%)] Loss: -598.125457\n",
      "Train Epoch: 344 [16939/17352 (98%)] Loss: -581.542285\n",
      "    epoch          : 344\n",
      "    loss           : -688.2199079540012\n",
      "    val_loss       : -610.0043684619285\n",
      "    val_log_likelihood: 981.2695374418615\n",
      "    val_log_marginal: 638.2356156589863\n",
      "Train Epoch: 345 [512/17352 (3%)] Loss: -749.320923\n",
      "Train Epoch: 345 [10303/17352 (59%)] Loss: -747.685459\n",
      "Train Epoch: 345 [16957/17352 (98%)] Loss: -535.509121\n",
      "    epoch          : 345\n",
      "    loss           : -709.6727545351166\n",
      "    val_loss       : -594.793833941927\n",
      "    val_log_likelihood: 991.2739350127363\n",
      "    val_log_marginal: 622.4020064029437\n",
      "Train Epoch: 346 [512/17352 (3%)] Loss: -726.865967\n",
      "Train Epoch: 346 [10267/17352 (59%)] Loss: -696.310718\n",
      "Train Epoch: 346 [17277/17352 (100%)] Loss: -754.232407\n",
      "    epoch          : 346\n",
      "    loss           : -707.8600963747404\n",
      "    val_loss       : -614.8235422776148\n",
      "    val_log_likelihood: 990.733002026826\n",
      "    val_log_marginal: 637.7669476225954\n",
      "Train Epoch: 347 [512/17352 (3%)] Loss: -762.478210\n",
      "Train Epoch: 347 [10490/17352 (60%)] Loss: -763.092816\n",
      "Train Epoch: 347 [16934/17352 (98%)] Loss: -652.792132\n",
      "    epoch          : 347\n",
      "    loss           : -699.3047039624739\n",
      "    val_loss       : -622.3711291953852\n",
      "    val_log_likelihood: 994.5214660263546\n",
      "    val_log_marginal: 643.2564699733521\n",
      "Train Epoch: 348 [512/17352 (3%)] Loss: -754.961426\n",
      "Train Epoch: 348 [9968/17352 (57%)] Loss: -741.350424\n",
      "Train Epoch: 348 [17253/17352 (99%)] Loss: -785.591066\n",
      "    epoch          : 348\n",
      "    loss           : -695.3015173125856\n",
      "    val_loss       : -603.6434411733081\n",
      "    val_log_likelihood: 983.4920064904339\n",
      "    val_log_marginal: 637.268837253881\n",
      "Train Epoch: 349 [512/17352 (3%)] Loss: -760.253235\n",
      "Train Epoch: 349 [10774/17352 (62%)] Loss: -732.966951\n",
      "Train Epoch: 349 [16934/17352 (98%)] Loss: -638.080767\n",
      "    epoch          : 349\n",
      "    loss           : -685.7483736699486\n",
      "    val_loss       : -594.2879014189141\n",
      "    val_log_likelihood: 983.1244871440994\n",
      "    val_log_marginal: 624.6558966475593\n",
      "Train Epoch: 350 [512/17352 (3%)] Loss: -746.708740\n",
      "Train Epoch: 350 [10737/17352 (62%)] Loss: -627.761567\n",
      "Train Epoch: 350 [17153/17352 (99%)] Loss: -745.770456\n",
      "    epoch          : 350\n",
      "    loss           : -709.2423117164675\n",
      "    val_loss       : -619.9993183309612\n",
      "    val_log_likelihood: 1000.5789950296867\n",
      "    val_log_marginal: 652.4368834245067\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch350.pth ...\n",
      "Train Epoch: 351 [512/17352 (3%)] Loss: -730.496643\n",
      "Train Epoch: 351 [9867/17352 (57%)] Loss: -776.058391\n",
      "Train Epoch: 351 [16939/17352 (98%)] Loss: -859.566026\n",
      "    epoch          : 351\n",
      "    loss           : -724.4243676740399\n",
      "    val_loss       : -627.1675246736526\n",
      "    val_log_likelihood: 1000.5511388339528\n",
      "    val_log_marginal: 649.4967419901648\n",
      "Train Epoch: 352 [512/17352 (3%)] Loss: -773.661438\n",
      "Train Epoch: 352 [10376/17352 (60%)] Loss: -793.619936\n",
      "Train Epoch: 352 [17263/17352 (99%)] Loss: -783.914312\n",
      "    epoch          : 352\n",
      "    loss           : -731.6873821070615\n",
      "    val_loss       : -622.7171881902788\n",
      "    val_log_likelihood: 1000.2898645192203\n",
      "    val_log_marginal: 641.4706258907165\n",
      "Train Epoch: 353 [512/17352 (3%)] Loss: -763.649536\n",
      "Train Epoch: 353 [10182/17352 (59%)] Loss: -798.286979\n",
      "Train Epoch: 353 [17064/17352 (98%)] Loss: -794.008866\n",
      "    epoch          : 353\n",
      "    loss           : -728.6446839709909\n",
      "    val_loss       : -638.3660368575544\n",
      "    val_log_likelihood: 1016.7906506907801\n",
      "    val_log_marginal: 662.8436166432724\n",
      "Train Epoch: 354 [512/17352 (3%)] Loss: -776.229736\n",
      "Train Epoch: 354 [10646/17352 (61%)] Loss: -796.378496\n",
      "Train Epoch: 354 [16882/17352 (97%)] Loss: -744.876975\n",
      "    epoch          : 354\n",
      "    loss           : -735.3741379636957\n",
      "    val_loss       : -636.5221028628827\n",
      "    val_log_likelihood: 1021.0954269134578\n",
      "    val_log_marginal: 661.2817901312067\n",
      "Train Epoch: 355 [512/17352 (3%)] Loss: -791.461182\n",
      "Train Epoch: 355 [10339/17352 (60%)] Loss: -791.935055\n",
      "Train Epoch: 355 [16957/17352 (98%)] Loss: -741.026121\n",
      "    epoch          : 355\n",
      "    loss           : -739.8555597651309\n",
      "    val_loss       : -637.3485827261619\n",
      "    val_log_likelihood: 1024.3570354508574\n",
      "    val_log_marginal: 659.4000835854024\n",
      "Train Epoch: 356 [512/17352 (3%)] Loss: -795.974670\n",
      "Train Epoch: 356 [10764/17352 (62%)] Loss: -662.785816\n",
      "Train Epoch: 356 [16883/17352 (97%)] Loss: -705.725931\n",
      "    epoch          : 356\n",
      "    loss           : -736.4165654849818\n",
      "    val_loss       : -636.4366789285069\n",
      "    val_log_likelihood: 1017.5051596848439\n",
      "    val_log_marginal: 661.4356554357898\n",
      "Train Epoch: 357 [512/17352 (3%)] Loss: -788.282166\n",
      "Train Epoch: 357 [10306/17352 (59%)] Loss: -814.061967\n",
      "Train Epoch: 357 [17277/17352 (100%)] Loss: -785.967101\n",
      "    epoch          : 357\n",
      "    loss           : -727.5318158176638\n",
      "    val_loss       : -626.9007165782049\n",
      "    val_log_likelihood: 1020.5885880249992\n",
      "    val_log_marginal: 655.441011634448\n",
      "Train Epoch: 358 [512/17352 (3%)] Loss: -780.809692\n",
      "Train Epoch: 358 [10461/17352 (60%)] Loss: -826.321962\n",
      "Train Epoch: 358 [17124/17352 (99%)] Loss: -681.162760\n",
      "    epoch          : 358\n",
      "    loss           : -734.4388083646214\n",
      "    val_loss       : -599.9722301909899\n",
      "    val_log_likelihood: 1000.0620522698931\n",
      "    val_log_marginal: 621.7457147152548\n",
      "Train Epoch: 359 [512/17352 (3%)] Loss: -749.016663\n",
      "Train Epoch: 359 [9930/17352 (57%)] Loss: -663.098447\n",
      "Train Epoch: 359 [17124/17352 (99%)] Loss: -763.181079\n",
      "    epoch          : 359\n",
      "    loss           : -731.1518935365284\n",
      "    val_loss       : -617.7785013634077\n",
      "    val_log_likelihood: 1013.6722624562175\n",
      "    val_log_marginal: 636.234108114815\n",
      "Train Epoch: 360 [512/17352 (3%)] Loss: -781.077393\n",
      "Train Epoch: 360 [10301/17352 (59%)] Loss: -676.951406\n",
      "Train Epoch: 360 [16922/17352 (98%)] Loss: -835.726544\n",
      "    epoch          : 360\n",
      "    loss           : -724.0504333171966\n",
      "    val_loss       : -633.4865819698169\n",
      "    val_log_likelihood: 1020.0793290977559\n",
      "    val_log_marginal: 657.7144885606853\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch360.pth ...\n",
      "Train Epoch: 361 [512/17352 (3%)] Loss: -764.327759\n",
      "Train Epoch: 361 [10200/17352 (59%)] Loss: -567.917614\n",
      "Train Epoch: 361 [17153/17352 (99%)] Loss: -703.216485\n",
      "    epoch          : 361\n",
      "    loss           : -626.623057933378\n",
      "    val_loss       : -386.3147093061326\n",
      "    val_log_likelihood: 979.6305173446249\n",
      "    val_log_marginal: 411.0050646372784\n",
      "Train Epoch: 362 [512/17352 (3%)] Loss: -545.780762\n",
      "Train Epoch: 362 [10421/17352 (60%)] Loss: -618.571600\n",
      "Train Epoch: 362 [17064/17352 (98%)] Loss: -651.098090\n",
      "    epoch          : 362\n",
      "    loss           : -572.8413928668188\n",
      "    val_loss       : -332.2854404650327\n",
      "    val_log_likelihood: 951.7714388732522\n",
      "    val_log_marginal: 356.67101044755765\n",
      "Train Epoch: 363 [512/17352 (3%)] Loss: -432.025330\n",
      "Train Epoch: 363 [10073/17352 (58%)] Loss: -509.262178\n",
      "Train Epoch: 363 [16958/17352 (98%)] Loss: -712.448165\n",
      "    epoch          : 363\n",
      "    loss           : -557.5153043459138\n",
      "    val_loss       : -572.6769130538961\n",
      "    val_log_likelihood: 961.0215677088487\n",
      "    val_log_marginal: 602.9030139863922\n",
      "Train Epoch: 364 [512/17352 (3%)] Loss: -729.327881\n",
      "Train Epoch: 364 [10868/17352 (63%)] Loss: -771.387209\n",
      "Train Epoch: 364 [17049/17352 (98%)] Loss: -656.695593\n",
      "    epoch          : 364\n",
      "    loss           : -660.9533362492942\n",
      "    val_loss       : -543.0742996890762\n",
      "    val_log_likelihood: 962.5613436429035\n",
      "    val_log_marginal: 573.7391708997453\n",
      "Train Epoch: 365 [512/17352 (3%)] Loss: -591.342773\n",
      "Train Epoch: 365 [10254/17352 (59%)] Loss: -583.607449\n",
      "Train Epoch: 365 [16887/17352 (97%)] Loss: -755.672775\n",
      "    epoch          : 365\n",
      "    loss           : -605.580114164703\n",
      "    val_loss       : -548.8864778211425\n",
      "    val_log_likelihood: 947.9968544967996\n",
      "    val_log_marginal: 596.2890528932129\n",
      "Train Epoch: 366 [512/17352 (3%)] Loss: -696.669373\n",
      "Train Epoch: 366 [10414/17352 (60%)] Loss: -480.325199\n",
      "Train Epoch: 366 [17335/17352 (100%)] Loss: -681.712649\n",
      "    epoch          : 366\n",
      "    loss           : -591.9936594648208\n",
      "    val_loss       : -249.3601838661255\n",
      "    val_log_likelihood: 822.8695004000707\n",
      "    val_log_marginal: 415.50836594715406\n",
      "Train Epoch: 367 [512/17352 (3%)] Loss: -514.752319\n",
      "Train Epoch: 367 [9813/17352 (57%)] Loss: -686.515729\n",
      "Train Epoch: 367 [16887/17352 (97%)] Loss: -670.461487\n",
      "    epoch          : 367\n",
      "    loss           : -558.6605915652918\n",
      "    val_loss       : -498.0003994214856\n",
      "    val_log_likelihood: 907.0847806906426\n",
      "    val_log_marginal: 553.4060039772088\n",
      "Train Epoch: 368 [512/17352 (3%)] Loss: -226.102844\n",
      "Train Epoch: 368 [10278/17352 (59%)] Loss: -465.972379\n",
      "Train Epoch: 368 [16934/17352 (98%)] Loss: -497.721105\n",
      "    epoch          : 368\n",
      "    loss           : -635.7662446104417\n",
      "    val_loss       : -537.5473312121288\n",
      "    val_log_likelihood: 917.6231405491867\n",
      "    val_log_marginal: 569.8170955787778\n",
      "Train Epoch: 369 [512/17352 (3%)] Loss: -676.968689\n",
      "Train Epoch: 369 [9963/17352 (57%)] Loss: -711.191555\n",
      "Train Epoch: 369 [17124/17352 (99%)] Loss: -816.527327\n",
      "    epoch          : 369\n",
      "    loss           : -668.8352621771504\n",
      "    val_loss       : -590.3378099688232\n",
      "    val_log_likelihood: 975.8877653646681\n",
      "    val_log_marginal: 627.714882906523\n",
      "Train Epoch: 370 [512/17352 (3%)] Loss: -734.455627\n",
      "Train Epoch: 370 [10309/17352 (59%)] Loss: -579.462871\n",
      "Train Epoch: 370 [16878/17352 (97%)] Loss: -623.519187\n",
      "    epoch          : 370\n",
      "    loss           : -709.2006434274493\n",
      "    val_loss       : -630.9564488771274\n",
      "    val_log_likelihood: 1003.4976137505773\n",
      "    val_log_marginal: 657.516305443316\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch370.pth ...\n",
      "Train Epoch: 371 [512/17352 (3%)] Loss: -764.980103\n",
      "Train Epoch: 371 [10575/17352 (61%)] Loss: -669.964149\n",
      "Train Epoch: 371 [17106/17352 (99%)] Loss: -709.564360\n",
      "    epoch          : 371\n",
      "    loss           : -726.3767850309172\n",
      "    val_loss       : -643.5055106696486\n",
      "    val_log_likelihood: 1019.3960591048731\n",
      "    val_log_marginal: 666.6952767456476\n",
      "Train Epoch: 372 [512/17352 (3%)] Loss: -788.895874\n",
      "Train Epoch: 372 [10475/17352 (60%)] Loss: -676.473937\n",
      "Train Epoch: 372 [17263/17352 (99%)] Loss: -559.175651\n",
      "    epoch          : 372\n",
      "    loss           : -717.4919629017046\n",
      "    val_loss       : -534.1135213543192\n",
      "    val_log_likelihood: 1011.6780165655329\n",
      "    val_log_marginal: 580.1769299017571\n",
      "Train Epoch: 373 [512/17352 (3%)] Loss: -693.946533\n",
      "Train Epoch: 373 [10679/17352 (62%)] Loss: -678.534940\n",
      "Train Epoch: 373 [17108/17352 (99%)] Loss: -555.511737\n",
      "    epoch          : 373\n",
      "    loss           : -640.0439467470059\n",
      "    val_loss       : -568.8667285998222\n",
      "    val_log_likelihood: 967.1710341697752\n",
      "    val_log_marginal: 596.4205745098183\n",
      "Train Epoch: 374 [512/17352 (3%)] Loss: -699.252502\n",
      "Train Epoch: 374 [10540/17352 (61%)] Loss: -618.438337\n",
      "Train Epoch: 374 [16922/17352 (98%)] Loss: -771.884132\n",
      "    epoch          : 374\n",
      "    loss           : -690.3895026789257\n",
      "    val_loss       : -613.3577373907713\n",
      "    val_log_likelihood: 999.5737822586121\n",
      "    val_log_marginal: 640.2805748873578\n",
      "Train Epoch: 375 [512/17352 (3%)] Loss: -546.180847\n",
      "Train Epoch: 375 [10252/17352 (59%)] Loss: -803.934738\n",
      "Train Epoch: 375 [17106/17352 (99%)] Loss: -727.218176\n",
      "    epoch          : 375\n",
      "    loss           : -730.7348020026801\n",
      "    val_loss       : -629.2025350225325\n",
      "    val_log_likelihood: 1012.8989464566575\n",
      "    val_log_marginal: 652.1296539690921\n",
      "Train Epoch: 376 [512/17352 (3%)] Loss: -736.908508\n",
      "Train Epoch: 376 [10174/17352 (59%)] Loss: -742.936287\n",
      "Train Epoch: 376 [16923/17352 (98%)] Loss: -744.093198\n",
      "    epoch          : 376\n",
      "    loss           : -716.320489041319\n",
      "    val_loss       : -638.4056400383026\n",
      "    val_log_likelihood: 1018.0078326008073\n",
      "    val_log_marginal: 664.2041759311705\n",
      "Train Epoch: 377 [512/17352 (3%)] Loss: -767.329102\n",
      "Train Epoch: 377 [10362/17352 (60%)] Loss: -782.649094\n",
      "Train Epoch: 377 [17106/17352 (99%)] Loss: -759.962151\n",
      "    epoch          : 377\n",
      "    loss           : -730.4742543955598\n",
      "    val_loss       : -614.7930027293826\n",
      "    val_log_likelihood: 1024.9610784666047\n",
      "    val_log_marginal: 641.7569148156593\n",
      "Train Epoch: 378 [512/17352 (3%)] Loss: -779.228943\n",
      "Train Epoch: 378 [10470/17352 (60%)] Loss: -780.332170\n",
      "Train Epoch: 378 [16887/17352 (97%)] Loss: -631.558797\n",
      "    epoch          : 378\n",
      "    loss           : -733.1149252614588\n",
      "    val_loss       : -604.9363669568149\n",
      "    val_log_likelihood: 1019.3784367695644\n",
      "    val_log_marginal: 618.1654881046502\n",
      "Train Epoch: 379 [512/17352 (3%)] Loss: -753.910767\n",
      "Train Epoch: 379 [10356/17352 (60%)] Loss: -818.162992\n",
      "Train Epoch: 379 [16992/17352 (98%)] Loss: -835.829255\n",
      "    epoch          : 379\n",
      "    loss           : -732.9671244174548\n",
      "    val_loss       : -635.0010725846954\n",
      "    val_log_likelihood: 1027.5956142294979\n",
      "    val_log_marginal: 660.727692249581\n",
      "Train Epoch: 380 [512/17352 (3%)] Loss: -782.177124\n",
      "Train Epoch: 380 [10416/17352 (60%)] Loss: -834.286392\n",
      "Train Epoch: 380 [17153/17352 (99%)] Loss: -704.508650\n",
      "    epoch          : 380\n",
      "    loss           : -750.4441770259112\n",
      "    val_loss       : -637.4402333499232\n",
      "    val_log_likelihood: 1033.7853366337263\n",
      "    val_log_marginal: 667.0489818766383\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch380.pth ...\n",
      "Train Epoch: 381 [512/17352 (3%)] Loss: -803.303589\n",
      "Train Epoch: 381 [10191/17352 (59%)] Loss: -800.866310\n",
      "Train Epoch: 381 [17153/17352 (99%)] Loss: -634.744318\n",
      "    epoch          : 381\n",
      "    loss           : -749.8967283711843\n",
      "    val_loss       : -650.3032828077794\n",
      "    val_log_likelihood: 1041.565467884681\n",
      "    val_log_marginal: 672.4300700421933\n",
      "Train Epoch: 382 [512/17352 (3%)] Loss: -789.459473\n",
      "Train Epoch: 382 [10388/17352 (60%)] Loss: -805.623854\n",
      "Train Epoch: 382 [16923/17352 (98%)] Loss: -611.200804\n",
      "    epoch          : 382\n",
      "    loss           : -754.5819899634728\n",
      "    val_loss       : -649.4258859298909\n",
      "    val_log_likelihood: 1041.4717597826304\n",
      "    val_log_marginal: 669.007657662036\n",
      "Train Epoch: 383 [512/17352 (3%)] Loss: -797.647217\n",
      "Train Epoch: 383 [10454/17352 (60%)] Loss: -797.432355\n",
      "Train Epoch: 383 [17101/17352 (99%)] Loss: -774.905857\n",
      "    epoch          : 383\n",
      "    loss           : -731.7575496493075\n",
      "    val_loss       : -619.8539739097555\n",
      "    val_log_likelihood: 1031.312947237426\n",
      "    val_log_marginal: 636.6789480997995\n",
      "Train Epoch: 384 [512/17352 (3%)] Loss: -785.749268\n",
      "Train Epoch: 384 [9570/17352 (55%)] Loss: -759.364215\n",
      "Train Epoch: 384 [16883/17352 (97%)] Loss: -689.609418\n",
      "    epoch          : 384\n",
      "    loss           : -746.1908329105773\n",
      "    val_loss       : -644.9225145623834\n",
      "    val_log_likelihood: 1036.5866796586997\n",
      "    val_log_marginal: 671.1679585492748\n",
      "Train Epoch: 385 [512/17352 (3%)] Loss: -804.894409\n",
      "Train Epoch: 385 [10760/17352 (62%)] Loss: -814.844746\n",
      "Train Epoch: 385 [17124/17352 (99%)] Loss: -645.504735\n",
      "    epoch          : 385\n",
      "    loss           : -752.5549089875661\n",
      "    val_loss       : -644.5411926272045\n",
      "    val_log_likelihood: 1039.1203192515227\n",
      "    val_log_marginal: 675.1484313300135\n",
      "Train Epoch: 386 [512/17352 (3%)] Loss: -793.661377\n",
      "Train Epoch: 386 [10192/17352 (59%)] Loss: -819.294695\n",
      "Train Epoch: 386 [17101/17352 (99%)] Loss: -692.182018\n",
      "    epoch          : 386\n",
      "    loss           : -709.0092861175408\n",
      "    val_loss       : -206.31117277825655\n",
      "    val_log_likelihood: 981.0953290929274\n",
      "    val_log_marginal: 243.57307046880496\n",
      "Train Epoch: 387 [512/17352 (3%)] Loss: -484.902985\n",
      "Train Epoch: 387 [10179/17352 (59%)] Loss: -657.740113\n",
      "Train Epoch: 387 [16992/17352 (98%)] Loss: -742.628776\n",
      "    epoch          : 387\n",
      "    loss           : -670.1124988893179\n",
      "    val_loss       : -591.2973945882607\n",
      "    val_log_likelihood: 1018.6114779929019\n",
      "    val_log_marginal: 614.7819405878123\n",
      "Train Epoch: 388 [512/17352 (3%)] Loss: -741.907227\n",
      "Train Epoch: 388 [10018/17352 (58%)] Loss: -677.518694\n",
      "Train Epoch: 388 [17143/17352 (99%)] Loss: -717.207089\n",
      "    epoch          : 388\n",
      "    loss           : -726.3611623020379\n",
      "    val_loss       : -620.764181369032\n",
      "    val_log_likelihood: 1021.3205341453571\n",
      "    val_log_marginal: 644.2775566170118\n",
      "Train Epoch: 389 [512/17352 (3%)] Loss: -775.067261\n",
      "Train Epoch: 389 [10237/17352 (59%)] Loss: -617.322088\n",
      "Train Epoch: 389 [17133/17352 (99%)] Loss: -715.215187\n",
      "    epoch          : 389\n",
      "    loss           : -706.1227140473375\n",
      "    val_loss       : -595.5887585855165\n",
      "    val_log_likelihood: 1031.5874539107965\n",
      "    val_log_marginal: 621.1289740623458\n",
      "Train Epoch: 390 [512/17352 (3%)] Loss: -729.484924\n",
      "Train Epoch: 390 [10252/17352 (59%)] Loss: -733.126727\n",
      "Train Epoch: 390 [17124/17352 (99%)] Loss: -383.834182\n",
      "    epoch          : 390\n",
      "    loss           : -409.46643378769886\n",
      "    val_loss       : -206.6985445012056\n",
      "    val_log_likelihood: 866.3807757272461\n",
      "    val_log_marginal: 266.49828711715435\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch390.pth ...\n",
      "Train Epoch: 391 [512/17352 (3%)] Loss: -380.715424\n",
      "Train Epoch: 391 [10573/17352 (61%)] Loss: -417.876395\n",
      "Train Epoch: 391 [16923/17352 (98%)] Loss: -611.399805\n",
      "    epoch          : 391\n",
      "    loss           : -554.8658732198182\n",
      "    val_loss       : -577.3828891924979\n",
      "    val_log_likelihood: 973.2642292515377\n",
      "    val_log_marginal: 618.0086762810472\n",
      "Train Epoch: 392 [512/17352 (3%)] Loss: -732.383423\n",
      "Train Epoch: 392 [10099/17352 (58%)] Loss: -726.057357\n",
      "Train Epoch: 392 [17106/17352 (99%)] Loss: -523.390999\n",
      "    epoch          : 392\n",
      "    loss           : -712.7964405467048\n",
      "    val_loss       : -632.6207527466646\n",
      "    val_log_likelihood: 1020.6892463676002\n",
      "    val_log_marginal: 660.0353683702754\n",
      "Train Epoch: 393 [512/17352 (3%)] Loss: -762.888611\n",
      "Train Epoch: 393 [10150/17352 (58%)] Loss: -685.516927\n",
      "Train Epoch: 393 [16939/17352 (98%)] Loss: -783.903277\n",
      "    epoch          : 393\n",
      "    loss           : -744.5054672555235\n",
      "    val_loss       : -637.4096307137519\n",
      "    val_log_likelihood: 1028.9550110443663\n",
      "    val_log_marginal: 651.7919055016628\n",
      "Train Epoch: 394 [512/17352 (3%)] Loss: -786.001160\n",
      "Train Epoch: 394 [10520/17352 (61%)] Loss: -693.410063\n",
      "Train Epoch: 394 [17133/17352 (99%)] Loss: -686.526511\n",
      "    epoch          : 394\n",
      "    loss           : -755.4399648212982\n",
      "    val_loss       : -647.8053467622154\n",
      "    val_log_likelihood: 1037.7915236531044\n",
      "    val_log_marginal: 668.0655481405132\n",
      "Train Epoch: 395 [512/17352 (3%)] Loss: -799.763184\n",
      "Train Epoch: 395 [10270/17352 (59%)] Loss: -689.405353\n",
      "Train Epoch: 395 [16988/17352 (98%)] Loss: -655.267067\n",
      "    epoch          : 395\n",
      "    loss           : -748.6405672729845\n",
      "    val_loss       : -644.1008204903104\n",
      "    val_log_likelihood: 1042.7407360252\n",
      "    val_log_marginal: 666.0672203924596\n",
      "Train Epoch: 396 [512/17352 (3%)] Loss: -560.803467\n",
      "Train Epoch: 396 [10540/17352 (61%)] Loss: -822.878191\n",
      "Train Epoch: 396 [17126/17352 (99%)] Loss: -791.435881\n",
      "    epoch          : 396\n",
      "    loss           : -751.6905111746956\n",
      "    val_loss       : -631.1824131058665\n",
      "    val_log_likelihood: 1044.1336952253898\n",
      "    val_log_marginal: 650.133860204423\n",
      "Train Epoch: 397 [512/17352 (3%)] Loss: -786.945435\n",
      "Train Epoch: 397 [10353/17352 (60%)] Loss: -827.247965\n",
      "Train Epoch: 397 [17124/17352 (99%)] Loss: -818.245210\n",
      "    epoch          : 397\n",
      "    loss           : -763.8974192996502\n",
      "    val_loss       : -655.9539372944444\n",
      "    val_log_likelihood: 1053.80186352495\n",
      "    val_log_marginal: 679.460514304142\n",
      "Train Epoch: 398 [512/17352 (3%)] Loss: -815.774658\n",
      "Train Epoch: 398 [10701/17352 (62%)] Loss: -816.413164\n",
      "Train Epoch: 398 [17106/17352 (99%)] Loss: -731.512881\n",
      "    epoch          : 398\n",
      "    loss           : -771.0087451044852\n",
      "    val_loss       : -646.6648414007777\n",
      "    val_log_likelihood: 1052.2904905317969\n",
      "    val_log_marginal: 669.6920467301334\n",
      "Train Epoch: 399 [512/17352 (3%)] Loss: -815.096680\n",
      "Train Epoch: 399 [10295/17352 (59%)] Loss: -849.937035\n",
      "Train Epoch: 399 [17049/17352 (98%)] Loss: -788.165375\n",
      "    epoch          : 399\n",
      "    loss           : -762.2585920289048\n",
      "    val_loss       : -660.1547368060999\n",
      "    val_log_likelihood: 1057.5914688449686\n",
      "    val_log_marginal: 683.6364478985258\n",
      "Train Epoch: 400 [512/17352 (3%)] Loss: -792.192932\n",
      "Train Epoch: 400 [9528/17352 (55%)] Loss: -660.827350\n",
      "Train Epoch: 400 [16923/17352 (98%)] Loss: -726.301085\n",
      "    epoch          : 400\n",
      "    loss           : -747.5213670112728\n",
      "    val_loss       : -652.9850894095525\n",
      "    val_log_likelihood: 1051.8124468818605\n",
      "    val_log_marginal: 679.2473314267858\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch400.pth ...\n",
      "Train Epoch: 401 [512/17352 (3%)] Loss: -797.811768\n",
      "Train Epoch: 401 [9657/17352 (56%)] Loss: -875.642403\n",
      "Train Epoch: 401 [16882/17352 (97%)] Loss: -783.254831\n",
      "    epoch          : 401\n",
      "    loss           : -758.4927381123734\n",
      "    val_loss       : -644.7094064884548\n",
      "    val_log_likelihood: 1055.3718357190585\n",
      "    val_log_marginal: 672.9618386769412\n",
      "Train Epoch: 402 [512/17352 (3%)] Loss: -821.369690\n",
      "Train Epoch: 402 [10550/17352 (61%)] Loss: -727.788281\n",
      "Train Epoch: 402 [16958/17352 (98%)] Loss: -844.988673\n",
      "    epoch          : 402\n",
      "    loss           : -769.0651941291951\n",
      "    val_loss       : -648.4899467343656\n",
      "    val_log_likelihood: 1058.3342801467986\n",
      "    val_log_marginal: 676.5835362638126\n",
      "Train Epoch: 403 [512/17352 (3%)] Loss: -832.223633\n",
      "Train Epoch: 403 [10295/17352 (59%)] Loss: -596.048113\n",
      "Train Epoch: 403 [16887/17352 (97%)] Loss: -810.911355\n",
      "    epoch          : 403\n",
      "    loss           : -753.4407353951663\n",
      "    val_loss       : -655.9539324928008\n",
      "    val_log_likelihood: 1059.4591078058436\n",
      "    val_log_marginal: 681.804008107585\n",
      "Train Epoch: 404 [512/17352 (3%)] Loss: -799.193237\n",
      "Train Epoch: 404 [10120/17352 (58%)] Loss: -832.416045\n",
      "Train Epoch: 404 [17253/17352 (99%)] Loss: -836.888404\n",
      "    epoch          : 404\n",
      "    loss           : -763.5043046528812\n",
      "    val_loss       : -629.0594514712196\n",
      "    val_log_likelihood: 1043.7321343918172\n",
      "    val_log_marginal: 644.3845986930406\n",
      "Train Epoch: 405 [512/17352 (3%)] Loss: -800.572083\n",
      "Train Epoch: 405 [10434/17352 (60%)] Loss: -856.587500\n",
      "Train Epoch: 405 [17106/17352 (99%)] Loss: -719.251581\n",
      "    epoch          : 405\n",
      "    loss           : -757.9773824093644\n",
      "    val_loss       : -620.5073533102639\n",
      "    val_log_likelihood: 1037.3545621801095\n",
      "    val_log_marginal: 642.3623179011043\n",
      "Train Epoch: 406 [512/17352 (3%)] Loss: -791.003784\n",
      "Train Epoch: 406 [10634/17352 (61%)] Loss: -641.308566\n",
      "Train Epoch: 406 [17124/17352 (99%)] Loss: -768.812960\n",
      "    epoch          : 406\n",
      "    loss           : -761.2013016642733\n",
      "    val_loss       : -639.1057535325875\n",
      "    val_log_likelihood: 1045.424598621503\n",
      "    val_log_marginal: 660.9309734762727\n",
      "Train Epoch: 407 [512/17352 (3%)] Loss: -805.779846\n",
      "Train Epoch: 407 [10770/17352 (62%)] Loss: -590.250739\n",
      "Train Epoch: 407 [16992/17352 (98%)] Loss: -642.944493\n",
      "    epoch          : 407\n",
      "    loss           : -766.1397787622178\n",
      "    val_loss       : -656.300921590299\n",
      "    val_log_likelihood: 1059.1279334090425\n",
      "    val_log_marginal: 675.008669871028\n",
      "Train Epoch: 408 [512/17352 (3%)] Loss: -815.144348\n",
      "Train Epoch: 408 [9633/17352 (56%)] Loss: -857.347612\n",
      "Train Epoch: 408 [17101/17352 (99%)] Loss: -870.178989\n",
      "    epoch          : 408\n",
      "    loss           : -773.3229897109397\n",
      "    val_loss       : -652.0505768160842\n",
      "    val_log_likelihood: 1064.2041895820446\n",
      "    val_log_marginal: 675.5800850104141\n",
      "Train Epoch: 409 [512/17352 (3%)] Loss: -795.933777\n",
      "Train Epoch: 409 [10748/17352 (62%)] Loss: -610.805242\n",
      "Train Epoch: 409 [16988/17352 (98%)] Loss: -646.482736\n",
      "    epoch          : 409\n",
      "    loss           : -764.0830071479044\n",
      "    val_loss       : -666.2386509899865\n",
      "    val_log_likelihood: 1068.2496707664693\n",
      "    val_log_marginal: 683.0185288004999\n",
      "Train Epoch: 410 [512/17352 (3%)] Loss: -821.660522\n",
      "Train Epoch: 410 [10555/17352 (61%)] Loss: -703.803005\n",
      "Train Epoch: 410 [17108/17352 (99%)] Loss: -856.825902\n",
      "    epoch          : 410\n",
      "    loss           : -761.0085762367602\n",
      "    val_loss       : -589.728001376208\n",
      "    val_log_likelihood: 1017.0805839909619\n",
      "    val_log_marginal: 623.7063030998627\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch410.pth ...\n",
      "Train Epoch: 411 [512/17352 (3%)] Loss: -736.205444\n",
      "Train Epoch: 411 [10279/17352 (59%)] Loss: -650.480382\n",
      "Train Epoch: 411 [17064/17352 (98%)] Loss: -840.200817\n",
      "    epoch          : 411\n",
      "    loss           : -736.0246027222897\n",
      "    val_loss       : -629.5002828579875\n",
      "    val_log_likelihood: 1047.5922704496872\n",
      "    val_log_marginal: 649.863252357802\n",
      "Train Epoch: 412 [512/17352 (3%)] Loss: -794.356812\n",
      "Train Epoch: 412 [9608/17352 (55%)] Loss: -860.577482\n",
      "Train Epoch: 412 [17277/17352 (100%)] Loss: -846.130814\n",
      "    epoch          : 412\n",
      "    loss           : -754.6666966563938\n",
      "    val_loss       : -607.0424300817292\n",
      "    val_log_likelihood: 1041.2219224047117\n",
      "    val_log_marginal: 642.3527553566117\n",
      "Train Epoch: 413 [512/17352 (3%)] Loss: -800.873779\n",
      "Train Epoch: 413 [10542/17352 (61%)] Loss: -810.179795\n",
      "Train Epoch: 413 [16883/17352 (97%)] Loss: -673.196322\n",
      "    epoch          : 413\n",
      "    loss           : -761.0072799889838\n",
      "    val_loss       : -671.29742450399\n",
      "    val_log_likelihood: 1070.2432502609104\n",
      "    val_log_marginal: 691.7236092748624\n",
      "Train Epoch: 414 [512/17352 (3%)] Loss: -828.223633\n",
      "Train Epoch: 414 [10877/17352 (63%)] Loss: -686.341006\n",
      "Train Epoch: 414 [17253/17352 (99%)] Loss: -860.671748\n",
      "    epoch          : 414\n",
      "    loss           : -739.1873187424853\n",
      "    val_loss       : -628.0230250947902\n",
      "    val_log_likelihood: 1053.487820404303\n",
      "    val_log_marginal: 660.1399532071853\n",
      "Train Epoch: 415 [512/17352 (3%)] Loss: -808.712585\n",
      "Train Epoch: 415 [10482/17352 (60%)] Loss: -762.171188\n",
      "Train Epoch: 415 [17106/17352 (99%)] Loss: -607.949536\n",
      "    epoch          : 415\n",
      "    loss           : -773.7900249291415\n",
      "    val_loss       : -641.1878543457821\n",
      "    val_log_likelihood: 1067.9871946136348\n",
      "    val_log_marginal: 660.1394467061696\n",
      "Train Epoch: 416 [512/17352 (3%)] Loss: -812.164307\n",
      "Train Epoch: 416 [10705/17352 (62%)] Loss: -856.448683\n",
      "Train Epoch: 416 [16988/17352 (98%)] Loss: -702.857205\n",
      "    epoch          : 416\n",
      "    loss           : -764.4327865605167\n",
      "    val_loss       : -646.1188348582841\n",
      "    val_log_likelihood: 1058.631432557521\n",
      "    val_log_marginal: 674.1665682724839\n",
      "Train Epoch: 417 [512/17352 (3%)] Loss: -822.723633\n",
      "Train Epoch: 417 [9928/17352 (57%)] Loss: -779.900518\n",
      "Train Epoch: 417 [16958/17352 (98%)] Loss: -739.970933\n",
      "    epoch          : 417\n",
      "    loss           : -756.7937763291266\n",
      "    val_loss       : -606.9450376736551\n",
      "    val_log_likelihood: 1059.2129144233097\n",
      "    val_log_marginal: 661.7638024356535\n",
      "Train Epoch: 418 [512/17352 (3%)] Loss: -771.515015\n",
      "Train Epoch: 418 [9976/17352 (57%)] Loss: -614.616908\n",
      "Train Epoch: 418 [16958/17352 (98%)] Loss: -649.203734\n",
      "    epoch          : 418\n",
      "    loss           : -722.5032096602821\n",
      "    val_loss       : -613.1551386643254\n",
      "    val_log_likelihood: 1054.028935560798\n",
      "    val_log_marginal: 638.8197463678098\n",
      "Train Epoch: 419 [512/17352 (3%)] Loss: -780.981934\n",
      "Train Epoch: 419 [10131/17352 (58%)] Loss: -699.041552\n",
      "Train Epoch: 419 [16958/17352 (98%)] Loss: -661.395182\n",
      "    epoch          : 419\n",
      "    loss           : -602.0113966257986\n",
      "    val_loss       : -474.3263987736573\n",
      "    val_log_likelihood: 966.7202033484156\n",
      "    val_log_marginal: 502.5638040378368\n",
      "Train Epoch: 420 [512/17352 (3%)] Loss: -689.652344\n",
      "Train Epoch: 420 [10367/17352 (60%)] Loss: -482.530511\n",
      "Train Epoch: 420 [16872/17352 (97%)] Loss: -678.396622\n",
      "    epoch          : 420\n",
      "    loss           : -561.7798004190238\n",
      "    val_loss       : -536.6018838690215\n",
      "    val_log_likelihood: 1000.9286801780643\n",
      "    val_log_marginal: 585.570506678722\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch420.pth ...\n",
      "Train Epoch: 421 [512/17352 (3%)] Loss: -722.072327\n",
      "Train Epoch: 421 [10382/17352 (60%)] Loss: -594.337685\n",
      "Train Epoch: 421 [17253/17352 (99%)] Loss: -717.040103\n",
      "    epoch          : 421\n",
      "    loss           : -613.1481072085352\n",
      "    val_loss       : -346.13447353074156\n",
      "    val_log_likelihood: 995.3498085520432\n",
      "    val_log_marginal: 365.3741508192575\n",
      "Train Epoch: 422 [512/17352 (3%)] Loss: -519.079895\n",
      "Train Epoch: 422 [10434/17352 (60%)] Loss: -628.186678\n",
      "Train Epoch: 422 [17133/17352 (99%)] Loss: -769.062945\n",
      "    epoch          : 422\n",
      "    loss           : -662.3585537052569\n",
      "    val_loss       : -602.4937890211326\n",
      "    val_log_likelihood: 1024.035185435451\n",
      "    val_log_marginal: 636.391389760056\n",
      "Train Epoch: 423 [512/17352 (3%)] Loss: -759.196899\n",
      "Train Epoch: 423 [10341/17352 (60%)] Loss: -782.139572\n",
      "Train Epoch: 423 [17253/17352 (99%)] Loss: -593.082386\n",
      "    epoch          : 423\n",
      "    loss           : -733.2404034233995\n",
      "    val_loss       : -483.15247091767134\n",
      "    val_log_likelihood: 1035.247495930635\n",
      "    val_log_marginal: 503.13476518215975\n",
      "Train Epoch: 424 [512/17352 (3%)] Loss: -613.964417\n",
      "Train Epoch: 424 [10666/17352 (61%)] Loss: -824.684768\n",
      "Train Epoch: 424 [17090/17352 (98%)] Loss: -790.111966\n",
      "    epoch          : 424\n",
      "    loss           : -735.8027155169253\n",
      "    val_loss       : -650.6186061754572\n",
      "    val_log_likelihood: 1058.3087873314823\n",
      "    val_log_marginal: 676.9358930759893\n",
      "Train Epoch: 425 [512/17352 (3%)] Loss: -788.107544\n",
      "Train Epoch: 425 [10248/17352 (59%)] Loss: -749.225411\n",
      "Train Epoch: 425 [16923/17352 (98%)] Loss: -675.184889\n",
      "    epoch          : 425\n",
      "    loss           : -751.0022203506917\n",
      "    val_loss       : -430.5530591842669\n",
      "    val_log_likelihood: 1038.0734655379115\n",
      "    val_log_marginal: 449.8588689995735\n",
      "Train Epoch: 426 [512/17352 (3%)] Loss: -541.333496\n",
      "Train Epoch: 426 [9813/17352 (57%)] Loss: -579.386059\n",
      "Train Epoch: 426 [16922/17352 (98%)] Loss: -551.884338\n",
      "    epoch          : 426\n",
      "    loss           : -543.6417188129802\n",
      "    val_loss       : -132.14757566434847\n",
      "    val_log_likelihood: 973.5850892440802\n",
      "    val_log_marginal: 170.36710953009307\n",
      "Train Epoch: 427 [512/17352 (3%)] Loss: -183.918304\n",
      "Train Epoch: 427 [10544/17352 (61%)] Loss: -827.495497\n",
      "Train Epoch: 427 [16887/17352 (97%)] Loss: -662.689798\n",
      "    epoch          : 427\n",
      "    loss           : -608.4299250295702\n",
      "    val_loss       : -602.8046627840166\n",
      "    val_log_likelihood: 1015.6576454383456\n",
      "    val_log_marginal: 643.3864459561328\n",
      "Train Epoch: 428 [512/17352 (3%)] Loss: -760.141968\n",
      "Train Epoch: 428 [10506/17352 (61%)] Loss: -817.853078\n",
      "Train Epoch: 428 [17016/17352 (98%)] Loss: -563.794947\n",
      "    epoch          : 428\n",
      "    loss           : -720.0357163710698\n",
      "    val_loss       : -616.4955034240077\n",
      "    val_log_likelihood: 1048.7620631843083\n",
      "    val_log_marginal: 645.335612016379\n",
      "Train Epoch: 429 [512/17352 (3%)] Loss: -777.025574\n",
      "Train Epoch: 429 [10833/17352 (62%)] Loss: -844.686167\n",
      "Train Epoch: 429 [17101/17352 (99%)] Loss: -814.517122\n",
      "    epoch          : 429\n",
      "    loss           : -761.1809327665371\n",
      "    val_loss       : -670.5742681016346\n",
      "    val_log_likelihood: 1071.8519665372582\n",
      "    val_log_marginal: 692.9710507304501\n",
      "Train Epoch: 430 [512/17352 (3%)] Loss: -815.522888\n",
      "Train Epoch: 430 [10399/17352 (60%)] Loss: -713.974026\n",
      "Train Epoch: 430 [16988/17352 (98%)] Loss: -839.691713\n",
      "    epoch          : 430\n",
      "    loss           : -784.8158763881063\n",
      "    val_loss       : -663.0610748012137\n",
      "    val_log_likelihood: 1073.2574097342354\n",
      "    val_log_marginal: 686.6367536009599\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch430.pth ...\n",
      "Train Epoch: 431 [512/17352 (3%)] Loss: -825.068665\n",
      "Train Epoch: 431 [9896/17352 (57%)] Loss: -844.186622\n",
      "Train Epoch: 431 [16923/17352 (98%)] Loss: -741.139813\n",
      "    epoch          : 431\n",
      "    loss           : -786.8907146938759\n",
      "    val_loss       : -668.9036956065555\n",
      "    val_log_likelihood: 1070.2353210168865\n",
      "    val_log_marginal: 686.1376107802532\n",
      "Train Epoch: 432 [512/17352 (3%)] Loss: -824.596436\n",
      "Train Epoch: 432 [10269/17352 (59%)] Loss: -784.440927\n",
      "Train Epoch: 432 [16882/17352 (97%)] Loss: -734.473575\n",
      "    epoch          : 432\n",
      "    loss           : -791.3229838939325\n",
      "    val_loss       : -669.9969754068817\n",
      "    val_log_likelihood: 1079.3225435100371\n",
      "    val_log_marginal: 694.969209277222\n",
      "Train Epoch: 433 [512/17352 (3%)] Loss: -817.069336\n",
      "Train Epoch: 433 [10667/17352 (61%)] Loss: -856.888847\n",
      "Train Epoch: 433 [17126/17352 (99%)] Loss: -564.464583\n",
      "    epoch          : 433\n",
      "    loss           : -734.1101820509082\n",
      "    val_loss       : -588.7557358340321\n",
      "    val_log_likelihood: 996.1714419448725\n",
      "    val_log_marginal: 604.0469333830838\n",
      "Train Epoch: 434 [512/17352 (3%)] Loss: -769.406616\n",
      "Train Epoch: 434 [10305/17352 (59%)] Loss: -606.851836\n",
      "Train Epoch: 434 [16887/17352 (97%)] Loss: -879.640434\n",
      "    epoch          : 434\n",
      "    loss           : -738.022612701342\n",
      "    val_loss       : -663.1692127294749\n",
      "    val_log_likelihood: 1053.5551885881116\n",
      "    val_log_marginal: 690.1196445843298\n",
      "Train Epoch: 435 [512/17352 (3%)] Loss: -823.877502\n",
      "Train Epoch: 435 [10103/17352 (58%)] Loss: -754.175207\n",
      "Train Epoch: 435 [17133/17352 (99%)] Loss: -850.283750\n",
      "    epoch          : 435\n",
      "    loss           : -775.1740496437567\n",
      "    val_loss       : -649.142863520917\n",
      "    val_log_likelihood: 1063.977563528486\n",
      "    val_log_marginal: 668.9841828866923\n",
      "Train Epoch: 436 [512/17352 (3%)] Loss: -819.007874\n",
      "Train Epoch: 436 [10198/17352 (59%)] Loss: -805.059968\n",
      "Train Epoch: 436 [16939/17352 (98%)] Loss: -864.703379\n",
      "    epoch          : 436\n",
      "    loss           : -751.7409094564479\n",
      "    val_loss       : -610.4793338665525\n",
      "    val_log_likelihood: 1042.2082114573393\n",
      "    val_log_marginal: 648.86509036552\n",
      "Train Epoch: 437 [512/17352 (3%)] Loss: -769.470093\n",
      "Train Epoch: 437 [10579/17352 (61%)] Loss: -812.078060\n",
      "Train Epoch: 437 [16887/17352 (97%)] Loss: -882.434322\n",
      "    epoch          : 437\n",
      "    loss           : -770.1357378377796\n",
      "    val_loss       : -677.8402894258293\n",
      "    val_log_likelihood: 1076.45139265248\n",
      "    val_log_marginal: 690.1941624135338\n",
      "Train Epoch: 438 [512/17352 (3%)] Loss: -839.830444\n",
      "Train Epoch: 438 [9583/17352 (55%)] Loss: -722.933594\n",
      "Train Epoch: 438 [16923/17352 (98%)] Loss: -752.331799\n",
      "    epoch          : 438\n",
      "    loss           : -796.8424870613205\n",
      "    val_loss       : -684.8381867853963\n",
      "    val_log_likelihood: 1084.770353859119\n",
      "    val_log_marginal: 700.0242716395644\n",
      "Train Epoch: 439 [512/17352 (3%)] Loss: -846.781799\n",
      "Train Epoch: 439 [10350/17352 (60%)] Loss: -887.182846\n",
      "Train Epoch: 439 [16878/17352 (97%)] Loss: -755.560417\n",
      "    epoch          : 439\n",
      "    loss           : -790.924040007977\n",
      "    val_loss       : -672.6401563233694\n",
      "    val_log_likelihood: 1087.1376857253535\n",
      "    val_log_marginal: 696.2122017172431\n",
      "Train Epoch: 440 [512/17352 (3%)] Loss: -846.440063\n",
      "Train Epoch: 440 [10263/17352 (59%)] Loss: -658.896416\n",
      "Train Epoch: 440 [17049/17352 (98%)] Loss: -849.488588\n",
      "    epoch          : 440\n",
      "    loss           : -789.9929418055402\n",
      "    val_loss       : -651.732538803016\n",
      "    val_log_likelihood: 1067.32885094437\n",
      "    val_log_marginal: 676.5760358661641\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch440.pth ...\n",
      "Train Epoch: 441 [512/17352 (3%)] Loss: -811.603760\n",
      "Train Epoch: 441 [9624/17352 (55%)] Loss: -668.927856\n",
      "Train Epoch: 441 [16878/17352 (97%)] Loss: -745.908717\n",
      "    epoch          : 441\n",
      "    loss           : -761.2541420889663\n",
      "    val_loss       : -668.1901207985543\n",
      "    val_log_likelihood: 1064.426370032766\n",
      "    val_log_marginal: 687.6589955638663\n",
      "Train Epoch: 442 [512/17352 (3%)] Loss: -817.359619\n",
      "Train Epoch: 442 [10313/17352 (59%)] Loss: -853.485000\n",
      "Train Epoch: 442 [16872/17352 (97%)] Loss: -644.934946\n",
      "    epoch          : 442\n",
      "    loss           : -789.3941310003951\n",
      "    val_loss       : -675.0408126156495\n",
      "    val_log_likelihood: 1079.9968658651424\n",
      "    val_log_marginal: 693.4647988564747\n",
      "Train Epoch: 443 [512/17352 (3%)] Loss: -847.912476\n",
      "Train Epoch: 443 [10382/17352 (60%)] Loss: -792.130666\n",
      "Train Epoch: 443 [17153/17352 (99%)] Loss: -768.249488\n",
      "    epoch          : 443\n",
      "    loss           : -809.0434308134503\n",
      "    val_loss       : -678.348504617589\n",
      "    val_log_likelihood: 1097.9977432188643\n",
      "    val_log_marginal: 702.8264383739411\n",
      "Train Epoch: 444 [512/17352 (3%)] Loss: -837.658081\n",
      "Train Epoch: 444 [9707/17352 (56%)] Loss: -905.512322\n",
      "Train Epoch: 444 [17124/17352 (99%)] Loss: -922.090929\n",
      "    epoch          : 444\n",
      "    loss           : -796.6859462610487\n",
      "    val_loss       : -673.5007624729875\n",
      "    val_log_likelihood: 1096.9913138988438\n",
      "    val_log_marginal: 695.1906944229722\n",
      "Train Epoch: 445 [512/17352 (3%)] Loss: -847.452148\n",
      "Train Epoch: 445 [10235/17352 (59%)] Loss: -756.053454\n",
      "Train Epoch: 445 [17016/17352 (98%)] Loss: -841.073806\n",
      "    epoch          : 445\n",
      "    loss           : -767.8741321965591\n",
      "    val_loss       : -642.5271756268504\n",
      "    val_log_likelihood: 1075.0625793579702\n",
      "    val_log_marginal: 670.5295691481485\n",
      "Train Epoch: 446 [512/17352 (3%)] Loss: -791.324646\n",
      "Train Epoch: 446 [10077/17352 (58%)] Loss: -795.673069\n",
      "Train Epoch: 446 [17108/17352 (99%)] Loss: -803.727616\n",
      "    epoch          : 446\n",
      "    loss           : -717.54765325182\n",
      "    val_loss       : -519.6878638136195\n",
      "    val_log_likelihood: 1070.7882078753462\n",
      "    val_log_marginal: 538.7261311178848\n",
      "Train Epoch: 447 [512/17352 (3%)] Loss: -679.983582\n",
      "Train Epoch: 447 [10463/17352 (60%)] Loss: -717.870095\n",
      "Train Epoch: 447 [16878/17352 (97%)] Loss: -814.716602\n",
      "    epoch          : 447\n",
      "    loss           : -699.6102895973222\n",
      "    val_loss       : -647.6714482720258\n",
      "    val_log_likelihood: 1068.5695106676353\n",
      "    val_log_marginal: 667.4864194271466\n",
      "Train Epoch: 448 [512/17352 (3%)] Loss: -823.684814\n",
      "Train Epoch: 448 [10785/17352 (62%)] Loss: -751.895306\n",
      "Train Epoch: 448 [17263/17352 (99%)] Loss: -644.817540\n",
      "    epoch          : 448\n",
      "    loss           : -801.3650460868942\n",
      "    val_loss       : -672.3885464687979\n",
      "    val_log_likelihood: 1100.354205382635\n",
      "    val_log_marginal: 694.2909932849954\n",
      "Train Epoch: 449 [512/17352 (3%)] Loss: -820.432251\n",
      "Train Epoch: 449 [10690/17352 (62%)] Loss: -849.537243\n",
      "Train Epoch: 449 [17064/17352 (98%)] Loss: -841.155208\n",
      "    epoch          : 449\n",
      "    loss           : -794.9986550416804\n",
      "    val_loss       : -641.8080454510512\n",
      "    val_log_likelihood: 1069.3357446236098\n",
      "    val_log_marginal: 663.8023251305473\n",
      "Train Epoch: 450 [512/17352 (3%)] Loss: -805.916931\n",
      "Train Epoch: 450 [10025/17352 (58%)] Loss: -730.682106\n",
      "Train Epoch: 450 [16878/17352 (97%)] Loss: -622.877424\n",
      "    epoch          : 450\n",
      "    loss           : -759.160867951309\n",
      "    val_loss       : -641.0410834286806\n",
      "    val_log_likelihood: 1068.5562184494831\n",
      "    val_log_marginal: 663.5098324574478\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch450.pth ...\n",
      "Train Epoch: 451 [512/17352 (3%)] Loss: -818.162109\n",
      "Train Epoch: 451 [10094/17352 (58%)] Loss: -866.978581\n",
      "Train Epoch: 451 [17108/17352 (99%)] Loss: -840.448830\n",
      "    epoch          : 451\n",
      "    loss           : -790.0082845919226\n",
      "    val_loss       : -667.9150105767305\n",
      "    val_log_likelihood: 1091.0577063569922\n",
      "    val_log_marginal: 694.0140632282731\n",
      "Train Epoch: 452 [512/17352 (3%)] Loss: -843.019226\n",
      "Train Epoch: 452 [10892/17352 (63%)] Loss: -668.521361\n",
      "Train Epoch: 452 [17049/17352 (98%)] Loss: -679.197240\n",
      "    epoch          : 452\n",
      "    loss           : -772.193611417203\n",
      "    val_loss       : -611.2811897218833\n",
      "    val_log_likelihood: 1041.8768244445712\n",
      "    val_log_marginal: 632.7029400913217\n",
      "Train Epoch: 453 [512/17352 (3%)] Loss: -809.525879\n",
      "Train Epoch: 453 [10742/17352 (62%)] Loss: -730.657851\n",
      "Train Epoch: 453 [17253/17352 (99%)] Loss: -788.356284\n",
      "    epoch          : 453\n",
      "    loss           : -794.6180260341511\n",
      "    val_loss       : -663.5249973441274\n",
      "    val_log_likelihood: 1092.2187047117523\n",
      "    val_log_marginal: 685.9051910240651\n",
      "Train Epoch: 454 [512/17352 (3%)] Loss: -827.937378\n",
      "Train Epoch: 454 [10861/17352 (63%)] Loss: -709.991696\n",
      "Train Epoch: 454 [16878/17352 (97%)] Loss: -856.792344\n",
      "    epoch          : 454\n",
      "    loss           : -807.2495659997674\n",
      "    val_loss       : -682.2627382470442\n",
      "    val_log_likelihood: 1105.1743693717963\n",
      "    val_log_marginal: 701.7554120053693\n",
      "Train Epoch: 455 [512/17352 (3%)] Loss: -859.115173\n",
      "Train Epoch: 455 [10434/17352 (60%)] Loss: -868.040214\n",
      "Train Epoch: 455 [17044/17352 (98%)] Loss: -830.187263\n",
      "    epoch          : 455\n",
      "    loss           : -818.5028316456138\n",
      "    val_loss       : -677.3150859228763\n",
      "    val_log_likelihood: 1106.8423670844656\n",
      "    val_log_marginal: 697.7355760698676\n",
      "Train Epoch: 456 [512/17352 (3%)] Loss: -857.074890\n",
      "Train Epoch: 456 [10592/17352 (61%)] Loss: -914.919779\n",
      "Train Epoch: 456 [17090/17352 (98%)] Loss: -891.388898\n",
      "    epoch          : 456\n",
      "    loss           : -817.5363604655955\n",
      "    val_loss       : -663.799865722205\n",
      "    val_log_likelihood: 1100.5560991325394\n",
      "    val_log_marginal: 684.4811227374835\n",
      "Train Epoch: 457 [512/17352 (3%)] Loss: -833.757324\n",
      "Train Epoch: 457 [9727/17352 (56%)] Loss: -911.650266\n",
      "Train Epoch: 457 [16958/17352 (98%)] Loss: -869.115365\n",
      "    epoch          : 457\n",
      "    loss           : -812.5077812238035\n",
      "    val_loss       : -684.1275524598638\n",
      "    val_log_likelihood: 1112.2796115504686\n",
      "    val_log_marginal: 710.3283589347358\n",
      "Train Epoch: 458 [512/17352 (3%)] Loss: -868.609619\n",
      "Train Epoch: 458 [9870/17352 (57%)] Loss: -902.979792\n",
      "Train Epoch: 458 [16939/17352 (98%)] Loss: -847.340923\n",
      "    epoch          : 458\n",
      "    loss           : -816.6519732659024\n",
      "    val_loss       : -670.2738865796337\n",
      "    val_log_likelihood: 1104.9498490189858\n",
      "    val_log_marginal: 699.4891571930278\n",
      "Train Epoch: 459 [512/17352 (3%)] Loss: -863.860352\n",
      "Train Epoch: 459 [10089/17352 (58%)] Loss: -668.537269\n",
      "Train Epoch: 459 [16922/17352 (98%)] Loss: -365.447271\n",
      "    epoch          : 459\n",
      "    loss           : -274.7917783642522\n",
      "    val_loss       : -66.53183474609219\n",
      "    val_log_likelihood: 864.7818444075582\n",
      "    val_log_marginal: 95.91569766264756\n",
      "Train Epoch: 460 [512/17352 (3%)] Loss: 225.770386\n",
      "Train Epoch: 460 [10515/17352 (61%)] Loss: -413.092677\n",
      "Train Epoch: 460 [16957/17352 (98%)] Loss: -515.141516\n",
      "    epoch          : 460\n",
      "    loss           : -399.9689345519372\n",
      "    val_loss       : -519.0344731634982\n",
      "    val_log_likelihood: 959.8512232997793\n",
      "    val_log_marginal: 569.3009068363547\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch460.pth ...\n",
      "Train Epoch: 461 [512/17352 (3%)] Loss: -725.739014\n",
      "Train Epoch: 461 [9856/17352 (57%)] Loss: -727.630969\n",
      "Train Epoch: 461 [17277/17352 (100%)] Loss: -736.767056\n",
      "    epoch          : 461\n",
      "    loss           : -642.8630920299138\n",
      "    val_loss       : -323.19379797921266\n",
      "    val_log_likelihood: 1034.4104198464172\n",
      "    val_log_marginal: 355.44630951882255\n",
      "Train Epoch: 462 [512/17352 (3%)] Loss: -336.392090\n",
      "Train Epoch: 462 [10489/17352 (60%)] Loss: -774.969649\n",
      "Train Epoch: 462 [16958/17352 (98%)] Loss: 399.517025\n",
      "    epoch          : 462\n",
      "    loss           : -480.18035377933705\n",
      "    val_loss       : 578.3870101919276\n",
      "    val_log_likelihood: 947.9523002523091\n",
      "    val_log_marginal: -497.7346167004895\n",
      "Train Epoch: 463 [512/17352 (3%)] Loss: 689.770325\n",
      "Train Epoch: 463 [9940/17352 (57%)] Loss: -491.906250\n",
      "Train Epoch: 463 [16922/17352 (98%)] Loss: -651.090676\n",
      "    epoch          : 463\n",
      "    loss           : -571.5729962218916\n",
      "    val_loss       : -608.4978863663961\n",
      "    val_log_likelihood: 1018.3926993448028\n",
      "    val_log_marginal: 635.468146102817\n",
      "Train Epoch: 464 [512/17352 (3%)] Loss: -735.696960\n",
      "Train Epoch: 464 [10387/17352 (60%)] Loss: -753.438468\n",
      "Train Epoch: 464 [16958/17352 (98%)] Loss: -842.350213\n",
      "    epoch          : 464\n",
      "    loss           : -751.2988785593294\n",
      "    val_loss       : -663.6080220024136\n",
      "    val_log_likelihood: 1070.1916152143187\n",
      "    val_log_marginal: 693.5870680708543\n",
      "Train Epoch: 465 [512/17352 (3%)] Loss: -825.473145\n",
      "Train Epoch: 465 [10361/17352 (60%)] Loss: -758.250558\n",
      "Train Epoch: 465 [16878/17352 (97%)] Loss: -777.574424\n",
      "    epoch          : 465\n",
      "    loss           : -792.8289503645558\n",
      "    val_loss       : -686.1364410826169\n",
      "    val_log_likelihood: 1088.7028031398152\n",
      "    val_log_marginal: 710.9065053145545\n",
      "Train Epoch: 466 [512/17352 (3%)] Loss: -846.249146\n",
      "Train Epoch: 466 [10477/17352 (60%)] Loss: -859.379709\n",
      "Train Epoch: 466 [17143/17352 (99%)] Loss: -820.891995\n",
      "    epoch          : 466\n",
      "    loss           : -800.3707571523341\n",
      "    val_loss       : -685.6928653321958\n",
      "    val_log_likelihood: 1097.9156507086168\n",
      "    val_log_marginal: 706.584216914728\n",
      "Train Epoch: 467 [512/17352 (3%)] Loss: -838.671021\n",
      "Train Epoch: 467 [10270/17352 (59%)] Loss: -798.235122\n",
      "Train Epoch: 467 [16957/17352 (98%)] Loss: -833.258435\n",
      "    epoch          : 467\n",
      "    loss           : -809.7441544916713\n",
      "    val_loss       : -690.3484779204921\n",
      "    val_log_likelihood: 1097.968218519303\n",
      "    val_log_marginal: 714.1146510615033\n",
      "Train Epoch: 468 [512/17352 (3%)] Loss: -856.907471\n",
      "Train Epoch: 468 [10269/17352 (59%)] Loss: -755.489104\n",
      "Train Epoch: 468 [17153/17352 (99%)] Loss: -919.630859\n",
      "    epoch          : 468\n",
      "    loss           : -795.4595389794097\n",
      "    val_loss       : -678.9007853464599\n",
      "    val_log_likelihood: 1094.9820011983443\n",
      "    val_log_marginal: 701.1589669975299\n",
      "Train Epoch: 469 [512/17352 (3%)] Loss: -833.245483\n",
      "Train Epoch: 469 [9988/17352 (58%)] Loss: -856.000954\n",
      "Train Epoch: 469 [17277/17352 (100%)] Loss: -802.127919\n",
      "    epoch          : 469\n",
      "    loss           : -809.5983443597676\n",
      "    val_loss       : -685.708425433755\n",
      "    val_log_likelihood: 1103.0370257310892\n",
      "    val_log_marginal: 711.3367457961173\n",
      "Train Epoch: 470 [512/17352 (3%)] Loss: -842.316589\n",
      "Train Epoch: 470 [10545/17352 (61%)] Loss: -811.188015\n",
      "Train Epoch: 470 [16922/17352 (98%)] Loss: -903.285106\n",
      "    epoch          : 470\n",
      "    loss           : -816.6042112735539\n",
      "    val_loss       : -698.2877003714074\n",
      "    val_log_likelihood: 1110.4662202360932\n",
      "    val_log_marginal: 720.567153913556\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch470.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 471 [512/17352 (3%)] Loss: -879.110229\n",
      "Train Epoch: 471 [10687/17352 (62%)] Loss: -861.616471\n",
      "Train Epoch: 471 [16958/17352 (98%)] Loss: -865.753872\n",
      "    epoch          : 471\n",
      "    loss           : -821.8962893385878\n",
      "    val_loss       : -692.0969398578852\n",
      "    val_log_likelihood: 1109.4457937878362\n",
      "    val_log_marginal: 714.2965344487536\n",
      "Train Epoch: 472 [512/17352 (3%)] Loss: -867.874084\n",
      "Train Epoch: 472 [10466/17352 (60%)] Loss: -779.818648\n",
      "Train Epoch: 472 [17143/17352 (99%)] Loss: -752.359515\n",
      "    epoch          : 472\n",
      "    loss           : -820.0006370355194\n",
      "    val_loss       : -675.4746546030813\n",
      "    val_log_likelihood: 1105.5044678682\n",
      "    val_log_marginal: 690.9442499322453\n",
      "Train Epoch: 473 [512/17352 (3%)] Loss: -850.241089\n",
      "Train Epoch: 473 [10527/17352 (61%)] Loss: -834.272254\n",
      "Train Epoch: 473 [17101/17352 (99%)] Loss: -891.722083\n",
      "    epoch          : 473\n",
      "    loss           : -824.9560058248575\n",
      "    val_loss       : -693.4670353488067\n",
      "    val_log_likelihood: 1115.5964795790837\n",
      "    val_log_marginal: 710.8742179548462\n",
      "Train Epoch: 474 [512/17352 (3%)] Loss: -878.933533\n",
      "Train Epoch: 474 [10261/17352 (59%)] Loss: -752.960938\n",
      "Train Epoch: 474 [16883/17352 (97%)] Loss: -712.040584\n",
      "    epoch          : 474\n",
      "    loss           : -820.918531042733\n",
      "    val_loss       : -699.3389063618652\n",
      "    val_log_likelihood: 1117.6433169751303\n",
      "    val_log_marginal: 719.2455707938796\n",
      "Train Epoch: 475 [512/17352 (3%)] Loss: -872.194702\n",
      "Train Epoch: 475 [10276/17352 (59%)] Loss: -854.754161\n",
      "Train Epoch: 475 [16882/17352 (97%)] Loss: -838.794609\n",
      "    epoch          : 475\n",
      "    loss           : -820.0828487379157\n",
      "    val_loss       : -689.9101494872796\n",
      "    val_log_likelihood: 1118.7628784903777\n",
      "    val_log_marginal: 717.1956397785075\n",
      "Train Epoch: 476 [512/17352 (3%)] Loss: -874.331421\n",
      "Train Epoch: 476 [10042/17352 (58%)] Loss: -923.456555\n",
      "Train Epoch: 476 [16887/17352 (97%)] Loss: -878.314997\n",
      "    epoch          : 476\n",
      "    loss           : -828.9190217127529\n",
      "    val_loss       : -707.6816154642718\n",
      "    val_log_likelihood: 1127.1293489548864\n",
      "    val_log_marginal: 721.6054489354731\n",
      "Train Epoch: 477 [512/17352 (3%)] Loss: -873.315552\n",
      "Train Epoch: 477 [10243/17352 (59%)] Loss: -859.790358\n",
      "Train Epoch: 477 [16887/17352 (97%)] Loss: -807.325056\n",
      "    epoch          : 477\n",
      "    loss           : -827.7559433256632\n",
      "    val_loss       : -697.1345129780119\n",
      "    val_log_likelihood: 1125.6549219108294\n",
      "    val_log_marginal: 719.0840685825611\n",
      "Train Epoch: 478 [512/17352 (3%)] Loss: -879.754517\n",
      "Train Epoch: 478 [10479/17352 (60%)] Loss: -746.592300\n",
      "Train Epoch: 478 [16882/17352 (97%)] Loss: -910.194937\n",
      "    epoch          : 478\n",
      "    loss           : -836.2496147561502\n",
      "    val_loss       : -705.7602020015382\n",
      "    val_log_likelihood: 1126.1192469508317\n",
      "    val_log_marginal: 724.5628424291759\n",
      "Train Epoch: 479 [512/17352 (3%)] Loss: -879.103271\n",
      "Train Epoch: 479 [10499/17352 (61%)] Loss: -790.315625\n",
      "Train Epoch: 479 [17335/17352 (100%)] Loss: -659.726075\n",
      "    epoch          : 479\n",
      "    loss           : -836.9767159031281\n",
      "    val_loss       : -694.7144725712398\n",
      "    val_log_likelihood: 1127.9146760283122\n",
      "    val_log_marginal: 715.2327566547032\n",
      "Train Epoch: 480 [512/17352 (3%)] Loss: -690.922180\n",
      "Train Epoch: 480 [10380/17352 (60%)] Loss: -842.048247\n",
      "Train Epoch: 480 [16923/17352 (98%)] Loss: -898.268190\n",
      "    epoch          : 480\n",
      "    loss           : -822.7294311146576\n",
      "    val_loss       : -676.0590163870299\n",
      "    val_log_likelihood: 1121.765239318959\n",
      "    val_log_marginal: 703.4806363818411\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch480.pth ...\n",
      "Train Epoch: 481 [512/17352 (3%)] Loss: -842.035522\n",
      "Train Epoch: 481 [10872/17352 (63%)] Loss: -917.841060\n",
      "Train Epoch: 481 [17126/17352 (99%)] Loss: -924.988873\n",
      "    epoch          : 481\n",
      "    loss           : -818.7075754309877\n",
      "    val_loss       : -687.7524535133762\n",
      "    val_log_likelihood: 1123.1760819988604\n",
      "    val_log_marginal: 714.2997075513908\n",
      "Train Epoch: 482 [512/17352 (3%)] Loss: -871.175659\n",
      "Train Epoch: 482 [9996/17352 (58%)] Loss: -771.701741\n",
      "Train Epoch: 482 [17253/17352 (99%)] Loss: -770.042867\n",
      "    epoch          : 482\n",
      "    loss           : -836.0501344651153\n",
      "    val_loss       : -685.0137881400404\n",
      "    val_log_likelihood: 1117.6509835088248\n",
      "    val_log_marginal: 701.7626113703376\n",
      "Train Epoch: 483 [512/17352 (3%)] Loss: -850.875122\n",
      "Train Epoch: 483 [10600/17352 (61%)] Loss: -611.232153\n",
      "Train Epoch: 483 [17090/17352 (98%)] Loss: -903.599680\n",
      "    epoch          : 483\n",
      "    loss           : -802.8416645719542\n",
      "    val_loss       : -592.0190477379275\n",
      "    val_log_likelihood: 1063.7885349053727\n",
      "    val_log_marginal: 624.2055836310819\n",
      "Train Epoch: 484 [512/17352 (3%)] Loss: -775.409180\n",
      "Train Epoch: 484 [10220/17352 (59%)] Loss: -554.633560\n",
      "Train Epoch: 484 [17143/17352 (99%)] Loss: -883.276584\n",
      "    epoch          : 484\n",
      "    loss           : -754.4198455639195\n",
      "    val_loss       : -626.7392819512886\n",
      "    val_log_likelihood: 1065.2450462925058\n",
      "    val_log_marginal: 662.999414308304\n",
      "Train Epoch: 485 [512/17352 (3%)] Loss: -788.380798\n",
      "Train Epoch: 485 [10514/17352 (61%)] Loss: -806.781730\n",
      "Train Epoch: 485 [17106/17352 (99%)] Loss: -946.096550\n",
      "    epoch          : 485\n",
      "    loss           : -810.814069290147\n",
      "    val_loss       : -618.3645597493141\n",
      "    val_log_likelihood: 1075.417439842543\n",
      "    val_log_marginal: 639.2353022829507\n",
      "Train Epoch: 486 [512/17352 (3%)] Loss: -816.960632\n",
      "Train Epoch: 486 [10432/17352 (60%)] Loss: -628.630415\n",
      "Train Epoch: 486 [16878/17352 (97%)] Loss: -800.040264\n",
      "    epoch          : 486\n",
      "    loss           : -780.0882724797314\n",
      "    val_loss       : -671.7816386070982\n",
      "    val_log_likelihood: 1102.4566380770884\n",
      "    val_log_marginal: 691.3394584204135\n",
      "Train Epoch: 487 [512/17352 (3%)] Loss: -860.889404\n",
      "Train Epoch: 487 [10327/17352 (60%)] Loss: -684.164707\n",
      "Train Epoch: 487 [17335/17352 (100%)] Loss: -804.904994\n",
      "    epoch          : 487\n",
      "    loss           : -806.3911205142225\n",
      "    val_loss       : -675.0314642870559\n",
      "    val_log_likelihood: 1116.3321537437198\n",
      "    val_log_marginal: 696.1404305129035\n",
      "Train Epoch: 488 [512/17352 (3%)] Loss: -846.614197\n",
      "Train Epoch: 488 [10827/17352 (62%)] Loss: -931.137579\n",
      "Train Epoch: 488 [17108/17352 (99%)] Loss: -721.129881\n",
      "    epoch          : 488\n",
      "    loss           : -830.625304407287\n",
      "    val_loss       : -685.6368686809244\n",
      "    val_log_likelihood: 1126.2012700885618\n",
      "    val_log_marginal: 702.1121299366301\n",
      "Train Epoch: 489 [512/17352 (3%)] Loss: -856.264526\n",
      "Train Epoch: 489 [11230/17352 (65%)] Loss: -658.262769\n",
      "Train Epoch: 489 [16934/17352 (98%)] Loss: -942.051453\n",
      "    epoch          : 489\n",
      "    loss           : -815.1552216575377\n",
      "    val_loss       : -664.2449970752823\n",
      "    val_log_likelihood: 1127.495199581478\n",
      "    val_log_marginal: 686.6490323459478\n",
      "Train Epoch: 490 [512/17352 (3%)] Loss: -832.382874\n",
      "Train Epoch: 490 [10855/17352 (63%)] Loss: -886.463154\n",
      "Train Epoch: 490 [17049/17352 (98%)] Loss: -826.225300\n",
      "    epoch          : 490\n",
      "    loss           : -818.4885398714314\n",
      "    val_loss       : -680.1346262925799\n",
      "    val_log_likelihood: 1121.288637190206\n",
      "    val_log_marginal: 711.6094633584947\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch490.pth ...\n",
      "Train Epoch: 491 [512/17352 (3%)] Loss: -687.524048\n",
      "Train Epoch: 491 [10659/17352 (61%)] Loss: -868.305390\n",
      "Train Epoch: 491 [17016/17352 (98%)] Loss: -860.715000\n",
      "    epoch          : 491\n",
      "    loss           : -792.5686385140851\n",
      "    val_loss       : -630.2994055297054\n",
      "    val_log_likelihood: 1080.8988200632564\n",
      "    val_log_marginal: 650.0077645772025\n",
      "Train Epoch: 492 [512/17352 (3%)] Loss: -804.998413\n",
      "Train Epoch: 492 [10386/17352 (60%)] Loss: -660.708452\n",
      "Train Epoch: 492 [17253/17352 (99%)] Loss: -753.297566\n",
      "    epoch          : 492\n",
      "    loss           : -790.7397668462961\n",
      "    val_loss       : -691.391148303355\n",
      "    val_log_likelihood: 1122.3395882189266\n",
      "    val_log_marginal: 716.9967886695068\n",
      "Train Epoch: 493 [512/17352 (3%)] Loss: -868.725586\n",
      "Train Epoch: 493 [10009/17352 (58%)] Loss: -761.809211\n",
      "Train Epoch: 493 [16887/17352 (97%)] Loss: -897.743065\n",
      "    epoch          : 493\n",
      "    loss           : -827.5681185967518\n",
      "    val_loss       : -703.9230897337414\n",
      "    val_log_likelihood: 1130.8518882029964\n",
      "    val_log_marginal: 723.3251021000871\n",
      "Train Epoch: 494 [512/17352 (3%)] Loss: -891.017395\n",
      "Train Epoch: 494 [10549/17352 (61%)] Loss: -755.779206\n",
      "Train Epoch: 494 [16988/17352 (98%)] Loss: -266.175299\n",
      "    epoch          : 494\n",
      "    loss           : -775.4109438154952\n",
      "    val_loss       : -653.7805435296777\n",
      "    val_log_likelihood: 1117.983051837465\n",
      "    val_log_marginal: 674.8773341363061\n",
      "Train Epoch: 495 [512/17352 (3%)] Loss: -836.838745\n",
      "Train Epoch: 495 [10950/17352 (63%)] Loss: -734.376059\n",
      "Train Epoch: 495 [17016/17352 (98%)] Loss: -602.771568\n",
      "    epoch          : 495\n",
      "    loss           : -689.9062810512155\n",
      "    val_loss       : -642.7425141978929\n",
      "    val_log_likelihood: 1084.495784247929\n",
      "    val_log_marginal: 671.7824867625411\n",
      "Train Epoch: 496 [512/17352 (3%)] Loss: -825.885803\n",
      "Train Epoch: 496 [10201/17352 (59%)] Loss: -879.895886\n",
      "Train Epoch: 496 [17108/17352 (99%)] Loss: -779.191685\n",
      "    epoch          : 496\n",
      "    loss           : -806.2668173763734\n",
      "    val_loss       : -657.8084317192446\n",
      "    val_log_likelihood: 1100.553081874749\n",
      "    val_log_marginal: 676.3503299870983\n",
      "Train Epoch: 497 [512/17352 (3%)] Loss: -782.345337\n",
      "Train Epoch: 497 [10186/17352 (59%)] Loss: -811.675609\n",
      "Train Epoch: 497 [16934/17352 (98%)] Loss: -864.150274\n",
      "    epoch          : 497\n",
      "    loss           : -811.6597221638027\n",
      "    val_loss       : -685.4510753331742\n",
      "    val_log_likelihood: 1116.0881362951257\n",
      "    val_log_marginal: 705.4441565066054\n",
      "Train Epoch: 498 [512/17352 (3%)] Loss: -867.436584\n",
      "Train Epoch: 498 [10522/17352 (61%)] Loss: -874.663813\n",
      "Train Epoch: 498 [16957/17352 (98%)] Loss: -775.305907\n",
      "    epoch          : 498\n",
      "    loss           : -825.5303085774834\n",
      "    val_loss       : -629.637849031777\n",
      "    val_log_likelihood: 1114.7902308439668\n",
      "    val_log_marginal: 646.000417114962\n",
      "Train Epoch: 499 [512/17352 (3%)] Loss: -834.136353\n",
      "Train Epoch: 499 [10176/17352 (59%)] Loss: -842.635820\n",
      "Train Epoch: 499 [17106/17352 (99%)] Loss: -680.268171\n",
      "    epoch          : 499\n",
      "    loss           : -665.0214134920119\n",
      "    val_loss       : -464.97154275297567\n",
      "    val_log_likelihood: 995.8621966013565\n",
      "    val_log_marginal: 490.3345852392099\n",
      "Train Epoch: 500 [512/17352 (3%)] Loss: -604.835693\n",
      "Train Epoch: 500 [10221/17352 (59%)] Loss: -758.607048\n",
      "Train Epoch: 500 [17253/17352 (99%)] Loss: -705.268921\n",
      "    epoch          : 500\n",
      "    loss           : -699.4204686722915\n",
      "    val_loss       : -589.5159198828586\n",
      "    val_log_likelihood: 1047.1888637305428\n",
      "    val_log_marginal: 617.5375987416394\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch500.pth ...\n",
      "Train Epoch: 501 [512/17352 (3%)] Loss: -738.095398\n",
      "Train Epoch: 501 [10210/17352 (59%)] Loss: -705.312998\n",
      "Train Epoch: 501 [16878/17352 (97%)] Loss: -789.396357\n",
      "    epoch          : 501\n",
      "    loss           : -750.9812853993833\n",
      "    val_loss       : -650.1497992481712\n",
      "    val_log_likelihood: 1083.3625636821816\n",
      "    val_log_marginal: 690.3184772356101\n",
      "Train Epoch: 502 [512/17352 (3%)] Loss: -853.297852\n",
      "Train Epoch: 502 [10059/17352 (58%)] Loss: -775.261610\n",
      "Train Epoch: 502 [16988/17352 (98%)] Loss: -661.904584\n",
      "    epoch          : 502\n",
      "    loss           : -732.2604931949573\n",
      "    val_loss       : -508.3672613324114\n",
      "    val_log_likelihood: 1034.4069687059607\n",
      "    val_log_marginal: 608.971222062567\n",
      "Train Epoch: 503 [512/17352 (3%)] Loss: -623.341125\n",
      "Train Epoch: 503 [10756/17352 (62%)] Loss: -817.276029\n",
      "Train Epoch: 503 [17106/17352 (99%)] Loss: -769.986888\n",
      "    epoch          : 503\n",
      "    loss           : -672.7375368723414\n",
      "    val_loss       : -561.9731958212942\n",
      "    val_log_likelihood: 1021.2512964222767\n",
      "    val_log_marginal: 597.9356788632973\n",
      "Train Epoch: 504 [512/17352 (3%)] Loss: -710.469482\n",
      "Train Epoch: 504 [9973/17352 (57%)] Loss: -609.889354\n",
      "Train Epoch: 504 [16939/17352 (98%)] Loss: -813.592961\n",
      "    epoch          : 504\n",
      "    loss           : -767.951301590978\n",
      "    val_loss       : -681.9909621635425\n",
      "    val_log_likelihood: 1093.5654527772906\n",
      "    val_log_marginal: 703.1779333465701\n",
      "Train Epoch: 505 [512/17352 (3%)] Loss: -836.546265\n",
      "Train Epoch: 505 [10272/17352 (59%)] Loss: -794.556275\n",
      "Train Epoch: 505 [17253/17352 (99%)] Loss: -918.337405\n",
      "    epoch          : 505\n",
      "    loss           : -799.1555153719354\n",
      "    val_loss       : -685.230131699712\n",
      "    val_log_likelihood: 1112.1077710596085\n",
      "    val_log_marginal: 709.290512498504\n",
      "Train Epoch: 506 [512/17352 (3%)] Loss: -857.568481\n",
      "Train Epoch: 506 [10563/17352 (61%)] Loss: -924.278553\n",
      "Train Epoch: 506 [17253/17352 (99%)] Loss: -867.047266\n",
      "    epoch          : 506\n",
      "    loss           : -826.364994473715\n",
      "    val_loss       : -673.2633815478015\n",
      "    val_log_likelihood: 1116.4711871346112\n",
      "    val_log_marginal: 704.3321994376543\n",
      "Train Epoch: 507 [512/17352 (3%)] Loss: -836.523560\n",
      "Train Epoch: 507 [10402/17352 (60%)] Loss: -673.624664\n",
      "Train Epoch: 507 [17143/17352 (99%)] Loss: -882.167279\n",
      "    epoch          : 507\n",
      "    loss           : -832.8713473894041\n",
      "    val_loss       : -684.401252436673\n",
      "    val_log_likelihood: 1120.0179497800152\n",
      "    val_log_marginal: 705.9853809601298\n",
      "Train Epoch: 508 [512/17352 (3%)] Loss: -873.316162\n",
      "Train Epoch: 508 [10002/17352 (58%)] Loss: -866.821094\n",
      "Train Epoch: 508 [16922/17352 (98%)] Loss: -711.871958\n",
      "    epoch          : 508\n",
      "    loss           : -831.7636751313075\n",
      "    val_loss       : -709.9104977260749\n",
      "    val_log_likelihood: 1131.9938544526563\n",
      "    val_log_marginal: 733.9675100272625\n",
      "Train Epoch: 509 [512/17352 (3%)] Loss: -882.652283\n",
      "Train Epoch: 509 [10026/17352 (58%)] Loss: -949.698933\n",
      "Train Epoch: 509 [17133/17352 (99%)] Loss: -782.435855\n",
      "    epoch          : 509\n",
      "    loss           : -837.6733043994519\n",
      "    val_loss       : -684.7120072528685\n",
      "    val_log_likelihood: 1126.5694065761495\n",
      "    val_log_marginal: 712.3880383863975\n",
      "Train Epoch: 510 [512/17352 (3%)] Loss: -886.182495\n",
      "Train Epoch: 510 [10623/17352 (61%)] Loss: -806.365191\n",
      "Train Epoch: 510 [17263/17352 (99%)] Loss: -767.434405\n",
      "    epoch          : 510\n",
      "    loss           : -830.7895295689345\n",
      "    val_loss       : -684.4523390630205\n",
      "    val_log_likelihood: 1134.825788619964\n",
      "    val_log_marginal: 710.5551146848682\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch510.pth ...\n",
      "Train Epoch: 511 [512/17352 (3%)] Loss: -864.046936\n",
      "Train Epoch: 511 [11042/17352 (64%)] Loss: -795.242448\n",
      "Train Epoch: 511 [17133/17352 (99%)] Loss: -917.435834\n",
      "    epoch          : 511\n",
      "    loss           : -834.8386138255696\n",
      "    val_loss       : -689.7923285368718\n",
      "    val_log_likelihood: 1128.0814311361355\n",
      "    val_log_marginal: 711.1576443712303\n",
      "Train Epoch: 512 [512/17352 (3%)] Loss: -875.247803\n",
      "Train Epoch: 512 [10258/17352 (59%)] Loss: -802.411830\n",
      "Train Epoch: 512 [16872/17352 (97%)] Loss: -927.724763\n",
      "    epoch          : 512\n",
      "    loss           : -836.4663351185967\n",
      "    val_loss       : -691.2966588986794\n",
      "    val_log_likelihood: 1136.920045496981\n",
      "    val_log_marginal: 720.2669515847458\n",
      "Train Epoch: 513 [512/17352 (3%)] Loss: -896.606628\n",
      "Train Epoch: 513 [10583/17352 (61%)] Loss: -827.819285\n",
      "Train Epoch: 513 [17253/17352 (99%)] Loss: -763.307715\n",
      "    epoch          : 513\n",
      "    loss           : -841.5212839324869\n",
      "    val_loss       : -679.3641393328078\n",
      "    val_log_likelihood: 1145.7808849659846\n",
      "    val_log_marginal: 726.5058950552346\n",
      "Train Epoch: 514 [512/17352 (3%)] Loss: -709.245178\n",
      "Train Epoch: 514 [10177/17352 (59%)] Loss: -688.036203\n",
      "Train Epoch: 514 [17277/17352 (100%)] Loss: -856.460868\n",
      "    epoch          : 514\n",
      "    loss           : -841.2985375432036\n",
      "    val_loss       : -703.4021412290471\n",
      "    val_log_likelihood: 1137.676511610482\n",
      "    val_log_marginal: 725.7901404652862\n",
      "Train Epoch: 515 [512/17352 (3%)] Loss: -715.893982\n",
      "Train Epoch: 515 [10389/17352 (60%)] Loss: -896.202469\n",
      "Train Epoch: 515 [16923/17352 (98%)] Loss: -948.387576\n",
      "    epoch          : 515\n",
      "    loss           : -847.5468503499307\n",
      "    val_loss       : -699.1171225185604\n",
      "    val_log_likelihood: 1142.216401655519\n",
      "    val_log_marginal: 727.971560580876\n",
      "Train Epoch: 516 [512/17352 (3%)] Loss: -895.891846\n",
      "Train Epoch: 516 [10243/17352 (59%)] Loss: -805.364757\n",
      "Train Epoch: 516 [16957/17352 (98%)] Loss: -818.121985\n",
      "    epoch          : 516\n",
      "    loss           : -856.096379608223\n",
      "    val_loss       : -720.584479862836\n",
      "    val_log_likelihood: 1155.2728091700592\n",
      "    val_log_marginal: 739.0709342352462\n",
      "Train Epoch: 517 [512/17352 (3%)] Loss: -903.188354\n",
      "Train Epoch: 517 [9901/17352 (57%)] Loss: -823.681296\n",
      "Train Epoch: 517 [16922/17352 (98%)] Loss: -916.798068\n",
      "    epoch          : 517\n",
      "    loss           : -852.4839888919486\n",
      "    val_loss       : -711.1269575818055\n",
      "    val_log_likelihood: 1154.4245402867027\n",
      "    val_log_marginal: 736.2408613873994\n",
      "Train Epoch: 518 [512/17352 (3%)] Loss: -895.720215\n",
      "Train Epoch: 518 [10855/17352 (63%)] Loss: -879.515563\n",
      "Train Epoch: 518 [17124/17352 (99%)] Loss: -796.911806\n",
      "    epoch          : 518\n",
      "    loss           : -842.3708983534732\n",
      "    val_loss       : -680.0564624433335\n",
      "    val_log_likelihood: 1143.6445149452204\n",
      "    val_log_marginal: 699.510840751207\n",
      "Train Epoch: 519 [512/17352 (3%)] Loss: -853.847107\n",
      "Train Epoch: 519 [9980/17352 (58%)] Loss: -845.993079\n",
      "Train Epoch: 519 [16988/17352 (98%)] Loss: -831.430087\n",
      "    epoch          : 519\n",
      "    loss           : -800.1756384183558\n",
      "    val_loss       : -637.8421078007846\n",
      "    val_log_likelihood: 1124.850078227341\n",
      "    val_log_marginal: 659.520268192961\n",
      "Train Epoch: 520 [512/17352 (3%)] Loss: -840.263062\n",
      "Train Epoch: 520 [10392/17352 (60%)] Loss: -594.251719\n",
      "Train Epoch: 520 [16958/17352 (98%)] Loss: -720.311841\n",
      "    epoch          : 520\n",
      "    loss           : -780.943132938724\n",
      "    val_loss       : -600.0741611286646\n",
      "    val_log_likelihood: 1094.6267859733598\n",
      "    val_log_marginal: 619.4297881521122\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch520.pth ...\n",
      "Train Epoch: 521 [512/17352 (3%)] Loss: -749.695679\n",
      "Train Epoch: 521 [10435/17352 (60%)] Loss: -745.617086\n",
      "Train Epoch: 521 [16958/17352 (98%)] Loss: -763.368935\n",
      "    epoch          : 521\n",
      "    loss           : -799.9670423764919\n",
      "    val_loss       : -665.910133443956\n",
      "    val_log_likelihood: 1126.1894278480765\n",
      "    val_log_marginal: 693.8578336104905\n",
      "Train Epoch: 522 [512/17352 (3%)] Loss: -871.238159\n",
      "Train Epoch: 522 [10853/17352 (63%)] Loss: -756.358969\n",
      "Train Epoch: 522 [17143/17352 (99%)] Loss: -914.549016\n",
      "    epoch          : 522\n",
      "    loss           : -835.8932871981168\n",
      "    val_loss       : -704.5487417200692\n",
      "    val_log_likelihood: 1148.3429418298617\n",
      "    val_log_marginal: 729.6122215431594\n",
      "Train Epoch: 523 [512/17352 (3%)] Loss: -898.402527\n",
      "Train Epoch: 523 [10506/17352 (61%)] Loss: -696.065191\n",
      "Train Epoch: 523 [17153/17352 (99%)] Loss: -846.321835\n",
      "    epoch          : 523\n",
      "    loss           : -798.9628053557564\n",
      "    val_loss       : -609.8033712100212\n",
      "    val_log_likelihood: 1109.2648205068276\n",
      "    val_log_marginal: 633.2173426085648\n",
      "Train Epoch: 524 [512/17352 (3%)] Loss: -825.252075\n",
      "Train Epoch: 524 [10655/17352 (61%)] Loss: -705.545860\n",
      "Train Epoch: 524 [17153/17352 (99%)] Loss: -655.692434\n",
      "    epoch          : 524\n",
      "    loss           : -789.1760437569254\n",
      "    val_loss       : -651.0082930852466\n",
      "    val_log_likelihood: 1132.5196087971958\n",
      "    val_log_marginal: 676.0260083382958\n",
      "Train Epoch: 525 [512/17352 (3%)] Loss: -822.637207\n",
      "Train Epoch: 525 [10470/17352 (60%)] Loss: -750.291139\n",
      "Train Epoch: 525 [17044/17352 (98%)] Loss: -911.311434\n",
      "    epoch          : 525\n",
      "    loss           : -798.8070419406994\n",
      "    val_loss       : -623.5700649778531\n",
      "    val_log_likelihood: 1128.4143719167903\n",
      "    val_log_marginal: 650.810626612591\n",
      "Train Epoch: 526 [512/17352 (3%)] Loss: -811.795776\n",
      "Train Epoch: 526 [10308/17352 (59%)] Loss: -833.820488\n",
      "Train Epoch: 526 [17277/17352 (100%)] Loss: -911.291616\n",
      "    epoch          : 526\n",
      "    loss           : -759.3926184027893\n",
      "    val_loss       : -580.5156628795332\n",
      "    val_log_likelihood: 1107.2499455114676\n",
      "    val_log_marginal: 603.0828387830949\n",
      "Train Epoch: 527 [512/17352 (3%)] Loss: -766.954468\n",
      "Train Epoch: 527 [10569/17352 (61%)] Loss: -928.731316\n",
      "Train Epoch: 527 [17108/17352 (99%)] Loss: -833.002999\n",
      "    epoch          : 527\n",
      "    loss           : -808.978052003364\n",
      "    val_loss       : -618.5419657720524\n",
      "    val_log_likelihood: 1114.4780010935197\n",
      "    val_log_marginal: 641.6814557008228\n",
      "Train Epoch: 528 [512/17352 (3%)] Loss: -818.622437\n",
      "Train Epoch: 528 [10087/17352 (58%)] Loss: -864.850292\n",
      "Train Epoch: 528 [16882/17352 (97%)] Loss: -727.719107\n",
      "    epoch          : 528\n",
      "    loss           : -786.3299305591552\n",
      "    val_loss       : -571.5047936119322\n",
      "    val_log_likelihood: 1116.0656922976323\n",
      "    val_log_marginal: 594.5074907097842\n",
      "Train Epoch: 529 [512/17352 (3%)] Loss: -695.409424\n",
      "Train Epoch: 529 [9931/17352 (57%)] Loss: -893.262322\n",
      "Train Epoch: 529 [17335/17352 (100%)] Loss: -901.477395\n",
      "    epoch          : 529\n",
      "    loss           : -797.848810290381\n",
      "    val_loss       : -645.2616673250217\n",
      "    val_log_likelihood: 1115.0591595903584\n",
      "    val_log_marginal: 669.4043422270979\n",
      "Train Epoch: 530 [512/17352 (3%)] Loss: -631.291748\n",
      "Train Epoch: 530 [11004/17352 (63%)] Loss: -689.568750\n",
      "Train Epoch: 530 [17044/17352 (98%)] Loss: -625.183149\n",
      "    epoch          : 530\n",
      "    loss           : -775.5454993025343\n",
      "    val_loss       : -370.6255383065286\n",
      "    val_log_likelihood: 1116.8811850293364\n",
      "    val_log_marginal: 393.9270551941993\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch530.pth ...\n",
      "Train Epoch: 531 [512/17352 (3%)] Loss: -579.366943\n",
      "Train Epoch: 531 [10378/17352 (60%)] Loss: -681.186504\n",
      "Train Epoch: 531 [17049/17352 (98%)] Loss: -567.898457\n",
      "    epoch          : 531\n",
      "    loss           : -676.5434969084262\n",
      "    val_loss       : -489.8039062367418\n",
      "    val_log_likelihood: 1098.6464091012172\n",
      "    val_log_marginal: 534.9966389874639\n",
      "Train Epoch: 532 [512/17352 (3%)] Loss: -668.481201\n",
      "Train Epoch: 532 [10247/17352 (59%)] Loss: -743.058431\n",
      "Train Epoch: 532 [17124/17352 (99%)] Loss: -671.841337\n",
      "    epoch          : 532\n",
      "    loss           : -705.1461687064018\n",
      "    val_loss       : -275.64218615742595\n",
      "    val_log_likelihood: 1040.2273128569716\n",
      "    val_log_marginal: 318.2042736421777\n",
      "Train Epoch: 533 [512/17352 (3%)] Loss: -364.295471\n",
      "Train Epoch: 533 [10395/17352 (60%)] Loss: -555.843441\n",
      "Train Epoch: 533 [16882/17352 (97%)] Loss: -732.355508\n",
      "    epoch          : 533\n",
      "    loss           : -711.7231382310922\n",
      "    val_loss       : -609.2128211413267\n",
      "    val_log_likelihood: 1070.201661308486\n",
      "    val_log_marginal: 635.4613448918997\n",
      "Train Epoch: 534 [512/17352 (3%)] Loss: -747.557129\n",
      "Train Epoch: 534 [10442/17352 (60%)] Loss: -588.673520\n",
      "Train Epoch: 534 [16992/17352 (98%)] Loss: -942.120309\n",
      "    epoch          : 534\n",
      "    loss           : -764.7314980311432\n",
      "    val_loss       : -647.0391832840708\n",
      "    val_log_likelihood: 1111.9051760322066\n",
      "    val_log_marginal: 682.6148665558744\n",
      "Train Epoch: 535 [512/17352 (3%)] Loss: -822.203125\n",
      "Train Epoch: 535 [10301/17352 (59%)] Loss: -764.338816\n",
      "Train Epoch: 535 [16992/17352 (98%)] Loss: -806.504918\n",
      "    epoch          : 535\n",
      "    loss           : -800.5864534415875\n",
      "    val_loss       : -522.1355110378225\n",
      "    val_log_likelihood: 1132.8220076293414\n",
      "    val_log_marginal: 549.8686143374721\n",
      "Train Epoch: 536 [512/17352 (3%)] Loss: -726.941406\n",
      "Train Epoch: 536 [10702/17352 (62%)] Loss: -899.001743\n",
      "Train Epoch: 536 [16923/17352 (98%)] Loss: -980.636502\n",
      "    epoch          : 536\n",
      "    loss           : -804.2007378733841\n",
      "    val_loss       : -678.1690008906363\n",
      "    val_log_likelihood: 1131.2653357717452\n",
      "    val_log_marginal: 712.5592813627144\n",
      "Train Epoch: 537 [512/17352 (3%)] Loss: -679.654541\n",
      "Train Epoch: 537 [10406/17352 (60%)] Loss: -951.237137\n",
      "Train Epoch: 537 [17101/17352 (99%)] Loss: -883.827732\n",
      "    epoch          : 537\n",
      "    loss           : -843.2982383554379\n",
      "    val_loss       : -706.367438896873\n",
      "    val_log_likelihood: 1148.7024854095932\n",
      "    val_log_marginal: 728.3796163821029\n",
      "Train Epoch: 538 [512/17352 (3%)] Loss: -888.642151\n",
      "Train Epoch: 538 [9975/17352 (57%)] Loss: -915.353881\n",
      "Train Epoch: 538 [17143/17352 (99%)] Loss: -788.898903\n",
      "    epoch          : 538\n",
      "    loss           : -844.591301983794\n",
      "    val_loss       : -683.0709581306019\n",
      "    val_log_likelihood: 1132.75025140144\n",
      "    val_log_marginal: 715.4136481903947\n",
      "Train Epoch: 539 [512/17352 (3%)] Loss: -897.870667\n",
      "Train Epoch: 539 [10248/17352 (59%)] Loss: -704.298549\n",
      "Train Epoch: 539 [17126/17352 (99%)] Loss: -886.557584\n",
      "    epoch          : 539\n",
      "    loss           : -817.5849838761569\n",
      "    val_loss       : -671.8945725419233\n",
      "    val_log_likelihood: 1124.5992237867426\n",
      "    val_log_marginal: 694.2364228893806\n",
      "Train Epoch: 540 [512/17352 (3%)] Loss: -862.219604\n",
      "Train Epoch: 540 [10352/17352 (60%)] Loss: -921.923399\n",
      "Train Epoch: 540 [17253/17352 (99%)] Loss: -828.141054\n",
      "    epoch          : 540\n",
      "    loss           : -824.4999427923068\n",
      "    val_loss       : -663.3953211535483\n",
      "    val_log_likelihood: 1122.0968646357817\n",
      "    val_log_marginal: 685.2697196854957\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch540.pth ...\n",
      "Train Epoch: 541 [512/17352 (3%)] Loss: -873.554749\n",
      "Train Epoch: 541 [10224/17352 (59%)] Loss: -902.984024\n",
      "Train Epoch: 541 [16887/17352 (97%)] Loss: -737.022380\n",
      "    epoch          : 541\n",
      "    loss           : -838.591462329242\n",
      "    val_loss       : -707.6881658176517\n",
      "    val_log_likelihood: 1152.9590533721844\n",
      "    val_log_marginal: 730.5788624028577\n",
      "Train Epoch: 542 [512/17352 (3%)] Loss: -906.807312\n",
      "Train Epoch: 542 [10631/17352 (61%)] Loss: -877.147286\n",
      "Train Epoch: 542 [16958/17352 (98%)] Loss: -588.195747\n",
      "    epoch          : 542\n",
      "    loss           : -702.5221035397204\n",
      "    val_loss       : 50.13459774926994\n",
      "    val_log_likelihood: 1062.458874859624\n",
      "    val_log_marginal: -30.730465506298\n",
      "Train Epoch: 543 [512/17352 (3%)] Loss: -50.430969\n",
      "Train Epoch: 543 [10464/17352 (60%)] Loss: -295.002658\n",
      "Train Epoch: 543 [17126/17352 (99%)] Loss: -710.377724\n",
      "    epoch          : 543\n",
      "    loss           : -364.1311032396637\n",
      "    val_loss       : -490.03452640102046\n",
      "    val_log_likelihood: 947.2386946525057\n",
      "    val_log_marginal: 537.851013358624\n",
      "Train Epoch: 544 [512/17352 (3%)] Loss: -665.832581\n",
      "Train Epoch: 544 [10928/17352 (63%)] Loss: -852.968372\n",
      "Train Epoch: 544 [17090/17352 (98%)] Loss: -693.808837\n",
      "    epoch          : 544\n",
      "    loss           : -692.4546097374935\n",
      "    val_loss       : -605.5904311956882\n",
      "    val_log_likelihood: 1073.941054044595\n",
      "    val_log_marginal: 664.573972080392\n",
      "Train Epoch: 545 [512/17352 (3%)] Loss: -812.999573\n",
      "Train Epoch: 545 [10015/17352 (58%)] Loss: -811.439867\n",
      "Train Epoch: 545 [16992/17352 (98%)] Loss: -877.419572\n",
      "    epoch          : 545\n",
      "    loss           : -787.3656699564525\n",
      "    val_loss       : -687.6673703203148\n",
      "    val_log_likelihood: 1119.2471538408909\n",
      "    val_log_marginal: 717.2158791121085\n",
      "Train Epoch: 546 [512/17352 (3%)] Loss: -891.775635\n",
      "Train Epoch: 546 [10673/17352 (62%)] Loss: -923.594146\n",
      "Train Epoch: 546 [17124/17352 (99%)] Loss: -844.393944\n",
      "    epoch          : 546\n",
      "    loss           : -823.0677141963505\n",
      "    val_loss       : -696.803222910237\n",
      "    val_log_likelihood: 1135.8516651612535\n",
      "    val_log_marginal: 722.3557269182467\n",
      "Train Epoch: 547 [512/17352 (3%)] Loss: -868.694824\n",
      "Train Epoch: 547 [9694/17352 (56%)] Loss: -981.121311\n",
      "Train Epoch: 547 [16922/17352 (98%)] Loss: -789.121449\n",
      "    epoch          : 547\n",
      "    loss           : -848.3878379429\n",
      "    val_loss       : -717.8162234836333\n",
      "    val_log_likelihood: 1148.1115620922078\n",
      "    val_log_marginal: 735.8494388917\n",
      "Train Epoch: 548 [512/17352 (3%)] Loss: -916.703796\n",
      "Train Epoch: 548 [10327/17352 (60%)] Loss: -919.171813\n",
      "Train Epoch: 548 [17106/17352 (99%)] Loss: -859.524210\n",
      "    epoch          : 548\n",
      "    loss           : -858.9579190810462\n",
      "    val_loss       : -716.8967323432694\n",
      "    val_log_likelihood: 1149.9050175827806\n",
      "    val_log_marginal: 737.0542107466631\n",
      "Train Epoch: 549 [512/17352 (3%)] Loss: -915.267700\n",
      "Train Epoch: 549 [9870/17352 (57%)] Loss: -829.508961\n",
      "Train Epoch: 549 [16988/17352 (98%)] Loss: -936.628807\n",
      "    epoch          : 549\n",
      "    loss           : -867.3015927314009\n",
      "    val_loss       : -725.4428169434558\n",
      "    val_log_likelihood: 1156.330582593004\n",
      "    val_log_marginal: 743.1872240817149\n",
      "Train Epoch: 550 [512/17352 (3%)] Loss: -882.723999\n",
      "Train Epoch: 550 [10503/17352 (61%)] Loss: -737.961634\n",
      "Train Epoch: 550 [16878/17352 (97%)] Loss: -864.569282\n",
      "    epoch          : 550\n",
      "    loss           : -861.9670095460851\n",
      "    val_loss       : -721.8061753817158\n",
      "    val_log_likelihood: 1162.2894263386165\n",
      "    val_log_marginal: 744.9687571069489\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch550.pth ...\n",
      "Train Epoch: 551 [512/17352 (3%)] Loss: -908.920166\n",
      "Train Epoch: 551 [10463/17352 (60%)] Loss: -928.665530\n",
      "Train Epoch: 551 [17049/17352 (98%)] Loss: -649.503696\n",
      "    epoch          : 551\n",
      "    loss           : -853.5424486792843\n",
      "    val_loss       : -719.8124447383766\n",
      "    val_log_likelihood: 1160.399694501266\n",
      "    val_log_marginal: 740.4705230054573\n",
      "Train Epoch: 552 [512/17352 (3%)] Loss: -894.364624\n",
      "Train Epoch: 552 [10516/17352 (61%)] Loss: -979.592014\n",
      "Train Epoch: 552 [17049/17352 (98%)] Loss: -911.794242\n",
      "    epoch          : 552\n",
      "    loss           : -861.7602029328316\n",
      "    val_loss       : -729.1868815099351\n",
      "    val_log_likelihood: 1162.180952346243\n",
      "    val_log_marginal: 748.5440382473157\n",
      "Train Epoch: 553 [512/17352 (3%)] Loss: -734.959717\n",
      "Train Epoch: 553 [9938/17352 (57%)] Loss: -765.042005\n",
      "Train Epoch: 553 [16923/17352 (98%)] Loss: -881.155713\n",
      "    epoch          : 553\n",
      "    loss           : -845.1341987435011\n",
      "    val_loss       : -713.8194505489729\n",
      "    val_log_likelihood: 1164.5031216646516\n",
      "    val_log_marginal: 737.2405461288769\n",
      "Train Epoch: 554 [512/17352 (3%)] Loss: -899.385315\n",
      "Train Epoch: 554 [10408/17352 (60%)] Loss: -779.571354\n",
      "Train Epoch: 554 [17126/17352 (99%)] Loss: -696.896717\n",
      "    epoch          : 554\n",
      "    loss           : -665.6871237295962\n",
      "    val_loss       : -316.74333254861597\n",
      "    val_log_likelihood: 962.9490279422588\n",
      "    val_log_marginal: 347.24315031290274\n",
      "Train Epoch: 555 [512/17352 (3%)] Loss: -525.970337\n",
      "Train Epoch: 555 [10237/17352 (59%)] Loss: -796.657513\n",
      "Train Epoch: 555 [17064/17352 (98%)] Loss: -715.032667\n",
      "    epoch          : 555\n",
      "    loss           : -687.5103742138704\n",
      "    val_loss       : -620.6198550863583\n",
      "    val_log_likelihood: 1077.773273914733\n",
      "    val_log_marginal: 671.7032363271956\n",
      "Train Epoch: 556 [512/17352 (3%)] Loss: -837.320618\n",
      "Train Epoch: 556 [10232/17352 (59%)] Loss: -819.504893\n",
      "Train Epoch: 556 [17126/17352 (99%)] Loss: -797.958376\n",
      "    epoch          : 556\n",
      "    loss           : -799.6031424192599\n",
      "    val_loss       : -684.5086030752389\n",
      "    val_log_likelihood: 1118.7515872725974\n",
      "    val_log_marginal: 708.5874452003519\n",
      "Train Epoch: 557 [512/17352 (3%)] Loss: -899.898132\n",
      "Train Epoch: 557 [10259/17352 (59%)] Loss: -795.546503\n",
      "Train Epoch: 557 [17133/17352 (99%)] Loss: -944.756171\n",
      "    epoch          : 557\n",
      "    loss           : -848.7684751332287\n",
      "    val_loss       : -714.2664444870397\n",
      "    val_log_likelihood: 1139.4535272085284\n",
      "    val_log_marginal: 733.4032612018866\n",
      "Train Epoch: 558 [512/17352 (3%)] Loss: -906.153137\n",
      "Train Epoch: 558 [10218/17352 (59%)] Loss: -905.182312\n",
      "Train Epoch: 558 [17124/17352 (99%)] Loss: -921.386265\n",
      "    epoch          : 558\n",
      "    loss           : -865.4665286541376\n",
      "    val_loss       : -731.0783075400194\n",
      "    val_log_likelihood: 1159.3618348254784\n",
      "    val_log_marginal: 744.6748067346509\n",
      "Train Epoch: 559 [512/17352 (3%)] Loss: -923.665649\n",
      "Train Epoch: 559 [10149/17352 (58%)] Loss: -837.942879\n",
      "Train Epoch: 559 [17064/17352 (98%)] Loss: -814.241926\n",
      "    epoch          : 559\n",
      "    loss           : -877.1571132606084\n",
      "    val_loss       : -725.6767433133213\n",
      "    val_log_likelihood: 1167.0971633070121\n",
      "    val_log_marginal: 745.4346632932428\n",
      "Train Epoch: 560 [512/17352 (3%)] Loss: -913.671631\n",
      "Train Epoch: 560 [10184/17352 (59%)] Loss: -849.479561\n",
      "Train Epoch: 560 [16878/17352 (97%)] Loss: -863.773180\n",
      "    epoch          : 560\n",
      "    loss           : -873.3873884564701\n",
      "    val_loss       : -722.8945365497942\n",
      "    val_log_likelihood: 1172.1539016155853\n",
      "    val_log_marginal: 745.09862742423\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch560.pth ...\n",
      "Train Epoch: 561 [512/17352 (3%)] Loss: -933.921753\n",
      "Train Epoch: 561 [10564/17352 (61%)] Loss: -794.443841\n",
      "Train Epoch: 561 [16992/17352 (98%)] Loss: -881.164501\n",
      "    epoch          : 561\n",
      "    loss           : -849.8682161200807\n",
      "    val_loss       : -684.6990033669794\n",
      "    val_log_likelihood: 1156.6265081808328\n",
      "    val_log_marginal: 736.4733680509325\n",
      "Train Epoch: 562 [512/17352 (3%)] Loss: -796.746277\n",
      "Train Epoch: 562 [10238/17352 (59%)] Loss: -915.293592\n",
      "Train Epoch: 562 [17277/17352 (100%)] Loss: -951.736979\n",
      "    epoch          : 562\n",
      "    loss           : -798.6091660776722\n",
      "    val_loss       : -681.3107874604326\n",
      "    val_log_likelihood: 1129.0962545320667\n",
      "    val_log_marginal: 709.2095760263012\n",
      "Train Epoch: 563 [512/17352 (3%)] Loss: -862.880554\n",
      "Train Epoch: 563 [10405/17352 (60%)] Loss: -776.116913\n",
      "Train Epoch: 563 [16957/17352 (98%)] Loss: -787.441279\n",
      "    epoch          : 563\n",
      "    loss           : -838.6291723833788\n",
      "    val_loss       : -642.1354505632575\n",
      "    val_log_likelihood: 1148.6223232567688\n",
      "    val_log_marginal: 662.3375961920505\n",
      "Train Epoch: 564 [512/17352 (3%)] Loss: -834.552124\n",
      "Train Epoch: 564 [10394/17352 (60%)] Loss: -873.323649\n",
      "Train Epoch: 564 [17143/17352 (99%)] Loss: -758.420641\n",
      "    epoch          : 564\n",
      "    loss           : -831.2332365785325\n",
      "    val_loss       : -677.4679411616974\n",
      "    val_log_likelihood: 1137.9925982396328\n",
      "    val_log_marginal: 701.6359358677369\n",
      "Train Epoch: 565 [512/17352 (3%)] Loss: -894.956299\n",
      "Train Epoch: 565 [10439/17352 (60%)] Loss: -840.953602\n",
      "Train Epoch: 565 [17263/17352 (99%)] Loss: -433.431362\n",
      "    epoch          : 565\n",
      "    loss           : -785.6638753593186\n",
      "    val_loss       : -651.1091983622504\n",
      "    val_log_likelihood: 1141.802274054701\n",
      "    val_log_marginal: 681.0502946512108\n",
      "Train Epoch: 566 [512/17352 (3%)] Loss: -877.646362\n",
      "Train Epoch: 566 [10241/17352 (59%)] Loss: -720.925955\n",
      "Train Epoch: 566 [17126/17352 (99%)] Loss: -697.441464\n",
      "    epoch          : 566\n",
      "    loss           : -798.2494417489826\n",
      "    val_loss       : -622.8028942356196\n",
      "    val_log_likelihood: 1142.4983861985413\n",
      "    val_log_marginal: 640.7295817211616\n",
      "Train Epoch: 567 [512/17352 (3%)] Loss: -834.472961\n",
      "Train Epoch: 567 [9997/17352 (58%)] Loss: -839.398259\n",
      "Train Epoch: 567 [16883/17352 (97%)] Loss: -708.374407\n",
      "    epoch          : 567\n",
      "    loss           : -682.0224574697583\n",
      "    val_loss       : -384.56845247118355\n",
      "    val_log_likelihood: 1088.6674346350194\n",
      "    val_log_marginal: 406.02137568951326\n",
      "Train Epoch: 568 [512/17352 (3%)] Loss: -254.146332\n",
      "Train Epoch: 568 [10234/17352 (59%)] Loss: -818.185285\n",
      "Train Epoch: 568 [17124/17352 (99%)] Loss: -730.004635\n",
      "    epoch          : 568\n",
      "    loss           : -737.5747585237674\n",
      "    val_loss       : -628.482890232038\n",
      "    val_log_likelihood: 1118.1117980364825\n",
      "    val_log_marginal: 676.8945682105526\n",
      "Train Epoch: 569 [512/17352 (3%)] Loss: -692.908569\n",
      "Train Epoch: 569 [10943/17352 (63%)] Loss: -941.570649\n",
      "Train Epoch: 569 [17044/17352 (98%)] Loss: -905.678198\n",
      "    epoch          : 569\n",
      "    loss           : -814.2273494589379\n",
      "    val_loss       : -666.2170842068892\n",
      "    val_log_likelihood: 1122.5636292814177\n",
      "    val_log_marginal: 692.6843777178616\n",
      "Train Epoch: 570 [512/17352 (3%)] Loss: -889.408936\n",
      "Train Epoch: 570 [9969/17352 (57%)] Loss: -794.281757\n",
      "Train Epoch: 570 [17090/17352 (98%)] Loss: -913.404314\n",
      "    epoch          : 570\n",
      "    loss           : -866.2115688478706\n",
      "    val_loss       : -729.1264465491222\n",
      "    val_log_likelihood: 1162.2635334837496\n",
      "    val_log_marginal: 749.3778489546606\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch570.pth ...\n",
      "Train Epoch: 571 [512/17352 (3%)] Loss: -917.601807\n",
      "Train Epoch: 571 [10132/17352 (58%)] Loss: -938.650938\n",
      "Train Epoch: 571 [16922/17352 (98%)] Loss: -945.691431\n",
      "    epoch          : 571\n",
      "    loss           : -876.1282550813594\n",
      "    val_loss       : -720.0562127653508\n",
      "    val_log_likelihood: 1169.8263479363895\n",
      "    val_log_marginal: 739.2749180237385\n",
      "Train Epoch: 572 [512/17352 (3%)] Loss: -916.912170\n",
      "Train Epoch: 572 [10185/17352 (59%)] Loss: -777.854779\n",
      "Train Epoch: 572 [17016/17352 (98%)] Loss: -748.297281\n",
      "    epoch          : 572\n",
      "    loss           : -871.2309733735633\n",
      "    val_loss       : -721.2411565804559\n",
      "    val_log_likelihood: 1170.604517587107\n",
      "    val_log_marginal: 742.2153184621747\n",
      "Train Epoch: 573 [512/17352 (3%)] Loss: -899.752136\n",
      "Train Epoch: 573 [9935/17352 (57%)] Loss: -715.740408\n",
      "Train Epoch: 573 [16878/17352 (97%)] Loss: -923.308542\n",
      "    epoch          : 573\n",
      "    loss           : -878.2124203132975\n",
      "    val_loss       : -723.2584594159873\n",
      "    val_log_likelihood: 1171.7857802378137\n",
      "    val_log_marginal: 746.0513282117898\n",
      "Train Epoch: 574 [512/17352 (3%)] Loss: -927.134338\n",
      "Train Epoch: 574 [10603/17352 (61%)] Loss: -836.956250\n",
      "Train Epoch: 574 [16957/17352 (98%)] Loss: -930.676953\n",
      "    epoch          : 574\n",
      "    loss           : -883.331830667399\n",
      "    val_loss       : -721.5865265061018\n",
      "    val_log_likelihood: 1178.0024802900728\n",
      "    val_log_marginal: 743.7415040608855\n",
      "Train Epoch: 575 [512/17352 (3%)] Loss: -938.939331\n",
      "Train Epoch: 575 [10621/17352 (61%)] Loss: -1004.321202\n",
      "Train Epoch: 575 [17090/17352 (98%)] Loss: -956.047456\n",
      "    epoch          : 575\n",
      "    loss           : -887.1155566351324\n",
      "    val_loss       : -717.2927802253863\n",
      "    val_log_likelihood: 1171.2401469719239\n",
      "    val_log_marginal: 738.1170107736159\n",
      "Train Epoch: 576 [512/17352 (3%)] Loss: -920.399536\n",
      "Train Epoch: 576 [10032/17352 (58%)] Loss: -729.150538\n",
      "Train Epoch: 576 [16883/17352 (97%)] Loss: -829.949795\n",
      "    epoch          : 576\n",
      "    loss           : -882.0787483898582\n",
      "    val_loss       : -735.9526396737538\n",
      "    val_log_likelihood: 1189.6543997989702\n",
      "    val_log_marginal: 755.3240780403805\n",
      "Train Epoch: 577 [512/17352 (3%)] Loss: -941.141785\n",
      "Train Epoch: 577 [10583/17352 (61%)] Loss: -760.491477\n",
      "Train Epoch: 577 [17016/17352 (98%)] Loss: -951.092433\n",
      "    epoch          : 577\n",
      "    loss           : -886.0846653398294\n",
      "    val_loss       : -715.405159292134\n",
      "    val_log_likelihood: 1176.74630575988\n",
      "    val_log_marginal: 737.1075335761406\n",
      "Train Epoch: 578 [512/17352 (3%)] Loss: -919.491028\n",
      "Train Epoch: 578 [10271/17352 (59%)] Loss: -804.591772\n",
      "Train Epoch: 578 [17335/17352 (100%)] Loss: -760.826372\n",
      "    epoch          : 578\n",
      "    loss           : -882.4770254327583\n",
      "    val_loss       : -714.7768318550524\n",
      "    val_log_likelihood: 1178.4315781103069\n",
      "    val_log_marginal: 731.8797654586976\n",
      "Train Epoch: 579 [512/17352 (3%)] Loss: -920.536865\n",
      "Train Epoch: 579 [10116/17352 (58%)] Loss: -912.535794\n",
      "Train Epoch: 579 [17253/17352 (99%)] Loss: -848.760455\n",
      "    epoch          : 579\n",
      "    loss           : -856.6399800256587\n",
      "    val_loss       : -619.436176314631\n",
      "    val_log_likelihood: 1113.3228539230977\n",
      "    val_log_marginal: 653.4290128797384\n",
      "Train Epoch: 580 [512/17352 (3%)] Loss: -854.776428\n",
      "Train Epoch: 580 [10814/17352 (62%)] Loss: -624.797245\n",
      "Train Epoch: 580 [16878/17352 (97%)] Loss: -771.952741\n",
      "    epoch          : 580\n",
      "    loss           : -811.0965699080682\n",
      "    val_loss       : -693.7449199919918\n",
      "    val_log_likelihood: 1141.9823841263092\n",
      "    val_log_marginal: 717.0644071634475\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch580.pth ...\n",
      "Train Epoch: 581 [512/17352 (3%)] Loss: -890.566589\n",
      "Train Epoch: 581 [9632/17352 (56%)] Loss: -790.178020\n",
      "Train Epoch: 581 [16957/17352 (98%)] Loss: -753.355004\n",
      "    epoch          : 581\n",
      "    loss           : -782.6901028783589\n",
      "    val_loss       : -652.0560606183485\n",
      "    val_log_likelihood: 1119.1233819828474\n",
      "    val_log_marginal: 685.1943526622136\n",
      "Train Epoch: 582 [512/17352 (3%)] Loss: -778.889038\n",
      "Train Epoch: 582 [10532/17352 (61%)] Loss: -928.274364\n",
      "Train Epoch: 582 [17133/17352 (99%)] Loss: -669.129839\n",
      "    epoch          : 582\n",
      "    loss           : -820.0210702757697\n",
      "    val_loss       : -699.3809120935196\n",
      "    val_log_likelihood: 1143.0650919743016\n",
      "    val_log_marginal: 719.3443391419114\n",
      "Train Epoch: 583 [512/17352 (3%)] Loss: -904.683960\n",
      "Train Epoch: 583 [10427/17352 (60%)] Loss: -853.226209\n",
      "Train Epoch: 583 [17335/17352 (100%)] Loss: -700.287679\n",
      "    epoch          : 583\n",
      "    loss           : -866.400188758469\n",
      "    val_loss       : -688.3913776164975\n",
      "    val_log_likelihood: 1149.6790696150244\n",
      "    val_log_marginal: 712.3678194324705\n",
      "Train Epoch: 584 [512/17352 (3%)] Loss: -861.676758\n",
      "Train Epoch: 584 [10355/17352 (60%)] Loss: -903.499491\n",
      "Train Epoch: 584 [16939/17352 (98%)] Loss: -885.630531\n",
      "    epoch          : 584\n",
      "    loss           : -867.3412379746134\n",
      "    val_loss       : -721.6871459059859\n",
      "    val_log_likelihood: 1177.4581453721403\n",
      "    val_log_marginal: 747.1831506533636\n",
      "Train Epoch: 585 [512/17352 (3%)] Loss: -934.857483\n",
      "Train Epoch: 585 [10487/17352 (60%)] Loss: -949.253886\n",
      "Train Epoch: 585 [16883/17352 (97%)] Loss: -856.423828\n",
      "    epoch          : 585\n",
      "    loss           : -869.4177901458182\n",
      "    val_loss       : -699.8700972465623\n",
      "    val_log_likelihood: 1171.7436678309552\n",
      "    val_log_marginal: 731.8687299122076\n",
      "Train Epoch: 586 [512/17352 (3%)] Loss: -931.107727\n",
      "Train Epoch: 586 [10245/17352 (59%)] Loss: -966.675562\n",
      "Train Epoch: 586 [16872/17352 (97%)] Loss: -811.172996\n",
      "    epoch          : 586\n",
      "    loss           : -879.1585026303532\n",
      "    val_loss       : -721.7632525796422\n",
      "    val_log_likelihood: 1183.6614394332719\n",
      "    val_log_marginal: 738.9544704608268\n",
      "Train Epoch: 587 [512/17352 (3%)] Loss: -712.219482\n",
      "Train Epoch: 587 [9889/17352 (57%)] Loss: -917.063842\n",
      "Train Epoch: 587 [16992/17352 (98%)] Loss: -884.726734\n",
      "    epoch          : 587\n",
      "    loss           : -875.5943498159173\n",
      "    val_loss       : -718.7609067060512\n",
      "    val_log_likelihood: 1174.100188114644\n",
      "    val_log_marginal: 739.3187531189559\n",
      "Train Epoch: 588 [512/17352 (3%)] Loss: -916.750366\n",
      "Train Epoch: 588 [10572/17352 (61%)] Loss: -942.285756\n",
      "Train Epoch: 588 [17106/17352 (99%)] Loss: -868.709099\n",
      "    epoch          : 588\n",
      "    loss           : -874.50022840162\n",
      "    val_loss       : -682.2345020871095\n",
      "    val_log_likelihood: 1172.2912170720817\n",
      "    val_log_marginal: 704.5659724292477\n",
      "Train Epoch: 589 [512/17352 (3%)] Loss: -681.832764\n",
      "Train Epoch: 589 [10641/17352 (61%)] Loss: -718.328159\n",
      "Train Epoch: 589 [17090/17352 (98%)] Loss: -717.271068\n",
      "    epoch          : 589\n",
      "    loss           : -814.9710897527926\n",
      "    val_loss       : -664.0396073108518\n",
      "    val_log_likelihood: 1163.879406585511\n",
      "    val_log_marginal: 685.9698799494498\n",
      "Train Epoch: 590 [512/17352 (3%)] Loss: -847.582458\n",
      "Train Epoch: 590 [10582/17352 (61%)] Loss: -832.476562\n",
      "Train Epoch: 590 [16939/17352 (98%)] Loss: -956.776596\n",
      "    epoch          : 590\n",
      "    loss           : -829.5909830247583\n",
      "    val_loss       : -672.412762938391\n",
      "    val_log_likelihood: 1158.7903961858717\n",
      "    val_log_marginal: 689.865181633999\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch590.pth ...\n",
      "Train Epoch: 591 [512/17352 (3%)] Loss: -887.475830\n",
      "Train Epoch: 591 [10688/17352 (62%)] Loss: -899.151021\n",
      "Train Epoch: 591 [17016/17352 (98%)] Loss: -726.169503\n",
      "    epoch          : 591\n",
      "    loss           : -853.6192700191559\n",
      "    val_loss       : -706.3120109700433\n",
      "    val_log_likelihood: 1172.007894779188\n",
      "    val_log_marginal: 728.7274433478748\n",
      "Train Epoch: 592 [512/17352 (3%)] Loss: -919.690125\n",
      "Train Epoch: 592 [10204/17352 (59%)] Loss: -806.332031\n",
      "Train Epoch: 592 [17090/17352 (98%)] Loss: -615.837631\n",
      "    epoch          : 592\n",
      "    loss           : -864.9648937085063\n",
      "    val_loss       : -476.1333390838134\n",
      "    val_log_likelihood: 1161.0871902509316\n",
      "    val_log_marginal: 492.87841137669415\n",
      "Train Epoch: 593 [512/17352 (3%)] Loss: -728.347534\n",
      "Train Epoch: 593 [10383/17352 (60%)] Loss: -787.948356\n",
      "Train Epoch: 593 [16882/17352 (97%)] Loss: -707.773721\n",
      "    epoch          : 593\n",
      "    loss           : -818.4977651049078\n",
      "    val_loss       : -708.1557630847\n",
      "    val_log_likelihood: 1173.9993791226934\n",
      "    val_log_marginal: 727.5750342691323\n",
      "Train Epoch: 594 [512/17352 (3%)] Loss: -923.245178\n",
      "Train Epoch: 594 [10370/17352 (60%)] Loss: -792.294819\n",
      "Train Epoch: 594 [17106/17352 (99%)] Loss: -968.907917\n",
      "    epoch          : 594\n",
      "    loss           : -876.7215341438832\n",
      "    val_loss       : -707.8140070837852\n",
      "    val_log_likelihood: 1170.2997274267104\n",
      "    val_log_marginal: 727.546419895778\n",
      "Train Epoch: 595 [512/17352 (3%)] Loss: -919.026123\n",
      "Train Epoch: 595 [10223/17352 (59%)] Loss: -957.867337\n",
      "Train Epoch: 595 [16957/17352 (98%)] Loss: -788.158947\n",
      "    epoch          : 595\n",
      "    loss           : -859.0253479662788\n",
      "    val_loss       : -675.0757351451759\n",
      "    val_log_likelihood: 1160.5849175190228\n",
      "    val_log_marginal: 704.0241543710156\n",
      "Train Epoch: 596 [512/17352 (3%)] Loss: -680.258728\n",
      "Train Epoch: 596 [10760/17352 (62%)] Loss: -937.953590\n",
      "Train Epoch: 596 [17143/17352 (99%)] Loss: -984.728624\n",
      "    epoch          : 596\n",
      "    loss           : -858.0292322836964\n",
      "    val_loss       : -707.1993413723236\n",
      "    val_log_likelihood: 1170.0143890401325\n",
      "    val_log_marginal: 725.393278999757\n",
      "Train Epoch: 597 [512/17352 (3%)] Loss: -861.766724\n",
      "Train Epoch: 597 [10111/17352 (58%)] Loss: -922.750000\n",
      "Train Epoch: 597 [16934/17352 (98%)] Loss: -938.672070\n",
      "    epoch          : 597\n",
      "    loss           : -880.097183232363\n",
      "    val_loss       : -730.231010853487\n",
      "    val_log_likelihood: 1183.3967322825572\n",
      "    val_log_marginal: 746.1733859289893\n",
      "Train Epoch: 598 [512/17352 (3%)] Loss: -940.594360\n",
      "Train Epoch: 598 [10551/17352 (61%)] Loss: -976.924792\n",
      "Train Epoch: 598 [17253/17352 (99%)] Loss: -934.407742\n",
      "    epoch          : 598\n",
      "    loss           : -890.9435482713322\n",
      "    val_loss       : -731.8486845713763\n",
      "    val_log_likelihood: 1193.257579608984\n",
      "    val_log_marginal: 748.3722750847384\n",
      "Train Epoch: 599 [512/17352 (3%)] Loss: -927.404419\n",
      "Train Epoch: 599 [9817/17352 (57%)] Loss: -819.353356\n",
      "Train Epoch: 599 [16923/17352 (98%)] Loss: -770.471432\n",
      "    epoch          : 599\n",
      "    loss           : -895.1992169776221\n",
      "    val_loss       : -732.1410226768373\n",
      "    val_log_likelihood: 1195.013883624907\n",
      "    val_log_marginal: 751.9075892359028\n",
      "Train Epoch: 600 [512/17352 (3%)] Loss: -946.474243\n",
      "Train Epoch: 600 [10654/17352 (61%)] Loss: -790.599869\n",
      "Train Epoch: 600 [16988/17352 (98%)] Loss: -983.292925\n",
      "    epoch          : 600\n",
      "    loss           : -898.0123126672114\n",
      "    val_loss       : -742.3154616275996\n",
      "    val_log_likelihood: 1206.461400407961\n",
      "    val_log_marginal: 759.7240226381641\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch600.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 601 [512/17352 (3%)] Loss: -949.826843\n",
      "Train Epoch: 601 [10607/17352 (61%)] Loss: -684.455446\n",
      "Train Epoch: 601 [16992/17352 (98%)] Loss: -966.109043\n",
      "    epoch          : 601\n",
      "    loss           : -873.8312319159081\n",
      "    val_loss       : -711.0423172857695\n",
      "    val_log_likelihood: 1189.5121090807081\n",
      "    val_log_marginal: 732.6493628262701\n",
      "Train Epoch: 602 [512/17352 (3%)] Loss: -913.010559\n",
      "Train Epoch: 602 [10499/17352 (61%)] Loss: -948.466820\n",
      "Train Epoch: 602 [16878/17352 (97%)] Loss: -1006.916857\n",
      "    epoch          : 602\n",
      "    loss           : -877.6925672502852\n",
      "    val_loss       : -710.5519066502662\n",
      "    val_log_likelihood: 1182.7060589434666\n",
      "    val_log_marginal: 730.9852925653574\n",
      "Train Epoch: 603 [512/17352 (3%)] Loss: -928.154236\n",
      "Train Epoch: 603 [10634/17352 (61%)] Loss: -780.445076\n",
      "Train Epoch: 603 [16992/17352 (98%)] Loss: -799.662978\n",
      "    epoch          : 603\n",
      "    loss           : -872.0739229047535\n",
      "    val_loss       : -692.3764871766674\n",
      "    val_log_likelihood: 1166.7989591817432\n",
      "    val_log_marginal: 709.5824642004147\n",
      "Train Epoch: 604 [512/17352 (3%)] Loss: -926.716858\n",
      "Train Epoch: 604 [10624/17352 (61%)] Loss: -843.284644\n",
      "Train Epoch: 604 [17049/17352 (98%)] Loss: -964.667909\n",
      "    epoch          : 604\n",
      "    loss           : -879.4388535997997\n",
      "    val_loss       : -717.1407363285092\n",
      "    val_log_likelihood: 1190.0494626789045\n",
      "    val_log_marginal: 737.3704170708729\n",
      "Train Epoch: 605 [512/17352 (3%)] Loss: -940.628174\n",
      "Train Epoch: 605 [10965/17352 (63%)] Loss: -934.318153\n",
      "Train Epoch: 605 [17049/17352 (98%)] Loss: -977.976612\n",
      "    epoch          : 605\n",
      "    loss           : -885.7715677634757\n",
      "    val_loss       : -693.9539261955025\n",
      "    val_log_likelihood: 1184.7650115757056\n",
      "    val_log_marginal: 725.7976805426867\n",
      "Train Epoch: 606 [512/17352 (3%)] Loss: -928.353027\n",
      "Train Epoch: 606 [10858/17352 (63%)] Loss: -934.033553\n",
      "Train Epoch: 606 [16872/17352 (97%)] Loss: -842.096447\n",
      "    epoch          : 606\n",
      "    loss           : -871.0244184860502\n",
      "    val_loss       : -657.3551340412239\n",
      "    val_log_likelihood: 1156.7711686023163\n",
      "    val_log_marginal: 695.7336487279439\n",
      "Train Epoch: 607 [512/17352 (3%)] Loss: -921.950989\n",
      "Train Epoch: 607 [10536/17352 (61%)] Loss: -867.700441\n",
      "Train Epoch: 607 [17101/17352 (99%)] Loss: -887.134310\n",
      "    epoch          : 607\n",
      "    loss           : -811.7143823033111\n",
      "    val_loss       : -499.3038451717902\n",
      "    val_log_likelihood: 1143.9430967325588\n",
      "    val_log_marginal: 516.6177645747968\n",
      "Train Epoch: 608 [512/17352 (3%)] Loss: -699.539124\n",
      "Train Epoch: 608 [10339/17352 (60%)] Loss: -679.502762\n",
      "Train Epoch: 608 [16923/17352 (98%)] Loss: -202.634157\n",
      "    epoch          : 608\n",
      "    loss           : -336.93724060804675\n",
      "    val_loss       : 120.30457452396129\n",
      "    val_log_likelihood: 997.5865778802706\n",
      "    val_log_marginal: -73.11953059719883\n",
      "Train Epoch: 609 [512/17352 (3%)] Loss: -70.758705\n",
      "Train Epoch: 609 [10419/17352 (60%)] Loss: -848.490017\n",
      "Train Epoch: 609 [16939/17352 (98%)] Loss: -22.713289\n",
      "    epoch          : 609\n",
      "    loss           : -368.2417036586265\n",
      "    val_loss       : -337.45881320010085\n",
      "    val_log_likelihood: 1016.099783059596\n",
      "    val_log_marginal: 424.64040379788725\n",
      "Train Epoch: 610 [512/17352 (3%)] Loss: -584.044434\n",
      "Train Epoch: 610 [10248/17352 (59%)] Loss: -464.575083\n",
      "Train Epoch: 610 [17263/17352 (99%)] Loss: -673.511663\n",
      "    epoch          : 610\n",
      "    loss           : -694.1187612001596\n",
      "    val_loss       : -651.4832219375116\n",
      "    val_log_likelihood: 1122.0149786147456\n",
      "    val_log_marginal: 687.1887028514872\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch610.pth ...\n",
      "Train Epoch: 611 [512/17352 (3%)] Loss: -600.516479\n",
      "Train Epoch: 611 [10696/17352 (62%)] Loss: -828.482594\n",
      "Train Epoch: 611 [17064/17352 (98%)] Loss: -901.197292\n",
      "    epoch          : 611\n",
      "    loss           : -798.3070653505948\n",
      "    val_loss       : -602.575897342724\n",
      "    val_log_likelihood: 1094.4493132518705\n",
      "    val_log_marginal: 676.7041009906117\n",
      "Train Epoch: 612 [512/17352 (3%)] Loss: -789.071594\n",
      "Train Epoch: 612 [9416/17352 (54%)] Loss: -639.766662\n",
      "Train Epoch: 612 [17090/17352 (98%)] Loss: -873.714041\n",
      "    epoch          : 612\n",
      "    loss           : -757.7182319555556\n",
      "    val_loss       : -643.094063814992\n",
      "    val_log_likelihood: 1109.9412071157801\n",
      "    val_log_marginal: 671.1977907673294\n",
      "Train Epoch: 613 [512/17352 (3%)] Loss: -831.007507\n",
      "Train Epoch: 613 [10198/17352 (59%)] Loss: -788.773991\n",
      "Train Epoch: 613 [16988/17352 (98%)] Loss: -973.413303\n",
      "    epoch          : 613\n",
      "    loss           : -830.8959681941661\n",
      "    val_loss       : -709.0634699028078\n",
      "    val_log_likelihood: 1152.4658274304015\n",
      "    val_log_marginal: 725.4796076868315\n",
      "Train Epoch: 614 [512/17352 (3%)] Loss: -876.720581\n",
      "Train Epoch: 614 [10414/17352 (60%)] Loss: -861.170093\n",
      "Train Epoch: 614 [17253/17352 (99%)] Loss: -703.477572\n",
      "    epoch          : 614\n",
      "    loss           : -875.0923048250231\n",
      "    val_loss       : -725.3960148670357\n",
      "    val_log_likelihood: 1168.5810449015505\n",
      "    val_log_marginal: 750.506725837034\n",
      "Train Epoch: 615 [512/17352 (3%)] Loss: -930.822998\n",
      "Train Epoch: 615 [10590/17352 (61%)] Loss: -920.182431\n",
      "Train Epoch: 615 [17108/17352 (99%)] Loss: -868.443040\n",
      "    epoch          : 615\n",
      "    loss           : -876.2736474240712\n",
      "    val_loss       : -714.7574259526298\n",
      "    val_log_likelihood: 1180.6601794619373\n",
      "    val_log_marginal: 751.9376749700472\n",
      "Train Epoch: 616 [512/17352 (3%)] Loss: -911.292236\n",
      "Train Epoch: 616 [10307/17352 (59%)] Loss: -905.651199\n",
      "Train Epoch: 616 [17133/17352 (99%)] Loss: -983.596672\n",
      "    epoch          : 616\n",
      "    loss           : -864.8141203158524\n",
      "    val_loss       : -725.1860993325164\n",
      "    val_log_likelihood: 1178.3958619439493\n",
      "    val_log_marginal: 747.8496466335516\n",
      "Train Epoch: 617 [512/17352 (3%)] Loss: -933.586182\n",
      "Train Epoch: 617 [11051/17352 (64%)] Loss: -938.834549\n",
      "Train Epoch: 617 [17335/17352 (100%)] Loss: -848.131130\n",
      "    epoch          : 617\n",
      "    loss           : -879.0313117408429\n",
      "    val_loss       : -739.4358484975946\n",
      "    val_log_likelihood: 1187.4581481909534\n",
      "    val_log_marginal: 756.6386837995137\n",
      "Train Epoch: 618 [512/17352 (3%)] Loss: -760.005859\n",
      "Train Epoch: 618 [10658/17352 (61%)] Loss: -815.418381\n",
      "Train Epoch: 618 [16887/17352 (97%)] Loss: -960.434494\n",
      "    epoch          : 618\n",
      "    loss           : -877.3648764920146\n",
      "    val_loss       : -726.1845191607376\n",
      "    val_log_likelihood: 1184.8697541107415\n",
      "    val_log_marginal: 751.3821095778698\n",
      "Train Epoch: 619 [512/17352 (3%)] Loss: -940.558350\n",
      "Train Epoch: 619 [10742/17352 (62%)] Loss: -914.567616\n",
      "Train Epoch: 619 [17143/17352 (99%)] Loss: -938.847805\n",
      "    epoch          : 619\n",
      "    loss           : -892.3040626033875\n",
      "    val_loss       : -736.2751736169571\n",
      "    val_log_likelihood: 1187.9242028037559\n",
      "    val_log_marginal: 756.9884919566035\n",
      "Train Epoch: 620 [512/17352 (3%)] Loss: -925.044922\n",
      "Train Epoch: 620 [10491/17352 (60%)] Loss: -763.244991\n",
      "Train Epoch: 620 [17106/17352 (99%)] Loss: -968.684707\n",
      "    epoch          : 620\n",
      "    loss           : -901.4150755551912\n",
      "    val_loss       : -737.3486087285968\n",
      "    val_log_likelihood: 1197.6362861513599\n",
      "    val_log_marginal: 759.2468335336762\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch620.pth ...\n",
      "Train Epoch: 621 [512/17352 (3%)] Loss: -939.873657\n",
      "Train Epoch: 621 [9536/17352 (55%)] Loss: -857.530546\n",
      "Train Epoch: 621 [16883/17352 (97%)] Loss: -836.473264\n",
      "    epoch          : 621\n",
      "    loss           : -903.7205186697357\n",
      "    val_loss       : -748.012693725907\n",
      "    val_log_likelihood: 1202.8971729904608\n",
      "    val_log_marginal: 767.1218020697739\n",
      "Train Epoch: 622 [512/17352 (3%)] Loss: -955.567322\n",
      "Train Epoch: 622 [10807/17352 (62%)] Loss: -1030.864583\n",
      "Train Epoch: 622 [17277/17352 (100%)] Loss: -1012.079827\n",
      "    epoch          : 622\n",
      "    loss           : -906.9147609704318\n",
      "    val_loss       : -739.2263200673918\n",
      "    val_log_likelihood: 1201.6137115773747\n",
      "    val_log_marginal: 755.3840984938755\n",
      "Train Epoch: 623 [512/17352 (3%)] Loss: -961.819275\n",
      "Train Epoch: 623 [9949/17352 (57%)] Loss: -1029.151584\n",
      "Train Epoch: 623 [17277/17352 (100%)] Loss: -736.184360\n",
      "    epoch          : 623\n",
      "    loss           : -904.8940951299867\n",
      "    val_loss       : -702.6192870070228\n",
      "    val_log_likelihood: 1172.9067688300331\n",
      "    val_log_marginal: 720.433611902341\n",
      "Train Epoch: 624 [512/17352 (3%)] Loss: -896.680115\n",
      "Train Epoch: 624 [10389/17352 (60%)] Loss: -999.522785\n",
      "Train Epoch: 624 [16923/17352 (98%)] Loss: -980.579521\n",
      "    epoch          : 624\n",
      "    loss           : -896.2078632016678\n",
      "    val_loss       : -724.6958014438127\n",
      "    val_log_likelihood: 1209.1483947415747\n",
      "    val_log_marginal: 741.2762640719604\n",
      "Train Epoch: 625 [512/17352 (3%)] Loss: -922.496216\n",
      "Train Epoch: 625 [10087/17352 (58%)] Loss: -958.316624\n",
      "Train Epoch: 625 [16878/17352 (97%)] Loss: -1005.993493\n",
      "    epoch          : 625\n",
      "    loss           : -879.5499018738328\n",
      "    val_loss       : -732.2162107392418\n",
      "    val_log_likelihood: 1202.9323106793418\n",
      "    val_log_marginal: 751.6037895612704\n",
      "Train Epoch: 626 [512/17352 (3%)] Loss: -951.939453\n",
      "Train Epoch: 626 [10573/17352 (61%)] Loss: -883.338979\n",
      "Train Epoch: 626 [16988/17352 (98%)] Loss: -772.846483\n",
      "    epoch          : 626\n",
      "    loss           : -894.0000153772938\n",
      "    val_loss       : -728.7573079208753\n",
      "    val_log_likelihood: 1201.4785296659722\n",
      "    val_log_marginal: 750.2847567678525\n",
      "Train Epoch: 627 [512/17352 (3%)] Loss: -747.083435\n",
      "Train Epoch: 627 [10704/17352 (62%)] Loss: -1027.880978\n",
      "Train Epoch: 627 [16887/17352 (97%)] Loss: -869.687779\n",
      "    epoch          : 627\n",
      "    loss           : -909.9594551167656\n",
      "    val_loss       : -742.389118883728\n",
      "    val_log_likelihood: 1207.9550621218286\n",
      "    val_log_marginal: 758.2078921448667\n",
      "Train Epoch: 628 [512/17352 (3%)] Loss: -965.607666\n",
      "Train Epoch: 628 [10894/17352 (63%)] Loss: -957.177474\n",
      "Train Epoch: 628 [17143/17352 (99%)] Loss: -911.235480\n",
      "    epoch          : 628\n",
      "    loss           : -916.0469222997955\n",
      "    val_loss       : -723.9227583562521\n",
      "    val_log_likelihood: 1206.2977847140098\n",
      "    val_log_marginal: 738.4125074212858\n",
      "Train Epoch: 629 [512/17352 (3%)] Loss: -955.651672\n",
      "Train Epoch: 629 [10121/17352 (58%)] Loss: -947.541746\n",
      "Train Epoch: 629 [17153/17352 (99%)] Loss: -931.391894\n",
      "    epoch          : 629\n",
      "    loss           : -897.5134327491813\n",
      "    val_loss       : -698.6461909799829\n",
      "    val_log_likelihood: 1202.7665511884834\n",
      "    val_log_marginal: 719.0949002932205\n",
      "Train Epoch: 630 [512/17352 (3%)] Loss: -920.220215\n",
      "Train Epoch: 630 [10203/17352 (59%)] Loss: -930.364791\n",
      "Train Epoch: 630 [17253/17352 (99%)] Loss: -924.603230\n",
      "    epoch          : 630\n",
      "    loss           : -895.2669729879761\n",
      "    val_loss       : -649.3313708534712\n",
      "    val_log_likelihood: 1163.9269731294733\n",
      "    val_log_marginal: 670.2483555497431\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch630.pth ...\n",
      "Train Epoch: 631 [512/17352 (3%)] Loss: -861.379150\n",
      "Train Epoch: 631 [10722/17352 (62%)] Loss: -973.340061\n",
      "Train Epoch: 631 [16922/17352 (98%)] Loss: -937.745886\n",
      "    epoch          : 631\n",
      "    loss           : -852.1726267208514\n",
      "    val_loss       : -664.9369273556146\n",
      "    val_log_likelihood: 1169.420389951422\n",
      "    val_log_marginal: 691.3916559775117\n",
      "Train Epoch: 632 [512/17352 (3%)] Loss: -888.736755\n",
      "Train Epoch: 632 [10061/17352 (58%)] Loss: -931.814278\n",
      "Train Epoch: 632 [16923/17352 (98%)] Loss: -457.119369\n",
      "    epoch          : 632\n",
      "    loss           : -738.8157478326117\n",
      "    val_loss       : -226.05489953465798\n",
      "    val_log_likelihood: 1135.1750253725363\n",
      "    val_log_marginal: 250.45128714835354\n",
      "Train Epoch: 633 [512/17352 (3%)] Loss: -461.306824\n",
      "Train Epoch: 633 [10378/17352 (60%)] Loss: -869.922082\n",
      "Train Epoch: 633 [17044/17352 (98%)] Loss: -742.594466\n",
      "    epoch          : 633\n",
      "    loss           : -745.7971872187243\n",
      "    val_loss       : -581.6572056252501\n",
      "    val_log_likelihood: 1125.775437351266\n",
      "    val_log_marginal: 608.0604995545542\n",
      "Train Epoch: 634 [512/17352 (3%)] Loss: -796.764465\n",
      "Train Epoch: 634 [10420/17352 (60%)] Loss: -893.075063\n",
      "Train Epoch: 634 [17049/17352 (98%)] Loss: -878.932103\n",
      "    epoch          : 634\n",
      "    loss           : -812.4277658557774\n",
      "    val_loss       : -607.8038714243695\n",
      "    val_log_likelihood: 1139.0626760779894\n",
      "    val_log_marginal: 635.1435004380149\n",
      "Train Epoch: 635 [512/17352 (3%)] Loss: -790.299561\n",
      "Train Epoch: 635 [10468/17352 (60%)] Loss: -920.858245\n",
      "Train Epoch: 635 [17263/17352 (99%)] Loss: -780.311732\n",
      "    epoch          : 635\n",
      "    loss           : -820.2188376855775\n",
      "    val_loss       : -616.3656780446629\n",
      "    val_log_likelihood: 1117.9929962401106\n",
      "    val_log_marginal: 641.1596534774632\n",
      "Train Epoch: 636 [512/17352 (3%)] Loss: -823.299683\n",
      "Train Epoch: 636 [10588/17352 (61%)] Loss: -961.413779\n",
      "Train Epoch: 636 [17153/17352 (99%)] Loss: -757.544440\n",
      "    epoch          : 636\n",
      "    loss           : -858.907796811167\n",
      "    val_loss       : -632.0060852221351\n",
      "    val_log_likelihood: 1136.5771871732977\n",
      "    val_log_marginal: 657.369825664765\n",
      "Train Epoch: 637 [512/17352 (3%)] Loss: -821.711731\n",
      "Train Epoch: 637 [10180/17352 (59%)] Loss: -831.892771\n",
      "Train Epoch: 637 [16872/17352 (97%)] Loss: -969.795417\n",
      "    epoch          : 637\n",
      "    loss           : -880.6604189419022\n",
      "    val_loss       : -724.9470173100632\n",
      "    val_log_likelihood: 1186.5214572287784\n",
      "    val_log_marginal: 752.6662329001276\n",
      "Train Epoch: 638 [512/17352 (3%)] Loss: -932.097839\n",
      "Train Epoch: 638 [9855/17352 (57%)] Loss: -966.490413\n",
      "Train Epoch: 638 [17335/17352 (100%)] Loss: -1021.555766\n",
      "    epoch          : 638\n",
      "    loss           : -906.8029685523022\n",
      "    val_loss       : -724.8660701831478\n",
      "    val_log_likelihood: 1178.3613708277496\n",
      "    val_log_marginal: 740.4104561475016\n",
      "Train Epoch: 639 [512/17352 (3%)] Loss: -947.918945\n",
      "Train Epoch: 639 [10892/17352 (63%)] Loss: -762.517195\n",
      "Train Epoch: 639 [17044/17352 (98%)] Loss: -956.662812\n",
      "    epoch          : 639\n",
      "    loss           : -903.5079778799513\n",
      "    val_loss       : -723.6692854783065\n",
      "    val_log_likelihood: 1196.6038783242159\n",
      "    val_log_marginal: 745.216057456095\n",
      "Train Epoch: 640 [512/17352 (3%)] Loss: -929.721497\n",
      "Train Epoch: 640 [10166/17352 (59%)] Loss: -1025.020508\n",
      "Train Epoch: 640 [16882/17352 (97%)] Loss: -761.427170\n",
      "    epoch          : 640\n",
      "    loss           : -880.5541831896938\n",
      "    val_loss       : -716.0516360107197\n",
      "    val_log_likelihood: 1193.4656011042212\n",
      "    val_log_marginal: 737.0116230760871\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch640.pth ...\n",
      "Train Epoch: 641 [512/17352 (3%)] Loss: -927.093750\n",
      "Train Epoch: 641 [9878/17352 (57%)] Loss: -980.746528\n",
      "Train Epoch: 641 [17153/17352 (99%)] Loss: -990.251995\n",
      "    epoch          : 641\n",
      "    loss           : -888.7908800143348\n",
      "    val_loss       : -714.5479274267299\n",
      "    val_log_likelihood: 1193.490519891368\n",
      "    val_log_marginal: 740.8885082449652\n",
      "Train Epoch: 642 [512/17352 (3%)] Loss: -937.768982\n",
      "Train Epoch: 642 [10815/17352 (62%)] Loss: -893.592720\n",
      "Train Epoch: 642 [16934/17352 (98%)] Loss: -971.358742\n",
      "    epoch          : 642\n",
      "    loss           : -889.1781031588615\n",
      "    val_loss       : -693.4528685016834\n",
      "    val_log_likelihood: 1182.8204001944925\n",
      "    val_log_marginal: 714.9060741028266\n",
      "Train Epoch: 643 [512/17352 (3%)] Loss: -886.291748\n",
      "Train Epoch: 643 [10431/17352 (60%)] Loss: -886.346734\n",
      "Train Epoch: 643 [16988/17352 (98%)] Loss: -764.494617\n",
      "    epoch          : 643\n",
      "    loss           : -845.7279961905058\n",
      "    val_loss       : -692.0244294959634\n",
      "    val_log_likelihood: 1165.940552557716\n",
      "    val_log_marginal: 724.777666346439\n",
      "Train Epoch: 644 [512/17352 (3%)] Loss: -867.056091\n",
      "Train Epoch: 644 [10068/17352 (58%)] Loss: -880.122128\n",
      "Train Epoch: 644 [16992/17352 (98%)] Loss: -717.139247\n",
      "    epoch          : 644\n",
      "    loss           : -876.1487126375436\n",
      "    val_loss       : -718.8591329983593\n",
      "    val_log_likelihood: 1193.0214591704816\n",
      "    val_log_marginal: 736.9172249781219\n",
      "Train Epoch: 645 [512/17352 (3%)] Loss: -769.159485\n",
      "Train Epoch: 645 [10400/17352 (60%)] Loss: -997.885461\n",
      "Train Epoch: 645 [17277/17352 (100%)] Loss: -972.780322\n",
      "    epoch          : 645\n",
      "    loss           : -909.5886284651763\n",
      "    val_loss       : -733.6725763626916\n",
      "    val_log_likelihood: 1205.9962543929034\n",
      "    val_log_marginal: 755.098522479637\n",
      "Train Epoch: 646 [512/17352 (3%)] Loss: -953.066162\n",
      "Train Epoch: 646 [11039/17352 (64%)] Loss: -875.858946\n",
      "Train Epoch: 646 [17106/17352 (99%)] Loss: -785.667817\n",
      "    epoch          : 646\n",
      "    loss           : -903.4680376357679\n",
      "    val_loss       : -739.0442854285732\n",
      "    val_log_likelihood: 1211.6515158855013\n",
      "    val_log_marginal: 756.921641751586\n",
      "Train Epoch: 647 [512/17352 (3%)] Loss: -961.672546\n",
      "Train Epoch: 647 [10059/17352 (58%)] Loss: -790.578059\n",
      "Train Epoch: 647 [16887/17352 (97%)] Loss: -842.198289\n",
      "    epoch          : 647\n",
      "    loss           : -865.011071965835\n",
      "    val_loss       : -728.5011156910124\n",
      "    val_log_likelihood: 1212.1542937073946\n",
      "    val_log_marginal: 747.7008227187831\n",
      "Train Epoch: 648 [512/17352 (3%)] Loss: -926.998840\n",
      "Train Epoch: 648 [9989/17352 (58%)] Loss: -634.876356\n",
      "Train Epoch: 648 [16883/17352 (97%)] Loss: 392.709521\n",
      "    epoch          : 648\n",
      "    loss           : -276.7551838182751\n",
      "    val_loss       : 146.31741538851836\n",
      "    val_log_likelihood: 1041.3723801670624\n",
      "    val_log_marginal: -120.85277509251355\n",
      "Train Epoch: 649 [512/17352 (3%)] Loss: -159.420181\n",
      "Train Epoch: 649 [10049/17352 (58%)] Loss: -497.570312\n",
      "Train Epoch: 649 [17153/17352 (99%)] Loss: -706.268523\n",
      "    epoch          : 649\n",
      "    loss           : -534.9577492654669\n",
      "    val_loss       : -168.5702979849463\n",
      "    val_log_likelihood: 1071.5683970285525\n",
      "    val_log_marginal: 193.20579775388913\n",
      "Train Epoch: 650 [512/17352 (3%)] Loss: -397.933838\n",
      "Train Epoch: 650 [10017/17352 (58%)] Loss: -909.777778\n",
      "Train Epoch: 650 [17143/17352 (99%)] Loss: -922.695000\n",
      "    epoch          : 650\n",
      "    loss           : -779.3388346127668\n",
      "    val_loss       : -671.0039918175872\n",
      "    val_log_likelihood: 1158.5625579690272\n",
      "    val_log_marginal: 707.2551099048472\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch650.pth ...\n",
      "Train Epoch: 651 [512/17352 (3%)] Loss: -705.874878\n",
      "Train Epoch: 651 [10641/17352 (61%)] Loss: -928.503180\n",
      "Train Epoch: 651 [16922/17352 (98%)] Loss: -1001.659958\n",
      "    epoch          : 651\n",
      "    loss           : -883.6750422839626\n",
      "    val_loss       : -752.2939706583339\n",
      "    val_log_likelihood: 1203.4431164923544\n",
      "    val_log_marginal: 770.153358718351\n",
      "Train Epoch: 652 [512/17352 (3%)] Loss: -943.888123\n",
      "Train Epoch: 652 [10074/17352 (58%)] Loss: -960.424022\n",
      "Train Epoch: 652 [16934/17352 (98%)] Loss: -1003.817576\n",
      "    epoch          : 652\n",
      "    loss           : -911.0226473063697\n",
      "    val_loss       : -747.7782288739296\n",
      "    val_log_likelihood: 1202.4840432606907\n",
      "    val_log_marginal: 762.8486709582228\n",
      "Train Epoch: 653 [512/17352 (3%)] Loss: -961.434509\n",
      "Train Epoch: 653 [10026/17352 (58%)] Loss: -1009.000793\n",
      "Train Epoch: 653 [16883/17352 (97%)] Loss: -859.971997\n",
      "    epoch          : 653\n",
      "    loss           : -918.5812500554185\n",
      "    val_loss       : -759.698615580462\n",
      "    val_log_likelihood: 1213.9306568206794\n",
      "    val_log_marginal: 777.2539198888514\n",
      "Train Epoch: 654 [512/17352 (3%)] Loss: -966.953613\n",
      "Train Epoch: 654 [9870/17352 (57%)] Loss: -777.121503\n",
      "Train Epoch: 654 [16922/17352 (98%)] Loss: -943.462846\n",
      "    epoch          : 654\n",
      "    loss           : -918.6886590024776\n",
      "    val_loss       : -753.4942445872662\n",
      "    val_log_likelihood: 1210.5168280338555\n",
      "    val_log_marginal: 765.9092156799892\n",
      "Train Epoch: 655 [512/17352 (3%)] Loss: -974.925049\n",
      "Train Epoch: 655 [10798/17352 (62%)] Loss: -1008.114606\n",
      "Train Epoch: 655 [16992/17352 (98%)] Loss: -978.898418\n",
      "    epoch          : 655\n",
      "    loss           : -907.7710188311482\n",
      "    val_loss       : -731.2420981768979\n",
      "    val_log_likelihood: 1216.5816829643434\n",
      "    val_log_marginal: 750.4583452124482\n",
      "Train Epoch: 656 [512/17352 (3%)] Loss: -924.894165\n",
      "Train Epoch: 656 [9700/17352 (56%)] Loss: -944.382743\n",
      "Train Epoch: 656 [17277/17352 (100%)] Loss: -1051.884874\n",
      "    epoch          : 656\n",
      "    loss           : -919.1463162364709\n",
      "    val_loss       : -744.8081626447971\n",
      "    val_log_likelihood: 1217.6826422753284\n",
      "    val_log_marginal: 763.4955263063359\n",
      "Train Epoch: 657 [512/17352 (3%)] Loss: -958.157715\n",
      "Train Epoch: 657 [10745/17352 (62%)] Loss: -1010.508511\n",
      "Train Epoch: 657 [17277/17352 (100%)] Loss: -846.582051\n",
      "    epoch          : 657\n",
      "    loss           : -901.8607431557417\n",
      "    val_loss       : -711.5455180231354\n",
      "    val_log_likelihood: 1211.7329657594637\n",
      "    val_log_marginal: 737.6322264088209\n",
      "Train Epoch: 658 [512/17352 (3%)] Loss: -926.137085\n",
      "Train Epoch: 658 [10136/17352 (58%)] Loss: -854.748872\n",
      "Train Epoch: 658 [16923/17352 (98%)] Loss: -851.912711\n",
      "    epoch          : 658\n",
      "    loss           : -899.0154608988476\n",
      "    val_loss       : -731.247614945742\n",
      "    val_log_likelihood: 1212.3432727728373\n",
      "    val_log_marginal: 748.373899308829\n",
      "Train Epoch: 659 [512/17352 (3%)] Loss: -935.733765\n",
      "Train Epoch: 659 [10464/17352 (60%)] Loss: -981.747303\n",
      "Train Epoch: 659 [16882/17352 (97%)] Loss: -990.368333\n",
      "    epoch          : 659\n",
      "    loss           : -913.5289150461423\n",
      "    val_loss       : -758.5917266906199\n",
      "    val_log_likelihood: 1220.4738114776023\n",
      "    val_log_marginal: 776.6585065954297\n",
      "Train Epoch: 660 [512/17352 (3%)] Loss: -971.552673\n",
      "Train Epoch: 660 [10297/17352 (59%)] Loss: -757.862298\n",
      "Train Epoch: 660 [16922/17352 (98%)] Loss: -846.381951\n",
      "    epoch          : 660\n",
      "    loss           : -921.2885360945619\n",
      "    val_loss       : -738.6116406237447\n",
      "    val_log_likelihood: 1217.0410142405703\n",
      "    val_log_marginal: 759.1961812975626\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch660.pth ...\n",
      "Train Epoch: 661 [512/17352 (3%)] Loss: -956.635315\n",
      "Train Epoch: 661 [10503/17352 (61%)] Loss: -931.802450\n",
      "Train Epoch: 661 [16922/17352 (98%)] Loss: -829.206140\n",
      "    epoch          : 661\n",
      "    loss           : -905.9123956450836\n",
      "    val_loss       : -731.078738070164\n",
      "    val_log_likelihood: 1212.5860633227971\n",
      "    val_log_marginal: 751.3826189297895\n",
      "Train Epoch: 662 [512/17352 (3%)] Loss: -956.616760\n",
      "Train Epoch: 662 [10113/17352 (58%)] Loss: -929.005129\n",
      "Train Epoch: 662 [17133/17352 (99%)] Loss: -732.366178\n",
      "    epoch          : 662\n",
      "    loss           : -902.4118804851475\n",
      "    val_loss       : -694.7826610270879\n",
      "    val_log_likelihood: 1197.713649892361\n",
      "    val_log_marginal: 712.5562618167959\n",
      "Train Epoch: 663 [512/17352 (3%)] Loss: -941.562561\n",
      "Train Epoch: 663 [9934/17352 (57%)] Loss: -898.672402\n",
      "Train Epoch: 663 [17090/17352 (98%)] Loss: -768.671035\n",
      "    epoch          : 663\n",
      "    loss           : -887.8663935454703\n",
      "    val_loss       : -694.1063597652995\n",
      "    val_log_likelihood: 1183.8601259971229\n",
      "    val_log_marginal: 713.772271869163\n",
      "Train Epoch: 664 [512/17352 (3%)] Loss: -921.689087\n",
      "Train Epoch: 664 [10230/17352 (59%)] Loss: -866.564165\n",
      "Train Epoch: 664 [16882/17352 (97%)] Loss: -890.763343\n",
      "    epoch          : 664\n",
      "    loss           : -911.6382880663069\n",
      "    val_loss       : -733.9279312410927\n",
      "    val_log_likelihood: 1207.2036504572131\n",
      "    val_log_marginal: 745.6746370896649\n",
      "Train Epoch: 665 [512/17352 (3%)] Loss: -964.002502\n",
      "Train Epoch: 665 [10179/17352 (59%)] Loss: -839.127865\n",
      "Train Epoch: 665 [16934/17352 (98%)] Loss: -984.241355\n",
      "    epoch          : 665\n",
      "    loss           : -894.5066842085507\n",
      "    val_loss       : -692.3827778039926\n",
      "    val_log_likelihood: 1182.5638290977797\n",
      "    val_log_marginal: 726.8222380158306\n",
      "Train Epoch: 666 [512/17352 (3%)] Loss: -900.103210\n",
      "Train Epoch: 666 [10047/17352 (58%)] Loss: -909.379193\n",
      "Train Epoch: 666 [17090/17352 (98%)] Loss: -973.572529\n",
      "    epoch          : 666\n",
      "    loss           : -876.3415053485807\n",
      "    val_loss       : -702.3913181284349\n",
      "    val_log_likelihood: 1199.8277066380422\n",
      "    val_log_marginal: 724.6057320110039\n",
      "Train Epoch: 667 [512/17352 (3%)] Loss: -899.826904\n",
      "Train Epoch: 667 [9807/17352 (57%)] Loss: -984.812436\n",
      "Train Epoch: 667 [16883/17352 (97%)] Loss: -737.831658\n",
      "    epoch          : 667\n",
      "    loss           : -886.344508975898\n",
      "    val_loss       : -703.8426119924546\n",
      "    val_log_likelihood: 1215.2658650914636\n",
      "    val_log_marginal: 751.3575349068101\n",
      "Train Epoch: 668 [512/17352 (3%)] Loss: -938.775696\n",
      "Train Epoch: 668 [10418/17352 (60%)] Loss: -952.518801\n",
      "Train Epoch: 668 [17016/17352 (98%)] Loss: -687.080033\n",
      "    epoch          : 668\n",
      "    loss           : -858.0236815859653\n",
      "    val_loss       : -690.8072245093647\n",
      "    val_log_likelihood: 1192.6676956166752\n",
      "    val_log_marginal: 719.1130485392389\n",
      "Train Epoch: 669 [512/17352 (3%)] Loss: -933.918518\n",
      "Train Epoch: 669 [10617/17352 (61%)] Loss: -907.212225\n",
      "Train Epoch: 669 [16872/17352 (97%)] Loss: -842.947309\n",
      "    epoch          : 669\n",
      "    loss           : -904.2779425203378\n",
      "    val_loss       : -733.8731988518598\n",
      "    val_log_likelihood: 1219.9244420688606\n",
      "    val_log_marginal: 757.3591237094271\n",
      "Train Epoch: 670 [512/17352 (3%)] Loss: -974.755493\n",
      "Train Epoch: 670 [10823/17352 (62%)] Loss: -901.695778\n",
      "Train Epoch: 670 [17263/17352 (99%)] Loss: -929.764681\n",
      "    epoch          : 670\n",
      "    loss           : -925.1892078765194\n",
      "    val_loss       : -722.0812440200284\n",
      "    val_log_likelihood: 1223.9526943414871\n",
      "    val_log_marginal: 745.7173447785751\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch670.pth ...\n",
      "Train Epoch: 671 [512/17352 (3%)] Loss: -951.777527\n",
      "Train Epoch: 671 [10665/17352 (61%)] Loss: -984.081942\n",
      "Train Epoch: 671 [17126/17352 (99%)] Loss: -924.298958\n",
      "    epoch          : 671\n",
      "    loss           : -916.3274266060487\n",
      "    val_loss       : -739.5451541262858\n",
      "    val_log_likelihood: 1223.3055803325929\n",
      "    val_log_marginal: 758.9579631174378\n",
      "Train Epoch: 672 [512/17352 (3%)] Loss: -951.282532\n",
      "Train Epoch: 672 [10488/17352 (60%)] Loss: -1012.955512\n",
      "Train Epoch: 672 [16882/17352 (97%)] Loss: -810.855485\n",
      "    epoch          : 672\n",
      "    loss           : -904.9405460863782\n",
      "    val_loss       : -715.4102536559764\n",
      "    val_log_likelihood: 1215.9851828238038\n",
      "    val_log_marginal: 728.8420611682027\n",
      "Train Epoch: 673 [512/17352 (3%)] Loss: -952.117554\n",
      "Train Epoch: 673 [10014/17352 (58%)] Loss: -855.905203\n",
      "Train Epoch: 673 [16872/17352 (97%)] Loss: -973.131584\n",
      "    epoch          : 673\n",
      "    loss           : -916.6990963545985\n",
      "    val_loss       : -734.2065319735285\n",
      "    val_log_likelihood: 1223.4714042040325\n",
      "    val_log_marginal: 754.6026266434292\n",
      "Train Epoch: 674 [512/17352 (3%)] Loss: -968.851196\n",
      "Train Epoch: 674 [10889/17352 (63%)] Loss: -1012.004521\n",
      "Train Epoch: 674 [17016/17352 (98%)] Loss: -990.097032\n",
      "    epoch          : 674\n",
      "    loss           : -929.0249419201363\n",
      "    val_loss       : -742.7600646013491\n",
      "    val_log_likelihood: 1222.4990215592416\n",
      "    val_log_marginal: 761.5076863381198\n",
      "Train Epoch: 675 [512/17352 (3%)] Loss: -961.282837\n",
      "Train Epoch: 675 [10471/17352 (60%)] Loss: -983.203198\n",
      "Train Epoch: 675 [16958/17352 (98%)] Loss: -918.226650\n",
      "    epoch          : 675\n",
      "    loss           : -896.8075292154709\n",
      "    val_loss       : -679.8033475595521\n",
      "    val_log_likelihood: 1170.1305830835186\n",
      "    val_log_marginal: 702.3241648726179\n",
      "Train Epoch: 676 [512/17352 (3%)] Loss: -910.656128\n",
      "Train Epoch: 676 [10987/17352 (63%)] Loss: -618.992972\n",
      "Train Epoch: 676 [16923/17352 (98%)] Loss: -865.232008\n",
      "    epoch          : 676\n",
      "    loss           : -833.9092442153565\n",
      "    val_loss       : -674.4787181614429\n",
      "    val_log_likelihood: 1176.0428816592153\n",
      "    val_log_marginal: 714.8572450175142\n",
      "Train Epoch: 677 [512/17352 (3%)] Loss: -877.464783\n",
      "Train Epoch: 677 [10041/17352 (58%)] Loss: -946.318350\n",
      "Train Epoch: 677 [16887/17352 (97%)] Loss: -796.922858\n",
      "    epoch          : 677\n",
      "    loss           : -891.9797915084803\n",
      "    val_loss       : -731.5539252687215\n",
      "    val_log_likelihood: 1212.472654415928\n",
      "    val_log_marginal: 758.1424001500744\n",
      "Train Epoch: 678 [512/17352 (3%)] Loss: -922.718506\n",
      "Train Epoch: 678 [10465/17352 (60%)] Loss: -889.931880\n",
      "Train Epoch: 678 [17335/17352 (100%)] Loss: -975.315840\n",
      "    epoch          : 678\n",
      "    loss           : -912.473991242541\n",
      "    val_loss       : -715.3270024103979\n",
      "    val_log_likelihood: 1208.7004760617892\n",
      "    val_log_marginal: 734.2496525416614\n",
      "Train Epoch: 679 [512/17352 (3%)] Loss: -930.315552\n",
      "Train Epoch: 679 [10417/17352 (60%)] Loss: -988.044066\n",
      "Train Epoch: 679 [17044/17352 (98%)] Loss: -916.710165\n",
      "    epoch          : 679\n",
      "    loss           : -911.9050382962623\n",
      "    val_loss       : -751.5332933992524\n",
      "    val_log_likelihood: 1230.8476391380548\n",
      "    val_log_marginal: 776.45713895502\n",
      "Train Epoch: 680 [512/17352 (3%)] Loss: -952.645691\n",
      "Train Epoch: 680 [9976/17352 (57%)] Loss: -829.537439\n",
      "Train Epoch: 680 [16922/17352 (98%)] Loss: -782.244901\n",
      "    epoch          : 680\n",
      "    loss           : -892.9436186350476\n",
      "    val_loss       : -719.8639932941222\n",
      "    val_log_likelihood: 1216.698447349837\n",
      "    val_log_marginal: 754.0158921760565\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch680.pth ...\n",
      "Train Epoch: 681 [512/17352 (3%)] Loss: -951.118103\n",
      "Train Epoch: 681 [10466/17352 (60%)] Loss: -968.861230\n",
      "Train Epoch: 681 [17277/17352 (100%)] Loss: -1023.359756\n",
      "    epoch          : 681\n",
      "    loss           : -900.742139986845\n",
      "    val_loss       : -645.5455382525843\n",
      "    val_log_likelihood: 1158.4510068077363\n",
      "    val_log_marginal: 667.0661238168763\n",
      "Train Epoch: 682 [512/17352 (3%)] Loss: -682.108154\n",
      "Train Epoch: 682 [9999/17352 (58%)] Loss: -852.495807\n",
      "Train Epoch: 682 [17044/17352 (98%)] Loss: -1009.605211\n",
      "    epoch          : 682\n",
      "    loss           : -887.4129640593205\n",
      "    val_loss       : -716.890075021714\n",
      "    val_log_likelihood: 1215.6955514259464\n",
      "    val_log_marginal: 760.6061643498961\n",
      "Train Epoch: 683 [512/17352 (3%)] Loss: -916.791870\n",
      "Train Epoch: 683 [9967/17352 (57%)] Loss: -870.606301\n",
      "Train Epoch: 683 [16887/17352 (97%)] Loss: -1011.739535\n",
      "    epoch          : 683\n",
      "    loss           : -918.3714375146736\n",
      "    val_loss       : -747.3944734157325\n",
      "    val_log_likelihood: 1228.4216095553788\n",
      "    val_log_marginal: 766.4881125424232\n",
      "Train Epoch: 684 [512/17352 (3%)] Loss: -956.356873\n",
      "Train Epoch: 684 [10297/17352 (59%)] Loss: -835.379160\n",
      "Train Epoch: 684 [17153/17352 (99%)] Loss: -961.467878\n",
      "    epoch          : 684\n",
      "    loss           : -926.8072667697531\n",
      "    val_loss       : -745.6729270407475\n",
      "    val_log_likelihood: 1228.7663729002363\n",
      "    val_log_marginal: 758.1310139279276\n",
      "Train Epoch: 685 [512/17352 (3%)] Loss: -960.205383\n",
      "Train Epoch: 685 [10534/17352 (61%)] Loss: -973.996624\n",
      "Train Epoch: 685 [17143/17352 (99%)] Loss: -1009.275729\n",
      "    epoch          : 685\n",
      "    loss           : -923.3303651251241\n",
      "    val_loss       : -696.6504259818244\n",
      "    val_log_likelihood: 1221.1301626881896\n",
      "    val_log_marginal: 715.6549212856885\n",
      "Train Epoch: 686 [512/17352 (3%)] Loss: -932.664551\n",
      "Train Epoch: 686 [10063/17352 (58%)] Loss: -631.803696\n",
      "Train Epoch: 686 [16958/17352 (98%)] Loss: -727.815928\n",
      "    epoch          : 686\n",
      "    loss           : -846.1885971546394\n",
      "    val_loss       : -588.5312951361486\n",
      "    val_log_likelihood: 1178.3659332168177\n",
      "    val_log_marginal: 610.0972808537659\n",
      "Train Epoch: 687 [512/17352 (3%)] Loss: -855.531006\n",
      "Train Epoch: 687 [10038/17352 (58%)] Loss: -925.399183\n",
      "Train Epoch: 687 [16872/17352 (97%)] Loss: -919.477983\n",
      "    epoch          : 687\n",
      "    loss           : -861.2345373673727\n",
      "    val_loss       : -707.4658100488493\n",
      "    val_log_likelihood: 1194.2756421779861\n",
      "    val_log_marginal: 722.6035330492284\n",
      "Train Epoch: 688 [512/17352 (3%)] Loss: -944.758850\n",
      "Train Epoch: 688 [10718/17352 (62%)] Loss: -876.229578\n",
      "Train Epoch: 688 [16872/17352 (97%)] Loss: -971.149228\n",
      "    epoch          : 688\n",
      "    loss           : -879.887859573524\n",
      "    val_loss       : -705.6458523394604\n",
      "    val_log_likelihood: 1200.7624074723021\n",
      "    val_log_marginal: 729.5095484254158\n",
      "Train Epoch: 689 [512/17352 (3%)] Loss: -954.196533\n",
      "Train Epoch: 689 [10378/17352 (60%)] Loss: -861.720415\n",
      "Train Epoch: 689 [16992/17352 (98%)] Loss: -971.209375\n",
      "    epoch          : 689\n",
      "    loss           : -907.088974713685\n",
      "    val_loss       : -724.1640258471926\n",
      "    val_log_likelihood: 1215.3140219453774\n",
      "    val_log_marginal: 746.6007116227978\n",
      "Train Epoch: 690 [512/17352 (3%)] Loss: -978.764282\n",
      "Train Epoch: 690 [10292/17352 (59%)] Loss: -882.167078\n",
      "Train Epoch: 690 [16923/17352 (98%)] Loss: -995.914044\n",
      "    epoch          : 690\n",
      "    loss           : -898.515512373277\n",
      "    val_loss       : -691.4627476396105\n",
      "    val_log_likelihood: 1221.8881135968993\n",
      "    val_log_marginal: 713.5125149623346\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch690.pth ...\n",
      "Train Epoch: 691 [512/17352 (3%)] Loss: -912.782837\n",
      "Train Epoch: 691 [10674/17352 (62%)] Loss: -992.945479\n",
      "Train Epoch: 691 [17016/17352 (98%)] Loss: -828.563444\n",
      "    epoch          : 691\n",
      "    loss           : -885.5635898626857\n",
      "    val_loss       : -693.6349961458108\n",
      "    val_log_likelihood: 1192.379196788531\n",
      "    val_log_marginal: 714.6827077215345\n",
      "Train Epoch: 692 [512/17352 (3%)] Loss: -890.905640\n",
      "Train Epoch: 692 [10172/17352 (59%)] Loss: -909.254494\n",
      "Train Epoch: 692 [17090/17352 (98%)] Loss: -666.523712\n",
      "    epoch          : 692\n",
      "    loss           : -870.5278926064035\n",
      "    val_loss       : -653.598503060354\n",
      "    val_log_likelihood: 1190.0814267170126\n",
      "    val_log_marginal: 672.7297982699627\n",
      "Train Epoch: 693 [512/17352 (3%)] Loss: -889.768921\n",
      "Train Epoch: 693 [10879/17352 (63%)] Loss: -956.995412\n",
      "Train Epoch: 693 [17143/17352 (99%)] Loss: -390.644838\n",
      "    epoch          : 693\n",
      "    loss           : -614.9446723234963\n",
      "    val_loss       : -391.6972359304606\n",
      "    val_log_likelihood: 1086.708510807025\n",
      "    val_log_marginal: 427.1234891441302\n",
      "Train Epoch: 694 [512/17352 (3%)] Loss: -608.392273\n",
      "Train Epoch: 694 [10285/17352 (59%)] Loss: -790.469781\n",
      "Train Epoch: 694 [16922/17352 (98%)] Loss: -241.179961\n",
      "    epoch          : 694\n",
      "    loss           : -657.3206421255388\n",
      "    val_loss       : -266.3486522652605\n",
      "    val_log_likelihood: 1128.8012042075588\n",
      "    val_log_marginal: 287.04285177061666\n",
      "Train Epoch: 695 [512/17352 (3%)] Loss: -552.659485\n",
      "Train Epoch: 695 [10727/17352 (62%)] Loss: -811.789773\n",
      "Train Epoch: 695 [17335/17352 (100%)] Loss: -713.502890\n",
      "    epoch          : 695\n",
      "    loss           : -808.17616443133\n",
      "    val_loss       : -564.7701297245584\n",
      "    val_log_likelihood: 1170.9663226080875\n",
      "    val_log_marginal: 589.1377641125737\n",
      "Train Epoch: 696 [512/17352 (3%)] Loss: -820.510132\n",
      "Train Epoch: 696 [10210/17352 (59%)] Loss: -939.080952\n",
      "Train Epoch: 696 [17090/17352 (98%)] Loss: -899.615891\n",
      "    epoch          : 696\n",
      "    loss           : -837.5481405168297\n",
      "    val_loss       : -628.3740665382966\n",
      "    val_log_likelihood: 1180.5325478056197\n",
      "    val_log_marginal: 663.1477871049102\n",
      "Train Epoch: 697 [512/17352 (3%)] Loss: -871.862854\n",
      "Train Epoch: 697 [10911/17352 (63%)] Loss: -743.906714\n",
      "Train Epoch: 697 [17108/17352 (99%)] Loss: -969.059575\n",
      "    epoch          : 697\n",
      "    loss           : -891.6376829392685\n",
      "    val_loss       : -735.2365509627776\n",
      "    val_log_likelihood: 1219.3743180341519\n",
      "    val_log_marginal: 756.9144312522909\n",
      "Train Epoch: 698 [512/17352 (3%)] Loss: -967.011841\n",
      "Train Epoch: 698 [10197/17352 (59%)] Loss: -768.589040\n",
      "Train Epoch: 698 [17106/17352 (99%)] Loss: -920.885302\n",
      "    epoch          : 698\n",
      "    loss           : -916.481907381729\n",
      "    val_loss       : -728.1426540125118\n",
      "    val_log_likelihood: 1212.843545377392\n",
      "    val_log_marginal: 744.7929523849989\n",
      "Train Epoch: 699 [512/17352 (3%)] Loss: -930.927124\n",
      "Train Epoch: 699 [10620/17352 (61%)] Loss: -1015.467500\n",
      "Train Epoch: 699 [17253/17352 (99%)] Loss: -742.328200\n",
      "    epoch          : 699\n",
      "    loss           : -915.6009392331664\n",
      "    val_loss       : -737.9480524452727\n",
      "    val_log_likelihood: 1227.7802498274407\n",
      "    val_log_marginal: 760.1682613157511\n",
      "Train Epoch: 700 [512/17352 (3%)] Loss: -977.108704\n",
      "Train Epoch: 700 [9996/17352 (58%)] Loss: -975.060383\n",
      "Train Epoch: 700 [17106/17352 (99%)] Loss: -838.924940\n",
      "    epoch          : 700\n",
      "    loss           : -925.8922511213614\n",
      "    val_loss       : -737.415555008384\n",
      "    val_log_likelihood: 1223.8078726183012\n",
      "    val_log_marginal: 753.2950142724809\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch700.pth ...\n",
      "Train Epoch: 701 [512/17352 (3%)] Loss: -977.391785\n",
      "Train Epoch: 701 [9864/17352 (57%)] Loss: -980.677890\n",
      "Train Epoch: 701 [17153/17352 (99%)] Loss: -803.023958\n",
      "    epoch          : 701\n",
      "    loss           : -927.3806874989131\n",
      "    val_loss       : -743.2912185913714\n",
      "    val_log_likelihood: 1229.1006815364547\n",
      "    val_log_marginal: 762.629350547611\n",
      "Train Epoch: 702 [512/17352 (3%)] Loss: -993.241943\n",
      "Train Epoch: 702 [10451/17352 (60%)] Loss: -1036.007120\n",
      "Train Epoch: 702 [16958/17352 (98%)] Loss: -1024.201093\n",
      "    epoch          : 702\n",
      "    loss           : -928.3691786593939\n",
      "    val_loss       : -724.9727640122212\n",
      "    val_log_likelihood: 1218.5859754360677\n",
      "    val_log_marginal: 740.4702473250024\n",
      "Train Epoch: 703 [512/17352 (3%)] Loss: -981.060913\n",
      "Train Epoch: 703 [10289/17352 (59%)] Loss: -996.493416\n",
      "Train Epoch: 703 [16887/17352 (97%)] Loss: -811.657011\n",
      "    epoch          : 703\n",
      "    loss           : -912.1775199769232\n",
      "    val_loss       : -722.2262439502334\n",
      "    val_log_likelihood: 1224.7084686163776\n",
      "    val_log_marginal: 739.5227658147164\n",
      "Train Epoch: 704 [512/17352 (3%)] Loss: -937.167603\n",
      "Train Epoch: 704 [10723/17352 (62%)] Loss: -1011.199494\n",
      "Train Epoch: 704 [17049/17352 (98%)] Loss: -1018.146543\n",
      "    epoch          : 704\n",
      "    loss           : -914.3846757028141\n",
      "    val_loss       : -739.1184789742244\n",
      "    val_log_likelihood: 1222.7659427360927\n",
      "    val_log_marginal: 758.3495923753329\n",
      "Train Epoch: 705 [512/17352 (3%)] Loss: -977.665466\n",
      "Train Epoch: 705 [9759/17352 (56%)] Loss: -925.694835\n",
      "Train Epoch: 705 [16988/17352 (98%)] Loss: -942.408676\n",
      "    epoch          : 705\n",
      "    loss           : -894.7834187402615\n",
      "    val_loss       : -703.5452339605308\n",
      "    val_log_likelihood: 1200.2156640389935\n",
      "    val_log_marginal: 730.2767353086117\n",
      "Train Epoch: 706 [512/17352 (3%)] Loss: -782.065613\n",
      "Train Epoch: 706 [10203/17352 (59%)] Loss: -928.530021\n",
      "Train Epoch: 706 [17106/17352 (99%)] Loss: -985.685066\n",
      "    epoch          : 706\n",
      "    loss           : -910.2134396522443\n",
      "    val_loss       : -706.416246781331\n",
      "    val_log_likelihood: 1212.6632935580121\n",
      "    val_log_marginal: 731.5324793051193\n",
      "Train Epoch: 707 [512/17352 (3%)] Loss: -966.049927\n",
      "Train Epoch: 707 [10377/17352 (60%)] Loss: -785.518771\n",
      "Train Epoch: 707 [17016/17352 (98%)] Loss: -731.892718\n",
      "    epoch          : 707\n",
      "    loss           : -905.0521869940817\n",
      "    val_loss       : -736.0075493784402\n",
      "    val_log_likelihood: 1223.862502136899\n",
      "    val_log_marginal: 754.6006832492467\n",
      "Train Epoch: 708 [512/17352 (3%)] Loss: -957.995667\n",
      "Train Epoch: 708 [10289/17352 (59%)] Loss: -958.480685\n",
      "Train Epoch: 708 [17335/17352 (100%)] Loss: -987.961901\n",
      "    epoch          : 708\n",
      "    loss           : -936.6167195157475\n",
      "    val_loss       : -720.28101516185\n",
      "    val_log_likelihood: 1224.4273606699373\n",
      "    val_log_marginal: 744.3758007023586\n",
      "Train Epoch: 709 [512/17352 (3%)] Loss: -953.652771\n",
      "Train Epoch: 709 [10303/17352 (59%)] Loss: -790.126869\n",
      "Train Epoch: 709 [16882/17352 (97%)] Loss: -834.691119\n",
      "    epoch          : 709\n",
      "    loss           : -940.9888729583182\n",
      "    val_loss       : -755.040215817028\n",
      "    val_log_likelihood: 1243.278933427603\n",
      "    val_log_marginal: 771.4784616201656\n",
      "Train Epoch: 710 [512/17352 (3%)] Loss: -1004.398193\n",
      "Train Epoch: 710 [10322/17352 (59%)] Loss: -988.821094\n",
      "Train Epoch: 710 [16878/17352 (97%)] Loss: -1021.138606\n",
      "    epoch          : 710\n",
      "    loss           : -947.5488144796312\n",
      "    val_loss       : -740.6662119754144\n",
      "    val_log_likelihood: 1241.4899699818072\n",
      "    val_log_marginal: 758.9859028889689\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch710.pth ...\n",
      "Train Epoch: 711 [512/17352 (3%)] Loss: -973.600525\n",
      "Train Epoch: 711 [10966/17352 (63%)] Loss: -1046.274587\n",
      "Train Epoch: 711 [17253/17352 (99%)] Loss: -797.087602\n",
      "    epoch          : 711\n",
      "    loss           : -906.7927897449716\n",
      "    val_loss       : -623.8681418691658\n",
      "    val_log_likelihood: 1196.482018317357\n",
      "    val_log_marginal: 643.5740645985946\n",
      "Train Epoch: 712 [512/17352 (3%)] Loss: -864.470947\n",
      "Train Epoch: 712 [10604/17352 (61%)] Loss: -1048.024523\n",
      "Train Epoch: 712 [16958/17352 (98%)] Loss: -536.130066\n",
      "    epoch          : 712\n",
      "    loss           : -808.1980241205164\n",
      "    val_loss       : -302.3283462635832\n",
      "    val_log_likelihood: 1144.126665553211\n",
      "    val_log_marginal: 340.33481464163805\n",
      "Train Epoch: 713 [512/17352 (3%)] Loss: -254.571625\n",
      "Train Epoch: 713 [10709/17352 (62%)] Loss: -477.480903\n",
      "Train Epoch: 713 [16883/17352 (97%)] Loss: -589.911244\n",
      "    epoch          : 713\n",
      "    loss           : -546.6267820138015\n",
      "    val_loss       : -344.02404628919703\n",
      "    val_log_likelihood: 1117.371393482082\n",
      "    val_log_marginal: 389.1144117839659\n",
      "Train Epoch: 714 [512/17352 (3%)] Loss: -324.771179\n",
      "Train Epoch: 714 [9834/17352 (57%)] Loss: -387.235651\n",
      "Train Epoch: 714 [16922/17352 (98%)] Loss: -866.605745\n",
      "    epoch          : 714\n",
      "    loss           : -688.5140166035395\n",
      "    val_loss       : -691.8944393097468\n",
      "    val_log_likelihood: 1175.3305483644776\n",
      "    val_log_marginal: 718.9290573905026\n",
      "Train Epoch: 715 [512/17352 (3%)] Loss: -728.049866\n",
      "Train Epoch: 715 [10010/17352 (58%)] Loss: -941.326056\n",
      "Train Epoch: 715 [16923/17352 (98%)] Loss: -933.093285\n",
      "    epoch          : 715\n",
      "    loss           : -891.585715468173\n",
      "    val_loss       : -666.5581876916251\n",
      "    val_log_likelihood: 1204.4894762636548\n",
      "    val_log_marginal: 687.1692164784708\n",
      "Train Epoch: 716 [512/17352 (3%)] Loss: -877.417480\n",
      "Train Epoch: 716 [10162/17352 (59%)] Loss: -718.860081\n",
      "Train Epoch: 716 [16923/17352 (98%)] Loss: -961.942839\n",
      "    epoch          : 716\n",
      "    loss           : -881.7033653608644\n",
      "    val_loss       : -739.6710189108074\n",
      "    val_log_likelihood: 1223.828347621285\n",
      "    val_log_marginal: 760.785022365794\n",
      "Train Epoch: 717 [512/17352 (3%)] Loss: -957.020508\n",
      "Train Epoch: 717 [10361/17352 (60%)] Loss: -888.961130\n",
      "Train Epoch: 717 [17044/17352 (98%)] Loss: -991.426169\n",
      "    epoch          : 717\n",
      "    loss           : -927.7861510435719\n",
      "    val_loss       : -743.6882188673457\n",
      "    val_log_likelihood: 1231.6334720534708\n",
      "    val_log_marginal: 760.5609873163518\n",
      "Train Epoch: 718 [512/17352 (3%)] Loss: -979.212585\n",
      "Train Epoch: 718 [9768/17352 (56%)] Loss: -898.566886\n",
      "Train Epoch: 718 [17108/17352 (99%)] Loss: -1039.359186\n",
      "    epoch          : 718\n",
      "    loss           : -921.1262431065375\n",
      "    val_loss       : -733.8492855725187\n",
      "    val_log_likelihood: 1236.8914050937642\n",
      "    val_log_marginal: 764.1698703575727\n",
      "Train Epoch: 719 [512/17352 (3%)] Loss: -959.397705\n",
      "Train Epoch: 719 [10219/17352 (59%)] Loss: -920.050505\n",
      "Train Epoch: 719 [17153/17352 (99%)] Loss: -1037.276396\n",
      "    epoch          : 719\n",
      "    loss           : -915.7750147775635\n",
      "    val_loss       : -679.236538328103\n",
      "    val_log_likelihood: 1231.9960278454412\n",
      "    val_log_marginal: 703.0000352021951\n",
      "Train Epoch: 720 [512/17352 (3%)] Loss: -735.016785\n",
      "Train Epoch: 720 [10886/17352 (63%)] Loss: -1016.658915\n",
      "Train Epoch: 720 [17090/17352 (98%)] Loss: -806.562221\n",
      "    epoch          : 720\n",
      "    loss           : -877.6320781490185\n",
      "    val_loss       : -590.2029027299416\n",
      "    val_log_likelihood: 1224.3894818474423\n",
      "    val_log_marginal: 606.7688999729008\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch720.pth ...\n",
      "Train Epoch: 721 [512/17352 (3%)] Loss: -762.408875\n",
      "Train Epoch: 721 [10546/17352 (61%)] Loss: -874.497243\n",
      "Train Epoch: 721 [16922/17352 (98%)] Loss: -770.059140\n",
      "    epoch          : 721\n",
      "    loss           : -902.3872626413365\n",
      "    val_loss       : -741.7528833687629\n",
      "    val_log_likelihood: 1236.5378679032642\n",
      "    val_log_marginal: 761.4199719749562\n",
      "Train Epoch: 722 [512/17352 (3%)] Loss: -977.706543\n",
      "Train Epoch: 722 [10496/17352 (60%)] Loss: -893.458160\n",
      "Train Epoch: 722 [16988/17352 (98%)] Loss: -707.851077\n",
      "    epoch          : 722\n",
      "    loss           : -918.8915937338646\n",
      "    val_loss       : -714.9541324121891\n",
      "    val_log_likelihood: 1224.2401210349246\n",
      "    val_log_marginal: 745.9427649844497\n",
      "Train Epoch: 723 [512/17352 (3%)] Loss: -969.272766\n",
      "Train Epoch: 723 [10557/17352 (61%)] Loss: -635.383747\n",
      "Train Epoch: 723 [17108/17352 (99%)] Loss: -847.194010\n",
      "    epoch          : 723\n",
      "    loss           : -889.7886862425936\n",
      "    val_loss       : -672.973105344098\n",
      "    val_log_likelihood: 1194.7341267171091\n",
      "    val_log_marginal: 712.0471497069196\n",
      "Train Epoch: 724 [512/17352 (3%)] Loss: -931.324707\n",
      "Train Epoch: 724 [10917/17352 (63%)] Loss: -829.469959\n",
      "Train Epoch: 724 [16939/17352 (98%)] Loss: -889.968357\n",
      "    epoch          : 724\n",
      "    loss           : -838.7631652619631\n",
      "    val_loss       : -712.8770493953426\n",
      "    val_log_likelihood: 1205.411365676672\n",
      "    val_log_marginal: 748.6238831415429\n",
      "Train Epoch: 725 [512/17352 (3%)] Loss: -951.683655\n",
      "Train Epoch: 725 [10140/17352 (58%)] Loss: -831.839583\n",
      "Train Epoch: 725 [16883/17352 (97%)] Loss: -567.417904\n",
      "    epoch          : 725\n",
      "    loss           : -857.3979684018022\n",
      "    val_loss       : -663.4571898182394\n",
      "    val_log_likelihood: 1169.4829792202195\n",
      "    val_log_marginal: 693.9464201381926\n",
      "Train Epoch: 726 [512/17352 (3%)] Loss: -665.993042\n",
      "Train Epoch: 726 [10304/17352 (59%)] Loss: -794.166958\n",
      "Train Epoch: 726 [16988/17352 (98%)] Loss: -930.920854\n",
      "    epoch          : 726\n",
      "    loss           : -867.6002318652555\n",
      "    val_loss       : -705.1984842500899\n",
      "    val_log_likelihood: 1193.2186974884326\n",
      "    val_log_marginal: 735.6067428930152\n",
      "Train Epoch: 727 [512/17352 (3%)] Loss: -905.390625\n",
      "Train Epoch: 727 [10374/17352 (60%)] Loss: -978.573021\n",
      "Train Epoch: 727 [16992/17352 (98%)] Loss: -935.019818\n",
      "    epoch          : 727\n",
      "    loss           : -901.593040232818\n",
      "    val_loss       : -735.5875445165894\n",
      "    val_log_likelihood: 1222.9795955971745\n",
      "    val_log_marginal: 767.7758908613857\n",
      "Train Epoch: 728 [512/17352 (3%)] Loss: -970.644287\n",
      "Train Epoch: 728 [9927/17352 (57%)] Loss: -959.228881\n",
      "Train Epoch: 728 [16887/17352 (97%)] Loss: -771.075508\n",
      "    epoch          : 728\n",
      "    loss           : -920.2880744064277\n",
      "    val_loss       : -733.0907363479057\n",
      "    val_log_likelihood: 1230.2510318466811\n",
      "    val_log_marginal: 768.1247263874135\n",
      "Train Epoch: 729 [512/17352 (3%)] Loss: -973.403442\n",
      "Train Epoch: 729 [9875/17352 (57%)] Loss: -849.766487\n",
      "Train Epoch: 729 [17253/17352 (99%)] Loss: -831.321885\n",
      "    epoch          : 729\n",
      "    loss           : -938.9228078382213\n",
      "    val_loss       : -751.246729911047\n",
      "    val_log_likelihood: 1240.8530154460052\n",
      "    val_log_marginal: 773.7467215517838\n",
      "Train Epoch: 730 [512/17352 (3%)] Loss: -979.178101\n",
      "Train Epoch: 730 [10410/17352 (60%)] Loss: -980.479190\n",
      "Train Epoch: 730 [16923/17352 (98%)] Loss: -930.482182\n",
      "    epoch          : 730\n",
      "    loss           : -942.968254787359\n",
      "    val_loss       : -747.5058814016388\n",
      "    val_log_likelihood: 1239.059470676203\n",
      "    val_log_marginal: 766.664659585063\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch730.pth ...\n",
      "Train Epoch: 731 [512/17352 (3%)] Loss: -980.075256\n",
      "Train Epoch: 731 [10465/17352 (60%)] Loss: -951.059860\n",
      "Train Epoch: 731 [17277/17352 (100%)] Loss: -1041.256092\n",
      "    epoch          : 731\n",
      "    loss           : -907.8233966992976\n",
      "    val_loss       : -649.7009175586181\n",
      "    val_log_likelihood: 1199.5782810026224\n",
      "    val_log_marginal: 670.8057795186337\n",
      "Train Epoch: 732 [512/17352 (3%)] Loss: -870.422974\n",
      "Train Epoch: 732 [10484/17352 (60%)] Loss: -1026.116989\n",
      "Train Epoch: 732 [17049/17352 (98%)] Loss: -932.437421\n",
      "    epoch          : 732\n",
      "    loss           : -916.4004900180071\n",
      "    val_loss       : -740.6387688449979\n",
      "    val_log_likelihood: 1229.4987385671425\n",
      "    val_log_marginal: 754.7639975425894\n",
      "Train Epoch: 733 [512/17352 (3%)] Loss: -965.541382\n",
      "Train Epoch: 733 [10613/17352 (61%)] Loss: -991.699896\n",
      "Train Epoch: 733 [17143/17352 (99%)] Loss: -899.299977\n",
      "    epoch          : 733\n",
      "    loss           : -882.2288410730451\n",
      "    val_loss       : -408.7535033950409\n",
      "    val_log_likelihood: 1186.5827056955873\n",
      "    val_log_marginal: 432.49991398364847\n",
      "Train Epoch: 734 [512/17352 (3%)] Loss: -689.174072\n",
      "Train Epoch: 734 [10590/17352 (61%)] Loss: -826.154688\n",
      "Train Epoch: 734 [17124/17352 (99%)] Loss: -890.878102\n",
      "    epoch          : 734\n",
      "    loss           : -808.2711673806008\n",
      "    val_loss       : -691.3299923065164\n",
      "    val_log_likelihood: 1199.3596971053585\n",
      "    val_log_marginal: 715.0813720456453\n",
      "Train Epoch: 735 [512/17352 (3%)] Loss: -931.156860\n",
      "Train Epoch: 735 [10872/17352 (63%)] Loss: -848.089267\n",
      "Train Epoch: 735 [17153/17352 (99%)] Loss: -859.414162\n",
      "    epoch          : 735\n",
      "    loss           : -848.7676459317418\n",
      "    val_loss       : -255.71349357785692\n",
      "    val_log_likelihood: 1208.211226387845\n",
      "    val_log_marginal: 291.57396768127603\n",
      "Train Epoch: 736 [512/17352 (3%)] Loss: -461.959198\n",
      "Train Epoch: 736 [10380/17352 (60%)] Loss: -908.260366\n",
      "Train Epoch: 736 [16872/17352 (97%)] Loss: -809.780359\n",
      "    epoch          : 736\n",
      "    loss           : -836.1888283218007\n",
      "    val_loss       : -700.8715626440032\n",
      "    val_log_likelihood: 1219.2399878882402\n",
      "    val_log_marginal: 721.21873982097\n",
      "Train Epoch: 737 [512/17352 (3%)] Loss: -913.888245\n",
      "Train Epoch: 737 [10253/17352 (59%)] Loss: -966.912984\n",
      "Train Epoch: 737 [17153/17352 (99%)] Loss: -1010.281487\n",
      "    epoch          : 737\n",
      "    loss           : -892.6088574115211\n",
      "    val_loss       : -702.4946416009946\n",
      "    val_log_likelihood: 1197.6732799771157\n",
      "    val_log_marginal: 731.8257912073199\n",
      "Train Epoch: 738 [512/17352 (3%)] Loss: -943.345154\n",
      "Train Epoch: 738 [9875/17352 (57%)] Loss: -978.299082\n",
      "Train Epoch: 738 [16988/17352 (98%)] Loss: -964.242188\n",
      "    epoch          : 738\n",
      "    loss           : -930.0400032964245\n",
      "    val_loss       : -723.745762441146\n",
      "    val_log_likelihood: 1234.7343248860868\n",
      "    val_log_marginal: 744.1640288793545\n",
      "Train Epoch: 739 [512/17352 (3%)] Loss: -963.125854\n",
      "Train Epoch: 739 [10652/17352 (61%)] Loss: -822.418172\n",
      "Train Epoch: 739 [17064/17352 (98%)] Loss: -786.057416\n",
      "    epoch          : 739\n",
      "    loss           : -938.777111276568\n",
      "    val_loss       : -745.9868375932881\n",
      "    val_log_likelihood: 1240.8067722261708\n",
      "    val_log_marginal: 767.121472474661\n",
      "Train Epoch: 740 [512/17352 (3%)] Loss: -980.475403\n",
      "Train Epoch: 740 [10446/17352 (60%)] Loss: -1051.122396\n",
      "Train Epoch: 740 [16934/17352 (98%)] Loss: -888.497907\n",
      "    epoch          : 740\n",
      "    loss           : -935.5705210109211\n",
      "    val_loss       : -758.8701846276348\n",
      "    val_log_likelihood: 1245.7927913774283\n",
      "    val_log_marginal: 773.0001911417478\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch740.pth ...\n",
      "Train Epoch: 741 [512/17352 (3%)] Loss: -995.476562\n",
      "Train Epoch: 741 [10571/17352 (61%)] Loss: -1014.304251\n",
      "Train Epoch: 741 [17064/17352 (98%)] Loss: -982.641281\n",
      "    epoch          : 741\n",
      "    loss           : -939.627735998271\n",
      "    val_loss       : -751.7596436191957\n",
      "    val_log_likelihood: 1240.49105800737\n",
      "    val_log_marginal: 766.129927698005\n",
      "Train Epoch: 742 [512/17352 (3%)] Loss: -986.003662\n",
      "Train Epoch: 742 [10352/17352 (60%)] Loss: -1017.269415\n",
      "Train Epoch: 742 [16939/17352 (98%)] Loss: -879.834784\n",
      "    epoch          : 742\n",
      "    loss           : -941.9046721390846\n",
      "    val_loss       : -743.7403352487971\n",
      "    val_log_likelihood: 1245.7895979636605\n",
      "    val_log_marginal: 769.2684830281135\n",
      "Train Epoch: 743 [512/17352 (3%)] Loss: -986.704468\n",
      "Train Epoch: 743 [10640/17352 (61%)] Loss: -734.303678\n",
      "Train Epoch: 743 [17263/17352 (99%)] Loss: -685.060779\n",
      "    epoch          : 743\n",
      "    loss           : -898.4995949690889\n",
      "    val_loss       : -697.7281023919943\n",
      "    val_log_likelihood: 1196.6742877611644\n",
      "    val_log_marginal: 724.7322434287529\n",
      "Train Epoch: 744 [512/17352 (3%)] Loss: -733.310181\n",
      "Train Epoch: 744 [10105/17352 (58%)] Loss: -639.655216\n",
      "Train Epoch: 744 [16922/17352 (98%)] Loss: -857.625093\n",
      "    epoch          : 744\n",
      "    loss           : -899.7097510729474\n",
      "    val_loss       : -704.5040885571469\n",
      "    val_log_likelihood: 1217.574765561158\n",
      "    val_log_marginal: 752.2250857884434\n",
      "Train Epoch: 745 [512/17352 (3%)] Loss: -954.633789\n",
      "Train Epoch: 745 [10709/17352 (62%)] Loss: -1049.513497\n",
      "Train Epoch: 745 [17108/17352 (99%)] Loss: -889.111607\n",
      "    epoch          : 745\n",
      "    loss           : -929.7465680598287\n",
      "    val_loss       : -734.6418784988042\n",
      "    val_log_likelihood: 1234.2386303999333\n",
      "    val_log_marginal: 755.2648839459023\n",
      "Train Epoch: 746 [512/17352 (3%)] Loss: -981.553650\n",
      "Train Epoch: 746 [10281/17352 (59%)] Loss: -852.202136\n",
      "Train Epoch: 746 [17049/17352 (98%)] Loss: -948.263913\n",
      "    epoch          : 746\n",
      "    loss           : -935.5141214199474\n",
      "    val_loss       : -748.1589115125232\n",
      "    val_log_likelihood: 1251.635524680655\n",
      "    val_log_marginal: 772.2935970021597\n",
      "Train Epoch: 747 [512/17352 (3%)] Loss: -996.859375\n",
      "Train Epoch: 747 [10034/17352 (58%)] Loss: -785.694095\n",
      "Train Epoch: 747 [16988/17352 (98%)] Loss: -1009.760261\n",
      "    epoch          : 747\n",
      "    loss           : -922.9905911697226\n",
      "    val_loss       : -705.2486147594936\n",
      "    val_log_likelihood: 1240.0909558920982\n",
      "    val_log_marginal: 726.6434854973585\n",
      "Train Epoch: 748 [512/17352 (3%)] Loss: -961.726196\n",
      "Train Epoch: 748 [10803/17352 (62%)] Loss: -1019.103797\n",
      "Train Epoch: 748 [16992/17352 (98%)] Loss: -862.594952\n",
      "    epoch          : 748\n",
      "    loss           : -888.5532429708859\n",
      "    val_loss       : -601.9028667269616\n",
      "    val_log_likelihood: 1158.1940389516535\n",
      "    val_log_marginal: 639.9158421873443\n",
      "Train Epoch: 749 [512/17352 (3%)] Loss: -804.987000\n",
      "Train Epoch: 749 [10234/17352 (59%)] Loss: -777.244634\n",
      "Train Epoch: 749 [17143/17352 (99%)] Loss: -932.618962\n",
      "    epoch          : 749\n",
      "    loss           : -837.7883038231774\n",
      "    val_loss       : -672.2922918489226\n",
      "    val_log_likelihood: 1182.5771971492088\n",
      "    val_log_marginal: 699.3730908389643\n",
      "Train Epoch: 750 [512/17352 (3%)] Loss: -943.300293\n",
      "Train Epoch: 750 [10315/17352 (59%)] Loss: -978.482734\n",
      "Train Epoch: 750 [16883/17352 (97%)] Loss: -703.186626\n",
      "    epoch          : 750\n",
      "    loss           : -897.7171494233193\n",
      "    val_loss       : -732.3598870763973\n",
      "    val_log_likelihood: 1229.2947481686142\n",
      "    val_log_marginal: 747.2065184682559\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch750.pth ...\n",
      "Train Epoch: 751 [512/17352 (3%)] Loss: -955.311768\n",
      "Train Epoch: 751 [10235/17352 (59%)] Loss: -929.563745\n",
      "Train Epoch: 751 [16878/17352 (97%)] Loss: -806.982226\n",
      "    epoch          : 751\n",
      "    loss           : -917.4646608942105\n",
      "    val_loss       : -735.6974834554621\n",
      "    val_log_likelihood: 1240.4372341299038\n",
      "    val_log_marginal: 762.0977131171076\n",
      "Train Epoch: 752 [512/17352 (3%)] Loss: -970.719238\n",
      "Train Epoch: 752 [10259/17352 (59%)] Loss: -999.312355\n",
      "Train Epoch: 752 [17124/17352 (99%)] Loss: -983.711146\n",
      "    epoch          : 752\n",
      "    loss           : -927.6464572849117\n",
      "    val_loss       : -655.5731518337118\n",
      "    val_log_likelihood: 1209.0328243940858\n",
      "    val_log_marginal: 693.9197758062837\n",
      "Train Epoch: 753 [512/17352 (3%)] Loss: -908.908752\n",
      "Train Epoch: 753 [10045/17352 (58%)] Loss: -891.533874\n",
      "Train Epoch: 753 [17064/17352 (98%)] Loss: -892.721326\n",
      "    epoch          : 753\n",
      "    loss           : -859.8147360955363\n",
      "    val_loss       : -682.3794680110861\n",
      "    val_log_likelihood: 1196.5321969052422\n",
      "    val_log_marginal: 716.5481870988204\n",
      "Train Epoch: 754 [512/17352 (3%)] Loss: -918.791748\n",
      "Train Epoch: 754 [10683/17352 (62%)] Loss: -1056.960612\n",
      "Train Epoch: 754 [17335/17352 (100%)] Loss: -687.389205\n",
      "    epoch          : 754\n",
      "    loss           : -904.3201744988446\n",
      "    val_loss       : -649.6650392011547\n",
      "    val_log_likelihood: 1208.9027581878684\n",
      "    val_log_marginal: 677.5741755622895\n",
      "Train Epoch: 755 [512/17352 (3%)] Loss: -870.679260\n",
      "Train Epoch: 755 [10691/17352 (62%)] Loss: -845.744493\n",
      "Train Epoch: 755 [17335/17352 (100%)] Loss: -882.884164\n",
      "    epoch          : 755\n",
      "    loss           : -912.9080747155001\n",
      "    val_loss       : -702.1202774907044\n",
      "    val_log_likelihood: 1233.0413726108127\n",
      "    val_log_marginal: 725.6099260036195\n",
      "Train Epoch: 756 [512/17352 (3%)] Loss: -945.364441\n",
      "Train Epoch: 756 [10451/17352 (60%)] Loss: -1033.353913\n",
      "Train Epoch: 756 [17124/17352 (99%)] Loss: -1040.839084\n",
      "    epoch          : 756\n",
      "    loss           : -929.0761627714131\n",
      "    val_loss       : -755.5952736019722\n",
      "    val_log_likelihood: 1249.9395643158655\n",
      "    val_log_marginal: 770.529034991736\n",
      "Train Epoch: 757 [512/17352 (3%)] Loss: -983.926392\n",
      "Train Epoch: 757 [10494/17352 (60%)] Loss: -983.193601\n",
      "Train Epoch: 757 [17124/17352 (99%)] Loss: -1010.856250\n",
      "    epoch          : 757\n",
      "    loss           : -935.9233828573923\n",
      "    val_loss       : -760.4103334049447\n",
      "    val_log_likelihood: 1247.0620942508042\n",
      "    val_log_marginal: 781.9711006785433\n",
      "Train Epoch: 758 [512/17352 (3%)] Loss: -992.727234\n",
      "Train Epoch: 758 [10054/17352 (58%)] Loss: -1041.776174\n",
      "Train Epoch: 758 [17064/17352 (98%)] Loss: -1022.682500\n",
      "    epoch          : 758\n",
      "    loss           : -959.6745194778186\n",
      "    val_loss       : -749.1355155369539\n",
      "    val_log_likelihood: 1250.6144190170544\n",
      "    val_log_marginal: 764.8463190944517\n",
      "Train Epoch: 759 [512/17352 (3%)] Loss: -979.748657\n",
      "Train Epoch: 759 [11018/17352 (63%)] Loss: -992.169011\n",
      "Train Epoch: 759 [16992/17352 (98%)] Loss: -618.068843\n",
      "    epoch          : 759\n",
      "    loss           : -923.1247061223997\n",
      "    val_loss       : -523.9421041982123\n",
      "    val_log_likelihood: 1250.8485526469926\n",
      "    val_log_marginal: 546.2949793227975\n",
      "Train Epoch: 760 [512/17352 (3%)] Loss: -739.666138\n",
      "Train Epoch: 760 [10333/17352 (60%)] Loss: -505.103027\n",
      "Train Epoch: 760 [16957/17352 (98%)] Loss: -746.594454\n",
      "    epoch          : 760\n",
      "    loss           : -718.5961419790082\n",
      "    val_loss       : -557.9452637749245\n",
      "    val_log_likelihood: 1180.2280317831248\n",
      "    val_log_marginal: 578.0398692008087\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch760.pth ...\n",
      "Train Epoch: 761 [512/17352 (3%)] Loss: -714.367676\n",
      "Train Epoch: 761 [10523/17352 (61%)] Loss: -986.831814\n",
      "Train Epoch: 761 [16883/17352 (97%)] Loss: -817.742532\n",
      "    epoch          : 761\n",
      "    loss           : -704.6216966924396\n",
      "    val_loss       : -625.6353430734268\n",
      "    val_log_likelihood: 1157.4198277813398\n",
      "    val_log_marginal: 646.4267930632437\n",
      "Train Epoch: 762 [512/17352 (3%)] Loss: -883.749329\n",
      "Train Epoch: 762 [10451/17352 (60%)] Loss: -436.761198\n",
      "Train Epoch: 762 [16957/17352 (98%)] Loss: -939.104215\n",
      "    epoch          : 762\n",
      "    loss           : -764.030624521325\n",
      "    val_loss       : -628.2499487264594\n",
      "    val_log_likelihood: 1162.6170556714642\n",
      "    val_log_marginal: 659.7027160640623\n",
      "Train Epoch: 763 [512/17352 (3%)] Loss: -896.237549\n",
      "Train Epoch: 763 [10619/17352 (61%)] Loss: -882.683454\n",
      "Train Epoch: 763 [16882/17352 (97%)] Loss: -756.828165\n",
      "    epoch          : 763\n",
      "    loss           : -829.4771496838953\n",
      "    val_loss       : -480.9133300038969\n",
      "    val_log_likelihood: 1194.9012580186782\n",
      "    val_log_marginal: 516.3904305591223\n",
      "Train Epoch: 764 [512/17352 (3%)] Loss: -548.350220\n",
      "Train Epoch: 764 [9939/17352 (57%)] Loss: -1015.924913\n",
      "Train Epoch: 764 [16957/17352 (98%)] Loss: -870.884606\n",
      "    epoch          : 764\n",
      "    loss           : -871.2658726309305\n",
      "    val_loss       : -709.1794026074211\n",
      "    val_log_likelihood: 1197.5603074303106\n",
      "    val_log_marginal: 723.300057613218\n",
      "Train Epoch: 765 [512/17352 (3%)] Loss: -969.154175\n",
      "Train Epoch: 765 [9954/17352 (57%)] Loss: -908.925264\n",
      "Train Epoch: 765 [16939/17352 (98%)] Loss: -799.097396\n",
      "    epoch          : 765\n",
      "    loss           : -902.5816877185252\n",
      "    val_loss       : -727.9810979493172\n",
      "    val_log_likelihood: 1201.9912268020205\n",
      "    val_log_marginal: 746.5764964286274\n",
      "Train Epoch: 766 [512/17352 (3%)] Loss: -952.881714\n",
      "Train Epoch: 766 [10584/17352 (61%)] Loss: -794.503140\n",
      "Train Epoch: 766 [17090/17352 (98%)] Loss: -996.111408\n",
      "    epoch          : 766\n",
      "    loss           : -904.8212552070091\n",
      "    val_loss       : -729.3964378025877\n",
      "    val_log_likelihood: 1224.8078171641773\n",
      "    val_log_marginal: 746.6996570375591\n",
      "Train Epoch: 767 [512/17352 (3%)] Loss: -931.318542\n",
      "Train Epoch: 767 [10438/17352 (60%)] Loss: -1014.287746\n",
      "Train Epoch: 767 [17277/17352 (100%)] Loss: -796.599736\n",
      "    epoch          : 767\n",
      "    loss           : -929.9064375766434\n",
      "    val_loss       : -708.4807533721313\n",
      "    val_log_likelihood: 1232.035479799461\n",
      "    val_log_marginal: 727.5299615389016\n",
      "Train Epoch: 768 [512/17352 (3%)] Loss: -946.075562\n",
      "Train Epoch: 768 [10452/17352 (60%)] Loss: -956.432278\n",
      "Train Epoch: 768 [16882/17352 (97%)] Loss: -678.494463\n",
      "    epoch          : 768\n",
      "    loss           : -899.6555324655135\n",
      "    val_loss       : -519.7857210370069\n",
      "    val_log_likelihood: 1232.5284036699663\n",
      "    val_log_marginal: 532.7825873818946\n",
      "Train Epoch: 769 [512/17352 (3%)] Loss: -703.677612\n",
      "Train Epoch: 769 [9955/17352 (57%)] Loss: -276.923603\n",
      "Train Epoch: 769 [17101/17352 (99%)] Loss: -152.621836\n",
      "    epoch          : 769\n",
      "    loss           : 43.10579830879963\n",
      "    val_loss       : 857.2082523355621\n",
      "    val_log_likelihood: 515.8868436345837\n",
      "    val_log_marginal: -670.1794953896446\n",
      "Train Epoch: 770 [512/17352 (3%)] Loss: 372.498871\n",
      "Train Epoch: 770 [9885/17352 (57%)] Loss: -552.765537\n",
      "Train Epoch: 770 [17106/17352 (99%)] Loss: -778.328063\n",
      "    epoch          : 770\n",
      "    loss           : -318.67490119624125\n",
      "    val_loss       : -569.1647000371825\n",
      "    val_log_likelihood: 1088.7873622736267\n",
      "    val_log_marginal: 627.1985273476253\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch770.pth ...\n",
      "Train Epoch: 771 [512/17352 (3%)] Loss: -745.754211\n",
      "Train Epoch: 771 [10791/17352 (62%)] Loss: -873.473887\n",
      "Train Epoch: 771 [16922/17352 (98%)] Loss: -928.167486\n",
      "    epoch          : 771\n",
      "    loss           : -820.5813063753416\n",
      "    val_loss       : -717.636556499577\n",
      "    val_log_likelihood: 1193.9432961019259\n",
      "    val_log_marginal: 759.7980301416104\n",
      "Train Epoch: 772 [512/17352 (3%)] Loss: -946.933838\n",
      "Train Epoch: 772 [10726/17352 (62%)] Loss: -844.427865\n",
      "Train Epoch: 772 [17124/17352 (99%)] Loss: -752.415384\n",
      "    epoch          : 772\n",
      "    loss           : -899.9621475311214\n",
      "    val_loss       : -728.178293338387\n",
      "    val_log_likelihood: 1217.5050170527957\n",
      "    val_log_marginal: 748.8477782267965\n",
      "Train Epoch: 773 [512/17352 (3%)] Loss: -939.856689\n",
      "Train Epoch: 773 [10474/17352 (60%)] Loss: -1036.729495\n",
      "Train Epoch: 773 [17106/17352 (99%)] Loss: -917.760280\n",
      "    epoch          : 773\n",
      "    loss           : -913.0237634308153\n",
      "    val_loss       : -751.6785494977441\n",
      "    val_log_likelihood: 1224.9769447777142\n",
      "    val_log_marginal: 779.0891522174835\n",
      "Train Epoch: 774 [512/17352 (3%)] Loss: -978.851807\n",
      "Train Epoch: 774 [10527/17352 (61%)] Loss: -927.267407\n",
      "Train Epoch: 774 [17253/17352 (99%)] Loss: -1005.693169\n",
      "    epoch          : 774\n",
      "    loss           : -933.5454309050984\n",
      "    val_loss       : -777.6116956652459\n",
      "    val_log_likelihood: 1234.8191073960893\n",
      "    val_log_marginal: 794.1744247932671\n",
      "Train Epoch: 775 [512/17352 (3%)] Loss: -985.919067\n",
      "Train Epoch: 775 [10617/17352 (61%)] Loss: -867.380011\n",
      "Train Epoch: 775 [17124/17352 (99%)] Loss: -1035.103877\n",
      "    epoch          : 775\n",
      "    loss           : -949.1521356861177\n",
      "    val_loss       : -773.8371216940379\n",
      "    val_log_likelihood: 1245.5095656198464\n",
      "    val_log_marginal: 787.2230495225401\n",
      "Train Epoch: 776 [512/17352 (3%)] Loss: -981.083008\n",
      "Train Epoch: 776 [10894/17352 (63%)] Loss: -1054.727149\n",
      "Train Epoch: 776 [17277/17352 (100%)] Loss: -924.890467\n",
      "    epoch          : 776\n",
      "    loss           : -940.2633413190117\n",
      "    val_loss       : -750.826638366168\n",
      "    val_log_likelihood: 1232.6523925223469\n",
      "    val_log_marginal: 765.4731515507622\n",
      "Train Epoch: 777 [512/17352 (3%)] Loss: -956.817444\n",
      "Train Epoch: 777 [10002/17352 (58%)] Loss: -1023.188897\n",
      "Train Epoch: 777 [16934/17352 (98%)] Loss: -977.322203\n",
      "    epoch          : 777\n",
      "    loss           : -908.4328077231654\n",
      "    val_loss       : -739.162245231874\n",
      "    val_log_likelihood: 1219.8614267010803\n",
      "    val_log_marginal: 755.1815394280708\n",
      "Train Epoch: 778 [512/17352 (3%)] Loss: -967.585815\n",
      "Train Epoch: 778 [10747/17352 (62%)] Loss: -907.091763\n",
      "Train Epoch: 778 [16957/17352 (98%)] Loss: -869.592160\n",
      "    epoch          : 778\n",
      "    loss           : -924.0442575002796\n",
      "    val_loss       : -725.1181155332869\n",
      "    val_log_likelihood: 1224.0206808040843\n",
      "    val_log_marginal: 739.6201512136976\n",
      "Train Epoch: 779 [512/17352 (3%)] Loss: -968.013550\n",
      "Train Epoch: 779 [9871/17352 (57%)] Loss: -864.661708\n",
      "Train Epoch: 779 [17153/17352 (99%)] Loss: -1022.093217\n",
      "    epoch          : 779\n",
      "    loss           : -924.1327942387805\n",
      "    val_loss       : -755.9786308036123\n",
      "    val_log_likelihood: 1236.9180494907778\n",
      "    val_log_marginal: 776.3393355775024\n",
      "Train Epoch: 780 [512/17352 (3%)] Loss: -968.724243\n",
      "Train Epoch: 780 [9889/17352 (57%)] Loss: -1061.207097\n",
      "Train Epoch: 780 [16988/17352 (98%)] Loss: -1069.146050\n",
      "    epoch          : 780\n",
      "    loss           : -942.6153171075421\n",
      "    val_loss       : -769.7586422818024\n",
      "    val_log_likelihood: 1244.906321766407\n",
      "    val_log_marginal: 782.9205437170631\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch780.pth ...\n",
      "Train Epoch: 781 [512/17352 (3%)] Loss: -983.472107\n",
      "Train Epoch: 781 [10369/17352 (60%)] Loss: -1000.228172\n",
      "Train Epoch: 781 [17016/17352 (98%)] Loss: -1044.511472\n",
      "    epoch          : 781\n",
      "    loss           : -960.196663239951\n",
      "    val_loss       : -774.0572330218649\n",
      "    val_log_likelihood: 1253.805444994064\n",
      "    val_log_marginal: 790.9428959320361\n",
      "Train Epoch: 782 [512/17352 (3%)] Loss: -996.373840\n",
      "Train Epoch: 782 [10599/17352 (61%)] Loss: -1095.694119\n",
      "Train Epoch: 782 [17049/17352 (98%)] Loss: -992.354956\n",
      "    epoch          : 782\n",
      "    loss           : -958.6887741085003\n",
      "    val_loss       : -761.5523349388877\n",
      "    val_log_likelihood: 1255.1604956553365\n",
      "    val_log_marginal: 779.5722827105668\n",
      "Train Epoch: 783 [512/17352 (3%)] Loss: -1003.405396\n",
      "Train Epoch: 783 [10581/17352 (61%)] Loss: -993.837251\n",
      "Train Epoch: 783 [16883/17352 (97%)] Loss: -903.468750\n",
      "    epoch          : 783\n",
      "    loss           : -958.3713812274518\n",
      "    val_loss       : -777.5961105691724\n",
      "    val_log_likelihood: 1258.7936132886466\n",
      "    val_log_marginal: 793.169757328382\n",
      "Train Epoch: 784 [512/17352 (3%)] Loss: -817.783997\n",
      "Train Epoch: 784 [10111/17352 (58%)] Loss: -867.168212\n",
      "Train Epoch: 784 [16992/17352 (98%)] Loss: -1042.153323\n",
      "    epoch          : 784\n",
      "    loss           : -957.0033902537164\n",
      "    val_loss       : -760.8308701959561\n",
      "    val_log_likelihood: 1243.1677951142115\n",
      "    val_log_marginal: 779.0708771175841\n",
      "Train Epoch: 785 [512/17352 (3%)] Loss: -1007.915100\n",
      "Train Epoch: 785 [9887/17352 (57%)] Loss: -980.903139\n",
      "Train Epoch: 785 [16923/17352 (98%)] Loss: -821.781405\n",
      "    epoch          : 785\n",
      "    loss           : -950.8813609201359\n",
      "    val_loss       : -756.0357527561629\n",
      "    val_log_likelihood: 1257.075664655714\n",
      "    val_log_marginal: 772.5837344031108\n",
      "Train Epoch: 786 [512/17352 (3%)] Loss: -968.442627\n",
      "Train Epoch: 786 [9897/17352 (57%)] Loss: -862.675072\n",
      "Train Epoch: 786 [17108/17352 (99%)] Loss: -833.729550\n",
      "    epoch          : 786\n",
      "    loss           : -953.7988160784928\n",
      "    val_loss       : -763.2671519333451\n",
      "    val_log_likelihood: 1253.605246850592\n",
      "    val_log_marginal: 780.4914729554723\n",
      "Train Epoch: 787 [512/17352 (3%)] Loss: -1002.248901\n",
      "Train Epoch: 787 [9965/17352 (57%)] Loss: -1070.183181\n",
      "Train Epoch: 787 [16883/17352 (97%)] Loss: -991.028516\n",
      "    epoch          : 787\n",
      "    loss           : -943.1934259738538\n",
      "    val_loss       : -660.1707884067424\n",
      "    val_log_likelihood: 1253.048267729841\n",
      "    val_log_marginal: 781.4068477426897\n",
      "Train Epoch: 788 [512/17352 (3%)] Loss: -1005.964478\n",
      "Train Epoch: 788 [10394/17352 (60%)] Loss: -850.789583\n",
      "Train Epoch: 788 [17143/17352 (99%)] Loss: -897.002107\n",
      "    epoch          : 788\n",
      "    loss           : -865.8796203904695\n",
      "    val_loss       : -579.2554148168438\n",
      "    val_log_likelihood: 1141.7739638190199\n",
      "    val_log_marginal: 614.0750349016786\n",
      "Train Epoch: 789 [512/17352 (3%)] Loss: -791.332520\n",
      "Train Epoch: 789 [10847/17352 (63%)] Loss: -944.347483\n",
      "Train Epoch: 789 [17106/17352 (99%)] Loss: -792.225962\n",
      "    epoch          : 789\n",
      "    loss           : -871.4821423866385\n",
      "    val_loss       : -729.505118695063\n",
      "    val_log_likelihood: 1216.4114540921814\n",
      "    val_log_marginal: 754.7714607114945\n",
      "Train Epoch: 790 [512/17352 (3%)] Loss: -967.414917\n",
      "Train Epoch: 790 [10321/17352 (59%)] Loss: -764.225103\n",
      "Train Epoch: 790 [17044/17352 (98%)] Loss: -980.439299\n",
      "    epoch          : 790\n",
      "    loss           : -856.8523051355465\n",
      "    val_loss       : -669.9373607803647\n",
      "    val_log_likelihood: 1195.3410424348294\n",
      "    val_log_marginal: 712.011205591886\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch790.pth ...\n",
      "Train Epoch: 791 [512/17352 (3%)] Loss: -899.317078\n",
      "Train Epoch: 791 [10347/17352 (60%)] Loss: -1046.398456\n",
      "Train Epoch: 791 [17101/17352 (99%)] Loss: -951.596583\n",
      "    epoch          : 791\n",
      "    loss           : -913.058426772451\n",
      "    val_loss       : -718.2428784573907\n",
      "    val_log_likelihood: 1225.9813190315356\n",
      "    val_log_marginal: 753.4111400706304\n",
      "Train Epoch: 792 [512/17352 (3%)] Loss: -985.155396\n",
      "Train Epoch: 792 [10410/17352 (60%)] Loss: -890.659040\n",
      "Train Epoch: 792 [17253/17352 (99%)] Loss: -940.314904\n",
      "    epoch          : 792\n",
      "    loss           : -949.4416103577997\n",
      "    val_loss       : -743.2801896418475\n",
      "    val_log_likelihood: 1242.2772151946058\n",
      "    val_log_marginal: 768.997408488682\n",
      "Train Epoch: 793 [512/17352 (3%)] Loss: -1003.592529\n",
      "Train Epoch: 793 [10721/17352 (62%)] Loss: -894.427734\n",
      "Train Epoch: 793 [16934/17352 (98%)] Loss: -990.306445\n",
      "    epoch          : 793\n",
      "    loss           : -955.7223855181998\n",
      "    val_loss       : -755.5726997125468\n",
      "    val_log_likelihood: 1251.6893217243307\n",
      "    val_log_marginal: 774.8943151882316\n",
      "Train Epoch: 794 [512/17352 (3%)] Loss: -1009.310791\n",
      "Train Epoch: 794 [10314/17352 (59%)] Loss: -1002.472261\n",
      "Train Epoch: 794 [16887/17352 (97%)] Loss: -873.061080\n",
      "    epoch          : 794\n",
      "    loss           : -961.3995251214311\n",
      "    val_loss       : -759.3324949200922\n",
      "    val_log_likelihood: 1263.0274641305916\n",
      "    val_log_marginal: 780.123458370086\n",
      "Train Epoch: 795 [512/17352 (3%)] Loss: -1013.439575\n",
      "Train Epoch: 795 [9883/17352 (57%)] Loss: -998.153511\n",
      "Train Epoch: 795 [17106/17352 (99%)] Loss: -877.487317\n",
      "    epoch          : 795\n",
      "    loss           : -961.2894004949696\n",
      "    val_loss       : -761.094383698341\n",
      "    val_log_likelihood: 1258.3822081863132\n",
      "    val_log_marginal: 783.995489792094\n",
      "Train Epoch: 796 [512/17352 (3%)] Loss: -982.918091\n",
      "Train Epoch: 796 [9896/17352 (57%)] Loss: -998.801508\n",
      "Train Epoch: 796 [17106/17352 (99%)] Loss: -934.132984\n",
      "    epoch          : 796\n",
      "    loss           : -956.0259873643258\n",
      "    val_loss       : -752.8048756089391\n",
      "    val_log_likelihood: 1264.681715251778\n",
      "    val_log_marginal: 772.8101099517731\n",
      "Train Epoch: 797 [512/17352 (3%)] Loss: -985.841797\n",
      "Train Epoch: 797 [10358/17352 (60%)] Loss: -838.971380\n",
      "Train Epoch: 797 [16934/17352 (98%)] Loss: -931.638775\n",
      "    epoch          : 797\n",
      "    loss           : -969.2368318423314\n",
      "    val_loss       : -772.0970430898159\n",
      "    val_log_likelihood: 1269.8806784351953\n",
      "    val_log_marginal: 791.4395332384554\n",
      "Train Epoch: 798 [512/17352 (3%)] Loss: -1018.356873\n",
      "Train Epoch: 798 [10360/17352 (60%)] Loss: -943.163651\n",
      "Train Epoch: 798 [17277/17352 (100%)] Loss: -995.480239\n",
      "    epoch          : 798\n",
      "    loss           : -972.3954864612856\n",
      "    val_loss       : -759.2392037141694\n",
      "    val_log_likelihood: 1269.7609218680977\n",
      "    val_log_marginal: 774.9424912804129\n",
      "Train Epoch: 799 [512/17352 (3%)] Loss: -1003.920959\n",
      "Train Epoch: 799 [10268/17352 (59%)] Loss: -902.611218\n",
      "Train Epoch: 799 [17064/17352 (98%)] Loss: -967.150884\n",
      "    epoch          : 799\n",
      "    loss           : -949.9555137548051\n",
      "    val_loss       : -735.4885476855233\n",
      "    val_log_likelihood: 1249.1191196224124\n",
      "    val_log_marginal: 764.3455490085223\n",
      "Train Epoch: 800 [512/17352 (3%)] Loss: -991.536804\n",
      "Train Epoch: 800 [10416/17352 (60%)] Loss: -860.386848\n",
      "Train Epoch: 800 [17090/17352 (98%)] Loss: -810.229961\n",
      "    epoch          : 800\n",
      "    loss           : -920.9588016459546\n",
      "    val_loss       : -691.866699824843\n",
      "    val_log_likelihood: 1201.3304803751926\n",
      "    val_log_marginal: 712.308099082786\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch800.pth ...\n",
      "Train Epoch: 801 [512/17352 (3%)] Loss: -878.035645\n",
      "Train Epoch: 801 [10029/17352 (58%)] Loss: -934.456107\n",
      "Train Epoch: 801 [17016/17352 (98%)] Loss: -1044.602539\n",
      "    epoch          : 801\n",
      "    loss           : -889.3885619242311\n",
      "    val_loss       : -694.9157274589179\n",
      "    val_log_likelihood: 1225.8252680831827\n",
      "    val_log_marginal: 728.5151013867446\n",
      "Train Epoch: 802 [512/17352 (3%)] Loss: -943.510315\n",
      "Train Epoch: 802 [10557/17352 (61%)] Loss: -969.544430\n",
      "Train Epoch: 802 [16923/17352 (98%)] Loss: -1055.816667\n",
      "    epoch          : 802\n",
      "    loss           : -933.6140150539351\n",
      "    val_loss       : -750.071244789191\n",
      "    val_log_likelihood: 1230.2119232600955\n",
      "    val_log_marginal: 769.513790502469\n",
      "Train Epoch: 803 [512/17352 (3%)] Loss: -977.685303\n",
      "Train Epoch: 803 [10409/17352 (60%)] Loss: -1027.049062\n",
      "Train Epoch: 803 [17126/17352 (99%)] Loss: -892.403432\n",
      "    epoch          : 803\n",
      "    loss           : -965.9650220862734\n",
      "    val_loss       : -771.1937142616326\n",
      "    val_log_likelihood: 1264.3251284821738\n",
      "    val_log_marginal: 789.419067242688\n",
      "Train Epoch: 804 [512/17352 (3%)] Loss: -1032.289307\n",
      "Train Epoch: 804 [10745/17352 (62%)] Loss: -1066.794443\n",
      "Train Epoch: 804 [17143/17352 (99%)] Loss: -1023.576947\n",
      "    epoch          : 804\n",
      "    loss           : -978.8763991039787\n",
      "    val_loss       : -774.1528566847397\n",
      "    val_log_likelihood: 1275.0982395469507\n",
      "    val_log_marginal: 787.2943785938753\n",
      "Train Epoch: 805 [512/17352 (3%)] Loss: -1030.150513\n",
      "Train Epoch: 805 [10515/17352 (61%)] Loss: -1032.499607\n",
      "Train Epoch: 805 [16957/17352 (98%)] Loss: -940.083607\n",
      "    epoch          : 805\n",
      "    loss           : -965.4431348206324\n",
      "    val_loss       : -771.8458352028781\n",
      "    val_log_likelihood: 1266.1175268197512\n",
      "    val_log_marginal: 790.149281716541\n",
      "Train Epoch: 806 [512/17352 (3%)] Loss: -1005.987122\n",
      "Train Epoch: 806 [10264/17352 (59%)] Loss: -1042.959688\n",
      "Train Epoch: 806 [16992/17352 (98%)] Loss: -996.250000\n",
      "    epoch          : 806\n",
      "    loss           : -956.6620750436482\n",
      "    val_loss       : -737.3138217798602\n",
      "    val_log_likelihood: 1229.34554433722\n",
      "    val_log_marginal: 748.8907653165726\n",
      "Train Epoch: 807 [512/17352 (3%)] Loss: -977.600830\n",
      "Train Epoch: 807 [10391/17352 (60%)] Loss: -816.369871\n",
      "Train Epoch: 807 [17277/17352 (100%)] Loss: -792.474938\n",
      "    epoch          : 807\n",
      "    loss           : -930.4360689371728\n",
      "    val_loss       : -730.2983767730755\n",
      "    val_log_likelihood: 1248.1827610362934\n",
      "    val_log_marginal: 759.6037424540472\n",
      "Train Epoch: 808 [512/17352 (3%)] Loss: -990.459900\n",
      "Train Epoch: 808 [10126/17352 (58%)] Loss: -1034.068471\n",
      "Train Epoch: 808 [16939/17352 (98%)] Loss: -978.323763\n",
      "    epoch          : 808\n",
      "    loss           : -950.0282494971492\n",
      "    val_loss       : -697.4245333969095\n",
      "    val_log_likelihood: 1260.3126427969146\n",
      "    val_log_marginal: 716.4396379840513\n",
      "Train Epoch: 809 [512/17352 (3%)] Loss: -936.585938\n",
      "Train Epoch: 809 [10158/17352 (59%)] Loss: -829.598048\n",
      "Train Epoch: 809 [16992/17352 (98%)] Loss: -1015.644708\n",
      "    epoch          : 809\n",
      "    loss           : -909.5605742170497\n",
      "    val_loss       : -751.3517208985191\n",
      "    val_log_likelihood: 1250.7543587656771\n",
      "    val_log_marginal: 772.7409267755204\n",
      "Train Epoch: 810 [512/17352 (3%)] Loss: -1016.607727\n",
      "Train Epoch: 810 [10334/17352 (60%)] Loss: -951.381579\n",
      "Train Epoch: 810 [16988/17352 (98%)] Loss: -678.177931\n",
      "    epoch          : 810\n",
      "    loss           : -927.6558764043162\n",
      "    val_loss       : -713.6456362652913\n",
      "    val_log_likelihood: 1243.363335590375\n",
      "    val_log_marginal: 738.3606834430245\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch810.pth ...\n",
      "Train Epoch: 811 [512/17352 (3%)] Loss: -942.727539\n",
      "Train Epoch: 811 [10589/17352 (61%)] Loss: -866.952110\n",
      "Train Epoch: 811 [16988/17352 (98%)] Loss: -1014.508681\n",
      "    epoch          : 811\n",
      "    loss           : -930.8986347488222\n",
      "    val_loss       : -707.3008847354956\n",
      "    val_log_likelihood: 1229.4108860940692\n",
      "    val_log_marginal: 729.9586692894098\n",
      "Train Epoch: 812 [512/17352 (3%)] Loss: -947.428101\n",
      "Train Epoch: 812 [10591/17352 (61%)] Loss: -1082.238313\n",
      "Train Epoch: 812 [16939/17352 (98%)] Loss: -838.703429\n",
      "    epoch          : 812\n",
      "    loss           : -941.0984253547778\n",
      "    val_loss       : -735.4582052406688\n",
      "    val_log_likelihood: 1260.9771207486228\n",
      "    val_log_marginal: 772.3010326679827\n",
      "Train Epoch: 813 [512/17352 (3%)] Loss: -998.468201\n",
      "Train Epoch: 813 [10103/17352 (58%)] Loss: -893.150834\n",
      "Train Epoch: 813 [16878/17352 (97%)] Loss: -971.361784\n",
      "    epoch          : 813\n",
      "    loss           : -917.3969774797831\n",
      "    val_loss       : -692.2176186184448\n",
      "    val_log_likelihood: 1215.0465167955313\n",
      "    val_log_marginal: 713.8007108173322\n",
      "Train Epoch: 814 [512/17352 (3%)] Loss: -968.031616\n",
      "Train Epoch: 814 [10783/17352 (62%)] Loss: -846.202808\n",
      "Train Epoch: 814 [17016/17352 (98%)] Loss: -788.104441\n",
      "    epoch          : 814\n",
      "    loss           : -867.8368780130725\n",
      "    val_loss       : -616.0691816993348\n",
      "    val_log_likelihood: 1144.7522266154097\n",
      "    val_log_marginal: 649.5399571749663\n",
      "Train Epoch: 815 [512/17352 (3%)] Loss: -800.892090\n",
      "Train Epoch: 815 [10573/17352 (61%)] Loss: -814.817599\n",
      "Train Epoch: 815 [16872/17352 (97%)] Loss: -874.109119\n",
      "    epoch          : 815\n",
      "    loss           : -895.328387026057\n",
      "    val_loss       : -747.1137022474092\n",
      "    val_log_likelihood: 1235.0307147949343\n",
      "    val_log_marginal: 766.7586885046511\n",
      "Train Epoch: 816 [512/17352 (3%)] Loss: -1012.063477\n",
      "Train Epoch: 816 [10074/17352 (58%)] Loss: -924.540296\n",
      "Train Epoch: 816 [16988/17352 (98%)] Loss: -946.104084\n",
      "    epoch          : 816\n",
      "    loss           : -953.6138659491019\n",
      "    val_loss       : -760.2971891235222\n",
      "    val_log_likelihood: 1262.9857090833027\n",
      "    val_log_marginal: 781.2388084862613\n",
      "Train Epoch: 817 [512/17352 (3%)] Loss: -1005.144897\n",
      "Train Epoch: 817 [10248/17352 (59%)] Loss: -973.218908\n",
      "Train Epoch: 817 [17044/17352 (98%)] Loss: -878.131404\n",
      "    epoch          : 817\n",
      "    loss           : -954.4254055848585\n",
      "    val_loss       : -734.8999444190479\n",
      "    val_log_likelihood: 1249.4794123511454\n",
      "    val_log_marginal: 760.875790707799\n",
      "Train Epoch: 818 [512/17352 (3%)] Loss: -992.447998\n",
      "Train Epoch: 818 [10993/17352 (63%)] Loss: -1040.965260\n",
      "Train Epoch: 818 [17277/17352 (100%)] Loss: -1048.282580\n",
      "    epoch          : 818\n",
      "    loss           : -956.623195290211\n",
      "    val_loss       : -708.2683318189036\n",
      "    val_log_likelihood: 1229.8565924750087\n",
      "    val_log_marginal: 727.6837908205365\n",
      "Train Epoch: 819 [512/17352 (3%)] Loss: -975.330200\n",
      "Train Epoch: 819 [10471/17352 (60%)] Loss: -868.663102\n",
      "Train Epoch: 819 [16958/17352 (98%)] Loss: -897.133224\n",
      "    epoch          : 819\n",
      "    loss           : -950.1078225102945\n",
      "    val_loss       : -747.4144289550942\n",
      "    val_log_likelihood: 1243.9097057311164\n",
      "    val_log_marginal: 762.3321357371987\n",
      "Train Epoch: 820 [512/17352 (3%)] Loss: -992.214966\n",
      "Train Epoch: 820 [10020/17352 (58%)] Loss: -1030.155384\n",
      "Train Epoch: 820 [16922/17352 (98%)] Loss: -1013.566709\n",
      "    epoch          : 820\n",
      "    loss           : -935.2110678025545\n",
      "    val_loss       : -765.2289816420276\n",
      "    val_log_likelihood: 1263.376828407278\n",
      "    val_log_marginal: 782.7618627286721\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch820.pth ...\n",
      "Train Epoch: 821 [512/17352 (3%)] Loss: -1026.618530\n",
      "Train Epoch: 821 [10744/17352 (62%)] Loss: -994.323074\n",
      "Train Epoch: 821 [16992/17352 (98%)] Loss: -935.756716\n",
      "    epoch          : 821\n",
      "    loss           : -977.8419497700859\n",
      "    val_loss       : -741.3393920936727\n",
      "    val_log_likelihood: 1255.2831634497957\n",
      "    val_log_marginal: 761.6733420787824\n",
      "Train Epoch: 822 [512/17352 (3%)] Loss: -1016.488586\n",
      "Train Epoch: 822 [9774/17352 (56%)] Loss: -986.059595\n",
      "Train Epoch: 822 [17126/17352 (99%)] Loss: -958.454059\n",
      "    epoch          : 822\n",
      "    loss           : -970.8743035038218\n",
      "    val_loss       : -761.1741642657032\n",
      "    val_log_likelihood: 1265.4511282805124\n",
      "    val_log_marginal: 780.405031844572\n",
      "Train Epoch: 823 [512/17352 (3%)] Loss: -993.301758\n",
      "Train Epoch: 823 [10009/17352 (58%)] Loss: -901.746926\n",
      "Train Epoch: 823 [17124/17352 (99%)] Loss: -1080.908217\n",
      "    epoch          : 823\n",
      "    loss           : -958.6532611968003\n",
      "    val_loss       : -732.5247187480397\n",
      "    val_log_likelihood: 1261.341228855568\n",
      "    val_log_marginal: 754.639816495076\n",
      "Train Epoch: 824 [512/17352 (3%)] Loss: -1002.793274\n",
      "Train Epoch: 824 [10251/17352 (59%)] Loss: -910.073864\n",
      "Train Epoch: 824 [16958/17352 (98%)] Loss: -1070.066184\n",
      "    epoch          : 824\n",
      "    loss           : -930.3898114099817\n",
      "    val_loss       : -725.2289116720433\n",
      "    val_log_likelihood: 1247.0351195095088\n",
      "    val_log_marginal: 751.4194675243344\n",
      "Train Epoch: 825 [512/17352 (3%)] Loss: -973.964966\n",
      "Train Epoch: 825 [10605/17352 (61%)] Loss: -1100.635200\n",
      "Train Epoch: 825 [17253/17352 (99%)] Loss: -995.240044\n",
      "    epoch          : 825\n",
      "    loss           : -927.6499492791571\n",
      "    val_loss       : -691.4451012583067\n",
      "    val_log_likelihood: 1243.725859495446\n",
      "    val_log_marginal: 727.1312312022952\n",
      "Train Epoch: 826 [512/17352 (3%)] Loss: -767.425110\n",
      "Train Epoch: 826 [9832/17352 (57%)] Loss: -980.518193\n",
      "Train Epoch: 826 [17335/17352 (100%)] Loss: -1051.639459\n",
      "    epoch          : 826\n",
      "    loss           : -948.7010765395361\n",
      "    val_loss       : -699.4766158883943\n",
      "    val_log_likelihood: 1246.3327505991242\n",
      "    val_log_marginal: 721.9758928955018\n",
      "Train Epoch: 827 [512/17352 (3%)] Loss: -742.846802\n",
      "Train Epoch: 827 [9834/17352 (57%)] Loss: -1018.638663\n",
      "Train Epoch: 827 [17049/17352 (98%)] Loss: -773.112550\n",
      "    epoch          : 827\n",
      "    loss           : -900.1444294177091\n",
      "    val_loss       : -654.8752948263924\n",
      "    val_log_likelihood: 1211.7446484873865\n",
      "    val_log_marginal: 677.6076454456921\n",
      "Train Epoch: 828 [512/17352 (3%)] Loss: -913.869141\n",
      "Train Epoch: 828 [10278/17352 (59%)] Loss: -1001.315698\n",
      "Train Epoch: 828 [17106/17352 (99%)] Loss: -1022.313630\n",
      "    epoch          : 828\n",
      "    loss           : -895.5996906213227\n",
      "    val_loss       : -716.8820778559179\n",
      "    val_log_likelihood: 1242.3885848486873\n",
      "    val_log_marginal: 740.4699234436042\n",
      "Train Epoch: 829 [512/17352 (3%)] Loss: -979.290405\n",
      "Train Epoch: 829 [10158/17352 (59%)] Loss: -1023.532567\n",
      "Train Epoch: 829 [17153/17352 (99%)] Loss: -1071.192231\n",
      "    epoch          : 829\n",
      "    loss           : -951.435711118132\n",
      "    val_loss       : -735.0695397027744\n",
      "    val_log_likelihood: 1251.4689946139006\n",
      "    val_log_marginal: 755.9253435862263\n",
      "Train Epoch: 830 [512/17352 (3%)] Loss: -1002.138367\n",
      "Train Epoch: 830 [10573/17352 (61%)] Loss: -940.421939\n",
      "Train Epoch: 830 [17106/17352 (99%)] Loss: -961.858823\n",
      "    epoch          : 830\n",
      "    loss           : -963.5338427732592\n",
      "    val_loss       : -739.8037168105881\n",
      "    val_log_likelihood: 1271.4730981047833\n",
      "    val_log_marginal: 758.9746460792047\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch830.pth ...\n",
      "Train Epoch: 831 [512/17352 (3%)] Loss: -985.580322\n",
      "Train Epoch: 831 [10551/17352 (61%)] Loss: -1008.422093\n",
      "Train Epoch: 831 [17101/17352 (99%)] Loss: -1049.359583\n",
      "    epoch          : 831\n",
      "    loss           : -965.8213348878913\n",
      "    val_loss       : -760.6374658303943\n",
      "    val_log_likelihood: 1273.1800690247592\n",
      "    val_log_marginal: 776.6091500818108\n",
      "Train Epoch: 832 [512/17352 (3%)] Loss: -1031.284302\n",
      "Train Epoch: 832 [10141/17352 (58%)] Loss: -1030.700075\n",
      "Train Epoch: 832 [17263/17352 (99%)] Loss: -751.856384\n",
      "    epoch          : 832\n",
      "    loss           : -952.6196982225584\n",
      "    val_loss       : -605.8618520252315\n",
      "    val_log_likelihood: 1253.3394833573072\n",
      "    val_log_marginal: 626.7939682533895\n",
      "Train Epoch: 833 [512/17352 (3%)] Loss: -681.736694\n",
      "Train Epoch: 833 [10169/17352 (59%)] Loss: -916.068685\n",
      "Train Epoch: 833 [16923/17352 (98%)] Loss: -892.231306\n",
      "    epoch          : 833\n",
      "    loss           : -912.9673000290705\n",
      "    val_loss       : -760.5656110276949\n",
      "    val_log_likelihood: 1267.29054801266\n",
      "    val_log_marginal: 776.714399866285\n",
      "Train Epoch: 834 [512/17352 (3%)] Loss: -989.389404\n",
      "Train Epoch: 834 [9939/17352 (57%)] Loss: -1027.125999\n",
      "Train Epoch: 834 [17016/17352 (98%)] Loss: -907.381944\n",
      "    epoch          : 834\n",
      "    loss           : -955.3516933850805\n",
      "    val_loss       : -732.005034360126\n",
      "    val_log_likelihood: 1257.9994726604848\n",
      "    val_log_marginal: 751.1394375620321\n",
      "Train Epoch: 835 [512/17352 (3%)] Loss: -974.971924\n",
      "Train Epoch: 835 [10242/17352 (59%)] Loss: -773.696770\n",
      "Train Epoch: 835 [16883/17352 (97%)] Loss: -923.145393\n",
      "    epoch          : 835\n",
      "    loss           : -952.2742749807903\n",
      "    val_loss       : -751.9983495721597\n",
      "    val_log_likelihood: 1268.9668850914757\n",
      "    val_log_marginal: 769.9711382621483\n",
      "Train Epoch: 836 [512/17352 (3%)] Loss: -1028.256348\n",
      "Train Epoch: 836 [10230/17352 (59%)] Loss: -936.180392\n",
      "Train Epoch: 836 [17106/17352 (99%)] Loss: -1030.573235\n",
      "    epoch          : 836\n",
      "    loss           : -979.6626940867463\n",
      "    val_loss       : -756.5926075253708\n",
      "    val_log_likelihood: 1277.1915445473082\n",
      "    val_log_marginal: 777.5635144574537\n",
      "Train Epoch: 837 [512/17352 (3%)] Loss: -1013.838501\n",
      "Train Epoch: 837 [10503/17352 (61%)] Loss: -1058.632729\n",
      "Train Epoch: 837 [17253/17352 (99%)] Loss: -866.497674\n",
      "    epoch          : 837\n",
      "    loss           : -950.9521442520033\n",
      "    val_loss       : -303.5147870543411\n",
      "    val_log_likelihood: 1245.782508936535\n",
      "    val_log_marginal: 320.4250716667736\n",
      "Train Epoch: 838 [512/17352 (3%)] Loss: -596.489319\n",
      "Train Epoch: 838 [9999/17352 (58%)] Loss: -758.059766\n",
      "Train Epoch: 838 [17263/17352 (99%)] Loss: -775.665912\n",
      "    epoch          : 838\n",
      "    loss           : -735.1570682405542\n",
      "    val_loss       : 472.6351311063162\n",
      "    val_log_likelihood: 1158.3975438593611\n",
      "    val_log_marginal: -414.296528056681\n",
      "Train Epoch: 839 [512/17352 (3%)] Loss: 136.284805\n",
      "Train Epoch: 839 [10150/17352 (58%)] Loss: -601.797752\n",
      "Train Epoch: 839 [16882/17352 (97%)] Loss: -605.078562\n",
      "    epoch          : 839\n",
      "    loss           : -778.3805716122961\n",
      "    val_loss       : -699.6604104698733\n",
      "    val_log_likelihood: 1223.6269814367745\n",
      "    val_log_marginal: 741.2731058430326\n",
      "Train Epoch: 840 [512/17352 (3%)] Loss: -988.105957\n",
      "Train Epoch: 840 [10524/17352 (61%)] Loss: -715.661932\n",
      "Train Epoch: 840 [17090/17352 (98%)] Loss: -965.833935\n",
      "    epoch          : 840\n",
      "    loss           : -907.501729802652\n",
      "    val_loss       : -713.0063375803823\n",
      "    val_log_likelihood: 1221.0374580793866\n",
      "    val_log_marginal: 734.3990599006836\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch840.pth ...\n",
      "Train Epoch: 841 [512/17352 (3%)] Loss: -953.296997\n",
      "Train Epoch: 841 [9997/17352 (58%)] Loss: -957.718908\n",
      "Train Epoch: 841 [17108/17352 (99%)] Loss: -1001.465172\n",
      "    epoch          : 841\n",
      "    loss           : -942.9900215212523\n",
      "    val_loss       : -775.4370481188871\n",
      "    val_log_likelihood: 1269.5983288946827\n",
      "    val_log_marginal: 796.9416462298122\n",
      "Train Epoch: 842 [512/17352 (3%)] Loss: -1019.636292\n",
      "Train Epoch: 842 [10370/17352 (60%)] Loss: -848.027536\n",
      "Train Epoch: 842 [17064/17352 (98%)] Loss: -742.740814\n",
      "    epoch          : 842\n",
      "    loss           : -888.5228393072737\n",
      "    val_loss       : -504.4386319096837\n",
      "    val_log_likelihood: 1152.679133893452\n",
      "    val_log_marginal: 634.8953121115691\n",
      "Train Epoch: 843 [512/17352 (3%)] Loss: -671.069031\n",
      "Train Epoch: 843 [10451/17352 (60%)] Loss: -884.218372\n",
      "Train Epoch: 843 [16988/17352 (98%)] Loss: -968.358305\n",
      "    epoch          : 843\n",
      "    loss           : -787.4671853176552\n",
      "    val_loss       : -635.9027601177454\n",
      "    val_log_likelihood: 1150.8464928863752\n",
      "    val_log_marginal: 676.7752192708484\n",
      "Train Epoch: 844 [512/17352 (3%)] Loss: -868.712280\n",
      "Train Epoch: 844 [10105/17352 (58%)] Loss: -676.881579\n",
      "Train Epoch: 844 [16883/17352 (97%)] Loss: -799.739438\n",
      "    epoch          : 844\n",
      "    loss           : -911.6350134657177\n",
      "    val_loss       : -741.9710827760402\n",
      "    val_log_likelihood: 1238.4359950643357\n",
      "    val_log_marginal: 769.2450306487973\n",
      "Train Epoch: 845 [512/17352 (3%)] Loss: -983.038452\n",
      "Train Epoch: 845 [10492/17352 (60%)] Loss: -896.030159\n",
      "Train Epoch: 845 [17016/17352 (98%)] Loss: -972.831834\n",
      "    epoch          : 845\n",
      "    loss           : -918.676260940117\n",
      "    val_loss       : -747.9504223501671\n",
      "    val_log_likelihood: 1246.7866690471928\n",
      "    val_log_marginal: 775.5885379314333\n",
      "Train Epoch: 846 [512/17352 (3%)] Loss: -793.217407\n",
      "Train Epoch: 846 [10543/17352 (61%)] Loss: -1017.984947\n",
      "Train Epoch: 846 [16934/17352 (98%)] Loss: -957.158178\n",
      "    epoch          : 846\n",
      "    loss           : -922.1373377346005\n",
      "    val_loss       : -719.4761265160254\n",
      "    val_log_likelihood: 1260.3406808249342\n",
      "    val_log_marginal: 738.15001133558\n",
      "Train Epoch: 847 [512/17352 (3%)] Loss: -969.782593\n",
      "Train Epoch: 847 [10699/17352 (62%)] Loss: -1013.918205\n",
      "Train Epoch: 847 [16988/17352 (98%)] Loss: -853.381119\n",
      "    epoch          : 847\n",
      "    loss           : -935.0871201164063\n",
      "    val_loss       : -756.2878321029417\n",
      "    val_log_likelihood: 1263.3807707501223\n",
      "    val_log_marginal: 776.722985014919\n",
      "Train Epoch: 848 [512/17352 (3%)] Loss: -990.669922\n",
      "Train Epoch: 848 [10723/17352 (62%)] Loss: -1066.064366\n",
      "Train Epoch: 848 [17049/17352 (98%)] Loss: -1068.359715\n",
      "    epoch          : 848\n",
      "    loss           : -976.1657348596312\n",
      "    val_loss       : -738.8668463834675\n",
      "    val_log_likelihood: 1275.553499853865\n",
      "    val_log_marginal: 760.6846718176793\n",
      "Train Epoch: 849 [512/17352 (3%)] Loss: -988.364868\n",
      "Train Epoch: 849 [10090/17352 (58%)] Loss: -801.333824\n",
      "Train Epoch: 849 [17016/17352 (98%)] Loss: -768.025718\n",
      "    epoch          : 849\n",
      "    loss           : -930.7513753860861\n",
      "    val_loss       : -734.8420225373022\n",
      "    val_log_likelihood: 1258.7224824104992\n",
      "    val_log_marginal: 752.9328478585983\n",
      "Train Epoch: 850 [512/17352 (3%)] Loss: -976.570374\n",
      "Train Epoch: 850 [9980/17352 (58%)] Loss: -960.169202\n",
      "Train Epoch: 850 [16878/17352 (97%)] Loss: -1088.738045\n",
      "    epoch          : 850\n",
      "    loss           : -964.9797738324811\n",
      "    val_loss       : -767.8643383239398\n",
      "    val_log_likelihood: 1272.8699196591872\n",
      "    val_log_marginal: 783.8219372012481\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch850.pth ...\n",
      "Train Epoch: 851 [512/17352 (3%)] Loss: -1023.780029\n",
      "Train Epoch: 851 [10057/17352 (58%)] Loss: -926.283043\n",
      "Train Epoch: 851 [16878/17352 (97%)] Loss: -1049.460660\n",
      "    epoch          : 851\n",
      "    loss           : -977.4275624016409\n",
      "    val_loss       : -770.0155008463121\n",
      "    val_log_likelihood: 1284.192547005765\n",
      "    val_log_marginal: 791.0991260839179\n",
      "Train Epoch: 852 [512/17352 (3%)] Loss: -1020.030640\n",
      "Train Epoch: 852 [9985/17352 (58%)] Loss: -1046.631441\n",
      "Train Epoch: 852 [16882/17352 (97%)] Loss: -995.283291\n",
      "    epoch          : 852\n",
      "    loss           : -977.6469604278807\n",
      "    val_loss       : -760.6504926518223\n",
      "    val_log_likelihood: 1287.9143681747316\n",
      "    val_log_marginal: 781.5398799048021\n",
      "Train Epoch: 853 [512/17352 (3%)] Loss: -1030.649658\n",
      "Train Epoch: 853 [9784/17352 (56%)] Loss: -609.326466\n",
      "Train Epoch: 853 [16923/17352 (98%)] Loss: -1006.346655\n",
      "    epoch          : 853\n",
      "    loss           : -939.280788015547\n",
      "    val_loss       : -768.5567484986285\n",
      "    val_log_likelihood: 1280.0777590080734\n",
      "    val_log_marginal: 785.3016743715687\n",
      "Train Epoch: 854 [512/17352 (3%)] Loss: -1027.827637\n",
      "Train Epoch: 854 [10221/17352 (59%)] Loss: -1083.412980\n",
      "Train Epoch: 854 [17143/17352 (99%)] Loss: -941.606079\n",
      "    epoch          : 854\n",
      "    loss           : -981.941749289061\n",
      "    val_loss       : -777.487522783826\n",
      "    val_log_likelihood: 1287.65423503049\n",
      "    val_log_marginal: 796.5331474054198\n",
      "Train Epoch: 855 [512/17352 (3%)] Loss: -1023.947571\n",
      "Train Epoch: 855 [9896/17352 (57%)] Loss: -1075.119792\n",
      "Train Epoch: 855 [17253/17352 (99%)] Loss: -1057.282043\n",
      "    epoch          : 855\n",
      "    loss           : -979.6932671772719\n",
      "    val_loss       : -696.739009061387\n",
      "    val_log_likelihood: 1281.2599640104404\n",
      "    val_log_marginal: 713.7926009860221\n",
      "Train Epoch: 856 [512/17352 (3%)] Loss: -968.702332\n",
      "Train Epoch: 856 [10273/17352 (59%)] Loss: -1070.355310\n",
      "Train Epoch: 856 [16923/17352 (98%)] Loss: -1042.165240\n",
      "    epoch          : 856\n",
      "    loss           : -956.3314815200908\n",
      "    val_loss       : -729.9744038474113\n",
      "    val_log_likelihood: 1264.3436501097362\n",
      "    val_log_marginal: 757.1876071796783\n",
      "Train Epoch: 857 [512/17352 (3%)] Loss: -943.819336\n",
      "Train Epoch: 857 [10400/17352 (60%)] Loss: -668.905610\n",
      "Train Epoch: 857 [17124/17352 (99%)] Loss: -738.681370\n",
      "    epoch          : 857\n",
      "    loss           : -930.0711855588364\n",
      "    val_loss       : -707.9026852427805\n",
      "    val_log_likelihood: 1245.1908668701628\n",
      "    val_log_marginal: 734.3757363853208\n",
      "Train Epoch: 858 [512/17352 (3%)] Loss: -974.124390\n",
      "Train Epoch: 858 [10674/17352 (62%)] Loss: -712.310460\n",
      "Train Epoch: 858 [16887/17352 (97%)] Loss: -802.915819\n",
      "    epoch          : 858\n",
      "    loss           : -815.6568463800868\n",
      "    val_loss       : -693.2109630211834\n",
      "    val_log_likelihood: 1216.449252281487\n",
      "    val_log_marginal: 730.7469348647761\n",
      "Train Epoch: 859 [512/17352 (3%)] Loss: -978.537109\n",
      "Train Epoch: 859 [10036/17352 (58%)] Loss: -829.760603\n",
      "Train Epoch: 859 [16957/17352 (98%)] Loss: -1063.825203\n",
      "    epoch          : 859\n",
      "    loss           : -913.7986020865692\n",
      "    val_loss       : -710.0822249547306\n",
      "    val_log_likelihood: 1224.1749358387729\n",
      "    val_log_marginal: 731.9728477968758\n",
      "Train Epoch: 860 [512/17352 (3%)] Loss: -870.595337\n",
      "Train Epoch: 860 [9927/17352 (57%)] Loss: -753.695948\n",
      "Train Epoch: 860 [17049/17352 (98%)] Loss: -987.669304\n",
      "    epoch          : 860\n",
      "    loss           : -888.7016582834088\n",
      "    val_loss       : -643.9045171592682\n",
      "    val_log_likelihood: 1237.9715014416067\n",
      "    val_log_marginal: 673.9026466615418\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch860.pth ...\n",
      "Train Epoch: 861 [512/17352 (3%)] Loss: -879.382263\n",
      "Train Epoch: 861 [10041/17352 (58%)] Loss: -948.500631\n",
      "Train Epoch: 861 [16883/17352 (97%)] Loss: -1099.159831\n",
      "    epoch          : 861\n",
      "    loss           : -911.3639306657856\n",
      "    val_loss       : -745.537514978279\n",
      "    val_log_likelihood: 1263.3978047753901\n",
      "    val_log_marginal: 780.6305810489639\n",
      "Train Epoch: 862 [512/17352 (3%)] Loss: -998.104980\n",
      "Train Epoch: 862 [10475/17352 (60%)] Loss: -947.816964\n",
      "Train Epoch: 862 [17277/17352 (100%)] Loss: -781.510282\n",
      "    epoch          : 862\n",
      "    loss           : -950.419271818566\n",
      "    val_loss       : -716.9972401635146\n",
      "    val_log_likelihood: 1242.0936996611554\n",
      "    val_log_marginal: 741.1318894299224\n",
      "Train Epoch: 863 [512/17352 (3%)] Loss: -962.749573\n",
      "Train Epoch: 863 [10189/17352 (59%)] Loss: -1083.734840\n",
      "Train Epoch: 863 [17253/17352 (99%)] Loss: -849.462995\n",
      "    epoch          : 863\n",
      "    loss           : -966.9929682781981\n",
      "    val_loss       : -718.6020019422762\n",
      "    val_log_likelihood: 1267.7638340980693\n",
      "    val_log_marginal: 737.7680074974775\n",
      "Train Epoch: 864 [512/17352 (3%)] Loss: -974.212219\n",
      "Train Epoch: 864 [10609/17352 (61%)] Loss: -1051.207725\n",
      "Train Epoch: 864 [16872/17352 (97%)] Loss: -894.557465\n",
      "    epoch          : 864\n",
      "    loss           : -905.1896244684671\n",
      "    val_loss       : -710.6205735551723\n",
      "    val_log_likelihood: 1256.8744146183071\n",
      "    val_log_marginal: 734.9425442427456\n",
      "Train Epoch: 865 [512/17352 (3%)] Loss: -986.640991\n",
      "Train Epoch: 865 [10712/17352 (62%)] Loss: -1002.594585\n",
      "Train Epoch: 865 [16934/17352 (98%)] Loss: -919.928314\n",
      "    epoch          : 865\n",
      "    loss           : -885.0604069407344\n",
      "    val_loss       : -726.4524156050916\n",
      "    val_log_likelihood: 1268.103249550006\n",
      "    val_log_marginal: 752.5500652205479\n",
      "Train Epoch: 866 [512/17352 (3%)] Loss: -997.304077\n",
      "Train Epoch: 866 [9609/17352 (55%)] Loss: -1041.483105\n",
      "Train Epoch: 866 [16957/17352 (98%)] Loss: -1017.604309\n",
      "    epoch          : 866\n",
      "    loss           : -931.8154819055724\n",
      "    val_loss       : -749.54651821337\n",
      "    val_log_likelihood: 1262.7164905614457\n",
      "    val_log_marginal: 771.9741861262622\n",
      "Train Epoch: 867 [512/17352 (3%)] Loss: -1014.244812\n",
      "Train Epoch: 867 [11057/17352 (64%)] Loss: -824.898454\n",
      "Train Epoch: 867 [16883/17352 (97%)] Loss: -872.076836\n",
      "    epoch          : 867\n",
      "    loss           : -980.8991465922553\n",
      "    val_loss       : -767.2975980556945\n",
      "    val_log_likelihood: 1284.3118263468439\n",
      "    val_log_marginal: 789.573747604602\n",
      "Train Epoch: 868 [512/17352 (3%)] Loss: -1022.519043\n",
      "Train Epoch: 868 [10580/17352 (61%)] Loss: -865.496941\n",
      "Train Epoch: 868 [16939/17352 (98%)] Loss: -923.837661\n",
      "    epoch          : 868\n",
      "    loss           : -968.4948983021073\n",
      "    val_loss       : -779.2409734215937\n",
      "    val_log_likelihood: 1279.118900912928\n",
      "    val_log_marginal: 800.8354722211577\n",
      "Train Epoch: 869 [512/17352 (3%)] Loss: -1031.793335\n",
      "Train Epoch: 869 [10029/17352 (58%)] Loss: -1037.683777\n",
      "Train Epoch: 869 [17133/17352 (99%)] Loss: -1005.303038\n",
      "    epoch          : 869\n",
      "    loss           : -973.2758373442427\n",
      "    val_loss       : -727.9376903439709\n",
      "    val_log_likelihood: 1267.4007948431572\n",
      "    val_log_marginal: 751.3324068747079\n",
      "Train Epoch: 870 [512/17352 (3%)] Loss: -1000.661743\n",
      "Train Epoch: 870 [10274/17352 (59%)] Loss: -1030.416090\n",
      "Train Epoch: 870 [16939/17352 (98%)] Loss: -1065.246135\n",
      "    epoch          : 870\n",
      "    loss           : -950.907932611083\n",
      "    val_loss       : -737.4683926235084\n",
      "    val_log_likelihood: 1264.4348220766387\n",
      "    val_log_marginal: 763.6089209974999\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch870.pth ...\n",
      "Train Epoch: 871 [512/17352 (3%)] Loss: -1010.575439\n",
      "Train Epoch: 871 [10399/17352 (60%)] Loss: -1028.191942\n",
      "Train Epoch: 871 [16923/17352 (98%)] Loss: -892.453509\n",
      "    epoch          : 871\n",
      "    loss           : -945.6270146678592\n",
      "    val_loss       : -750.2987867289743\n",
      "    val_log_likelihood: 1269.6001138957017\n",
      "    val_log_marginal: 771.3021781294576\n",
      "Train Epoch: 872 [512/17352 (3%)] Loss: -998.606079\n",
      "Train Epoch: 872 [10666/17352 (61%)] Loss: -1013.242295\n",
      "Train Epoch: 872 [17124/17352 (99%)] Loss: -1033.449263\n",
      "    epoch          : 872\n",
      "    loss           : -963.6699977604404\n",
      "    val_loss       : -757.3360962420394\n",
      "    val_log_likelihood: 1277.3658128667528\n",
      "    val_log_marginal: 775.3470414410518\n",
      "Train Epoch: 873 [512/17352 (3%)] Loss: -1014.957520\n",
      "Train Epoch: 873 [10742/17352 (62%)] Loss: -1093.713697\n",
      "Train Epoch: 873 [17153/17352 (99%)] Loss: -1081.918275\n",
      "    epoch          : 873\n",
      "    loss           : -986.2948600686558\n",
      "    val_loss       : -760.7423762326729\n",
      "    val_log_likelihood: 1283.4883131192332\n",
      "    val_log_marginal: 778.8851418185415\n",
      "Train Epoch: 874 [512/17352 (3%)] Loss: -1030.087524\n",
      "Train Epoch: 874 [9844/17352 (57%)] Loss: -968.993845\n",
      "Train Epoch: 874 [16887/17352 (97%)] Loss: -1052.419937\n",
      "    epoch          : 874\n",
      "    loss           : -968.0193271494805\n",
      "    val_loss       : -757.9366690932966\n",
      "    val_log_likelihood: 1286.075251313028\n",
      "    val_log_marginal: 777.9570440967482\n",
      "Train Epoch: 875 [512/17352 (3%)] Loss: -1043.291870\n",
      "Train Epoch: 875 [10367/17352 (60%)] Loss: -912.791735\n",
      "Train Epoch: 875 [16923/17352 (98%)] Loss: -327.340433\n",
      "    epoch          : 875\n",
      "    loss           : -744.337156601424\n",
      "    val_loss       : -440.7409973129471\n",
      "    val_log_likelihood: 1212.3821790731731\n",
      "    val_log_marginal: 461.3295422414376\n",
      "Train Epoch: 876 [512/17352 (3%)] Loss: -723.449951\n",
      "Train Epoch: 876 [10528/17352 (61%)] Loss: -73.111889\n",
      "Train Epoch: 876 [17090/17352 (98%)] Loss: -890.154584\n",
      "    epoch          : 876\n",
      "    loss           : -512.0222725678077\n",
      "    val_loss       : -518.4165713313196\n",
      "    val_log_likelihood: 1138.927150369652\n",
      "    val_log_marginal: 579.359246234341\n",
      "Train Epoch: 877 [512/17352 (3%)] Loss: -829.701050\n",
      "Train Epoch: 877 [10348/17352 (60%)] Loss: -530.044185\n",
      "Train Epoch: 877 [17277/17352 (100%)] Loss: -813.182819\n",
      "    epoch          : 877\n",
      "    loss           : -795.2414927984747\n",
      "    val_loss       : -665.4067517044587\n",
      "    val_log_likelihood: 1192.708210224785\n",
      "    val_log_marginal: 709.110702244381\n",
      "Train Epoch: 878 [512/17352 (3%)] Loss: -931.153687\n",
      "Train Epoch: 878 [10316/17352 (59%)] Loss: -985.167369\n",
      "Train Epoch: 878 [17153/17352 (99%)] Loss: -855.882610\n",
      "    epoch          : 878\n",
      "    loss           : -920.8596694319764\n",
      "    val_loss       : -738.6040894618169\n",
      "    val_log_likelihood: 1248.4225243748974\n",
      "    val_log_marginal: 761.8749426849987\n",
      "Train Epoch: 879 [512/17352 (3%)] Loss: -1001.086609\n",
      "Train Epoch: 879 [9867/17352 (57%)] Loss: -863.691220\n",
      "Train Epoch: 879 [17090/17352 (98%)] Loss: -876.605188\n",
      "    epoch          : 879\n",
      "    loss           : -967.2643653831777\n",
      "    val_loss       : -762.8198804641596\n",
      "    val_log_likelihood: 1273.471738825938\n",
      "    val_log_marginal: 785.1548758853285\n",
      "Train Epoch: 880 [512/17352 (3%)] Loss: -1027.008545\n",
      "Train Epoch: 880 [10114/17352 (58%)] Loss: -910.843077\n",
      "Train Epoch: 880 [17106/17352 (99%)] Loss: -1018.560459\n",
      "    epoch          : 880\n",
      "    loss           : -981.5547588003466\n",
      "    val_loss       : -765.7374852028724\n",
      "    val_log_likelihood: 1280.2704209304334\n",
      "    val_log_marginal: 784.3203869220828\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch880.pth ...\n",
      "Train Epoch: 881 [512/17352 (3%)] Loss: -849.780029\n",
      "Train Epoch: 881 [10470/17352 (60%)] Loss: -897.251623\n",
      "Train Epoch: 881 [17143/17352 (99%)] Loss: -815.874072\n",
      "    epoch          : 881\n",
      "    loss           : -972.087038622486\n",
      "    val_loss       : -711.3628305173693\n",
      "    val_log_likelihood: 1268.040178674959\n",
      "    val_log_marginal: 734.9182175569418\n",
      "Train Epoch: 882 [512/17352 (3%)] Loss: -802.310974\n",
      "Train Epoch: 882 [10288/17352 (59%)] Loss: -984.764691\n",
      "Train Epoch: 882 [16923/17352 (98%)] Loss: -553.079053\n",
      "    epoch          : 882\n",
      "    loss           : -868.1960884773912\n",
      "    val_loss       : -357.31776368611855\n",
      "    val_log_likelihood: 1222.8198583577962\n",
      "    val_log_marginal: 378.51879418306305\n",
      "Train Epoch: 883 [512/17352 (3%)] Loss: -648.990967\n",
      "Train Epoch: 883 [10397/17352 (60%)] Loss: -680.551358\n",
      "Train Epoch: 883 [16872/17352 (97%)] Loss: -840.287052\n",
      "    epoch          : 883\n",
      "    loss           : -801.5994066700515\n",
      "    val_loss       : -708.5696017844036\n",
      "    val_log_likelihood: 1234.8616321074164\n",
      "    val_log_marginal: 733.7105992093774\n",
      "Train Epoch: 884 [512/17352 (3%)] Loss: -968.374146\n",
      "Train Epoch: 884 [10364/17352 (60%)] Loss: -942.102769\n",
      "Train Epoch: 884 [16878/17352 (97%)] Loss: -858.472611\n",
      "    epoch          : 884\n",
      "    loss           : -921.7452006394764\n",
      "    val_loss       : -749.3464610022936\n",
      "    val_log_likelihood: 1268.8685294861025\n",
      "    val_log_marginal: 774.7817955480609\n",
      "Train Epoch: 885 [512/17352 (3%)] Loss: -1012.747375\n",
      "Train Epoch: 885 [10358/17352 (60%)] Loss: -1017.193493\n",
      "Train Epoch: 885 [16882/17352 (97%)] Loss: -871.209059\n",
      "    epoch          : 885\n",
      "    loss           : -941.1929709894135\n",
      "    val_loss       : -693.1331089942174\n",
      "    val_log_likelihood: 1261.5730095454649\n",
      "    val_log_marginal: 717.7525308171951\n",
      "Train Epoch: 886 [512/17352 (3%)] Loss: -987.948486\n",
      "Train Epoch: 886 [10080/17352 (58%)] Loss: -658.174821\n",
      "Train Epoch: 886 [17044/17352 (98%)] Loss: -880.838685\n",
      "    epoch          : 886\n",
      "    loss           : -868.4995782536344\n",
      "    val_loss       : -560.3843996003689\n",
      "    val_log_likelihood: 1248.0828329867431\n",
      "    val_log_marginal: 581.0638826898776\n",
      "Train Epoch: 887 [512/17352 (3%)] Loss: -739.364014\n",
      "Train Epoch: 887 [11010/17352 (63%)] Loss: -713.752554\n",
      "Train Epoch: 887 [17143/17352 (99%)] Loss: -905.040326\n",
      "    epoch          : 887\n",
      "    loss           : -815.4599123127801\n",
      "    val_loss       : -679.9131770567079\n",
      "    val_log_likelihood: 1236.2314128197706\n",
      "    val_log_marginal: 709.4513993213454\n",
      "Train Epoch: 888 [512/17352 (3%)] Loss: -884.108337\n",
      "Train Epoch: 888 [10698/17352 (62%)] Loss: -1008.320768\n",
      "Train Epoch: 888 [17090/17352 (98%)] Loss: -584.680914\n",
      "    epoch          : 888\n",
      "    loss           : -909.7203687243718\n",
      "    val_loss       : -446.1882980879176\n",
      "    val_log_likelihood: 1249.2133411305035\n",
      "    val_log_marginal: 504.6737202567088\n",
      "Train Epoch: 889 [512/17352 (3%)] Loss: -726.670532\n",
      "Train Epoch: 889 [10050/17352 (58%)] Loss: -906.942138\n",
      "Train Epoch: 889 [16992/17352 (98%)] Loss: -1053.052660\n",
      "    epoch          : 889\n",
      "    loss           : -902.0437523157955\n",
      "    val_loss       : -724.4249309610113\n",
      "    val_log_likelihood: 1248.8347908719652\n",
      "    val_log_marginal: 741.8272660076321\n",
      "Train Epoch: 890 [512/17352 (3%)] Loss: -931.113403\n",
      "Train Epoch: 890 [10250/17352 (59%)] Loss: -995.846195\n",
      "Train Epoch: 890 [16923/17352 (98%)] Loss: -992.047124\n",
      "    epoch          : 890\n",
      "    loss           : -937.0578956108874\n",
      "    val_loss       : -766.8591189995988\n",
      "    val_log_likelihood: 1267.4707857445446\n",
      "    val_log_marginal: 787.6484521419536\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch890.pth ...\n",
      "Train Epoch: 891 [512/17352 (3%)] Loss: -1008.692688\n",
      "Train Epoch: 891 [10472/17352 (60%)] Loss: -932.343091\n",
      "Train Epoch: 891 [17090/17352 (98%)] Loss: -898.688140\n",
      "    epoch          : 891\n",
      "    loss           : -969.7806855987712\n",
      "    val_loss       : -767.8146032099683\n",
      "    val_log_likelihood: 1280.7191327708708\n",
      "    val_log_marginal: 784.9404629006358\n",
      "Train Epoch: 892 [512/17352 (3%)] Loss: -1027.676880\n",
      "Train Epoch: 892 [10446/17352 (60%)] Loss: -1026.279938\n",
      "Train Epoch: 892 [17108/17352 (99%)] Loss: -1032.724339\n",
      "    epoch          : 892\n",
      "    loss           : -968.7065576885333\n",
      "    val_loss       : -753.109241397822\n",
      "    val_log_likelihood: 1278.900457939069\n",
      "    val_log_marginal: 775.7582811549987\n",
      "Train Epoch: 893 [512/17352 (3%)] Loss: -1020.581299\n",
      "Train Epoch: 893 [10643/17352 (61%)] Loss: -1090.998476\n",
      "Train Epoch: 893 [17064/17352 (98%)] Loss: -1033.831667\n",
      "    epoch          : 893\n",
      "    loss           : -966.9904252031871\n",
      "    val_loss       : -729.5967648619186\n",
      "    val_log_likelihood: 1275.7188434575444\n",
      "    val_log_marginal: 747.3490142944081\n",
      "Train Epoch: 894 [512/17352 (3%)] Loss: -999.816467\n",
      "Train Epoch: 894 [10224/17352 (59%)] Loss: -904.645800\n",
      "Train Epoch: 894 [17335/17352 (100%)] Loss: -1030.775525\n",
      "    epoch          : 894\n",
      "    loss           : -963.3876772107096\n",
      "    val_loss       : -579.370562324882\n",
      "    val_log_likelihood: 1260.1197707902318\n",
      "    val_log_marginal: 596.5516213570584\n",
      "Train Epoch: 895 [512/17352 (3%)] Loss: -815.639709\n",
      "Train Epoch: 895 [10095/17352 (58%)] Loss: -845.145852\n",
      "Train Epoch: 895 [16922/17352 (98%)] Loss: -1043.503557\n",
      "    epoch          : 895\n",
      "    loss           : -957.8901347343458\n",
      "    val_loss       : -764.5938843640721\n",
      "    val_log_likelihood: 1289.5791431799887\n",
      "    val_log_marginal: 784.61394026825\n",
      "Train Epoch: 896 [512/17352 (3%)] Loss: -1021.123169\n",
      "Train Epoch: 896 [10039/17352 (58%)] Loss: -1113.826044\n",
      "Train Epoch: 896 [17263/17352 (99%)] Loss: -1012.402141\n",
      "    epoch          : 896\n",
      "    loss           : -988.4414878392627\n",
      "    val_loss       : -770.5719343557248\n",
      "    val_log_likelihood: 1290.7208428425645\n",
      "    val_log_marginal: 785.4565799838315\n",
      "Train Epoch: 897 [512/17352 (3%)] Loss: -1047.067871\n",
      "Train Epoch: 897 [9933/17352 (57%)] Loss: -1061.280460\n",
      "Train Epoch: 897 [17253/17352 (99%)] Loss: -1052.881424\n",
      "    epoch          : 897\n",
      "    loss           : -981.0086042204833\n",
      "    val_loss       : -704.9680152927809\n",
      "    val_log_likelihood: 1277.367348887419\n",
      "    val_log_marginal: 731.3259556152923\n",
      "Train Epoch: 898 [512/17352 (3%)] Loss: -966.997070\n",
      "Train Epoch: 898 [10351/17352 (60%)] Loss: -1076.008777\n",
      "Train Epoch: 898 [16883/17352 (97%)] Loss: -1058.526163\n",
      "    epoch          : 898\n",
      "    loss           : -944.7835223599186\n",
      "    val_loss       : -760.4240450135774\n",
      "    val_log_likelihood: 1275.0018709503481\n",
      "    val_log_marginal: 780.1485577369558\n",
      "Train Epoch: 899 [512/17352 (3%)] Loss: -1036.634277\n",
      "Train Epoch: 899 [10291/17352 (59%)] Loss: -903.280667\n",
      "Train Epoch: 899 [17106/17352 (99%)] Loss: -1124.185981\n",
      "    epoch          : 899\n",
      "    loss           : -971.2342304126053\n",
      "    val_loss       : -687.5390064187966\n",
      "    val_log_likelihood: 1280.3139300583098\n",
      "    val_log_marginal: 706.7429857785437\n",
      "Train Epoch: 900 [512/17352 (3%)] Loss: -943.230225\n",
      "Train Epoch: 900 [10641/17352 (61%)] Loss: -752.092540\n",
      "Train Epoch: 900 [17126/17352 (99%)] Loss: -911.500897\n",
      "    epoch          : 900\n",
      "    loss           : -925.9989319260817\n",
      "    val_loss       : -709.7693580669675\n",
      "    val_log_likelihood: 1256.5735939628353\n",
      "    val_log_marginal: 730.4528351416558\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch900.pth ...\n",
      "Train Epoch: 901 [512/17352 (3%)] Loss: -1011.878296\n",
      "Train Epoch: 901 [9983/17352 (58%)] Loss: -976.783169\n",
      "Train Epoch: 901 [17106/17352 (99%)] Loss: -353.098609\n",
      "    epoch          : 901\n",
      "    loss           : -865.4588018387715\n",
      "    val_loss       : -628.791543218431\n",
      "    val_log_likelihood: 1235.034231662029\n",
      "    val_log_marginal: 640.7102073030403\n",
      "Train Epoch: 902 [512/17352 (3%)] Loss: -933.626831\n",
      "Train Epoch: 902 [9582/17352 (55%)] Loss: -817.651639\n",
      "Train Epoch: 902 [17106/17352 (99%)] Loss: -896.689670\n",
      "    epoch          : 902\n",
      "    loss           : -858.5968968401938\n",
      "    val_loss       : -642.522126575318\n",
      "    val_log_likelihood: 1233.6495364189377\n",
      "    val_log_marginal: 692.6741357907284\n",
      "Train Epoch: 903 [512/17352 (3%)] Loss: -904.296692\n",
      "Train Epoch: 903 [10575/17352 (61%)] Loss: -1003.964705\n",
      "Train Epoch: 903 [16883/17352 (97%)] Loss: -1023.605696\n",
      "    epoch          : 903\n",
      "    loss           : -884.3180082041257\n",
      "    val_loss       : -700.1172498146099\n",
      "    val_log_likelihood: 1238.8430616985474\n",
      "    val_log_marginal: 726.7767242975212\n",
      "Train Epoch: 904 [512/17352 (3%)] Loss: -926.894104\n",
      "Train Epoch: 904 [10257/17352 (59%)] Loss: -1022.729063\n",
      "Train Epoch: 904 [17049/17352 (98%)] Loss: -998.825884\n",
      "    epoch          : 904\n",
      "    loss           : -960.0466921219187\n",
      "    val_loss       : -734.194576619128\n",
      "    val_log_likelihood: 1254.21507759859\n",
      "    val_log_marginal: 747.2127998427163\n",
      "Train Epoch: 905 [512/17352 (3%)] Loss: -998.636963\n",
      "Train Epoch: 905 [10494/17352 (60%)] Loss: -1068.981199\n",
      "Train Epoch: 905 [17124/17352 (99%)] Loss: -837.678103\n",
      "    epoch          : 905\n",
      "    loss           : -977.9057991691541\n",
      "    val_loss       : -752.4031519517782\n",
      "    val_log_likelihood: 1276.8913829665994\n",
      "    val_log_marginal: 773.2331211640239\n",
      "Train Epoch: 906 [512/17352 (3%)] Loss: -1015.441162\n",
      "Train Epoch: 906 [9941/17352 (57%)] Loss: -797.167337\n",
      "Train Epoch: 906 [16988/17352 (98%)] Loss: -887.420455\n",
      "    epoch          : 906\n",
      "    loss           : -974.8004699806977\n",
      "    val_loss       : -765.5601631652472\n",
      "    val_log_likelihood: 1284.9090726756228\n",
      "    val_log_marginal: 786.0590491457075\n",
      "Train Epoch: 907 [512/17352 (3%)] Loss: -1029.875244\n",
      "Train Epoch: 907 [10504/17352 (61%)] Loss: -917.312779\n",
      "Train Epoch: 907 [17049/17352 (98%)] Loss: -985.125158\n",
      "    epoch          : 907\n",
      "    loss           : -971.5161777183235\n",
      "    val_loss       : -760.854113227699\n",
      "    val_log_likelihood: 1286.6756345074073\n",
      "    val_log_marginal: 785.125488936824\n",
      "Train Epoch: 908 [512/17352 (3%)] Loss: -1022.980591\n",
      "Train Epoch: 908 [10821/17352 (62%)] Loss: -969.388158\n",
      "Train Epoch: 908 [17153/17352 (99%)] Loss: -836.074597\n",
      "    epoch          : 908\n",
      "    loss           : -998.486809190177\n",
      "    val_loss       : -738.0246072219238\n",
      "    val_log_likelihood: 1298.7833616089329\n",
      "    val_log_marginal: 781.626489743461\n",
      "Train Epoch: 909 [512/17352 (3%)] Loss: -1024.325562\n",
      "Train Epoch: 909 [10136/17352 (58%)] Loss: -845.619169\n",
      "Train Epoch: 909 [17016/17352 (98%)] Loss: -900.547643\n",
      "    epoch          : 909\n",
      "    loss           : -980.4517489522101\n",
      "    val_loss       : -748.3719316999338\n",
      "    val_log_likelihood: 1283.9534901244813\n",
      "    val_log_marginal: 775.0177642405288\n",
      "Train Epoch: 910 [512/17352 (3%)] Loss: -1037.687744\n",
      "Train Epoch: 910 [10393/17352 (60%)] Loss: -1051.302369\n",
      "Train Epoch: 910 [17335/17352 (100%)] Loss: -1131.748264\n",
      "    epoch          : 910\n",
      "    loss           : -980.2260378391824\n",
      "    val_loss       : -734.8679534885009\n",
      "    val_log_likelihood: 1268.7224845864894\n",
      "    val_log_marginal: 757.6896551716582\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch910.pth ...\n",
      "Train Epoch: 911 [512/17352 (3%)] Loss: -1021.719971\n",
      "Train Epoch: 911 [10377/17352 (60%)] Loss: -1134.535482\n",
      "Train Epoch: 911 [16957/17352 (98%)] Loss: -1027.151334\n",
      "    epoch          : 911\n",
      "    loss           : -989.9787389632661\n",
      "    val_loss       : -700.6586888466472\n",
      "    val_log_likelihood: 1243.537249468072\n",
      "    val_log_marginal: 730.18299613167\n",
      "Train Epoch: 912 [512/17352 (3%)] Loss: -1038.487305\n",
      "Train Epoch: 912 [10895/17352 (63%)] Loss: -898.193942\n",
      "Train Epoch: 912 [16883/17352 (97%)] Loss: -937.643827\n",
      "    epoch          : 912\n",
      "    loss           : -924.2960518753575\n",
      "    val_loss       : -691.9464870979571\n",
      "    val_log_likelihood: 1228.3595114973373\n",
      "    val_log_marginal: 715.3199620083464\n",
      "Train Epoch: 913 [512/17352 (3%)] Loss: -1028.167358\n",
      "Train Epoch: 913 [10361/17352 (60%)] Loss: -818.739982\n",
      "Train Epoch: 913 [16923/17352 (98%)] Loss: -956.167668\n",
      "    epoch          : 913\n",
      "    loss           : -976.029390754609\n",
      "    val_loss       : -764.109587313605\n",
      "    val_log_likelihood: 1282.5876982849045\n",
      "    val_log_marginal: 788.5888078980398\n",
      "Train Epoch: 914 [512/17352 (3%)] Loss: -1032.021729\n",
      "Train Epoch: 914 [10344/17352 (60%)] Loss: -999.671559\n",
      "Train Epoch: 914 [16883/17352 (97%)] Loss: -927.656624\n",
      "    epoch          : 914\n",
      "    loss           : -986.3286938259317\n",
      "    val_loss       : -771.5598682336133\n",
      "    val_log_likelihood: 1293.2459857881859\n",
      "    val_log_marginal: 792.1622650547952\n",
      "Train Epoch: 915 [512/17352 (3%)] Loss: -1052.399292\n",
      "Train Epoch: 915 [10405/17352 (60%)] Loss: -1089.397074\n",
      "Train Epoch: 915 [16883/17352 (97%)] Loss: -1147.959201\n",
      "    epoch          : 915\n",
      "    loss           : -1006.0070129814137\n",
      "    val_loss       : -787.1501998207135\n",
      "    val_log_likelihood: 1307.885037227648\n",
      "    val_log_marginal: 810.3070609274239\n",
      "Train Epoch: 916 [512/17352 (3%)] Loss: -883.567505\n",
      "Train Epoch: 916 [10032/17352 (58%)] Loss: -1088.710971\n",
      "Train Epoch: 916 [16992/17352 (98%)] Loss: -1072.665530\n",
      "    epoch          : 916\n",
      "    loss           : -996.2904164525078\n",
      "    val_loss       : -744.7810764267872\n",
      "    val_log_likelihood: 1298.1513530600414\n",
      "    val_log_marginal: 762.2390036424306\n",
      "Train Epoch: 917 [512/17352 (3%)] Loss: -1026.694458\n",
      "Train Epoch: 917 [10535/17352 (61%)] Loss: -994.569208\n",
      "Train Epoch: 917 [17106/17352 (99%)] Loss: -1043.138770\n",
      "    epoch          : 917\n",
      "    loss           : -954.9757998721802\n",
      "    val_loss       : -620.3864627111234\n",
      "    val_log_likelihood: 1223.90875457093\n",
      "    val_log_marginal: 643.6388555644867\n",
      "Train Epoch: 918 [512/17352 (3%)] Loss: -923.319336\n",
      "Train Epoch: 918 [10453/17352 (60%)] Loss: -1071.058919\n",
      "Train Epoch: 918 [17106/17352 (99%)] Loss: -898.896289\n",
      "    epoch          : 918\n",
      "    loss           : -794.6819743621388\n",
      "    val_loss       : 362.89432229225076\n",
      "    val_log_likelihood: 1169.1441184563744\n",
      "    val_log_marginal: -324.69425404350625\n",
      "Train Epoch: 919 [512/17352 (3%)] Loss: -230.235138\n",
      "Train Epoch: 919 [10104/17352 (58%)] Loss: -779.102603\n",
      "Train Epoch: 919 [16957/17352 (98%)] Loss: -183.778988\n",
      "    epoch          : 919\n",
      "    loss           : -146.13694853312492\n",
      "    val_loss       : -369.53184938351905\n",
      "    val_log_likelihood: 1048.4491576199055\n",
      "    val_log_marginal: 453.76802570889976\n",
      "Train Epoch: 920 [512/17352 (3%)] Loss: -581.858093\n",
      "Train Epoch: 920 [9787/17352 (56%)] Loss: -587.985647\n",
      "Train Epoch: 920 [16939/17352 (98%)] Loss: -917.653006\n",
      "    epoch          : 920\n",
      "    loss           : -695.1801672492425\n",
      "    val_loss       : -655.8091875308531\n",
      "    val_log_likelihood: 1192.316435822969\n",
      "    val_log_marginal: 710.948803084431\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch920.pth ...\n",
      "Train Epoch: 921 [512/17352 (3%)] Loss: -944.874512\n",
      "Train Epoch: 921 [10342/17352 (60%)] Loss: -879.488039\n",
      "Train Epoch: 921 [16872/17352 (97%)] Loss: -993.544858\n",
      "    epoch          : 921\n",
      "    loss           : -854.212831854762\n",
      "    val_loss       : -719.8660009008269\n",
      "    val_log_likelihood: 1240.856551484398\n",
      "    val_log_marginal: 743.8087551359064\n",
      "Train Epoch: 922 [512/17352 (3%)] Loss: -962.421692\n",
      "Train Epoch: 922 [9974/17352 (57%)] Loss: -872.984225\n",
      "Train Epoch: 922 [16887/17352 (97%)] Loss: -960.437917\n",
      "    epoch          : 922\n",
      "    loss           : -928.9782040019645\n",
      "    val_loss       : -748.2838466575199\n",
      "    val_log_likelihood: 1271.990711247777\n",
      "    val_log_marginal: 771.5811849693996\n",
      "Train Epoch: 923 [512/17352 (3%)] Loss: -996.777954\n",
      "Train Epoch: 923 [10076/17352 (58%)] Loss: -969.588411\n",
      "Train Epoch: 923 [16988/17352 (98%)] Loss: -1042.506530\n",
      "    epoch          : 923\n",
      "    loss           : -926.5999533099595\n",
      "    val_loss       : -739.9879300733601\n",
      "    val_log_likelihood: 1265.9594203751221\n",
      "    val_log_marginal: 772.9950326386581\n",
      "Train Epoch: 924 [512/17352 (3%)] Loss: -1007.334351\n",
      "Train Epoch: 924 [10453/17352 (60%)] Loss: -847.127976\n",
      "Train Epoch: 924 [16957/17352 (98%)] Loss: -1044.181749\n",
      "    epoch          : 924\n",
      "    loss           : -948.9623107533994\n",
      "    val_loss       : -699.0471043550193\n",
      "    val_log_likelihood: 1270.1116183665174\n",
      "    val_log_marginal: 723.2124679458523\n",
      "Train Epoch: 925 [512/17352 (3%)] Loss: -799.056641\n",
      "Train Epoch: 925 [10256/17352 (59%)] Loss: -863.785106\n",
      "Train Epoch: 925 [17016/17352 (98%)] Loss: -837.986961\n",
      "    epoch          : 925\n",
      "    loss           : -934.8505943422872\n",
      "    val_loss       : -746.3993283841571\n",
      "    val_log_likelihood: 1276.920006366108\n",
      "    val_log_marginal: 764.9891319901293\n",
      "Train Epoch: 926 [512/17352 (3%)] Loss: -813.683350\n",
      "Train Epoch: 926 [10561/17352 (61%)] Loss: -1063.416045\n",
      "Train Epoch: 926 [16988/17352 (98%)] Loss: -1056.899375\n",
      "    epoch          : 926\n",
      "    loss           : -965.2765882633587\n",
      "    val_loss       : -728.7868024611142\n",
      "    val_log_likelihood: 1271.1165788540216\n",
      "    val_log_marginal: 750.7771486033324\n",
      "Train Epoch: 927 [512/17352 (3%)] Loss: -815.723022\n",
      "Train Epoch: 927 [10385/17352 (60%)] Loss: -769.458199\n",
      "Train Epoch: 927 [17016/17352 (98%)] Loss: -869.692708\n",
      "    epoch          : 927\n",
      "    loss           : -939.6491703937745\n",
      "    val_loss       : -753.3424752662947\n",
      "    val_log_likelihood: 1274.3493120537923\n",
      "    val_log_marginal: 775.6335951868857\n",
      "Train Epoch: 928 [512/17352 (3%)] Loss: -1019.729004\n",
      "Train Epoch: 928 [10255/17352 (59%)] Loss: -885.402426\n",
      "Train Epoch: 928 [17277/17352 (100%)] Loss: -874.450392\n",
      "    epoch          : 928\n",
      "    loss           : -984.7084293981044\n",
      "    val_loss       : -758.5090640855617\n",
      "    val_log_likelihood: 1277.7672217026238\n",
      "    val_log_marginal: 781.5207906947741\n",
      "Train Epoch: 929 [512/17352 (3%)] Loss: -819.524231\n",
      "Train Epoch: 929 [10237/17352 (59%)] Loss: -945.457162\n",
      "Train Epoch: 929 [16992/17352 (98%)] Loss: -951.371394\n",
      "    epoch          : 929\n",
      "    loss           : -995.7704626740297\n",
      "    val_loss       : -770.851253756898\n",
      "    val_log_likelihood: 1294.408570616683\n",
      "    val_log_marginal: 785.4681366480303\n",
      "Train Epoch: 930 [512/17352 (3%)] Loss: -856.980042\n",
      "Train Epoch: 930 [10054/17352 (58%)] Loss: -1086.315506\n",
      "Train Epoch: 930 [16992/17352 (98%)] Loss: -932.984968\n",
      "    epoch          : 930\n",
      "    loss           : -990.5316890479893\n",
      "    val_loss       : -775.9249754025313\n",
      "    val_log_likelihood: 1295.61410007794\n",
      "    val_log_marginal: 796.9806007218186\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch930.pth ...\n",
      "Train Epoch: 931 [512/17352 (3%)] Loss: -1031.086060\n",
      "Train Epoch: 931 [10367/17352 (60%)] Loss: -976.512638\n",
      "Train Epoch: 931 [17090/17352 (98%)] Loss: -1078.859851\n",
      "    epoch          : 931\n",
      "    loss           : -1001.5952662184129\n",
      "    val_loss       : -780.0516198104738\n",
      "    val_log_likelihood: 1303.341708949016\n",
      "    val_log_marginal: 803.7556344300575\n",
      "Train Epoch: 932 [512/17352 (3%)] Loss: -1052.963623\n",
      "Train Epoch: 932 [9742/17352 (56%)] Loss: -1139.748915\n",
      "Train Epoch: 932 [16872/17352 (97%)] Loss: -1035.278277\n",
      "    epoch          : 932\n",
      "    loss           : -1007.0184134529969\n",
      "    val_loss       : -780.4726621216357\n",
      "    val_log_likelihood: 1306.9042540840542\n",
      "    val_log_marginal: 800.6262659136804\n",
      "Train Epoch: 933 [512/17352 (3%)] Loss: -1047.243896\n",
      "Train Epoch: 933 [10508/17352 (61%)] Loss: -864.353629\n",
      "Train Epoch: 933 [16878/17352 (97%)] Loss: -1096.455937\n",
      "    epoch          : 933\n",
      "    loss           : -1016.0006631515824\n",
      "    val_loss       : -789.7315592199384\n",
      "    val_log_likelihood: 1313.887840166693\n",
      "    val_log_marginal: 810.1332028564334\n",
      "Train Epoch: 934 [512/17352 (3%)] Loss: -1072.373779\n",
      "Train Epoch: 934 [10269/17352 (59%)] Loss: -1111.026719\n",
      "Train Epoch: 934 [16939/17352 (98%)] Loss: -949.904119\n",
      "    epoch          : 934\n",
      "    loss           : -1014.1940902772589\n",
      "    val_loss       : -774.1765599904093\n",
      "    val_log_likelihood: 1312.137272517377\n",
      "    val_log_marginal: 793.6736065451696\n",
      "Train Epoch: 935 [512/17352 (3%)] Loss: -1035.383789\n",
      "Train Epoch: 935 [9626/17352 (55%)] Loss: -1148.480035\n",
      "Train Epoch: 935 [17153/17352 (99%)] Loss: -980.846497\n",
      "    epoch          : 935\n",
      "    loss           : -1017.5216477945316\n",
      "    val_loss       : -775.9287742976228\n",
      "    val_log_likelihood: 1306.3819351224745\n",
      "    val_log_marginal: 795.3192352691009\n",
      "Train Epoch: 936 [512/17352 (3%)] Loss: -1060.255371\n",
      "Train Epoch: 936 [10193/17352 (59%)] Loss: -1003.960526\n",
      "Train Epoch: 936 [17106/17352 (99%)] Loss: -1110.254994\n",
      "    epoch          : 936\n",
      "    loss           : -1016.0425023482782\n",
      "    val_loss       : -764.393601647414\n",
      "    val_log_likelihood: 1310.500795912319\n",
      "    val_log_marginal: 781.0907053196546\n",
      "Train Epoch: 937 [512/17352 (3%)] Loss: -1051.235718\n",
      "Train Epoch: 937 [10549/17352 (61%)] Loss: -1052.673426\n",
      "Train Epoch: 937 [17124/17352 (99%)] Loss: -850.772129\n",
      "    epoch          : 937\n",
      "    loss           : -1007.4392458641571\n",
      "    val_loss       : -770.6050358066456\n",
      "    val_log_likelihood: 1313.7501381838126\n",
      "    val_log_marginal: 788.2355329670345\n",
      "Train Epoch: 938 [512/17352 (3%)] Loss: -1053.655518\n",
      "Train Epoch: 938 [9512/17352 (55%)] Loss: -1077.515713\n",
      "Train Epoch: 938 [17049/17352 (98%)] Loss: -894.172205\n",
      "    epoch          : 938\n",
      "    loss           : -1003.7272002258234\n",
      "    val_loss       : -750.7714514157802\n",
      "    val_log_likelihood: 1309.306037833286\n",
      "    val_log_marginal: 770.5372932256363\n",
      "Train Epoch: 939 [512/17352 (3%)] Loss: -1030.751709\n",
      "Train Epoch: 939 [10850/17352 (63%)] Loss: -1057.198235\n",
      "Train Epoch: 939 [16887/17352 (97%)] Loss: -905.495722\n",
      "    epoch          : 939\n",
      "    loss           : -968.0801537956072\n",
      "    val_loss       : -724.5483551390828\n",
      "    val_log_likelihood: 1294.4661745303697\n",
      "    val_log_marginal: 747.3425638337279\n",
      "Train Epoch: 940 [512/17352 (3%)] Loss: -1026.678589\n",
      "Train Epoch: 940 [10433/17352 (60%)] Loss: -815.237322\n",
      "Train Epoch: 940 [17064/17352 (98%)] Loss: -834.134606\n",
      "    epoch          : 940\n",
      "    loss           : -874.7214056237458\n",
      "    val_loss       : -502.7100229415797\n",
      "    val_log_likelihood: 1244.49121660931\n",
      "    val_log_marginal: 538.6900956371132\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch940.pth ...\n",
      "Train Epoch: 941 [512/17352 (3%)] Loss: -618.890686\n",
      "Train Epoch: 941 [10671/17352 (61%)] Loss: -602.548437\n",
      "Train Epoch: 941 [16957/17352 (98%)] Loss: -698.507241\n",
      "    epoch          : 941\n",
      "    loss           : -774.2363760072049\n",
      "    val_loss       : -580.2094931910302\n",
      "    val_log_likelihood: 1228.3983783535969\n",
      "    val_log_marginal: 635.4588599549181\n",
      "Train Epoch: 942 [512/17352 (3%)] Loss: -828.747681\n",
      "Train Epoch: 942 [10274/17352 (59%)] Loss: -737.125728\n",
      "Train Epoch: 942 [17253/17352 (99%)] Loss: -871.329619\n",
      "    epoch          : 942\n",
      "    loss           : -907.5618445480147\n",
      "    val_loss       : -579.2067229498672\n",
      "    val_log_likelihood: 1251.5374465954505\n",
      "    val_log_marginal: 607.6855889908688\n",
      "Train Epoch: 943 [512/17352 (3%)] Loss: -851.000183\n",
      "Train Epoch: 943 [10279/17352 (59%)] Loss: -678.043730\n",
      "Train Epoch: 943 [16882/17352 (97%)] Loss: -896.033767\n",
      "    epoch          : 943\n",
      "    loss           : -895.3456645675195\n",
      "    val_loss       : -749.3625164413817\n",
      "    val_log_likelihood: 1279.6452337353005\n",
      "    val_log_marginal: 776.3377965691685\n",
      "Train Epoch: 944 [512/17352 (3%)] Loss: -814.124878\n",
      "Train Epoch: 944 [10294/17352 (59%)] Loss: -1015.126953\n",
      "Train Epoch: 944 [16992/17352 (98%)] Loss: -1004.454556\n",
      "    epoch          : 944\n",
      "    loss           : -946.3932222442365\n",
      "    val_loss       : -734.9167012866737\n",
      "    val_log_likelihood: 1284.8898494969906\n",
      "    val_log_marginal: 753.6270135960057\n",
      "Train Epoch: 945 [512/17352 (3%)] Loss: -976.246094\n",
      "Train Epoch: 945 [10448/17352 (60%)] Loss: -859.027847\n",
      "Train Epoch: 945 [17108/17352 (99%)] Loss: -1042.783473\n",
      "    epoch          : 945\n",
      "    loss           : -971.2567241213575\n",
      "    val_loss       : -752.4221474714562\n",
      "    val_log_likelihood: 1290.3891158866954\n",
      "    val_log_marginal: 778.4426966703217\n",
      "Train Epoch: 946 [512/17352 (3%)] Loss: -1044.478149\n",
      "Train Epoch: 946 [10622/17352 (61%)] Loss: -975.470052\n",
      "Train Epoch: 946 [17277/17352 (100%)] Loss: -927.090935\n",
      "    epoch          : 946\n",
      "    loss           : -1005.4963581717606\n",
      "    val_loss       : -738.278245211561\n",
      "    val_log_likelihood: 1297.3059967475335\n",
      "    val_log_marginal: 762.2072879599609\n",
      "Train Epoch: 947 [512/17352 (3%)] Loss: -1027.375488\n",
      "Train Epoch: 947 [9996/17352 (58%)] Loss: -917.202626\n",
      "Train Epoch: 947 [17143/17352 (99%)] Loss: -1005.274479\n",
      "    epoch          : 947\n",
      "    loss           : -979.3863855705548\n",
      "    val_loss       : -432.2225857731395\n",
      "    val_log_likelihood: 1281.9057936991119\n",
      "    val_log_marginal: 450.8797700196301\n",
      "Train Epoch: 948 [512/17352 (3%)] Loss: -766.518921\n",
      "Train Epoch: 948 [10385/17352 (60%)] Loss: -1055.219699\n",
      "Train Epoch: 948 [16988/17352 (98%)] Loss: 182.756485\n",
      "    epoch          : 948\n",
      "    loss           : -788.6182257129158\n",
      "    val_loss       : -296.4926907502166\n",
      "    val_log_likelihood: 1237.1415189328663\n",
      "    val_log_marginal: 326.27101947445425\n",
      "Train Epoch: 949 [512/17352 (3%)] Loss: -653.630981\n",
      "Train Epoch: 949 [10165/17352 (59%)] Loss: -954.197345\n",
      "Train Epoch: 949 [17253/17352 (99%)] Loss: -539.759809\n",
      "    epoch          : 949\n",
      "    loss           : -691.3857281530449\n",
      "    val_loss       : -200.45389033567054\n",
      "    val_log_likelihood: 1209.3884976245633\n",
      "    val_log_marginal: 244.13775401547915\n",
      "Train Epoch: 950 [512/17352 (3%)] Loss: -519.400818\n",
      "Train Epoch: 950 [10128/17352 (58%)] Loss: -927.188881\n",
      "Train Epoch: 950 [16992/17352 (98%)] Loss: -1046.071362\n",
      "    epoch          : 950\n",
      "    loss           : -858.8719193753933\n",
      "    val_loss       : -712.7083701377496\n",
      "    val_log_likelihood: 1253.234037482979\n",
      "    val_log_marginal: 740.9585392764809\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch950.pth ...\n",
      "Train Epoch: 951 [512/17352 (3%)] Loss: -988.849487\n",
      "Train Epoch: 951 [9870/17352 (57%)] Loss: -859.747112\n",
      "Train Epoch: 951 [17153/17352 (99%)] Loss: -1090.401423\n",
      "    epoch          : 951\n",
      "    loss           : -982.2554012519373\n",
      "    val_loss       : -732.7137142460533\n",
      "    val_log_likelihood: 1284.558500807263\n",
      "    val_log_marginal: 754.3821948186408\n",
      "Train Epoch: 952 [512/17352 (3%)] Loss: -1010.226196\n",
      "Train Epoch: 952 [10043/17352 (58%)] Loss: -882.298138\n",
      "Train Epoch: 952 [16883/17352 (97%)] Loss: -926.470373\n",
      "    epoch          : 952\n",
      "    loss           : -947.9778694850143\n",
      "    val_loss       : -754.0919906915991\n",
      "    val_log_likelihood: 1290.5516117322802\n",
      "    val_log_marginal: 775.7971302222751\n",
      "Train Epoch: 953 [512/17352 (3%)] Loss: -1049.012085\n",
      "Train Epoch: 953 [10613/17352 (61%)] Loss: -859.377527\n",
      "Train Epoch: 953 [16922/17352 (98%)] Loss: -1094.113098\n",
      "    epoch          : 953\n",
      "    loss           : -996.8527682074317\n",
      "    val_loss       : -767.6420874113554\n",
      "    val_log_likelihood: 1303.0182863349246\n",
      "    val_log_marginal: 790.8882738460044\n",
      "Train Epoch: 954 [512/17352 (3%)] Loss: -1049.605835\n",
      "Train Epoch: 954 [9850/17352 (57%)] Loss: -1056.427939\n",
      "Train Epoch: 954 [17335/17352 (100%)] Loss: -1019.119476\n",
      "    epoch          : 954\n",
      "    loss           : -980.1418143499815\n",
      "    val_loss       : -677.5601080933868\n",
      "    val_log_likelihood: 1283.0121295367971\n",
      "    val_log_marginal: 697.1676246306049\n",
      "Train Epoch: 955 [512/17352 (3%)] Loss: -941.895386\n",
      "Train Epoch: 955 [10213/17352 (59%)] Loss: -936.086453\n",
      "Train Epoch: 955 [17143/17352 (99%)] Loss: -932.260417\n",
      "    epoch          : 955\n",
      "    loss           : -960.3457364677175\n",
      "    val_loss       : -742.9258158693362\n",
      "    val_log_likelihood: 1275.7263510087398\n",
      "    val_log_marginal: 757.6878771888586\n",
      "Train Epoch: 956 [512/17352 (3%)] Loss: -1005.688293\n",
      "Train Epoch: 956 [10601/17352 (61%)] Loss: -948.502637\n",
      "Train Epoch: 956 [17335/17352 (100%)] Loss: -1092.685914\n",
      "    epoch          : 956\n",
      "    loss           : -998.5343038694348\n",
      "    val_loss       : -764.3789484414568\n",
      "    val_log_likelihood: 1298.8355742703895\n",
      "    val_log_marginal: 781.064815218641\n",
      "Train Epoch: 957 [512/17352 (3%)] Loss: -1046.333374\n",
      "Train Epoch: 957 [10458/17352 (60%)] Loss: -969.016298\n",
      "Train Epoch: 957 [16872/17352 (97%)] Loss: -1130.065905\n",
      "    epoch          : 957\n",
      "    loss           : -1007.0877240937936\n",
      "    val_loss       : -752.6871419542713\n",
      "    val_log_likelihood: 1293.2106140183735\n",
      "    val_log_marginal: 770.6414274731524\n",
      "Train Epoch: 958 [512/17352 (3%)] Loss: -1042.100098\n",
      "Train Epoch: 958 [10169/17352 (59%)] Loss: -812.496371\n",
      "Train Epoch: 958 [17044/17352 (98%)] Loss: -964.062201\n",
      "    epoch          : 958\n",
      "    loss           : -982.4112900726752\n",
      "    val_loss       : -773.5600640478885\n",
      "    val_log_likelihood: 1307.349483860757\n",
      "    val_log_marginal: 796.6693690823719\n",
      "Train Epoch: 959 [512/17352 (3%)] Loss: -1043.311523\n",
      "Train Epoch: 959 [10116/17352 (58%)] Loss: -1107.094375\n",
      "Train Epoch: 959 [16883/17352 (97%)] Loss: -1056.762500\n",
      "    epoch          : 959\n",
      "    loss           : -1018.8059292836631\n",
      "    val_loss       : -775.2655676724339\n",
      "    val_log_likelihood: 1310.2759141246804\n",
      "    val_log_marginal: 795.6228230376094\n",
      "Train Epoch: 960 [512/17352 (3%)] Loss: -1056.976929\n",
      "Train Epoch: 960 [10525/17352 (61%)] Loss: -971.004747\n",
      "Train Epoch: 960 [17277/17352 (100%)] Loss: -1133.629464\n",
      "    epoch          : 960\n",
      "    loss           : -1013.8185203818381\n",
      "    val_loss       : -759.666322623764\n",
      "    val_log_likelihood: 1308.0954293968134\n",
      "    val_log_marginal: 785.4129643438201\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch960.pth ...\n",
      "Train Epoch: 961 [512/17352 (3%)] Loss: -1049.950439\n",
      "Train Epoch: 961 [10265/17352 (59%)] Loss: -1042.563881\n",
      "Train Epoch: 961 [16958/17352 (98%)] Loss: -1092.895198\n",
      "    epoch          : 961\n",
      "    loss           : -993.1657186990299\n",
      "    val_loss       : -765.6480983750847\n",
      "    val_log_likelihood: 1301.7603982211147\n",
      "    val_log_marginal: 787.4454916241579\n",
      "Train Epoch: 962 [512/17352 (3%)] Loss: -1038.836548\n",
      "Train Epoch: 962 [10172/17352 (59%)] Loss: -1043.391146\n",
      "Train Epoch: 962 [17124/17352 (99%)] Loss: -891.535693\n",
      "    epoch          : 962\n",
      "    loss           : -1006.0346609005213\n",
      "    val_loss       : -761.0773479406876\n",
      "    val_log_likelihood: 1303.1342309822537\n",
      "    val_log_marginal: 785.0418425106405\n",
      "Train Epoch: 963 [512/17352 (3%)] Loss: -1044.842529\n",
      "Train Epoch: 963 [10030/17352 (58%)] Loss: -935.334256\n",
      "Train Epoch: 963 [17133/17352 (99%)] Loss: -873.619637\n",
      "    epoch          : 963\n",
      "    loss           : -1013.490395927989\n",
      "    val_loss       : -764.4003494027774\n",
      "    val_log_likelihood: 1305.4669054957994\n",
      "    val_log_marginal: 780.929651462564\n",
      "Train Epoch: 964 [512/17352 (3%)] Loss: -1068.106323\n",
      "Train Epoch: 964 [10621/17352 (61%)] Loss: -1071.123216\n",
      "Train Epoch: 964 [17126/17352 (99%)] Loss: -1077.060259\n",
      "    epoch          : 964\n",
      "    loss           : -1017.5339431696568\n",
      "    val_loss       : -757.8918744466142\n",
      "    val_log_likelihood: 1302.165267892244\n",
      "    val_log_marginal: 776.9533969052212\n",
      "Train Epoch: 965 [512/17352 (3%)] Loss: -1045.774170\n",
      "Train Epoch: 965 [10094/17352 (58%)] Loss: -958.248072\n",
      "Train Epoch: 965 [16882/17352 (97%)] Loss: -933.912156\n",
      "    epoch          : 965\n",
      "    loss           : -1019.3424611767235\n",
      "    val_loss       : -776.2333824738031\n",
      "    val_log_likelihood: 1317.9285990824217\n",
      "    val_log_marginal: 792.9376752434168\n",
      "Train Epoch: 966 [512/17352 (3%)] Loss: -1069.359375\n",
      "Train Epoch: 966 [10343/17352 (60%)] Loss: -942.877637\n",
      "Train Epoch: 966 [17090/17352 (98%)] Loss: -947.089583\n",
      "    epoch          : 966\n",
      "    loss           : -1013.6286702224015\n",
      "    val_loss       : -771.2330334817121\n",
      "    val_log_likelihood: 1315.304794892287\n",
      "    val_log_marginal: 790.9909220763739\n",
      "Train Epoch: 967 [512/17352 (3%)] Loss: -1058.072754\n",
      "Train Epoch: 967 [10596/17352 (61%)] Loss: -1051.596029\n",
      "Train Epoch: 967 [16923/17352 (98%)] Loss: -1075.968532\n",
      "    epoch          : 967\n",
      "    loss           : -1023.6274045499138\n",
      "    val_loss       : -781.1739572429481\n",
      "    val_log_likelihood: 1321.3327923128647\n",
      "    val_log_marginal: 795.3034763180574\n",
      "Train Epoch: 968 [512/17352 (3%)] Loss: -1056.075195\n",
      "Train Epoch: 968 [10583/17352 (61%)] Loss: -852.836722\n",
      "Train Epoch: 968 [17106/17352 (99%)] Loss: -1049.034707\n",
      "    epoch          : 968\n",
      "    loss           : -1019.7063971673637\n",
      "    val_loss       : -756.9196220327193\n",
      "    val_log_likelihood: 1314.5776955903725\n",
      "    val_log_marginal: 774.9152884124155\n",
      "Train Epoch: 969 [512/17352 (3%)] Loss: -1053.246582\n",
      "Train Epoch: 969 [10478/17352 (60%)] Loss: -1085.366513\n",
      "Train Epoch: 969 [17090/17352 (98%)] Loss: -950.116383\n",
      "    epoch          : 969\n",
      "    loss           : -997.0134534662559\n",
      "    val_loss       : -713.9714266432002\n",
      "    val_log_likelihood: 1296.2759472526063\n",
      "    val_log_marginal: 736.5279043219858\n",
      "Train Epoch: 970 [512/17352 (3%)] Loss: -975.659302\n",
      "Train Epoch: 970 [10190/17352 (59%)] Loss: -505.227230\n",
      "Train Epoch: 970 [16923/17352 (98%)] Loss: -833.759196\n",
      "    epoch          : 970\n",
      "    loss           : -781.5226857770915\n",
      "    val_loss       : -653.4042929807151\n",
      "    val_log_likelihood: 1247.8259792540332\n",
      "    val_log_marginal: 705.4900697375198\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch970.pth ...\n",
      "Train Epoch: 971 [512/17352 (3%)] Loss: -939.726074\n",
      "Train Epoch: 971 [10180/17352 (59%)] Loss: -990.652396\n",
      "Train Epoch: 971 [17108/17352 (99%)] Loss: -1028.592957\n",
      "    epoch          : 971\n",
      "    loss           : -869.4281639916273\n",
      "    val_loss       : -696.7636557150106\n",
      "    val_log_likelihood: 1259.5563945794006\n",
      "    val_log_marginal: 740.8498871902129\n",
      "Train Epoch: 972 [512/17352 (3%)] Loss: -981.063293\n",
      "Train Epoch: 972 [10903/17352 (63%)] Loss: -939.947743\n",
      "Train Epoch: 972 [17016/17352 (98%)] Loss: -829.191911\n",
      "    epoch          : 972\n",
      "    loss           : -989.8225326317765\n",
      "    val_loss       : -747.2387519372348\n",
      "    val_log_likelihood: 1301.5188343858322\n",
      "    val_log_marginal: 774.448672816167\n",
      "Train Epoch: 973 [512/17352 (3%)] Loss: -1013.893677\n",
      "Train Epoch: 973 [10747/17352 (62%)] Loss: -1107.160181\n",
      "Train Epoch: 973 [16939/17352 (98%)] Loss: -944.909115\n",
      "    epoch          : 973\n",
      "    loss           : -1003.2568508124668\n",
      "    val_loss       : -764.4787739473966\n",
      "    val_log_likelihood: 1308.3742192649265\n",
      "    val_log_marginal: 785.2267020326406\n",
      "Train Epoch: 974 [512/17352 (3%)] Loss: -1054.689819\n",
      "Train Epoch: 974 [10667/17352 (61%)] Loss: -955.597707\n",
      "Train Epoch: 974 [16939/17352 (98%)] Loss: -1086.985160\n",
      "    epoch          : 974\n",
      "    loss           : -1010.9475392391433\n",
      "    val_loss       : -785.5247253650604\n",
      "    val_log_likelihood: 1323.8897308625444\n",
      "    val_log_marginal: 804.3584344412701\n",
      "Train Epoch: 975 [512/17352 (3%)] Loss: -1050.807983\n",
      "Train Epoch: 975 [10363/17352 (60%)] Loss: -1074.415625\n",
      "Train Epoch: 975 [17143/17352 (99%)] Loss: -976.430492\n",
      "    epoch          : 975\n",
      "    loss           : -1011.9734571867201\n",
      "    val_loss       : -726.6808127031178\n",
      "    val_log_likelihood: 1284.9720449193737\n",
      "    val_log_marginal: 747.1495535805947\n",
      "Train Epoch: 976 [512/17352 (3%)] Loss: -1010.431885\n",
      "Train Epoch: 976 [9830/17352 (57%)] Loss: -994.616843\n",
      "Train Epoch: 976 [16883/17352 (97%)] Loss: -955.016640\n",
      "    epoch          : 976\n",
      "    loss           : -1011.7042028999417\n",
      "    val_loss       : -766.5815780752586\n",
      "    val_log_likelihood: 1322.9483662225273\n",
      "    val_log_marginal: 795.4128787089631\n",
      "Train Epoch: 977 [512/17352 (3%)] Loss: -1037.540283\n",
      "Train Epoch: 977 [9687/17352 (56%)] Loss: -1054.322396\n",
      "Train Epoch: 977 [16882/17352 (97%)] Loss: -935.317269\n",
      "    epoch          : 977\n",
      "    loss           : -986.6299598982056\n",
      "    val_loss       : -764.2511204546552\n",
      "    val_log_likelihood: 1311.1285066969199\n",
      "    val_log_marginal: 786.8761010007454\n",
      "Train Epoch: 978 [512/17352 (3%)] Loss: -1046.352295\n",
      "Train Epoch: 978 [10064/17352 (58%)] Loss: -1041.340609\n",
      "Train Epoch: 978 [16939/17352 (98%)] Loss: -888.887285\n",
      "    epoch          : 978\n",
      "    loss           : -976.2359513158283\n",
      "    val_loss       : -718.6695400540498\n",
      "    val_log_likelihood: 1274.0500135408986\n",
      "    val_log_marginal: 734.0641553677126\n",
      "Train Epoch: 979 [512/17352 (3%)] Loss: -1015.059448\n",
      "Train Epoch: 979 [9939/17352 (57%)] Loss: -983.290953\n",
      "Train Epoch: 979 [16887/17352 (97%)] Loss: -1026.436793\n",
      "    epoch          : 979\n",
      "    loss           : -938.4795988693844\n",
      "    val_loss       : -747.1440990979\n",
      "    val_log_likelihood: 1280.8397611784167\n",
      "    val_log_marginal: 775.4528108079485\n",
      "Train Epoch: 980 [512/17352 (3%)] Loss: -1038.119019\n",
      "Train Epoch: 980 [10565/17352 (61%)] Loss: -1044.400145\n",
      "Train Epoch: 980 [17049/17352 (98%)] Loss: -911.657479\n",
      "    epoch          : 980\n",
      "    loss           : -955.7231859176862\n",
      "    val_loss       : -711.4424548854277\n",
      "    val_log_likelihood: 1273.1579269062913\n",
      "    val_log_marginal: 745.6224485958346\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch980.pth ...\n",
      "Train Epoch: 981 [512/17352 (3%)] Loss: -993.610718\n",
      "Train Epoch: 981 [10340/17352 (60%)] Loss: -790.787007\n",
      "Train Epoch: 981 [16872/17352 (97%)] Loss: -799.216667\n",
      "    epoch          : 981\n",
      "    loss           : -957.5059839713268\n",
      "    val_loss       : -730.1880071546464\n",
      "    val_log_likelihood: 1280.484773050583\n",
      "    val_log_marginal: 742.3691549102213\n",
      "Train Epoch: 982 [512/17352 (3%)] Loss: -1029.902832\n",
      "Train Epoch: 982 [10339/17352 (60%)] Loss: -528.693238\n",
      "Train Epoch: 982 [17153/17352 (99%)] Loss: -644.579509\n",
      "    epoch          : 982\n",
      "    loss           : -830.083554380719\n",
      "    val_loss       : -532.3455991004092\n",
      "    val_log_likelihood: 1229.7416674906992\n",
      "    val_log_marginal: 612.1114657360495\n",
      "Train Epoch: 983 [512/17352 (3%)] Loss: -810.384521\n",
      "Train Epoch: 983 [10577/17352 (61%)] Loss: -952.080934\n",
      "Train Epoch: 983 [17133/17352 (99%)] Loss: -1084.205811\n",
      "    epoch          : 983\n",
      "    loss           : -876.0077665866031\n",
      "    val_loss       : -631.959580108186\n",
      "    val_log_likelihood: 1272.095151930859\n",
      "    val_log_marginal: 651.1187855461982\n",
      "Train Epoch: 984 [512/17352 (3%)] Loss: -909.884949\n",
      "Train Epoch: 984 [11077/17352 (64%)] Loss: -834.669931\n",
      "Train Epoch: 984 [17277/17352 (100%)] Loss: -929.747674\n",
      "    epoch          : 984\n",
      "    loss           : -952.706632894083\n",
      "    val_loss       : -749.8621393135978\n",
      "    val_log_likelihood: 1280.5322357627856\n",
      "    val_log_marginal: 769.5971336136432\n",
      "Train Epoch: 985 [512/17352 (3%)] Loss: -817.735474\n",
      "Train Epoch: 985 [10313/17352 (59%)] Loss: -950.872817\n",
      "Train Epoch: 985 [17126/17352 (99%)] Loss: -1048.007198\n",
      "    epoch          : 985\n",
      "    loss           : -972.2977690922442\n",
      "    val_loss       : -724.872860977419\n",
      "    val_log_likelihood: 1282.068744223387\n",
      "    val_log_marginal: 747.532938576562\n",
      "Train Epoch: 986 [512/17352 (3%)] Loss: -1012.233765\n",
      "Train Epoch: 986 [10198/17352 (59%)] Loss: -1024.104585\n",
      "Train Epoch: 986 [16939/17352 (98%)] Loss: -1020.384766\n",
      "    epoch          : 986\n",
      "    loss           : -996.1291286167872\n",
      "    val_loss       : -748.7461288384723\n",
      "    val_log_likelihood: 1287.4467825536926\n",
      "    val_log_marginal: 772.4978709101091\n",
      "Train Epoch: 987 [512/17352 (3%)] Loss: -1037.042847\n",
      "Train Epoch: 987 [10396/17352 (60%)] Loss: -921.169457\n",
      "Train Epoch: 987 [16887/17352 (97%)] Loss: -998.502366\n",
      "    epoch          : 987\n",
      "    loss           : -990.765341863009\n",
      "    val_loss       : -755.2550336473694\n",
      "    val_log_likelihood: 1304.6824702071478\n",
      "    val_log_marginal: 782.3126345467657\n",
      "Train Epoch: 988 [512/17352 (3%)] Loss: -1045.910889\n",
      "Train Epoch: 988 [10474/17352 (60%)] Loss: -840.322298\n",
      "Train Epoch: 988 [17124/17352 (99%)] Loss: -1073.242937\n",
      "    epoch          : 988\n",
      "    loss           : -1001.9736547537968\n",
      "    val_loss       : -729.8803304194164\n",
      "    val_log_likelihood: 1293.670641948502\n",
      "    val_log_marginal: 752.8690642732174\n",
      "Train Epoch: 989 [512/17352 (3%)] Loss: -1025.881958\n",
      "Train Epoch: 989 [10709/17352 (62%)] Loss: -1043.121875\n",
      "Train Epoch: 989 [17090/17352 (98%)] Loss: -877.670049\n",
      "    epoch          : 989\n",
      "    loss           : -994.5035906180495\n",
      "    val_loss       : -736.32961391252\n",
      "    val_log_likelihood: 1295.438751719588\n",
      "    val_log_marginal: 748.2492954797125\n",
      "Train Epoch: 990 [512/17352 (3%)] Loss: -1009.899597\n",
      "Train Epoch: 990 [10410/17352 (60%)] Loss: -1042.187223\n",
      "Train Epoch: 990 [17101/17352 (99%)] Loss: -969.261340\n",
      "    epoch          : 990\n",
      "    loss           : -1002.0985526536391\n",
      "    val_loss       : -762.9618158276129\n",
      "    val_log_likelihood: 1308.7641030940258\n",
      "    val_log_marginal: 780.9438217013942\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch990.pth ...\n",
      "Train Epoch: 991 [512/17352 (3%)] Loss: -1048.700195\n",
      "Train Epoch: 991 [10074/17352 (58%)] Loss: -863.470469\n",
      "Train Epoch: 991 [17049/17352 (98%)] Loss: -1122.178438\n",
      "    epoch          : 991\n",
      "    loss           : -1023.8179956043099\n",
      "    val_loss       : -759.4804517140909\n",
      "    val_log_likelihood: 1309.4896988794549\n",
      "    val_log_marginal: 774.9700003721499\n",
      "Train Epoch: 992 [512/17352 (3%)] Loss: -1057.378784\n",
      "Train Epoch: 992 [10582/17352 (61%)] Loss: -966.028185\n",
      "Train Epoch: 992 [17133/17352 (99%)] Loss: -991.113967\n",
      "    epoch          : 992\n",
      "    loss           : -1025.699309465465\n",
      "    val_loss       : -761.3840509285317\n",
      "    val_log_likelihood: 1308.617651390242\n",
      "    val_log_marginal: 785.1669329870701\n",
      "Train Epoch: 993 [512/17352 (3%)] Loss: -1051.557983\n",
      "Train Epoch: 993 [10393/17352 (60%)] Loss: -937.102958\n",
      "Train Epoch: 993 [16887/17352 (97%)] Loss: -1041.945848\n",
      "    epoch          : 993\n",
      "    loss           : -1002.3833020036706\n",
      "    val_loss       : -755.3405446522562\n",
      "    val_log_likelihood: 1314.1292631171063\n",
      "    val_log_marginal: 778.0675961440809\n",
      "Train Epoch: 994 [512/17352 (3%)] Loss: -1047.607666\n",
      "Train Epoch: 994 [10153/17352 (59%)] Loss: -1089.213750\n",
      "Train Epoch: 994 [17126/17352 (99%)] Loss: -1029.730887\n",
      "    epoch          : 994\n",
      "    loss           : -998.0758685588178\n",
      "    val_loss       : -620.1376943853505\n",
      "    val_log_likelihood: 1295.4958242077328\n",
      "    val_log_marginal: 641.8320547008097\n",
      "Train Epoch: 995 [512/17352 (3%)] Loss: -952.289917\n",
      "Train Epoch: 995 [10281/17352 (59%)] Loss: -1068.164883\n",
      "Train Epoch: 995 [16934/17352 (98%)] Loss: -1053.373596\n",
      "    epoch          : 995\n",
      "    loss           : -994.3239244351546\n",
      "    val_loss       : -753.4028665489099\n",
      "    val_log_likelihood: 1308.3367988276689\n",
      "    val_log_marginal: 780.581115519848\n",
      "Train Epoch: 996 [512/17352 (3%)] Loss: -965.293579\n",
      "Train Epoch: 996 [10140/17352 (58%)] Loss: -907.128750\n",
      "Train Epoch: 996 [17044/17352 (98%)] Loss: -1008.294127\n",
      "    epoch          : 996\n",
      "    loss           : -923.550983296063\n",
      "    val_loss       : -669.2149525135674\n",
      "    val_log_likelihood: 1247.825996668057\n",
      "    val_log_marginal: 699.4243728687634\n",
      "Train Epoch: 997 [512/17352 (3%)] Loss: -915.200623\n",
      "Train Epoch: 997 [10256/17352 (59%)] Loss: -1084.395579\n",
      "Train Epoch: 997 [16923/17352 (98%)] Loss: -949.744192\n",
      "    epoch          : 997\n",
      "    loss           : -960.6116179801073\n",
      "    val_loss       : -703.3404342608367\n",
      "    val_log_likelihood: 1297.1352862886147\n",
      "    val_log_marginal: 732.7070270580904\n",
      "Train Epoch: 998 [512/17352 (3%)] Loss: -1001.157593\n",
      "Train Epoch: 998 [10353/17352 (60%)] Loss: -1011.857577\n",
      "Train Epoch: 998 [16923/17352 (98%)] Loss: -1136.407461\n",
      "    epoch          : 998\n",
      "    loss           : -989.5571056967553\n",
      "    val_loss       : -762.0016141558754\n",
      "    val_log_likelihood: 1312.359689548813\n",
      "    val_log_marginal: 783.5948186929643\n",
      "Train Epoch: 999 [512/17352 (3%)] Loss: -1037.998413\n",
      "Train Epoch: 999 [9852/17352 (57%)] Loss: -860.817811\n",
      "Train Epoch: 999 [17108/17352 (99%)] Loss: -961.442708\n",
      "    epoch          : 999\n",
      "    loss           : -1013.8896568228471\n",
      "    val_loss       : -780.7156020952013\n",
      "    val_log_likelihood: 1323.232316249314\n",
      "    val_log_marginal: 798.407927809896\n",
      "Train Epoch: 1000 [512/17352 (3%)] Loss: -1069.872925\n",
      "Train Epoch: 1000 [10145/17352 (58%)] Loss: -1080.020916\n",
      "Train Epoch: 1000 [17153/17352 (99%)] Loss: -1073.611119\n",
      "    epoch          : 1000\n",
      "    loss           : -1025.9851856083649\n",
      "    val_loss       : -777.5533216507052\n",
      "    val_log_likelihood: 1329.6539091954385\n",
      "    val_log_marginal: 804.2191091239388\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1000.pth ...\n",
      "Train Epoch: 1001 [512/17352 (3%)] Loss: -1081.606689\n",
      "Train Epoch: 1001 [9983/17352 (58%)] Loss: -928.582896\n",
      "Train Epoch: 1001 [16958/17352 (98%)] Loss: -1134.742537\n",
      "    epoch          : 1001\n",
      "    loss           : -1030.2483625210164\n",
      "    val_loss       : -769.8607693486416\n",
      "    val_log_likelihood: 1327.3767102055403\n",
      "    val_log_marginal: 791.8901308279296\n",
      "Train Epoch: 1002 [512/17352 (3%)] Loss: -1080.319580\n",
      "Train Epoch: 1002 [10339/17352 (60%)] Loss: -1024.657977\n",
      "Train Epoch: 1002 [17101/17352 (99%)] Loss: -1161.820638\n",
      "    epoch          : 1002\n",
      "    loss           : -1016.1374837542858\n",
      "    val_loss       : -728.6465366273715\n",
      "    val_log_likelihood: 1315.6937665538826\n",
      "    val_log_marginal: 755.4804068333364\n",
      "Train Epoch: 1003 [512/17352 (3%)] Loss: -1007.366882\n",
      "Train Epoch: 1003 [10006/17352 (58%)] Loss: -1070.949288\n",
      "Train Epoch: 1003 [16882/17352 (97%)] Loss: -1050.701341\n",
      "    epoch          : 1003\n",
      "    loss           : -980.897112652754\n",
      "    val_loss       : -700.2723258010299\n",
      "    val_log_likelihood: 1282.791049228978\n",
      "    val_log_marginal: 724.2611742623942\n",
      "Train Epoch: 1004 [512/17352 (3%)] Loss: -972.984863\n",
      "Train Epoch: 1004 [10568/17352 (61%)] Loss: -892.695513\n",
      "Train Epoch: 1004 [16872/17352 (97%)] Loss: -920.178711\n",
      "    epoch          : 1004\n",
      "    loss           : -964.3105510943368\n",
      "    val_loss       : -672.1281218227856\n",
      "    val_log_likelihood: 1300.467753738791\n",
      "    val_log_marginal: 694.6435471273878\n",
      "Train Epoch: 1005 [512/17352 (3%)] Loss: -947.654297\n",
      "Train Epoch: 1005 [10612/17352 (61%)] Loss: -910.470395\n",
      "Train Epoch: 1005 [17126/17352 (99%)] Loss: -870.590256\n",
      "    epoch          : 1005\n",
      "    loss           : -831.9876990931193\n",
      "    val_loss       : -582.7857065104007\n",
      "    val_log_likelihood: 1267.848565546327\n",
      "    val_log_marginal: 612.1941306981435\n",
      "Train Epoch: 1006 [512/17352 (3%)] Loss: -918.641418\n",
      "Train Epoch: 1006 [10599/17352 (61%)] Loss: -1077.954949\n",
      "Train Epoch: 1006 [17253/17352 (99%)] Loss: -936.134270\n",
      "    epoch          : 1006\n",
      "    loss           : -971.4417071455473\n",
      "    val_loss       : -734.6322127243784\n",
      "    val_log_likelihood: 1293.9498385688373\n",
      "    val_log_marginal: 753.6323785079634\n",
      "Train Epoch: 1007 [512/17352 (3%)] Loss: -1020.617126\n",
      "Train Epoch: 1007 [10348/17352 (60%)] Loss: -888.052861\n",
      "Train Epoch: 1007 [16992/17352 (98%)] Loss: -715.831518\n",
      "    epoch          : 1007\n",
      "    loss           : -937.8651445416172\n",
      "    val_loss       : -667.417520336109\n",
      "    val_log_likelihood: 1285.5785404566618\n",
      "    val_log_marginal: 700.7995750279428\n",
      "Train Epoch: 1008 [512/17352 (3%)] Loss: -977.763733\n",
      "Train Epoch: 1008 [9974/17352 (57%)] Loss: -973.950475\n",
      "Train Epoch: 1008 [16934/17352 (98%)] Loss: -854.938621\n",
      "    epoch          : 1008\n",
      "    loss           : -855.667096125952\n",
      "    val_loss       : -716.9254801661556\n",
      "    val_log_likelihood: 1279.175283482834\n",
      "    val_log_marginal: 742.8469298552891\n",
      "Train Epoch: 1009 [512/17352 (3%)] Loss: -985.672852\n",
      "Train Epoch: 1009 [10282/17352 (59%)] Loss: -944.896484\n",
      "Train Epoch: 1009 [16878/17352 (97%)] Loss: -701.833834\n",
      "    epoch          : 1009\n",
      "    loss           : -914.138138876496\n",
      "    val_loss       : -509.975194125467\n",
      "    val_log_likelihood: 1275.088622409689\n",
      "    val_log_marginal: 526.9904108097778\n",
      "Train Epoch: 1010 [512/17352 (3%)] Loss: -832.353638\n",
      "Train Epoch: 1010 [10385/17352 (60%)] Loss: -1026.468372\n",
      "Train Epoch: 1010 [16883/17352 (97%)] Loss: -1047.044847\n",
      "    epoch          : 1010\n",
      "    loss           : -862.7465992824937\n",
      "    val_loss       : -598.7241778495844\n",
      "    val_log_likelihood: 1255.5787728830253\n",
      "    val_log_marginal: 614.4322870742554\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1010.pth ...\n",
      "Train Epoch: 1011 [512/17352 (3%)] Loss: -959.986694\n",
      "Train Epoch: 1011 [10197/17352 (59%)] Loss: -848.626395\n",
      "Train Epoch: 1011 [17277/17352 (100%)] Loss: -1040.575399\n",
      "    epoch          : 1011\n",
      "    loss           : -946.8465959138889\n",
      "    val_loss       : -425.01806632810377\n",
      "    val_log_likelihood: 1273.3442295391324\n",
      "    val_log_marginal: 448.1244583731345\n",
      "Train Epoch: 1012 [512/17352 (3%)] Loss: -661.544067\n",
      "Train Epoch: 1012 [10469/17352 (60%)] Loss: -966.736068\n",
      "Train Epoch: 1012 [16878/17352 (97%)] Loss: -1031.611833\n",
      "    epoch          : 1012\n",
      "    loss           : -906.7538051195479\n",
      "    val_loss       : -653.8143659303805\n",
      "    val_log_likelihood: 1242.5902029079189\n",
      "    val_log_marginal: 677.3681644150979\n",
      "Train Epoch: 1013 [512/17352 (3%)] Loss: -929.880432\n",
      "Train Epoch: 1013 [10439/17352 (60%)] Loss: -1001.315058\n",
      "Train Epoch: 1013 [17335/17352 (100%)] Loss: -700.986759\n",
      "    epoch          : 1013\n",
      "    loss           : -921.0511673762959\n",
      "    val_loss       : -650.910761407338\n",
      "    val_log_likelihood: 1238.1714487692407\n",
      "    val_log_marginal: 698.1193081087531\n",
      "Train Epoch: 1014 [512/17352 (3%)] Loss: -922.413696\n",
      "Train Epoch: 1014 [10684/17352 (62%)] Loss: -985.061442\n",
      "Train Epoch: 1014 [17108/17352 (99%)] Loss: -951.268530\n",
      "    epoch          : 1014\n",
      "    loss           : -930.1655187368867\n",
      "    val_loss       : -722.5691514857251\n",
      "    val_log_likelihood: 1274.6275081699268\n",
      "    val_log_marginal: 752.0070734678601\n",
      "Train Epoch: 1015 [512/17352 (3%)] Loss: -938.527405\n",
      "Train Epoch: 1015 [10392/17352 (60%)] Loss: -1032.558024\n",
      "Train Epoch: 1015 [17064/17352 (98%)] Loss: 528.671555\n",
      "    epoch          : 1015\n",
      "    loss           : -673.1862756323981\n",
      "    val_loss       : -455.20101318878585\n",
      "    val_log_likelihood: 1178.2336772484964\n",
      "    val_log_marginal: 497.2337234913633\n",
      "Train Epoch: 1016 [512/17352 (3%)] Loss: -743.116577\n",
      "Train Epoch: 1016 [10229/17352 (59%)] Loss: -641.199923\n",
      "Train Epoch: 1016 [17101/17352 (99%)] Loss: -861.765587\n",
      "    epoch          : 1016\n",
      "    loss           : -494.0404251914738\n",
      "    val_loss       : -578.0431505926751\n",
      "    val_log_likelihood: 1176.2336056433612\n",
      "    val_log_marginal: 616.0371874578516\n",
      "Train Epoch: 1017 [512/17352 (3%)] Loss: -882.100952\n",
      "Train Epoch: 1017 [10256/17352 (59%)] Loss: -978.030814\n",
      "Train Epoch: 1017 [17064/17352 (98%)] Loss: -1016.623947\n",
      "    epoch          : 1017\n",
      "    loss           : -919.3307763706435\n",
      "    val_loss       : -733.173757629837\n",
      "    val_log_likelihood: 1249.9640644677415\n",
      "    val_log_marginal: 755.5660771292869\n",
      "Train Epoch: 1018 [512/17352 (3%)] Loss: -1018.777161\n",
      "Train Epoch: 1018 [10097/17352 (58%)] Loss: -855.072698\n",
      "Train Epoch: 1018 [16939/17352 (98%)] Loss: -759.093548\n",
      "    epoch          : 1018\n",
      "    loss           : -975.8217689981449\n",
      "    val_loss       : -741.3213163498285\n",
      "    val_log_likelihood: 1287.618308478325\n",
      "    val_log_marginal: 762.9986334682108\n",
      "Train Epoch: 1019 [512/17352 (3%)] Loss: -1042.758545\n",
      "Train Epoch: 1019 [9947/17352 (57%)] Loss: -985.963268\n",
      "Train Epoch: 1019 [17108/17352 (99%)] Loss: -907.657634\n",
      "    epoch          : 1019\n",
      "    loss           : -1010.5216822117286\n",
      "    val_loss       : -733.8249325443244\n",
      "    val_log_likelihood: 1284.2806085514248\n",
      "    val_log_marginal: 751.1067340034042\n",
      "Train Epoch: 1020 [512/17352 (3%)] Loss: -1010.872681\n",
      "Train Epoch: 1020 [10628/17352 (61%)] Loss: -1105.669282\n",
      "Train Epoch: 1020 [17064/17352 (98%)] Loss: -1071.720462\n",
      "    epoch          : 1020\n",
      "    loss           : -1011.0763888542492\n",
      "    val_loss       : -731.4481308241706\n",
      "    val_log_likelihood: 1297.2291500137644\n",
      "    val_log_marginal: 765.3103505500161\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1020.pth ...\n",
      "Train Epoch: 1021 [512/17352 (3%)] Loss: -1023.685547\n",
      "Train Epoch: 1021 [10757/17352 (62%)] Loss: -1078.622965\n",
      "Train Epoch: 1021 [17101/17352 (99%)] Loss: -1081.542642\n",
      "    epoch          : 1021\n",
      "    loss           : -990.2545399150945\n",
      "    val_loss       : -755.2631031523854\n",
      "    val_log_likelihood: 1291.6199884828716\n",
      "    val_log_marginal: 772.9454402478212\n",
      "Train Epoch: 1022 [512/17352 (3%)] Loss: -1047.465820\n",
      "Train Epoch: 1022 [9928/17352 (57%)] Loss: -963.261591\n",
      "Train Epoch: 1022 [16878/17352 (97%)] Loss: -1000.384663\n",
      "    epoch          : 1022\n",
      "    loss           : -1013.3029957217327\n",
      "    val_loss       : -734.2541842317498\n",
      "    val_log_likelihood: 1285.3914175423074\n",
      "    val_log_marginal: 753.867581979587\n",
      "Train Epoch: 1023 [512/17352 (3%)] Loss: -1022.021545\n",
      "Train Epoch: 1023 [10022/17352 (58%)] Loss: -1090.104020\n",
      "Train Epoch: 1023 [17106/17352 (99%)] Loss: -1043.617810\n",
      "    epoch          : 1023\n",
      "    loss           : -1023.0214406675419\n",
      "    val_loss       : -793.1332975245805\n",
      "    val_log_likelihood: 1320.882640772678\n",
      "    val_log_marginal: 805.0156466429651\n",
      "Train Epoch: 1024 [512/17352 (3%)] Loss: -1073.973999\n",
      "Train Epoch: 1024 [10649/17352 (61%)] Loss: -869.794483\n",
      "Train Epoch: 1024 [16883/17352 (97%)] Loss: -987.162224\n",
      "    epoch          : 1024\n",
      "    loss           : -1008.4367511698098\n",
      "    val_loss       : -766.6086106745182\n",
      "    val_log_likelihood: 1296.490105264983\n",
      "    val_log_marginal: 784.6205652659588\n",
      "Train Epoch: 1025 [512/17352 (3%)] Loss: -1065.257324\n",
      "Train Epoch: 1025 [10490/17352 (60%)] Loss: -1127.462899\n",
      "Train Epoch: 1025 [16992/17352 (98%)] Loss: -1101.435042\n",
      "    epoch          : 1025\n",
      "    loss           : -1023.530767780604\n",
      "    val_loss       : -792.8191187200761\n",
      "    val_log_likelihood: 1330.3568630116629\n",
      "    val_log_marginal: 811.2099106600498\n",
      "Train Epoch: 1026 [512/17352 (3%)] Loss: -1054.313721\n",
      "Train Epoch: 1026 [10583/17352 (61%)] Loss: -1169.559028\n",
      "Train Epoch: 1026 [16988/17352 (98%)] Loss: -923.860067\n",
      "    epoch          : 1026\n",
      "    loss           : -1037.5131775919394\n",
      "    val_loss       : -795.7654333802905\n",
      "    val_log_likelihood: 1331.9073506906589\n",
      "    val_log_marginal: 812.4800696391322\n",
      "Train Epoch: 1027 [512/17352 (3%)] Loss: -1086.331299\n",
      "Train Epoch: 1027 [10128/17352 (58%)] Loss: -1026.470943\n",
      "Train Epoch: 1027 [16957/17352 (98%)] Loss: -909.652098\n",
      "    epoch          : 1027\n",
      "    loss           : -1039.2743487064765\n",
      "    val_loss       : -775.9404091799264\n",
      "    val_log_likelihood: 1325.5698921121077\n",
      "    val_log_marginal: 792.6447167301395\n",
      "Train Epoch: 1028 [512/17352 (3%)] Loss: -1061.207275\n",
      "Train Epoch: 1028 [10554/17352 (61%)] Loss: -1064.882121\n",
      "Train Epoch: 1028 [16883/17352 (97%)] Loss: -1130.318883\n",
      "    epoch          : 1028\n",
      "    loss           : -1025.6873178465514\n",
      "    val_loss       : -782.3978825983806\n",
      "    val_log_likelihood: 1324.827263129401\n",
      "    val_log_marginal: 805.0828558434214\n",
      "Train Epoch: 1029 [512/17352 (3%)] Loss: -909.940430\n",
      "Train Epoch: 1029 [10191/17352 (59%)] Loss: -1072.001563\n",
      "Train Epoch: 1029 [16922/17352 (98%)] Loss: -869.269596\n",
      "    epoch          : 1029\n",
      "    loss           : -1038.1413244301598\n",
      "    val_loss       : -768.027017209027\n",
      "    val_log_likelihood: 1321.8179833848085\n",
      "    val_log_marginal: 784.8477863703097\n",
      "Train Epoch: 1030 [512/17352 (3%)] Loss: -1061.380615\n",
      "Train Epoch: 1030 [10255/17352 (59%)] Loss: -896.315697\n",
      "Train Epoch: 1030 [17124/17352 (99%)] Loss: -986.671950\n",
      "    epoch          : 1030\n",
      "    loss           : -1033.62693730703\n",
      "    val_loss       : -770.5995283381595\n",
      "    val_log_likelihood: 1325.319341674568\n",
      "    val_log_marginal: 797.9645844767588\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1030.pth ...\n",
      "Train Epoch: 1031 [512/17352 (3%)] Loss: -1072.055420\n",
      "Train Epoch: 1031 [10204/17352 (59%)] Loss: -995.676339\n",
      "Train Epoch: 1031 [16939/17352 (98%)] Loss: -961.083198\n",
      "    epoch          : 1031\n",
      "    loss           : -1040.0699054614538\n",
      "    val_loss       : -782.7845305473252\n",
      "    val_log_likelihood: 1337.5756417412313\n",
      "    val_log_marginal: 800.221652454435\n",
      "Train Epoch: 1032 [512/17352 (3%)] Loss: -897.958374\n",
      "Train Epoch: 1032 [10884/17352 (63%)] Loss: -879.325134\n",
      "Train Epoch: 1032 [17090/17352 (98%)] Loss: -1080.424334\n",
      "    epoch          : 1032\n",
      "    loss           : -1029.1659799781569\n",
      "    val_loss       : -727.0646492672056\n",
      "    val_log_likelihood: 1323.3271315118916\n",
      "    val_log_marginal: 741.1144888831487\n",
      "Train Epoch: 1033 [512/17352 (3%)] Loss: -1020.058594\n",
      "Train Epoch: 1033 [10123/17352 (58%)] Loss: -1072.916257\n",
      "Train Epoch: 1033 [17016/17352 (98%)] Loss: -1104.432103\n",
      "    epoch          : 1033\n",
      "    loss           : -997.9416424652679\n",
      "    val_loss       : -687.7609589718102\n",
      "    val_log_likelihood: 1288.4519156777205\n",
      "    val_log_marginal: 725.0958456014004\n",
      "Train Epoch: 1034 [512/17352 (3%)] Loss: -1019.609741\n",
      "Train Epoch: 1034 [10180/17352 (59%)] Loss: -1121.117839\n",
      "Train Epoch: 1034 [17124/17352 (99%)] Loss: -987.291930\n",
      "    epoch          : 1034\n",
      "    loss           : -949.8602259335648\n",
      "    val_loss       : -429.8293638054351\n",
      "    val_log_likelihood: 1273.5726881342011\n",
      "    val_log_marginal: 451.47889926571463\n",
      "Train Epoch: 1035 [512/17352 (3%)] Loss: -754.997986\n",
      "Train Epoch: 1035 [10333/17352 (60%)] Loss: -825.067839\n",
      "Train Epoch: 1035 [16988/17352 (98%)] Loss: -881.469841\n",
      "    epoch          : 1035\n",
      "    loss           : -888.6223366514103\n",
      "    val_loss       : -637.6287938056131\n",
      "    val_log_likelihood: 1209.6963134240398\n",
      "    val_log_marginal: 671.5314927756237\n",
      "Train Epoch: 1036 [512/17352 (3%)] Loss: -955.359009\n",
      "Train Epoch: 1036 [10737/17352 (62%)] Loss: -998.359217\n",
      "Train Epoch: 1036 [16939/17352 (98%)] Loss: -981.570998\n",
      "    epoch          : 1036\n",
      "    loss           : -963.0509598872786\n",
      "    val_loss       : -744.0631040632197\n",
      "    val_log_likelihood: 1297.1024434896306\n",
      "    val_log_marginal: 765.1229302306998\n",
      "Train Epoch: 1037 [512/17352 (3%)] Loss: -1057.263916\n",
      "Train Epoch: 1037 [10450/17352 (60%)] Loss: -946.492059\n",
      "Train Epoch: 1037 [17106/17352 (99%)] Loss: -1008.277474\n",
      "    epoch          : 1037\n",
      "    loss           : -1017.5503094474475\n",
      "    val_loss       : -722.917086270672\n",
      "    val_log_likelihood: 1315.8418514306431\n",
      "    val_log_marginal: 748.030167055905\n",
      "Train Epoch: 1038 [512/17352 (3%)] Loss: -1019.453491\n",
      "Train Epoch: 1038 [10067/17352 (58%)] Loss: -1074.067054\n",
      "Train Epoch: 1038 [16887/17352 (97%)] Loss: -992.304802\n",
      "    epoch          : 1038\n",
      "    loss           : -1018.4161769286042\n",
      "    val_loss       : -785.5426391500274\n",
      "    val_log_likelihood: 1320.239248616533\n",
      "    val_log_marginal: 800.6091965804924\n",
      "Train Epoch: 1039 [512/17352 (3%)] Loss: -903.923157\n",
      "Train Epoch: 1039 [10468/17352 (60%)] Loss: -1143.851014\n",
      "Train Epoch: 1039 [16957/17352 (98%)] Loss: -1025.305632\n",
      "    epoch          : 1039\n",
      "    loss           : -1024.2950155089288\n",
      "    val_loss       : -772.1227134453079\n",
      "    val_log_likelihood: 1326.1872454395202\n",
      "    val_log_marginal: 793.0617290089776\n",
      "Train Epoch: 1040 [512/17352 (3%)] Loss: -1086.255493\n",
      "Train Epoch: 1040 [10157/17352 (59%)] Loss: -1067.805030\n",
      "Train Epoch: 1040 [16878/17352 (97%)] Loss: -1042.283381\n",
      "    epoch          : 1040\n",
      "    loss           : -1029.9097901200985\n",
      "    val_loss       : -764.0744734616239\n",
      "    val_log_likelihood: 1325.7861804162533\n",
      "    val_log_marginal: 786.2587951201263\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1040.pth ...\n",
      "Train Epoch: 1041 [512/17352 (3%)] Loss: -1081.003784\n",
      "Train Epoch: 1041 [10305/17352 (59%)] Loss: -889.486489\n",
      "Train Epoch: 1041 [16883/17352 (97%)] Loss: -1023.890453\n",
      "    epoch          : 1041\n",
      "    loss           : -1038.6943662309598\n",
      "    val_loss       : -778.9567367023872\n",
      "    val_log_likelihood: 1334.7623499438637\n",
      "    val_log_marginal: 801.270431490529\n",
      "Train Epoch: 1042 [512/17352 (3%)] Loss: -1103.341064\n",
      "Train Epoch: 1042 [9766/17352 (56%)] Loss: -1095.428797\n",
      "Train Epoch: 1042 [17124/17352 (99%)] Loss: -932.265164\n",
      "    epoch          : 1042\n",
      "    loss           : -1018.6473579239108\n",
      "    val_loss       : -740.2076324408841\n",
      "    val_log_likelihood: 1311.6462752995365\n",
      "    val_log_marginal: 759.5301306559423\n",
      "Train Epoch: 1043 [512/17352 (3%)] Loss: -1049.839111\n",
      "Train Epoch: 1043 [10287/17352 (59%)] Loss: -987.609786\n",
      "Train Epoch: 1043 [16958/17352 (98%)] Loss: -1063.933638\n",
      "    epoch          : 1043\n",
      "    loss           : -1024.1918183963894\n",
      "    val_loss       : -754.9062617408526\n",
      "    val_log_likelihood: 1319.8040504725295\n",
      "    val_log_marginal: 781.3414018704794\n",
      "Train Epoch: 1044 [512/17352 (3%)] Loss: -1056.409668\n",
      "Train Epoch: 1044 [10285/17352 (59%)] Loss: -959.875725\n",
      "Train Epoch: 1044 [17049/17352 (98%)] Loss: -757.738710\n",
      "    epoch          : 1044\n",
      "    loss           : -983.9792736423636\n",
      "    val_loss       : -660.5049570074827\n",
      "    val_log_likelihood: 1247.0186082811815\n",
      "    val_log_marginal: 689.3181827283655\n",
      "Train Epoch: 1045 [512/17352 (3%)] Loss: -995.420959\n",
      "Train Epoch: 1045 [9888/17352 (57%)] Loss: -932.572838\n",
      "Train Epoch: 1045 [17126/17352 (99%)] Loss: -900.209465\n",
      "    epoch          : 1045\n",
      "    loss           : -964.2247628218784\n",
      "    val_loss       : -643.9411602740976\n",
      "    val_log_likelihood: 1228.9526408882616\n",
      "    val_log_marginal: 666.4694998130262\n",
      "Train Epoch: 1046 [512/17352 (3%)] Loss: -990.621460\n",
      "Train Epoch: 1046 [10410/17352 (60%)] Loss: -898.857656\n",
      "Train Epoch: 1046 [17124/17352 (99%)] Loss: -922.029221\n",
      "    epoch          : 1046\n",
      "    loss           : -973.9912611407941\n",
      "    val_loss       : -725.7274736447553\n",
      "    val_log_likelihood: 1293.6987124169239\n",
      "    val_log_marginal: 748.7640615365798\n",
      "Train Epoch: 1047 [512/17352 (3%)] Loss: -779.146484\n",
      "Train Epoch: 1047 [10226/17352 (59%)] Loss: -939.570350\n",
      "Train Epoch: 1047 [17106/17352 (99%)] Loss: -1100.093958\n",
      "    epoch          : 1047\n",
      "    loss           : -994.8466954461963\n",
      "    val_loss       : -678.5639461860658\n",
      "    val_log_likelihood: 1284.8906378273043\n",
      "    val_log_marginal: 703.7656729727688\n",
      "Train Epoch: 1048 [512/17352 (3%)] Loss: -1018.658691\n",
      "Train Epoch: 1048 [9894/17352 (57%)] Loss: -950.105193\n",
      "Train Epoch: 1048 [16882/17352 (97%)] Loss: -1037.608229\n",
      "    epoch          : 1048\n",
      "    loss           : -945.1745072803825\n",
      "    val_loss       : -685.2009110575075\n",
      "    val_log_likelihood: 1268.3992041989047\n",
      "    val_log_marginal: 707.1428281302252\n",
      "Train Epoch: 1049 [512/17352 (3%)] Loss: -958.098267\n",
      "Train Epoch: 1049 [10423/17352 (60%)] Loss: -556.127637\n",
      "Train Epoch: 1049 [16872/17352 (97%)] Loss: -625.967915\n",
      "    epoch          : 1049\n",
      "    loss           : -854.4262043925748\n",
      "    val_loss       : -434.58445749731055\n",
      "    val_log_likelihood: 1256.145156166211\n",
      "    val_log_marginal: 456.5665705298162\n",
      "Train Epoch: 1050 [512/17352 (3%)] Loss: -743.432739\n",
      "Train Epoch: 1050 [10161/17352 (59%)] Loss: -378.020962\n",
      "Train Epoch: 1050 [16878/17352 (97%)] Loss: -223.621467\n",
      "    epoch          : 1050\n",
      "    loss           : -604.7972107681109\n",
      "    val_loss       : -209.64706153163888\n",
      "    val_log_likelihood: 1217.2378393996878\n",
      "    val_log_marginal: 264.90772828363\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1050.pth ...\n",
      "Train Epoch: 1051 [512/17352 (3%)] Loss: -486.710968\n",
      "Train Epoch: 1051 [9905/17352 (57%)] Loss: -538.306424\n",
      "Train Epoch: 1051 [17133/17352 (99%)] Loss: -592.273759\n",
      "    epoch          : 1051\n",
      "    loss           : -698.5344942637942\n",
      "    val_loss       : -324.19947412311313\n",
      "    val_log_likelihood: 1228.9535087475938\n",
      "    val_log_marginal: 353.8267799108663\n",
      "Train Epoch: 1052 [512/17352 (3%)] Loss: -638.151550\n",
      "Train Epoch: 1052 [10262/17352 (59%)] Loss: -1081.855630\n",
      "Train Epoch: 1052 [17335/17352 (100%)] Loss: -1052.132529\n",
      "    epoch          : 1052\n",
      "    loss           : -886.1759033641999\n",
      "    val_loss       : -649.3086859734914\n",
      "    val_log_likelihood: 1277.8161087747758\n",
      "    val_log_marginal: 674.1995319222481\n",
      "Train Epoch: 1053 [512/17352 (3%)] Loss: -959.508423\n",
      "Train Epoch: 1053 [10314/17352 (59%)] Loss: -1137.318576\n",
      "Train Epoch: 1053 [17133/17352 (99%)] Loss: -1009.822287\n",
      "    epoch          : 1053\n",
      "    loss           : -981.2117901665733\n",
      "    val_loss       : -747.8399806356488\n",
      "    val_log_likelihood: 1295.2226881475103\n",
      "    val_log_marginal: 775.256630329786\n",
      "Train Epoch: 1054 [512/17352 (3%)] Loss: -1063.027588\n",
      "Train Epoch: 1054 [10243/17352 (59%)] Loss: -964.956752\n",
      "Train Epoch: 1054 [17049/17352 (98%)] Loss: -993.617424\n",
      "    epoch          : 1054\n",
      "    loss           : -1020.7473654431304\n",
      "    val_loss       : -780.4399865208217\n",
      "    val_log_likelihood: 1318.7183354505423\n",
      "    val_log_marginal: 803.1048764212194\n",
      "Train Epoch: 1055 [512/17352 (3%)] Loss: -1084.010986\n",
      "Train Epoch: 1055 [9997/17352 (58%)] Loss: -1130.447207\n",
      "Train Epoch: 1055 [16992/17352 (98%)] Loss: -1008.716732\n",
      "    epoch          : 1055\n",
      "    loss           : -1010.2346830868021\n",
      "    val_loss       : -678.6429105930451\n",
      "    val_log_likelihood: 1246.8168806101792\n",
      "    val_log_marginal: 701.393732346275\n",
      "Train Epoch: 1056 [512/17352 (3%)] Loss: -1017.890625\n",
      "Train Epoch: 1056 [10699/17352 (62%)] Loss: -499.058434\n",
      "Train Epoch: 1056 [17126/17352 (99%)] Loss: -934.999546\n",
      "    epoch          : 1056\n",
      "    loss           : -860.5941106826131\n",
      "    val_loss       : -681.1415303363468\n",
      "    val_log_likelihood: 1221.949517392594\n",
      "    val_log_marginal: 703.1239003826009\n",
      "Train Epoch: 1057 [512/17352 (3%)] Loss: -946.766907\n",
      "Train Epoch: 1057 [10548/17352 (61%)] Loss: -1046.839896\n",
      "Train Epoch: 1057 [17133/17352 (99%)] Loss: -1066.191099\n",
      "    epoch          : 1057\n",
      "    loss           : -966.2758146337299\n",
      "    val_loss       : -744.5328536297054\n",
      "    val_log_likelihood: 1277.1200968852097\n",
      "    val_log_marginal: 776.7441981180623\n",
      "Train Epoch: 1058 [512/17352 (3%)] Loss: -1031.452148\n",
      "Train Epoch: 1058 [10427/17352 (60%)] Loss: -1108.314800\n",
      "Train Epoch: 1058 [17335/17352 (100%)] Loss: -1141.273154\n",
      "    epoch          : 1058\n",
      "    loss           : -1007.7694383317247\n",
      "    val_loss       : -775.948629220856\n",
      "    val_log_likelihood: 1310.3392306209273\n",
      "    val_log_marginal: 800.2178828046293\n",
      "Train Epoch: 1059 [512/17352 (3%)] Loss: -1072.868408\n",
      "Train Epoch: 1059 [10036/17352 (58%)] Loss: -1104.267917\n",
      "Train Epoch: 1059 [16992/17352 (98%)] Loss: -1077.955551\n",
      "    epoch          : 1059\n",
      "    loss           : -1010.8804172280892\n",
      "    val_loss       : -732.0711653042239\n",
      "    val_log_likelihood: 1313.861723233926\n",
      "    val_log_marginal: 759.6804997827181\n",
      "Train Epoch: 1060 [512/17352 (3%)] Loss: -1013.421509\n",
      "Train Epoch: 1060 [10880/17352 (63%)] Loss: -968.759338\n",
      "Train Epoch: 1060 [17335/17352 (100%)] Loss: -802.929043\n",
      "    epoch          : 1060\n",
      "    loss           : -914.8800527523493\n",
      "    val_loss       : -687.6454986741625\n",
      "    val_log_likelihood: 1300.749030425725\n",
      "    val_log_marginal: 710.8701232204809\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1060.pth ...\n",
      "Train Epoch: 1061 [512/17352 (3%)] Loss: -965.190186\n",
      "Train Epoch: 1061 [10555/17352 (61%)] Loss: -1019.000258\n",
      "Train Epoch: 1061 [16878/17352 (97%)] Loss: -954.147220\n",
      "    epoch          : 1061\n",
      "    loss           : -991.3433436085477\n",
      "    val_loss       : -782.7675941643975\n",
      "    val_log_likelihood: 1321.1293481277673\n",
      "    val_log_marginal: 800.7219007656539\n",
      "Train Epoch: 1062 [512/17352 (3%)] Loss: -1047.872314\n",
      "Train Epoch: 1062 [10140/17352 (58%)] Loss: -921.664336\n",
      "Train Epoch: 1062 [17124/17352 (99%)] Loss: -935.595052\n",
      "    epoch          : 1062\n",
      "    loss           : -1025.0153720169662\n",
      "    val_loss       : -776.5728299208877\n",
      "    val_log_likelihood: 1323.156374482709\n",
      "    val_log_marginal: 789.4971943252501\n",
      "Train Epoch: 1063 [512/17352 (3%)] Loss: -1042.092041\n",
      "Train Epoch: 1063 [9924/17352 (57%)] Loss: -957.016544\n",
      "Train Epoch: 1063 [17044/17352 (98%)] Loss: -1106.812737\n",
      "    epoch          : 1063\n",
      "    loss           : -1028.3567309026612\n",
      "    val_loss       : -754.5712074199432\n",
      "    val_log_likelihood: 1333.023826899498\n",
      "    val_log_marginal: 791.514971628225\n",
      "Train Epoch: 1064 [512/17352 (3%)] Loss: -902.949951\n",
      "Train Epoch: 1064 [10128/17352 (58%)] Loss: -1133.841418\n",
      "Train Epoch: 1064 [16988/17352 (98%)] Loss: -954.596387\n",
      "    epoch          : 1064\n",
      "    loss           : -1023.6776110244032\n",
      "    val_loss       : -750.6920522705728\n",
      "    val_log_likelihood: 1337.419132556193\n",
      "    val_log_marginal: 768.9363712210027\n",
      "Train Epoch: 1065 [512/17352 (3%)] Loss: -1032.599365\n",
      "Train Epoch: 1065 [10306/17352 (59%)] Loss: -1053.622526\n",
      "Train Epoch: 1065 [16922/17352 (98%)] Loss: -943.479911\n",
      "    epoch          : 1065\n",
      "    loss           : -1017.358390889574\n",
      "    val_loss       : -777.0341204816294\n",
      "    val_log_likelihood: 1334.091190391511\n",
      "    val_log_marginal: 794.9527167247929\n",
      "Train Epoch: 1066 [512/17352 (3%)] Loss: -1078.184326\n",
      "Train Epoch: 1066 [9780/17352 (56%)] Loss: -882.484014\n",
      "Train Epoch: 1066 [16992/17352 (98%)] Loss: -1038.170849\n",
      "    epoch          : 1066\n",
      "    loss           : -1033.2904906369356\n",
      "    val_loss       : -790.5339122087585\n",
      "    val_log_likelihood: 1336.480231196695\n",
      "    val_log_marginal: 805.045363051961\n",
      "Train Epoch: 1067 [512/17352 (3%)] Loss: -1088.271484\n",
      "Train Epoch: 1067 [10324/17352 (59%)] Loss: -1166.339134\n",
      "Train Epoch: 1067 [17106/17352 (99%)] Loss: -989.127561\n",
      "    epoch          : 1067\n",
      "    loss           : -1048.1974918925366\n",
      "    val_loss       : -760.0715047830562\n",
      "    val_log_likelihood: 1330.5699955662399\n",
      "    val_log_marginal: 784.0105666916995\n",
      "Train Epoch: 1068 [512/17352 (3%)] Loss: -1082.999023\n",
      "Train Epoch: 1068 [10075/17352 (58%)] Loss: -1097.113125\n",
      "Train Epoch: 1068 [17126/17352 (99%)] Loss: -1116.051890\n",
      "    epoch          : 1068\n",
      "    loss           : -1044.6456574086778\n",
      "    val_loss       : -762.0129305752729\n",
      "    val_log_likelihood: 1328.5958645522255\n",
      "    val_log_marginal: 778.7755669689142\n",
      "Train Epoch: 1069 [512/17352 (3%)] Loss: -1086.364746\n",
      "Train Epoch: 1069 [10184/17352 (59%)] Loss: -909.277389\n",
      "Train Epoch: 1069 [16934/17352 (98%)] Loss: -1011.815934\n",
      "    epoch          : 1069\n",
      "    loss           : -1017.862054552674\n",
      "    val_loss       : -766.7732251172934\n",
      "    val_log_likelihood: 1330.9346727454529\n",
      "    val_log_marginal: 793.7031722159885\n",
      "Train Epoch: 1070 [512/17352 (3%)] Loss: -1071.221558\n",
      "Train Epoch: 1070 [10262/17352 (59%)] Loss: -1088.041424\n",
      "Train Epoch: 1070 [16939/17352 (98%)] Loss: -956.072443\n",
      "    epoch          : 1070\n",
      "    loss           : -1024.5032938488098\n",
      "    val_loss       : -788.3228394806263\n",
      "    val_log_likelihood: 1337.7922089510093\n",
      "    val_log_marginal: 804.2314684357615\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1070.pth ...\n",
      "Train Epoch: 1071 [512/17352 (3%)] Loss: -1085.114502\n",
      "Train Epoch: 1071 [10020/17352 (58%)] Loss: -964.230786\n",
      "Train Epoch: 1071 [17253/17352 (99%)] Loss: -1013.366639\n",
      "    epoch          : 1071\n",
      "    loss           : -1037.3713697618289\n",
      "    val_loss       : -761.7484369821716\n",
      "    val_log_likelihood: 1329.245364504446\n",
      "    val_log_marginal: 778.8708114385854\n",
      "Train Epoch: 1072 [512/17352 (3%)] Loss: -1079.653320\n",
      "Train Epoch: 1072 [10281/17352 (59%)] Loss: -1031.945443\n",
      "Train Epoch: 1072 [16878/17352 (97%)] Loss: -976.330459\n",
      "    epoch          : 1072\n",
      "    loss           : -1033.6596237511985\n",
      "    val_loss       : -781.9169008347114\n",
      "    val_log_likelihood: 1340.20546987668\n",
      "    val_log_marginal: 802.4465450999534\n",
      "Train Epoch: 1073 [512/17352 (3%)] Loss: -1084.037231\n",
      "Train Epoch: 1073 [10210/17352 (59%)] Loss: -959.477651\n",
      "Train Epoch: 1073 [17101/17352 (99%)] Loss: -827.484788\n",
      "    epoch          : 1073\n",
      "    loss           : -1029.2581269049585\n",
      "    val_loss       : -767.8737771788428\n",
      "    val_log_likelihood: 1336.70244718577\n",
      "    val_log_marginal: 786.5315740828933\n",
      "Train Epoch: 1074 [512/17352 (3%)] Loss: -1071.612793\n",
      "Train Epoch: 1074 [10426/17352 (60%)] Loss: -901.219587\n",
      "Train Epoch: 1074 [17108/17352 (99%)] Loss: -1049.861667\n",
      "    epoch          : 1074\n",
      "    loss           : -919.9532741858508\n",
      "    val_loss       : -684.9922520890103\n",
      "    val_log_likelihood: 1310.4349670930467\n",
      "    val_log_marginal: 705.9326834216739\n",
      "Train Epoch: 1075 [512/17352 (3%)] Loss: -955.425964\n",
      "Train Epoch: 1075 [10347/17352 (60%)] Loss: -1039.698297\n",
      "Train Epoch: 1075 [16992/17352 (98%)] Loss: -772.733553\n",
      "    epoch          : 1075\n",
      "    loss           : -946.3290088669261\n",
      "    val_loss       : -624.1221293603285\n",
      "    val_log_likelihood: 1250.7502344262464\n",
      "    val_log_marginal: 646.5618701888089\n",
      "Train Epoch: 1076 [512/17352 (3%)] Loss: -934.742676\n",
      "Train Epoch: 1076 [10270/17352 (59%)] Loss: -960.145378\n",
      "Train Epoch: 1076 [16939/17352 (98%)] Loss: -868.049141\n",
      "    epoch          : 1076\n",
      "    loss           : -958.70094659005\n",
      "    val_loss       : -602.0844373268964\n",
      "    val_log_likelihood: 1300.1187812408452\n",
      "    val_log_marginal: 623.905050663109\n",
      "Train Epoch: 1077 [512/17352 (3%)] Loss: -941.908630\n",
      "Train Epoch: 1077 [10291/17352 (59%)] Loss: -1028.170289\n",
      "Train Epoch: 1077 [17126/17352 (99%)] Loss: 50.298669\n",
      "    epoch          : 1077\n",
      "    loss           : -709.8000031610438\n",
      "    val_loss       : 1605.767414742086\n",
      "    val_log_likelihood: 1056.6363032470676\n",
      "    val_log_marginal: -1567.4099067704326\n",
      "Train Epoch: 1078 [512/17352 (3%)] Loss: 720.509155\n",
      "Train Epoch: 1078 [10225/17352 (59%)] Loss: -208.319748\n",
      "Train Epoch: 1078 [16992/17352 (98%)] Loss: -653.284177\n",
      "    epoch          : 1078\n",
      "    loss           : -75.22788611950872\n",
      "    val_loss       : -355.3409275228702\n",
      "    val_log_likelihood: 1113.2637384359623\n",
      "    val_log_marginal: 412.4175361246292\n",
      "Train Epoch: 1079 [512/17352 (3%)] Loss: -617.317505\n",
      "Train Epoch: 1079 [10025/17352 (58%)] Loss: -673.139354\n",
      "Train Epoch: 1079 [17064/17352 (98%)] Loss: -927.466304\n",
      "    epoch          : 1079\n",
      "    loss           : -839.7500633644441\n",
      "    val_loss       : -709.0394142131311\n",
      "    val_log_likelihood: 1261.2187177270987\n",
      "    val_log_marginal: 746.5301075449078\n",
      "Train Epoch: 1080 [512/17352 (3%)] Loss: -1007.531067\n",
      "Train Epoch: 1080 [10391/17352 (60%)] Loss: -906.245066\n",
      "Train Epoch: 1080 [17263/17352 (99%)] Loss: -825.759592\n",
      "    epoch          : 1080\n",
      "    loss           : -986.7174045436153\n",
      "    val_loss       : -718.0867117041366\n",
      "    val_log_likelihood: 1296.6818531734527\n",
      "    val_log_marginal: 739.5672998150485\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1080.pth ...\n",
      "Train Epoch: 1081 [512/17352 (3%)] Loss: -1007.528076\n",
      "Train Epoch: 1081 [10378/17352 (60%)] Loss: -864.031549\n",
      "Train Epoch: 1081 [16882/17352 (97%)] Loss: -1070.885707\n",
      "    epoch          : 1081\n",
      "    loss           : -1011.9274259445135\n",
      "    val_loss       : -762.2277125907835\n",
      "    val_log_likelihood: 1302.285137699948\n",
      "    val_log_marginal: 776.4868047474106\n",
      "Train Epoch: 1082 [512/17352 (3%)] Loss: -1072.125488\n",
      "Train Epoch: 1082 [10042/17352 (58%)] Loss: -1046.971930\n",
      "Train Epoch: 1082 [16882/17352 (97%)] Loss: -1047.431059\n",
      "    epoch          : 1082\n",
      "    loss           : -1013.3693333862649\n",
      "    val_loss       : -764.8586394428928\n",
      "    val_log_likelihood: 1316.334420941179\n",
      "    val_log_marginal: 791.0968772474141\n",
      "Train Epoch: 1083 [512/17352 (3%)] Loss: -899.117310\n",
      "Train Epoch: 1083 [10329/17352 (60%)] Loss: -1085.444233\n",
      "Train Epoch: 1083 [16872/17352 (97%)] Loss: -1090.292925\n",
      "    epoch          : 1083\n",
      "    loss           : -1003.676755472413\n",
      "    val_loss       : -775.8575559593002\n",
      "    val_log_likelihood: 1315.897777694671\n",
      "    val_log_marginal: 788.1054994927772\n",
      "Train Epoch: 1084 [512/17352 (3%)] Loss: -1082.812988\n",
      "Train Epoch: 1084 [10620/17352 (61%)] Loss: -965.585047\n",
      "Train Epoch: 1084 [16923/17352 (98%)] Loss: -1025.884204\n",
      "    epoch          : 1084\n",
      "    loss           : -1025.5615874950915\n",
      "    val_loss       : -790.156694257976\n",
      "    val_log_likelihood: 1334.597346596684\n",
      "    val_log_marginal: 803.5417903909755\n",
      "Train Epoch: 1085 [512/17352 (3%)] Loss: -914.673035\n",
      "Train Epoch: 1085 [9869/17352 (57%)] Loss: -1079.133342\n",
      "Train Epoch: 1085 [16883/17352 (97%)] Loss: -1143.522993\n",
      "    epoch          : 1085\n",
      "    loss           : -1036.406137532888\n",
      "    val_loss       : -783.528435869839\n",
      "    val_log_likelihood: 1332.1972201313818\n",
      "    val_log_marginal: 801.9430520348491\n",
      "Train Epoch: 1086 [512/17352 (3%)] Loss: -1087.286499\n",
      "Train Epoch: 1086 [10178/17352 (59%)] Loss: -1105.951984\n",
      "Train Epoch: 1086 [16887/17352 (97%)] Loss: -1109.085501\n",
      "    epoch          : 1086\n",
      "    loss           : -1033.5223465378747\n",
      "    val_loss       : -799.4047691072343\n",
      "    val_log_likelihood: 1340.779090592506\n",
      "    val_log_marginal: 818.8964026872171\n",
      "Train Epoch: 1087 [512/17352 (3%)] Loss: -1091.258789\n",
      "Train Epoch: 1087 [10208/17352 (59%)] Loss: -1184.023872\n",
      "Train Epoch: 1087 [16878/17352 (97%)] Loss: -990.862132\n",
      "    epoch          : 1087\n",
      "    loss           : -1018.2263948083438\n",
      "    val_loss       : -718.4995708499085\n",
      "    val_log_likelihood: 1318.200899347448\n",
      "    val_log_marginal: 777.5778597431478\n",
      "Train Epoch: 1088 [512/17352 (3%)] Loss: -1060.449585\n",
      "Train Epoch: 1088 [10474/17352 (60%)] Loss: -1099.196265\n",
      "Train Epoch: 1088 [16872/17352 (97%)] Loss: -1010.981043\n",
      "    epoch          : 1088\n",
      "    loss           : -977.9959264876336\n",
      "    val_loss       : -770.1921231623407\n",
      "    val_log_likelihood: 1318.6736703538086\n",
      "    val_log_marginal: 796.0438960670665\n",
      "Train Epoch: 1089 [512/17352 (3%)] Loss: -1080.385010\n",
      "Train Epoch: 1089 [10433/17352 (60%)] Loss: -1103.109262\n",
      "Train Epoch: 1089 [16958/17352 (98%)] Loss: -1041.843513\n",
      "    epoch          : 1089\n",
      "    loss           : -979.276351675898\n",
      "    val_loss       : -725.6479641589978\n",
      "    val_log_likelihood: 1313.1357653464197\n",
      "    val_log_marginal: 752.3364869642105\n",
      "Train Epoch: 1090 [512/17352 (3%)] Loss: -1038.058594\n",
      "Train Epoch: 1090 [10618/17352 (61%)] Loss: -933.250558\n",
      "Train Epoch: 1090 [16934/17352 (98%)] Loss: -799.417742\n",
      "    epoch          : 1090\n",
      "    loss           : -951.0044102674728\n",
      "    val_loss       : -705.9326677163674\n",
      "    val_log_likelihood: 1292.377214397875\n",
      "    val_log_marginal: 728.7600174674857\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1090.pth ...\n",
      "Train Epoch: 1091 [512/17352 (3%)] Loss: -1041.653076\n",
      "Train Epoch: 1091 [10057/17352 (58%)] Loss: -1075.610417\n",
      "Train Epoch: 1091 [17064/17352 (98%)] Loss: -1116.210247\n",
      "    epoch          : 1091\n",
      "    loss           : -1025.3446888278002\n",
      "    val_loss       : -794.8714937286046\n",
      "    val_log_likelihood: 1338.3982436959034\n",
      "    val_log_marginal: 812.204631561543\n",
      "Train Epoch: 1092 [512/17352 (3%)] Loss: -1078.043823\n",
      "Train Epoch: 1092 [10005/17352 (58%)] Loss: -1048.134049\n",
      "Train Epoch: 1092 [16992/17352 (98%)] Loss: -1122.587234\n",
      "    epoch          : 1092\n",
      "    loss           : -1041.0481983544646\n",
      "    val_loss       : -782.9663203875783\n",
      "    val_log_likelihood: 1343.0765065071414\n",
      "    val_log_marginal: 802.786912766864\n",
      "Train Epoch: 1093 [512/17352 (3%)] Loss: -1082.541016\n",
      "Train Epoch: 1093 [10350/17352 (60%)] Loss: -1125.369131\n",
      "Train Epoch: 1093 [17101/17352 (99%)] Loss: -1070.799154\n",
      "    epoch          : 1093\n",
      "    loss           : -1047.699024526073\n",
      "    val_loss       : -790.2258417849542\n",
      "    val_log_likelihood: 1347.3342531791377\n",
      "    val_log_marginal: 809.3284267307314\n",
      "Train Epoch: 1094 [512/17352 (3%)] Loss: -1096.838867\n",
      "Train Epoch: 1094 [9667/17352 (56%)] Loss: -991.991728\n",
      "Train Epoch: 1094 [17143/17352 (99%)] Loss: -1133.361789\n",
      "    epoch          : 1094\n",
      "    loss           : -1038.7999806439466\n",
      "    val_loss       : -749.6676837013732\n",
      "    val_log_likelihood: 1335.595554530559\n",
      "    val_log_marginal: 765.0314961064358\n",
      "Train Epoch: 1095 [512/17352 (3%)] Loss: -1076.674316\n",
      "Train Epoch: 1095 [10351/17352 (60%)] Loss: -987.257347\n",
      "Train Epoch: 1095 [16957/17352 (98%)] Loss: -875.953873\n",
      "    epoch          : 1095\n",
      "    loss           : -1031.3201092735178\n",
      "    val_loss       : -777.069315639196\n",
      "    val_log_likelihood: 1343.6695369077993\n",
      "    val_log_marginal: 794.7602442242601\n",
      "Train Epoch: 1096 [512/17352 (3%)] Loss: -1049.798828\n",
      "Train Epoch: 1096 [10558/17352 (61%)] Loss: -1078.187695\n",
      "Train Epoch: 1096 [17124/17352 (99%)] Loss: -1127.605011\n",
      "    epoch          : 1096\n",
      "    loss           : -1036.13172433897\n",
      "    val_loss       : -711.9808995095983\n",
      "    val_log_likelihood: 1314.4882400392257\n",
      "    val_log_marginal: 736.0303631770995\n",
      "Train Epoch: 1097 [512/17352 (3%)] Loss: -1026.100708\n",
      "Train Epoch: 1097 [9850/17352 (57%)] Loss: -1091.103258\n",
      "Train Epoch: 1097 [17108/17352 (99%)] Loss: -1096.730568\n",
      "    epoch          : 1097\n",
      "    loss           : -1001.427674245914\n",
      "    val_loss       : -745.7643184166751\n",
      "    val_log_likelihood: 1306.216999252217\n",
      "    val_log_marginal: 762.778214476359\n",
      "Train Epoch: 1098 [512/17352 (3%)] Loss: -1068.489746\n",
      "Train Epoch: 1098 [10190/17352 (59%)] Loss: -1125.428494\n",
      "Train Epoch: 1098 [16878/17352 (97%)] Loss: -1024.309073\n",
      "    epoch          : 1098\n",
      "    loss           : -1017.1956430124762\n",
      "    val_loss       : -771.1754149539083\n",
      "    val_log_likelihood: 1336.7376691010709\n",
      "    val_log_marginal: 792.6418084517571\n",
      "Train Epoch: 1099 [512/17352 (3%)] Loss: -1099.862793\n",
      "Train Epoch: 1099 [10301/17352 (59%)] Loss: -1123.873255\n",
      "Train Epoch: 1099 [17124/17352 (99%)] Loss: -1141.118603\n",
      "    epoch          : 1099\n",
      "    loss           : -1043.1116438154615\n",
      "    val_loss       : -770.5826828065967\n",
      "    val_log_likelihood: 1340.3169487139862\n",
      "    val_log_marginal: 791.0901670247781\n",
      "Train Epoch: 1100 [512/17352 (3%)] Loss: -1092.781006\n",
      "Train Epoch: 1100 [10491/17352 (60%)] Loss: -1106.607268\n",
      "Train Epoch: 1100 [17106/17352 (99%)] Loss: -1083.501875\n",
      "    epoch          : 1100\n",
      "    loss           : -1045.3251544113689\n",
      "    val_loss       : -744.8079499024476\n",
      "    val_log_likelihood: 1335.9394734234124\n",
      "    val_log_marginal: 764.5460848963382\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1100.pth ...\n",
      "Train Epoch: 1101 [512/17352 (3%)] Loss: -1072.260010\n",
      "Train Epoch: 1101 [10438/17352 (60%)] Loss: -1123.451582\n",
      "Train Epoch: 1101 [17016/17352 (98%)] Loss: -1165.297635\n",
      "    epoch          : 1101\n",
      "    loss           : -1031.8903928836266\n",
      "    val_loss       : -773.7734089484035\n",
      "    val_log_likelihood: 1340.302000358668\n",
      "    val_log_marginal: 788.162782029368\n",
      "Train Epoch: 1102 [512/17352 (3%)] Loss: -1095.614990\n",
      "Train Epoch: 1102 [9758/17352 (56%)] Loss: -1088.717813\n",
      "Train Epoch: 1102 [16957/17352 (98%)] Loss: -1076.771810\n",
      "    epoch          : 1102\n",
      "    loss           : -1044.7276654210882\n",
      "    val_loss       : -743.5682743778536\n",
      "    val_log_likelihood: 1322.854019458205\n",
      "    val_log_marginal: 763.1340007395867\n",
      "Train Epoch: 1103 [512/17352 (3%)] Loss: -1046.298828\n",
      "Train Epoch: 1103 [10770/17352 (62%)] Loss: -1140.971519\n",
      "Train Epoch: 1103 [16958/17352 (98%)] Loss: -1122.559019\n",
      "    epoch          : 1103\n",
      "    loss           : -1023.0298799128246\n",
      "    val_loss       : -758.0945905881218\n",
      "    val_log_likelihood: 1350.6158884118347\n",
      "    val_log_marginal: 780.1567740723946\n",
      "Train Epoch: 1104 [512/17352 (3%)] Loss: -1076.562988\n",
      "Train Epoch: 1104 [10408/17352 (60%)] Loss: -917.863036\n",
      "Train Epoch: 1104 [16922/17352 (98%)] Loss: -888.202506\n",
      "    epoch          : 1104\n",
      "    loss           : -1037.2193351711273\n",
      "    val_loss       : -767.0701054283937\n",
      "    val_log_likelihood: 1342.5884185756506\n",
      "    val_log_marginal: 787.3043684608348\n",
      "Train Epoch: 1105 [512/17352 (3%)] Loss: -1085.439697\n",
      "Train Epoch: 1105 [10533/17352 (61%)] Loss: -1117.816042\n",
      "Train Epoch: 1105 [16934/17352 (98%)] Loss: -1111.922710\n",
      "    epoch          : 1105\n",
      "    loss           : -1042.4879123532687\n",
      "    val_loss       : -787.5852730876225\n",
      "    val_log_likelihood: 1350.6962936313596\n",
      "    val_log_marginal: 807.7262962413919\n",
      "Train Epoch: 1106 [512/17352 (3%)] Loss: -1110.022827\n",
      "Train Epoch: 1106 [10661/17352 (61%)] Loss: -1008.874721\n",
      "Train Epoch: 1106 [17277/17352 (100%)] Loss: -1071.230371\n",
      "    epoch          : 1106\n",
      "    loss           : -1030.1476517061208\n",
      "    val_loss       : -733.0196573187279\n",
      "    val_log_likelihood: 1322.771328330052\n",
      "    val_log_marginal: 762.7079819756507\n",
      "Train Epoch: 1107 [512/17352 (3%)] Loss: -1073.113770\n",
      "Train Epoch: 1107 [10754/17352 (62%)] Loss: -1155.024120\n",
      "Train Epoch: 1107 [16923/17352 (98%)] Loss: -1088.752426\n",
      "    epoch          : 1107\n",
      "    loss           : -1036.6149514634662\n",
      "    val_loss       : -758.4958746811817\n",
      "    val_log_likelihood: 1342.1852439638185\n",
      "    val_log_marginal: 780.5170260042017\n",
      "Train Epoch: 1108 [512/17352 (3%)] Loss: -1073.175659\n",
      "Train Epoch: 1108 [10161/17352 (59%)] Loss: -913.185471\n",
      "Train Epoch: 1108 [17049/17352 (98%)] Loss: -1029.548503\n",
      "    epoch          : 1108\n",
      "    loss           : -1032.3192213245895\n",
      "    val_loss       : -760.8779737476951\n",
      "    val_log_likelihood: 1345.176530493054\n",
      "    val_log_marginal: 783.7780893263908\n",
      "Train Epoch: 1109 [512/17352 (3%)] Loss: -896.410889\n",
      "Train Epoch: 1109 [10254/17352 (59%)] Loss: -946.242882\n",
      "Train Epoch: 1109 [16988/17352 (98%)] Loss: -877.537052\n",
      "    epoch          : 1109\n",
      "    loss           : -1016.613607420935\n",
      "    val_loss       : -687.2778610885857\n",
      "    val_log_likelihood: 1282.2827197686229\n",
      "    val_log_marginal: 707.5101270165366\n",
      "Train Epoch: 1110 [512/17352 (3%)] Loss: -1010.602661\n",
      "Train Epoch: 1110 [9931/17352 (57%)] Loss: -1047.997853\n",
      "Train Epoch: 1110 [17049/17352 (98%)] Loss: -1058.972852\n",
      "    epoch          : 1110\n",
      "    loss           : -1019.2400678862331\n",
      "    val_loss       : -740.1078419687183\n",
      "    val_log_likelihood: 1324.362873629601\n",
      "    val_log_marginal: 762.4995060913889\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1110.pth ...\n",
      "Train Epoch: 1111 [512/17352 (3%)] Loss: -1062.217163\n",
      "Train Epoch: 1111 [10881/17352 (63%)] Loss: -1104.139447\n",
      "Train Epoch: 1111 [17064/17352 (98%)] Loss: -1160.649254\n",
      "    epoch          : 1111\n",
      "    loss           : -1052.0147184544041\n",
      "    val_loss       : -788.7788507695349\n",
      "    val_log_likelihood: 1350.9297043941406\n",
      "    val_log_marginal: 805.824574141074\n",
      "Train Epoch: 1112 [512/17352 (3%)] Loss: -1109.113770\n",
      "Train Epoch: 1112 [10263/17352 (59%)] Loss: -1041.805117\n",
      "Train Epoch: 1112 [16922/17352 (98%)] Loss: -1132.616037\n",
      "    epoch          : 1112\n",
      "    loss           : -1041.6904080506124\n",
      "    val_loss       : -773.6824009446196\n",
      "    val_log_likelihood: 1338.135149911412\n",
      "    val_log_marginal: 792.3493462486658\n",
      "Train Epoch: 1113 [512/17352 (3%)] Loss: -1078.054932\n",
      "Train Epoch: 1113 [10500/17352 (61%)] Loss: -961.195724\n",
      "Train Epoch: 1113 [17101/17352 (99%)] Loss: -1033.241012\n",
      "    epoch          : 1113\n",
      "    loss           : -1034.6706449286678\n",
      "    val_loss       : -737.4833425248414\n",
      "    val_log_likelihood: 1324.7776925600822\n",
      "    val_log_marginal: 755.3971347246267\n",
      "Train Epoch: 1114 [512/17352 (3%)] Loss: -1080.268799\n",
      "Train Epoch: 1114 [10576/17352 (61%)] Loss: -1070.770667\n",
      "Train Epoch: 1114 [16939/17352 (98%)] Loss: -1123.281504\n",
      "    epoch          : 1114\n",
      "    loss           : -1026.3092800869006\n",
      "    val_loss       : -753.3957009085464\n",
      "    val_log_likelihood: 1335.476413824011\n",
      "    val_log_marginal: 775.4545265655851\n",
      "Train Epoch: 1115 [512/17352 (3%)] Loss: -1083.079224\n",
      "Train Epoch: 1115 [9878/17352 (57%)] Loss: -1008.811985\n",
      "Train Epoch: 1115 [17126/17352 (99%)] Loss: -906.905594\n",
      "    epoch          : 1115\n",
      "    loss           : -1028.8049325012796\n",
      "    val_loss       : -779.3252821138468\n",
      "    val_log_likelihood: 1343.9988491624383\n",
      "    val_log_marginal: 799.4823413711296\n",
      "Train Epoch: 1116 [512/17352 (3%)] Loss: -1086.821777\n",
      "Train Epoch: 1116 [10051/17352 (58%)] Loss: -889.962665\n",
      "Train Epoch: 1116 [16939/17352 (98%)] Loss: -1087.122931\n",
      "    epoch          : 1116\n",
      "    loss           : -1041.2888217478028\n",
      "    val_loss       : -783.566602215216\n",
      "    val_log_likelihood: 1354.6047089589185\n",
      "    val_log_marginal: 808.9476654228815\n",
      "Train Epoch: 1117 [512/17352 (3%)] Loss: -1112.810303\n",
      "Train Epoch: 1117 [10701/17352 (62%)] Loss: -1167.468950\n",
      "Train Epoch: 1117 [17044/17352 (98%)] Loss: -1162.242963\n",
      "    epoch          : 1117\n",
      "    loss           : -1037.586690778709\n",
      "    val_loss       : -767.2547364251452\n",
      "    val_log_likelihood: 1345.168589601115\n",
      "    val_log_marginal: 785.8703870496577\n",
      "Train Epoch: 1118 [512/17352 (3%)] Loss: -1082.875610\n",
      "Train Epoch: 1118 [10132/17352 (58%)] Loss: -1103.068974\n",
      "Train Epoch: 1118 [17253/17352 (99%)] Loss: -1156.608883\n",
      "    epoch          : 1118\n",
      "    loss           : -1032.2234323419261\n",
      "    val_loss       : -628.4477297221938\n",
      "    val_log_likelihood: 1325.8627291615364\n",
      "    val_log_marginal: 645.8427899556876\n",
      "Train Epoch: 1119 [512/17352 (3%)] Loss: -944.429749\n",
      "Train Epoch: 1119 [10589/17352 (61%)] Loss: -933.086335\n",
      "Train Epoch: 1119 [16923/17352 (98%)] Loss: 717.487234\n",
      "    epoch          : 1119\n",
      "    loss           : -668.7570700028676\n",
      "    val_loss       : 582.0620606916557\n",
      "    val_log_likelihood: 1182.278530428958\n",
      "    val_log_marginal: -547.7090327716837\n",
      "Train Epoch: 1120 [512/17352 (3%)] Loss: 117.151764\n",
      "Train Epoch: 1120 [9966/17352 (57%)] Loss: -958.953854\n",
      "Train Epoch: 1120 [16958/17352 (98%)] Loss: -937.110692\n",
      "    epoch          : 1120\n",
      "    loss           : -729.7526594794379\n",
      "    val_loss       : -545.9019216208068\n",
      "    val_log_likelihood: 1188.3786658208146\n",
      "    val_log_marginal: 629.2754216402606\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1120.pth ...\n",
      "Train Epoch: 1121 [512/17352 (3%)] Loss: -893.422424\n",
      "Train Epoch: 1121 [10743/17352 (62%)] Loss: -1036.716688\n",
      "Train Epoch: 1121 [16934/17352 (98%)] Loss: -1045.987437\n",
      "    epoch          : 1121\n",
      "    loss           : -927.0875779694704\n",
      "    val_loss       : -724.0911195618868\n",
      "    val_log_likelihood: 1292.6367324524897\n",
      "    val_log_marginal: 759.4981684162944\n",
      "Train Epoch: 1122 [512/17352 (3%)] Loss: -992.442383\n",
      "Train Epoch: 1122 [10133/17352 (58%)] Loss: -931.252922\n",
      "Train Epoch: 1122 [17044/17352 (98%)] Loss: -943.261892\n",
      "    epoch          : 1122\n",
      "    loss           : -968.0983970156016\n",
      "    val_loss       : -712.0411515715505\n",
      "    val_log_likelihood: 1293.9578019158514\n",
      "    val_log_marginal: 733.5359154435234\n",
      "Train Epoch: 1123 [512/17352 (3%)] Loss: -1010.567139\n",
      "Train Epoch: 1123 [10474/17352 (60%)] Loss: -1097.626108\n",
      "Train Epoch: 1123 [16934/17352 (98%)] Loss: -1056.231391\n",
      "    epoch          : 1123\n",
      "    loss           : -988.1670017176896\n",
      "    val_loss       : -764.4775394084851\n",
      "    val_log_likelihood: 1322.0004858798936\n",
      "    val_log_marginal: 781.5718408183664\n",
      "Train Epoch: 1124 [512/17352 (3%)] Loss: -1072.757324\n",
      "Train Epoch: 1124 [10200/17352 (59%)] Loss: -1064.367948\n",
      "Train Epoch: 1124 [17277/17352 (100%)] Loss: -1112.030773\n",
      "    epoch          : 1124\n",
      "    loss           : -1043.913978860117\n",
      "    val_loss       : -759.6057961289878\n",
      "    val_log_likelihood: 1335.5252825782602\n",
      "    val_log_marginal: 777.199682156934\n",
      "Train Epoch: 1125 [512/17352 (3%)] Loss: -1073.920898\n",
      "Train Epoch: 1125 [9975/17352 (57%)] Loss: -979.610784\n",
      "Train Epoch: 1125 [17153/17352 (99%)] Loss: -1138.696717\n",
      "    epoch          : 1125\n",
      "    loss           : -1051.9809927255517\n",
      "    val_loss       : -777.6590950763356\n",
      "    val_log_likelihood: 1347.399940151997\n",
      "    val_log_marginal: 798.3593252730894\n",
      "Train Epoch: 1126 [512/17352 (3%)] Loss: -1089.152344\n",
      "Train Epoch: 1126 [9758/17352 (56%)] Loss: -987.664175\n",
      "Train Epoch: 1126 [17126/17352 (99%)] Loss: -1123.290379\n",
      "    epoch          : 1126\n",
      "    loss           : -1053.0124261458782\n",
      "    val_loss       : -791.2030563424823\n",
      "    val_log_likelihood: 1357.8454794386291\n",
      "    val_log_marginal: 818.5788805577598\n",
      "Train Epoch: 1127 [512/17352 (3%)] Loss: -1105.116089\n",
      "Train Epoch: 1127 [10401/17352 (60%)] Loss: -939.729895\n",
      "Train Epoch: 1127 [16934/17352 (98%)] Loss: -1101.029819\n",
      "    epoch          : 1127\n",
      "    loss           : -1064.4276654537061\n",
      "    val_loss       : -794.5653105181932\n",
      "    val_log_likelihood: 1361.0627268917672\n",
      "    val_log_marginal: 809.9297384340533\n",
      "Train Epoch: 1128 [512/17352 (3%)] Loss: -1109.471680\n",
      "Train Epoch: 1128 [10467/17352 (60%)] Loss: -1162.502799\n",
      "Train Epoch: 1128 [17253/17352 (99%)] Loss: -910.537366\n",
      "    epoch          : 1128\n",
      "    loss           : -1058.8721524483385\n",
      "    val_loss       : -769.0710900354289\n",
      "    val_log_likelihood: 1352.0561659098244\n",
      "    val_log_marginal: 788.4199581661564\n",
      "Train Epoch: 1129 [512/17352 (3%)] Loss: -1078.476196\n",
      "Train Epoch: 1129 [9818/17352 (57%)] Loss: -1094.183076\n",
      "Train Epoch: 1129 [16872/17352 (97%)] Loss: -912.856116\n",
      "    epoch          : 1129\n",
      "    loss           : -1059.27914104609\n",
      "    val_loss       : -776.1795082921268\n",
      "    val_log_likelihood: 1351.8772990788098\n",
      "    val_log_marginal: 797.3315231796868\n",
      "Train Epoch: 1130 [512/17352 (3%)] Loss: -920.602783\n",
      "Train Epoch: 1130 [10923/17352 (63%)] Loss: -938.932110\n",
      "Train Epoch: 1130 [16883/17352 (97%)] Loss: -1043.290433\n",
      "    epoch          : 1130\n",
      "    loss           : -1054.1759650785812\n",
      "    val_loss       : -768.969896701234\n",
      "    val_log_likelihood: 1348.9429420437752\n",
      "    val_log_marginal: 790.9236736723818\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1130.pth ...\n",
      "Train Epoch: 1131 [512/17352 (3%)] Loss: -1104.103027\n",
      "Train Epoch: 1131 [10044/17352 (58%)] Loss: -1122.944786\n",
      "Train Epoch: 1131 [17153/17352 (99%)] Loss: -942.556353\n",
      "    epoch          : 1131\n",
      "    loss           : -1049.7566279486061\n",
      "    val_loss       : -759.3566951631034\n",
      "    val_log_likelihood: 1346.6556470754558\n",
      "    val_log_marginal: 778.8190386717126\n",
      "Train Epoch: 1132 [512/17352 (3%)] Loss: -1080.624390\n",
      "Train Epoch: 1132 [10035/17352 (58%)] Loss: -1106.409849\n",
      "Train Epoch: 1132 [17335/17352 (100%)] Loss: -921.788366\n",
      "    epoch          : 1132\n",
      "    loss           : -1049.4984222506139\n",
      "    val_loss       : -777.7500294772418\n",
      "    val_log_likelihood: 1351.8285281871579\n",
      "    val_log_marginal: 796.5524528122808\n",
      "Train Epoch: 1133 [512/17352 (3%)] Loss: -1108.581787\n",
      "Train Epoch: 1133 [10144/17352 (58%)] Loss: -1139.003323\n",
      "Train Epoch: 1133 [17124/17352 (99%)] Loss: -1193.937391\n",
      "    epoch          : 1133\n",
      "    loss           : -1061.330164868894\n",
      "    val_loss       : -779.8590611184364\n",
      "    val_log_likelihood: 1349.2032541044034\n",
      "    val_log_marginal: 796.4507899146538\n",
      "Train Epoch: 1134 [512/17352 (3%)] Loss: -1112.816650\n",
      "Train Epoch: 1134 [10524/17352 (61%)] Loss: -960.195515\n",
      "Train Epoch: 1134 [17124/17352 (99%)] Loss: -852.328899\n",
      "    epoch          : 1134\n",
      "    loss           : -1053.784550408937\n",
      "    val_loss       : -723.0756089222333\n",
      "    val_log_likelihood: 1353.8642826684281\n",
      "    val_log_marginal: 744.4002077014545\n",
      "Train Epoch: 1135 [512/17352 (3%)] Loss: -1046.979492\n",
      "Train Epoch: 1135 [10660/17352 (61%)] Loss: -1130.126031\n",
      "Train Epoch: 1135 [17153/17352 (99%)] Loss: -483.224245\n",
      "    epoch          : 1135\n",
      "    loss           : -981.6104834084795\n",
      "    val_loss       : -360.5960334628036\n",
      "    val_log_likelihood: 1300.8822780346295\n",
      "    val_log_marginal: 380.82239962931743\n",
      "Train Epoch: 1136 [512/17352 (3%)] Loss: -638.295166\n",
      "Train Epoch: 1136 [10770/17352 (62%)] Loss: -484.172286\n",
      "Train Epoch: 1136 [17253/17352 (99%)] Loss: -1025.368513\n",
      "    epoch          : 1136\n",
      "    loss           : -885.9457350245275\n",
      "    val_loss       : -582.9255790256706\n",
      "    val_log_likelihood: 1270.7210583045319\n",
      "    val_log_marginal: 619.9029988897328\n",
      "Train Epoch: 1137 [512/17352 (3%)] Loss: -903.704834\n",
      "Train Epoch: 1137 [9937/17352 (57%)] Loss: -1048.717083\n",
      "Train Epoch: 1137 [16887/17352 (97%)] Loss: -1050.782620\n",
      "    epoch          : 1137\n",
      "    loss           : -938.7917847025686\n",
      "    val_loss       : -728.9587744102075\n",
      "    val_log_likelihood: 1308.8163538081092\n",
      "    val_log_marginal: 767.8754300892867\n",
      "Train Epoch: 1138 [512/17352 (3%)] Loss: -1016.037964\n",
      "Train Epoch: 1138 [10858/17352 (63%)] Loss: -1015.633703\n",
      "Train Epoch: 1138 [17277/17352 (100%)] Loss: -572.892946\n",
      "    epoch          : 1138\n",
      "    loss           : -879.9137611557709\n",
      "    val_loss       : -645.4261759322471\n",
      "    val_log_likelihood: 1279.5689896522988\n",
      "    val_log_marginal: 686.8826851392423\n",
      "Train Epoch: 1139 [512/17352 (3%)] Loss: -978.515991\n",
      "Train Epoch: 1139 [10611/17352 (61%)] Loss: -910.512153\n",
      "Train Epoch: 1139 [16934/17352 (98%)] Loss: -899.026255\n",
      "    epoch          : 1139\n",
      "    loss           : -944.4680597426576\n",
      "    val_loss       : -695.9150454817969\n",
      "    val_log_likelihood: 1293.876987198864\n",
      "    val_log_marginal: 715.7040005171907\n",
      "Train Epoch: 1140 [512/17352 (3%)] Loss: -997.879028\n",
      "Train Epoch: 1140 [9797/17352 (56%)] Loss: -1120.539479\n",
      "Train Epoch: 1140 [16934/17352 (98%)] Loss: -975.509098\n",
      "    epoch          : 1140\n",
      "    loss           : -1017.1285253832958\n",
      "    val_loss       : -745.3777083523855\n",
      "    val_log_likelihood: 1320.7475439813486\n",
      "    val_log_marginal: 765.3218020943362\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1140.pth ...\n",
      "Train Epoch: 1141 [512/17352 (3%)] Loss: -1048.197266\n",
      "Train Epoch: 1141 [10781/17352 (62%)] Loss: -1097.904382\n",
      "Train Epoch: 1141 [16939/17352 (98%)] Loss: -1131.958228\n",
      "    epoch          : 1141\n",
      "    loss           : -1037.527092270171\n",
      "    val_loss       : -777.0607054607593\n",
      "    val_log_likelihood: 1346.9841035018576\n",
      "    val_log_marginal: 799.2107634423879\n",
      "Train Epoch: 1142 [512/17352 (3%)] Loss: -1086.706299\n",
      "Train Epoch: 1142 [10496/17352 (60%)] Loss: -1007.069928\n",
      "Train Epoch: 1142 [16882/17352 (97%)] Loss: -956.149476\n",
      "    epoch          : 1142\n",
      "    loss           : -1052.8154362596918\n",
      "    val_loss       : -786.4161002138055\n",
      "    val_log_likelihood: 1346.7807962002419\n",
      "    val_log_marginal: 805.2874812222518\n",
      "Train Epoch: 1143 [512/17352 (3%)] Loss: -1120.787842\n",
      "Train Epoch: 1143 [10248/17352 (59%)] Loss: -1095.532840\n",
      "Train Epoch: 1143 [17064/17352 (98%)] Loss: -1137.902522\n",
      "    epoch          : 1143\n",
      "    loss           : -1059.0709526671342\n",
      "    val_loss       : -761.1897082459988\n",
      "    val_log_likelihood: 1348.9142789689117\n",
      "    val_log_marginal: 785.0490167465846\n",
      "Train Epoch: 1144 [512/17352 (3%)] Loss: -1069.920166\n",
      "Train Epoch: 1144 [10222/17352 (59%)] Loss: -1052.931332\n",
      "Train Epoch: 1144 [17335/17352 (100%)] Loss: -1018.664615\n",
      "    epoch          : 1144\n",
      "    loss           : -1047.8551887987214\n",
      "    val_loss       : -740.6934634988953\n",
      "    val_log_likelihood: 1340.9596631642971\n",
      "    val_log_marginal: 757.0759997017925\n",
      "Train Epoch: 1145 [512/17352 (3%)] Loss: -1051.301147\n",
      "Train Epoch: 1145 [10103/17352 (58%)] Loss: -1083.193557\n",
      "Train Epoch: 1145 [16934/17352 (98%)] Loss: -951.725809\n",
      "    epoch          : 1145\n",
      "    loss           : -1010.1529856138369\n",
      "    val_loss       : -709.5794366891549\n",
      "    val_log_likelihood: 1296.3139723488296\n",
      "    val_log_marginal: 722.6895991192436\n",
      "Train Epoch: 1146 [512/17352 (3%)] Loss: -781.581421\n",
      "Train Epoch: 1146 [10288/17352 (59%)] Loss: -1023.978274\n",
      "Train Epoch: 1146 [17106/17352 (99%)] Loss: -888.525359\n",
      "    epoch          : 1146\n",
      "    loss           : -954.771821534446\n",
      "    val_loss       : -708.8675377003511\n",
      "    val_log_likelihood: 1315.4278401330819\n",
      "    val_log_marginal: 734.5608130250329\n",
      "Train Epoch: 1147 [512/17352 (3%)] Loss: -843.053955\n",
      "Train Epoch: 1147 [10470/17352 (60%)] Loss: -762.885766\n",
      "Train Epoch: 1147 [17064/17352 (98%)] Loss: -627.699128\n",
      "    epoch          : 1147\n",
      "    loss           : -856.5213044480033\n",
      "    val_loss       : 892.3050262030703\n",
      "    val_log_likelihood: 1142.753053869704\n",
      "    val_log_marginal: -844.872632442182\n",
      "Train Epoch: 1148 [512/17352 (3%)] Loss: 612.070496\n",
      "Train Epoch: 1148 [10201/17352 (59%)] Loss: -808.153001\n",
      "Train Epoch: 1148 [17101/17352 (99%)] Loss: 81.525847\n",
      "    epoch          : 1148\n",
      "    loss           : -552.0831147970135\n",
      "    val_loss       : 95.15168558968458\n",
      "    val_log_likelihood: 1216.5629937222825\n",
      "    val_log_marginal: -48.830797143308665\n",
      "Train Epoch: 1149 [512/17352 (3%)] Loss: -282.607605\n",
      "Train Epoch: 1149 [9802/17352 (56%)] Loss: -876.009100\n",
      "Train Epoch: 1149 [16872/17352 (97%)] Loss: -604.189807\n",
      "    epoch          : 1149\n",
      "    loss           : -765.7249873815624\n",
      "    val_loss       : -205.67576172720865\n",
      "    val_log_likelihood: 1251.6832816762058\n",
      "    val_log_marginal: 232.87465096306343\n",
      "Train Epoch: 1150 [512/17352 (3%)] Loss: -648.251831\n",
      "Train Epoch: 1150 [10442/17352 (60%)] Loss: -744.858610\n",
      "Train Epoch: 1150 [17090/17352 (98%)] Loss: -993.703657\n",
      "    epoch          : 1150\n",
      "    loss           : -882.7344005374559\n",
      "    val_loss       : -668.1775897719435\n",
      "    val_log_likelihood: 1290.3174157429046\n",
      "    val_log_marginal: 705.3280811339356\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1150.pth ...\n",
      "Train Epoch: 1151 [512/17352 (3%)] Loss: -969.308533\n",
      "Train Epoch: 1151 [10677/17352 (62%)] Loss: -1158.628906\n",
      "Train Epoch: 1151 [17126/17352 (99%)] Loss: -1077.031516\n",
      "    epoch          : 1151\n",
      "    loss           : -871.0269273089662\n",
      "    val_loss       : -581.3147070315256\n",
      "    val_log_likelihood: 1309.0109830060035\n",
      "    val_log_marginal: 610.3335240961253\n",
      "Train Epoch: 1152 [512/17352 (3%)] Loss: -871.972900\n",
      "Train Epoch: 1152 [10145/17352 (58%)] Loss: -789.157682\n",
      "Train Epoch: 1152 [16922/17352 (98%)] Loss: -851.872200\n",
      "    epoch          : 1152\n",
      "    loss           : -814.7803358172921\n",
      "    val_loss       : -414.98023115757144\n",
      "    val_log_likelihood: 1260.2486777162405\n",
      "    val_log_marginal: 426.3754402656995\n",
      "Train Epoch: 1153 [512/17352 (3%)] Loss: -827.829346\n",
      "Train Epoch: 1153 [10646/17352 (61%)] Loss: -1000.359203\n",
      "Train Epoch: 1153 [17126/17352 (99%)] Loss: -1127.059840\n",
      "    epoch          : 1153\n",
      "    loss           : -964.6398478871913\n",
      "    val_loss       : -746.1621789255732\n",
      "    val_log_likelihood: 1304.1156120584442\n",
      "    val_log_marginal: 767.2954288079214\n",
      "Train Epoch: 1154 [512/17352 (3%)] Loss: -1064.473755\n",
      "Train Epoch: 1154 [10171/17352 (59%)] Loss: -1038.245172\n",
      "Train Epoch: 1154 [17277/17352 (100%)] Loss: -829.964286\n",
      "    epoch          : 1154\n",
      "    loss           : -960.4158257924605\n",
      "    val_loss       : -699.6525716108093\n",
      "    val_log_likelihood: 1278.3700585353654\n",
      "    val_log_marginal: 732.9804706504768\n",
      "Train Epoch: 1155 [512/17352 (3%)] Loss: -992.600037\n",
      "Train Epoch: 1155 [9718/17352 (56%)] Loss: -976.690675\n",
      "Train Epoch: 1155 [17153/17352 (99%)] Loss: -1040.940885\n",
      "    epoch          : 1155\n",
      "    loss           : -966.8880071382009\n",
      "    val_loss       : -631.7762211066361\n",
      "    val_log_likelihood: 1321.573898895423\n",
      "    val_log_marginal: 650.2469904184334\n",
      "Train Epoch: 1156 [512/17352 (3%)] Loss: -939.984558\n",
      "Train Epoch: 1156 [10869/17352 (63%)] Loss: -1017.082717\n",
      "Train Epoch: 1156 [16923/17352 (98%)] Loss: -1004.260417\n",
      "    epoch          : 1156\n",
      "    loss           : -1027.990042350427\n",
      "    val_loss       : -781.2531522015506\n",
      "    val_log_likelihood: 1334.962891289768\n",
      "    val_log_marginal: 799.2416477102505\n",
      "Train Epoch: 1157 [512/17352 (3%)] Loss: -911.514771\n",
      "Train Epoch: 1157 [9696/17352 (56%)] Loss: -977.348535\n",
      "Train Epoch: 1157 [16957/17352 (98%)] Loss: -916.985215\n",
      "    epoch          : 1157\n",
      "    loss           : -1057.3876416828325\n",
      "    val_loss       : -800.2165632654229\n",
      "    val_log_likelihood: 1352.164654513165\n",
      "    val_log_marginal: 821.0030734724178\n",
      "Train Epoch: 1158 [512/17352 (3%)] Loss: -1108.638916\n",
      "Train Epoch: 1158 [10288/17352 (59%)] Loss: -988.859001\n",
      "Train Epoch: 1158 [17064/17352 (98%)] Loss: -918.317473\n",
      "    epoch          : 1158\n",
      "    loss           : -1058.979648869313\n",
      "    val_loss       : -790.3943585093756\n",
      "    val_log_likelihood: 1348.558914993314\n",
      "    val_log_marginal: 806.2218704775186\n",
      "Train Epoch: 1159 [512/17352 (3%)] Loss: -1108.408203\n",
      "Train Epoch: 1159 [9977/17352 (57%)] Loss: -1167.927337\n",
      "Train Epoch: 1159 [17253/17352 (99%)] Loss: -1000.411420\n",
      "    epoch          : 1159\n",
      "    loss           : -1063.4556140309346\n",
      "    val_loss       : -784.5780669797119\n",
      "    val_log_likelihood: 1353.4789344537069\n",
      "    val_log_marginal: 805.0548278623656\n",
      "Train Epoch: 1160 [512/17352 (3%)] Loss: -1076.585449\n",
      "Train Epoch: 1160 [10373/17352 (60%)] Loss: -925.946970\n",
      "Train Epoch: 1160 [16988/17352 (98%)] Loss: -1053.760705\n",
      "    epoch          : 1160\n",
      "    loss           : -1035.1927283815523\n",
      "    val_loss       : -749.0495985821979\n",
      "    val_log_likelihood: 1340.1163727786966\n",
      "    val_log_marginal: 767.3117689924211\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1160.pth ...\n",
      "Train Epoch: 1161 [512/17352 (3%)] Loss: -1073.028809\n",
      "Train Epoch: 1161 [10651/17352 (61%)] Loss: -1090.293191\n",
      "Train Epoch: 1161 [16939/17352 (98%)] Loss: -1071.377120\n",
      "    epoch          : 1161\n",
      "    loss           : -996.5388100496974\n",
      "    val_loss       : -737.3508649258422\n",
      "    val_log_likelihood: 1330.8476273384317\n",
      "    val_log_marginal: 757.090739441723\n",
      "Train Epoch: 1162 [512/17352 (3%)] Loss: -1044.215576\n",
      "Train Epoch: 1162 [10932/17352 (63%)] Loss: -918.040359\n",
      "Train Epoch: 1162 [16992/17352 (98%)] Loss: -1009.262929\n",
      "    epoch          : 1162\n",
      "    loss           : -888.7589673282245\n",
      "    val_loss       : -684.5884289009998\n",
      "    val_log_likelihood: 1307.1909147741205\n",
      "    val_log_marginal: 710.9098995586727\n",
      "Train Epoch: 1163 [512/17352 (3%)] Loss: -970.874817\n",
      "Train Epoch: 1163 [10639/17352 (61%)] Loss: -1043.033491\n",
      "Train Epoch: 1163 [17126/17352 (99%)] Loss: -1002.978451\n",
      "    epoch          : 1163\n",
      "    loss           : -949.5686786834752\n",
      "    val_loss       : -758.6019123802083\n",
      "    val_log_likelihood: 1323.16335471484\n",
      "    val_log_marginal: 785.6232236628015\n",
      "Train Epoch: 1164 [512/17352 (3%)] Loss: -1074.187988\n",
      "Train Epoch: 1164 [10498/17352 (61%)] Loss: -1129.192454\n",
      "Train Epoch: 1164 [17263/17352 (99%)] Loss: -1085.524062\n",
      "    epoch          : 1164\n",
      "    loss           : -1016.2216564268374\n",
      "    val_loss       : -710.7576268653422\n",
      "    val_log_likelihood: 1307.2026059785817\n",
      "    val_log_marginal: 734.1252444531239\n",
      "Train Epoch: 1165 [512/17352 (3%)] Loss: -1018.491699\n",
      "Train Epoch: 1165 [10066/17352 (58%)] Loss: -1025.615385\n",
      "Train Epoch: 1165 [17153/17352 (99%)] Loss: -1147.209222\n",
      "    epoch          : 1165\n",
      "    loss           : -1034.9965184655498\n",
      "    val_loss       : -763.6218533206627\n",
      "    val_log_likelihood: 1327.864625190869\n",
      "    val_log_marginal: 783.9602878113808\n",
      "Train Epoch: 1166 [512/17352 (3%)] Loss: -1072.407715\n",
      "Train Epoch: 1166 [9898/17352 (57%)] Loss: -1138.856520\n",
      "Train Epoch: 1166 [16922/17352 (98%)] Loss: -1059.283808\n",
      "    epoch          : 1166\n",
      "    loss           : -1049.348651425243\n",
      "    val_loss       : -784.9459916132344\n",
      "    val_log_likelihood: 1355.8102439709655\n",
      "    val_log_marginal: 802.9141162563362\n",
      "Train Epoch: 1167 [512/17352 (3%)] Loss: -1087.505249\n",
      "Train Epoch: 1167 [10248/17352 (59%)] Loss: -1129.439533\n",
      "Train Epoch: 1167 [17049/17352 (98%)] Loss: -1106.197988\n",
      "    epoch          : 1167\n",
      "    loss           : -1059.5330535236615\n",
      "    val_loss       : -802.2475782573791\n",
      "    val_log_likelihood: 1361.9033291762191\n",
      "    val_log_marginal: 820.7630142175019\n",
      "Train Epoch: 1168 [512/17352 (3%)] Loss: -1119.105591\n",
      "Train Epoch: 1168 [10695/17352 (62%)] Loss: -996.801389\n",
      "Train Epoch: 1168 [17133/17352 (99%)] Loss: -1145.542222\n",
      "    epoch          : 1168\n",
      "    loss           : -1051.2970845960633\n",
      "    val_loss       : -757.4696211452869\n",
      "    val_log_likelihood: 1341.9465180621771\n",
      "    val_log_marginal: 779.7583297419911\n",
      "Train Epoch: 1169 [512/17352 (3%)] Loss: -1109.777222\n",
      "Train Epoch: 1169 [10396/17352 (60%)] Loss: -1085.203685\n",
      "Train Epoch: 1169 [17044/17352 (98%)] Loss: -997.850211\n",
      "    epoch          : 1169\n",
      "    loss           : -1049.9555560978554\n",
      "    val_loss       : -755.3510011149051\n",
      "    val_log_likelihood: 1355.6785379911003\n",
      "    val_log_marginal: 780.9172561190131\n",
      "Train Epoch: 1170 [512/17352 (3%)] Loss: -1070.673950\n",
      "Train Epoch: 1170 [10226/17352 (59%)] Loss: -1097.638646\n",
      "Train Epoch: 1170 [16958/17352 (98%)] Loss: -1099.160234\n",
      "    epoch          : 1170\n",
      "    loss           : -1048.309796247215\n",
      "    val_loss       : -779.1229288599958\n",
      "    val_log_likelihood: 1357.0038051220572\n",
      "    val_log_marginal: 794.9332741007779\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1170.pth ...\n",
      "Train Epoch: 1171 [512/17352 (3%)] Loss: -1098.344116\n",
      "Train Epoch: 1171 [10321/17352 (59%)] Loss: -917.163779\n",
      "Train Epoch: 1171 [17124/17352 (99%)] Loss: -1132.953634\n",
      "    epoch          : 1171\n",
      "    loss           : -1062.160007074317\n",
      "    val_loss       : -788.2520718273819\n",
      "    val_log_likelihood: 1363.2965313176148\n",
      "    val_log_marginal: 802.7250483578305\n",
      "Train Epoch: 1172 [512/17352 (3%)] Loss: -1106.481689\n",
      "Train Epoch: 1172 [10581/17352 (61%)] Loss: -1080.418956\n",
      "Train Epoch: 1172 [16887/17352 (97%)] Loss: -1065.066111\n",
      "    epoch          : 1172\n",
      "    loss           : -1059.276441011987\n",
      "    val_loss       : -737.6337160557362\n",
      "    val_log_likelihood: 1363.1758194092909\n",
      "    val_log_marginal: 755.0017038349903\n",
      "Train Epoch: 1173 [512/17352 (3%)] Loss: -1068.143677\n",
      "Train Epoch: 1173 [10183/17352 (59%)] Loss: -1129.324870\n",
      "Train Epoch: 1173 [17124/17352 (99%)] Loss: -979.616419\n",
      "    epoch          : 1173\n",
      "    loss           : -1055.6506662742122\n",
      "    val_loss       : -785.3152977947128\n",
      "    val_log_likelihood: 1363.9222218923828\n",
      "    val_log_marginal: 802.1648042065656\n",
      "Train Epoch: 1174 [512/17352 (3%)] Loss: -1100.894775\n",
      "Train Epoch: 1174 [10533/17352 (61%)] Loss: -1127.481235\n",
      "Train Epoch: 1174 [17106/17352 (99%)] Loss: -994.464933\n",
      "    epoch          : 1174\n",
      "    loss           : -1027.7395323835253\n",
      "    val_loss       : -464.7124860653118\n",
      "    val_log_likelihood: 1347.5624106862733\n",
      "    val_log_marginal: 487.73220982696927\n",
      "Train Epoch: 1175 [512/17352 (3%)] Loss: -676.804810\n",
      "Train Epoch: 1175 [9907/17352 (57%)] Loss: -962.180936\n",
      "Train Epoch: 1175 [17049/17352 (98%)] Loss: -952.557487\n",
      "    epoch          : 1175\n",
      "    loss           : -852.6427671595218\n",
      "    val_loss       : -525.8557243444535\n",
      "    val_log_likelihood: 1161.5249474268035\n",
      "    val_log_marginal: 554.8977550635782\n",
      "Train Epoch: 1176 [512/17352 (3%)] Loss: -851.562622\n",
      "Train Epoch: 1176 [9609/17352 (55%)] Loss: -1109.530380\n",
      "Train Epoch: 1176 [16878/17352 (97%)] Loss: -1110.157447\n",
      "    epoch          : 1176\n",
      "    loss           : -978.0946340552815\n",
      "    val_loss       : -753.4460404804464\n",
      "    val_log_likelihood: 1316.043877771019\n",
      "    val_log_marginal: 772.9009745784558\n",
      "Train Epoch: 1177 [512/17352 (3%)] Loss: -1070.612305\n",
      "Train Epoch: 1177 [10181/17352 (59%)] Loss: -1088.465485\n",
      "Train Epoch: 1177 [17277/17352 (100%)] Loss: -1091.318555\n",
      "    epoch          : 1177\n",
      "    loss           : -1041.7392985986887\n",
      "    val_loss       : -740.7997795663557\n",
      "    val_log_likelihood: 1323.8829953354268\n",
      "    val_log_marginal: 758.6094394594967\n",
      "Train Epoch: 1178 [512/17352 (3%)] Loss: -1067.537109\n",
      "Train Epoch: 1178 [10656/17352 (61%)] Loss: -886.555099\n",
      "Train Epoch: 1178 [16883/17352 (97%)] Loss: -958.668544\n",
      "    epoch          : 1178\n",
      "    loss           : -988.6774195198834\n",
      "    val_loss       : -656.8209841096026\n",
      "    val_log_likelihood: 1334.296502991339\n",
      "    val_log_marginal: 675.2284850734343\n",
      "Train Epoch: 1179 [512/17352 (3%)] Loss: -953.049500\n",
      "Train Epoch: 1179 [10815/17352 (62%)] Loss: -1104.384994\n",
      "Train Epoch: 1179 [17263/17352 (99%)] Loss: -1101.465194\n",
      "    epoch          : 1179\n",
      "    loss           : -969.4606597962236\n",
      "    val_loss       : -610.5703290773364\n",
      "    val_log_likelihood: 1295.8489851289494\n",
      "    val_log_marginal: 638.1414525315665\n",
      "Train Epoch: 1180 [512/17352 (3%)] Loss: -932.982300\n",
      "Train Epoch: 1180 [10083/17352 (58%)] Loss: -852.478032\n",
      "Train Epoch: 1180 [16992/17352 (98%)] Loss: -809.202809\n",
      "    epoch          : 1180\n",
      "    loss           : -954.6238746450379\n",
      "    val_loss       : -624.7450637848164\n",
      "    val_log_likelihood: 1256.7069069911684\n",
      "    val_log_marginal: 701.8819532787929\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1180.pth ...\n",
      "Train Epoch: 1181 [512/17352 (3%)] Loss: -929.171692\n",
      "Train Epoch: 1181 [10127/17352 (58%)] Loss: -1072.513291\n",
      "Train Epoch: 1181 [17133/17352 (99%)] Loss: -922.427390\n",
      "    epoch          : 1181\n",
      "    loss           : -876.1857058379105\n",
      "    val_loss       : -446.5438731897686\n",
      "    val_log_likelihood: 1046.0078007147686\n",
      "    val_log_marginal: 484.9110105527493\n",
      "Train Epoch: 1182 [512/17352 (3%)] Loss: -847.916687\n",
      "Train Epoch: 1182 [10433/17352 (60%)] Loss: -990.476475\n",
      "Train Epoch: 1182 [16939/17352 (98%)] Loss: -442.751142\n",
      "    epoch          : 1182\n",
      "    loss           : -877.0359494319848\n",
      "    val_loss       : -646.3073964427338\n",
      "    val_log_likelihood: 1256.8173758238524\n",
      "    val_log_marginal: 709.3841813343918\n",
      "Train Epoch: 1183 [512/17352 (3%)] Loss: -1018.468994\n",
      "Train Epoch: 1183 [10740/17352 (62%)] Loss: -941.923669\n",
      "Train Epoch: 1183 [16934/17352 (98%)] Loss: -744.679043\n",
      "    epoch          : 1183\n",
      "    loss           : -972.6627987740872\n",
      "    val_loss       : -747.4009970127807\n",
      "    val_log_likelihood: 1310.2754371228395\n",
      "    val_log_marginal: 781.8046312472816\n",
      "Train Epoch: 1184 [512/17352 (3%)] Loss: -1067.088745\n",
      "Train Epoch: 1184 [10831/17352 (62%)] Loss: -937.552156\n",
      "Train Epoch: 1184 [17016/17352 (98%)] Loss: -1044.248603\n",
      "    epoch          : 1184\n",
      "    loss           : -972.8805025466422\n",
      "    val_loss       : -758.6797762092731\n",
      "    val_log_likelihood: 1332.1658329758943\n",
      "    val_log_marginal: 785.9476468802422\n",
      "Train Epoch: 1185 [512/17352 (3%)] Loss: -1067.388428\n",
      "Train Epoch: 1185 [10635/17352 (61%)] Loss: -958.851469\n",
      "Train Epoch: 1185 [17124/17352 (99%)] Loss: -1030.072285\n",
      "    epoch          : 1185\n",
      "    loss           : -964.6626190651021\n",
      "    val_loss       : -532.2690828406935\n",
      "    val_log_likelihood: 1327.2936744340648\n",
      "    val_log_marginal: 552.0772976918498\n",
      "Train Epoch: 1186 [512/17352 (3%)] Loss: -839.615479\n",
      "Train Epoch: 1186 [10511/17352 (61%)] Loss: -836.643690\n",
      "Train Epoch: 1186 [16958/17352 (98%)] Loss: -1113.958822\n",
      "    epoch          : 1186\n",
      "    loss           : -948.8571170385517\n",
      "    val_loss       : -717.1392966221556\n",
      "    val_log_likelihood: 1330.3449016433337\n",
      "    val_log_marginal: 738.9966897682125\n",
      "Train Epoch: 1187 [512/17352 (3%)] Loss: -1018.330994\n",
      "Train Epoch: 1187 [10229/17352 (59%)] Loss: -1064.581305\n",
      "Train Epoch: 1187 [16883/17352 (97%)] Loss: -889.920380\n",
      "    epoch          : 1187\n",
      "    loss           : -1044.918717544726\n",
      "    val_loss       : -797.7698970831163\n",
      "    val_log_likelihood: 1344.5860077399611\n",
      "    val_log_marginal: 814.9819368495858\n",
      "Train Epoch: 1188 [512/17352 (3%)] Loss: -1088.004639\n",
      "Train Epoch: 1188 [10448/17352 (60%)] Loss: -960.150493\n",
      "Train Epoch: 1188 [16872/17352 (97%)] Loss: -1014.905990\n",
      "    epoch          : 1188\n",
      "    loss           : -1053.7304913565333\n",
      "    val_loss       : -778.853977521037\n",
      "    val_log_likelihood: 1345.5066805834058\n",
      "    val_log_marginal: 797.3345861941585\n",
      "Train Epoch: 1189 [512/17352 (3%)] Loss: -1112.388428\n",
      "Train Epoch: 1189 [10471/17352 (60%)] Loss: -1169.837772\n",
      "Train Epoch: 1189 [17124/17352 (99%)] Loss: -1012.517793\n",
      "    epoch          : 1189\n",
      "    loss           : -1064.8617714231636\n",
      "    val_loss       : -803.7171062708884\n",
      "    val_log_likelihood: 1364.439751034801\n",
      "    val_log_marginal: 826.7317514376281\n",
      "Train Epoch: 1190 [512/17352 (3%)] Loss: -1112.386719\n",
      "Train Epoch: 1190 [10028/17352 (58%)] Loss: -986.907147\n",
      "Train Epoch: 1190 [17106/17352 (99%)] Loss: -1098.369645\n",
      "    epoch          : 1190\n",
      "    loss           : -1067.6855111242455\n",
      "    val_loss       : -788.2834160642558\n",
      "    val_log_likelihood: 1359.1393667420382\n",
      "    val_log_marginal: 806.1384648271641\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1190.pth ...\n",
      "Train Epoch: 1191 [512/17352 (3%)] Loss: -1112.942871\n",
      "Train Epoch: 1191 [10561/17352 (61%)] Loss: -1156.598450\n",
      "Train Epoch: 1191 [17133/17352 (99%)] Loss: -1132.593115\n",
      "    epoch          : 1191\n",
      "    loss           : -1072.0682680065977\n",
      "    val_loss       : -802.0485354459938\n",
      "    val_log_likelihood: 1372.4272942873538\n",
      "    val_log_marginal: 821.2712078057606\n",
      "Train Epoch: 1192 [512/17352 (3%)] Loss: -1112.952271\n",
      "Train Epoch: 1192 [10411/17352 (60%)] Loss: -1169.976118\n",
      "Train Epoch: 1192 [17124/17352 (99%)] Loss: -1123.535490\n",
      "    epoch          : 1192\n",
      "    loss           : -1076.1416634807645\n",
      "    val_loss       : -788.4284076995044\n",
      "    val_log_likelihood: 1369.3088342938668\n",
      "    val_log_marginal: 807.0266641040231\n",
      "Train Epoch: 1193 [512/17352 (3%)] Loss: -1130.432617\n",
      "Train Epoch: 1193 [10948/17352 (63%)] Loss: -1012.952821\n",
      "Train Epoch: 1193 [17108/17352 (99%)] Loss: -951.814103\n",
      "    epoch          : 1193\n",
      "    loss           : -1077.4459173023163\n",
      "    val_loss       : -784.2302064392079\n",
      "    val_log_likelihood: 1370.9950938556158\n",
      "    val_log_marginal: 802.094992807227\n",
      "Train Epoch: 1194 [512/17352 (3%)] Loss: -1113.336426\n",
      "Train Epoch: 1194 [10278/17352 (59%)] Loss: -1131.289062\n",
      "Train Epoch: 1194 [17049/17352 (98%)] Loss: -996.016639\n",
      "    epoch          : 1194\n",
      "    loss           : -981.1113527361085\n",
      "    val_loss       : -680.9326256944926\n",
      "    val_log_likelihood: 1342.566134827281\n",
      "    val_log_marginal: 709.3083802425066\n",
      "Train Epoch: 1195 [512/17352 (3%)] Loss: -936.860962\n",
      "Train Epoch: 1195 [10201/17352 (59%)] Loss: -919.906906\n",
      "Train Epoch: 1195 [16939/17352 (98%)] Loss: -1075.393114\n",
      "    epoch          : 1195\n",
      "    loss           : -1005.8811107955568\n",
      "    val_loss       : -756.493863412229\n",
      "    val_log_likelihood: 1337.7382216978244\n",
      "    val_log_marginal: 777.4259887565967\n",
      "Train Epoch: 1196 [512/17352 (3%)] Loss: -1030.106567\n",
      "Train Epoch: 1196 [9892/17352 (57%)] Loss: -1095.183199\n",
      "Train Epoch: 1196 [17106/17352 (99%)] Loss: -1087.596027\n",
      "    epoch          : 1196\n",
      "    loss           : -1027.101140245759\n",
      "    val_loss       : -728.3677596236752\n",
      "    val_log_likelihood: 1340.5175599809327\n",
      "    val_log_marginal: 751.4346693180543\n",
      "Train Epoch: 1197 [512/17352 (3%)] Loss: -1064.378052\n",
      "Train Epoch: 1197 [10315/17352 (59%)] Loss: -913.384834\n",
      "Train Epoch: 1197 [16872/17352 (97%)] Loss: -991.100103\n",
      "    epoch          : 1197\n",
      "    loss           : -1001.4296538046748\n",
      "    val_loss       : -754.9874056654207\n",
      "    val_log_likelihood: 1346.9205797421055\n",
      "    val_log_marginal: 774.9063592559003\n",
      "Train Epoch: 1198 [512/17352 (3%)] Loss: -1080.966309\n",
      "Train Epoch: 1198 [10474/17352 (60%)] Loss: -976.103609\n",
      "Train Epoch: 1198 [17064/17352 (98%)] Loss: -1159.365938\n",
      "    epoch          : 1198\n",
      "    loss           : -1020.9928849012887\n",
      "    val_loss       : -752.5810103095516\n",
      "    val_log_likelihood: 1352.9685341848915\n",
      "    val_log_marginal: 789.4918946411523\n",
      "Train Epoch: 1199 [512/17352 (3%)] Loss: -1085.614746\n",
      "Train Epoch: 1199 [10072/17352 (58%)] Loss: -1133.577425\n",
      "Train Epoch: 1199 [16887/17352 (97%)] Loss: -1002.835323\n",
      "    epoch          : 1199\n",
      "    loss           : -996.2990429778285\n",
      "    val_loss       : -735.6763454032063\n",
      "    val_log_likelihood: 1344.7950879291122\n",
      "    val_log_marginal: 759.0134648033749\n",
      "Train Epoch: 1200 [512/17352 (3%)] Loss: -1011.326111\n",
      "Train Epoch: 1200 [10604/17352 (61%)] Loss: -1054.135851\n",
      "Train Epoch: 1200 [17133/17352 (99%)] Loss: -830.808320\n",
      "    epoch          : 1200\n",
      "    loss           : -974.8508707420244\n",
      "    val_loss       : -620.5528740070312\n",
      "    val_log_likelihood: 1331.1698809643644\n",
      "    val_log_marginal: 636.511709846063\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0504_170408/checkpoint-epoch1200.pth ...\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:categorical_bpl] *",
   "language": "python",
   "name": "conda-env-categorical_bpl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
